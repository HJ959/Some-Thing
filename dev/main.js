/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@babel/runtime/helpers/arrayLikeToArray.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/arrayLikeToArray.js ***!
  \*****************************************************************/
/***/ ((module) => {

eval("function _arrayLikeToArray(arr, len) {\n  if (len == null || len > arr.length) len = arr.length;\n\n  for (var i = 0, arr2 = new Array(len); i < len; i++) {\n    arr2[i] = arr[i];\n  }\n\n  return arr2;\n}\n\nmodule.exports = _arrayLikeToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/arrayLikeToArray.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/arrayWithHoles.js":
/*!***************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/arrayWithHoles.js ***!
  \***************************************************************/
/***/ ((module) => {

eval("function _arrayWithHoles(arr) {\n  if (Array.isArray(arr)) return arr;\n}\n\nmodule.exports = _arrayWithHoles, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/arrayWithHoles.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/classCallCheck.js":
/*!***************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/classCallCheck.js ***!
  \***************************************************************/
/***/ ((module) => {

eval("function _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n\nmodule.exports = _classCallCheck, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/classCallCheck.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/createClass.js":
/*!************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/createClass.js ***!
  \************************************************************/
/***/ ((module) => {

eval("function _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  Object.defineProperty(Constructor, \"prototype\", {\n    writable: false\n  });\n  return Constructor;\n}\n\nmodule.exports = _createClass, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/createClass.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js ***!
  \*********************************************************************/
/***/ ((module) => {

eval("function _iterableToArrayLimit(arr, i) {\n  var _i = arr == null ? null : typeof Symbol !== \"undefined\" && arr[Symbol.iterator] || arr[\"@@iterator\"];\n\n  if (_i == null) return;\n  var _arr = [];\n  var _n = true;\n  var _d = false;\n\n  var _s, _e;\n\n  try {\n    for (_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true) {\n      _arr.push(_s.value);\n\n      if (i && _arr.length === i) break;\n    }\n  } catch (err) {\n    _d = true;\n    _e = err;\n  } finally {\n    try {\n      if (!_n && _i[\"return\"] != null) _i[\"return\"]();\n    } finally {\n      if (_d) throw _e;\n    }\n  }\n\n  return _arr;\n}\n\nmodule.exports = _iterableToArrayLimit, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/nonIterableRest.js":
/*!****************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/nonIterableRest.js ***!
  \****************************************************************/
/***/ ((module) => {

eval("function _nonIterableRest() {\n  throw new TypeError(\"Invalid attempt to destructure non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\");\n}\n\nmodule.exports = _nonIterableRest, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/nonIterableRest.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/slicedToArray.js":
/*!**************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/slicedToArray.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var arrayWithHoles = __webpack_require__(/*! ./arrayWithHoles.js */ \"./node_modules/@babel/runtime/helpers/arrayWithHoles.js\");\n\nvar iterableToArrayLimit = __webpack_require__(/*! ./iterableToArrayLimit.js */ \"./node_modules/@babel/runtime/helpers/iterableToArrayLimit.js\");\n\nvar unsupportedIterableToArray = __webpack_require__(/*! ./unsupportedIterableToArray.js */ \"./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js\");\n\nvar nonIterableRest = __webpack_require__(/*! ./nonIterableRest.js */ \"./node_modules/@babel/runtime/helpers/nonIterableRest.js\");\n\nfunction _slicedToArray(arr, i) {\n  return arrayWithHoles(arr) || iterableToArrayLimit(arr, i) || unsupportedIterableToArray(arr, i) || nonIterableRest();\n}\n\nmodule.exports = _slicedToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/slicedToArray.js?");

/***/ }),

/***/ "./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js ***!
  \***************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var arrayLikeToArray = __webpack_require__(/*! ./arrayLikeToArray.js */ \"./node_modules/@babel/runtime/helpers/arrayLikeToArray.js\");\n\nfunction _unsupportedIterableToArray(o, minLen) {\n  if (!o) return;\n  if (typeof o === \"string\") return arrayLikeToArray(o, minLen);\n  var n = Object.prototype.toString.call(o).slice(8, -1);\n  if (n === \"Object\" && o.constructor) n = o.constructor.name;\n  if (n === \"Map\" || n === \"Set\") return Array.from(o);\n  if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return arrayLikeToArray(o, minLen);\n}\n\nmodule.exports = _unsupportedIterableToArray, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;\n\n//# sourceURL=webpack://Something/./node_modules/@babel/runtime/helpers/unsupportedIterableToArray.js?");

/***/ }),

/***/ "./node_modules/automation-events/build/es5/bundle.js":
/*!************************************************************!*\
  !*** ./node_modules/automation-events/build/es5/bundle.js ***!
  \************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

eval("(function (global, factory) {\n     true ? factory(exports, __webpack_require__(/*! @babel/runtime/helpers/slicedToArray */ \"./node_modules/@babel/runtime/helpers/slicedToArray.js\"), __webpack_require__(/*! @babel/runtime/helpers/classCallCheck */ \"./node_modules/@babel/runtime/helpers/classCallCheck.js\"), __webpack_require__(/*! @babel/runtime/helpers/createClass */ \"./node_modules/@babel/runtime/helpers/createClass.js\")) :\n    0;\n})(this, (function (exports, _slicedToArray, _classCallCheck, _createClass) { 'use strict';\n\n    function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }\n\n    var _slicedToArray__default = /*#__PURE__*/_interopDefaultLegacy(_slicedToArray);\n    var _classCallCheck__default = /*#__PURE__*/_interopDefaultLegacy(_classCallCheck);\n    var _createClass__default = /*#__PURE__*/_interopDefaultLegacy(_createClass);\n\n    var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent(value, endTime, insertTime) {\n      return {\n        endTime: endTime,\n        insertTime: insertTime,\n        type: 'exponentialRampToValue',\n        value: value\n      };\n    };\n\n    var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent(value, endTime, insertTime) {\n      return {\n        endTime: endTime,\n        insertTime: insertTime,\n        type: 'linearRampToValue',\n        value: value\n      };\n    };\n\n    var createSetValueAutomationEvent = function createSetValueAutomationEvent(value, startTime) {\n      return {\n        startTime: startTime,\n        type: 'setValue',\n        value: value\n      };\n    };\n\n    var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent(values, startTime, duration) {\n      return {\n        duration: duration,\n        startTime: startTime,\n        type: 'setValueCurve',\n        values: values\n      };\n    };\n\n    var getTargetValueAtTime = function getTargetValueAtTime(time, valueAtStartTime, _ref) {\n      var startTime = _ref.startTime,\n          target = _ref.target,\n          timeConstant = _ref.timeConstant;\n      return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);\n    };\n\n    var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'exponentialRampToValue';\n    };\n\n    var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'linearRampToValue';\n    };\n\n    var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent(automationEvent) {\n      return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);\n    };\n\n    var isSetValueAutomationEvent = function isSetValueAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setValue';\n    };\n\n    var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setValueCurve';\n    };\n\n    var getValueOfAutomationEventAtIndexAtTime = function getValueOfAutomationEventAtIndexAtTime(automationEvents, index, time, defaultValue) {\n      var automationEvent = automationEvents[index];\n      return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);\n    };\n\n    var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {\n      return currentAutomationEvent === undefined ? [nextAutomationEvent.insertTime, defaultValue] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.endTime, currentAutomationEvent.value] : isSetValueAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime, currentAutomationEvent.value] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [currentAutomationEvent.startTime + currentAutomationEvent.duration, currentAutomationEvent.values[currentAutomationEvent.values.length - 1]] : [currentAutomationEvent.startTime, getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)];\n    };\n\n    var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent(automationEvent) {\n      return automationEvent.type === 'cancelAndHold';\n    };\n\n    var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent(automationEvent) {\n      return automationEvent.type === 'cancelScheduledValues';\n    };\n\n    var getEventTime = function getEventTime(automationEvent) {\n      if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {\n        return automationEvent.cancelTime;\n      }\n\n      if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) {\n        return automationEvent.endTime;\n      }\n\n      return automationEvent.startTime;\n    };\n\n    var getExponentialRampValueAtTime = function getExponentialRampValueAtTime(time, startTime, valueAtStartTime, _ref) {\n      var endTime = _ref.endTime,\n          value = _ref.value;\n\n      if (valueAtStartTime === value) {\n        return value;\n      }\n\n      if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) {\n        return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));\n      }\n\n      return 0;\n    };\n\n    var getLinearRampValueAtTime = function getLinearRampValueAtTime(time, startTime, valueAtStartTime, _ref) {\n      var endTime = _ref.endTime,\n          value = _ref.value;\n      return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);\n    };\n\n    var interpolateValue = function interpolateValue(values, theoreticIndex) {\n      var lowerIndex = Math.floor(theoreticIndex);\n      var upperIndex = Math.ceil(theoreticIndex);\n\n      if (lowerIndex === upperIndex) {\n        return values[lowerIndex];\n      }\n\n      return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];\n    };\n\n    var getValueCurveValueAtTime = function getValueCurveValueAtTime(time, _ref) {\n      var duration = _ref.duration,\n          startTime = _ref.startTime,\n          values = _ref.values;\n      var theoreticIndex = (time - startTime) / duration * (values.length - 1);\n      return interpolateValue(values, theoreticIndex);\n    };\n\n    var isSetTargetAutomationEvent = function isSetTargetAutomationEvent(automationEvent) {\n      return automationEvent.type === 'setTarget';\n    };\n\n    var AutomationEventList = /*#__PURE__*/function (_Symbol$iterator) {\n      function AutomationEventList(defaultValue) {\n        _classCallCheck__default[\"default\"](this, AutomationEventList);\n\n        this._automationEvents = [];\n        this._currenTime = 0;\n        this._defaultValue = defaultValue;\n      }\n\n      _createClass__default[\"default\"](AutomationEventList, [{\n        key: _Symbol$iterator,\n        value: function value() {\n          return this._automationEvents[Symbol.iterator]();\n        }\n      }, {\n        key: \"add\",\n        value: function add(automationEvent) {\n          var eventTime = getEventTime(automationEvent);\n\n          if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {\n            var index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n              if (isCancelScheduledValuesAutomationEvent(automationEvent) && isSetValueCurveAutomationEvent(currentAutomationEvent)) {\n                return currentAutomationEvent.startTime + currentAutomationEvent.duration >= eventTime;\n              }\n\n              return getEventTime(currentAutomationEvent) >= eventTime;\n            });\n\n            var removedAutomationEvent = this._automationEvents[index];\n\n            if (index !== -1) {\n              this._automationEvents = this._automationEvents.slice(0, index);\n            }\n\n            if (isCancelAndHoldAutomationEvent(automationEvent)) {\n              var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];\n\n              if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {\n                if (isSetTargetAutomationEvent(lastAutomationEvent)) {\n                  throw new Error('The internal list is malformed.');\n                }\n\n                var startTime = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);\n                var startValue = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;\n                var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);\n                var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);\n\n                this._automationEvents.push(truncatedAutomationEvent);\n              }\n\n              if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) {\n                this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));\n              }\n\n              if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) {\n                this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(new Float32Array([6, 7]), lastAutomationEvent.startTime, eventTime - lastAutomationEvent.startTime);\n              }\n            }\n          } else {\n            var _index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n              return getEventTime(currentAutomationEvent) > eventTime;\n            });\n\n            var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];\n\n            if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) {\n              return false;\n            }\n\n            var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;\n\n            if (_index === -1) {\n              this._automationEvents.push(persistentAutomationEvent);\n            } else {\n              if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) {\n                return false;\n              }\n\n              this._automationEvents.splice(_index, 0, persistentAutomationEvent);\n            }\n          }\n\n          return true;\n        }\n      }, {\n        key: \"flush\",\n        value: function flush(time) {\n          var index = this._automationEvents.findIndex(function (currentAutomationEvent) {\n            return getEventTime(currentAutomationEvent) > time;\n          });\n\n          if (index > 1) {\n            var remainingAutomationEvents = this._automationEvents.slice(index - 1);\n\n            var firstRemainingAutomationEvent = remainingAutomationEvents[0];\n\n            if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) {\n              remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));\n            }\n\n            this._automationEvents = remainingAutomationEvents;\n          }\n        }\n      }, {\n        key: \"getValue\",\n        value: function getValue(time) {\n          if (this._automationEvents.length === 0) {\n            return this._defaultValue;\n          }\n\n          var indexOfNextEvent = this._automationEvents.findIndex(function (automationEvent) {\n            return getEventTime(automationEvent) > time;\n          });\n\n          var nextAutomationEvent = this._automationEvents[indexOfNextEvent];\n          var indexOfCurrentEvent = (indexOfNextEvent === -1 ? this._automationEvents.length : indexOfNextEvent) - 1;\n          var currentAutomationEvent = this._automationEvents[indexOfCurrentEvent];\n\n          if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) {\n            return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(this._automationEvents, indexOfCurrentEvent - 1, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);\n          }\n\n          if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {\n            return currentAutomationEvent.value;\n          }\n\n          if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {\n            if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) {\n              return getValueCurveValueAtTime(time, currentAutomationEvent);\n            }\n\n            return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];\n          }\n\n          if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) {\n            return currentAutomationEvent.value;\n          }\n\n          if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {\n            var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue),\n                _getEndTimeAndValueOf2 = _slicedToArray__default[\"default\"](_getEndTimeAndValueOf, 2),\n                startTime = _getEndTimeAndValueOf2[0],\n                value = _getEndTimeAndValueOf2[1];\n\n            return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);\n          }\n\n          if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {\n            var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue),\n                _getEndTimeAndValueOf4 = _slicedToArray__default[\"default\"](_getEndTimeAndValueOf3, 2),\n                _startTime = _getEndTimeAndValueOf4[0],\n                _value = _getEndTimeAndValueOf4[1];\n\n            return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);\n          }\n\n          return this._defaultValue;\n        }\n      }]);\n\n      return AutomationEventList;\n    }(Symbol.iterator);\n\n    var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent(cancelTime) {\n      return {\n        cancelTime: cancelTime,\n        type: 'cancelAndHold'\n      };\n    };\n\n    var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent(cancelTime) {\n      return {\n        cancelTime: cancelTime,\n        type: 'cancelScheduledValues'\n      };\n    };\n\n    var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent(value, endTime) {\n      return {\n        endTime: endTime,\n        type: 'exponentialRampToValue',\n        value: value\n      };\n    };\n\n    var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent(value, endTime) {\n      return {\n        endTime: endTime,\n        type: 'linearRampToValue',\n        value: value\n      };\n    };\n\n    var createSetTargetAutomationEvent = function createSetTargetAutomationEvent(target, startTime, timeConstant) {\n      return {\n        startTime: startTime,\n        target: target,\n        timeConstant: timeConstant,\n        type: 'setTarget'\n      };\n    };\n\n    exports.AutomationEventList = AutomationEventList;\n    exports.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;\n    exports.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;\n    exports.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;\n    exports.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;\n    exports.createSetTargetAutomationEvent = createSetTargetAutomationEvent;\n    exports.createSetValueAutomationEvent = createSetValueAutomationEvent;\n    exports.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n}));\n\n\n//# sourceURL=webpack://Something/./node_modules/automation-events/build/es5/bundle.js?");

/***/ }),

/***/ "./node_modules/css-loader/dist/cjs.js!./src/css/main.css":
/*!****************************************************************!*\
  !*** ./node_modules/css-loader/dist/cjs.js!./src/css/main.css ***!
  \****************************************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/noSourceMaps.js */ \"./node_modules/css-loader/dist/runtime/noSourceMaps.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__);\n// Imports\n\n\nvar ___CSS_LOADER_EXPORT___ = _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default()((_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default()));\n// Module\n___CSS_LOADER_EXPORT___.push([module.id, \"/* Mobile Styles */\\r\\n@media only screen and (max-width: 600px) {}\\r\\n\\r\\n/* Tablet Styles */\\r\\n@media only screen and (min-width: 601px) and (max-width: 960px) {}\\r\\n\\r\\n/* Desktop Styles */\\r\\n@media only screen and (min-width: 961px) {}\\r\\n\\r\\nhtml, \\r\\nbody {\\r\\n    height: 100%;\\r\\n    width: 100%;\\r\\n    overflow: hidden;\\r\\n    background-color: rgb(0, 0, 0);\\r\\n    margin: 0;\\r\\n    font-family: 'Lexend', sans-serif;\\r\\n}\\r\\n\\r\\n.container {\\r\\n    display: grid;\\r\\n    grid-template-columns: 1fr;\\r\\n    grid-template-rows: 1fr;\\r\\n    grid-template-areas:\\r\\n        \\\"screen\\\";\\r\\n}\\r\\n\\r\\n.screen {\\r\\n    grid-area: screen;\\r\\n}\\r\\n\\r\\ncanvas {\\r\\n    z-index: 1;\\r\\n    filter: grayscale(100%) contrast(0.5) blur(5px);\\r\\n}\\r\\n\\r\\nvideo {\\r\\n    width: 100%;\\r\\n    height: 100%;\\r\\n    object-fit: cover;\\r\\n    filter: blur(20px) saturate(1) contrast(1) brightness(1);\\r\\n}\\r\\n\\r\\n.textBoxes {\\r\\n    height: 100%;\\r\\n    width: 100%;\\r\\n    display: grid;\\r\\n    grid-template-columns: 1fr 3fr 3fr 1fr;\\r\\n    grid-template-rows: 1fr 1fr 1fr 1fr 1fr;\\r\\n    grid-template-areas:\\r\\n        \\\". . . .\\\"\\r\\n        \\\". topBox . .\\\"\\r\\n        \\\"middleBox . . .\\\"\\r\\n        \\\". . . .\\\"\\r\\n        \\\". . bottomBox .\\\";\\r\\n    z-index: 3;\\r\\n    color: white;\\r\\n    font-size: 12vmin;\\r\\n}\\r\\n\\r\\n.topBox {\\r\\n    grid-area: topBox;\\r\\n}\\r\\n.middleBox {\\r\\n    grid-area: middleBox;\\r\\n}\\r\\n.bottomBox {\\r\\n    grid-area: bottomBox;\\r\\n}\\r\\n\\r\\n.show {\\r\\n    display:block;\\r\\n}\\r\\n.hide {\\r\\n    display: none;\\r\\n}\\r\\n\\r\\n.noselect {\\r\\n    -webkit-touch-callout: none; /* iOS Safari */\\r\\n      -webkit-user-select: none; /* Safari */\\r\\n       -khtml-user-select: none; /* Konqueror HTML */\\r\\n         -moz-user-select: none; /* Old versions of Firefox */\\r\\n          -ms-user-select: none; /* Internet Explorer/Edge */\\r\\n              user-select: none; /* Non-prefixed version, currently\\r\\n                                    supported by Chrome, Edge, Opera and Firefox */\\r\\n  }\", \"\"]);\n// Exports\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (___CSS_LOADER_EXPORT___);\n\n\n//# sourceURL=webpack://Something/./src/css/main.css?./node_modules/css-loader/dist/cjs.js");

/***/ }),

/***/ "./node_modules/css-loader/dist/cjs.js!./src/css/normalise.css":
/*!*********************************************************************!*\
  !*** ./node_modules/css-loader/dist/cjs.js!./src/css/normalise.css ***!
  \*********************************************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/noSourceMaps.js */ \"./node_modules/css-loader/dist/runtime/noSourceMaps.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__);\n// Imports\n\n\nvar ___CSS_LOADER_EXPORT___ = _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default()((_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default()));\n// Module\n___CSS_LOADER_EXPORT___.push([module.id, \"/****** Elad Shechter's RESET *******/\\r\\n/*** box sizing border-box for all elements ***/\\r\\n*,\\r\\n*::before,\\r\\n*::after{box-sizing:border-box;}\\r\\na{text-decoration:none; color:inherit; cursor:pointer;}\\r\\nbutton{background-color:transparent; color:inherit; border-width:0; padding:0; cursor:pointer;}\\r\\nfigure{margin:0;}\\r\\ninput::-moz-focus-inner {border:0; padding:0; margin:0;}\\r\\nul, ol, dd{margin:0; padding:0; list-style:none;}\\r\\nh1, h2, h3, h4, h5, h6{margin:0; font-size:inherit; font-weight:inherit;}\\r\\np{margin:0;}\\r\\ncite {font-style:normal;}\\r\\nfieldset{border-width:0; padding:0; margin:0;}\\r\\n\", \"\"]);\n// Exports\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (___CSS_LOADER_EXPORT___);\n\n\n//# sourceURL=webpack://Something/./src/css/normalise.css?./node_modules/css-loader/dist/cjs.js");

/***/ }),

/***/ "./node_modules/css-loader/dist/runtime/api.js":
/*!*****************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/api.js ***!
  \*****************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/*\n  MIT License http://www.opensource.org/licenses/mit-license.php\n  Author Tobias Koppers @sokra\n*/\nmodule.exports = function (cssWithMappingToString) {\n  var list = []; // return the list of modules as css string\n\n  list.toString = function toString() {\n    return this.map(function (item) {\n      var content = \"\";\n      var needLayer = typeof item[5] !== \"undefined\";\n\n      if (item[4]) {\n        content += \"@supports (\".concat(item[4], \") {\");\n      }\n\n      if (item[2]) {\n        content += \"@media \".concat(item[2], \" {\");\n      }\n\n      if (needLayer) {\n        content += \"@layer\".concat(item[5].length > 0 ? \" \".concat(item[5]) : \"\", \" {\");\n      }\n\n      content += cssWithMappingToString(item);\n\n      if (needLayer) {\n        content += \"}\";\n      }\n\n      if (item[2]) {\n        content += \"}\";\n      }\n\n      if (item[4]) {\n        content += \"}\";\n      }\n\n      return content;\n    }).join(\"\");\n  }; // import a list of modules into the list\n\n\n  list.i = function i(modules, media, dedupe, supports, layer) {\n    if (typeof modules === \"string\") {\n      modules = [[null, modules, undefined]];\n    }\n\n    var alreadyImportedModules = {};\n\n    if (dedupe) {\n      for (var k = 0; k < this.length; k++) {\n        var id = this[k][0];\n\n        if (id != null) {\n          alreadyImportedModules[id] = true;\n        }\n      }\n    }\n\n    for (var _k = 0; _k < modules.length; _k++) {\n      var item = [].concat(modules[_k]);\n\n      if (dedupe && alreadyImportedModules[item[0]]) {\n        continue;\n      }\n\n      if (typeof layer !== \"undefined\") {\n        if (typeof item[5] === \"undefined\") {\n          item[5] = layer;\n        } else {\n          item[1] = \"@layer\".concat(item[5].length > 0 ? \" \".concat(item[5]) : \"\", \" {\").concat(item[1], \"}\");\n          item[5] = layer;\n        }\n      }\n\n      if (media) {\n        if (!item[2]) {\n          item[2] = media;\n        } else {\n          item[1] = \"@media \".concat(item[2], \" {\").concat(item[1], \"}\");\n          item[2] = media;\n        }\n      }\n\n      if (supports) {\n        if (!item[4]) {\n          item[4] = \"\".concat(supports);\n        } else {\n          item[1] = \"@supports (\".concat(item[4], \") {\").concat(item[1], \"}\");\n          item[4] = supports;\n        }\n      }\n\n      list.push(item);\n    }\n  };\n\n  return list;\n};\n\n//# sourceURL=webpack://Something/./node_modules/css-loader/dist/runtime/api.js?");

/***/ }),

/***/ "./node_modules/css-loader/dist/runtime/noSourceMaps.js":
/*!**************************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/noSourceMaps.js ***!
  \**************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function (i) {\n  return i[1];\n};\n\n//# sourceURL=webpack://Something/./node_modules/css-loader/dist/runtime/noSourceMaps.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/constants.js":
/*!***************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/constants.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MOST_NEGATIVE_SINGLE_FLOAT\": () => (/* binding */ MOST_NEGATIVE_SINGLE_FLOAT),\n/* harmony export */   \"MOST_POSITIVE_SINGLE_FLOAT\": () => (/* binding */ MOST_POSITIVE_SINGLE_FLOAT)\n/* harmony export */ });\nconst MOST_NEGATIVE_SINGLE_FLOAT = -3.4028234663852886e38;\nconst MOST_POSITIVE_SINGLE_FLOAT = -MOST_NEGATIVE_SINGLE_FLOAT;\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/constants.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAbortError\": () => (/* binding */ createAbortError)\n/* harmony export */ });\nconst createAbortError = () => new DOMException('', 'AbortError');\n//# sourceMappingURL=abort-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddActiveInputConnectionToAudioNode\": () => (/* binding */ createAddActiveInputConnectionToAudioNode)\n/* harmony export */ });\nconst createAddActiveInputConnectionToAudioNode = (insertElementInSet) => {\n    return (activeInputs, source, [output, input, eventListener], ignoreDuplicates) => {\n        insertElementInSet(activeInputs[input], [source, output, eventListener], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);\n    };\n};\n//# sourceMappingURL=add-active-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddAudioNodeConnections\": () => (/* binding */ createAddAudioNodeConnections)\n/* harmony export */ });\nconst createAddAudioNodeConnections = (audioNodeConnectionsStore) => {\n    return (audioNode, audioNodeRenderer, nativeAudioNode) => {\n        const activeInputs = [];\n        for (let i = 0; i < nativeAudioNode.numberOfInputs; i += 1) {\n            activeInputs.push(new Set());\n        }\n        audioNodeConnectionsStore.set(audioNode, {\n            activeInputs,\n            outputs: new Set(),\n            passiveInputs: new WeakMap(),\n            renderer: audioNodeRenderer\n        });\n    };\n};\n//# sourceMappingURL=add-audio-node-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddAudioParamConnections\": () => (/* binding */ createAddAudioParamConnections)\n/* harmony export */ });\nconst createAddAudioParamConnections = (audioParamConnectionsStore) => {\n    return (audioParam, audioParamRenderer) => {\n        audioParamConnectionsStore.set(audioParam, { activeInputs: new Set(), passiveInputs: new WeakMap(), renderer: audioParamRenderer });\n    };\n};\n//# sourceMappingURL=add-audio-param-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddAudioWorkletModule\": () => (/* binding */ createAddAudioWorkletModule)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _helpers_is_constructible__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-constructible */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js\");\n/* harmony import */ var _helpers_split_import_statements__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/split-import-statements */ \"./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js\");\n\n\n\nconst verifyParameterDescriptors = (parameterDescriptors) => {\n    if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) {\n        throw new TypeError('The parameterDescriptors property of given value for processorCtor is not an array.');\n    }\n};\nconst verifyProcessorCtor = (processorCtor) => {\n    if (!(0,_helpers_is_constructible__WEBPACK_IMPORTED_MODULE_1__.isConstructible)(processorCtor)) {\n        throw new TypeError('The given value for processorCtor should be a constructor.');\n    }\n    if (processorCtor.prototype === null || typeof processorCtor.prototype !== 'object') {\n        throw new TypeError('The given value for processorCtor should have a prototype.');\n    }\n};\nconst createAddAudioWorkletModule = (cacheTestResult, createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, ongoingRequests, resolvedRequests, testAudioWorkletProcessorPostMessageSupport, window) => {\n    let index = 0;\n    return (context, moduleURL, options = { credentials: 'omit' }) => {\n        const resolvedRequestsOfContext = resolvedRequests.get(context);\n        if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) {\n            return Promise.resolve();\n        }\n        const ongoingRequestsOfContext = ongoingRequests.get(context);\n        if (ongoingRequestsOfContext !== undefined) {\n            const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);\n            if (promiseOfOngoingRequest !== undefined) {\n                return promiseOfOngoingRequest;\n            }\n        }\n        const nativeContext = getNativeContext(context);\n        // Bug #59: Safari does not implement the audioWorklet property.\n        const promise = nativeContext.audioWorklet === undefined\n            ? fetchSource(moduleURL)\n                .then(([source, absoluteUrl]) => {\n                const [importStatements, sourceWithoutImportStatements] = (0,_helpers_split_import_statements__WEBPACK_IMPORTED_MODULE_2__.splitImportStatements)(source, absoluteUrl);\n                /*\n                 * This is the unminified version of the code used below:\n                 *\n                 * ```js\n                 * ${ importStatements };\n                 * ((a, b) => {\n                 *     (a[b] = a[b] || [ ]).push(\n                 *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {\n                 *             ${ sourceWithoutImportStatements }\n                 *         }\n                 *     );\n                 * })(window, '_AWGS');\n                 * ```\n                 */\n                // tslint:disable-next-line:max-line-length\n                const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}\n})})(window,'_AWGS')`;\n                // @todo Evaluating the given source code is a possible security problem.\n                return evaluateSource(wrappedSource);\n            })\n                .then(() => {\n                const evaluateAudioWorkletGlobalScope = window._AWGS.pop();\n                if (evaluateAudioWorkletGlobalScope === undefined) {\n                    // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n                    throw new SyntaxError();\n                }\n                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor {\n                }, undefined, (name, processorCtor) => {\n                    if (name.trim() === '') {\n                        throw createNotSupportedError();\n                    }\n                    const nodeNameToProcessorConstructorMap = _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);\n                    if (nodeNameToProcessorConstructorMap !== undefined) {\n                        if (nodeNameToProcessorConstructorMap.has(name)) {\n                            throw createNotSupportedError();\n                        }\n                        verifyProcessorCtor(processorCtor);\n                        verifyParameterDescriptors(processorCtor.parameterDescriptors);\n                        nodeNameToProcessorConstructorMap.set(name, processorCtor);\n                    }\n                    else {\n                        verifyProcessorCtor(processorCtor);\n                        verifyParameterDescriptors(processorCtor.parameterDescriptors);\n                        _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.set(nativeContext, new Map([[name, processorCtor]]));\n                    }\n                }, nativeContext.sampleRate, undefined, undefined));\n            })\n            : Promise.all([\n                fetchSource(moduleURL),\n                Promise.resolve(cacheTestResult(testAudioWorkletProcessorPostMessageSupport, testAudioWorkletProcessorPostMessageSupport))\n            ]).then(([[source, absoluteUrl], isSupportingPostMessage]) => {\n                const currentIndex = index + 1;\n                index = currentIndex;\n                const [importStatements, sourceWithoutImportStatements] = (0,_helpers_split_import_statements__WEBPACK_IMPORTED_MODULE_2__.splitImportStatements)(source, absoluteUrl);\n                /*\n                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.\n                 *\n                 * This is the unminified version of the code used below.\n                 *\n                 * ```js\n                 * class extends AudioWorkletProcessor {\n                 *\n                 *     __buffers = new WeakSet();\n                 *\n                 *     constructor () {\n                 *         super();\n                 *\n                 *         this.port.postMessage = ((postMessage) => {\n                 *             return (message, transferables) => {\n                 *                 const filteredTransferables = (transferables)\n                 *                     ? transferables.filter((transferable) => !this.__buffers.has(transferable))\n                 *                     : transferables;\n                 *\n                 *                 return postMessage.call(this.port, message, filteredTransferables);\n                 *              };\n                 *         })(this.port.postMessage);\n                 *     }\n                 * }\n                 * ```\n                 */\n                const patchedAudioWorkletProcessor = isSupportingPostMessage\n                    ? 'AudioWorkletProcessor'\n                    : 'class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}';\n                /*\n                 * Bug #170: Chrome and Edge do call process() with an array with empty channelData for each input if no input is connected.\n                 *\n                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.\n                 *\n                 * Bug #190: Safari doesn't throw an error when loading an unparsable module.\n                 *\n                 * This is the unminified version of the code used below:\n                 *\n                 * ```js\n                 * `${ importStatements };\n                 * ((AudioWorkletProcessor, registerProcessor) => {${ sourceWithoutImportStatements }\n                 * })(\n                 *     ${patchedAudioWorkletProcessor },\n                 *     (name, processorCtor) => registerProcessor(name, class extends processorCtor {\n                 *\n                 *         __collectBuffers = (array) => {\n                 *             array.forEach((element) => this.__buffers.add(element.buffer));\n                 *         };\n                 *\n                 *         process (inputs, outputs, parameters) {\n                 *             inputs.forEach(this.__collectBuffers);\n                 *             outputs.forEach(this.__collectBuffers);\n                 *             this.__collectBuffers(Object.values(parameters));\n                 *\n                 *             return super.process(\n                 *                 (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),\n                 *                 outputs,\n                 *                 parameters\n                 *             );\n                 *         }\n                 *\n                 *     })\n                 * );\n                 *\n                 * registerProcessor(`__sac${currentIndex}`, class extends AudioWorkletProcessor{\n                 *\n                 *     process () {\n                 *         return false;\n                 *     }\n                 *\n                 * })`\n                 * ```\n                 */\n                const memberDefinition = isSupportingPostMessage ? '' : '__c = (a) => a.forEach(e=>this.__b.add(e.buffer));';\n                const bufferRegistration = isSupportingPostMessage\n                    ? ''\n                    : 'i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));';\n                const wrappedSource = `${importStatements};((AudioWorkletProcessor,registerProcessor)=>{${sourceWithoutImportStatements}\n})(${patchedAudioWorkletProcessor},(n,p)=>registerProcessor(n,class extends p{${memberDefinition}process(i,o,p){${bufferRegistration}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}));registerProcessor('__sac${currentIndex}',class extends AudioWorkletProcessor{process(){return !1}})`;\n                const blob = new Blob([wrappedSource], { type: 'application/javascript; charset=utf-8' });\n                const url = URL.createObjectURL(blob);\n                return nativeContext.audioWorklet\n                    .addModule(url, options)\n                    .then(() => {\n                    if (isNativeOfflineAudioContext(nativeContext)) {\n                        return nativeContext;\n                    }\n                    // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.\n                    const backupOfflineAudioContext = getOrCreateBackupOfflineAudioContext(nativeContext);\n                    return backupOfflineAudioContext.audioWorklet.addModule(url, options).then(() => backupOfflineAudioContext);\n                })\n                    .then((nativeContextOrBackupOfflineAudioContext) => {\n                    if (nativeAudioWorkletNodeConstructor === null) {\n                        throw new SyntaxError();\n                    }\n                    try {\n                        // Bug #190: Safari doesn't throw an error when loading an unparsable module.\n                        new nativeAudioWorkletNodeConstructor(nativeContextOrBackupOfflineAudioContext, `__sac${currentIndex}`); // tslint:disable-line:no-unused-expression\n                    }\n                    catch {\n                        throw new SyntaxError();\n                    }\n                })\n                    .finally(() => URL.revokeObjectURL(url));\n            });\n        if (ongoingRequestsOfContext === undefined) {\n            ongoingRequests.set(context, new Map([[moduleURL, promise]]));\n        }\n        else {\n            ongoingRequestsOfContext.set(moduleURL, promise);\n        }\n        promise\n            .then(() => {\n            const updatedResolvedRequestsOfContext = resolvedRequests.get(context);\n            if (updatedResolvedRequestsOfContext === undefined) {\n                resolvedRequests.set(context, new Set([moduleURL]));\n            }\n            else {\n                updatedResolvedRequestsOfContext.add(moduleURL);\n            }\n        })\n            .finally(() => {\n            const updatedOngoingRequestsOfContext = ongoingRequests.get(context);\n            if (updatedOngoingRequestsOfContext !== undefined) {\n                updatedOngoingRequestsOfContext.delete(moduleURL);\n            }\n        });\n        return promise;\n    };\n};\n//# sourceMappingURL=add-audio-worklet-module.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddConnectionToAudioNode\": () => (/* binding */ createAddConnectionToAudioNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/delete-passive-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive-when-necessary */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js\");\n\n\n\nconst createAddConnectionToAudioNode = (addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode) => {\n    const tailTimeTimeoutIds = new WeakMap();\n    return (source, destination, output, input, isOffline) => {\n        const { activeInputs, passiveInputs } = getAudioNodeConnections(destination);\n        const { outputs } = getAudioNodeConnections(source);\n        const eventListeners = getEventListenersOfAudioNode(source);\n        const eventListener = (isActive) => {\n            const nativeDestinationAudioNode = getNativeAudioNode(destination);\n            const nativeSourceAudioNode = getNativeAudioNode(source);\n            if (isActive) {\n                const partialConnection = (0,_helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_0__.deletePassiveInputConnectionToAudioNode)(passiveInputs, source, output, input);\n                addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);\n                if (!isOffline && !isPartOfACycle(source)) {\n                    connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);\n                }\n                if (isPassiveAudioNode(destination)) {\n                    (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__.setInternalStateToActive)(destination);\n                }\n            }\n            else {\n                const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);\n                addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);\n                if (!isOffline && !isPartOfACycle(source)) {\n                    disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);\n                }\n                const tailTime = getAudioNodeTailTime(destination);\n                if (tailTime === 0) {\n                    if (isActiveAudioNode(destination)) {\n                        (0,_helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);\n                    }\n                }\n                else {\n                    const tailTimeTimeoutId = tailTimeTimeoutIds.get(destination);\n                    if (tailTimeTimeoutId !== undefined) {\n                        clearTimeout(tailTimeTimeoutId);\n                    }\n                    tailTimeTimeoutIds.set(destination, setTimeout(() => {\n                        if (isActiveAudioNode(destination)) {\n                            (0,_helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);\n                        }\n                    }, tailTime * 1000));\n                }\n            }\n        };\n        if (insertElementInSet(outputs, [destination, output, input], (outputConnection) => outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input, true)) {\n            eventListeners.add(eventListener);\n            if (isActiveAudioNode(source)) {\n                addActiveInputConnectionToAudioNode(activeInputs, source, [output, input, eventListener], true);\n            }\n            else {\n                addPassiveInputConnectionToAudioNode(passiveInputs, input, [source, output, eventListener], true);\n            }\n            return true;\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=add-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddPassiveInputConnectionToAudioNode\": () => (/* binding */ createAddPassiveInputConnectionToAudioNode)\n/* harmony export */ });\nconst createAddPassiveInputConnectionToAudioNode = (insertElementInSet) => {\n    return (passiveInputs, input, [source, output, eventListener], ignoreDuplicates) => {\n        const passiveInputConnections = passiveInputs.get(source);\n        if (passiveInputConnections === undefined) {\n            passiveInputs.set(source, new Set([[output, input, eventListener]]));\n        }\n        else {\n            insertElementInSet(passiveInputConnections, [output, input, eventListener], (passiveInputConnection) => passiveInputConnection[0] === output && passiveInputConnection[1] === input, ignoreDuplicates);\n        }\n    };\n};\n//# sourceMappingURL=add-passive-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddSilentConnection\": () => (/* binding */ createAddSilentConnection)\n/* harmony export */ });\nconst createAddSilentConnection = (createNativeGainNode) => {\n    return (nativeContext, nativeAudioScheduledSourceNode) => {\n        const nativeGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        nativeAudioScheduledSourceNode.connect(nativeGainNode).connect(nativeContext.destination);\n        const disconnect = () => {\n            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnect);\n            nativeAudioScheduledSourceNode.disconnect(nativeGainNode);\n            nativeGainNode.disconnect();\n        };\n        nativeAudioScheduledSourceNode.addEventListener('ended', disconnect);\n    };\n};\n//# sourceMappingURL=add-silent-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAddUnrenderedAudioWorkletNode\": () => (/* binding */ createAddUnrenderedAudioWorkletNode)\n/* harmony export */ });\nconst createAddUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {\n    return (nativeContext, audioWorkletNode) => {\n        getUnrenderedAudioWorkletNodes(nativeContext).add(audioWorkletNode);\n    };\n};\n//# sourceMappingURL=add-unrendered-audio-worklet-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAnalyserNodeConstructor\": () => (/* binding */ createAnalyserNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    fftSize: 2048,\n    maxDecibels: -30,\n    minDecibels: -100,\n    smoothingTimeConstant: 0.8\n};\nconst createAnalyserNodeConstructor = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class AnalyserNode extends audionNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);\n            const analyserNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null));\n            super(context, false, nativeAnalyserNode, analyserNodeRenderer);\n            this._nativeAnalyserNode = nativeAnalyserNode;\n        }\n        get fftSize() {\n            return this._nativeAnalyserNode.fftSize;\n        }\n        set fftSize(value) {\n            this._nativeAnalyserNode.fftSize = value;\n        }\n        get frequencyBinCount() {\n            return this._nativeAnalyserNode.frequencyBinCount;\n        }\n        get maxDecibels() {\n            return this._nativeAnalyserNode.maxDecibels;\n        }\n        set maxDecibels(value) {\n            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n            const maxDecibels = this._nativeAnalyserNode.maxDecibels;\n            this._nativeAnalyserNode.maxDecibels = value;\n            if (!(value > this._nativeAnalyserNode.minDecibels)) {\n                this._nativeAnalyserNode.maxDecibels = maxDecibels;\n                throw createIndexSizeError();\n            }\n        }\n        get minDecibels() {\n            return this._nativeAnalyserNode.minDecibels;\n        }\n        set minDecibels(value) {\n            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n            const minDecibels = this._nativeAnalyserNode.minDecibels;\n            this._nativeAnalyserNode.minDecibels = value;\n            if (!(this._nativeAnalyserNode.maxDecibels > value)) {\n                this._nativeAnalyserNode.minDecibels = minDecibels;\n                throw createIndexSizeError();\n            }\n        }\n        get smoothingTimeConstant() {\n            return this._nativeAnalyserNode.smoothingTimeConstant;\n        }\n        set smoothingTimeConstant(value) {\n            this._nativeAnalyserNode.smoothingTimeConstant = value;\n        }\n        getByteFrequencyData(array) {\n            this._nativeAnalyserNode.getByteFrequencyData(array);\n        }\n        getByteTimeDomainData(array) {\n            this._nativeAnalyserNode.getByteTimeDomainData(array);\n        }\n        getFloatFrequencyData(array) {\n            this._nativeAnalyserNode.getFloatFrequencyData(array);\n        }\n        getFloatTimeDomainData(array) {\n            this._nativeAnalyserNode.getFloatTimeDomainData(array);\n        }\n    };\n};\n//# sourceMappingURL=analyser-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAnalyserNodeRendererFactory\": () => (/* binding */ createAnalyserNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createAnalyserNodeRendererFactory = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAnalyserNodes = new WeakMap();\n        const createAnalyserNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAnalyserNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAnalyserNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAnalyserNode, nativeOfflineAudioContext);\n            if (!nativeAnalyserNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAnalyserNode.channelCount,\n                    channelCountMode: nativeAnalyserNode.channelCountMode,\n                    channelInterpretation: nativeAnalyserNode.channelInterpretation,\n                    fftSize: nativeAnalyserNode.fftSize,\n                    maxDecibels: nativeAnalyserNode.maxDecibels,\n                    minDecibels: nativeAnalyserNode.minDecibels,\n                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant\n                };\n                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode);\n            return nativeAnalyserNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAnalyserNode !== undefined) {\n                    return Promise.resolve(renderedNativeAnalyserNode);\n                }\n                return createAnalyserNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=analyser-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioBufferConstructor\": () => (/* binding */ createAudioBufferConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-get-channel-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nconst createAudioBufferConstructor = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    let nativeOfflineAudioContext = null;\n    return class AudioBuffer {\n        constructor(options) {\n            if (nativeOfflineAudioContextConstructor === null) {\n                throw new Error('Missing the native OfflineAudioContext constructor.');\n            }\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            if (nativeOfflineAudioContext === null) {\n                nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n            }\n            /*\n             * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the\n             * factory function. But since Firefox also supports the constructor everything should be fine.\n             */\n            const audioBuffer = nativeAudioBufferConstructor !== null &&\n                cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport)\n                ? new nativeAudioBufferConstructor({ length, numberOfChannels, sampleRate })\n                : nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);\n            // Bug #99: Safari does not throw an error when the numberOfChannels is zero.\n            if (audioBuffer.numberOfChannels === 0) {\n                throw createNotSupportedError();\n            }\n            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n            if (typeof audioBuffer.copyFromChannel !== 'function') {\n                wrapAudioBufferCopyChannelMethods(audioBuffer);\n                (0,_helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__.wrapAudioBufferGetChannelDataMethod)(audioBuffer);\n                // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.\n            }\n            else if (!cacheTestResult(_helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_0__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => (0,_helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_0__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport)(audioBuffer))) {\n                wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n            }\n            audioBufferStore.add(audioBuffer);\n            /*\n             * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native\n             * (Offline)AudioContexts.\n             */\n            return audioBuffer;\n        }\n        static [Symbol.hasInstance](instance) {\n            return ((instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === AudioBuffer.prototype) ||\n                audioBufferStore.has(instance));\n        }\n    };\n};\n//# sourceMappingURL=audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioBufferSourceNodeConstructor\": () => (/* binding */ createAudioBufferSourceNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\n\nconst DEFAULT_OPTIONS = {\n    buffer: null,\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    // Bug #149: Safari does not yet support the detune AudioParam.\n    loop: false,\n    loopEnd: 0,\n    loopStart: 0,\n    playbackRate: 1\n};\nconst createAudioBufferSourceNodeConstructor = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class AudioBufferSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const audioBufferSourceNodeRenderer = ((isOffline ? createAudioBufferSourceNodeRenderer() : null));\n            super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);\n            this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;\n            this._isBufferNullified = false;\n            this._isBufferSet = mergedOptions.buffer !== null;\n            this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;\n            this._onended = null;\n            // Bug #73: Safari does not export the correct values for maxValue and minValue.\n            this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get buffer() {\n            if (this._isBufferNullified) {\n                return null;\n            }\n            return this._nativeAudioBufferSourceNode.buffer;\n        }\n        set buffer(value) {\n            this._nativeAudioBufferSourceNode.buffer = value;\n            // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.\n            if (value !== null) {\n                if (this._isBufferSet) {\n                    throw createInvalidStateError();\n                }\n                this._isBufferSet = true;\n            }\n        }\n        get loop() {\n            return this._nativeAudioBufferSourceNode.loop;\n        }\n        set loop(value) {\n            this._nativeAudioBufferSourceNode.loop = value;\n        }\n        get loopEnd() {\n            return this._nativeAudioBufferSourceNode.loopEnd;\n        }\n        set loopEnd(value) {\n            this._nativeAudioBufferSourceNode.loopEnd = value;\n        }\n        get loopStart() {\n            return this._nativeAudioBufferSourceNode.loopStart;\n        }\n        set loopStart(value) {\n            this._nativeAudioBufferSourceNode.loopStart = value;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeAudioBufferSourceNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;\n            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;\n        }\n        get playbackRate() {\n            return this._playbackRate;\n        }\n        start(when = 0, offset = 0, duration) {\n            this._nativeAudioBufferSourceNode.start(when, offset, duration);\n            if (this._audioBufferSourceNodeRenderer !== null) {\n                this._audioBufferSourceNodeRenderer.start = duration === undefined ? [when, offset] : [when, offset, duration];\n            }\n            if (this.context.state !== 'closed') {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToActive)(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeAudioBufferSourceNode.removeEventListener('ended', resetInternalStateToPassive);\n                    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__.isActiveAudioNode)(this)) {\n                        (0,_helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__.setInternalStateToPassive)(this);\n                    }\n                };\n                this._nativeAudioBufferSourceNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeAudioBufferSourceNode.stop(when);\n            if (this._audioBufferSourceNodeRenderer !== null) {\n                this._audioBufferSourceNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=audio-buffer-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioBufferSourceNodeRendererFactory\": () => (/* binding */ createAudioBufferSourceNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createAudioBufferSourceNodeRendererFactory = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioBufferSourceNodes = new WeakMap();\n        let start = null;\n        let stop = null;\n        const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeAudioBufferSourceNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAudioBufferSourceNode, nativeOfflineAudioContext);\n            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {\n                const options = {\n                    buffer: nativeAudioBufferSourceNode.buffer,\n                    channelCount: nativeAudioBufferSourceNode.channelCount,\n                    channelCountMode: nativeAudioBufferSourceNode.channelCountMode,\n                    channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,\n                    // Bug #149: Safari does not yet support the detune AudioParam.\n                    loop: nativeAudioBufferSourceNode.loop,\n                    loopEnd: nativeAudioBufferSourceNode.loopEnd,\n                    loopStart: nativeAudioBufferSourceNode.loopStart,\n                    playbackRate: nativeAudioBufferSourceNode.playbackRate.value\n                };\n                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeAudioBufferSourceNode.start(...start);\n                }\n                if (stop !== null) {\n                    nativeAudioBufferSourceNode.stop(stop);\n                }\n            }\n            renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);\n            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {\n                // Bug #149: Safari does not yet support the detune AudioParam.\n                await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);\n            }\n            else {\n                // Bug #149: Safari does not yet support the detune AudioParam.\n                await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode);\n            return nativeAudioBufferSourceNode;\n        };\n        return {\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioBufferSourceNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioBufferSourceNode);\n                }\n                return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=audio-buffer-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioContextConstructor\": () => (/* binding */ createAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-valid-latency-hint */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js\");\n\n\nconst createAudioContextConstructor = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor) => {\n    return class AudioContext extends baseAudioContextConstructor {\n        constructor(options = {}) {\n            if (nativeAudioContextConstructor === null) {\n                throw new Error('Missing the native AudioContext constructor.');\n            }\n            let nativeAudioContext;\n            try {\n                nativeAudioContext = new nativeAudioContextConstructor(options);\n            }\n            catch (err) {\n                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.\n                if (err.code === 12 && err.message === 'sampleRate is not in range') {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n            // Bug #131 Safari returns null when there are four other AudioContexts running already.\n            if (nativeAudioContext === null) {\n                throw createUnknownError();\n            }\n            // Bug #51 Only Chrome, Edge and Opera throw an error if the given latencyHint is invalid.\n            if (!(0,_helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__.isValidLatencyHint)(options.latencyHint)) {\n                throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);\n            }\n            // Bug #150 Safari does not support setting the sampleRate.\n            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {\n                throw createNotSupportedError();\n            }\n            super(nativeAudioContext, 2);\n            const { latencyHint } = options;\n            const { sampleRate } = nativeAudioContext;\n            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.\n            this._baseLatency =\n                typeof nativeAudioContext.baseLatency === 'number'\n                    ? nativeAudioContext.baseLatency\n                    : latencyHint === 'balanced'\n                        ? 512 / sampleRate\n                        : latencyHint === 'interactive' || latencyHint === undefined\n                            ? 256 / sampleRate\n                            : latencyHint === 'playback'\n                                ? 1024 / sampleRate\n                                : /*\n                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a\n                                   * ScriptProcessorNode.\n                                   */\n                                    (Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate;\n            this._nativeAudioContext = nativeAudioContext;\n            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.\n            if (nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                this._nativeGainNode = nativeAudioContext.createGain();\n                this._nativeOscillatorNode = nativeAudioContext.createOscillator();\n                this._nativeGainNode.gain.value = 1e-37;\n                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);\n                this._nativeOscillatorNode.start();\n            }\n            else {\n                this._nativeGainNode = null;\n                this._nativeOscillatorNode = null;\n            }\n            this._state = null;\n            /*\n             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually\n             * changes to 'running'.\n             */\n            if (nativeAudioContext.state === 'running') {\n                this._state = 'suspended';\n                const revokeState = () => {\n                    if (this._state === 'suspended') {\n                        this._state = null;\n                    }\n                    nativeAudioContext.removeEventListener('statechange', revokeState);\n                };\n                nativeAudioContext.addEventListener('statechange', revokeState);\n            }\n        }\n        get baseLatency() {\n            return this._baseLatency;\n        }\n        get state() {\n            return this._state !== null ? this._state : this._nativeAudioContext.state;\n        }\n        close() {\n            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.\n            if (this.state === 'closed') {\n                return this._nativeAudioContext.close().then(() => {\n                    throw createInvalidStateError();\n                });\n            }\n            // Bug #34: If the state was set to suspended before it should be revoked now.\n            if (this._state === 'suspended') {\n                this._state = null;\n            }\n            return this._nativeAudioContext.close().then(() => {\n                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {\n                    this._nativeOscillatorNode.stop();\n                    this._nativeGainNode.disconnect();\n                    this._nativeOscillatorNode.disconnect();\n                }\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        createMediaElementSource(mediaElement) {\n            return new mediaElementAudioSourceNodeConstructor(this, { mediaElement });\n        }\n        createMediaStreamDestination() {\n            return new mediaStreamAudioDestinationNodeConstructor(this);\n        }\n        createMediaStreamSource(mediaStream) {\n            return new mediaStreamAudioSourceNodeConstructor(this, { mediaStream });\n        }\n        createMediaStreamTrackSource(mediaStreamTrack) {\n            return new mediaStreamTrackAudioSourceNodeConstructor(this, { mediaStreamTrack });\n        }\n        resume() {\n            if (this._state === 'suspended') {\n                return new Promise((resolve, reject) => {\n                    const resolvePromise = () => {\n                        this._nativeAudioContext.removeEventListener('statechange', resolvePromise);\n                        if (this._nativeAudioContext.state === 'running') {\n                            resolve();\n                        }\n                        else {\n                            this.resume().then(resolve, reject);\n                        }\n                    };\n                    this._nativeAudioContext.addEventListener('statechange', resolvePromise);\n                });\n            }\n            return this._nativeAudioContext.resume().catch((err) => {\n                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined || err.code === 15) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n        suspend() {\n            return this._nativeAudioContext.suspend().catch((err) => {\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioDestinationNodeConstructor\": () => (/* binding */ createAudioDestinationNodeConstructor)\n/* harmony export */ });\nconst createAudioDestinationNodeConstructor = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode) => {\n    return class AudioDestinationNode extends audioNodeConstructor {\n        constructor(context, channelCount) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);\n            const audioDestinationNodeRenderer = ((isOffline ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode) : null));\n            super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);\n            this._isNodeOfNativeOfflineAudioContext = isOffline;\n            this._nativeAudioDestinationNode = nativeAudioDestinationNode;\n        }\n        get channelCount() {\n            return this._nativeAudioDestinationNode.channelCount;\n        }\n        set channelCount(value) {\n            // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.\n            // Bug #54: Firefox does throw an IndexSizeError.\n            if (this._isNodeOfNativeOfflineAudioContext) {\n                throw createInvalidStateError();\n            }\n            // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.\n            if (value > this._nativeAudioDestinationNode.maxChannelCount) {\n                throw createIndexSizeError();\n            }\n            this._nativeAudioDestinationNode.channelCount = value;\n        }\n        get channelCountMode() {\n            return this._nativeAudioDestinationNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            // Bug #53: No browser does throw an exception yet.\n            if (this._isNodeOfNativeOfflineAudioContext) {\n                throw createInvalidStateError();\n            }\n            this._nativeAudioDestinationNode.channelCountMode = value;\n        }\n        get maxChannelCount() {\n            return this._nativeAudioDestinationNode.maxChannelCount;\n        }\n    };\n};\n//# sourceMappingURL=audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioDestinationNodeRenderer\": () => (/* binding */ createAudioDestinationNodeRenderer)\n/* harmony export */ });\nconst createAudioDestinationNodeRenderer = (renderInputsOfAudioNode) => {\n    const renderedNativeAudioDestinationNodes = new WeakMap();\n    const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext) => {\n        const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;\n        renderedNativeAudioDestinationNodes.set(nativeOfflineAudioContext, nativeAudioDestinationNode);\n        await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode);\n        return nativeAudioDestinationNode;\n    };\n    return {\n        render(proxy, nativeOfflineAudioContext) {\n            const renderedNativeAudioDestinationNode = renderedNativeAudioDestinationNodes.get(nativeOfflineAudioContext);\n            if (renderedNativeAudioDestinationNode !== undefined) {\n                return Promise.resolve(renderedNativeAudioDestinationNode);\n            }\n            return createAudioDestinationNode(proxy, nativeOfflineAudioContext);\n        }\n    };\n};\n//# sourceMappingURL=audio-destination-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioListenerFactory\": () => (/* binding */ createAudioListenerFactory)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst createAudioListenerFactory = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, createNotSupportedError, getFirstSample, isNativeOfflineAudioContext, overwriteAccessors) => {\n    return (context, nativeContext) => {\n        const nativeListener = nativeContext.listener;\n        // Bug #117: Only Chrome, Edge & Opera support the new interface already.\n        const createFakeAudioParams = () => {\n            const buffer = new Float32Array(1);\n            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'speakers',\n                numberOfInputs: 9\n            });\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            let isScriptProcessorNodeCreated = false;\n            let lastOrientation = [0, 0, -1, 0, 1, 0];\n            let lastPosition = [0, 0, 0];\n            const createScriptProcessorNode = () => {\n                if (isScriptProcessorNodeCreated) {\n                    return;\n                }\n                isScriptProcessorNodeCreated = true;\n                const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);\n                // tslint:disable-next-line:deprecation\n                scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {\n                    const orientation = [\n                        getFirstSample(inputBuffer, buffer, 0),\n                        getFirstSample(inputBuffer, buffer, 1),\n                        getFirstSample(inputBuffer, buffer, 2),\n                        getFirstSample(inputBuffer, buffer, 3),\n                        getFirstSample(inputBuffer, buffer, 4),\n                        getFirstSample(inputBuffer, buffer, 5)\n                    ];\n                    if (orientation.some((value, index) => value !== lastOrientation[index])) {\n                        nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation\n                        lastOrientation = orientation;\n                    }\n                    const positon = [\n                        getFirstSample(inputBuffer, buffer, 6),\n                        getFirstSample(inputBuffer, buffer, 7),\n                        getFirstSample(inputBuffer, buffer, 8)\n                    ];\n                    if (positon.some((value, index) => value !== lastPosition[index])) {\n                        nativeListener.setPosition(...positon); // tslint:disable-line:deprecation\n                        lastPosition = positon;\n                    }\n                };\n                channelMergerNode.connect(scriptProcessorNode);\n            };\n            const createSetOrientation = (index) => (value) => {\n                if (value !== lastOrientation[index]) {\n                    lastOrientation[index] = value;\n                    nativeListener.setOrientation(...lastOrientation); // tslint:disable-line:deprecation\n                }\n            };\n            const createSetPosition = (index) => (value) => {\n                if (value !== lastPosition[index]) {\n                    lastPosition[index] = value;\n                    nativeListener.setPosition(...lastPosition); // tslint:disable-line:deprecation\n                }\n            };\n            const createFakeAudioParam = (input, initialValue, setValue) => {\n                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {\n                    channelCount: 1,\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    offset: initialValue\n                });\n                constantSourceNode.connect(channelMergerNode, 0, input);\n                // @todo This should be stopped when the context is closed.\n                constantSourceNode.start();\n                Object.defineProperty(constantSourceNode.offset, 'defaultValue', {\n                    get() {\n                        return initialValue;\n                    }\n                });\n                /*\n                 * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and\n                 * minValue for GainNodes.\n                 */\n                const audioParam = createAudioParam({ context }, isOffline, constantSourceNode.offset, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n                overwriteAccessors(audioParam, 'value', (get) => () => get.call(audioParam), (set) => (value) => {\n                    try {\n                        set.call(audioParam, value);\n                    }\n                    catch (err) {\n                        if (err.code !== 9) {\n                            throw err;\n                        }\n                    }\n                    createScriptProcessorNode();\n                    if (isOffline) {\n                        // Bug #117: Using setOrientation() and setPosition() doesn't work with an OfflineAudioContext.\n                        setValue(value);\n                    }\n                });\n                audioParam.cancelAndHoldAtTime = ((cancelAndHoldAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = cancelAndHoldAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.cancelAndHoldAtTime);\n                audioParam.cancelScheduledValues = ((cancelScheduledValues) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = cancelScheduledValues.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.cancelScheduledValues);\n                audioParam.exponentialRampToValueAtTime = ((exponentialRampToValueAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = exponentialRampToValueAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.exponentialRampToValueAtTime);\n                audioParam.linearRampToValueAtTime = ((linearRampToValueAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = linearRampToValueAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.linearRampToValueAtTime);\n                audioParam.setTargetAtTime = ((setTargetAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = setTargetAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.setTargetAtTime);\n                audioParam.setValueAtTime = ((setValueAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = setValueAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.setValueAtTime);\n                audioParam.setValueCurveAtTime = ((setValueCurveAtTime) => {\n                    if (isOffline) {\n                        return () => {\n                            throw createNotSupportedError();\n                        };\n                    }\n                    return (...args) => {\n                        const value = setValueCurveAtTime.apply(audioParam, args);\n                        createScriptProcessorNode();\n                        return value;\n                    };\n                })(audioParam.setValueCurveAtTime);\n                return audioParam;\n            };\n            return {\n                forwardX: createFakeAudioParam(0, 0, createSetOrientation(0)),\n                forwardY: createFakeAudioParam(1, 0, createSetOrientation(1)),\n                forwardZ: createFakeAudioParam(2, -1, createSetOrientation(2)),\n                positionX: createFakeAudioParam(6, 0, createSetPosition(0)),\n                positionY: createFakeAudioParam(7, 0, createSetPosition(1)),\n                positionZ: createFakeAudioParam(8, 0, createSetPosition(2)),\n                upX: createFakeAudioParam(3, 0, createSetOrientation(3)),\n                upY: createFakeAudioParam(4, 1, createSetOrientation(4)),\n                upZ: createFakeAudioParam(5, 0, createSetOrientation(5))\n            };\n        };\n        const { forwardX, forwardY, forwardZ, positionX, positionY, positionZ, upX, upY, upZ } = nativeListener.forwardX === undefined ? createFakeAudioParams() : nativeListener;\n        return {\n            get forwardX() {\n                return forwardX;\n            },\n            get forwardY() {\n                return forwardY;\n            },\n            get forwardZ() {\n                return forwardZ;\n            },\n            get positionX() {\n                return positionX;\n            },\n            get positionY() {\n                return positionY;\n            },\n            get positionZ() {\n                return positionZ;\n            },\n            get upX() {\n                return upX;\n            },\n            get upY() {\n                return upY;\n            },\n            get upZ() {\n                return upZ;\n            }\n        };\n    };\n};\n//# sourceMappingURL=audio-listener-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioNodeConstructor\": () => (/* binding */ createAudioNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _guards_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../guards/audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js\");\n/* harmony import */ var _guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../guards/audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js\");\n/* harmony import */ var _helpers_add_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/add-active-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_add_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/add-passive-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/connect-native-audio-node-to-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js\");\n/* harmony import */ var _helpers_delete_active_input_connection__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../helpers/delete-active-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js\");\n/* harmony import */ var _helpers_delete_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../helpers/delete-active-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_delete_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../helpers/delete-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js\");\n/* harmony import */ var _helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../helpers/delete-passive-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js\");\n/* harmony import */ var _helpers_delete_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../helpers/delete-passive-input-connection-to-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js\");\n/* harmony import */ var _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../helpers/disconnect-native-audio-node-from-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js\");\n/* harmony import */ var _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../helpers/get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ../helpers/get-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js\");\n/* harmony import */ var _helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ../helpers/get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n/* harmony import */ var _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ../helpers/get-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js\");\n/* harmony import */ var _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ../helpers/get-native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js\");\n/* harmony import */ var _helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ../helpers/insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ../helpers/is-part-of-a-cycle */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js\");\n/* harmony import */ var _helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ../helpers/is-passive-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive-when-necessary */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js\");\n/* harmony import */ var _helpers_test_audio_node_disconnect_method_support__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ../helpers/test-audio-node-disconnect-method-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js\");\n/* harmony import */ var _helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ../helpers/visit-each-audio-node-once */ \"./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js\");\n/* harmony import */ var _helpers_wrap_audio_node_disconnect_method__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ../helpers/wrap-audio-node-disconnect-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst addConnectionToAudioParamOfAudioContext = (source, destination, output, isOffline) => {\n    const { activeInputs, passiveInputs } = (0,_helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_13__.getAudioParamConnections)(destination);\n    const { outputs } = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    const eventListeners = (0,_helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_14__.getEventListenersOfAudioNode)(source);\n    const eventListener = (isActive) => {\n        const nativeAudioNode = (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(source);\n        const nativeAudioParam = (0,_helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__.getNativeAudioParam)(destination);\n        if (isActive) {\n            const partialConnection = (0,_helpers_delete_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_10__.deletePassiveInputConnectionToAudioParam)(passiveInputs, source, output);\n            (0,_helpers_add_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_3__.addActiveInputConnectionToAudioParam)(activeInputs, source, partialConnection, false);\n            if (!isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n                nativeAudioNode.connect(nativeAudioParam, output);\n            }\n        }\n        else {\n            const partialConnection = (0,_helpers_delete_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_7__.deleteActiveInputConnectionToAudioParam)(activeInputs, source, output);\n            (0,_helpers_add_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_4__.addPassiveInputConnectionToAudioParam)(passiveInputs, partialConnection, false);\n            if (!isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n                nativeAudioNode.disconnect(nativeAudioParam, output);\n            }\n        }\n    };\n    if ((0,_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_17__.insertElementInSet)(outputs, [destination, output], (outputConnection) => outputConnection[0] === destination && outputConnection[1] === output, true)) {\n        eventListeners.add(eventListener);\n        if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_18__.isActiveAudioNode)(source)) {\n            (0,_helpers_add_active_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_3__.addActiveInputConnectionToAudioParam)(activeInputs, source, [output, eventListener], true);\n        }\n        else {\n            (0,_helpers_add_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_4__.addPassiveInputConnectionToAudioParam)(passiveInputs, [source, output, eventListener], true);\n        }\n        return true;\n    }\n    return false;\n};\nconst deleteInputConnectionOfAudioNode = (source, destination, output, input) => {\n    const { activeInputs, passiveInputs } = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(destination);\n    const activeInputConnection = (0,_helpers_delete_active_input_connection__WEBPACK_IMPORTED_MODULE_6__.deleteActiveInputConnection)(activeInputs[input], source, output);\n    if (activeInputConnection === null) {\n        const passiveInputConnection = (0,_helpers_delete_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_9__.deletePassiveInputConnectionToAudioNode)(passiveInputs, source, output, input);\n        return [passiveInputConnection[2], false];\n    }\n    return [activeInputConnection[2], true];\n};\nconst deleteInputConnectionOfAudioParam = (source, destination, output) => {\n    const { activeInputs, passiveInputs } = (0,_helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_13__.getAudioParamConnections)(destination);\n    const activeInputConnection = (0,_helpers_delete_active_input_connection__WEBPACK_IMPORTED_MODULE_6__.deleteActiveInputConnection)(activeInputs, source, output);\n    if (activeInputConnection === null) {\n        const passiveInputConnection = (0,_helpers_delete_passive_input_connection_to_audio_param__WEBPACK_IMPORTED_MODULE_10__.deletePassiveInputConnectionToAudioParam)(passiveInputs, source, output);\n        return [passiveInputConnection[1], false];\n    }\n    return [activeInputConnection[2], true];\n};\nconst deleteInputsOfAudioNode = (source, isOffline, destination, output, input) => {\n    const [listener, isActive] = deleteInputConnectionOfAudioNode(source, destination, output, input);\n    if (listener !== null) {\n        (0,_helpers_delete_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_8__.deleteEventListenerOfAudioNode)(source, listener);\n        if (isActive && !isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n            (0,_helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_11__.disconnectNativeAudioNodeFromNativeAudioNode)((0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(source), (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(destination), output, input);\n        }\n    }\n    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_18__.isActiveAudioNode)(destination)) {\n        const { activeInputs } = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(destination);\n        (0,_helpers_set_internal_state_to_passive_when_necessary__WEBPACK_IMPORTED_MODULE_22__.setInternalStateToPassiveWhenNecessary)(destination, activeInputs);\n    }\n};\nconst deleteInputsOfAudioParam = (source, isOffline, destination, output) => {\n    const [listener, isActive] = deleteInputConnectionOfAudioParam(source, destination, output);\n    if (listener !== null) {\n        (0,_helpers_delete_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_8__.deleteEventListenerOfAudioNode)(source, listener);\n        if (isActive && !isOffline && !(0,_helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_19__.isPartOfACycle)(source)) {\n            (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(source).disconnect((0,_helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__.getNativeAudioParam)(destination), output);\n        }\n    }\n};\nconst deleteAnyConnection = (source, isOffline) => {\n    const audioNodeConnectionsOfSource = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    const destinations = [];\n    for (const outputConnection of audioNodeConnectionsOfSource.outputs) {\n        if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__.isAudioNodeOutputConnection)(outputConnection)) {\n            deleteInputsOfAudioNode(source, isOffline, ...outputConnection);\n        }\n        else {\n            deleteInputsOfAudioParam(source, isOffline, ...outputConnection);\n        }\n        destinations.push(outputConnection[0]);\n    }\n    audioNodeConnectionsOfSource.outputs.clear();\n    return destinations;\n};\nconst deleteConnectionAtOutput = (source, isOffline, output) => {\n    const audioNodeConnectionsOfSource = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    const destinations = [];\n    for (const outputConnection of audioNodeConnectionsOfSource.outputs) {\n        if (outputConnection[1] === output) {\n            if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__.isAudioNodeOutputConnection)(outputConnection)) {\n                deleteInputsOfAudioNode(source, isOffline, ...outputConnection);\n            }\n            else {\n                deleteInputsOfAudioParam(source, isOffline, ...outputConnection);\n            }\n            destinations.push(outputConnection[0]);\n            audioNodeConnectionsOfSource.outputs.delete(outputConnection);\n        }\n    }\n    return destinations;\n};\nconst deleteConnectionToDestination = (source, isOffline, destination, output, input) => {\n    const audioNodeConnectionsOfSource = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_12__.getAudioNodeConnections)(source);\n    return Array.from(audioNodeConnectionsOfSource.outputs)\n        .filter((outputConnection) => outputConnection[0] === destination &&\n        (output === undefined || outputConnection[1] === output) &&\n        (input === undefined || outputConnection[2] === input))\n        .map((outputConnection) => {\n        if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_2__.isAudioNodeOutputConnection)(outputConnection)) {\n            deleteInputsOfAudioNode(source, isOffline, ...outputConnection);\n        }\n        else {\n            deleteInputsOfAudioParam(source, isOffline, ...outputConnection);\n        }\n        audioNodeConnectionsOfSource.outputs.delete(outputConnection);\n        return outputConnection[0];\n    });\n};\nconst createAudioNodeConstructor = (addAudioNodeConnections, addConnectionToAudioNode, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor) => {\n    return class AudioNode extends eventTargetConstructor {\n        constructor(context, isActive, nativeAudioNode, audioNodeRenderer) {\n            super(nativeAudioNode);\n            this._context = context;\n            this._nativeAudioNode = nativeAudioNode;\n            const nativeContext = getNativeContext(context);\n            // Bug #12: Safari does not support to disconnect a specific destination.\n            if (isNativeAudioContext(nativeContext) &&\n                true !==\n                    cacheTestResult(_helpers_test_audio_node_disconnect_method_support__WEBPACK_IMPORTED_MODULE_23__.testAudioNodeDisconnectMethodSupport, () => {\n                        return (0,_helpers_test_audio_node_disconnect_method_support__WEBPACK_IMPORTED_MODULE_23__.testAudioNodeDisconnectMethodSupport)(nativeContext, nativeAudioWorkletNodeConstructor);\n                    })) {\n                (0,_helpers_wrap_audio_node_disconnect_method__WEBPACK_IMPORTED_MODULE_25__.wrapAudioNodeDisconnectMethod)(nativeAudioNode);\n            }\n            _globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_NODE_STORE.set(this, nativeAudioNode);\n            _globals__WEBPACK_IMPORTED_MODULE_0__.EVENT_LISTENERS.set(this, new Set());\n            if (context.state !== 'closed' && isActive) {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_21__.setInternalStateToActive)(this);\n            }\n            addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);\n        }\n        get channelCount() {\n            return this._nativeAudioNode.channelCount;\n        }\n        set channelCount(value) {\n            this._nativeAudioNode.channelCount = value;\n        }\n        get channelCountMode() {\n            return this._nativeAudioNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            this._nativeAudioNode.channelCountMode = value;\n        }\n        get channelInterpretation() {\n            return this._nativeAudioNode.channelInterpretation;\n        }\n        set channelInterpretation(value) {\n            this._nativeAudioNode.channelInterpretation = value;\n        }\n        get context() {\n            return this._context;\n        }\n        get numberOfInputs() {\n            return this._nativeAudioNode.numberOfInputs;\n        }\n        get numberOfOutputs() {\n            return this._nativeAudioNode.numberOfOutputs;\n        }\n        // tslint:disable-next-line:invalid-void\n        connect(destination, output = 0, input = 0) {\n            // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.\n            if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) {\n                throw createIndexSizeError();\n            }\n            const nativeContext = getNativeContext(this._context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) {\n                throw createInvalidAccessError();\n            }\n            if ((0,_guards_audio_node__WEBPACK_IMPORTED_MODULE_1__.isAudioNode)(destination)) {\n                const nativeDestinationAudioNode = (0,_helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_15__.getNativeAudioNode)(destination);\n                try {\n                    const connection = (0,_helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_5__.connectNativeAudioNodeToNativeAudioNode)(this._nativeAudioNode, nativeDestinationAudioNode, output, input);\n                    const isPassive = (0,_helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__.isPassiveAudioNode)(this);\n                    if (isOffline || isPassive) {\n                        this._nativeAudioNode.disconnect(...connection);\n                    }\n                    if (this.context.state !== 'closed' && !isPassive && (0,_helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__.isPassiveAudioNode)(destination)) {\n                        (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_21__.setInternalStateToActive)(destination);\n                    }\n                }\n                catch (err) {\n                    // Bug #41: Safari does not throw the correct exception so far.\n                    if (err.code === 12) {\n                        throw createInvalidAccessError();\n                    }\n                    throw err;\n                }\n                const isNewConnectionToAudioNode = addConnectionToAudioNode(this, destination, output, input, isOffline);\n                // Bug #164: Only Firefox detects cycles so far.\n                if (isNewConnectionToAudioNode) {\n                    const cycles = detectCycles([this], destination);\n                    (0,_helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__.visitEachAudioNodeOnce)(cycles, createIncrementCycleCounter(isOffline));\n                }\n                return destination;\n            }\n            const nativeAudioParam = (0,_helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_16__.getNativeAudioParam)(destination);\n            /*\n             * Bug #73, #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an\n             * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify\n             * Safari. In addition to that the maxValue property is used to only detect the affected versions below v14.0.2.\n             */\n            if (nativeAudioParam.name === 'playbackRate' && nativeAudioParam.maxValue === 1024) {\n                throw createNotSupportedError();\n            }\n            try {\n                this._nativeAudioNode.connect(nativeAudioParam, output);\n                if (isOffline || (0,_helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_20__.isPassiveAudioNode)(this)) {\n                    this._nativeAudioNode.disconnect(nativeAudioParam, output);\n                }\n            }\n            catch (err) {\n                // Bug #58: Safari doesn't throw an InvalidAccessError yet.\n                if (err.code === 12) {\n                    throw createInvalidAccessError();\n                }\n                throw err;\n            }\n            const isNewConnectionToAudioParam = addConnectionToAudioParamOfAudioContext(this, destination, output, isOffline);\n            // Bug #164: Only Firefox detects cycles so far.\n            if (isNewConnectionToAudioParam) {\n                const cycles = detectCycles([this], destination);\n                (0,_helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__.visitEachAudioNodeOnce)(cycles, createIncrementCycleCounter(isOffline));\n            }\n        }\n        disconnect(destinationOrOutput, output, input) {\n            let destinations;\n            const nativeContext = getNativeContext(this._context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            if (destinationOrOutput === undefined) {\n                destinations = deleteAnyConnection(this, isOffline);\n            }\n            else if (typeof destinationOrOutput === 'number') {\n                if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) {\n                    throw createIndexSizeError();\n                }\n                destinations = deleteConnectionAtOutput(this, isOffline, destinationOrOutput);\n            }\n            else {\n                if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) {\n                    throw createIndexSizeError();\n                }\n                if ((0,_guards_audio_node__WEBPACK_IMPORTED_MODULE_1__.isAudioNode)(destinationOrOutput) && input !== undefined && (input < 0 || input >= destinationOrOutput.numberOfInputs)) {\n                    throw createIndexSizeError();\n                }\n                destinations = deleteConnectionToDestination(this, isOffline, destinationOrOutput, output, input);\n                if (destinations.length === 0) {\n                    throw createInvalidAccessError();\n                }\n            }\n            // Bug #164: Only Firefox detects cycles so far.\n            for (const destination of destinations) {\n                const cycles = detectCycles([this], destination);\n                (0,_helpers_visit_each_audio_node_once__WEBPACK_IMPORTED_MODULE_24__.visitEachAudioNodeOnce)(cycles, decrementCycleCounter);\n            }\n        }\n    };\n};\n//# sourceMappingURL=audio-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioParamFactory\": () => (/* binding */ createAudioParamFactory)\n/* harmony export */ });\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! automation-events */ \"./node_modules/automation-events/build/es5/bundle.js\");\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(automation_events__WEBPACK_IMPORTED_MODULE_0__);\n\nconst createAudioParamFactory = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor, setValueAtTimeUntilPossible) => {\n    return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null) => {\n        const automationEventList = new automation_events__WEBPACK_IMPORTED_MODULE_0__.AutomationEventList(nativeAudioParam.defaultValue);\n        const audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer(automationEventList) : null;\n        const audioParam = {\n            get defaultValue() {\n                return nativeAudioParam.defaultValue;\n            },\n            get maxValue() {\n                return maxValue === null ? nativeAudioParam.maxValue : maxValue;\n            },\n            get minValue() {\n                return minValue === null ? nativeAudioParam.minValue : minValue;\n            },\n            get value() {\n                return nativeAudioParam.value;\n            },\n            set value(value) {\n                nativeAudioParam.value = value;\n                // Bug #98: Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().\n                audioParam.setValueAtTime(value, audioNode.context.currentTime);\n            },\n            cancelAndHoldAtTime(cancelTime) {\n                // Bug #28: Firefox & Safari do not yet implement cancelAndHoldAtTime().\n                if (typeof nativeAudioParam.cancelAndHoldAtTime === 'function') {\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));\n                    nativeAudioParam.cancelAndHoldAtTime(cancelTime);\n                }\n                else {\n                    const previousLastEvent = Array.from(automationEventList).pop();\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));\n                    const currentLastEvent = Array.from(automationEventList).pop();\n                    nativeAudioParam.cancelScheduledValues(cancelTime);\n                    if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {\n                        if (currentLastEvent.type === 'exponentialRampToValue') {\n                            nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);\n                        }\n                        else if (currentLastEvent.type === 'linearRampToValue') {\n                            nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);\n                        }\n                        else if (currentLastEvent.type === 'setValue') {\n                            nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);\n                        }\n                        else if (currentLastEvent.type === 'setValueCurve') {\n                            nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);\n                        }\n                    }\n                }\n                return audioParam;\n            },\n            cancelScheduledValues(cancelTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));\n                nativeAudioParam.cancelScheduledValues(cancelTime);\n                return audioParam;\n            },\n            exponentialRampToValueAtTime(value, endTime) {\n                // Bug #45: Safari does not throw an error yet.\n                if (value === 0) {\n                    throw new RangeError();\n                }\n                // Bug #187: Safari does not throw an error yet.\n                if (!Number.isFinite(endTime) || endTime < 0) {\n                    throw new RangeError();\n                }\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createExponentialRampToValueAutomationEvent(value, endTime));\n                nativeAudioParam.exponentialRampToValueAtTime(value, endTime);\n                return audioParam;\n            },\n            linearRampToValueAtTime(value, endTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createLinearRampToValueAutomationEvent(value, endTime));\n                nativeAudioParam.linearRampToValueAtTime(value, endTime);\n                return audioParam;\n            },\n            setTargetAtTime(target, startTime, timeConstant) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));\n                nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);\n                return audioParam;\n            },\n            setValueAtTime(value, startTime) {\n                if (audioParamRenderer === null) {\n                    automationEventList.flush(audioNode.context.currentTime);\n                }\n                automationEventList.add(createSetValueAutomationEvent(value, startTime));\n                nativeAudioParam.setValueAtTime(value, startTime);\n                return audioParam;\n            },\n            setValueCurveAtTime(values, startTime, duration) {\n                // Bug 183: Safari only accepts a Float32Array.\n                const convertedValues = values instanceof Float32Array ? values : new Float32Array(values);\n                /*\n                 * Bug #152: Safari does not correctly interpolate the values of the curve.\n                 * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the\n                 * existence of the webkitAudioContext is used as a workaround here.\n                 */\n                if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                    const endTime = startTime + duration;\n                    const sampleRate = audioNode.context.sampleRate;\n                    const firstSample = Math.ceil(startTime * sampleRate);\n                    const lastSample = Math.floor(endTime * sampleRate);\n                    const numberOfInterpolatedValues = lastSample - firstSample;\n                    const interpolatedValues = new Float32Array(numberOfInterpolatedValues);\n                    for (let i = 0; i < numberOfInterpolatedValues; i += 1) {\n                        const theoreticIndex = ((convertedValues.length - 1) / duration) * ((firstSample + i) / sampleRate - startTime);\n                        const lowerIndex = Math.floor(theoreticIndex);\n                        const upperIndex = Math.ceil(theoreticIndex);\n                        interpolatedValues[i] =\n                            lowerIndex === upperIndex\n                                ? convertedValues[lowerIndex]\n                                : (1 - (theoreticIndex - lowerIndex)) * convertedValues[lowerIndex] +\n                                    (1 - (upperIndex - theoreticIndex)) * convertedValues[upperIndex];\n                    }\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));\n                    nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);\n                    const timeOfLastSample = lastSample / sampleRate;\n                    if (timeOfLastSample < endTime) {\n                        setValueAtTimeUntilPossible(audioParam, interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);\n                    }\n                    setValueAtTimeUntilPossible(audioParam, convertedValues[convertedValues.length - 1], endTime);\n                }\n                else {\n                    if (audioParamRenderer === null) {\n                        automationEventList.flush(audioNode.context.currentTime);\n                    }\n                    automationEventList.add(createSetValueCurveAutomationEvent(convertedValues, startTime, duration));\n                    nativeAudioParam.setValueCurveAtTime(convertedValues, startTime, duration);\n                }\n                return audioParam;\n            }\n        };\n        audioParamStore.set(audioParam, nativeAudioParam);\n        audioParamAudioNodeStore.set(audioParam, audioNode);\n        addAudioParamConnections(audioParam, audioParamRenderer);\n        return audioParam;\n    };\n};\n//# sourceMappingURL=audio-param-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioParamRenderer\": () => (/* binding */ createAudioParamRenderer)\n/* harmony export */ });\nconst createAudioParamRenderer = (automationEventList) => {\n    return {\n        replay(audioParam) {\n            for (const automationEvent of automationEventList) {\n                if (automationEvent.type === 'exponentialRampToValue') {\n                    const { endTime, value } = automationEvent;\n                    audioParam.exponentialRampToValueAtTime(value, endTime);\n                }\n                else if (automationEvent.type === 'linearRampToValue') {\n                    const { endTime, value } = automationEvent;\n                    audioParam.linearRampToValueAtTime(value, endTime);\n                }\n                else if (automationEvent.type === 'setTarget') {\n                    const { startTime, target, timeConstant } = automationEvent;\n                    audioParam.setTargetAtTime(target, startTime, timeConstant);\n                }\n                else if (automationEvent.type === 'setValue') {\n                    const { startTime, value } = automationEvent;\n                    audioParam.setValueAtTime(value, startTime);\n                }\n                else if (automationEvent.type === 'setValueCurve') {\n                    const { duration, startTime, values } = automationEvent;\n                    audioParam.setValueCurveAtTime(values, startTime, duration);\n                }\n                else {\n                    throw new Error(\"Can't apply an unknown automation.\");\n                }\n            }\n        }\n    };\n};\n//# sourceMappingURL=audio-param-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletNodeConstructor\": () => (/* binding */ createAudioWorkletNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _read_only_map__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../read-only-map */ \"./node_modules/standardized-audio-context/build/es2019/read-only-map.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    numberOfInputs: 1,\n    numberOfOutputs: 1,\n    parameterData: {},\n    processorOptions: {}\n};\nconst createAudioWorkletNodeConstructor = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, testAudioWorkletNodeOptionsClonability, wrapEventListener) => {\n    return class AudioWorkletNode extends audioNodeConstructor {\n        constructor(context, name, options) {\n            var _a;\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const mergedOptions = sanitizeAudioWorkletNodeOptions({ ...DEFAULT_OPTIONS, ...options });\n            // Bug #191: Safari doesn't throw an error if the options aren't clonable.\n            testAudioWorkletNodeOptionsClonability(mergedOptions);\n            const nodeNameToProcessorConstructorMap = _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);\n            const processorConstructor = nodeNameToProcessorConstructorMap === null || nodeNameToProcessorConstructorMap === void 0 ? void 0 : nodeNameToProcessorConstructorMap.get(name);\n            // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.\n            const nativeContextOrBackupOfflineAudioContext = isOffline || nativeContext.state !== 'closed'\n                ? nativeContext\n                : (_a = getBackupOfflineAudioContext(nativeContext)) !== null && _a !== void 0 ? _a : nativeContext;\n            const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContextOrBackupOfflineAudioContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);\n            const audioWorkletNodeRenderer = ((isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor) : null));\n            /*\n             * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor\n             * returns false.\n             */\n            super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);\n            const parameters = [];\n            nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm) => {\n                const audioParam = createAudioParam(this, isOffline, nativeAudioParam);\n                parameters.push([nm, audioParam]);\n            });\n            this._nativeAudioWorkletNode = nativeAudioWorkletNode;\n            this._onprocessorerror = null;\n            this._parameters = new _read_only_map__WEBPACK_IMPORTED_MODULE_1__.ReadOnlyMap(parameters);\n            /*\n             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to\n             * the destination.\n             */\n            if (isOffline) {\n                addUnrenderedAudioWorkletNode(nativeContext, this);\n            }\n            const { activeInputs } = getAudioNodeConnections(this);\n            setActiveAudioWorkletNodeInputs(nativeAudioWorkletNode, activeInputs);\n        }\n        get onprocessorerror() {\n            return this._onprocessorerror;\n        }\n        set onprocessorerror(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;\n            const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;\n            this._onprocessorerror =\n                nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener\n                    ? value\n                    : nativeOnProcessorError;\n        }\n        get parameters() {\n            if (this._parameters === null) {\n                // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                return this._nativeAudioWorkletNode.parameters;\n            }\n            return this._parameters;\n        }\n        get port() {\n            return this._nativeAudioWorkletNode.port;\n        }\n    };\n};\n//# sourceMappingURL=audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletNodeRendererFactory\": () => (/* binding */ createAudioWorkletNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/copy-from-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js\");\n/* harmony import */ var _helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/copy-to-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js\");\n/* harmony import */ var _helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/create-nested-arrays */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js\");\n/* harmony import */ var _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _helpers_get_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/get-audio-worklet-processor */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\n\n\n\n\nconst processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime) => {\n    // Ceil the length to the next full render quantum.\n    // Bug #17: Safari does not yet expose the length.\n    const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;\n    const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n    const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n    const processedBuffer = numberOfOutputChannels === 0\n        ? null\n        : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);\n    if (processorConstructor === undefined) {\n        throw new Error('Missing the processor constructor.');\n    }\n    const audioNodeConnections = (0,_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__.getAudioNodeConnections)(proxy);\n    const audioWorkletProcessor = await (0,_helpers_get_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__.getAudioWorkletProcessor)(nativeOfflineAudioContext, proxy);\n    const inputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_2__.createNestedArrays)(options.numberOfInputs, options.channelCount);\n    const outputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_2__.createNestedArrays)(options.numberOfOutputs, outputChannelCount);\n    const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});\n    for (let i = 0; i < length; i += 128) {\n        if (options.numberOfInputs > 0 && renderedBuffer !== null) {\n            for (let j = 0; j < options.numberOfInputs; j += 1) {\n                for (let k = 0; k < options.channelCount; k += 1) {\n                    (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_0__.copyFromChannel)(renderedBuffer, inputs[j], k, k, i);\n                }\n            }\n        }\n        if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) {\n            processorConstructor.parameterDescriptors.forEach(({ name }, index) => {\n                (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_0__.copyFromChannel)(renderedBuffer, parameters, name, numberOfInputChannels + index, i);\n            });\n        }\n        for (let j = 0; j < options.numberOfInputs; j += 1) {\n            for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                // The byteLength will be 0 when the ArrayBuffer was transferred.\n                if (outputs[j][k].byteLength === 0) {\n                    outputs[j][k] = new Float32Array(128);\n                }\n            }\n        }\n        try {\n            const potentiallyEmptyInputs = inputs.map((input, index) => {\n                if (audioNodeConnections.activeInputs[index].size === 0) {\n                    return [];\n                }\n                return input;\n            });\n            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n            if (processedBuffer !== null) {\n                for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n                    for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                        (0,_helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_1__.copyToChannel)(processedBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n                    }\n                    outputChannelSplitterNodeOutput += outputChannelCount[j];\n                }\n            }\n            if (!activeSourceFlag) {\n                break;\n            }\n        }\n        catch (error) {\n            proxy.dispatchEvent(new ErrorEvent('processorerror', {\n                colno: error.colno,\n                filename: error.filename,\n                lineno: error.lineno,\n                message: error.message\n            }));\n            break;\n        }\n    }\n    return processedBuffer;\n};\nconst createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return (name, options, processorConstructor) => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let processedBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioWorkletNode = getNativeAudioNode(proxy);\n            let nativeOutputNodes = null;\n            const nativeAudioWorkletNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_5__.isOwnedByContext)(nativeAudioWorkletNode, nativeOfflineAudioContext);\n            const outputChannelCount = Array.isArray(options.outputChannelCount)\n                ? options.outputChannelCount\n                : Array.from(options.outputChannelCount);\n            // Bug #61: Only Chrome, Edge, Firefox & Opera have an implementation of the AudioWorkletNode yet.\n            if (nativeAudioWorkletNodeConstructor === null) {\n                const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n                const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {\n                    channelCount: Math.max(1, numberOfOutputChannels),\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    numberOfOutputs: Math.max(1, numberOfOutputChannels)\n                });\n                const outputChannelMergerNodes = [];\n                for (let i = 0; i < proxy.numberOfOutputs; i += 1) {\n                    outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'speakers',\n                        numberOfInputs: outputChannelCount[i]\n                    }));\n                }\n                const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {\n                    channelCount: options.channelCount,\n                    channelCountMode: options.channelCountMode,\n                    channelInterpretation: options.channelInterpretation,\n                    gain: 1\n                });\n                outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);\n                outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);\n                nativeOutputNodes = [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode];\n            }\n            else if (!nativeAudioWorkletNodeIsOwnedByContext) {\n                nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);\n            if (nativeOutputNodes !== null) {\n                if (processedBufferPromise === null) {\n                    if (processorConstructor === undefined) {\n                        throw new Error('Missing the processor constructor.');\n                    }\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.\n                    const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;\n                    const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;\n                    const numberOfChannels = numberOfInputChannels + numberOfParameters;\n                    const renderBuffer = async () => {\n                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, \n                        // Ceil the length to the next full render quantum.\n                        // Bug #17: Safari does not yet expose the length.\n                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);\n                        const gainNodes = [];\n                        const inputChannelSplitterNodes = [];\n                        for (let i = 0; i < options.numberOfInputs; i += 1) {\n                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {\n                                channelCount: options.channelCount,\n                                channelCountMode: options.channelCountMode,\n                                channelInterpretation: options.channelInterpretation,\n                                gain: 1\n                            }));\n                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {\n                                channelCount: options.channelCount,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                numberOfOutputs: options.channelCount\n                            }));\n                        }\n                        const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async (audioParam) => {\n                            const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                channelCount: 1,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                offset: audioParam.value\n                            });\n                            await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset);\n                            return constantSourceNode;\n                        }));\n                        const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                            channelCount: 1,\n                            channelCountMode: 'explicit',\n                            channelInterpretation: 'speakers',\n                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n                        });\n                        for (let i = 0; i < options.numberOfInputs; i += 1) {\n                            gainNodes[i].connect(inputChannelSplitterNodes[i]);\n                            for (let j = 0; j < options.channelCount; j += 1) {\n                                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);\n                            }\n                        }\n                        for (const [index, constantSourceNode] of constantSourceNodes.entries()) {\n                            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                            constantSourceNode.start(0);\n                        }\n                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                        await Promise.all(gainNodes.map((gainNode) => renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode)));\n                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                    };\n                    processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);\n                }\n                const processedBuffer = await processedBufferPromise;\n                const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n                    buffer: null,\n                    channelCount: 2,\n                    channelCountMode: 'max',\n                    channelInterpretation: 'speakers',\n                    loop: false,\n                    loopEnd: 0,\n                    loopStart: 0,\n                    playbackRate: 1\n                });\n                const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;\n                if (processedBuffer !== null) {\n                    audioBufferSourceNode.buffer = processedBuffer;\n                    audioBufferSourceNode.start(0);\n                }\n                audioBufferSourceNode.connect(outputChannelSplitterNode);\n                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1) {\n                    const outputChannelMergerNode = outputChannelMergerNodes[i];\n                    for (let j = 0; j < outputChannelCount[i]; j += 1) {\n                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                    }\n                    outputChannelSplitterNodeOutput += outputChannelCount[i];\n                }\n                return outputGainNode;\n            }\n            if (!nativeAudioWorkletNodeIsOwnedByContext) {\n                for (const [nm, audioParam] of proxy.parameters.entries()) {\n                    await renderAutomation(nativeOfflineAudioContext, audioParam, \n                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                    nativeAudioWorkletNode.parameters.get(nm));\n                }\n            }\n            else {\n                for (const [nm, audioParam] of proxy.parameters.entries()) {\n                    await connectAudioParam(nativeOfflineAudioContext, audioParam, \n                    // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.\n                    nativeAudioWorkletNode.parameters.get(nm));\n                }\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode);\n            return nativeAudioWorkletNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);\n                const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=audio-worklet-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createBaseAudioContextConstructor\": () => (/* binding */ createBaseAudioContextConstructor)\n/* harmony export */ });\nconst createBaseAudioContextConstructor = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor) => {\n    return class BaseAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(_nativeContext, numberOfChannels) {\n            super(_nativeContext, numberOfChannels);\n            this._nativeContext = _nativeContext;\n            this._audioWorklet =\n                addAudioWorkletModule === undefined\n                    ? undefined\n                    : {\n                        addModule: (moduleURL, options) => {\n                            return addAudioWorkletModule(this, moduleURL, options);\n                        }\n                    };\n        }\n        get audioWorklet() {\n            return this._audioWorklet;\n        }\n        createAnalyser() {\n            return new analyserNodeConstructor(this);\n        }\n        createBiquadFilter() {\n            return new biquadFilterNodeConstructor(this);\n        }\n        createBuffer(numberOfChannels, length, sampleRate) {\n            return new audioBufferConstructor({ length, numberOfChannels, sampleRate });\n        }\n        createBufferSource() {\n            return new audioBufferSourceNodeConstructor(this);\n        }\n        createChannelMerger(numberOfInputs = 6) {\n            return new channelMergerNodeConstructor(this, { numberOfInputs });\n        }\n        createChannelSplitter(numberOfOutputs = 6) {\n            return new channelSplitterNodeConstructor(this, { numberOfOutputs });\n        }\n        createConstantSource() {\n            return new constantSourceNodeConstructor(this);\n        }\n        createConvolver() {\n            return new convolverNodeConstructor(this);\n        }\n        createDelay(maxDelayTime = 1) {\n            return new delayNodeConstructor(this, { maxDelayTime });\n        }\n        createDynamicsCompressor() {\n            return new dynamicsCompressorNodeConstructor(this);\n        }\n        createGain() {\n            return new gainNodeConstructor(this);\n        }\n        createIIRFilter(feedforward, feedback) {\n            return new iIRFilterNodeConstructor(this, { feedback, feedforward });\n        }\n        createOscillator() {\n            return new oscillatorNodeConstructor(this);\n        }\n        createPanner() {\n            return new pannerNodeConstructor(this);\n        }\n        createPeriodicWave(real, imag, constraints = { disableNormalization: false }) {\n            return new periodicWaveConstructor(this, { ...constraints, imag, real });\n        }\n        createStereoPanner() {\n            return new stereoPannerNodeConstructor(this);\n        }\n        createWaveShaper() {\n            return new waveShaperNodeConstructor(this);\n        }\n        decodeAudioData(audioData, successCallback, errorCallback) {\n            return decodeAudioData(this._nativeContext, audioData).then((audioBuffer) => {\n                if (typeof successCallback === 'function') {\n                    successCallback(audioBuffer);\n                }\n                return audioBuffer;\n            }, (err) => {\n                if (typeof errorCallback === 'function') {\n                    errorCallback(err);\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createBiquadFilterNodeConstructor\": () => (/* binding */ createBiquadFilterNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst DEFAULT_OPTIONS = {\n    Q: 1,\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    detune: 0,\n    frequency: 350,\n    gain: 0,\n    type: 'lowpass'\n};\nconst createBiquadFilterNodeConstructor = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class BiquadFilterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const biquadFilterNodeRenderer = (isOffline ? createBiquadFilterNodeRenderer() : null);\n            super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);\n            // Bug #80: Safari does not export the correct values for maxValue and minValue.\n            this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2(_constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT), -1200 * Math.log2(_constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT));\n            // Bug #77: Firefox & Safari do not export the correct value for minValue.\n            this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);\n            // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10(_constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT), _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._nativeBiquadFilterNode = nativeBiquadFilterNode;\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        get detune() {\n            return this._detune;\n        }\n        get frequency() {\n            return this._frequency;\n        }\n        get gain() {\n            return this._gain;\n        }\n        get Q() {\n            return this._Q;\n        }\n        get type() {\n            return this._nativeBiquadFilterNode.type;\n        }\n        set type(value) {\n            this._nativeBiquadFilterNode.type = value;\n        }\n        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n            // Bug #189: Safari does throw an InvalidStateError.\n            try {\n                this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);\n            }\n            catch (err) {\n                if (err.code === 11) {\n                    throw createInvalidAccessError();\n                }\n                throw err;\n            }\n            // Bug #68: Safari does not throw an error if the parameters differ in their length.\n            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {\n                throw createInvalidAccessError();\n            }\n        }\n    };\n};\n//# sourceMappingURL=biquad-filter-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createBiquadFilterNodeRendererFactory\": () => (/* binding */ createBiquadFilterNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createBiquadFilterNodeRendererFactory = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeBiquadFilterNodes = new WeakMap();\n        const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeBiquadFilterNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeBiquadFilterNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeBiquadFilterNode, nativeOfflineAudioContext);\n            if (!nativeBiquadFilterNodeIsOwnedByContext) {\n                const options = {\n                    Q: nativeBiquadFilterNode.Q.value,\n                    channelCount: nativeBiquadFilterNode.channelCount,\n                    channelCountMode: nativeBiquadFilterNode.channelCountMode,\n                    channelInterpretation: nativeBiquadFilterNode.channelInterpretation,\n                    detune: nativeBiquadFilterNode.detune.value,\n                    frequency: nativeBiquadFilterNode.frequency.value,\n                    gain: nativeBiquadFilterNode.gain.value,\n                    type: nativeBiquadFilterNode.type\n                };\n                nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);\n            if (!nativeBiquadFilterNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);\n                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);\n                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);\n                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode);\n            return nativeBiquadFilterNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeBiquadFilterNode !== undefined) {\n                    return Promise.resolve(renderedNativeBiquadFilterNode);\n                }\n                return createBiquadFilterNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=biquad-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createCacheTestResult\": () => (/* binding */ createCacheTestResult)\n/* harmony export */ });\nconst createCacheTestResult = (ongoingTests, testResults) => {\n    return (tester, test) => {\n        const cachedTestResult = testResults.get(tester);\n        if (cachedTestResult !== undefined) {\n            return cachedTestResult;\n        }\n        const ongoingTest = ongoingTests.get(tester);\n        if (ongoingTest !== undefined) {\n            return ongoingTest;\n        }\n        try {\n            const synchronousTestResult = test();\n            if (synchronousTestResult instanceof Promise) {\n                ongoingTests.set(tester, synchronousTestResult);\n                return synchronousTestResult\n                    .catch(() => false)\n                    .then((finalTestResult) => {\n                    ongoingTests.delete(tester);\n                    testResults.set(tester, finalTestResult);\n                    return finalTestResult;\n                });\n            }\n            testResults.set(tester, synchronousTestResult);\n            return synchronousTestResult;\n        }\n        catch {\n            testResults.set(tester, false);\n            return false;\n        }\n    };\n};\n//# sourceMappingURL=cache-test-result.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelMergerNodeConstructor\": () => (/* binding */ createChannelMergerNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 1,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    numberOfInputs: 6\n};\nconst createChannelMergerNodeConstructor = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class ChannelMergerNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);\n            const channelMergerNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null));\n            super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);\n        }\n    };\n};\n//# sourceMappingURL=channel-merger-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelMergerNodeRendererFactory\": () => (/* binding */ createChannelMergerNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createChannelMergerNodeRendererFactory = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAudioNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAudioNode, nativeOfflineAudioContext);\n            if (!nativeAudioNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAudioNode.channelCount,\n                    channelCountMode: nativeAudioNode.channelCountMode,\n                    channelInterpretation: nativeAudioNode.channelInterpretation,\n                    numberOfInputs: nativeAudioNode.numberOfInputs\n                };\n                nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);\n            return nativeAudioNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=channel-merger-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelSplitterNodeConstructor\": () => (/* binding */ createChannelSplitterNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 6,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'discrete',\n    numberOfOutputs: 6\n};\nconst createChannelSplitterNodeConstructor = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions) => {\n    return class ChannelSplitterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = sanitizeChannelSplitterOptions({ ...DEFAULT_OPTIONS, ...options });\n            const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);\n            const channelSplitterNodeRenderer = ((isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null));\n            super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);\n        }\n    };\n};\n//# sourceMappingURL=channel-splitter-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createChannelSplitterNodeRendererFactory\": () => (/* binding */ createChannelSplitterNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createChannelSplitterNodeRendererFactory = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioNode = getNativeAudioNode(proxy);\n            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeAudioNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeAudioNode, nativeOfflineAudioContext);\n            if (!nativeAudioNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeAudioNode.channelCount,\n                    channelCountMode: nativeAudioNode.channelCountMode,\n                    channelInterpretation: nativeAudioNode.channelInterpretation,\n                    numberOfOutputs: nativeAudioNode.numberOfOutputs\n                };\n                nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode);\n            return nativeAudioNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=channel-splitter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConnectAudioParam\": () => (/* binding */ createConnectAudioParam)\n/* harmony export */ });\nconst createConnectAudioParam = (renderInputsOfAudioParam) => {\n    return (nativeOfflineAudioContext, audioParam, nativeAudioParam) => {\n        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);\n    };\n};\n//# sourceMappingURL=connect-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConnectMultipleOutputs\": () => (/* binding */ createConnectMultipleOutputs)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js\");\n\nconst createConnectMultipleOutputs = (createIndexSizeError) => {\n    return (outputAudioNodes, destination, output = 0, input = 0) => {\n        const outputAudioNode = outputAudioNodes[output];\n        if (outputAudioNode === undefined) {\n            throw createIndexSizeError();\n        }\n        if ((0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destination)) {\n            return outputAudioNode.connect(destination, 0, input);\n        }\n        return outputAudioNode.connect(destination, 0);\n    };\n};\n//# sourceMappingURL=connect-multiple-outputs.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConnectedNativeAudioBufferSourceNodeFactory\": () => (/* binding */ createConnectedNativeAudioBufferSourceNodeFactory)\n/* harmony export */ });\nconst createConnectedNativeAudioBufferSourceNodeFactory = (createNativeAudioBufferSourceNode) => {\n    return (nativeContext, nativeAudioNode) => {\n        const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n        });\n        const nativeAudioBuffer = nativeContext.createBuffer(1, 2, 44100);\n        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n        nativeAudioBufferSourceNode.loop = true;\n        nativeAudioBufferSourceNode.connect(nativeAudioNode);\n        nativeAudioBufferSourceNode.start();\n        return () => {\n            nativeAudioBufferSourceNode.stop();\n            nativeAudioBufferSourceNode.disconnect(nativeAudioNode);\n        };\n    };\n};\n//# sourceMappingURL=connected-native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConstantSourceNodeConstructor\": () => (/* binding */ createConstantSourceNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    offset: 1\n};\nconst createConstantSourceNodeConstructor = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class ConstantSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const constantSourceNodeRenderer = ((isOffline ? createConstantSourceNodeRendererFactory() : null));\n            super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);\n            this._constantSourceNodeRenderer = constantSourceNodeRenderer;\n            this._nativeConstantSourceNode = nativeConstantSourceNode;\n            /*\n             * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and minValue\n             * for GainNodes.\n             */\n            this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._onended = null;\n        }\n        get offset() {\n            return this._offset;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeConstantSourceNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeConstantSourceNode.onended;\n            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;\n        }\n        start(when = 0) {\n            this._nativeConstantSourceNode.start(when);\n            if (this._constantSourceNodeRenderer !== null) {\n                this._constantSourceNodeRenderer.start = when;\n            }\n            if (this.context.state !== 'closed') {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToActive)(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeConstantSourceNode.removeEventListener('ended', resetInternalStateToPassive);\n                    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_1__.isActiveAudioNode)(this)) {\n                        (0,_helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_3__.setInternalStateToPassive)(this);\n                    }\n                };\n                this._nativeConstantSourceNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeConstantSourceNode.stop(when);\n            if (this._constantSourceNodeRenderer !== null) {\n                this._constantSourceNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=constant-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConstantSourceNodeRendererFactory\": () => (/* binding */ createConstantSourceNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createConstantSourceNodeRendererFactory = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeConstantSourceNodes = new WeakMap();\n        let start = null;\n        let stop = null;\n        const createConstantSourceNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeConstantSourceNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeConstantSourceNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeConstantSourceNode, nativeOfflineAudioContext);\n            if (!nativeConstantSourceNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeConstantSourceNode.channelCount,\n                    channelCountMode: nativeConstantSourceNode.channelCountMode,\n                    channelInterpretation: nativeConstantSourceNode.channelInterpretation,\n                    offset: nativeConstantSourceNode.offset.value\n                };\n                nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeConstantSourceNode.start(start);\n                }\n                if (stop !== null) {\n                    nativeConstantSourceNode.stop(stop);\n                }\n            }\n            renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);\n            if (!nativeConstantSourceNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode);\n            return nativeConstantSourceNode;\n        };\n        return {\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeConstantSourceNode !== undefined) {\n                    return Promise.resolve(renderedNativeConstantSourceNode);\n                }\n                return createConstantSourceNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=constant-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConvertNumberToUnsignedLong\": () => (/* binding */ createConvertNumberToUnsignedLong)\n/* harmony export */ });\nconst createConvertNumberToUnsignedLong = (unit32Array) => {\n    return (value) => {\n        unit32Array[0] = value;\n        return unit32Array[0];\n    };\n};\n//# sourceMappingURL=convert-number-to-unsigned-long.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConvolverNodeConstructor\": () => (/* binding */ createConvolverNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    buffer: null,\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    disableNormalization: false\n};\nconst createConvolverNodeConstructor = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class ConvolverNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const convolverNodeRenderer = (isOffline ? createConvolverNodeRenderer() : null);\n            super(context, false, nativeConvolverNode, convolverNodeRenderer);\n            this._isBufferNullified = false;\n            this._nativeConvolverNode = nativeConvolverNode;\n            if (mergedOptions.buffer !== null) {\n                setAudioNodeTailTime(this, mergedOptions.buffer.duration);\n            }\n        }\n        get buffer() {\n            if (this._isBufferNullified) {\n                return null;\n            }\n            return this._nativeConvolverNode.buffer;\n        }\n        set buffer(value) {\n            this._nativeConvolverNode.buffer = value;\n            // Bug #115: Safari does not allow to set the buffer to null.\n            if (value === null && this._nativeConvolverNode.buffer !== null) {\n                const nativeContext = this._nativeConvolverNode.context;\n                this._nativeConvolverNode.buffer = nativeContext.createBuffer(1, 1, 44100);\n                this._isBufferNullified = true;\n                setAudioNodeTailTime(this, 0);\n            }\n            else {\n                this._isBufferNullified = false;\n                setAudioNodeTailTime(this, this._nativeConvolverNode.buffer === null ? 0 : this._nativeConvolverNode.buffer.duration);\n            }\n        }\n        get normalize() {\n            return this._nativeConvolverNode.normalize;\n        }\n        set normalize(value) {\n            this._nativeConvolverNode.normalize = value;\n        }\n    };\n};\n//# sourceMappingURL=convolver-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createConvolverNodeRendererFactory\": () => (/* binding */ createConvolverNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createConvolverNodeRendererFactory = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeConvolverNodes = new WeakMap();\n        const createConvolverNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeConvolverNode = getNativeAudioNode(proxy);\n            // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeConvolverNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeConvolverNode, nativeOfflineAudioContext);\n            if (!nativeConvolverNodeIsOwnedByContext) {\n                const options = {\n                    buffer: nativeConvolverNode.buffer,\n                    channelCount: nativeConvolverNode.channelCount,\n                    channelCountMode: nativeConvolverNode.channelCountMode,\n                    channelInterpretation: nativeConvolverNode.channelInterpretation,\n                    disableNormalization: !nativeConvolverNode.normalize\n                };\n                nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeConvolverNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode);\n            }\n            return nativeConvolverNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeConvolverNode !== undefined) {\n                    return Promise.resolve(renderedNativeConvolverNode);\n                }\n                return createConvolverNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=convolver-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createCreateNativeOfflineAudioContext\": () => (/* binding */ createCreateNativeOfflineAudioContext)\n/* harmony export */ });\nconst createCreateNativeOfflineAudioContext = (createNotSupportedError, nativeOfflineAudioContextConstructor) => {\n    return (numberOfChannels, length, sampleRate) => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            throw new Error('Missing the native OfflineAudioContext constructor.');\n        }\n        try {\n            return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);\n        }\n        catch (err) {\n            // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.\n            if (err.name === 'SyntaxError') {\n                throw createNotSupportedError();\n            }\n            throw err;\n        }\n    };\n};\n//# sourceMappingURL=create-native-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDataCloneError\": () => (/* binding */ createDataCloneError)\n/* harmony export */ });\nconst createDataCloneError = () => new DOMException('', 'DataCloneError');\n//# sourceMappingURL=data-clone-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDecodeAudioData\": () => (/* binding */ createDecodeAudioData)\n/* harmony export */ });\n/* harmony import */ var _helpers_detach_array_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/detach-array-buffer */ \"./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-get-channel-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js\");\n\n\nconst createDecodeAudioData = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    return (anyContext, audioData) => {\n        const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);\n        // Bug #43: Only Chrome, Edge and Opera do throw a DataCloneError.\n        if (detachedArrayBuffers.has(audioData)) {\n            const err = createDataCloneError();\n            return Promise.reject(err);\n        }\n        // The audioData parameter maybe of a type which can't be added to a WeakSet.\n        try {\n            detachedArrayBuffers.add(audioData);\n        }\n        catch {\n            // Ignore errors.\n        }\n        // Bug #21: Safari does not support promises yet.\n        if (cacheTestResult(testPromiseSupport, () => testPromiseSupport(nativeContext))) {\n            return nativeContext.decodeAudioData(audioData).then((audioBuffer) => {\n                // Bug #133: Safari does neuter the ArrayBuffer.\n                (0,_helpers_detach_array_buffer__WEBPACK_IMPORTED_MODULE_0__.detachArrayBuffer)(audioData).catch(() => {\n                    // Ignore errors.\n                });\n                // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.\n                if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n                    wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n                }\n                audioBufferStore.add(audioBuffer);\n                return audioBuffer;\n            });\n        }\n        // Bug #21: Safari does not return a Promise yet.\n        return new Promise((resolve, reject) => {\n            const complete = async () => {\n                // Bug #133: Safari does neuter the ArrayBuffer.\n                try {\n                    await (0,_helpers_detach_array_buffer__WEBPACK_IMPORTED_MODULE_0__.detachArrayBuffer)(audioData);\n                }\n                catch {\n                    // Ignore errors.\n                }\n            };\n            const fail = (err) => {\n                reject(err);\n                complete();\n            };\n            // Bug #26: Safari throws a synchronous error.\n            try {\n                // Bug #1: Safari requires a successCallback.\n                nativeContext.decodeAudioData(audioData, (audioBuffer) => {\n                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n                    // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n                    if (typeof audioBuffer.copyFromChannel !== 'function') {\n                        wrapAudioBufferCopyChannelMethods(audioBuffer);\n                        (0,_helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_1__.wrapAudioBufferGetChannelDataMethod)(audioBuffer);\n                    }\n                    audioBufferStore.add(audioBuffer);\n                    complete().then(() => resolve(audioBuffer));\n                }, (err) => {\n                    // Bug #4: Safari returns null instead of an error.\n                    if (err === null) {\n                        fail(createEncodingError());\n                    }\n                    else {\n                        fail(err);\n                    }\n                });\n            }\n            catch (err) {\n                fail(err);\n            }\n        });\n    };\n};\n//# sourceMappingURL=decode-audio-data.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDecrementCycleCounter\": () => (/* binding */ createDecrementCycleCounter)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js\");\n\nconst createDecrementCycleCounter = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext) => {\n    return (audioNode, count) => {\n        const cycleCounter = cycleCounters.get(audioNode);\n        if (cycleCounter === undefined) {\n            throw new Error('Missing the expected cycle count.');\n        }\n        const nativeContext = getNativeContext(audioNode.context);\n        const isOffline = isNativeOfflineAudioContext(nativeContext);\n        if (cycleCounter === count) {\n            cycleCounters.delete(audioNode);\n            if (!isOffline && isActiveAudioNode(audioNode)) {\n                const nativeSourceAudioNode = getNativeAudioNode(audioNode);\n                const { outputs } = getAudioNodeConnections(audioNode);\n                for (const output of outputs) {\n                    if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__.isAudioNodeOutputConnection)(output)) {\n                        const nativeDestinationAudioNode = getNativeAudioNode(output[0]);\n                        connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);\n                    }\n                    else {\n                        const nativeDestinationAudioParam = getNativeAudioParam(output[0]);\n                        nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);\n                    }\n                }\n            }\n        }\n        else {\n            cycleCounters.set(audioNode, cycleCounter - count);\n        }\n    };\n};\n//# sourceMappingURL=decrement-cycle-counter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDelayNodeConstructor\": () => (/* binding */ createDelayNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    delayTime: 0,\n    maxDelayTime: 1\n};\nconst createDelayNodeConstructor = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class DelayNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const delayNodeRenderer = (isOffline ? createDelayNodeRenderer(mergedOptions.maxDelayTime) : null);\n            super(context, false, nativeDelayNode, delayNodeRenderer);\n            this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime);\n            setAudioNodeTailTime(this, mergedOptions.maxDelayTime);\n        }\n        get delayTime() {\n            return this._delayTime;\n        }\n    };\n};\n//# sourceMappingURL=delay-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDelayNodeRendererFactory\": () => (/* binding */ createDelayNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createDelayNodeRendererFactory = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return (maxDelayTime) => {\n        const renderedNativeDelayNodes = new WeakMap();\n        const createDelayNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeDelayNode = getNativeAudioNode(proxy);\n            // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeDelayNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeDelayNode, nativeOfflineAudioContext);\n            if (!nativeDelayNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeDelayNode.channelCount,\n                    channelCountMode: nativeDelayNode.channelCountMode,\n                    channelInterpretation: nativeDelayNode.channelInterpretation,\n                    delayTime: nativeDelayNode.delayTime.value,\n                    maxDelayTime\n                };\n                nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);\n            if (!nativeDelayNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode);\n            return nativeDelayNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeDelayNode !== undefined) {\n                    return Promise.resolve(renderedNativeDelayNode);\n                }\n                return createDelayNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=delay-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDeleteActiveInputConnectionToAudioNode\": () => (/* binding */ createDeleteActiveInputConnectionToAudioNode)\n/* harmony export */ });\nconst createDeleteActiveInputConnectionToAudioNode = (pickElementFromSet) => {\n    return (activeInputs, source, output, input) => {\n        return pickElementFromSet(activeInputs[input], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output);\n    };\n};\n//# sourceMappingURL=delete-active-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDeleteUnrenderedAudioWorkletNode\": () => (/* binding */ createDeleteUnrenderedAudioWorkletNode)\n/* harmony export */ });\nconst createDeleteUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes) => {\n    return (nativeContext, audioWorkletNode) => {\n        getUnrenderedAudioWorkletNodes(nativeContext).delete(audioWorkletNode);\n    };\n};\n//# sourceMappingURL=delete-unrendered-audio-worklet-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDetectCycles\": () => (/* binding */ createDetectCycles)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js\");\n/* harmony import */ var _guards_delay_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../guards/delay-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js\");\n\n\nconst createDetectCycles = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey) => {\n    return function detectCycles(chain, nextLink) {\n        const audioNode = (0,_guards_audio_node__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(nextLink) ? nextLink : getValueForKey(audioParamAudioNodeStore, nextLink);\n        if ((0,_guards_delay_node__WEBPACK_IMPORTED_MODULE_1__.isDelayNode)(audioNode)) {\n            return [];\n        }\n        if (chain[0] === audioNode) {\n            return [chain];\n        }\n        if (chain.includes(audioNode)) {\n            return [];\n        }\n        const { outputs } = getAudioNodeConnections(audioNode);\n        return Array.from(outputs)\n            .map((outputConnection) => detectCycles([...chain, audioNode], outputConnection[0]))\n            .reduce((mergedCycles, nestedCycles) => mergedCycles.concat(nestedCycles), []);\n    };\n};\n//# sourceMappingURL=detect-cycles.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDisconnectMultipleOutputs\": () => (/* binding */ createDisconnectMultipleOutputs)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js\");\n\nconst getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output) => {\n    const outputAudioNode = outputAudioNodes[output];\n    if (outputAudioNode === undefined) {\n        throw createIndexSizeError();\n    }\n    return outputAudioNode;\n};\nconst createDisconnectMultipleOutputs = (createIndexSizeError) => {\n    return (outputAudioNodes, destinationOrOutput = undefined, output = undefined, input = 0) => {\n        if (destinationOrOutput === undefined) {\n            return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect());\n        }\n        if (typeof destinationOrOutput === 'number') {\n            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput).disconnect();\n        }\n        if ((0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destinationOrOutput)) {\n            if (output === undefined) {\n                return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));\n            }\n            if (input === undefined) {\n                return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);\n            }\n            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0, input);\n        }\n        if (output === undefined) {\n            return outputAudioNodes.forEach((outputAudioNode) => outputAudioNode.disconnect(destinationOrOutput));\n        }\n        return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);\n    };\n};\n//# sourceMappingURL=disconnect-multiple-outputs.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDynamicsCompressorNodeConstructor\": () => (/* binding */ createDynamicsCompressorNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    attack: 0.003,\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    knee: 30,\n    ratio: 12,\n    release: 0.25,\n    threshold: -24\n};\nconst createDynamicsCompressorNodeConstructor = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class DynamicsCompressorNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const dynamicsCompressorNodeRenderer = (isOffline ? createDynamicsCompressorNodeRenderer() : null);\n            super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);\n            this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack);\n            this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee);\n            this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;\n            this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio);\n            this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release);\n            this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold);\n            setAudioNodeTailTime(this, 0.006);\n        }\n        get attack() {\n            return this._attack;\n        }\n        // Bug #108: Safari allows a channelCount of three and above which is why the getter and setter needs to be overwritten here.\n        get channelCount() {\n            return this._nativeDynamicsCompressorNode.channelCount;\n        }\n        set channelCount(value) {\n            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;\n            this._nativeDynamicsCompressorNode.channelCount = value;\n            if (value > 2) {\n                this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;\n                throw createNotSupportedError();\n            }\n        }\n        /*\n         * Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be\n         * overwritten here.\n         */\n        get channelCountMode() {\n            return this._nativeDynamicsCompressorNode.channelCountMode;\n        }\n        set channelCountMode(value) {\n            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;\n            this._nativeDynamicsCompressorNode.channelCountMode = value;\n            if (value === 'max') {\n                this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;\n                throw createNotSupportedError();\n            }\n        }\n        get knee() {\n            return this._knee;\n        }\n        get ratio() {\n            return this._ratio;\n        }\n        get reduction() {\n            // Bug #111: Safari returns an AudioParam instead of a number.\n            if (typeof this._nativeDynamicsCompressorNode.reduction.value === 'number') {\n                return this._nativeDynamicsCompressorNode.reduction.value;\n            }\n            return this._nativeDynamicsCompressorNode.reduction;\n        }\n        get release() {\n            return this._release;\n        }\n        get threshold() {\n            return this._threshold;\n        }\n    };\n};\n//# sourceMappingURL=dynamics-compressor-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createDynamicsCompressorNodeRendererFactory\": () => (/* binding */ createDynamicsCompressorNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createDynamicsCompressorNodeRendererFactory = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeDynamicsCompressorNodes = new WeakMap();\n        const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be\n             * created again.\n             */\n            const nativeDynamicsCompressorNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeDynamicsCompressorNode, nativeOfflineAudioContext);\n            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {\n                const options = {\n                    attack: nativeDynamicsCompressorNode.attack.value,\n                    channelCount: nativeDynamicsCompressorNode.channelCount,\n                    channelCountMode: nativeDynamicsCompressorNode.channelCountMode,\n                    channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,\n                    knee: nativeDynamicsCompressorNode.knee.value,\n                    ratio: nativeDynamicsCompressorNode.ratio.value,\n                    release: nativeDynamicsCompressorNode.release.value,\n                    threshold: nativeDynamicsCompressorNode.threshold.value\n                };\n                nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);\n            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);\n                await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);\n                await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);\n                await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);\n                await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode);\n            return nativeDynamicsCompressorNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeDynamicsCompressorNode !== undefined) {\n                    return Promise.resolve(renderedNativeDynamicsCompressorNode);\n                }\n                return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=dynamics-compressor-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createEncodingError\": () => (/* binding */ createEncodingError)\n/* harmony export */ });\nconst createEncodingError = () => new DOMException('', 'EncodingError');\n//# sourceMappingURL=encoding-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createEvaluateSource\": () => (/* binding */ createEvaluateSource)\n/* harmony export */ });\nconst createEvaluateSource = (window) => {\n    return (source) => new Promise((resolve, reject) => {\n        if (window === null) {\n            // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n            reject(new SyntaxError());\n            return;\n        }\n        const head = window.document.head;\n        if (head === null) {\n            // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n            reject(new SyntaxError());\n        }\n        else {\n            const script = window.document.createElement('script');\n            // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.\n            const blob = new Blob([source], { type: 'application/javascript' });\n            const url = URL.createObjectURL(blob);\n            const originalOnErrorHandler = window.onerror;\n            const removeErrorEventListenerAndRevokeUrl = () => {\n                window.onerror = originalOnErrorHandler;\n                URL.revokeObjectURL(url);\n            };\n            window.onerror = (message, src, lineno, colno, error) => {\n                // @todo Edge thinks the source is the one of the html document.\n                if (src === url || (src === window.location.href && lineno === 1 && colno === 1)) {\n                    removeErrorEventListenerAndRevokeUrl();\n                    reject(error);\n                    return false;\n                }\n                if (originalOnErrorHandler !== null) {\n                    return originalOnErrorHandler(message, src, lineno, colno, error);\n                }\n            };\n            script.onerror = () => {\n                removeErrorEventListenerAndRevokeUrl();\n                // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.\n                reject(new SyntaxError());\n            };\n            script.onload = () => {\n                removeErrorEventListenerAndRevokeUrl();\n                resolve();\n            };\n            script.src = url;\n            script.type = 'module';\n            head.appendChild(script);\n        }\n    });\n};\n//# sourceMappingURL=evaluate-source.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createEventTargetConstructor\": () => (/* binding */ createEventTargetConstructor)\n/* harmony export */ });\nconst createEventTargetConstructor = (wrapEventListener) => {\n    return class EventTarget {\n        constructor(_nativeEventTarget) {\n            this._nativeEventTarget = _nativeEventTarget;\n            this._listeners = new WeakMap();\n        }\n        addEventListener(type, listener, options) {\n            if (listener !== null) {\n                let wrappedEventListener = this._listeners.get(listener);\n                if (wrappedEventListener === undefined) {\n                    wrappedEventListener = wrapEventListener(this, listener);\n                    if (typeof listener === 'function') {\n                        this._listeners.set(listener, wrappedEventListener);\n                    }\n                }\n                this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);\n            }\n        }\n        dispatchEvent(event) {\n            return this._nativeEventTarget.dispatchEvent(event);\n        }\n        removeEventListener(type, listener, options) {\n            const wrappedEventListener = listener === null ? undefined : this._listeners.get(listener);\n            this._nativeEventTarget.removeEventListener(type, wrappedEventListener === undefined ? null : wrappedEventListener, options);\n        }\n    };\n};\n//# sourceMappingURL=event-target-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createExposeCurrentFrameAndCurrentTime\": () => (/* binding */ createExposeCurrentFrameAndCurrentTime)\n/* harmony export */ });\nconst createExposeCurrentFrameAndCurrentTime = (window) => {\n    return (currentTime, sampleRate, fn) => {\n        Object.defineProperties(window, {\n            currentFrame: {\n                configurable: true,\n                get() {\n                    return Math.round(currentTime * sampleRate);\n                }\n            },\n            currentTime: {\n                configurable: true,\n                get() {\n                    return currentTime;\n                }\n            }\n        });\n        try {\n            return fn();\n        }\n        finally {\n            if (window !== null) {\n                delete window.currentFrame;\n                delete window.currentTime;\n            }\n        }\n    };\n};\n//# sourceMappingURL=expose-current-frame-and-current-time.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createFetchSource\": () => (/* binding */ createFetchSource)\n/* harmony export */ });\nconst createFetchSource = (createAbortError) => {\n    return async (url) => {\n        try {\n            const response = await fetch(url);\n            if (response.ok) {\n                return [await response.text(), response.url];\n            }\n        }\n        catch {\n            // Ignore errors.\n        } // tslint:disable-line:no-empty\n        throw createAbortError();\n    };\n};\n//# sourceMappingURL=fetch-source.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGainNodeConstructor\": () => (/* binding */ createGainNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    gain: 1\n};\nconst createGainNodeConstructor = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class GainNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const gainNodeRenderer = (isOffline ? createGainNodeRenderer() : null);\n            super(context, false, nativeGainNode, gainNodeRenderer);\n            // Bug #74: Safari does not export the correct values for maxValue and minValue.\n            this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n        }\n        get gain() {\n            return this._gain;\n        }\n    };\n};\n//# sourceMappingURL=gain-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGainNodeRendererFactory\": () => (/* binding */ createGainNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createGainNodeRendererFactory = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeGainNodes = new WeakMap();\n        const createGainNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeGainNode = getNativeAudioNode(proxy);\n            // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeGainNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeGainNode, nativeOfflineAudioContext);\n            if (!nativeGainNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeGainNode.channelCount,\n                    channelCountMode: nativeGainNode.channelCountMode,\n                    channelInterpretation: nativeGainNode.channelInterpretation,\n                    gain: nativeGainNode.gain.value\n                };\n                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);\n            if (!nativeGainNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode);\n            return nativeGainNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeGainNode !== undefined) {\n                    return Promise.resolve(renderedNativeGainNode);\n                }\n                return createGainNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=gain-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetActiveAudioWorkletNodeInputs\": () => (/* binding */ createGetActiveAudioWorkletNodeInputs)\n/* harmony export */ });\nconst createGetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore, getValueForKey) => {\n    return (nativeAudioWorkletNode) => getValueForKey(activeAudioWorkletNodeInputsStore, nativeAudioWorkletNode);\n};\n//# sourceMappingURL=get-active-audio-worklet-node-inputs.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetAudioNodeRenderer\": () => (/* binding */ createGetAudioNodeRenderer)\n/* harmony export */ });\nconst createGetAudioNodeRenderer = (getAudioNodeConnections) => {\n    return (audioNode) => {\n        const audioNodeConnections = getAudioNodeConnections(audioNode);\n        if (audioNodeConnections.renderer === null) {\n            throw new Error('Missing the renderer of the given AudioNode in the audio graph.');\n        }\n        return audioNodeConnections.renderer;\n    };\n};\n//# sourceMappingURL=get-audio-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetAudioNodeTailTime\": () => (/* binding */ createGetAudioNodeTailTime)\n/* harmony export */ });\nconst createGetAudioNodeTailTime = (audioNodeTailTimeStore) => {\n    return (audioNode) => { var _a; return (_a = audioNodeTailTimeStore.get(audioNode)) !== null && _a !== void 0 ? _a : 0; };\n};\n//# sourceMappingURL=get-audio-node-tail-time.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetAudioParamRenderer\": () => (/* binding */ createGetAudioParamRenderer)\n/* harmony export */ });\nconst createGetAudioParamRenderer = (getAudioParamConnections) => {\n    return (audioParam) => {\n        const audioParamConnections = getAudioParamConnections(audioParam);\n        if (audioParamConnections.renderer === null) {\n            throw new Error('Missing the renderer of the given AudioParam in the audio graph.');\n        }\n        return audioParamConnections.renderer;\n    };\n};\n//# sourceMappingURL=get-audio-param-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetBackupOfflineAudioContext\": () => (/* binding */ createGetBackupOfflineAudioContext)\n/* harmony export */ });\nconst createGetBackupOfflineAudioContext = (backupOfflineAudioContextStore) => {\n    return (nativeContext) => {\n        return backupOfflineAudioContextStore.get(nativeContext);\n    };\n};\n//# sourceMappingURL=get-backup-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetNativeContext\": () => (/* binding */ createGetNativeContext)\n/* harmony export */ });\n/* harmony import */ var _invalid_state_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n\nconst createGetNativeContext = (contextStore) => {\n    return (context) => {\n        const nativeContext = contextStore.get(context);\n        if (nativeContext === undefined) {\n            throw (0,_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n        }\n        return (nativeContext);\n    };\n};\n//# sourceMappingURL=get-native-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetOrCreateBackupOfflineAudioContext\": () => (/* binding */ createGetOrCreateBackupOfflineAudioContext)\n/* harmony export */ });\nconst createGetOrCreateBackupOfflineAudioContext = (backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor) => {\n    return (nativeContext) => {\n        let backupOfflineAudioContext = backupOfflineAudioContextStore.get(nativeContext);\n        if (backupOfflineAudioContext !== undefined) {\n            return backupOfflineAudioContext;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            throw new Error('Missing the native OfflineAudioContext constructor.');\n        }\n        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.\n        backupOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        backupOfflineAudioContextStore.set(nativeContext, backupOfflineAudioContext);\n        return backupOfflineAudioContext;\n    };\n};\n//# sourceMappingURL=get-or-create-backup-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createGetUnrenderedAudioWorkletNodes\": () => (/* binding */ createGetUnrenderedAudioWorkletNodes)\n/* harmony export */ });\nconst createGetUnrenderedAudioWorkletNodes = (unrenderedAudioWorkletNodeStore) => {\n    return (nativeContext) => {\n        const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);\n        if (unrenderedAudioWorkletNodes === undefined) {\n            throw new Error('The context has no set of AudioWorkletNodes.');\n        }\n        return unrenderedAudioWorkletNodes;\n    };\n};\n//# sourceMappingURL=get-unrendered-audio-worklet-nodes.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIIRFilterNodeConstructor\": () => (/* binding */ createIIRFilterNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_wrap_iir_filter_node_get_frequency_response_method__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/wrap-iir-filter-node-get-frequency-response-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js\");\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers'\n};\nconst createIIRFilterNodeConstructor = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class IIRFilterNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);\n            const iirFilterNodeRenderer = ((isOffline ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null));\n            super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);\n            // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.\n            // @todo Write a test which allows other browsers to remain unpatched.\n            (0,_helpers_wrap_iir_filter_node_get_frequency_response_method__WEBPACK_IMPORTED_MODULE_0__.wrapIIRFilterNodeGetFrequencyResponseMethod)(nativeIIRFilterNode);\n            this._nativeIIRFilterNode = nativeIIRFilterNode;\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n            return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);\n        }\n    };\n};\n//# sourceMappingURL=iir-filter-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIIRFilterNodeRendererFactory\": () => (/* binding */ createIIRFilterNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/filter-buffer */ \"./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward) => {\n    const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);\n    const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);\n    const feedbackLength = convertedFeedback.length;\n    const feedforwardLength = convertedFeedforward.length;\n    const minLength = Math.min(feedbackLength, feedforwardLength);\n    if (convertedFeedback[0] !== 1) {\n        for (let i = 0; i < feedbackLength; i += 1) {\n            convertedFeedforward[i] /= convertedFeedback[0];\n        }\n        for (let i = 1; i < feedforwardLength; i += 1) {\n            convertedFeedback[i] /= convertedFeedback[0];\n        }\n    }\n    const bufferLength = 32;\n    const xBuffer = new Float32Array(bufferLength);\n    const yBuffer = new Float32Array(bufferLength);\n    const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);\n    const numberOfChannels = renderedBuffer.numberOfChannels;\n    for (let i = 0; i < numberOfChannels; i += 1) {\n        const input = renderedBuffer.getChannelData(i);\n        const output = filteredBuffer.getChannelData(i);\n        xBuffer.fill(0);\n        yBuffer.fill(0);\n        (0,_helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_0__.filterBuffer)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);\n    }\n    return filteredBuffer;\n};\nconst createIIRFilterNodeRendererFactory = (createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return (feedback, feedforward) => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let filteredBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeAudioBufferSourceNode = null;\n            let nativeIIRFilterNode = getNativeAudioNode(proxy);\n            // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeIIRFilterNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeIIRFilterNode, nativeOfflineAudioContext);\n            // Bug #9: Safari does not support IIRFilterNodes.\n            if (nativeOfflineAudioContext.createIIRFilter === undefined) {\n                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {\n                    buffer: null,\n                    channelCount: 2,\n                    channelCountMode: 'max',\n                    channelInterpretation: 'speakers',\n                    loop: false,\n                    loopEnd: 0,\n                    loopStart: 0,\n                    playbackRate: 1\n                });\n            }\n            else if (!nativeIIRFilterNodeIsOwnedByContext) {\n                // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.\n                nativeIIRFilterNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode === null ? nativeIIRFilterNode : nativeAudioBufferSourceNode);\n            if (nativeAudioBufferSourceNode !== null) {\n                if (filteredBufferPromise === null) {\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(\n                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.\n                    proxy.context.destination.channelCount, \n                    // Bug #17: Safari does not yet expose the length.\n                    proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                    filteredBufferPromise = (async () => {\n                        await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination);\n                        const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                        return filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);\n                    })();\n                }\n                const filteredBuffer = await filteredBufferPromise;\n                nativeAudioBufferSourceNode.buffer = filteredBuffer;\n                nativeAudioBufferSourceNode.start(0);\n                return nativeAudioBufferSourceNode;\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode);\n            return nativeIIRFilterNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeAudioNode !== undefined) {\n                    return Promise.resolve(renderedNativeAudioNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=iir-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIncrementCycleCounterFactory\": () => (/* binding */ createIncrementCycleCounterFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js\");\n\nconst createIncrementCycleCounterFactory = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode) => {\n    return (isOffline) => {\n        return (audioNode, count) => {\n            const cycleCounter = cycleCounters.get(audioNode);\n            if (cycleCounter === undefined) {\n                if (!isOffline && isActiveAudioNode(audioNode)) {\n                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);\n                    const { outputs } = getAudioNodeConnections(audioNode);\n                    for (const output of outputs) {\n                        if ((0,_guards_audio_node_output_connection__WEBPACK_IMPORTED_MODULE_0__.isAudioNodeOutputConnection)(output)) {\n                            const nativeDestinationAudioNode = getNativeAudioNode(output[0]);\n                            disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);\n                        }\n                        else {\n                            const nativeDestinationAudioParam = getNativeAudioParam(output[0]);\n                            nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);\n                        }\n                    }\n                }\n                cycleCounters.set(audioNode, count);\n            }\n            else {\n                cycleCounters.set(audioNode, cycleCounter + count);\n            }\n        };\n    };\n};\n//# sourceMappingURL=increment-cycle-counter-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIndexSizeError\": () => (/* binding */ createIndexSizeError)\n/* harmony export */ });\nconst createIndexSizeError = () => new DOMException('', 'IndexSizeError');\n//# sourceMappingURL=index-size-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createInvalidAccessError\": () => (/* binding */ createInvalidAccessError)\n/* harmony export */ });\nconst createInvalidAccessError = () => new DOMException('', 'InvalidAccessError');\n//# sourceMappingURL=invalid-access-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createInvalidStateError\": () => (/* binding */ createInvalidStateError)\n/* harmony export */ });\nconst createInvalidStateError = () => new DOMException('', 'InvalidStateError');\n//# sourceMappingURL=invalid-state-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyAudioContext\": () => (/* binding */ createIsAnyAudioContext)\n/* harmony export */ });\nconst createIsAnyAudioContext = (contextStore, isNativeAudioContext) => {\n    return (anything) => {\n        const nativeContext = contextStore.get(anything);\n        return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);\n    };\n};\n//# sourceMappingURL=is-any-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyAudioNode\": () => (/* binding */ createIsAnyAudioNode)\n/* harmony export */ });\nconst createIsAnyAudioNode = (audioNodeStore, isNativeAudioNode) => {\n    return (anything) => audioNodeStore.has(anything) || isNativeAudioNode(anything);\n};\n//# sourceMappingURL=is-any-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyAudioParam\": () => (/* binding */ createIsAnyAudioParam)\n/* harmony export */ });\nconst createIsAnyAudioParam = (audioParamStore, isNativeAudioParam) => {\n    return (anything) => audioParamStore.has(anything) || isNativeAudioParam(anything);\n};\n//# sourceMappingURL=is-any-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsAnyOfflineAudioContext\": () => (/* binding */ createIsAnyOfflineAudioContext)\n/* harmony export */ });\nconst createIsAnyOfflineAudioContext = (contextStore, isNativeOfflineAudioContext) => {\n    return (anything) => {\n        const nativeContext = contextStore.get(anything);\n        return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);\n    };\n};\n//# sourceMappingURL=is-any-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeAudioContext\": () => (/* binding */ createIsNativeAudioContext)\n/* harmony export */ });\nconst createIsNativeAudioContext = (nativeAudioContextConstructor) => {\n    return (anything) => {\n        return nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor;\n    };\n};\n//# sourceMappingURL=is-native-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeAudioNode\": () => (/* binding */ createIsNativeAudioNode)\n/* harmony export */ });\nconst createIsNativeAudioNode = (window) => {\n    return (anything) => {\n        return window !== null && typeof window.AudioNode === 'function' && anything instanceof window.AudioNode;\n    };\n};\n//# sourceMappingURL=is-native-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeAudioParam\": () => (/* binding */ createIsNativeAudioParam)\n/* harmony export */ });\nconst createIsNativeAudioParam = (window) => {\n    return (anything) => {\n        return window !== null && typeof window.AudioParam === 'function' && anything instanceof window.AudioParam;\n    };\n};\n//# sourceMappingURL=is-native-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeContext\": () => (/* binding */ createIsNativeContext)\n/* harmony export */ });\nconst createIsNativeContext = (isNativeAudioContext, isNativeOfflineAudioContext) => {\n    return (anything) => {\n        return isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything);\n    };\n};\n//# sourceMappingURL=is-native-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsNativeOfflineAudioContext\": () => (/* binding */ createIsNativeOfflineAudioContext)\n/* harmony export */ });\nconst createIsNativeOfflineAudioContext = (nativeOfflineAudioContextConstructor) => {\n    return (anything) => {\n        return nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor;\n    };\n};\n//# sourceMappingURL=is-native-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsSecureContext\": () => (/* binding */ createIsSecureContext)\n/* harmony export */ });\nconst createIsSecureContext = (window) => window !== null && window.isSecureContext;\n//# sourceMappingURL=is-secure-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createIsSupportedPromise\": () => (/* binding */ createIsSupportedPromise)\n/* harmony export */ });\nconst createIsSupportedPromise = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testConvolverNodeChannelCountSupport, testDomExceptionContrucorSupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport) => {\n    if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport) &&\n        cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport) &&\n        cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport) &&\n        cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport) &&\n        cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport) &&\n        cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport) &&\n        cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport) &&\n        cacheTestResult(testConvolverNodeChannelCountSupport, testConvolverNodeChannelCountSupport) &&\n        cacheTestResult(testDomExceptionContrucorSupport, testDomExceptionContrucorSupport) &&\n        cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport) &&\n        cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {\n        const results = await Promise.all([\n            cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),\n            cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),\n            cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),\n            cacheTestResult(testTransferablesSupport, testTransferablesSupport)\n        ]);\n        return results.every((result) => result);\n    }\n    return false;\n};\n//# sourceMappingURL=is-supported-promise.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaElementAudioSourceNodeConstructor\": () => (/* binding */ createMediaElementAudioSourceNodeConstructor)\n/* harmony export */ });\nconst createMediaElementAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaElementAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);\n            // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw TypeError();\n            }\n            super(context, true, nativeMediaElementAudioSourceNode, null);\n            this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;\n        }\n        get mediaElement() {\n            return this._nativeMediaElementAudioSourceNode.mediaElement;\n        }\n    };\n};\n//# sourceMappingURL=media-element-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaStreamAudioDestinationNodeConstructor\": () => (/* binding */ createMediaStreamAudioDestinationNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers'\n};\nconst createMediaStreamAudioDestinationNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaStreamAudioDestinationNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw new TypeError();\n            }\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);\n            super(context, false, nativeMediaStreamAudioDestinationNode, null);\n            this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;\n        }\n        get stream() {\n            return this._nativeMediaStreamAudioDestinationNode.stream;\n        }\n    };\n};\n//# sourceMappingURL=media-stream-audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaStreamAudioSourceNodeConstructor\": () => (/* binding */ createMediaStreamAudioSourceNodeConstructor)\n/* harmony export */ });\nconst createMediaStreamAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext) => {\n    return class MediaStreamAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);\n            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.\n            if (isNativeOfflineAudioContext(nativeContext)) {\n                throw new TypeError();\n            }\n            super(context, true, nativeMediaStreamAudioSourceNode, null);\n            this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;\n        }\n        get mediaStream() {\n            return this._nativeMediaStreamAudioSourceNode.mediaStream;\n        }\n    };\n};\n//# sourceMappingURL=media-stream-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMediaStreamTrackAudioSourceNodeConstructor\": () => (/* binding */ createMediaStreamTrackAudioSourceNodeConstructor)\n/* harmony export */ });\nconst createMediaStreamTrackAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext) => {\n    return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);\n            super(context, true, nativeMediaStreamTrackAudioSourceNode, null);\n        }\n    };\n};\n//# sourceMappingURL=media-stream-track-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMinimalAudioContextConstructor\": () => (/* binding */ createMinimalAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-valid-latency-hint */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js\");\n\n\nconst createMinimalAudioContextConstructor = (createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor) => {\n    return class MinimalAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(options = {}) {\n            if (nativeAudioContextConstructor === null) {\n                throw new Error('Missing the native AudioContext constructor.');\n            }\n            let nativeAudioContext;\n            try {\n                nativeAudioContext = new nativeAudioContextConstructor(options);\n            }\n            catch (err) {\n                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.\n                if (err.code === 12 && err.message === 'sampleRate is not in range') {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n            // Bug #131 Safari returns null when there are four other AudioContexts running already.\n            if (nativeAudioContext === null) {\n                throw createUnknownError();\n            }\n            // Bug #51 Only Chrome Edge, and Opera throw an error if the given latencyHint is invalid.\n            if (!(0,_helpers_is_valid_latency_hint__WEBPACK_IMPORTED_MODULE_1__.isValidLatencyHint)(options.latencyHint)) {\n                throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);\n            }\n            // Bug #150 Safari does not support setting the sampleRate.\n            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) {\n                throw createNotSupportedError();\n            }\n            super(nativeAudioContext, 2);\n            const { latencyHint } = options;\n            const { sampleRate } = nativeAudioContext;\n            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.\n            this._baseLatency =\n                typeof nativeAudioContext.baseLatency === 'number'\n                    ? nativeAudioContext.baseLatency\n                    : latencyHint === 'balanced'\n                        ? 512 / sampleRate\n                        : latencyHint === 'interactive' || latencyHint === undefined\n                            ? 256 / sampleRate\n                            : latencyHint === 'playback'\n                                ? 1024 / sampleRate\n                                : /*\n                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a\n                                   * ScriptProcessorNode.\n                                   */\n                                    (Math.max(2, Math.min(128, Math.round((latencyHint * sampleRate) / 128))) * 128) / sampleRate;\n            this._nativeAudioContext = nativeAudioContext;\n            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.\n            if (nativeAudioContextConstructor.name === 'webkitAudioContext') {\n                this._nativeGainNode = nativeAudioContext.createGain();\n                this._nativeOscillatorNode = nativeAudioContext.createOscillator();\n                this._nativeGainNode.gain.value = 1e-37;\n                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);\n                this._nativeOscillatorNode.start();\n            }\n            else {\n                this._nativeGainNode = null;\n                this._nativeOscillatorNode = null;\n            }\n            this._state = null;\n            /*\n             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually\n             * changes to 'running'.\n             */\n            if (nativeAudioContext.state === 'running') {\n                this._state = 'suspended';\n                const revokeState = () => {\n                    if (this._state === 'suspended') {\n                        this._state = null;\n                    }\n                    nativeAudioContext.removeEventListener('statechange', revokeState);\n                };\n                nativeAudioContext.addEventListener('statechange', revokeState);\n            }\n        }\n        get baseLatency() {\n            return this._baseLatency;\n        }\n        get state() {\n            return this._state !== null ? this._state : this._nativeAudioContext.state;\n        }\n        close() {\n            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.\n            if (this.state === 'closed') {\n                return this._nativeAudioContext.close().then(() => {\n                    throw createInvalidStateError();\n                });\n            }\n            // Bug #34: If the state was set to suspended before it should be revoked now.\n            if (this._state === 'suspended') {\n                this._state = null;\n            }\n            return this._nativeAudioContext.close().then(() => {\n                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {\n                    this._nativeOscillatorNode.stop();\n                    this._nativeGainNode.disconnect();\n                    this._nativeOscillatorNode.disconnect();\n                }\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        resume() {\n            if (this._state === 'suspended') {\n                return new Promise((resolve, reject) => {\n                    const resolvePromise = () => {\n                        this._nativeAudioContext.removeEventListener('statechange', resolvePromise);\n                        if (this._nativeAudioContext.state === 'running') {\n                            resolve();\n                        }\n                        else {\n                            this.resume().then(resolve, reject);\n                        }\n                    };\n                    this._nativeAudioContext.addEventListener('statechange', resolvePromise);\n                });\n            }\n            return this._nativeAudioContext.resume().catch((err) => {\n                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined || err.code === 15) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n        suspend() {\n            return this._nativeAudioContext.suspend().catch((err) => {\n                // Bug #56: Safari invokes the catch handler but without an error.\n                if (err === undefined) {\n                    throw createInvalidStateError();\n                }\n                throw err;\n            });\n        }\n    };\n};\n//# sourceMappingURL=minimal-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMinimalBaseAudioContextConstructor\": () => (/* binding */ createMinimalBaseAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst createMinimalBaseAudioContextConstructor = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener) => {\n    return class MinimalBaseAudioContext extends eventTargetConstructor {\n        constructor(_nativeContext, numberOfChannels) {\n            super(_nativeContext);\n            this._nativeContext = _nativeContext;\n            _globals__WEBPACK_IMPORTED_MODULE_0__.CONTEXT_STORE.set(this, _nativeContext);\n            if (isNativeOfflineAudioContext(_nativeContext)) {\n                unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());\n            }\n            this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);\n            this._listener = createAudioListener(this, _nativeContext);\n            this._onstatechange = null;\n        }\n        get currentTime() {\n            return this._nativeContext.currentTime;\n        }\n        get destination() {\n            return this._destination;\n        }\n        get listener() {\n            return this._listener;\n        }\n        get onstatechange() {\n            return this._onstatechange;\n        }\n        set onstatechange(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeContext.onstatechange = wrappedListener;\n            const nativeOnStateChange = this._nativeContext.onstatechange;\n            this._onstatechange = nativeOnStateChange !== null && nativeOnStateChange === wrappedListener ? value : nativeOnStateChange;\n        }\n        get sampleRate() {\n            return this._nativeContext.sampleRate;\n        }\n        get state() {\n            return this._nativeContext.state;\n        }\n    };\n};\n//# sourceMappingURL=minimal-base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMinimalOfflineAudioContextConstructor\": () => (/* binding */ createMinimalOfflineAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nconst createMinimalOfflineAudioContextConstructor = (cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering) => {\n    return class MinimalOfflineAudioContext extends minimalBaseAudioContextConstructor {\n        constructor(options) {\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);\n            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.\n            if (!cacheTestResult(_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport, () => (0,_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport)(nativeOfflineAudioContext))) {\n                nativeOfflineAudioContext.addEventListener('statechange', (() => {\n                    let i = 0;\n                    const delayStateChangeEvent = (event) => {\n                        if (this._state === 'running') {\n                            if (i > 0) {\n                                nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);\n                                event.stopImmediatePropagation();\n                                this._waitForThePromiseToSettle(event);\n                            }\n                            else {\n                                i += 1;\n                            }\n                        }\n                    };\n                    return delayStateChangeEvent;\n                })());\n            }\n            super(nativeOfflineAudioContext, numberOfChannels);\n            this._length = length;\n            this._nativeOfflineAudioContext = nativeOfflineAudioContext;\n            this._state = null;\n        }\n        get length() {\n            // Bug #17: Safari does not yet expose the length.\n            if (this._nativeOfflineAudioContext.length === undefined) {\n                return this._length;\n            }\n            return this._nativeOfflineAudioContext.length;\n        }\n        get state() {\n            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;\n        }\n        startRendering() {\n            /*\n             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore\n             * the state of the nativeOfflineAudioContext might no transition to running immediately.\n             */\n            if (this._state === 'running') {\n                return Promise.reject(createInvalidStateError());\n            }\n            this._state = 'running';\n            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(() => {\n                this._state = null;\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        _waitForThePromiseToSettle(event) {\n            if (this._state === null) {\n                this._nativeOfflineAudioContext.dispatchEvent(event);\n            }\n            else {\n                setTimeout(() => this._waitForThePromiseToSettle(event));\n            }\n        }\n    };\n};\n//# sourceMappingURL=minimal-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createMonitorConnections\": () => (/* binding */ createMonitorConnections)\n/* harmony export */ });\nconst createMonitorConnections = (insertElementInSet, isNativeAudioNode) => {\n    return (nativeAudioNode, whenConnected, whenDisconnected) => {\n        const connections = new Set();\n        nativeAudioNode.connect = ((connect) => {\n            // tslint:disable-next-line:invalid-void no-inferrable-types\n            return (destination, output = 0, input = 0) => {\n                const wasDisconnected = connections.size === 0;\n                if (isNativeAudioNode(destination)) {\n                    // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n                    connect.call(nativeAudioNode, destination, output, input);\n                    insertElementInSet(connections, [destination, output, input], (connection) => connection[0] === destination && connection[1] === output && connection[2] === input, true);\n                    if (wasDisconnected) {\n                        whenConnected();\n                    }\n                    return destination;\n                }\n                connect.call(nativeAudioNode, destination, output);\n                insertElementInSet(connections, [destination, output], (connection) => connection[0] === destination && connection[1] === output, true);\n                if (wasDisconnected) {\n                    whenConnected();\n                }\n                return;\n            };\n        })(nativeAudioNode.connect);\n        nativeAudioNode.disconnect = ((disconnect) => {\n            return (destinationOrOutput, output, input) => {\n                const wasConnected = connections.size > 0;\n                if (destinationOrOutput === undefined) {\n                    disconnect.apply(nativeAudioNode);\n                    connections.clear();\n                }\n                else if (typeof destinationOrOutput === 'number') {\n                    // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.\n                    disconnect.call(nativeAudioNode, destinationOrOutput);\n                    for (const connection of connections) {\n                        if (connection[1] === destinationOrOutput) {\n                            connections.delete(connection);\n                        }\n                    }\n                }\n                else {\n                    if (isNativeAudioNode(destinationOrOutput)) {\n                        // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n                        disconnect.call(nativeAudioNode, destinationOrOutput, output, input);\n                    }\n                    else {\n                        // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.\n                        disconnect.call(nativeAudioNode, destinationOrOutput, output);\n                    }\n                    for (const connection of connections) {\n                        if (connection[0] === destinationOrOutput &&\n                            (output === undefined || connection[1] === output) &&\n                            (input === undefined || connection[2] === input)) {\n                            connections.delete(connection);\n                        }\n                    }\n                }\n                const isDisconnected = connections.size === 0;\n                if (wasConnected && isDisconnected) {\n                    whenDisconnected();\n                }\n            };\n        })(nativeAudioNode.disconnect);\n        return nativeAudioNode;\n    };\n};\n//# sourceMappingURL=monitor-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAnalyserNodeFactory\": () => (/* binding */ createNativeAnalyserNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_test_analyser_node_get_float_time_domain_data_method_support__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/test-analyser-node-get-float-time-domain-data-method-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js\");\n/* harmony import */ var _helpers_wrap_analyser_node_get_float_time_domain_data_method__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-analyser-node-get-float-time-domain-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js\");\n\n\n\n\nconst createNativeAnalyserNodeFactory = (cacheTestResult, createIndexSizeError) => {\n    return (nativeContext, options) => {\n        const nativeAnalyserNode = nativeContext.createAnalyser();\n        // Bug #37: Firefox does not create an AnalyserNode with the default properties.\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeAnalyserNode, options);\n        // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.\n        if (!(options.maxDecibels > options.minDecibels)) {\n            throw createIndexSizeError();\n        }\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'fftSize');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'maxDecibels');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'minDecibels');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAnalyserNode, options, 'smoothingTimeConstant');\n        // Bug #36: Safari does not support getFloatTimeDomainData() yet.\n        if (!cacheTestResult(_helpers_test_analyser_node_get_float_time_domain_data_method_support__WEBPACK_IMPORTED_MODULE_2__.testAnalyserNodeGetFloatTimeDomainDataMethodSupport, () => (0,_helpers_test_analyser_node_get_float_time_domain_data_method_support__WEBPACK_IMPORTED_MODULE_2__.testAnalyserNodeGetFloatTimeDomainDataMethodSupport)(nativeAnalyserNode))) {\n            (0,_helpers_wrap_analyser_node_get_float_time_domain_data_method__WEBPACK_IMPORTED_MODULE_3__.wrapAnalyserNodeGetFloatTimeDomainDataMethod)(nativeAnalyserNode);\n        }\n        return nativeAnalyserNode;\n    };\n};\n//# sourceMappingURL=native-analyser-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioBufferConstructor\": () => (/* binding */ createNativeAudioBufferConstructor)\n/* harmony export */ });\nconst createNativeAudioBufferConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('AudioBuffer')) {\n        return window.AudioBuffer;\n    }\n    return null;\n};\n//# sourceMappingURL=native-audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioBufferSourceNodeFactory\": () => (/* binding */ createNativeAudioBufferSourceNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_source_node_start_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js\");\n\n\n\n\n\n\nconst createNativeAudioBufferSourceNodeFactory = (addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {\n    return (nativeContext, options) => {\n        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativeAudioBufferSourceNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeAudioBufferSourceNode, options, 'playbackRate');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'buffer');\n        // Bug #149: Safari does not yet support the detune AudioParam.\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'loop');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'loopEnd');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeAudioBufferSourceNode, options, 'loopStart');\n        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, () => testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_buffer_source_node_start_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_3__.wrapAudioBufferSourceNodeStartMethodConsecutiveCalls)(nativeAudioBufferSourceNode);\n        }\n        // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.\n        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, () => testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);\n        }\n        // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.\n        if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, () => testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext))) {\n            wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #44: Safari does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeAudioBufferSourceNode);\n        }\n        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_5__.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeAudioBufferSourceNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.\n        addSilentConnection(nativeContext, nativeAudioBufferSourceNode);\n        return nativeAudioBufferSourceNode;\n    };\n};\n//# sourceMappingURL=native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioContextConstructor\": () => (/* binding */ createNativeAudioContextConstructor)\n/* harmony export */ });\nconst createNativeAudioContextConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('AudioContext')) {\n        return window.AudioContext;\n    }\n    return window.hasOwnProperty('webkitAudioContext') ? window.webkitAudioContext : null;\n};\n//# sourceMappingURL=native-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioDestinationNodeFactory\": () => (/* binding */ createNativeAudioDestinationNodeFactory)\n/* harmony export */ });\nconst createNativeAudioDestinationNodeFactory = (createNativeGainNode, overwriteAccessors) => {\n    return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext) => {\n        const nativeAudioDestinationNode = nativeContext.destination;\n        // Bug #132: Safari does not have the correct channelCount.\n        if (nativeAudioDestinationNode.channelCount !== channelCount) {\n            try {\n                nativeAudioDestinationNode.channelCount = channelCount;\n            }\n            catch {\n                // Bug #169: Safari throws an error on each attempt to change the channelCount.\n            }\n        }\n        // Bug #83: Safari does not have the correct channelCountMode.\n        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== 'explicit') {\n            nativeAudioDestinationNode.channelCountMode = 'explicit';\n        }\n        // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.\n        if (nativeAudioDestinationNode.maxChannelCount === 0) {\n            Object.defineProperty(nativeAudioDestinationNode, 'maxChannelCount', {\n                value: channelCount\n            });\n        }\n        // Bug #168: No browser does yet have an AudioDestinationNode with an output.\n        const gainNode = createNativeGainNode(nativeContext, {\n            channelCount,\n            channelCountMode: nativeAudioDestinationNode.channelCountMode,\n            channelInterpretation: nativeAudioDestinationNode.channelInterpretation,\n            gain: 1\n        });\n        overwriteAccessors(gainNode, 'channelCount', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            try {\n                nativeAudioDestinationNode.channelCount = value;\n            }\n            catch (err) {\n                // Bug #169: Safari throws an error on each attempt to change the channelCount.\n                if (value > nativeAudioDestinationNode.maxChannelCount) {\n                    throw err;\n                }\n            }\n        });\n        overwriteAccessors(gainNode, 'channelCountMode', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            nativeAudioDestinationNode.channelCountMode = value;\n        });\n        overwriteAccessors(gainNode, 'channelInterpretation', (get) => () => get.call(gainNode), (set) => (value) => {\n            set.call(gainNode, value);\n            nativeAudioDestinationNode.channelInterpretation = value;\n        });\n        Object.defineProperty(gainNode, 'maxChannelCount', {\n            get: () => nativeAudioDestinationNode.maxChannelCount\n        });\n        // @todo This should be disconnected when the context is closed.\n        gainNode.connect(nativeAudioDestinationNode);\n        return gainNode;\n    };\n};\n//# sourceMappingURL=native-audio-destination-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioWorkletNodeConstructor\": () => (/* binding */ createNativeAudioWorkletNodeConstructor)\n/* harmony export */ });\nconst createNativeAudioWorkletNodeConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    return window.hasOwnProperty('AudioWorkletNode') ? window.AudioWorkletNode : null;\n};\n//# sourceMappingURL=native-audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioWorkletNodeFactory\": () => (/* binding */ createNativeAudioWorkletNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_test_clonability_of_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/test-clonability-of-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js\");\n\nconst createNativeAudioWorkletNodeFactory = (createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections) => {\n    return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options) => {\n        if (nativeAudioWorkletNodeConstructor !== null) {\n            try {\n                const nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeContext, name, options);\n                const patchedEventListeners = new Map();\n                let onprocessorerror = null;\n                Object.defineProperties(nativeAudioWorkletNode, {\n                    /*\n                     * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some\n                     * browsers have no native implementation to achieve a consistent behavior.\n                     */\n                    channelCount: {\n                        get: () => options.channelCount,\n                        set: () => {\n                            throw createInvalidStateError();\n                        }\n                    },\n                    channelCountMode: {\n                        get: () => 'explicit',\n                        set: () => {\n                            throw createInvalidStateError();\n                        }\n                    },\n                    // Bug #156: Chrome and Edge do not yet fire an ErrorEvent.\n                    onprocessorerror: {\n                        get: () => onprocessorerror,\n                        set: (value) => {\n                            if (typeof onprocessorerror === 'function') {\n                                nativeAudioWorkletNode.removeEventListener('processorerror', onprocessorerror);\n                            }\n                            onprocessorerror = typeof value === 'function' ? value : null;\n                            if (typeof onprocessorerror === 'function') {\n                                nativeAudioWorkletNode.addEventListener('processorerror', onprocessorerror);\n                            }\n                        }\n                    }\n                });\n                nativeAudioWorkletNode.addEventListener = ((addEventListener) => {\n                    return (...args) => {\n                        if (args[0] === 'processorerror') {\n                            const unpatchedEventListener = typeof args[1] === 'function'\n                                ? args[1]\n                                : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function'\n                                    ? args[1].handleEvent\n                                    : null;\n                            if (unpatchedEventListener !== null) {\n                                const patchedEventListener = patchedEventListeners.get(args[1]);\n                                if (patchedEventListener !== undefined) {\n                                    args[1] = patchedEventListener;\n                                }\n                                else {\n                                    args[1] = (event) => {\n                                        // Bug #178: Chrome, Edge and Opera do fire an event of type error.\n                                        if (event.type === 'error') {\n                                            Object.defineProperties(event, {\n                                                type: { value: 'processorerror' }\n                                            });\n                                            unpatchedEventListener(event);\n                                        }\n                                        else {\n                                            unpatchedEventListener(new ErrorEvent(args[0], { ...event }));\n                                        }\n                                    };\n                                    patchedEventListeners.set(unpatchedEventListener, args[1]);\n                                }\n                            }\n                        }\n                        // Bug #178: Chrome, Edge and Opera do fire an event of type error.\n                        addEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);\n                        return addEventListener.call(nativeAudioWorkletNode, ...args);\n                    };\n                })(nativeAudioWorkletNode.addEventListener);\n                nativeAudioWorkletNode.removeEventListener = ((removeEventListener) => {\n                    return (...args) => {\n                        if (args[0] === 'processorerror') {\n                            const patchedEventListener = patchedEventListeners.get(args[1]);\n                            if (patchedEventListener !== undefined) {\n                                patchedEventListeners.delete(args[1]);\n                                args[1] = patchedEventListener;\n                            }\n                        }\n                        // Bug #178: Chrome, Edge and Opera do fire an event of type error.\n                        removeEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);\n                        return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);\n                    };\n                })(nativeAudioWorkletNode.removeEventListener);\n                /*\n                 * Bug #86: Chrome and Edge do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but\n                 * has an output.\n                 */\n                if (options.numberOfOutputs !== 0) {\n                    const nativeGainNode = createNativeGainNode(nativeContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'discrete',\n                        gain: 0\n                    });\n                    nativeAudioWorkletNode.connect(nativeGainNode).connect(nativeContext.destination);\n                    const whenConnected = () => nativeGainNode.disconnect();\n                    const whenDisconnected = () => nativeGainNode.connect(nativeContext.destination);\n                    // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.\n                    return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);\n                }\n                return nativeAudioWorkletNode;\n            }\n            catch (err) {\n                // Bug #60: Chrome, Edge & Opera throw an InvalidStateError instead of a NotSupportedError.\n                if (err.code === 11) {\n                    throw createNotSupportedError();\n                }\n                throw err;\n            }\n        }\n        // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.\n        if (processorConstructor === undefined) {\n            throw createNotSupportedError();\n        }\n        (0,_helpers_test_clonability_of_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__.testClonabilityOfAudioWorkletNodeOptions)(options);\n        return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);\n    };\n};\n//# sourceMappingURL=native-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeAudioWorkletNodeFakerFactory\": () => (/* binding */ createNativeAudioWorkletNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n/* harmony import */ var _helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/compute-buffer-size */ \"./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js\");\n/* harmony import */ var _helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/copy-from-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js\");\n/* harmony import */ var _helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/copy-to-channel */ \"./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js\");\n/* harmony import */ var _helpers_create_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/create-audio-worklet-processor */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js\");\n/* harmony import */ var _helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../helpers/create-nested-arrays */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js\");\n/* harmony import */ var _read_only_map__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../read-only-map */ \"./node_modules/standardized-audio-context/build/es2019/read-only-map.js\");\n\n\n\n\n\n\n\nconst createNativeAudioWorkletNodeFakerFactory = (connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections) => {\n    return (nativeContext, baseLatency, processorConstructor, options) => {\n        if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) {\n            throw createNotSupportedError();\n        }\n        const outputChannelCount = Array.isArray(options.outputChannelCount)\n            ? options.outputChannelCount\n            : Array.from(options.outputChannelCount);\n        // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.\n        if (outputChannelCount.some((channelCount) => channelCount < 1)) {\n            throw createNotSupportedError();\n        }\n        if (outputChannelCount.length !== options.numberOfOutputs) {\n            throw createIndexSizeError();\n        }\n        // Bug #61: This is not part of the standard but required for the faker to work.\n        if (options.channelCountMode !== 'explicit') {\n            throw createNotSupportedError();\n        }\n        const numberOfInputChannels = options.channelCount * options.numberOfInputs;\n        const numberOfOutputChannels = outputChannelCount.reduce((sum, value) => sum + value, 0);\n        const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;\n        // Bug #61: This is not part of the standard but required for the faker to work.\n        if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) {\n            throw createNotSupportedError();\n        }\n        const messageChannel = new MessageChannel();\n        const gainNodes = [];\n        const inputChannelSplitterNodes = [];\n        for (let i = 0; i < options.numberOfInputs; i += 1) {\n            gainNodes.push(createNativeGainNode(nativeContext, {\n                channelCount: options.channelCount,\n                channelCountMode: options.channelCountMode,\n                channelInterpretation: options.channelInterpretation,\n                gain: 1\n            }));\n            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {\n                channelCount: options.channelCount,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                numberOfOutputs: options.channelCount\n            }));\n        }\n        const constantSourceNodes = [];\n        if (processorConstructor.parameterDescriptors !== undefined) {\n            for (const { defaultValue, maxValue, minValue, name } of processorConstructor.parameterDescriptors) {\n                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {\n                    channelCount: 1,\n                    channelCountMode: 'explicit',\n                    channelInterpretation: 'discrete',\n                    offset: options.parameterData[name] !== undefined\n                        ? options.parameterData[name]\n                        : defaultValue === undefined\n                            ? 0\n                            : defaultValue\n                });\n                Object.defineProperties(constantSourceNode.offset, {\n                    defaultValue: {\n                        get: () => (defaultValue === undefined ? 0 : defaultValue)\n                    },\n                    maxValue: {\n                        get: () => (maxValue === undefined ? _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT : maxValue)\n                    },\n                    minValue: {\n                        get: () => (minValue === undefined ? _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT : minValue)\n                    }\n                });\n                constantSourceNodes.push(constantSourceNode);\n            }\n        }\n        const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'speakers',\n            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)\n        });\n        const bufferSize = (0,_helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_1__.computeBufferSize)(baseLatency, nativeContext.sampleRate);\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, \n        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.\n        Math.max(1, numberOfOutputChannels));\n        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {\n            channelCount: Math.max(1, numberOfOutputChannels),\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: Math.max(1, numberOfOutputChannels)\n        });\n        const outputChannelMergerNodes = [];\n        for (let i = 0; i < options.numberOfOutputs; i += 1) {\n            outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'speakers',\n                numberOfInputs: outputChannelCount[i]\n            }));\n        }\n        for (let i = 0; i < options.numberOfInputs; i += 1) {\n            gainNodes[i].connect(inputChannelSplitterNodes[i]);\n            for (let j = 0; j < options.channelCount; j += 1) {\n                inputChannelSplitterNodes[i].connect(inputChannelMergerNode, j, i * options.channelCount + j);\n            }\n        }\n        const parameterMap = new _read_only_map__WEBPACK_IMPORTED_MODULE_6__.ReadOnlyMap(processorConstructor.parameterDescriptors === undefined\n            ? []\n            : processorConstructor.parameterDescriptors.map(({ name }, index) => {\n                const constantSourceNode = constantSourceNodes[index];\n                constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);\n                constantSourceNode.start(0);\n                return [name, constantSourceNode.offset];\n            }));\n        inputChannelMergerNode.connect(scriptProcessorNode);\n        let channelInterpretation = options.channelInterpretation;\n        let onprocessorerror = null;\n        // Bug #87: Expose at least one output to make this node connectable.\n        const outputAudioNodes = options.numberOfOutputs === 0 ? [scriptProcessorNode] : outputChannelMergerNodes;\n        const nativeAudioWorkletNodeFaker = {\n            get bufferSize() {\n                return bufferSize;\n            },\n            get channelCount() {\n                return options.channelCount;\n            },\n            set channelCount(_) {\n                // Bug #61: This is not part of the standard but required for the faker to work.\n                throw createInvalidStateError();\n            },\n            get channelCountMode() {\n                return options.channelCountMode;\n            },\n            set channelCountMode(_) {\n                // Bug #61: This is not part of the standard but required for the faker to work.\n                throw createInvalidStateError();\n            },\n            get channelInterpretation() {\n                return channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                for (const gainNode of gainNodes) {\n                    gainNode.channelInterpretation = value;\n                }\n                channelInterpretation = value;\n            },\n            get context() {\n                return scriptProcessorNode.context;\n            },\n            get inputs() {\n                return gainNodes;\n            },\n            get numberOfInputs() {\n                return options.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return options.numberOfOutputs;\n            },\n            get onprocessorerror() {\n                return onprocessorerror;\n            },\n            set onprocessorerror(value) {\n                if (typeof onprocessorerror === 'function') {\n                    nativeAudioWorkletNodeFaker.removeEventListener('processorerror', onprocessorerror);\n                }\n                onprocessorerror = typeof value === 'function' ? value : null;\n                if (typeof onprocessorerror === 'function') {\n                    nativeAudioWorkletNodeFaker.addEventListener('processorerror', onprocessorerror);\n                }\n            },\n            get parameters() {\n                return parameterMap;\n            },\n            get port() {\n                return messageChannel.port2;\n            },\n            addEventListener(...args) {\n                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);\n            },\n            connect: connectMultipleOutputs.bind(null, outputAudioNodes),\n            disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),\n            dispatchEvent(...args) {\n                return scriptProcessorNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        const patchedEventListeners = new Map();\n        messageChannel.port1.addEventListener = ((addEventListener) => {\n            return (...args) => {\n                if (args[0] === 'message') {\n                    const unpatchedEventListener = typeof args[1] === 'function'\n                        ? args[1]\n                        : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function'\n                            ? args[1].handleEvent\n                            : null;\n                    if (unpatchedEventListener !== null) {\n                        const patchedEventListener = patchedEventListeners.get(args[1]);\n                        if (patchedEventListener !== undefined) {\n                            args[1] = patchedEventListener;\n                        }\n                        else {\n                            args[1] = (event) => {\n                                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, () => unpatchedEventListener(event));\n                            };\n                            patchedEventListeners.set(unpatchedEventListener, args[1]);\n                        }\n                    }\n                }\n                return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);\n            };\n        })(messageChannel.port1.addEventListener);\n        messageChannel.port1.removeEventListener = ((removeEventListener) => {\n            return (...args) => {\n                if (args[0] === 'message') {\n                    const patchedEventListener = patchedEventListeners.get(args[1]);\n                    if (patchedEventListener !== undefined) {\n                        patchedEventListeners.delete(args[1]);\n                        args[1] = patchedEventListener;\n                    }\n                }\n                return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);\n            };\n        })(messageChannel.port1.removeEventListener);\n        let onmessage = null;\n        Object.defineProperty(messageChannel.port1, 'onmessage', {\n            get: () => onmessage,\n            set: (value) => {\n                if (typeof onmessage === 'function') {\n                    messageChannel.port1.removeEventListener('message', onmessage);\n                }\n                onmessage = typeof value === 'function' ? value : null;\n                if (typeof onmessage === 'function') {\n                    messageChannel.port1.addEventListener('message', onmessage);\n                    messageChannel.port1.start();\n                }\n            }\n        });\n        processorConstructor.prototype.port = messageChannel.port1;\n        let audioWorkletProcessor = null;\n        const audioWorkletProcessorPromise = (0,_helpers_create_audio_worklet_processor__WEBPACK_IMPORTED_MODULE_4__.createAudioWorkletProcessor)(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);\n        audioWorkletProcessorPromise.then((dWrkltPrcssr) => (audioWorkletProcessor = dWrkltPrcssr));\n        const inputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_5__.createNestedArrays)(options.numberOfInputs, options.channelCount);\n        const outputs = (0,_helpers_create_nested_arrays__WEBPACK_IMPORTED_MODULE_5__.createNestedArrays)(options.numberOfOutputs, outputChannelCount);\n        const parameters = processorConstructor.parameterDescriptors === undefined\n            ? []\n            : processorConstructor.parameterDescriptors.reduce((prmtrs, { name }) => ({ ...prmtrs, [name]: new Float32Array(128) }), {});\n        let isActive = true;\n        const disconnectOutputsGraph = () => {\n            if (options.numberOfOutputs > 0) {\n                scriptProcessorNode.disconnect(outputChannelSplitterNode);\n            }\n            for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {\n                const outputChannelMergerNode = outputChannelMergerNodes[i];\n                for (let j = 0; j < outputChannelCount[i]; j += 1) {\n                    outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                }\n                outputChannelSplitterNodeOutput += outputChannelCount[i];\n            }\n        };\n        const activeInputIndexes = new Map();\n        // tslint:disable-next-line:deprecation\n        scriptProcessorNode.onaudioprocess = ({ inputBuffer, outputBuffer }) => {\n            if (audioWorkletProcessor !== null) {\n                const activeInputs = getActiveAudioWorkletNodeInputs(nativeAudioWorkletNodeFaker);\n                for (let i = 0; i < bufferSize; i += 128) {\n                    for (let j = 0; j < options.numberOfInputs; j += 1) {\n                        for (let k = 0; k < options.channelCount; k += 1) {\n                            (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_2__.copyFromChannel)(inputBuffer, inputs[j], k, k, i);\n                        }\n                    }\n                    if (processorConstructor.parameterDescriptors !== undefined) {\n                        processorConstructor.parameterDescriptors.forEach(({ name }, index) => {\n                            (0,_helpers_copy_from_channel__WEBPACK_IMPORTED_MODULE_2__.copyFromChannel)(inputBuffer, parameters, name, numberOfInputChannels + index, i);\n                        });\n                    }\n                    for (let j = 0; j < options.numberOfInputs; j += 1) {\n                        for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                            // The byteLength will be 0 when the ArrayBuffer was transferred.\n                            if (outputs[j][k].byteLength === 0) {\n                                outputs[j][k] = new Float32Array(128);\n                            }\n                        }\n                    }\n                    try {\n                        const potentiallyEmptyInputs = inputs.map((input, index) => {\n                            const activeInput = activeInputs[index];\n                            if (activeInput.size > 0) {\n                                activeInputIndexes.set(index, bufferSize / 128);\n                                return input;\n                            }\n                            const count = activeInputIndexes.get(index);\n                            if (count === undefined) {\n                                return [];\n                            }\n                            if (input.every((channelData) => channelData.every((sample) => sample === 0))) {\n                                if (count === 1) {\n                                    activeInputIndexes.delete(index);\n                                }\n                                else {\n                                    activeInputIndexes.set(index, count - 1);\n                                }\n                            }\n                            return input;\n                        });\n                        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + i / nativeContext.sampleRate, nativeContext.sampleRate, () => audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters));\n                        isActive = activeSourceFlag;\n                        for (let j = 0, outputChannelSplitterNodeOutput = 0; j < options.numberOfOutputs; j += 1) {\n                            for (let k = 0; k < outputChannelCount[j]; k += 1) {\n                                (0,_helpers_copy_to_channel__WEBPACK_IMPORTED_MODULE_3__.copyToChannel)(outputBuffer, outputs[j], k, outputChannelSplitterNodeOutput + k, i);\n                            }\n                            outputChannelSplitterNodeOutput += outputChannelCount[j];\n                        }\n                    }\n                    catch (error) {\n                        isActive = false;\n                        nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent('processorerror', {\n                            colno: error.colno,\n                            filename: error.filename,\n                            lineno: error.lineno,\n                            message: error.message\n                        }));\n                    }\n                    if (!isActive) {\n                        for (let j = 0; j < options.numberOfInputs; j += 1) {\n                            gainNodes[j].disconnect(inputChannelSplitterNodes[j]);\n                            for (let k = 0; k < options.channelCount; k += 1) {\n                                inputChannelSplitterNodes[i].disconnect(inputChannelMergerNode, k, j * options.channelCount + k);\n                            }\n                        }\n                        if (processorConstructor.parameterDescriptors !== undefined) {\n                            const length = processorConstructor.parameterDescriptors.length;\n                            for (let j = 0; j < length; j += 1) {\n                                const constantSourceNode = constantSourceNodes[j];\n                                constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j);\n                                constantSourceNode.stop();\n                            }\n                        }\n                        inputChannelMergerNode.disconnect(scriptProcessorNode);\n                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation\n                        if (isConnected) {\n                            disconnectOutputsGraph();\n                        }\n                        else {\n                            disconnectFakeGraph();\n                        }\n                        break;\n                    }\n                }\n            }\n        };\n        let isConnected = false;\n        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.\n        const nativeGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        const connectFakeGraph = () => scriptProcessorNode.connect(nativeGainNode).connect(nativeContext.destination);\n        const disconnectFakeGraph = () => {\n            scriptProcessorNode.disconnect(nativeGainNode);\n            nativeGainNode.disconnect();\n        };\n        const whenConnected = () => {\n            if (isActive) {\n                disconnectFakeGraph();\n                if (options.numberOfOutputs > 0) {\n                    scriptProcessorNode.connect(outputChannelSplitterNode);\n                }\n                for (let i = 0, outputChannelSplitterNodeOutput = 0; i < options.numberOfOutputs; i += 1) {\n                    const outputChannelMergerNode = outputChannelMergerNodes[i];\n                    for (let j = 0; j < outputChannelCount[i]; j += 1) {\n                        outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);\n                    }\n                    outputChannelSplitterNodeOutput += outputChannelCount[i];\n                }\n            }\n            isConnected = true;\n        };\n        const whenDisconnected = () => {\n            if (isActive) {\n                connectFakeGraph();\n                disconnectOutputsGraph();\n            }\n            isConnected = false;\n        };\n        connectFakeGraph();\n        return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-audio-worklet-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeBiquadFilterNode\": () => (/* binding */ createNativeBiquadFilterNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\n\nconst createNativeBiquadFilterNode = (nativeContext, options) => {\n    const nativeBiquadFilterNode = nativeContext.createBiquadFilter();\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativeBiquadFilterNode, options);\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'Q');\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'detune');\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'frequency');\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeBiquadFilterNode, options, 'gain');\n    (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeBiquadFilterNode, options, 'type');\n    return nativeBiquadFilterNode;\n};\n//# sourceMappingURL=native-biquad-filter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeChannelMergerNodeFactory\": () => (/* binding */ createNativeChannelMergerNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\nconst createNativeChannelMergerNodeFactory = (nativeAudioContextConstructor, wrapChannelMergerNode) => {\n    return (nativeContext, options) => {\n        const nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs);\n        /*\n         * Bug #20: Safari requires a connection of any kind to treat the input signal correctly.\n         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of\n         * the webkitAudioContext is used as a workaround here.\n         */\n        if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {\n            wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeChannelMergerNode, options);\n        return nativeChannelMergerNode;\n    };\n};\n//# sourceMappingURL=native-channel-merger-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeChannelSplitterNode\": () => (/* binding */ createNativeChannelSplitterNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_channel_splitter_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/wrap-channel-splitter-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js\");\n\n\nconst createNativeChannelSplitterNode = (nativeContext, options) => {\n    const nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);\n    // Bug #96: Safari does not have the correct channelCount.\n    // Bug #29: Safari does not have the correct channelCountMode.\n    // Bug #31: Safari does not have the correct channelInterpretation.\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeChannelSplitterNode, options);\n    // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Edge, Firefox & Opera partially support the spec yet.\n    (0,_helpers_wrap_channel_splitter_node__WEBPACK_IMPORTED_MODULE_1__.wrapChannelSplitterNode)(nativeChannelSplitterNode);\n    return nativeChannelSplitterNode;\n};\n//# sourceMappingURL=native-channel-splitter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeConstantSourceNodeFactory\": () => (/* binding */ createNativeConstantSourceNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js\");\n\n\n\n\nconst createNativeConstantSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport) => {\n    return (nativeContext, options) => {\n        // Bug #62: Safari does not support ConstantSourceNodes.\n        if (nativeContext.createConstantSource === undefined) {\n            return createNativeConstantSourceNodeFaker(nativeContext, options);\n        }\n        const nativeConstantSourceNode = nativeContext.createConstantSource();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeConstantSourceNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeConstantSourceNode, options, 'offset');\n        // Bug #44: Safari does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_2__.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeConstantSourceNode);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeConstantSourceNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.\n        addSilentConnection(nativeContext, nativeConstantSourceNode);\n        return nativeConstantSourceNode;\n    };\n};\n//# sourceMappingURL=native-constant-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeConstantSourceNodeFakerFactory\": () => (/* binding */ createNativeConstantSourceNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\nconst createNativeConstantSourceNodeFakerFactory = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections) => {\n    return (nativeContext, { offset, ...audioNodeOptions }) => {\n        const audioBuffer = nativeContext.createBuffer(1, 2, 44100);\n        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {\n            buffer: null,\n            channelCount: 2,\n            channelCountMode: 'max',\n            channelInterpretation: 'speakers',\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            playbackRate: 1\n        });\n        const gainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: offset });\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        const channelData = audioBuffer.getChannelData(0);\n        // Bug #95: Safari does not play or loop one sample buffers.\n        channelData[0] = 1;\n        channelData[1] = 1;\n        audioBufferSourceNode.buffer = audioBuffer;\n        audioBufferSourceNode.loop = true;\n        const nativeConstantSourceNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return gainNode.channelCount;\n            },\n            set channelCount(value) {\n                gainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return gainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                gainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return gainNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                gainNode.channelInterpretation = value;\n            },\n            get context() {\n                return gainNode.context;\n            },\n            get inputs() {\n                return [];\n            },\n            get numberOfInputs() {\n                return audioBufferSourceNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return gainNode.numberOfOutputs;\n            },\n            get offset() {\n                return gainNode.gain;\n            },\n            get onended() {\n                return audioBufferSourceNode.onended;\n            },\n            set onended(value) {\n                audioBufferSourceNode.onended = value;\n            },\n            addEventListener(...args) {\n                return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return audioBufferSourceNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);\n            },\n            start(when = 0) {\n                audioBufferSourceNode.start.call(audioBufferSourceNode, when);\n            },\n            stop(when = 0) {\n                audioBufferSourceNode.stop.call(audioBufferSourceNode, when);\n            }\n        };\n        const whenConnected = () => audioBufferSourceNode.connect(gainNode);\n        const whenDisconnected = () => audioBufferSourceNode.disconnect(gainNode);\n        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.\n        addSilentConnection(nativeContext, audioBufferSourceNode);\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__.interceptConnections)(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-constant-source-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeConvolverNodeFactory\": () => (/* binding */ createNativeConvolverNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeConvolverNodeFactory = (createNotSupportedError, overwriteAccessors) => {\n    return (nativeContext, options) => {\n        const nativeConvolverNode = nativeContext.createConvolver();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeConvolverNode, options);\n        // The normalize property needs to be set before setting the buffer.\n        if (options.disableNormalization === nativeConvolverNode.normalize) {\n            nativeConvolverNode.normalize = !options.disableNormalization;\n        }\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeConvolverNode, options, 'buffer');\n        // Bug #113: Safari does allow to set the channelCount to a value larger than 2.\n        if (options.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        overwriteAccessors(nativeConvolverNode, 'channelCount', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {\n            if (value > 2) {\n                throw createNotSupportedError();\n            }\n            return set.call(nativeConvolverNode, value);\n        });\n        // Bug #114: Safari allows to set the channelCountMode to 'max'.\n        if (options.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        overwriteAccessors(nativeConvolverNode, 'channelCountMode', (get) => () => get.call(nativeConvolverNode), (set) => (value) => {\n            if (value === 'max') {\n                throw createNotSupportedError();\n            }\n            return set.call(nativeConvolverNode, value);\n        });\n        return nativeConvolverNode;\n    };\n};\n//# sourceMappingURL=native-convolver-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeDelayNode\": () => (/* binding */ createNativeDelayNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeDelayNode = (nativeContext, options) => {\n    const nativeDelayNode = nativeContext.createDelay(options.maxDelayTime);\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeDelayNode, options);\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDelayNode, options, 'delayTime');\n    return nativeDelayNode;\n};\n//# sourceMappingURL=native-delay-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeDynamicsCompressorNodeFactory\": () => (/* binding */ createNativeDynamicsCompressorNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeDynamicsCompressorNodeFactory = (createNotSupportedError) => {\n    return (nativeContext, options) => {\n        const nativeDynamicsCompressorNode = nativeContext.createDynamicsCompressor();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeDynamicsCompressorNode, options);\n        // Bug #108: Safari allows a channelCount of three and above.\n        if (options.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        // Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max'.\n        if (options.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'attack');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'knee');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'ratio');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'release');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeDynamicsCompressorNode, options, 'threshold');\n        return nativeDynamicsCompressorNode;\n    };\n};\n//# sourceMappingURL=native-dynamics-compressor-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeGainNode\": () => (/* binding */ createNativeGainNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeGainNode = (nativeContext, options) => {\n    const nativeGainNode = nativeContext.createGain();\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeGainNode, options);\n    (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeGainNode, options, 'gain');\n    return nativeGainNode;\n};\n//# sourceMappingURL=native-gain-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeIIRFilterNodeFactory\": () => (/* binding */ createNativeIIRFilterNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\nconst createNativeIIRFilterNodeFactory = (createNativeIIRFilterNodeFaker) => {\n    return (nativeContext, baseLatency, options) => {\n        // Bug #9: Safari does not support IIRFilterNodes.\n        if (nativeContext.createIIRFilter === undefined) {\n            return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);\n        }\n        // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.\n        const nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeIIRFilterNode, options);\n        return nativeIIRFilterNode;\n    };\n};\n//# sourceMappingURL=native-iir-filter-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeIIRFilterNodeFakerFactory\": () => (/* binding */ createNativeIIRFilterNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/compute-buffer-size */ \"./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js\");\n/* harmony import */ var _helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/filter-buffer */ \"./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js\");\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\n\n\nfunction divide(a, b) {\n    const denominator = b[0] * b[0] + b[1] * b[1];\n    return [(a[0] * b[0] + a[1] * b[1]) / denominator, (a[1] * b[0] - a[0] * b[1]) / denominator];\n}\nfunction multiply(a, b) {\n    return [a[0] * b[0] - a[1] * b[1], a[0] * b[1] + a[1] * b[0]];\n}\nfunction evaluatePolynomial(coefficient, z) {\n    let result = [0, 0];\n    for (let i = coefficient.length - 1; i >= 0; i -= 1) {\n        result = multiply(result, z);\n        result[0] += coefficient[i];\n    }\n    return result;\n}\nconst createNativeIIRFilterNodeFakerFactory = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError) => {\n    return (nativeContext, baseLatency, { channelCount, channelCountMode, channelInterpretation, feedback, feedforward }) => {\n        const bufferSize = (0,_helpers_compute_buffer_size__WEBPACK_IMPORTED_MODULE_0__.computeBufferSize)(baseLatency, nativeContext.sampleRate);\n        const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);\n        const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);\n        const feedbackLength = convertedFeedback.length;\n        const feedforwardLength = convertedFeedforward.length;\n        const minLength = Math.min(feedbackLength, feedforwardLength);\n        if (feedbackLength === 0 || feedbackLength > 20) {\n            throw createNotSupportedError();\n        }\n        if (convertedFeedback[0] === 0) {\n            throw createInvalidStateError();\n        }\n        if (feedforwardLength === 0 || feedforwardLength > 20) {\n            throw createNotSupportedError();\n        }\n        if (convertedFeedforward[0] === 0) {\n            throw createInvalidStateError();\n        }\n        if (convertedFeedback[0] !== 1) {\n            for (let i = 0; i < feedforwardLength; i += 1) {\n                convertedFeedforward[i] /= convertedFeedback[0];\n            }\n            for (let i = 1; i < feedbackLength; i += 1) {\n                convertedFeedback[i] /= convertedFeedback[0];\n            }\n        }\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);\n        scriptProcessorNode.channelCount = channelCount;\n        scriptProcessorNode.channelCountMode = channelCountMode;\n        scriptProcessorNode.channelInterpretation = channelInterpretation;\n        const bufferLength = 32;\n        const bufferIndexes = [];\n        const xBuffers = [];\n        const yBuffers = [];\n        for (let i = 0; i < channelCount; i += 1) {\n            bufferIndexes.push(0);\n            const xBuffer = new Float32Array(bufferLength);\n            const yBuffer = new Float32Array(bufferLength);\n            xBuffer.fill(0);\n            yBuffer.fill(0);\n            xBuffers.push(xBuffer);\n            yBuffers.push(yBuffer);\n        }\n        // tslint:disable-next-line:deprecation\n        scriptProcessorNode.onaudioprocess = (event) => {\n            const inputBuffer = event.inputBuffer;\n            const outputBuffer = event.outputBuffer;\n            const numberOfChannels = inputBuffer.numberOfChannels;\n            for (let i = 0; i < numberOfChannels; i += 1) {\n                const input = inputBuffer.getChannelData(i);\n                const output = outputBuffer.getChannelData(i);\n                bufferIndexes[i] = (0,_helpers_filter_buffer__WEBPACK_IMPORTED_MODULE_1__.filterBuffer)(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffers[i], yBuffers[i], bufferIndexes[i], bufferLength, input, output);\n            }\n        };\n        const nyquist = nativeContext.sampleRate / 2;\n        const nativeIIRFilterNodeFaker = {\n            get bufferSize() {\n                return bufferSize;\n            },\n            get channelCount() {\n                return scriptProcessorNode.channelCount;\n            },\n            set channelCount(value) {\n                scriptProcessorNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return scriptProcessorNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                scriptProcessorNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return scriptProcessorNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                scriptProcessorNode.channelInterpretation = value;\n            },\n            get context() {\n                return scriptProcessorNode.context;\n            },\n            get inputs() {\n                return [scriptProcessorNode];\n            },\n            get numberOfInputs() {\n                return scriptProcessorNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return scriptProcessorNode.numberOfOutputs;\n            },\n            addEventListener(...args) {\n                // @todo Dissallow adding an audioprocess listener.\n                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return scriptProcessorNode.dispatchEvent(args[0]);\n            },\n            getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {\n                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {\n                    throw createInvalidAccessError();\n                }\n                const length = frequencyHz.length;\n                for (let i = 0; i < length; i += 1) {\n                    const omega = -Math.PI * (frequencyHz[i] / nyquist);\n                    const z = [Math.cos(omega), Math.sin(omega)];\n                    const numerator = evaluatePolynomial(convertedFeedforward, z);\n                    const denominator = evaluatePolynomial(convertedFeedback, z);\n                    const response = divide(numerator, denominator);\n                    magResponse[i] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);\n                    phaseResponse[i] = Math.atan2(response[1], response[0]);\n                }\n            },\n            removeEventListener(...args) {\n                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        return (0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_2__.interceptConnections)(nativeIIRFilterNodeFaker, scriptProcessorNode);\n    };\n};\n//# sourceMappingURL=native-iir-filter-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaElementAudioSourceNode\": () => (/* binding */ createNativeMediaElementAudioSourceNode)\n/* harmony export */ });\nconst createNativeMediaElementAudioSourceNode = (nativeAudioContext, options) => {\n    return nativeAudioContext.createMediaElementSource(options.mediaElement);\n};\n//# sourceMappingURL=native-media-element-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaStreamAudioDestinationNode\": () => (/* binding */ createNativeMediaStreamAudioDestinationNode)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\nconst createNativeMediaStreamAudioDestinationNode = (nativeAudioContext, options) => {\n    const nativeMediaStreamAudioDestinationNode = nativeAudioContext.createMediaStreamDestination();\n    (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(nativeMediaStreamAudioDestinationNode, options);\n    // Bug #174: Safari does expose a wrong numberOfOutputs.\n    if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) {\n        Object.defineProperty(nativeMediaStreamAudioDestinationNode, 'numberOfOutputs', { get: () => 0 });\n    }\n    return nativeMediaStreamAudioDestinationNode;\n};\n//# sourceMappingURL=native-media-stream-audio-destination-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaStreamAudioSourceNode\": () => (/* binding */ createNativeMediaStreamAudioSourceNode)\n/* harmony export */ });\nconst createNativeMediaStreamAudioSourceNode = (nativeAudioContext, { mediaStream }) => {\n    const audioStreamTracks = mediaStream.getAudioTracks();\n    /*\n     * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.\n     * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.\n     */\n    audioStreamTracks.sort((a, b) => (a.id < b.id ? -1 : a.id > b.id ? 1 : 0));\n    const filteredAudioStreamTracks = audioStreamTracks.slice(0, 1);\n    const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));\n    /*\n     * Bug #151 & #159: The given mediaStream gets reconstructed before it gets passed to the native node which is why the accessor needs\n     * to be overwritten as it would otherwise expose the reconstructed version.\n     */\n    Object.defineProperty(nativeMediaStreamAudioSourceNode, 'mediaStream', { value: mediaStream });\n    return nativeMediaStreamAudioSourceNode;\n};\n//# sourceMappingURL=native-media-stream-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeMediaStreamTrackAudioSourceNodeFactory\": () => (/* binding */ createNativeMediaStreamTrackAudioSourceNodeFactory)\n/* harmony export */ });\nconst createNativeMediaStreamTrackAudioSourceNodeFactory = (createInvalidStateError, isNativeOfflineAudioContext) => {\n    return (nativeAudioContext, { mediaStreamTrack }) => {\n        // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.\n        if (typeof nativeAudioContext.createMediaStreamTrackSource === 'function') {\n            return nativeAudioContext.createMediaStreamTrackSource(mediaStreamTrack);\n        }\n        const mediaStream = new MediaStream([mediaStreamTrack]);\n        const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(mediaStream);\n        // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.\n        if (mediaStreamTrack.kind !== 'audio') {\n            throw createInvalidStateError();\n        }\n        // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.\n        if (isNativeOfflineAudioContext(nativeAudioContext)) {\n            throw new TypeError();\n        }\n        return nativeMediaStreamAudioSourceNode;\n    };\n};\n//# sourceMappingURL=native-media-stream-track-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeOfflineAudioContextConstructor\": () => (/* binding */ createNativeOfflineAudioContextConstructor)\n/* harmony export */ });\nconst createNativeOfflineAudioContextConstructor = (window) => {\n    if (window === null) {\n        return null;\n    }\n    if (window.hasOwnProperty('OfflineAudioContext')) {\n        return window.OfflineAudioContext;\n    }\n    return window.hasOwnProperty('webkitOfflineAudioContext') ? window.webkitOfflineAudioContext : null;\n};\n//# sourceMappingURL=native-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeOscillatorNodeFactory\": () => (/* binding */ createNativeOscillatorNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js\");\n\n\n\n\n\nconst createNativeOscillatorNodeFactory = (addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls) => {\n    return (nativeContext, options) => {\n        const nativeOscillatorNode = nativeContext.createOscillator();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativeOscillatorNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeOscillatorNode, options, 'detune');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeOscillatorNode, options, 'frequency');\n        if (options.periodicWave !== undefined) {\n            nativeOscillatorNode.setPeriodicWave(options.periodicWave);\n        }\n        else {\n            (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativeOscillatorNode, options, 'type');\n        }\n        // Bug #44: Only Chrome, Edge & Opera throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_start_method_negative_parameters__WEBPACK_IMPORTED_MODULE_3__.wrapAudioScheduledSourceNodeStartMethodNegativeParameters)(nativeOscillatorNode);\n        }\n        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, () => testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext))) {\n            wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);\n        }\n        // Bug #44: Only Firefox does not throw a RangeError yet.\n        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, () => testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext))) {\n            (0,_helpers_wrap_audio_scheduled_source_node_stop_method_negative_parameters__WEBPACK_IMPORTED_MODULE_4__.wrapAudioScheduledSourceNodeStopMethodNegativeParameters)(nativeOscillatorNode);\n        }\n        // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.\n        addSilentConnection(nativeContext, nativeOscillatorNode);\n        return nativeOscillatorNode;\n    };\n};\n//# sourceMappingURL=native-oscillator-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativePannerNodeFactory\": () => (/* binding */ createNativePannerNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\n\nconst createNativePannerNodeFactory = (createNativePannerNodeFaker) => {\n    return (nativeContext, options) => {\n        const nativePannerNode = nativeContext.createPanner();\n        // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.\n        if (nativePannerNode.orientationX === undefined) {\n            return createNativePannerNodeFaker(nativeContext, options);\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_2__.assignNativeAudioNodeOptions)(nativePannerNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'orientationX');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'orientationY');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'orientationZ');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'positionX');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'positionY');\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativePannerNode, options, 'positionZ');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'coneInnerAngle');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'coneOuterAngle');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'coneOuterGain');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'distanceModel');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'maxDistance');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'panningModel');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'refDistance');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOption)(nativePannerNode, options, 'rolloffFactor');\n        return nativePannerNode;\n    };\n};\n//# sourceMappingURL=native-panner-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativePannerNodeFakerFactory\": () => (/* binding */ createNativePannerNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\n\nconst createNativePannerNodeFakerFactory = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, getFirstSample, monitorConnections) => {\n    return (nativeContext, { coneInnerAngle, coneOuterAngle, coneOuterGain, distanceModel, maxDistance, orientationX, orientationY, orientationZ, panningModel, positionX, positionY, positionZ, refDistance, rolloffFactor, ...audioNodeOptions }) => {\n        const pannerNode = nativeContext.createPanner();\n        // Bug #125: Safari does not throw an error yet.\n        if (audioNodeOptions.channelCount > 2) {\n            throw createNotSupportedError();\n        }\n        // Bug #126: Safari does not throw an error yet.\n        if (audioNodeOptions.channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(pannerNode, audioNodeOptions);\n        const SINGLE_CHANNEL_OPTIONS = {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete'\n        };\n        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            ...SINGLE_CHANNEL_OPTIONS,\n            channelInterpretation: 'speakers',\n            numberOfInputs: 6\n        });\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const orientationXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 1 });\n        const orientationYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const orientationZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionXGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionYGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const positionZGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);\n        const waveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_OPTIONS,\n            curve: new Float32Array([1, 1]),\n            oversample: 'none'\n        });\n        let lastOrientation = [orientationX, orientationY, orientationZ];\n        let lastPosition = [positionX, positionY, positionZ];\n        const buffer = new Float32Array(1);\n        // tslint:disable-next-line:deprecation\n        scriptProcessorNode.onaudioprocess = ({ inputBuffer }) => {\n            const orientation = [\n                getFirstSample(inputBuffer, buffer, 0),\n                getFirstSample(inputBuffer, buffer, 1),\n                getFirstSample(inputBuffer, buffer, 2)\n            ];\n            if (orientation.some((value, index) => value !== lastOrientation[index])) {\n                pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation\n                lastOrientation = orientation;\n            }\n            const positon = [\n                getFirstSample(inputBuffer, buffer, 3),\n                getFirstSample(inputBuffer, buffer, 4),\n                getFirstSample(inputBuffer, buffer, 5)\n            ];\n            if (positon.some((value, index) => value !== lastPosition[index])) {\n                pannerNode.setPosition(...positon); // tslint:disable-line:deprecation\n                lastPosition = positon;\n            }\n        };\n        Object.defineProperty(orientationYGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(orientationZGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionXGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionYGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(positionZGainNode.gain, 'defaultValue', { get: () => 0 });\n        const nativePannerNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return pannerNode.channelCount;\n            },\n            set channelCount(value) {\n                // Bug #125: Safari does not throw an error yet.\n                if (value > 2) {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCount = value;\n                pannerNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return pannerNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                // Bug #126: Safari does not throw an error yet.\n                if (value === 'max') {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCountMode = value;\n                pannerNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return pannerNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n                pannerNode.channelInterpretation = value;\n            },\n            get coneInnerAngle() {\n                return pannerNode.coneInnerAngle;\n            },\n            set coneInnerAngle(value) {\n                pannerNode.coneInnerAngle = value;\n            },\n            get coneOuterAngle() {\n                return pannerNode.coneOuterAngle;\n            },\n            set coneOuterAngle(value) {\n                pannerNode.coneOuterAngle = value;\n            },\n            get coneOuterGain() {\n                return pannerNode.coneOuterGain;\n            },\n            set coneOuterGain(value) {\n                // Bug #127: Safari does not throw an InvalidStateError yet.\n                if (value < 0 || value > 1) {\n                    throw createInvalidStateError();\n                }\n                pannerNode.coneOuterGain = value;\n            },\n            get context() {\n                return pannerNode.context;\n            },\n            get distanceModel() {\n                return pannerNode.distanceModel;\n            },\n            set distanceModel(value) {\n                pannerNode.distanceModel = value;\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get maxDistance() {\n                return pannerNode.maxDistance;\n            },\n            set maxDistance(value) {\n                // Bug #128: Safari does not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.maxDistance = value;\n            },\n            get numberOfInputs() {\n                return pannerNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return pannerNode.numberOfOutputs;\n            },\n            get orientationX() {\n                return orientationXGainNode.gain;\n            },\n            get orientationY() {\n                return orientationYGainNode.gain;\n            },\n            get orientationZ() {\n                return orientationZGainNode.gain;\n            },\n            get panningModel() {\n                return pannerNode.panningModel;\n            },\n            set panningModel(value) {\n                pannerNode.panningModel = value;\n            },\n            get positionX() {\n                return positionXGainNode.gain;\n            },\n            get positionY() {\n                return positionYGainNode.gain;\n            },\n            get positionZ() {\n                return positionZGainNode.gain;\n            },\n            get refDistance() {\n                return pannerNode.refDistance;\n            },\n            set refDistance(value) {\n                // Bug #129: Safari does not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.refDistance = value;\n            },\n            get rolloffFactor() {\n                return pannerNode.rolloffFactor;\n            },\n            set rolloffFactor(value) {\n                // Bug #130: Safari does not throw an error yet.\n                if (value < 0) {\n                    throw new RangeError();\n                }\n                pannerNode.rolloffFactor = value;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) {\n            nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;\n        }\n        if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) {\n            nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;\n        }\n        if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) {\n            nativePannerNodeFaker.coneOuterGain = coneOuterGain;\n        }\n        if (distanceModel !== nativePannerNodeFaker.distanceModel) {\n            nativePannerNodeFaker.distanceModel = distanceModel;\n        }\n        if (maxDistance !== nativePannerNodeFaker.maxDistance) {\n            nativePannerNodeFaker.maxDistance = maxDistance;\n        }\n        if (orientationX !== nativePannerNodeFaker.orientationX.value) {\n            nativePannerNodeFaker.orientationX.value = orientationX;\n        }\n        if (orientationY !== nativePannerNodeFaker.orientationY.value) {\n            nativePannerNodeFaker.orientationY.value = orientationY;\n        }\n        if (orientationZ !== nativePannerNodeFaker.orientationZ.value) {\n            nativePannerNodeFaker.orientationZ.value = orientationZ;\n        }\n        if (panningModel !== nativePannerNodeFaker.panningModel) {\n            nativePannerNodeFaker.panningModel = panningModel;\n        }\n        if (positionX !== nativePannerNodeFaker.positionX.value) {\n            nativePannerNodeFaker.positionX.value = positionX;\n        }\n        if (positionY !== nativePannerNodeFaker.positionY.value) {\n            nativePannerNodeFaker.positionY.value = positionY;\n        }\n        if (positionZ !== nativePannerNodeFaker.positionZ.value) {\n            nativePannerNodeFaker.positionZ.value = positionZ;\n        }\n        if (refDistance !== nativePannerNodeFaker.refDistance) {\n            nativePannerNodeFaker.refDistance = refDistance;\n        }\n        if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) {\n            nativePannerNodeFaker.rolloffFactor = rolloffFactor;\n        }\n        if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) {\n            pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation\n        }\n        if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) {\n            pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation\n        }\n        const whenConnected = () => {\n            inputGainNode.connect(pannerNode);\n            // Bug #119: Safari does not fully support the WaveShaperNode.\n            connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);\n            waveShaperNode.connect(orientationXGainNode).connect(channelMergerNode, 0, 0);\n            waveShaperNode.connect(orientationYGainNode).connect(channelMergerNode, 0, 1);\n            waveShaperNode.connect(orientationZGainNode).connect(channelMergerNode, 0, 2);\n            waveShaperNode.connect(positionXGainNode).connect(channelMergerNode, 0, 3);\n            waveShaperNode.connect(positionYGainNode).connect(channelMergerNode, 0, 4);\n            waveShaperNode.connect(positionZGainNode).connect(channelMergerNode, 0, 5);\n            channelMergerNode.connect(scriptProcessorNode).connect(nativeContext.destination);\n        };\n        const whenDisconnected = () => {\n            inputGainNode.disconnect(pannerNode);\n            // Bug #119: Safari does not fully support the WaveShaperNode.\n            disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);\n            waveShaperNode.disconnect(orientationXGainNode);\n            orientationXGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(orientationYGainNode);\n            orientationYGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(orientationZGainNode);\n            orientationZGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionXGainNode);\n            positionXGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionYGainNode);\n            positionYGainNode.disconnect(channelMergerNode);\n            waveShaperNode.disconnect(positionZGainNode);\n            positionZGainNode.disconnect(channelMergerNode);\n            channelMergerNode.disconnect(scriptProcessorNode);\n            scriptProcessorNode.disconnect(nativeContext.destination);\n        };\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__.interceptConnections)(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativePeriodicWaveFactory\": () => (/* binding */ createNativePeriodicWaveFactory)\n/* harmony export */ });\nconst createNativePeriodicWaveFactory = (createIndexSizeError) => {\n    return (nativeContext, { disableNormalization, imag, real }) => {\n        // Bug #180: Safari does not allow to use ordinary arrays.\n        const convertedImag = imag instanceof Float32Array ? imag : new Float32Array(imag);\n        const convertedReal = real instanceof Float32Array ? real : new Float32Array(real);\n        const nativePeriodicWave = nativeContext.createPeriodicWave(convertedReal, convertedImag, { disableNormalization });\n        // Bug #181: Safari does not throw an IndexSizeError so far if the given arrays have less than two values.\n        if (Array.from(imag).length < 2) {\n            throw createIndexSizeError();\n        }\n        return nativePeriodicWave;\n    };\n};\n//# sourceMappingURL=native-periodic-wave-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeScriptProcessorNode\": () => (/* binding */ createNativeScriptProcessorNode)\n/* harmony export */ });\nconst createNativeScriptProcessorNode = (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels) => {\n    return nativeContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels); // tslint:disable-line deprecation\n};\n//# sourceMappingURL=native-script-processor-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeStereoPannerNodeFactory\": () => (/* binding */ createNativeStereoPannerNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-audio-param-value */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeStereoPannerNodeFactory = (createNativeStereoPannerNodeFaker, createNotSupportedError) => {\n    return (nativeContext, options) => {\n        const channelCountMode = options.channelCountMode;\n        /*\n         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari\n         * which supports it and therefore it can't be supported at all.\n         */\n        if (channelCountMode === 'clamped-max') {\n            throw createNotSupportedError();\n        }\n        // Bug #105: Safari does not support the StereoPannerNode.\n        if (nativeContext.createStereoPanner === undefined) {\n            return createNativeStereoPannerNodeFaker(nativeContext, options);\n        }\n        const nativeStereoPannerNode = nativeContext.createStereoPanner();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeStereoPannerNode, options);\n        (0,_helpers_assign_native_audio_node_audio_param_value__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeAudioParamValue)(nativeStereoPannerNode, options, 'pan');\n        /*\n         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari\n         * which supports it and therefore it can't be supported at all.\n         */\n        Object.defineProperty(nativeStereoPannerNode, 'channelCountMode', {\n            get: () => channelCountMode,\n            set: (value) => {\n                if (value !== channelCountMode) {\n                    throw createNotSupportedError();\n                }\n            }\n        });\n        return nativeStereoPannerNode;\n    };\n};\n//# sourceMappingURL=native-stereo-panner-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeStereoPannerNodeFakerFactory\": () => (/* binding */ createNativeStereoPannerNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\nconst createNativeStereoPannerNodeFakerFactory = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections) => {\n    // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.\n    const CURVE_SIZE = 16385;\n    const DC_CURVE = new Float32Array([1, 1]);\n    const HALF_PI = Math.PI / 2;\n    const SINGLE_CHANNEL_OPTIONS = { channelCount: 1, channelCountMode: 'explicit', channelInterpretation: 'discrete' };\n    const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = { ...SINGLE_CHANNEL_OPTIONS, oversample: 'none' };\n    const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {\n        const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        for (let i = 0; i < CURVE_SIZE; i += 1) {\n            const x = (i / (CURVE_SIZE - 1)) * HALF_PI;\n            leftWaveShaperCurve[i] = Math.cos(x);\n            rightWaveShaperCurve[i] = Math.sin(x);\n        }\n        const leftGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: leftWaveShaperCurve }));\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const panWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE }));\n        const rightGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: rightWaveShaperCurve }));\n        return {\n            connectGraph() {\n                inputGainNode.connect(leftGainNode);\n                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                inputGainNode.connect(rightGainNode);\n                panWaveShaperNode.connect(panGainNode);\n                panGainNode.connect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);\n                leftWaveShaperNode.connect(leftGainNode.gain);\n                rightWaveShaperNode.connect(rightGainNode.gain);\n                leftGainNode.connect(channelMergerNode, 0, 0);\n                rightGainNode.connect(channelMergerNode, 0, 1);\n            },\n            disconnectGraph() {\n                inputGainNode.disconnect(leftGainNode);\n                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                inputGainNode.disconnect(rightGainNode);\n                panWaveShaperNode.disconnect(panGainNode);\n                panGainNode.disconnect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);\n                leftWaveShaperNode.disconnect(leftGainNode.gain);\n                rightWaveShaperNode.disconnect(rightGainNode.gain);\n                leftGainNode.disconnect(channelMergerNode, 0, 0);\n                rightGainNode.disconnect(channelMergerNode, 0, 1);\n            }\n        };\n    };\n    const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode) => {\n        const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);\n        const centerIndex = Math.floor(CURVE_SIZE / 2);\n        for (let i = 0; i < CURVE_SIZE; i += 1) {\n            if (i > centerIndex) {\n                const x = ((i - centerIndex) / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;\n                leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);\n                leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);\n                rightInputForLeftOutputWaveShaperCurve[i] = 0;\n                rightInputForRightOutputWaveShaperCurve[i] = 1;\n            }\n            else {\n                const x = (i / (CURVE_SIZE - 1 - centerIndex)) * HALF_PI;\n                leftInputForLeftOutputWaveShaperCurve[i] = 1;\n                leftInputForRightOutputWaveShaperCurve[i] = 0;\n                rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);\n                rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);\n            }\n        }\n        const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {\n            channelCount: 2,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            numberOfOutputs: 2\n        });\n        const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: leftInputForLeftOutputWaveShaperCurve\n        });\n        const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: leftInputForRightOutputWaveShaperCurve\n        });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const panWaveShaperNode = (createNativeWaveShaperNode(nativeContext, { ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS, curve: DC_CURVE }));\n        const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: rightInputForLeftOutputWaveShaperCurve\n        });\n        const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, { ...SINGLE_CHANNEL_OPTIONS, gain: 0 });\n        // Bug #119: Safari does not fully support the WaveShaperNode.\n        const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {\n            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,\n            curve: rightInputForRightOutputWaveShaperCurve\n        });\n        return {\n            connectGraph() {\n                inputGainNode.connect(channelSplitterNode);\n                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                channelSplitterNode.connect(leftInputForLeftOutputGainNode, 0);\n                channelSplitterNode.connect(leftInputForRightOutputGainNode, 0);\n                channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);\n                channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);\n                panWaveShaperNode.connect(panGainNode);\n                panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForLeftOutputWaveShaperNode\n                    : leftInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForRightOutputWaveShaperNode\n                    : leftInputForRightOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForLeftOutputWaveShaperNode\n                    : rightInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForRightOutputWaveShaperNode\n                    : rightInputForRightOutputWaveShaperNode.inputs[0]);\n                leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);\n                leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);\n                rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);\n                rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);\n                leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);\n                rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);\n                leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);\n                rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);\n            },\n            disconnectGraph() {\n                inputGainNode.disconnect(channelSplitterNode);\n                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);\n                channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 0);\n                channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 0);\n                channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);\n                channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);\n                panWaveShaperNode.disconnect(panGainNode);\n                panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForLeftOutputWaveShaperNode\n                    : leftInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? leftInputForRightOutputWaveShaperNode\n                    : leftInputForRightOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForLeftOutputWaveShaperNode\n                    : rightInputForLeftOutputWaveShaperNode.inputs[0]);\n                panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs === undefined\n                    ? rightInputForRightOutputWaveShaperNode\n                    : rightInputForRightOutputWaveShaperNode.inputs[0]);\n                leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);\n                leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);\n                rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);\n                rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);\n                leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);\n                rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);\n                leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);\n                rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);\n            }\n        };\n    };\n    const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode) => {\n        if (channelCount === 1) {\n            return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);\n        }\n        if (channelCount === 2) {\n            return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);\n        }\n        throw createNotSupportedError();\n    };\n    return (nativeContext, { channelCount, channelCountMode, pan, ...audioNodeOptions }) => {\n        if (channelCountMode === 'max') {\n            throw createNotSupportedError();\n        }\n        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {\n            ...audioNodeOptions,\n            channelCount: 1,\n            channelCountMode,\n            numberOfInputs: 2\n        });\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, channelCount, channelCountMode, gain: 1 });\n        const panGainNode = createNativeGainNode(nativeContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: pan\n        });\n        let { connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);\n        Object.defineProperty(panGainNode.gain, 'defaultValue', { get: () => 0 });\n        Object.defineProperty(panGainNode.gain, 'maxValue', { get: () => 1 });\n        Object.defineProperty(panGainNode.gain, 'minValue', { get: () => -1 });\n        const nativeStereoPannerNodeFakerFactory = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return inputGainNode.channelCount;\n            },\n            set channelCount(value) {\n                if (inputGainNode.channelCount !== value) {\n                    if (isConnected) {\n                        disconnectGraph();\n                    }\n                    ({ connectGraph, disconnectGraph } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));\n                    if (isConnected) {\n                        connectGraph();\n                    }\n                }\n                inputGainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return inputGainNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                if (value === 'clamped-max' || value === 'max') {\n                    throw createNotSupportedError();\n                }\n                inputGainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return inputGainNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n            },\n            get context() {\n                return inputGainNode.context;\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get numberOfInputs() {\n                return inputGainNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return inputGainNode.numberOfOutputs;\n            },\n            get pan() {\n                return panGainNode.gain;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        let isConnected = false;\n        const whenConnected = () => {\n            connectGraph();\n            isConnected = true;\n        };\n        const whenDisconnected = () => {\n            disconnectGraph();\n            isConnected = false;\n        };\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_0__.interceptConnections)(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-stereo-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeWaveShaperNodeFactory\": () => (/* binding */ createNativeWaveShaperNodeFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n\n\nconst createNativeWaveShaperNodeFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors) => {\n    return (nativeContext, options) => {\n        const nativeWaveShaperNode = nativeContext.createWaveShaper();\n        /*\n         * Bug #119: Safari does not correctly map the values.\n         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of\n         * the webkitAudioContext is used as a workaround here. Testing for the automationRate property is necessary because this workaround\n         * isn't necessary anymore since v14.0.2 of Safari.\n         */\n        if (nativeAudioContextConstructor !== null &&\n            nativeAudioContextConstructor.name === 'webkitAudioContext' &&\n            nativeContext.createGain().gain.automationRate === undefined) {\n            return createNativeWaveShaperNodeFaker(nativeContext, options);\n        }\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_1__.assignNativeAudioNodeOptions)(nativeWaveShaperNode, options);\n        const curve = options.curve === null || options.curve instanceof Float32Array ? options.curve : new Float32Array(options.curve);\n        // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.\n        if (curve !== null && curve.length < 2) {\n            throw createInvalidStateError();\n        }\n        // Only values of type Float32Array can be assigned to the curve property.\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeWaveShaperNode, { curve }, 'curve');\n        (0,_helpers_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeWaveShaperNode, options, 'oversample');\n        let disconnectNativeAudioBufferSourceNode = null;\n        let isConnected = false;\n        overwriteAccessors(nativeWaveShaperNode, 'curve', (get) => () => get.call(nativeWaveShaperNode), (set) => (value) => {\n            set.call(nativeWaveShaperNode, value);\n            if (isConnected) {\n                if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) {\n                    disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);\n                }\n                else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {\n                    disconnectNativeAudioBufferSourceNode();\n                    disconnectNativeAudioBufferSourceNode = null;\n                }\n            }\n            return value;\n        });\n        const whenConnected = () => {\n            isConnected = true;\n            if (isDCCurve(nativeWaveShaperNode.curve)) {\n                disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);\n            }\n        };\n        const whenDisconnected = () => {\n            isConnected = false;\n            if (disconnectNativeAudioBufferSourceNode !== null) {\n                disconnectNativeAudioBufferSourceNode();\n                disconnectNativeAudioBufferSourceNode = null;\n            }\n        };\n        return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-wave-shaper-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNativeWaveShaperNodeFakerFactory\": () => (/* binding */ createNativeWaveShaperNodeFakerFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/assign-native-audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js\");\n/* harmony import */ var _helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\n\nconst createNativeWaveShaperNodeFakerFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections) => {\n    return (nativeContext, { curve, oversample, ...audioNodeOptions }) => {\n        const negativeWaveShaperNode = nativeContext.createWaveShaper();\n        const positiveWaveShaperNode = nativeContext.createWaveShaper();\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(negativeWaveShaperNode, audioNodeOptions);\n        (0,_helpers_assign_native_audio_node_options__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOptions)(positiveWaveShaperNode, audioNodeOptions);\n        const inputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const invertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });\n        const outputGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: 1 });\n        const revertGainNode = createNativeGainNode(nativeContext, { ...audioNodeOptions, gain: -1 });\n        let disconnectNativeAudioBufferSourceNode = null;\n        let isConnected = false;\n        let unmodifiedCurve = null;\n        const nativeWaveShaperNodeFaker = {\n            get bufferSize() {\n                return undefined;\n            },\n            get channelCount() {\n                return negativeWaveShaperNode.channelCount;\n            },\n            set channelCount(value) {\n                inputGainNode.channelCount = value;\n                invertGainNode.channelCount = value;\n                negativeWaveShaperNode.channelCount = value;\n                outputGainNode.channelCount = value;\n                positiveWaveShaperNode.channelCount = value;\n                revertGainNode.channelCount = value;\n            },\n            get channelCountMode() {\n                return negativeWaveShaperNode.channelCountMode;\n            },\n            set channelCountMode(value) {\n                inputGainNode.channelCountMode = value;\n                invertGainNode.channelCountMode = value;\n                negativeWaveShaperNode.channelCountMode = value;\n                outputGainNode.channelCountMode = value;\n                positiveWaveShaperNode.channelCountMode = value;\n                revertGainNode.channelCountMode = value;\n            },\n            get channelInterpretation() {\n                return negativeWaveShaperNode.channelInterpretation;\n            },\n            set channelInterpretation(value) {\n                inputGainNode.channelInterpretation = value;\n                invertGainNode.channelInterpretation = value;\n                negativeWaveShaperNode.channelInterpretation = value;\n                outputGainNode.channelInterpretation = value;\n                positiveWaveShaperNode.channelInterpretation = value;\n                revertGainNode.channelInterpretation = value;\n            },\n            get context() {\n                return negativeWaveShaperNode.context;\n            },\n            get curve() {\n                return unmodifiedCurve;\n            },\n            set curve(value) {\n                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n                if (value !== null && value.length < 2) {\n                    throw createInvalidStateError();\n                }\n                if (value === null) {\n                    negativeWaveShaperNode.curve = value;\n                    positiveWaveShaperNode.curve = value;\n                }\n                else {\n                    const curveLength = value.length;\n                    const negativeCurve = new Float32Array(curveLength + 2 - (curveLength % 2));\n                    const positiveCurve = new Float32Array(curveLength + 2 - (curveLength % 2));\n                    negativeCurve[0] = value[0];\n                    positiveCurve[0] = -value[curveLength - 1];\n                    const length = Math.ceil((curveLength + 1) / 2);\n                    const centerIndex = (curveLength + 1) / 2 - 1;\n                    for (let i = 1; i < length; i += 1) {\n                        const theoreticIndex = (i / length) * centerIndex;\n                        const lowerIndex = Math.floor(theoreticIndex);\n                        const upperIndex = Math.ceil(theoreticIndex);\n                        negativeCurve[i] =\n                            lowerIndex === upperIndex\n                                ? value[lowerIndex]\n                                : (1 - (theoreticIndex - lowerIndex)) * value[lowerIndex] +\n                                    (1 - (upperIndex - theoreticIndex)) * value[upperIndex];\n                        positiveCurve[i] =\n                            lowerIndex === upperIndex\n                                ? -value[curveLength - 1 - lowerIndex]\n                                : -((1 - (theoreticIndex - lowerIndex)) * value[curveLength - 1 - lowerIndex]) -\n                                    (1 - (upperIndex - theoreticIndex)) * value[curveLength - 1 - upperIndex];\n                    }\n                    negativeCurve[length] = curveLength % 2 === 1 ? value[length - 1] : (value[length - 2] + value[length - 1]) / 2;\n                    negativeWaveShaperNode.curve = negativeCurve;\n                    positiveWaveShaperNode.curve = positiveCurve;\n                }\n                unmodifiedCurve = value;\n                if (isConnected) {\n                    if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) {\n                        disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);\n                    }\n                    else if (disconnectNativeAudioBufferSourceNode !== null) {\n                        disconnectNativeAudioBufferSourceNode();\n                        disconnectNativeAudioBufferSourceNode = null;\n                    }\n                }\n            },\n            get inputs() {\n                return [inputGainNode];\n            },\n            get numberOfInputs() {\n                return negativeWaveShaperNode.numberOfInputs;\n            },\n            get numberOfOutputs() {\n                return negativeWaveShaperNode.numberOfOutputs;\n            },\n            get oversample() {\n                return negativeWaveShaperNode.oversample;\n            },\n            set oversample(value) {\n                negativeWaveShaperNode.oversample = value;\n                positiveWaveShaperNode.oversample = value;\n            },\n            addEventListener(...args) {\n                return inputGainNode.addEventListener(args[0], args[1], args[2]);\n            },\n            dispatchEvent(...args) {\n                return inputGainNode.dispatchEvent(args[0]);\n            },\n            removeEventListener(...args) {\n                return inputGainNode.removeEventListener(args[0], args[1], args[2]);\n            }\n        };\n        if (curve !== null) {\n            // Only values of type Float32Array can be assigned to the curve property.\n            nativeWaveShaperNodeFaker.curve = curve instanceof Float32Array ? curve : new Float32Array(curve);\n        }\n        if (oversample !== nativeWaveShaperNodeFaker.oversample) {\n            nativeWaveShaperNodeFaker.oversample = oversample;\n        }\n        const whenConnected = () => {\n            inputGainNode.connect(negativeWaveShaperNode).connect(outputGainNode);\n            inputGainNode.connect(invertGainNode).connect(positiveWaveShaperNode).connect(revertGainNode).connect(outputGainNode);\n            isConnected = true;\n            if (isDCCurve(unmodifiedCurve)) {\n                disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);\n            }\n        };\n        const whenDisconnected = () => {\n            inputGainNode.disconnect(negativeWaveShaperNode);\n            negativeWaveShaperNode.disconnect(outputGainNode);\n            inputGainNode.disconnect(invertGainNode);\n            invertGainNode.disconnect(positiveWaveShaperNode);\n            positiveWaveShaperNode.disconnect(revertGainNode);\n            revertGainNode.disconnect(outputGainNode);\n            isConnected = false;\n            if (disconnectNativeAudioBufferSourceNode !== null) {\n                disconnectNativeAudioBufferSourceNode();\n                disconnectNativeAudioBufferSourceNode = null;\n            }\n        };\n        return monitorConnections((0,_helpers_intercept_connections__WEBPACK_IMPORTED_MODULE_1__.interceptConnections)(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=native-wave-shaper-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNotSupportedError\": () => (/* binding */ createNotSupportedError)\n/* harmony export */ });\nconst createNotSupportedError = () => new DOMException('', 'NotSupportedError');\n//# sourceMappingURL=not-supported-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createOfflineAudioContextConstructor\": () => (/* binding */ createOfflineAudioContextConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/deactivate-audio-graph */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js\");\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n\n\nconst DEFAULT_OPTIONS = {\n    numberOfChannels: 1\n};\nconst createOfflineAudioContextConstructor = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering) => {\n    return class OfflineAudioContext extends baseAudioContextConstructor {\n        constructor(a, b, c) {\n            let options;\n            if (typeof a === 'number' && b !== undefined && c !== undefined) {\n                options = { length: b, numberOfChannels: a, sampleRate: c };\n            }\n            else if (typeof a === 'object') {\n                options = a;\n            }\n            else {\n                throw new Error('The given parameters are not valid.');\n            }\n            const { length, numberOfChannels, sampleRate } = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);\n            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.\n            if (!cacheTestResult(_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport, () => (0,_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_1__.testPromiseSupport)(nativeOfflineAudioContext))) {\n                nativeOfflineAudioContext.addEventListener('statechange', (() => {\n                    let i = 0;\n                    const delayStateChangeEvent = (event) => {\n                        if (this._state === 'running') {\n                            if (i > 0) {\n                                nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);\n                                event.stopImmediatePropagation();\n                                this._waitForThePromiseToSettle(event);\n                            }\n                            else {\n                                i += 1;\n                            }\n                        }\n                    };\n                    return delayStateChangeEvent;\n                })());\n            }\n            super(nativeOfflineAudioContext, numberOfChannels);\n            this._length = length;\n            this._nativeOfflineAudioContext = nativeOfflineAudioContext;\n            this._state = null;\n        }\n        get length() {\n            // Bug #17: Safari does not yet expose the length.\n            if (this._nativeOfflineAudioContext.length === undefined) {\n                return this._length;\n            }\n            return this._nativeOfflineAudioContext.length;\n        }\n        get state() {\n            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;\n        }\n        startRendering() {\n            /*\n             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore\n             * the state of the nativeOfflineAudioContext might no transition to running immediately.\n             */\n            if (this._state === 'running') {\n                return Promise.reject(createInvalidStateError());\n            }\n            this._state = 'running';\n            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(() => {\n                this._state = null;\n                (0,_helpers_deactivate_audio_graph__WEBPACK_IMPORTED_MODULE_0__.deactivateAudioGraph)(this);\n            });\n        }\n        _waitForThePromiseToSettle(event) {\n            if (this._state === null) {\n                this._nativeOfflineAudioContext.dispatchEvent(event);\n            }\n            else {\n                setTimeout(() => this._waitForThePromiseToSettle(event));\n            }\n        }\n    };\n};\n//# sourceMappingURL=offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createOscillatorNodeConstructor\": () => (/* binding */ createOscillatorNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/set-internal-state-to-active */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js\");\n/* harmony import */ var _helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../helpers/set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    detune: 0,\n    frequency: 440,\n    periodicWave: undefined,\n    type: 'sine'\n};\nconst createOscillatorNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener) => {\n    return class OscillatorNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const oscillatorNodeRenderer = (isOffline ? createOscillatorNodeRenderer() : null);\n            const nyquist = context.sampleRate / 2;\n            super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);\n            // Bug #81: Firefox & Safari do not export the correct values for maxValue and minValue.\n            this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);\n            // Bug #76: Safari does not export the correct values for maxValue and minValue.\n            this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);\n            this._nativeOscillatorNode = nativeOscillatorNode;\n            this._onended = null;\n            this._oscillatorNodeRenderer = oscillatorNodeRenderer;\n            if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) {\n                this._oscillatorNodeRenderer.periodicWave =\n                    mergedOptions.periodicWave;\n            }\n        }\n        get detune() {\n            return this._detune;\n        }\n        get frequency() {\n            return this._frequency;\n        }\n        get onended() {\n            return this._onended;\n        }\n        set onended(value) {\n            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;\n            this._nativeOscillatorNode.onended = wrappedListener;\n            const nativeOnEnded = this._nativeOscillatorNode.onended;\n            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;\n        }\n        get type() {\n            return this._nativeOscillatorNode.type;\n        }\n        set type(value) {\n            this._nativeOscillatorNode.type = value;\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.periodicWave = null;\n            }\n        }\n        setPeriodicWave(periodicWave) {\n            this._nativeOscillatorNode.setPeriodicWave(periodicWave);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.periodicWave = periodicWave;\n            }\n        }\n        start(when = 0) {\n            this._nativeOscillatorNode.start(when);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.start = when;\n            }\n            if (this.context.state !== 'closed') {\n                (0,_helpers_set_internal_state_to_active__WEBPACK_IMPORTED_MODULE_1__.setInternalStateToActive)(this);\n                const resetInternalStateToPassive = () => {\n                    this._nativeOscillatorNode.removeEventListener('ended', resetInternalStateToPassive);\n                    if ((0,_helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_0__.isActiveAudioNode)(this)) {\n                        (0,_helpers_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_2__.setInternalStateToPassive)(this);\n                    }\n                };\n                this._nativeOscillatorNode.addEventListener('ended', resetInternalStateToPassive);\n            }\n        }\n        stop(when = 0) {\n            this._nativeOscillatorNode.stop(when);\n            if (this._oscillatorNodeRenderer !== null) {\n                this._oscillatorNodeRenderer.stop = when;\n            }\n        }\n    };\n};\n//# sourceMappingURL=oscillator-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createOscillatorNodeRendererFactory\": () => (/* binding */ createOscillatorNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\nconst createOscillatorNodeRendererFactory = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeOscillatorNodes = new WeakMap();\n        let periodicWave = null;\n        let start = null;\n        let stop = null;\n        const createOscillatorNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeOscillatorNode = getNativeAudioNode(proxy);\n            // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeOscillatorNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_0__.isOwnedByContext)(nativeOscillatorNode, nativeOfflineAudioContext);\n            if (!nativeOscillatorNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeOscillatorNode.channelCount,\n                    channelCountMode: nativeOscillatorNode.channelCountMode,\n                    channelInterpretation: nativeOscillatorNode.channelInterpretation,\n                    detune: nativeOscillatorNode.detune.value,\n                    frequency: nativeOscillatorNode.frequency.value,\n                    periodicWave: periodicWave === null ? undefined : periodicWave,\n                    type: nativeOscillatorNode.type\n                };\n                nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);\n                if (start !== null) {\n                    nativeOscillatorNode.start(start);\n                }\n                if (stop !== null) {\n                    nativeOscillatorNode.stop(stop);\n                }\n            }\n            renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);\n            if (!nativeOscillatorNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);\n                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency);\n            }\n            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode);\n            return nativeOscillatorNode;\n        };\n        return {\n            set periodicWave(value) {\n                periodicWave = value;\n            },\n            set start(value) {\n                start = value;\n            },\n            set stop(value) {\n                stop = value;\n            },\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeOscillatorNode !== undefined) {\n                    return Promise.resolve(renderedNativeOscillatorNode);\n                }\n                return createOscillatorNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=oscillator-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createPannerNodeConstructor\": () => (/* binding */ createPannerNodeConstructor)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../constants */ \"./node_modules/standardized-audio-context/build/es2019/constants.js\");\n\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'clamped-max',\n    channelInterpretation: 'speakers',\n    coneInnerAngle: 360,\n    coneOuterAngle: 360,\n    coneOuterGain: 0,\n    distanceModel: 'inverse',\n    maxDistance: 10000,\n    orientationX: 1,\n    orientationY: 0,\n    orientationZ: 0,\n    panningModel: 'equalpower',\n    positionX: 0,\n    positionY: 0,\n    positionZ: 0,\n    refDistance: 1,\n    rolloffFactor: 1\n};\nconst createPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class PannerNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const pannerNodeRenderer = (isOffline ? createPannerNodeRenderer() : null);\n            super(context, false, nativePannerNode, pannerNodeRenderer);\n            this._nativePannerNode = nativePannerNode;\n            // Bug #74: Safari does not export the correct values for maxValue and minValue.\n            this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_POSITIVE_SINGLE_FLOAT, _constants__WEBPACK_IMPORTED_MODULE_0__.MOST_NEGATIVE_SINGLE_FLOAT);\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        get coneInnerAngle() {\n            return this._nativePannerNode.coneInnerAngle;\n        }\n        set coneInnerAngle(value) {\n            this._nativePannerNode.coneInnerAngle = value;\n        }\n        get coneOuterAngle() {\n            return this._nativePannerNode.coneOuterAngle;\n        }\n        set coneOuterAngle(value) {\n            this._nativePannerNode.coneOuterAngle = value;\n        }\n        get coneOuterGain() {\n            return this._nativePannerNode.coneOuterGain;\n        }\n        set coneOuterGain(value) {\n            this._nativePannerNode.coneOuterGain = value;\n        }\n        get distanceModel() {\n            return this._nativePannerNode.distanceModel;\n        }\n        set distanceModel(value) {\n            this._nativePannerNode.distanceModel = value;\n        }\n        get maxDistance() {\n            return this._nativePannerNode.maxDistance;\n        }\n        set maxDistance(value) {\n            this._nativePannerNode.maxDistance = value;\n        }\n        get orientationX() {\n            return this._orientationX;\n        }\n        get orientationY() {\n            return this._orientationY;\n        }\n        get orientationZ() {\n            return this._orientationZ;\n        }\n        get panningModel() {\n            return this._nativePannerNode.panningModel;\n        }\n        set panningModel(value) {\n            this._nativePannerNode.panningModel = value;\n        }\n        get positionX() {\n            return this._positionX;\n        }\n        get positionY() {\n            return this._positionY;\n        }\n        get positionZ() {\n            return this._positionZ;\n        }\n        get refDistance() {\n            return this._nativePannerNode.refDistance;\n        }\n        set refDistance(value) {\n            this._nativePannerNode.refDistance = value;\n        }\n        get rolloffFactor() {\n            return this._nativePannerNode.rolloffFactor;\n        }\n        set rolloffFactor(value) {\n            this._nativePannerNode.rolloffFactor = value;\n        }\n    };\n};\n//# sourceMappingURL=panner-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createPannerNodeRendererFactory\": () => (/* binding */ createPannerNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createPannerNodeRendererFactory = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext) => {\n    return () => {\n        const renderedNativeAudioNodes = new WeakMap();\n        let renderedBufferPromise = null;\n        const createAudioNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeGainNode = null;\n            let nativePannerNode = getNativeAudioNode(proxy);\n            const commonAudioNodeOptions = {\n                channelCount: nativePannerNode.channelCount,\n                channelCountMode: nativePannerNode.channelCountMode,\n                channelInterpretation: nativePannerNode.channelInterpretation\n            };\n            const commonNativePannerNodeOptions = {\n                ...commonAudioNodeOptions,\n                coneInnerAngle: nativePannerNode.coneInnerAngle,\n                coneOuterAngle: nativePannerNode.coneOuterAngle,\n                coneOuterGain: nativePannerNode.coneOuterGain,\n                distanceModel: nativePannerNode.distanceModel,\n                maxDistance: nativePannerNode.maxDistance,\n                panningModel: nativePannerNode.panningModel,\n                refDistance: nativePannerNode.refDistance,\n                rolloffFactor: nativePannerNode.rolloffFactor\n            };\n            // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativePannerNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativePannerNode, nativeOfflineAudioContext);\n            // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.\n            if ('bufferSize' in nativePannerNode) {\n                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n            }\n            else if (!nativePannerNodeIsOwnedByContext) {\n                const options = {\n                    ...commonNativePannerNodeOptions,\n                    orientationX: nativePannerNode.orientationX.value,\n                    orientationY: nativePannerNode.orientationY.value,\n                    orientationZ: nativePannerNode.orientationZ.value,\n                    positionX: nativePannerNode.positionX.value,\n                    positionY: nativePannerNode.positionY.value,\n                    positionZ: nativePannerNode.positionZ.value\n                };\n                nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);\n            if (nativeGainNode !== null) {\n                if (renderedBufferPromise === null) {\n                    if (nativeOfflineAudioContextConstructor === null) {\n                        throw new Error('Missing the native OfflineAudioContext constructor.');\n                    }\n                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, \n                    // Bug #17: Safari does not yet expose the length.\n                    proxy.context.length, nativeOfflineAudioContext.sampleRate);\n                    const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {\n                        channelCount: 1,\n                        channelCountMode: 'explicit',\n                        channelInterpretation: 'speakers',\n                        numberOfInputs: 6\n                    });\n                    nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);\n                    renderedBufferPromise = (async () => {\n                        const nativeConstantSourceNodes = await Promise.all([\n                            proxy.orientationX,\n                            proxy.orientationY,\n                            proxy.orientationZ,\n                            proxy.positionX,\n                            proxy.positionY,\n                            proxy.positionZ\n                        ].map(async (audioParam, index) => {\n                            const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {\n                                channelCount: 1,\n                                channelCountMode: 'explicit',\n                                channelInterpretation: 'discrete',\n                                offset: index === 0 ? 1 : 0\n                            });\n                            await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset);\n                            return nativeConstantSourceNode;\n                        }));\n                        for (let i = 0; i < 6; i += 1) {\n                            nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);\n                            nativeConstantSourceNodes[i].start(0);\n                        }\n                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);\n                    })();\n                }\n                const renderedBuffer = await renderedBufferPromise;\n                const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode);\n                const channelDatas = [];\n                for (let i = 0; i < renderedBuffer.numberOfChannels; i += 1) {\n                    channelDatas.push(renderedBuffer.getChannelData(i));\n                }\n                let lastOrientation = [channelDatas[0][0], channelDatas[1][0], channelDatas[2][0]];\n                let lastPosition = [channelDatas[3][0], channelDatas[4][0], channelDatas[5][0]];\n                let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 1 });\n                let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {\n                    ...commonNativePannerNodeOptions,\n                    orientationX: lastOrientation[0],\n                    orientationY: lastOrientation[1],\n                    orientationZ: lastOrientation[2],\n                    positionX: lastPosition[0],\n                    positionY: lastPosition[1],\n                    positionZ: lastPosition[2]\n                });\n                inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);\n                partialPannerNode.connect(nativeGainNode);\n                for (let i = 128; i < renderedBuffer.length; i += 128) {\n                    const orientation = [channelDatas[0][i], channelDatas[1][i], channelDatas[2][i]];\n                    const positon = [channelDatas[3][i], channelDatas[4][i], channelDatas[5][i]];\n                    if (orientation.some((value, index) => value !== lastOrientation[index]) ||\n                        positon.some((value, index) => value !== lastPosition[index])) {\n                        lastOrientation = orientation;\n                        lastPosition = positon;\n                        const currentTime = i / nativeOfflineAudioContext.sampleRate;\n                        gateGainNode.gain.setValueAtTime(0, currentTime);\n                        gateGainNode = createNativeGainNode(nativeOfflineAudioContext, { ...commonAudioNodeOptions, gain: 0 });\n                        partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {\n                            ...commonNativePannerNodeOptions,\n                            orientationX: lastOrientation[0],\n                            orientationY: lastOrientation[1],\n                            orientationZ: lastOrientation[2],\n                            positionX: lastPosition[0],\n                            positionY: lastPosition[1],\n                            positionZ: lastPosition[2]\n                        });\n                        gateGainNode.gain.setValueAtTime(1, currentTime);\n                        inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);\n                        partialPannerNode.connect(nativeGainNode);\n                    }\n                }\n                return nativeGainNode;\n            }\n            if (!nativePannerNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);\n                await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);\n                await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY);\n                await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ);\n            }\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativePannerNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode);\n            }\n            return nativePannerNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeGainNodeOrNativePannerNode !== undefined) {\n                    return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);\n                }\n                return createAudioNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createPeriodicWaveConstructor\": () => (/* binding */ createPeriodicWaveConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    disableNormalization: false\n};\nconst createPeriodicWaveConstructor = (createNativePeriodicWave, getNativeContext, periodicWaveStore, sanitizePeriodicWaveOptions) => {\n    return class PeriodicWave {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = sanitizePeriodicWaveOptions({ ...DEFAULT_OPTIONS, ...options });\n            const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);\n            periodicWaveStore.add(periodicWave);\n            // This does violate all good pratices but it is used here to simplify the handling of periodic waves.\n            return periodicWave;\n        }\n        static [Symbol.hasInstance](instance) {\n            return ((instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === PeriodicWave.prototype) ||\n                periodicWaveStore.has(instance));\n        }\n    };\n};\n//# sourceMappingURL=periodic-wave-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderAutomation\": () => (/* binding */ createRenderAutomation)\n/* harmony export */ });\nconst createRenderAutomation = (getAudioParamRenderer, renderInputsOfAudioParam) => {\n    return (nativeOfflineAudioContext, audioParam, nativeAudioParam) => {\n        const audioParamRenderer = getAudioParamRenderer(audioParam);\n        audioParamRenderer.replay(nativeAudioParam);\n        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam);\n    };\n};\n//# sourceMappingURL=render-automation.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderInputsOfAudioNode\": () => (/* binding */ createRenderInputsOfAudioNode)\n/* harmony export */ });\nconst createRenderInputsOfAudioNode = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle) => {\n    return async (audioNode, nativeOfflineAudioContext, nativeAudioNode) => {\n        const audioNodeConnections = getAudioNodeConnections(audioNode);\n        await Promise.all(audioNodeConnections.activeInputs\n            .map((connections, input) => Array.from(connections).map(async ([source, output]) => {\n            const audioNodeRenderer = getAudioNodeRenderer(source);\n            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);\n            const destination = audioNode.context.destination;\n            if (!isPartOfACycle(source) && (audioNode !== destination || !isPartOfACycle(audioNode))) {\n                renderedNativeAudioNode.connect(nativeAudioNode, output, input);\n            }\n        }))\n            .reduce((allRenderingPromises, renderingPromises) => [...allRenderingPromises, ...renderingPromises], []));\n    };\n};\n//# sourceMappingURL=render-inputs-of-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderInputsOfAudioParam\": () => (/* binding */ createRenderInputsOfAudioParam)\n/* harmony export */ });\nconst createRenderInputsOfAudioParam = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle) => {\n    return async (audioParam, nativeOfflineAudioContext, nativeAudioParam) => {\n        const audioParamConnections = getAudioParamConnections(audioParam);\n        await Promise.all(Array.from(audioParamConnections.activeInputs).map(async ([source, output]) => {\n            const audioNodeRenderer = getAudioNodeRenderer(source);\n            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext);\n            if (!isPartOfACycle(source)) {\n                renderedNativeAudioNode.connect(nativeAudioParam, output);\n            }\n        }));\n    };\n};\n//# sourceMappingURL=render-inputs-of-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createRenderNativeOfflineAudioContext\": () => (/* binding */ createRenderNativeOfflineAudioContext)\n/* harmony export */ });\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n\nconst createRenderNativeOfflineAudioContext = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport) => {\n    return (nativeOfflineAudioContext) => {\n        // Bug #21: Safari does not support promises yet.\n        if (cacheTestResult(_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_0__.testPromiseSupport, () => (0,_helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_0__.testPromiseSupport)(nativeOfflineAudioContext))) {\n            // Bug #158: Chrome and Edge do not advance currentTime if it is not accessed while rendering the audio.\n            return Promise.resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport)).then((isOfflineAudioContextCurrentTimeSupported) => {\n                if (!isOfflineAudioContextCurrentTimeSupported) {\n                    const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);\n                    nativeOfflineAudioContext.oncomplete = () => {\n                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation\n                        scriptProcessorNode.disconnect();\n                    };\n                    scriptProcessorNode.onaudioprocess = () => nativeOfflineAudioContext.currentTime; // tslint:disable-line:deprecation\n                    scriptProcessorNode.connect(nativeOfflineAudioContext.destination);\n                }\n                return nativeOfflineAudioContext.startRendering();\n            });\n        }\n        return new Promise((resolve) => {\n            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.\n            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {\n                channelCount: 1,\n                channelCountMode: 'explicit',\n                channelInterpretation: 'discrete',\n                gain: 0\n            });\n            nativeOfflineAudioContext.oncomplete = (event) => {\n                gainNode.disconnect();\n                resolve(event.renderedBuffer);\n            };\n            gainNode.connect(nativeOfflineAudioContext.destination);\n            nativeOfflineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=render-native-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createSetActiveAudioWorkletNodeInputs\": () => (/* binding */ createSetActiveAudioWorkletNodeInputs)\n/* harmony export */ });\nconst createSetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore) => {\n    return (nativeAudioWorkletNode, activeInputs) => {\n        activeAudioWorkletNodeInputsStore.set(nativeAudioWorkletNode, activeInputs);\n    };\n};\n//# sourceMappingURL=set-active-audio-worklet-node-inputs.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createSetAudioNodeTailTime\": () => (/* binding */ createSetAudioNodeTailTime)\n/* harmony export */ });\nconst createSetAudioNodeTailTime = (audioNodeTailTimeStore) => {\n    return (audioNode, tailTime) => audioNodeTailTimeStore.set(audioNode, tailTime);\n};\n//# sourceMappingURL=set-audio-node-tail-time.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createStartRendering\": () => (/* binding */ createStartRendering)\n/* harmony export */ });\n/* harmony import */ var _helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../helpers/wrap-audio-buffer-get-channel-data-method */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js\");\n\nconst createStartRendering = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds) => {\n    return (destination, nativeOfflineAudioContext) => getAudioNodeRenderer(destination)\n        .render(destination, nativeOfflineAudioContext)\n        /*\n         * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the\n         * destination.\n         */\n        .then(() => Promise.all(Array.from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext)).map((audioWorkletNode) => getAudioNodeRenderer(audioWorkletNode).render(audioWorkletNode, nativeOfflineAudioContext))))\n        .then(() => renderNativeOfflineAudioContext(nativeOfflineAudioContext))\n        .then((audioBuffer) => {\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.\n        if (typeof audioBuffer.copyFromChannel !== 'function') {\n            wrapAudioBufferCopyChannelMethods(audioBuffer);\n            (0,_helpers_wrap_audio_buffer_get_channel_data_method__WEBPACK_IMPORTED_MODULE_0__.wrapAudioBufferGetChannelDataMethod)(audioBuffer);\n            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.\n        }\n        else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, () => testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer))) {\n            wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);\n        }\n        audioBufferStore.add(audioBuffer);\n        return audioBuffer;\n    });\n};\n//# sourceMappingURL=start-rendering.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createStereoPannerNodeConstructor\": () => (/* binding */ createStereoPannerNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    /*\n     * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent\n     * behavior.\n     */\n    channelCountMode: 'explicit',\n    channelInterpretation: 'speakers',\n    pan: 0\n};\nconst createStereoPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext) => {\n    return class StereoPannerNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const stereoPannerNodeRenderer = (isOffline ? createStereoPannerNodeRenderer() : null);\n            super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);\n            this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan);\n        }\n        get pan() {\n            return this._pan;\n        }\n    };\n};\n//# sourceMappingURL=stereo-panner-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createStereoPannerNodeRendererFactory\": () => (/* binding */ createStereoPannerNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createStereoPannerNodeRendererFactory = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeStereoPannerNodes = new WeakMap();\n        const createStereoPannerNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeStereoPannerNode = getNativeAudioNode(proxy);\n            /*\n             * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created\n             * again.\n             */\n            const nativeStereoPannerNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeStereoPannerNode, nativeOfflineAudioContext);\n            if (!nativeStereoPannerNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeStereoPannerNode.channelCount,\n                    channelCountMode: nativeStereoPannerNode.channelCountMode,\n                    channelInterpretation: nativeStereoPannerNode.channelInterpretation,\n                    pan: nativeStereoPannerNode.pan.value\n                };\n                nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);\n            if (!nativeStereoPannerNodeIsOwnedByContext) {\n                await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);\n            }\n            else {\n                await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan);\n            }\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeStereoPannerNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode);\n            }\n            return nativeStereoPannerNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeStereoPannerNode !== undefined) {\n                    return Promise.resolve(renderedNativeStereoPannerNode);\n                }\n                return createStereoPannerNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=stereo-panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioBufferConstructorSupport\": () => (/* binding */ createTestAudioBufferConstructorSupport)\n/* harmony export */ });\n// Bug #33: Safari exposes an AudioBuffer but it can't be used as a constructor.\nconst createTestAudioBufferConstructorSupport = (nativeAudioBufferConstructor) => {\n    return () => {\n        if (nativeAudioBufferConstructor === null) {\n            return false;\n        }\n        try {\n            new nativeAudioBufferConstructor({ length: 1, sampleRate: 44100 }); // tslint:disable-line:no-unused-expression\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-audio-buffer-constructor-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioBufferCopyChannelMethodsSubarraySupport\": () => (/* binding */ createTestAudioBufferCopyChannelMethodsSubarraySupport)\n/* harmony export */ });\n/*\n * Firefox up to version 67 didn't fully support the copyFromChannel() and copyToChannel() methods. Therefore testing one of those methods\n * is enough to know if the other one is supported as well.\n */\nconst createTestAudioBufferCopyChannelMethodsSubarraySupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);\n        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n        if (nativeAudioBuffer.copyToChannel === undefined) {\n            return true;\n        }\n        const source = new Float32Array(2);\n        try {\n            nativeAudioBuffer.copyFromChannel(source, 0, 0);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-audio-buffer-copy-channel-methods-subarray-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioContextCloseMethodSupport\": () => (/* binding */ createTestAudioContextCloseMethodSupport)\n/* harmony export */ });\nconst createTestAudioContextCloseMethodSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        // Try to check the prototype before constructing the AudioContext.\n        if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) {\n            return true;\n        }\n        const audioContext = new nativeAudioContextConstructor();\n        const isAudioContextClosable = audioContext.close !== undefined;\n        try {\n            audioContext.close();\n        }\n        catch {\n            // Ignore errors.\n        }\n        return isAudioContextClosable;\n    };\n};\n//# sourceMappingURL=test-audio-context-close-method-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioContextDecodeAudioDataMethodTypeErrorSupport\": () => (/* binding */ createTestAudioContextDecodeAudioDataMethodTypeErrorSupport)\n/* harmony export */ });\n/**\n * Edge up to version 14, Firefox up to version 52, Safari up to version 9 and maybe other browsers\n * did not refuse to decode invalid parameters with a TypeError.\n */\nconst createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            let isPending = true;\n            const resolvePromise = (err) => {\n                if (isPending) {\n                    isPending = false;\n                    offlineAudioContext.startRendering();\n                    resolve(err instanceof TypeError);\n                }\n            };\n            let promise;\n            // Bug #26: Safari throws a synchronous error.\n            try {\n                promise = offlineAudioContext\n                    // Bug #1: Safari requires a successCallback.\n                    .decodeAudioData(null, () => {\n                    // Ignore the success callback.\n                }, resolvePromise);\n            }\n            catch (err) {\n                resolvePromise(err);\n            }\n            // Bug #21: Safari does not support promises yet.\n            if (promise !== undefined) {\n                // Bug #6: Chrome, Edge, Firefox and Opera do not call the errorCallback.\n                promise.catch(resolvePromise);\n            }\n        });\n    };\n};\n//# sourceMappingURL=test-audio-context-decode-audio-data-method-type-error-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioContextOptionsSupport\": () => (/* binding */ createTestAudioContextOptionsSupport)\n/* harmony export */ });\nconst createTestAudioContextOptionsSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        let audioContext;\n        try {\n            audioContext = new nativeAudioContextConstructor({ latencyHint: 'balanced' });\n        }\n        catch {\n            return false;\n        }\n        audioContext.close();\n        return true;\n    };\n};\n//# sourceMappingURL=test-audio-context-options-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioNodeConnectMethodSupport\": () => (/* binding */ createTestAudioNodeConnectMethodSupport)\n/* harmony export */ });\n// Safari up to version 12.0 (but not v12.1) didn't return the destination in case it was an AudioNode.\nconst createTestAudioNodeConnectMethodSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeGainNode = nativeOfflineAudioContext.createGain();\n        const isSupported = nativeGainNode.connect(nativeGainNode) === nativeGainNode;\n        nativeGainNode.disconnect(nativeGainNode);\n        return isSupported;\n    };\n};\n//# sourceMappingURL=test-audio-node-connect-method-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioWorkletProcessorNoOutputsSupport\": () => (/* binding */ createTestAudioWorkletProcessorNoOutputsSupport)\n/* harmony export */ });\n/**\n * Chrome version 66 and 67 did not call the process() function of an AudioWorkletProcessor if it had no outputs. AudioWorklet support was\n * enabled by default in version 66.\n */\nconst createTestAudioWorkletProcessorNoOutputsSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {\n    return async () => {\n        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.\n        if (nativeAudioWorkletNodeConstructor === null) {\n            return true;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const blob = new Blob([\n            'let c,p;class A extends AudioWorkletProcessor{constructor(){super();this.port.onmessage=(e)=>{p=e.data;p.onmessage=()=>{p.postMessage(c);p.close()};this.port.postMessage(0)}}process(){c=1}}registerProcessor(\"a\",A)'\n        ], {\n            type: 'application/javascript; charset=utf-8'\n        });\n        const messageChannel = new MessageChannel();\n        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);\n        const url = URL.createObjectURL(blob);\n        let isCallingProcess = false;\n        try {\n            await offlineAudioContext.audioWorklet.addModule(url);\n            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });\n            const oscillator = offlineAudioContext.createOscillator();\n            await new Promise((resolve) => {\n                audioWorkletNode.port.onmessage = () => resolve();\n                audioWorkletNode.port.postMessage(messageChannel.port2, [messageChannel.port2]);\n            });\n            audioWorkletNode.port.onmessage = () => (isCallingProcess = true);\n            oscillator.connect(audioWorkletNode);\n            oscillator.start(0);\n            await offlineAudioContext.startRendering();\n            isCallingProcess = await new Promise((resolve) => {\n                messageChannel.port1.onmessage = ({ data }) => resolve(data === 1);\n                messageChannel.port1.postMessage(0);\n            });\n        }\n        catch {\n            // Ignore errors.\n        }\n        finally {\n            messageChannel.port1.close();\n            URL.revokeObjectURL(url);\n        }\n        return isCallingProcess;\n    };\n};\n//# sourceMappingURL=test-audio-worklet-processor-no-outputs-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestAudioWorkletProcessorPostMessageSupport\": () => (/* binding */ createTestAudioWorkletProcessorPostMessageSupport)\n/* harmony export */ });\n// Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.\nconst createTestAudioWorkletProcessorPostMessageSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor) => {\n    return async () => {\n        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.\n        if (nativeAudioWorkletNodeConstructor === null) {\n            return true;\n        }\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const blob = new Blob(['class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor(\"a\",A)'], {\n            type: 'application/javascript; charset=utf-8'\n        });\n        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);\n        const url = URL.createObjectURL(blob);\n        let isEmittingMessageEvents = false;\n        let isEmittingProcessorErrorEvents = false;\n        try {\n            await offlineAudioContext.audioWorklet.addModule(url);\n            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', { numberOfOutputs: 0 });\n            const oscillator = offlineAudioContext.createOscillator();\n            audioWorkletNode.port.onmessage = () => (isEmittingMessageEvents = true);\n            audioWorkletNode.onprocessorerror = () => (isEmittingProcessorErrorEvents = true);\n            oscillator.connect(audioWorkletNode);\n            oscillator.start(0);\n            await offlineAudioContext.startRendering();\n        }\n        catch {\n            // Ignore errors.\n        }\n        finally {\n            URL.revokeObjectURL(url);\n        }\n        return isEmittingMessageEvents && !isEmittingProcessorErrorEvents;\n    };\n};\n//# sourceMappingURL=test-audio-worklet-processor-post-message-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestChannelMergerNodeChannelCountSupport\": () => (/* binding */ createTestChannelMergerNodeChannelCountSupport)\n/* harmony export */ });\n/**\n * Firefox up to version 69 did not throw an error when setting a different channelCount or channelCountMode.\n */\nconst createTestChannelMergerNodeChannelCountSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeChannelMergerNode = offlineAudioContext.createChannelMerger();\n        /**\n         * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support\n         * in other browsers.\n         */\n        if (nativeChannelMergerNode.channelCountMode === 'max') {\n            return true;\n        }\n        try {\n            nativeChannelMergerNode.channelCount = 2;\n        }\n        catch {\n            return true;\n        }\n        return false;\n    };\n};\n//# sourceMappingURL=test-channel-merger-node-channel-count-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestConstantSourceNodeAccurateSchedulingSupport\": () => (/* binding */ createTestConstantSourceNodeAccurateSchedulingSupport)\n/* harmony export */ });\nconst createTestConstantSourceNodeAccurateSchedulingSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #62: Safari does not support ConstantSourceNodes.\n        if (nativeOfflineAudioContext.createConstantSource === undefined) {\n            return true;\n        }\n        const nativeConstantSourceNode = nativeOfflineAudioContext.createConstantSource();\n        /*\n         * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to\n         * the implementation of Firefox right now, but it could probably be done in a better way.\n         */\n        return nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY;\n    };\n};\n//# sourceMappingURL=test-constant-source-node-accurate-scheduling-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestConvolverNodeBufferReassignabilitySupport\": () => (/* binding */ createTestConvolverNodeBufferReassignabilitySupport)\n/* harmony export */ });\n// Opera up to version 57 did not allow to reassign the buffer of a ConvolverNode.\nconst createTestConvolverNodeBufferReassignabilitySupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeConvolverNode = offlineAudioContext.createConvolver();\n        nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        try {\n            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-convolver-node-buffer-reassignability-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestConvolverNodeChannelCountSupport\": () => (/* binding */ createTestConvolverNodeChannelCountSupport)\n/* harmony export */ });\n// Chrome up to version v80, Edge up to version v80 and Opera up to version v67 did not allow to set the channelCount property of a ConvolverNode to 1. They also did not allow to set the channelCountMode to 'explicit'.\nconst createTestConvolverNodeChannelCountSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return false;\n        }\n        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        const nativeConvolverNode = offlineAudioContext.createConvolver();\n        try {\n            nativeConvolverNode.channelCount = 1;\n        }\n        catch {\n            return false;\n        }\n        return true;\n    };\n};\n//# sourceMappingURL=test-convolver-node-channel-count-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestIsSecureContextSupport\": () => (/* binding */ createTestIsSecureContextSupport)\n/* harmony export */ });\nconst createTestIsSecureContextSupport = (window) => {\n    return () => window !== null && window.hasOwnProperty('isSecureContext');\n};\n//# sourceMappingURL=test-is-secure-context-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js":
/*!********************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js ***!
  \********************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport\": () => (/* binding */ createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)\n/* harmony export */ });\n// Firefox up to version 68 did not throw an error when creating a MediaStreamAudioSourceNode with a mediaStream that had no audio track.\nconst createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = (nativeAudioContextConstructor) => {\n    return () => {\n        if (nativeAudioContextConstructor === null) {\n            return false;\n        }\n        const audioContext = new nativeAudioContextConstructor();\n        try {\n            audioContext.createMediaStreamSource(new MediaStream());\n            return false;\n        }\n        catch (err) {\n            return true;\n        }\n        finally {\n            audioContext.close();\n        }\n    };\n};\n//# sourceMappingURL=test-media-stream-audio-source-node-media-stream-without-audio-track-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestOfflineAudioContextCurrentTimeSupport\": () => (/* binding */ createTestOfflineAudioContextCurrentTimeSupport)\n/* harmony export */ });\nconst createTestOfflineAudioContextCurrentTimeSupport = (createNativeGainNode, nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        // Bug #48: Safari does not render an OfflineAudioContext without any connected node.\n        const gainNode = createNativeGainNode(nativeOfflineAudioContext, {\n            channelCount: 1,\n            channelCountMode: 'explicit',\n            channelInterpretation: 'discrete',\n            gain: 0\n        });\n        // Bug #21: Safari does not support promises yet.\n        return new Promise((resolve) => {\n            nativeOfflineAudioContext.oncomplete = () => {\n                gainNode.disconnect();\n                resolve(nativeOfflineAudioContext.currentTime !== 0);\n            };\n            nativeOfflineAudioContext.startRendering();\n        });\n    };\n};\n//# sourceMappingURL=test-offline-audio-context-current-time-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createTestStereoPannerNodeDefaultValueSupport\": () => (/* binding */ createTestStereoPannerNodeDefaultValueSupport)\n/* harmony export */ });\n/**\n * Firefox up to version 62 did not kick off the processing of the StereoPannerNode if the value of pan was zero.\n */\nconst createTestStereoPannerNodeDefaultValueSupport = (nativeOfflineAudioContextConstructor) => {\n    return () => {\n        if (nativeOfflineAudioContextConstructor === null) {\n            return Promise.resolve(false);\n        }\n        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);\n        /*\n         * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does\n         * support the tested behaviour.\n         */\n        if (nativeOfflineAudioContext.createStereoPanner === undefined) {\n            return Promise.resolve(true);\n        }\n        // Bug #62: Safari does not support ConstantSourceNodes.\n        if (nativeOfflineAudioContext.createConstantSource === undefined) {\n            return Promise.resolve(true);\n        }\n        const constantSourceNode = nativeOfflineAudioContext.createConstantSource();\n        const stereoPanner = nativeOfflineAudioContext.createStereoPanner();\n        constantSourceNode.channelCount = 1;\n        constantSourceNode.offset.value = 1;\n        stereoPanner.channelCount = 1;\n        constantSourceNode.start();\n        constantSourceNode.connect(stereoPanner).connect(nativeOfflineAudioContext.destination);\n        return nativeOfflineAudioContext.startRendering().then((buffer) => buffer.getChannelData(0)[0] !== 1);\n    };\n};\n//# sourceMappingURL=test-stereo-panner-node-default-value-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createUnknownError\": () => (/* binding */ createUnknownError)\n/* harmony export */ });\nconst createUnknownError = () => new DOMException('', 'UnknownError');\n//# sourceMappingURL=unknown-error.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWaveShaperNodeConstructor\": () => (/* binding */ createWaveShaperNodeConstructor)\n/* harmony export */ });\nconst DEFAULT_OPTIONS = {\n    channelCount: 2,\n    channelCountMode: 'max',\n    channelInterpretation: 'speakers',\n    curve: null,\n    oversample: 'none'\n};\nconst createWaveShaperNodeConstructor = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime) => {\n    return class WaveShaperNode extends audioNodeConstructor {\n        constructor(context, options) {\n            const nativeContext = getNativeContext(context);\n            const mergedOptions = { ...DEFAULT_OPTIONS, ...options };\n            const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);\n            const isOffline = isNativeOfflineAudioContext(nativeContext);\n            const waveShaperNodeRenderer = (isOffline ? createWaveShaperNodeRenderer() : null);\n            // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.\n            super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);\n            this._isCurveNullified = false;\n            this._nativeWaveShaperNode = nativeWaveShaperNode;\n            // @todo Determine a meaningful tail-time instead of just using one second.\n            setAudioNodeTailTime(this, 1);\n        }\n        get curve() {\n            if (this._isCurveNullified) {\n                return null;\n            }\n            return this._nativeWaveShaperNode.curve;\n        }\n        set curve(value) {\n            // Bug #103: Safari does not allow to set the curve to null.\n            if (value === null) {\n                this._isCurveNullified = true;\n                this._nativeWaveShaperNode.curve = new Float32Array([0, 0]);\n            }\n            else {\n                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.\n                // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.\n                if (value.length < 2) {\n                    throw createInvalidStateError();\n                }\n                this._isCurveNullified = false;\n                this._nativeWaveShaperNode.curve = value;\n            }\n        }\n        get oversample() {\n            return this._nativeWaveShaperNode.oversample;\n        }\n        set oversample(value) {\n            this._nativeWaveShaperNode.oversample = value;\n        }\n    };\n};\n//# sourceMappingURL=wave-shaper-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWaveShaperNodeRendererFactory\": () => (/* binding */ createWaveShaperNodeRendererFactory)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n/* harmony import */ var _helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../helpers/is-owned-by-context */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js\");\n\n\nconst createWaveShaperNodeRendererFactory = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode) => {\n    return () => {\n        const renderedNativeWaveShaperNodes = new WeakMap();\n        const createWaveShaperNode = async (proxy, nativeOfflineAudioContext) => {\n            let nativeWaveShaperNode = getNativeAudioNode(proxy);\n            // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.\n            const nativeWaveShaperNodeIsOwnedByContext = (0,_helpers_is_owned_by_context__WEBPACK_IMPORTED_MODULE_1__.isOwnedByContext)(nativeWaveShaperNode, nativeOfflineAudioContext);\n            if (!nativeWaveShaperNodeIsOwnedByContext) {\n                const options = {\n                    channelCount: nativeWaveShaperNode.channelCount,\n                    channelCountMode: nativeWaveShaperNode.channelCountMode,\n                    channelInterpretation: nativeWaveShaperNode.channelInterpretation,\n                    curve: nativeWaveShaperNode.curve,\n                    oversample: nativeWaveShaperNode.oversample\n                };\n                nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);\n            }\n            renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);\n            if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeWaveShaperNode)) {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0]);\n            }\n            else {\n                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode);\n            }\n            return nativeWaveShaperNode;\n        };\n        return {\n            render(proxy, nativeOfflineAudioContext) {\n                const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);\n                if (renderedNativeWaveShaperNode !== undefined) {\n                    return Promise.resolve(renderedNativeWaveShaperNode);\n                }\n                return createWaveShaperNode(proxy, nativeOfflineAudioContext);\n            }\n        };\n    };\n};\n//# sourceMappingURL=wave-shaper-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/window.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/window.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWindow\": () => (/* binding */ createWindow)\n/* harmony export */ });\nconst createWindow = () => (typeof window === 'undefined' ? null : window);\n//# sourceMappingURL=window.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/window.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapAudioBufferCopyChannelMethodsOutOfBounds\": () => (/* binding */ createWrapAudioBufferCopyChannelMethodsOutOfBounds)\n/* harmony export */ });\nconst createWrapAudioBufferCopyChannelMethodsOutOfBounds = (convertNumberToUnsignedLong) => {\n    return (audioBuffer) => {\n        audioBuffer.copyFromChannel = ((copyFromChannel) => {\n            return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n                if (bufferOffset < audioBuffer.length) {\n                    return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);\n                }\n            };\n        })(audioBuffer.copyFromChannel);\n        audioBuffer.copyToChannel = ((copyToChannel) => {\n            return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n                if (bufferOffset < audioBuffer.length) {\n                    return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);\n                }\n            };\n        })(audioBuffer.copyToChannel);\n    };\n};\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-out-of-bounds.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapAudioBufferCopyChannelMethods\": () => (/* binding */ createWrapAudioBufferCopyChannelMethods)\n/* harmony export */ });\nconst createWrapAudioBufferCopyChannelMethods = (convertNumberToUnsignedLong, createIndexSizeError) => {\n    return (audioBuffer) => {\n        audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n            if (channelNumber >= audioBuffer.numberOfChannels) {\n                throw createIndexSizeError();\n            }\n            const audioBufferLength = audioBuffer.length;\n            const channelData = audioBuffer.getChannelData(channelNumber);\n            const destinationLength = destination.length;\n            for (let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1) {\n                destination[i] = channelData[i + bufferOffset];\n            }\n        };\n        audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0) => {\n            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);\n            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);\n            if (channelNumber >= audioBuffer.numberOfChannels) {\n                throw createIndexSizeError();\n            }\n            const audioBufferLength = audioBuffer.length;\n            const channelData = audioBuffer.getChannelData(channelNumber);\n            const sourceLength = source.length;\n            for (let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1) {\n                channelData[i + bufferOffset] = source[i];\n            }\n        };\n    };\n};\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer\": () => (/* binding */ createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer)\n/* harmony export */ });\nconst createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer = (overwriteAccessors) => {\n    return (nativeAudioBufferSourceNode, nativeContext) => {\n        const nullifiedBuffer = nativeContext.createBuffer(1, 1, 44100);\n        if (nativeAudioBufferSourceNode.buffer === null) {\n            nativeAudioBufferSourceNode.buffer = nullifiedBuffer;\n        }\n        overwriteAccessors(nativeAudioBufferSourceNode, 'buffer', (get) => () => {\n            const value = get.call(nativeAudioBufferSourceNode);\n            return value === nullifiedBuffer ? null : value;\n        }, (set) => (value) => {\n            return set.call(nativeAudioBufferSourceNode, value === null ? nullifiedBuffer : value);\n        });\n    };\n};\n//# sourceMappingURL=wrap-audio-buffer-source-node-stop-method-nullified-buffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createWrapChannelMergerNode\": () => (/* binding */ createWrapChannelMergerNode)\n/* harmony export */ });\nconst createWrapChannelMergerNode = (createInvalidStateError, monitorConnections) => {\n    return (nativeContext, channelMergerNode) => {\n        // Bug #15: Safari does not return the default properties.\n        channelMergerNode.channelCount = 1;\n        channelMergerNode.channelCountMode = 'explicit';\n        // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.\n        Object.defineProperty(channelMergerNode, 'channelCount', {\n            get: () => 1,\n            set: () => {\n                throw createInvalidStateError();\n            }\n        });\n        Object.defineProperty(channelMergerNode, 'channelCountMode', {\n            get: () => 'explicit',\n            set: () => {\n                throw createInvalidStateError();\n            }\n        });\n        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.\n        const audioBufferSourceNode = nativeContext.createBufferSource();\n        const whenConnected = () => {\n            const length = channelMergerNode.numberOfInputs;\n            for (let i = 0; i < length; i += 1) {\n                audioBufferSourceNode.connect(channelMergerNode, 0, i);\n            }\n        };\n        const whenDisconnected = () => audioBufferSourceNode.disconnect(channelMergerNode);\n        monitorConnections(channelMergerNode, whenConnected, whenDisconnected);\n    };\n};\n//# sourceMappingURL=wrap-channel-merger-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/globals.js":
/*!*************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/globals.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ACTIVE_AUDIO_NODE_STORE\": () => (/* binding */ ACTIVE_AUDIO_NODE_STORE),\n/* harmony export */   \"AUDIO_NODE_CONNECTIONS_STORE\": () => (/* binding */ AUDIO_NODE_CONNECTIONS_STORE),\n/* harmony export */   \"AUDIO_NODE_STORE\": () => (/* binding */ AUDIO_NODE_STORE),\n/* harmony export */   \"AUDIO_PARAM_CONNECTIONS_STORE\": () => (/* binding */ AUDIO_PARAM_CONNECTIONS_STORE),\n/* harmony export */   \"AUDIO_PARAM_STORE\": () => (/* binding */ AUDIO_PARAM_STORE),\n/* harmony export */   \"CONTEXT_STORE\": () => (/* binding */ CONTEXT_STORE),\n/* harmony export */   \"CYCLE_COUNTERS\": () => (/* binding */ CYCLE_COUNTERS),\n/* harmony export */   \"EVENT_LISTENERS\": () => (/* binding */ EVENT_LISTENERS),\n/* harmony export */   \"NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS\": () => (/* binding */ NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS),\n/* harmony export */   \"NODE_TO_PROCESSOR_MAPS\": () => (/* binding */ NODE_TO_PROCESSOR_MAPS)\n/* harmony export */ });\nconst ACTIVE_AUDIO_NODE_STORE = new WeakSet();\nconst AUDIO_NODE_CONNECTIONS_STORE = new WeakMap();\nconst AUDIO_NODE_STORE = new WeakMap();\nconst AUDIO_PARAM_CONNECTIONS_STORE = new WeakMap();\nconst AUDIO_PARAM_STORE = new WeakMap();\nconst CONTEXT_STORE = new WeakMap();\nconst EVENT_LISTENERS = new WeakMap();\nconst CYCLE_COUNTERS = new WeakMap();\n// This clunky name is borrowed from the spec. :-)\nconst NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS = new WeakMap();\nconst NODE_TO_PROCESSOR_MAPS = new WeakMap();\n//# sourceMappingURL=globals.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/globals.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioBufferSourceNode\": () => (/* binding */ isAudioBufferSourceNode)\n/* harmony export */ });\nconst isAudioBufferSourceNode = (audioNode) => {\n    return 'playbackRate' in audioNode;\n};\n//# sourceMappingURL=audio-buffer-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioNodeOutputConnection\": () => (/* binding */ isAudioNodeOutputConnection)\n/* harmony export */ });\n/* harmony import */ var _audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js\");\n\nconst isAudioNodeOutputConnection = (outputConnection) => {\n    return (0,_audio_node__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(outputConnection[0]);\n};\n//# sourceMappingURL=audio-node-output-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/audio-node-output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioNode\": () => (/* binding */ isAudioNode)\n/* harmony export */ });\nconst isAudioNode = (audioNodeOrAudioParam) => {\n    return 'context' in audioNodeOrAudioParam;\n};\n//# sourceMappingURL=audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioWorkletNode\": () => (/* binding */ isAudioWorkletNode)\n/* harmony export */ });\nconst isAudioWorkletNode = (audioNode) => {\n    return 'port' in audioNode;\n};\n//# sourceMappingURL=audio-worklet-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isBiquadFilterNode\": () => (/* binding */ isBiquadFilterNode)\n/* harmony export */ });\nconst isBiquadFilterNode = (audioNode) => {\n    return 'frequency' in audioNode && 'gain' in audioNode;\n};\n//# sourceMappingURL=biquad-filter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isConstantSourceNode\": () => (/* binding */ isConstantSourceNode)\n/* harmony export */ });\nconst isConstantSourceNode = (audioNode) => {\n    return 'offset' in audioNode;\n};\n//# sourceMappingURL=constant-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isDelayNode\": () => (/* binding */ isDelayNode)\n/* harmony export */ });\nconst isDelayNode = (audioNode) => {\n    return 'delayTime' in audioNode;\n};\n//# sourceMappingURL=delay-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isGainNode\": () => (/* binding */ isGainNode)\n/* harmony export */ });\nconst isGainNode = (audioNode) => {\n    return !('frequency' in audioNode) && 'gain' in audioNode;\n};\n//# sourceMappingURL=gain-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isNativeAudioNodeFaker\": () => (/* binding */ isNativeAudioNodeFaker)\n/* harmony export */ });\nconst isNativeAudioNodeFaker = (nativeAudioNodeOrNativeAudioNodeFaker) => {\n    return 'inputs' in nativeAudioNodeOrNativeAudioNodeFaker;\n};\n//# sourceMappingURL=native-audio-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isNativeAudioNode\": () => (/* binding */ isNativeAudioNode)\n/* harmony export */ });\nconst isNativeAudioNode = (nativeAudioNodeOrAudioParam) => {\n    return 'context' in nativeAudioNodeOrAudioParam;\n};\n//# sourceMappingURL=native-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isOscillatorNode\": () => (/* binding */ isOscillatorNode)\n/* harmony export */ });\nconst isOscillatorNode = (audioNode) => {\n    return 'detune' in audioNode && 'frequency' in audioNode;\n};\n//# sourceMappingURL=oscillator-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isStereoPannerNode\": () => (/* binding */ isStereoPannerNode)\n/* harmony export */ });\nconst isStereoPannerNode = (audioNode) => {\n    return 'pan' in audioNode;\n};\n//# sourceMappingURL=stereo-panner-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addActiveInputConnectionToAudioParam\": () => (/* binding */ addActiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n\nconst addActiveInputConnectionToAudioParam = (activeInputs, source, [output, eventListener], ignoreDuplicates) => {\n    (0,_insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__.insertElementInSet)(activeInputs, [source, output, eventListener], (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output, ignoreDuplicates);\n};\n//# sourceMappingURL=add-active-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/add-active-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addPassiveInputConnectionToAudioParam\": () => (/* binding */ addPassiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n\nconst addPassiveInputConnectionToAudioParam = (passiveInputs, [source, output, eventListener], ignoreDuplicates) => {\n    const passiveInputConnections = passiveInputs.get(source);\n    if (passiveInputConnections === undefined) {\n        passiveInputs.set(source, new Set([[output, eventListener]]));\n    }\n    else {\n        (0,_insert_element_in_set__WEBPACK_IMPORTED_MODULE_0__.insertElementInSet)(passiveInputConnections, [output, eventListener], (passiveInputConnection) => passiveInputConnection[0] === output, ignoreDuplicates);\n    }\n};\n//# sourceMappingURL=add-passive-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/add-passive-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assignNativeAudioNodeAudioParamValue\": () => (/* binding */ assignNativeAudioNodeAudioParamValue)\n/* harmony export */ });\nconst assignNativeAudioNodeAudioParamValue = (nativeAudioNode, options, audioParam) => {\n    const value = options[audioParam];\n    if (value !== undefined && value !== nativeAudioNode[audioParam].value) {\n        nativeAudioNode[audioParam].value = value;\n    }\n};\n//# sourceMappingURL=assign-native-audio-node-audio-param-value.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-audio-param-value.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assignNativeAudioNodeOption\": () => (/* binding */ assignNativeAudioNodeOption)\n/* harmony export */ });\nconst assignNativeAudioNodeOption = (nativeAudioNode, options, option) => {\n    const value = options[option];\n    if (value !== undefined && value !== nativeAudioNode[option]) {\n        nativeAudioNode[option] = value;\n    }\n};\n//# sourceMappingURL=assign-native-audio-node-option.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assignNativeAudioNodeOptions\": () => (/* binding */ assignNativeAudioNodeOptions)\n/* harmony export */ });\n/* harmony import */ var _assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./assign-native-audio-node-option */ \"./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-option.js\");\n\nconst assignNativeAudioNodeOptions = (nativeAudioNode, options) => {\n    (0,_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAudioNode, options, 'channelCount');\n    (0,_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAudioNode, options, 'channelCountMode');\n    (0,_assign_native_audio_node_option__WEBPACK_IMPORTED_MODULE_0__.assignNativeAudioNodeOption)(nativeAudioNode, options, 'channelInterpretation');\n};\n//# sourceMappingURL=assign-native-audio-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/assign-native-audio-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"cloneAudioWorkletNodeOptions\": () => (/* binding */ cloneAudioWorkletNodeOptions)\n/* harmony export */ });\nconst cloneAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {\n    return new Promise((resolve, reject) => {\n        const { port1, port2 } = new MessageChannel();\n        port1.onmessage = ({ data }) => {\n            port1.close();\n            port2.close();\n            resolve(data);\n        };\n        port1.onmessageerror = ({ data }) => {\n            port1.close();\n            port2.close();\n            reject(data);\n        };\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port2.postMessage(audioWorkletNodeOptions);\n    });\n};\n//# sourceMappingURL=clone-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"computeBufferSize\": () => (/* binding */ computeBufferSize)\n/* harmony export */ });\nconst computeBufferSize = (baseLatency, sampleRate) => {\n    if (baseLatency === null) {\n        return 512;\n    }\n    return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));\n};\n//# sourceMappingURL=compute-buffer-size.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/compute-buffer-size.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"connectNativeAudioNodeToNativeAudioNode\": () => (/* binding */ connectNativeAudioNodeToNativeAudioNode)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n\nconst connectNativeAudioNodeToNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {\n    if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeDestinationAudioNode)) {\n        const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];\n        nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);\n        return [fakeNativeDestinationAudioNode, output, 0];\n    }\n    nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);\n    return [nativeDestinationAudioNode, output, input];\n};\n//# sourceMappingURL=connect-native-audio-node-to-native-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"copyFromChannel\": () => (/* binding */ copyFromChannel)\n/* harmony export */ });\nfunction copyFromChannel(audioBuffer, \n// @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }\nparent, key, channelNumber, bufferOffset) {\n    if (typeof audioBuffer.copyFromChannel === 'function') {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength === 0) {\n            parent[key] = new Float32Array(128);\n        }\n        audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);\n        // Bug #5: Safari does not support copyFromChannel().\n    }\n    else {\n        const channelData = audioBuffer.getChannelData(channelNumber);\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength === 0) {\n            parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);\n        }\n        else {\n            const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);\n            parent[key].set(slicedInput);\n        }\n    }\n}\n//# sourceMappingURL=copy-from-channel.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/copy-from-channel.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"copyToChannel\": () => (/* binding */ copyToChannel)\n/* harmony export */ });\nconst copyToChannel = (audioBuffer, parent, key, channelNumber, bufferOffset) => {\n    if (typeof audioBuffer.copyToChannel === 'function') {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength !== 0) {\n            audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);\n        }\n        // Bug #5: Safari does not support copyToChannel().\n    }\n    else {\n        // The byteLength will be 0 when the ArrayBuffer was transferred.\n        if (parent[key].byteLength !== 0) {\n            audioBuffer.getChannelData(channelNumber).set(parent[key], bufferOffset);\n        }\n    }\n};\n//# sourceMappingURL=copy-to-channel.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/copy-to-channel.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletProcessorPromise\": () => (/* binding */ createAudioWorkletProcessorPromise)\n/* harmony export */ });\n/* harmony import */ var _clone_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./clone-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/clone-audio-worklet-node-options.js\");\n\nconst createAudioWorkletProcessorPromise = async (processorConstructor, audioWorkletNodeOptions) => {\n    const clonedAudioWorkletNodeOptions = await (0,_clone_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_0__.cloneAudioWorkletNodeOptions)(audioWorkletNodeOptions);\n    return new processorConstructor(clonedAudioWorkletNodeOptions);\n};\n//# sourceMappingURL=create-audio-worklet-processor-promise.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioWorkletProcessor\": () => (/* binding */ createAudioWorkletProcessor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _create_audio_worklet_processor_promise__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./create-audio-worklet-processor-promise */ \"./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor-promise.js\");\n\n\nconst createAudioWorkletProcessor = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions) => {\n    let nodeToProcessorMap = _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_TO_PROCESSOR_MAPS.get(nativeContext);\n    if (nodeToProcessorMap === undefined) {\n        nodeToProcessorMap = new WeakMap();\n        _globals__WEBPACK_IMPORTED_MODULE_0__.NODE_TO_PROCESSOR_MAPS.set(nativeContext, nodeToProcessorMap);\n    }\n    const audioWorkletProcessorPromise = (0,_create_audio_worklet_processor_promise__WEBPACK_IMPORTED_MODULE_1__.createAudioWorkletProcessorPromise)(processorConstructor, audioWorkletNodeOptions);\n    nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);\n    return audioWorkletProcessorPromise;\n};\n//# sourceMappingURL=create-audio-worklet-processor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/create-audio-worklet-processor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createNestedArrays\": () => (/* binding */ createNestedArrays)\n/* harmony export */ });\nconst createNestedArrays = (x, y) => {\n    const arrays = [];\n    for (let i = 0; i < x; i += 1) {\n        const array = [];\n        const length = typeof y === 'number' ? y : y[i];\n        for (let j = 0; j < length; j += 1) {\n            array.push(new Float32Array(128));\n        }\n        arrays.push(array);\n    }\n    return arrays;\n};\n//# sourceMappingURL=create-nested-arrays.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/create-nested-arrays.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deactivateActiveAudioNodeInputConnections\": () => (/* binding */ deactivateActiveAudioNodeInputConnections)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-buffer-source-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-buffer-source-node.js\");\n/* harmony import */ var _guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../guards/audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js\");\n/* harmony import */ var _guards_biquad_filter_node__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../guards/biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/biquad-filter-node.js\");\n/* harmony import */ var _guards_constant_source_node__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../guards/constant-source-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/constant-source-node.js\");\n/* harmony import */ var _guards_gain_node__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../guards/gain-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/gain-node.js\");\n/* harmony import */ var _guards_oscillator_node__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../guards/oscillator-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/oscillator-node.js\");\n/* harmony import */ var _guards_stereo_panner_node__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../guards/stereo-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/stereo-panner-node.js\");\n/* harmony import */ var _get_audio_node_connections__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _get_audio_param_connections__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./get-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js\");\n/* harmony import */ var _is_active_audio_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n\n\n\n\n\n\n\n\n\nconst deactivateActiveAudioNodeInputConnections = (audioNode, trace) => {\n    const { activeInputs } = (0,_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_7__.getAudioNodeConnections)(audioNode);\n    activeInputs.forEach((connections) => connections.forEach(([source]) => {\n        if (!trace.includes(audioNode)) {\n            deactivateActiveAudioNodeInputConnections(source, [...trace, audioNode]);\n        }\n    }));\n    const audioParams = (0,_guards_audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_0__.isAudioBufferSourceNode)(audioNode)\n        ? [\n            // Bug #149: Safari does not yet support the detune AudioParam.\n            audioNode.playbackRate\n        ]\n        : (0,_guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_1__.isAudioWorkletNode)(audioNode)\n            ? Array.from(audioNode.parameters.values())\n            : (0,_guards_biquad_filter_node__WEBPACK_IMPORTED_MODULE_2__.isBiquadFilterNode)(audioNode)\n                ? [audioNode.Q, audioNode.detune, audioNode.frequency, audioNode.gain]\n                : (0,_guards_constant_source_node__WEBPACK_IMPORTED_MODULE_3__.isConstantSourceNode)(audioNode)\n                    ? [audioNode.offset]\n                    : (0,_guards_gain_node__WEBPACK_IMPORTED_MODULE_4__.isGainNode)(audioNode)\n                        ? [audioNode.gain]\n                        : (0,_guards_oscillator_node__WEBPACK_IMPORTED_MODULE_5__.isOscillatorNode)(audioNode)\n                            ? [audioNode.detune, audioNode.frequency]\n                            : (0,_guards_stereo_panner_node__WEBPACK_IMPORTED_MODULE_6__.isStereoPannerNode)(audioNode)\n                                ? [audioNode.pan]\n                                : [];\n    for (const audioParam of audioParams) {\n        const audioParamConnections = (0,_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_8__.getAudioParamConnections)(audioParam);\n        if (audioParamConnections !== undefined) {\n            audioParamConnections.activeInputs.forEach(([source]) => deactivateActiveAudioNodeInputConnections(source, trace));\n        }\n    }\n    if ((0,_is_active_audio_node__WEBPACK_IMPORTED_MODULE_9__.isActiveAudioNode)(audioNode)) {\n        (0,_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_10__.setInternalStateToPassive)(audioNode);\n    }\n};\n//# sourceMappingURL=deactivate-active-audio-node-input-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deactivateAudioGraph\": () => (/* binding */ deactivateAudioGraph)\n/* harmony export */ });\n/* harmony import */ var _deactivate_active_audio_node_input_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./deactivate-active-audio-node-input-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-active-audio-node-input-connections.js\");\n\nconst deactivateAudioGraph = (context) => {\n    (0,_deactivate_active_audio_node_input_connections__WEBPACK_IMPORTED_MODULE_0__.deactivateActiveAudioNodeInputConnections)(context.destination, []);\n};\n//# sourceMappingURL=deactivate-audio-graph.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/deactivate-audio-graph.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deleteActiveInputConnectionToAudioParam\": () => (/* binding */ deleteActiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _pick_element_from_set__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n\nconst deleteActiveInputConnectionToAudioParam = (activeInputs, source, output) => {\n    return (0,_pick_element_from_set__WEBPACK_IMPORTED_MODULE_0__.pickElementFromSet)(activeInputs, (activeInputConnection) => activeInputConnection[0] === source && activeInputConnection[1] === output);\n};\n//# sourceMappingURL=delete-active-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deleteActiveInputConnection\": () => (/* binding */ deleteActiveInputConnection)\n/* harmony export */ });\nconst deleteActiveInputConnection = (activeInputConnections, source, output) => {\n    for (const activeInputConnection of activeInputConnections) {\n        if (activeInputConnection[0] === source && activeInputConnection[1] === output) {\n            activeInputConnections.delete(activeInputConnection);\n            return activeInputConnection;\n        }\n    }\n    return null;\n};\n//# sourceMappingURL=delete-active-input-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/delete-active-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deleteEventListenerOfAudioNode\": () => (/* binding */ deleteEventListenerOfAudioNode)\n/* harmony export */ });\n/* harmony import */ var _get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n\nconst deleteEventListenerOfAudioNode = (audioNode, eventListener) => {\n    const eventListeners = (0,_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_0__.getEventListenersOfAudioNode)(audioNode);\n    if (!eventListeners.delete(eventListener)) {\n        throw new Error('Missing the expected event listener.');\n    }\n};\n//# sourceMappingURL=delete-event-listeners-of-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/delete-event-listeners-of-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deletePassiveInputConnectionToAudioNode\": () => (/* binding */ deletePassiveInputConnectionToAudioNode)\n/* harmony export */ });\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n/* harmony import */ var _pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n\n\nconst deletePassiveInputConnectionToAudioNode = (passiveInputs, source, output, input) => {\n    const passiveInputConnections = (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_0__.getValueForKey)(passiveInputs, source);\n    const matchingConnection = (0,_pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__.pickElementFromSet)(passiveInputConnections, (passiveInputConnection) => passiveInputConnection[0] === output && passiveInputConnection[1] === input);\n    if (passiveInputConnections.size === 0) {\n        passiveInputs.delete(source);\n    }\n    return matchingConnection;\n};\n//# sourceMappingURL=delete-passive-input-connection-to-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deletePassiveInputConnectionToAudioParam\": () => (/* binding */ deletePassiveInputConnectionToAudioParam)\n/* harmony export */ });\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n/* harmony import */ var _pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n\n\nconst deletePassiveInputConnectionToAudioParam = (passiveInputs, source, output) => {\n    const passiveInputConnections = (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_0__.getValueForKey)(passiveInputs, source);\n    const matchingConnection = (0,_pick_element_from_set__WEBPACK_IMPORTED_MODULE_1__.pickElementFromSet)(passiveInputConnections, (passiveInputConnection) => passiveInputConnection[0] === output);\n    if (passiveInputConnections.size === 0) {\n        passiveInputs.delete(source);\n    }\n    return matchingConnection;\n};\n//# sourceMappingURL=delete-passive-input-connection-to-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/delete-passive-input-connection-to-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"detachArrayBuffer\": () => (/* binding */ detachArrayBuffer)\n/* harmony export */ });\nconst detachArrayBuffer = (arrayBuffer) => {\n    const { port1, port2 } = new MessageChannel();\n    return new Promise((resolve) => {\n        const closeAndResolve = () => {\n            port2.onmessage = null;\n            port1.close();\n            port2.close();\n            resolve();\n        };\n        port2.onmessage = () => closeAndResolve();\n        try {\n            port1.postMessage(arrayBuffer, [arrayBuffer]);\n        }\n        finally {\n            closeAndResolve();\n        }\n    });\n};\n//# sourceMappingURL=detach-array-buffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/detach-array-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"disconnectNativeAudioNodeFromNativeAudioNode\": () => (/* binding */ disconnectNativeAudioNodeFromNativeAudioNode)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node-faker.js\");\n\nconst disconnectNativeAudioNodeFromNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input) => {\n    if ((0,_guards_native_audio_node_faker__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNodeFaker)(nativeDestinationAudioNode)) {\n        nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);\n    }\n    else {\n        nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);\n    }\n};\n//# sourceMappingURL=disconnect-native-audio-node-from-native-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"filterBuffer\": () => (/* binding */ filterBuffer)\n/* harmony export */ });\n// This implementation as shamelessly inspired by source code of\n// tslint:disable-next-line:max-line-length\n// {@link https://chromium.googlesource.com/chromium/src.git/+/master/third_party/WebKit/Source/platform/audio/IIRFilter.cpp|Chromium's IIRFilter}.\nconst filterBuffer = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output) => {\n    const inputLength = input.length;\n    let i = bufferIndex;\n    for (let j = 0; j < inputLength; j += 1) {\n        let y = feedforward[0] * input[j];\n        for (let k = 1; k < minLength; k += 1) {\n            const x = (i - k) & (bufferLength - 1); // tslint:disable-line:no-bitwise\n            y += feedforward[k] * xBuffer[x];\n            y -= feedback[k] * yBuffer[x];\n        }\n        for (let k = minLength; k < feedforwardLength; k += 1) {\n            y += feedforward[k] * xBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise\n        }\n        for (let k = minLength; k < feedbackLength; k += 1) {\n            y -= feedback[k] * yBuffer[(i - k) & (bufferLength - 1)]; // tslint:disable-line:no-bitwise\n        }\n        xBuffer[i] = input[j];\n        yBuffer[i] = y;\n        i = (i + 1) & (bufferLength - 1); // tslint:disable-line:no-bitwise\n        output[j] = y;\n    }\n    return i;\n};\n//# sourceMappingURL=filter-buffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/filter-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getAudioNodeConnections\": () => (/* binding */ getAudioNodeConnections)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getAudioNodeConnections = (audioNode) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_NODE_CONNECTIONS_STORE, audioNode);\n};\n//# sourceMappingURL=get-audio-node-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getAudioParamConnections\": () => (/* binding */ getAudioParamConnections)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getAudioParamConnections = (audioParam) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_PARAM_CONNECTIONS_STORE, audioParam);\n};\n//# sourceMappingURL=get-audio-param-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getAudioWorkletProcessor\": () => (/* binding */ getAudioWorkletProcessor)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_native_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\n\nconst getAudioWorkletProcessor = (nativeOfflineAudioContext, proxy) => {\n    const nodeToProcessorMap = (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_2__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.NODE_TO_PROCESSOR_MAPS, nativeOfflineAudioContext);\n    const nativeAudioWorkletNode = (0,_get_native_audio_node__WEBPACK_IMPORTED_MODULE_1__.getNativeAudioNode)(proxy);\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_2__.getValueForKey)(nodeToProcessorMap, nativeAudioWorkletNode);\n};\n//# sourceMappingURL=get-audio-worklet-processor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-worklet-processor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getEventListenersOfAudioNode\": () => (/* binding */ getEventListenersOfAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getEventListenersOfAudioNode = (audioNode) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.EVENT_LISTENERS, audioNode);\n};\n//# sourceMappingURL=get-event-listeners-of-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getFirstSample\": () => (/* binding */ getFirstSample)\n/* harmony export */ });\nconst getFirstSample = (audioBuffer, buffer, channelNumber) => {\n    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().\n    if (audioBuffer.copyFromChannel === undefined) {\n        return audioBuffer.getChannelData(channelNumber)[0];\n    }\n    audioBuffer.copyFromChannel(buffer, channelNumber);\n    return buffer[0];\n};\n//# sourceMappingURL=get-first-sample.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getNativeAudioNode\": () => (/* binding */ getNativeAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getNativeAudioNode = (audioNode) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_NODE_STORE, audioNode);\n};\n//# sourceMappingURL=get-native-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getNativeAudioParam\": () => (/* binding */ getNativeAudioParam)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_value_for_key__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n\n\nconst getNativeAudioParam = (audioParam) => {\n    return (0,_get_value_for_key__WEBPACK_IMPORTED_MODULE_1__.getValueForKey)(_globals__WEBPACK_IMPORTED_MODULE_0__.AUDIO_PARAM_STORE, audioParam);\n};\n//# sourceMappingURL=get-native-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getValueForKey\": () => (/* binding */ getValueForKey)\n/* harmony export */ });\nconst getValueForKey = (map, key) => {\n    const value = map.get(key);\n    if (value === undefined) {\n        throw new Error('A value with the given key could not be found.');\n    }\n    return value;\n};\n//# sourceMappingURL=get-value-for-key.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"insertElementInSet\": () => (/* binding */ insertElementInSet)\n/* harmony export */ });\nconst insertElementInSet = (set, element, predicate, ignoreDuplicates) => {\n    for (const lmnt of set) {\n        if (predicate(lmnt)) {\n            if (ignoreDuplicates) {\n                return false;\n            }\n            throw Error('The set contains at least one similar element.');\n        }\n    }\n    set.add(element);\n    return true;\n};\n//# sourceMappingURL=insert-element-in-set.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"interceptConnections\": () => (/* binding */ interceptConnections)\n/* harmony export */ });\nconst interceptConnections = (original, interceptor) => {\n    original.connect = interceptor.connect.bind(interceptor);\n    original.disconnect = interceptor.disconnect.bind(interceptor);\n    return original;\n};\n//# sourceMappingURL=intercept-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isActiveAudioNode\": () => (/* binding */ isActiveAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst isActiveAudioNode = (audioNode) => _globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode);\n//# sourceMappingURL=is-active-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isConstructible\": () => (/* binding */ isConstructible)\n/* harmony export */ });\nconst handler = {\n    construct() {\n        return handler;\n    }\n};\nconst isConstructible = (constructible) => {\n    try {\n        const proxy = new Proxy(constructible, handler);\n        new proxy(); // tslint:disable-line:no-unused-expression\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=is-constructible.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-constructible.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isDCCurve\": () => (/* binding */ isDCCurve)\n/* harmony export */ });\nconst isDCCurve = (curve) => {\n    if (curve === null) {\n        return false;\n    }\n    const length = curve.length;\n    if (length % 2 !== 0) {\n        return curve[Math.floor(length / 2)] !== 0;\n    }\n    return curve[length / 2 - 1] + curve[length / 2] !== 0;\n};\n//# sourceMappingURL=is-dc-curve.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isOwnedByContext\": () => (/* binding */ isOwnedByContext)\n/* harmony export */ });\nconst isOwnedByContext = (nativeAudioNode, nativeContext) => {\n    return nativeAudioNode.context === nativeContext;\n};\n//# sourceMappingURL=is-owned-by-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-owned-by-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isPartOfACycle\": () => (/* binding */ isPartOfACycle)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst isPartOfACycle = (audioNode) => {\n    return _globals__WEBPACK_IMPORTED_MODULE_0__.CYCLE_COUNTERS.has(audioNode);\n};\n//# sourceMappingURL=is-part-of-a-cycle.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isPassiveAudioNode\": () => (/* binding */ isPassiveAudioNode)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n\nconst isPassiveAudioNode = (audioNode) => {\n    return !_globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode);\n};\n//# sourceMappingURL=is-passive-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isValidLatencyHint\": () => (/* binding */ isValidLatencyHint)\n/* harmony export */ });\nconst isValidLatencyHint = (latencyHint) => {\n    return (latencyHint === undefined ||\n        typeof latencyHint === 'number' ||\n        (typeof latencyHint === 'string' && (latencyHint === 'balanced' || latencyHint === 'interactive' || latencyHint === 'playback')));\n};\n//# sourceMappingURL=is-valid-latency-hint.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/is-valid-latency-hint.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"overwriteAccessors\": () => (/* binding */ overwriteAccessors)\n/* harmony export */ });\nconst overwriteAccessors = (object, property, createGetter, createSetter) => {\n    let prototype = object;\n    while (!prototype.hasOwnProperty(property)) {\n        prototype = Object.getPrototypeOf(prototype);\n    }\n    const { get, set } = Object.getOwnPropertyDescriptor(prototype, property);\n    Object.defineProperty(object, property, { get: createGetter(get), set: createSetter(set) });\n};\n//# sourceMappingURL=overwrite-accessors.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"pickElementFromSet\": () => (/* binding */ pickElementFromSet)\n/* harmony export */ });\nconst pickElementFromSet = (set, predicate) => {\n    const matchingElements = Array.from(set).filter(predicate);\n    if (matchingElements.length > 1) {\n        throw Error('More than one element was found.');\n    }\n    if (matchingElements.length === 0) {\n        throw Error('No element was found.');\n    }\n    const [matchingElement] = matchingElements;\n    set.delete(matchingElement);\n    return matchingElement;\n};\n//# sourceMappingURL=pick-element-from-set.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"sanitizeAudioWorkletNodeOptions\": () => (/* binding */ sanitizeAudioWorkletNodeOptions)\n/* harmony export */ });\nconst sanitizeAudioWorkletNodeOptions = (options) => {\n    return {\n        ...options,\n        outputChannelCount: options.outputChannelCount !== undefined\n            ? options.outputChannelCount\n            : options.numberOfInputs === 1 && options.numberOfOutputs === 1\n                ? /*\n                   * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why\n                   * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That\n                   * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.\n                   */\n                    [options.channelCount]\n                : Array.from({ length: options.numberOfOutputs }, () => 1)\n    };\n};\n//# sourceMappingURL=sanitize-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"sanitizeChannelSplitterOptions\": () => (/* binding */ sanitizeChannelSplitterOptions)\n/* harmony export */ });\nconst sanitizeChannelSplitterOptions = (options) => {\n    return { ...options, channelCount: options.numberOfOutputs };\n};\n//# sourceMappingURL=sanitize-channel-splitter-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"sanitizePeriodicWaveOptions\": () => (/* binding */ sanitizePeriodicWaveOptions)\n/* harmony export */ });\nconst sanitizePeriodicWaveOptions = (options) => {\n    const { imag, real } = options;\n    if (imag === undefined) {\n        if (real === undefined) {\n            return { ...options, imag: [0, 0], real: [0, 0] };\n        }\n        return { ...options, imag: Array.from(real, () => 0), real };\n    }\n    if (real === undefined) {\n        return { ...options, imag, real: Array.from(imag, () => 0) };\n    }\n    return { ...options, imag, real };\n};\n//# sourceMappingURL=sanitize-periodic-wave-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setInternalStateToActive\": () => (/* binding */ setInternalStateToActive)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n\n\nconst setInternalStateToActive = (audioNode) => {\n    if (_globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {\n        throw new Error('The AudioNode is already stored.');\n    }\n    _globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.add(audioNode);\n    (0,_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__.getEventListenersOfAudioNode)(audioNode).forEach((eventListener) => eventListener(true));\n};\n//# sourceMappingURL=set-internal-state-to-active.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-active.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setInternalStateToPassiveWhenNecessary\": () => (/* binding */ setInternalStateToPassiveWhenNecessary)\n/* harmony export */ });\n/* harmony import */ var _guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/audio-worklet-node.js\");\n/* harmony import */ var _set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./set-internal-state-to-passive */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js\");\n\n\n// Set the internalState of the audioNode to 'passive' if it is not an AudioWorkletNode and if it has no 'active' input connections.\nconst setInternalStateToPassiveWhenNecessary = (audioNode, activeInputs) => {\n    if (!(0,_guards_audio_worklet_node__WEBPACK_IMPORTED_MODULE_0__.isAudioWorkletNode)(audioNode) && activeInputs.every((connections) => connections.size === 0)) {\n        (0,_set_internal_state_to_passive__WEBPACK_IMPORTED_MODULE_1__.setInternalStateToPassive)(audioNode);\n    }\n};\n//# sourceMappingURL=set-internal-state-to-passive-when-necessary.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive-when-necessary.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setInternalStateToPassive\": () => (/* binding */ setInternalStateToPassive)\n/* harmony export */ });\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n\n\nconst setInternalStateToPassive = (audioNode) => {\n    if (!_globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE.has(audioNode)) {\n        throw new Error('The AudioNode is not stored.');\n    }\n    _globals__WEBPACK_IMPORTED_MODULE_0__.ACTIVE_AUDIO_NODE_STORE[\"delete\"](audioNode);\n    (0,_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_1__.getEventListenersOfAudioNode)(audioNode).forEach((eventListener) => eventListener(false));\n};\n//# sourceMappingURL=set-internal-state-to-passive.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/set-internal-state-to-passive.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"setValueAtTimeUntilPossible\": () => (/* binding */ setValueAtTimeUntilPossible)\n/* harmony export */ });\nconst setValueAtTimeUntilPossible = (audioParam, value, startTime) => {\n    try {\n        audioParam.setValueAtTime(value, startTime);\n    }\n    catch (err) {\n        if (err.code !== 9) {\n            throw err;\n        }\n        setValueAtTimeUntilPossible(audioParam, value, startTime + 1e-7);\n    }\n};\n//# sourceMappingURL=set-value-at-time-until-possible.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"splitImportStatements\": () => (/* binding */ splitImportStatements)\n/* harmony export */ });\n/*\n * This massive regex tries to cover all the following cases.\n *\n * import './path';\n * import defaultImport from './path';\n * import { namedImport } from './path';\n * import { namedImport as renamendImport } from './path';\n * import * as namespaceImport from './path';\n * import defaultImport, { namedImport } from './path';\n * import defaultImport, { namedImport as renamendImport } from './path';\n * import defaultImport, * as namespaceImport from './path';\n */\nconst IMPORT_STATEMENT_REGEX = /^import(?:(?:[\\s]+[\\w]+|(?:[\\s]+[\\w]+[\\s]*,)?[\\s]*\\{[\\s]*[\\w]+(?:[\\s]+as[\\s]+[\\w]+)?(?:[\\s]*,[\\s]*[\\w]+(?:[\\s]+as[\\s]+[\\w]+)?)*[\\s]*}|(?:[\\s]+[\\w]+[\\s]*,)?[\\s]*\\*[\\s]+as[\\s]+[\\w]+)[\\s]+from)?(?:[\\s]*)(\"([^\"\\\\]|\\\\.)+\"|'([^'\\\\]|\\\\.)+')(?:[\\s]*);?/; // tslint:disable-line:max-line-length\nconst splitImportStatements = (source, url) => {\n    const importStatements = [];\n    let sourceWithoutImportStatements = source.replace(/^[\\s]+/, '');\n    let result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);\n    while (result !== null) {\n        const unresolvedUrl = result[1].slice(1, -1);\n        const importStatementWithResolvedUrl = result[0]\n            .replace(/([\\s]+)?;?$/, '')\n            .replace(unresolvedUrl, new URL(unresolvedUrl, url).toString());\n        importStatements.push(importStatementWithResolvedUrl);\n        sourceWithoutImportStatements = sourceWithoutImportStatements.slice(result[0].length).replace(/^[\\s]+/, '');\n        result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);\n    }\n    return [importStatements.join(';'), sourceWithoutImportStatements];\n};\n//# sourceMappingURL=split-import-statements.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/split-import-statements.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAnalyserNodeGetFloatTimeDomainDataMethodSupport\": () => (/* binding */ testAnalyserNodeGetFloatTimeDomainDataMethodSupport)\n/* harmony export */ });\nconst testAnalyserNodeGetFloatTimeDomainDataMethodSupport = (nativeAnalyserNode) => {\n    return typeof nativeAnalyserNode.getFloatTimeDomainData === 'function';\n};\n//# sourceMappingURL=test-analyser-node-get-float-time-domain-data-method-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-analyser-node-get-float-time-domain-data-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferCopyChannelMethodsOutOfBoundsSupport\": () => (/* binding */ testAudioBufferCopyChannelMethodsOutOfBoundsSupport)\n/* harmony export */ });\nconst testAudioBufferCopyChannelMethodsOutOfBoundsSupport = (nativeAudioBuffer) => {\n    try {\n        nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-audio-buffer-copy-channel-methods-out-of-bounds-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport\": () => (/* binding */ testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport)\n/* harmony export */ });\nconst testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    nativeAudioBufferSourceNode.start();\n    try {\n        nativeAudioBufferSourceNode.start();\n    }\n    catch {\n        return true;\n    }\n    return false;\n};\n//# sourceMappingURL=test-audio-buffer-source-node-start-method-consecutive-calls-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferSourceNodeStartMethodOffsetClampingSupport\": () => (/* binding */ testAudioBufferSourceNodeStartMethodOffsetClampingSupport)\n/* harmony export */ });\nconst testAudioBufferSourceNodeStartMethodOffsetClampingSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);\n    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n    try {\n        nativeAudioBufferSourceNode.start(0, 1);\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-audio-buffer-source-node-start-method-offset-clamping-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js":
/*!********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js ***!
  \********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioBufferSourceNodeStopMethodNullifiedBufferSupport\": () => (/* binding */ testAudioBufferSourceNodeStopMethodNullifiedBufferSupport)\n/* harmony export */ });\nconst testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    nativeAudioBufferSourceNode.start();\n    try {\n        nativeAudioBufferSourceNode.stop();\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-audio-buffer-source-node-stop-method-nullified-buffer-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioNodeDisconnectMethodSupport\": () => (/* binding */ testAudioNodeDisconnectMethodSupport)\n/* harmony export */ });\nconst testAudioNodeDisconnectMethodSupport = (nativeAudioContext, nativeAudioWorkletNodeConstructor) => {\n    return new Promise((resolve) => {\n        /*\n         * This bug existed in Safari up until v14.0.2. Since AudioWorklets were not supported in Safari until v14.1 the presence of the\n         * constructor for an AudioWorkletNode can be used here to skip the test.\n         */\n        if (nativeAudioWorkletNodeConstructor !== null) {\n            resolve(true);\n        }\n        else {\n            const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1); // tslint:disable-line deprecation\n            const dummy = nativeAudioContext.createGain();\n            // Bug #95: Safari does not play one sample buffers.\n            const ones = nativeAudioContext.createBuffer(1, 2, 44100);\n            const channelData = ones.getChannelData(0);\n            channelData[0] = 1;\n            channelData[1] = 1;\n            const source = nativeAudioContext.createBufferSource();\n            source.buffer = ones;\n            source.loop = true;\n            source.connect(analyzer).connect(nativeAudioContext.destination);\n            source.connect(dummy);\n            source.disconnect(dummy);\n            // tslint:disable-next-line:deprecation\n            analyzer.onaudioprocess = (event) => {\n                const chnnlDt = event.inputBuffer.getChannelData(0); // tslint:disable-line deprecation\n                if (Array.prototype.some.call(chnnlDt, (sample) => sample === 1)) {\n                    resolve(true);\n                }\n                else {\n                    resolve(false);\n                }\n                source.stop();\n                analyzer.onaudioprocess = null; // tslint:disable-line:deprecation\n                source.disconnect(analyzer);\n                analyzer.disconnect(nativeAudioContext.destination);\n            };\n            source.start();\n        }\n    });\n};\n//# sourceMappingURL=test-audio-node-disconnect-method-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-node-disconnect-method-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js":
/*!***************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js ***!
  \***************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioScheduledSourceNodeStartMethodNegativeParametersSupport\": () => (/* binding */ testAudioScheduledSourceNodeStartMethodNegativeParametersSupport)\n/* harmony export */ });\nconst testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createOscillator();\n    try {\n        nativeAudioBufferSourceNode.start(-1);\n    }\n    catch (err) {\n        return err instanceof RangeError;\n    }\n    return false;\n};\n//# sourceMappingURL=test-audio-scheduled-source-node-start-method-negative-parameters-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js":
/*!************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js ***!
  \************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport\": () => (/* binding */ testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport)\n/* harmony export */ });\nconst testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = (nativeContext) => {\n    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);\n    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();\n    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;\n    nativeAudioBufferSourceNode.start();\n    nativeAudioBufferSourceNode.stop();\n    try {\n        nativeAudioBufferSourceNode.stop();\n        return true;\n    }\n    catch {\n        return false;\n    }\n};\n//# sourceMappingURL=test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js":
/*!**************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js ***!
  \**************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioScheduledSourceNodeStopMethodNegativeParametersSupport\": () => (/* binding */ testAudioScheduledSourceNodeStopMethodNegativeParametersSupport)\n/* harmony export */ });\nconst testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = (nativeContext) => {\n    const nativeAudioBufferSourceNode = nativeContext.createOscillator();\n    try {\n        nativeAudioBufferSourceNode.stop(-1);\n    }\n    catch (err) {\n        return err instanceof RangeError;\n    }\n    return false;\n};\n//# sourceMappingURL=test-audio-scheduled-source-node-stop-method-negative-parameters-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testAudioWorkletNodeOptionsClonability\": () => (/* binding */ testAudioWorkletNodeOptionsClonability)\n/* harmony export */ });\nconst testAudioWorkletNodeOptionsClonability = (audioWorkletNodeOptions) => {\n    const { port1, port2 } = new MessageChannel();\n    try {\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port1.postMessage(audioWorkletNodeOptions);\n    }\n    finally {\n        port1.close();\n        port2.close();\n    }\n};\n//# sourceMappingURL=test-audio-worklet-node-options-clonability.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testClonabilityOfAudioWorkletNodeOptions\": () => (/* binding */ testClonabilityOfAudioWorkletNodeOptions)\n/* harmony export */ });\nconst testClonabilityOfAudioWorkletNodeOptions = (audioWorkletNodeOptions) => {\n    const { port1 } = new MessageChannel();\n    try {\n        // This will throw an error if the audioWorkletNodeOptions are not clonable.\n        port1.postMessage(audioWorkletNodeOptions);\n    }\n    finally {\n        port1.close();\n    }\n};\n//# sourceMappingURL=test-clonability-of-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-clonability-of-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testDomExceptionConstructorSupport\": () => (/* binding */ testDomExceptionConstructorSupport)\n/* harmony export */ });\n/*\n * Bug #122: Edge up to version v18 did not allow to construct a DOMException'. It also had a couple more bugs but since this is easy to\n * test it's used here as a placeholder.\n *\n * Bug #27: Edge up to version v18 did reject an invalid arrayBuffer passed to decodeAudioData() with a DOMException.\n *\n * Bug #50: Edge up to version v18 did not allow to create AudioNodes on a closed context.\n *\n * Bug #57: Edge up to version v18 did not throw an error when assigning the type of an OscillatorNode to 'custom'.\n *\n * Bug #63: Edge up to version v18 did not expose the mediaElement property of a MediaElementAudioSourceNode.\n *\n * Bug #64: Edge up to version v18 did not support the MediaStreamAudioDestinationNode.\n *\n * Bug #71: Edge up to version v18 did not allow to set the buffer of an AudioBufferSourceNode to null.\n *\n * Bug #93: Edge up to version v18 did set the sampleRate of an AudioContext to zero when it was closed.\n *\n * Bug #101: Edge up to version v18 refused to execute decodeAudioData() on a closed context.\n *\n * Bug #106: Edge up to version v18 did not expose the maxValue and minValue properties of the pan AudioParam of a StereoPannerNode.\n *\n * Bug #110: Edge up to version v18 did not expose the maxValue and minValue properties of the attack, knee, ratio, release and threshold AudioParams of a DynamicsCompressorNode.\n *\n * Bug #123: Edge up to version v18 did not support HRTF as the panningModel for a PannerNode.\n *\n * Bug #145: Edge up to version v18 did throw an IndexSizeError when an OfflineAudioContext was created with a sampleRate of zero.\n *\n * Bug #161: Edge up to version v18 did not expose the maxValue and minValue properties of the delayTime AudioParam of a DelayNode.\n */\nconst testDomExceptionConstructorSupport = () => {\n    try {\n        new DOMException(); // tslint:disable-line:no-unused-expression\n    }\n    catch {\n        return false;\n    }\n    return true;\n};\n//# sourceMappingURL=test-dom-exception-constructor-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testPromiseSupport\": () => (/* binding */ testPromiseSupport)\n/* harmony export */ });\nconst testPromiseSupport = (nativeContext) => {\n    // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.\n    const uint32Array = new Uint32Array([1179011410, 40, 1163280727, 544501094, 16, 131073, 44100, 176400, 1048580, 1635017060, 4, 0]);\n    try {\n        // Bug #1: Safari requires a successCallback.\n        const promise = nativeContext.decodeAudioData(uint32Array.buffer, () => {\n            // Ignore the success callback.\n        });\n        if (promise === undefined) {\n            return false;\n        }\n        promise.catch(() => {\n            // Ignore rejected errors.\n        });\n        return true;\n    }\n    catch {\n        // Ignore errors.\n    }\n    return false;\n};\n//# sourceMappingURL=test-promise-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"testTransferablesSupport\": () => (/* binding */ testTransferablesSupport)\n/* harmony export */ });\n// Safari at version 11 did not support transferables.\nconst testTransferablesSupport = () => new Promise((resolve) => {\n    const arrayBuffer = new ArrayBuffer(0);\n    const { port1, port2 } = new MessageChannel();\n    port1.onmessage = ({ data }) => resolve(data !== null);\n    port2.postMessage(arrayBuffer, [arrayBuffer]);\n});\n//# sourceMappingURL=test-transferables-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"visitEachAudioNodeOnce\": () => (/* binding */ visitEachAudioNodeOnce)\n/* harmony export */ });\nconst visitEachAudioNodeOnce = (cycles, visitor) => {\n    const counts = new Map();\n    for (const cycle of cycles) {\n        for (const audioNode of cycle) {\n            const count = counts.get(audioNode);\n            counts.set(audioNode, count === undefined ? 1 : count + 1);\n        }\n    }\n    counts.forEach((count, audioNode) => visitor(audioNode, count));\n};\n//# sourceMappingURL=visit-each-audio-node-once.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/visit-each-audio-node-once.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAnalyserNodeGetFloatTimeDomainDataMethod\": () => (/* binding */ wrapAnalyserNodeGetFloatTimeDomainDataMethod)\n/* harmony export */ });\nconst wrapAnalyserNodeGetFloatTimeDomainDataMethod = (nativeAnalyserNode) => {\n    nativeAnalyserNode.getFloatTimeDomainData = (array) => {\n        const byteTimeDomainData = new Uint8Array(array.length);\n        nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);\n        const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);\n        for (let i = 0; i < length; i += 1) {\n            array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;\n        }\n        return array;\n    };\n};\n//# sourceMappingURL=wrap-analyser-node-get-float-time-domain-data-method.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-analyser-node-get-float-time-domain-data-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioBufferGetChannelDataMethod\": () => (/* binding */ wrapAudioBufferGetChannelDataMethod)\n/* harmony export */ });\n/* harmony import */ var _factories_index_size_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/index-size-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js\");\n\nconst wrapAudioBufferGetChannelDataMethod = (audioBuffer) => {\n    audioBuffer.getChannelData = ((getChannelData) => {\n        return (channel) => {\n            try {\n                return getChannelData.call(audioBuffer, channel);\n            }\n            catch (err) {\n                if (err.code === 12) {\n                    throw (0,_factories_index_size_error__WEBPACK_IMPORTED_MODULE_0__.createIndexSizeError)();\n                }\n                throw err;\n            }\n        };\n    })(audioBuffer.getChannelData);\n};\n//# sourceMappingURL=wrap-audio-buffer-get-channel-data-method.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-get-channel-data-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js":
/*!**************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js ***!
  \**************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioBufferSourceNodeStartMethodConsecutiveCalls\": () => (/* binding */ wrapAudioBufferSourceNodeStartMethodConsecutiveCalls)\n/* harmony export */ });\n/* harmony import */ var _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n\nconst wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = (nativeAudioBufferSourceNode) => {\n    nativeAudioBufferSourceNode.start = ((start) => {\n        let isScheduled = false;\n        return (when = 0, offset = 0, duration) => {\n            if (isScheduled) {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n            start.call(nativeAudioBufferSourceNode, when, offset, duration);\n            isScheduled = true;\n        };\n    })(nativeAudioBufferSourceNode.start);\n};\n//# sourceMappingURL=wrap-audio-buffer-source-node-start-method-consecutive-calls.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioBufferSourceNodeStartMethodOffsetClamping\": () => (/* binding */ wrapAudioBufferSourceNodeStartMethodOffsetClamping)\n/* harmony export */ });\nconst wrapAudioBufferSourceNodeStartMethodOffsetClamping = (nativeAudioBufferSourceNode) => {\n    nativeAudioBufferSourceNode.start = ((start) => {\n        return (when = 0, offset = 0, duration) => {\n            const buffer = nativeAudioBufferSourceNode.buffer;\n            // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.\n            const clampedOffset = buffer === null ? offset : Math.min(buffer.duration, offset);\n            // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.\n            if (buffer !== null && clampedOffset > buffer.duration - 0.5 / nativeAudioBufferSourceNode.context.sampleRate) {\n                start.call(nativeAudioBufferSourceNode, when, 0, 0);\n            }\n            else {\n                start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);\n            }\n        };\n    })(nativeAudioBufferSourceNode.start);\n};\n//# sourceMappingURL=wrap-audio-buffer-source-node-start-method-offset-clamping.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioNodeDisconnectMethod\": () => (/* binding */ wrapAudioNodeDisconnectMethod)\n/* harmony export */ });\n/* harmony import */ var _guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../guards/native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/guards/native-audio-node.js\");\n\nconst wrapAudioNodeDisconnectMethod = (nativeAudioNode) => {\n    const connections = new Map();\n    nativeAudioNode.connect = ((connect) => {\n        // tslint:disable-next-line:invalid-void no-inferrable-types\n        return (destination, output = 0, input = 0) => {\n            const returnValue = (0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destination) ? connect(destination, output, input) : connect(destination, output);\n            // Save the new connection only if the calls to connect above didn't throw an error.\n            const connectionsToDestination = connections.get(destination);\n            if (connectionsToDestination === undefined) {\n                connections.set(destination, [{ input, output }]);\n            }\n            else {\n                if (connectionsToDestination.every((connection) => connection.input !== input || connection.output !== output)) {\n                    connectionsToDestination.push({ input, output });\n                }\n            }\n            return returnValue;\n        };\n    })(nativeAudioNode.connect.bind(nativeAudioNode));\n    nativeAudioNode.disconnect = ((disconnect) => {\n        return (destinationOrOutput, output, input) => {\n            disconnect.apply(nativeAudioNode);\n            if (destinationOrOutput === undefined) {\n                connections.clear();\n            }\n            else if (typeof destinationOrOutput === 'number') {\n                for (const [destination, connectionsToDestination] of connections) {\n                    const filteredConnections = connectionsToDestination.filter((connection) => connection.output !== destinationOrOutput);\n                    if (filteredConnections.length === 0) {\n                        connections.delete(destination);\n                    }\n                    else {\n                        connections.set(destination, filteredConnections);\n                    }\n                }\n            }\n            else if (connections.has(destinationOrOutput)) {\n                if (output === undefined) {\n                    connections.delete(destinationOrOutput);\n                }\n                else {\n                    const connectionsToDestination = connections.get(destinationOrOutput);\n                    if (connectionsToDestination !== undefined) {\n                        const filteredConnections = connectionsToDestination.filter((connection) => connection.output !== output && (connection.input !== input || input === undefined));\n                        if (filteredConnections.length === 0) {\n                            connections.delete(destinationOrOutput);\n                        }\n                        else {\n                            connections.set(destinationOrOutput, filteredConnections);\n                        }\n                    }\n                }\n            }\n            for (const [destination, connectionsToDestination] of connections) {\n                connectionsToDestination.forEach((connection) => {\n                    if ((0,_guards_native_audio_node__WEBPACK_IMPORTED_MODULE_0__.isNativeAudioNode)(destination)) {\n                        nativeAudioNode.connect(destination, connection.output, connection.input);\n                    }\n                    else {\n                        nativeAudioNode.connect(destination, connection.output);\n                    }\n                });\n            }\n        };\n    })(nativeAudioNode.disconnect);\n};\n//# sourceMappingURL=wrap-audio-node-disconnect-method.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-node-disconnect-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioScheduledSourceNodeStartMethodNegativeParameters\": () => (/* binding */ wrapAudioScheduledSourceNodeStartMethodNegativeParameters)\n/* harmony export */ });\nconst wrapAudioScheduledSourceNodeStartMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {\n    nativeAudioScheduledSourceNode.start = ((start) => {\n        return (when = 0, offset = 0, duration) => {\n            if ((typeof duration === 'number' && duration < 0) || offset < 0 || when < 0) {\n                throw new RangeError(\"The parameters can't be negative.\");\n            }\n            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.\n            start.call(nativeAudioScheduledSourceNode, when, offset, duration);\n        };\n    })(nativeAudioScheduledSourceNode.start);\n};\n//# sourceMappingURL=wrap-audio-scheduled-source-node-start-method-negative-parameters.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js":
/*!****************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js ***!
  \****************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls\": () => (/* binding */ wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)\n/* harmony export */ });\n/* harmony import */ var _intercept_connections__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./intercept-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/intercept-connections.js\");\n\nconst wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = (nativeAudioScheduledSourceNode, nativeContext) => {\n    const nativeGainNode = nativeContext.createGain();\n    nativeAudioScheduledSourceNode.connect(nativeGainNode);\n    const disconnectGainNode = ((disconnect) => {\n        return () => {\n            // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.\n            disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);\n            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnectGainNode);\n        };\n    })(nativeAudioScheduledSourceNode.disconnect);\n    nativeAudioScheduledSourceNode.addEventListener('ended', disconnectGainNode);\n    (0,_intercept_connections__WEBPACK_IMPORTED_MODULE_0__.interceptConnections)(nativeAudioScheduledSourceNode, nativeGainNode);\n    nativeAudioScheduledSourceNode.stop = ((stop) => {\n        let isStopped = false;\n        return (when = 0) => {\n            if (isStopped) {\n                try {\n                    stop.call(nativeAudioScheduledSourceNode, when);\n                }\n                catch {\n                    nativeGainNode.gain.setValueAtTime(0, when);\n                }\n            }\n            else {\n                stop.call(nativeAudioScheduledSourceNode, when);\n                isStopped = true;\n            }\n        };\n    })(nativeAudioScheduledSourceNode.stop);\n};\n//# sourceMappingURL=wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapAudioScheduledSourceNodeStopMethodNegativeParameters\": () => (/* binding */ wrapAudioScheduledSourceNodeStopMethodNegativeParameters)\n/* harmony export */ });\nconst wrapAudioScheduledSourceNodeStopMethodNegativeParameters = (nativeAudioScheduledSourceNode) => {\n    nativeAudioScheduledSourceNode.stop = ((stop) => {\n        return (when = 0) => {\n            if (when < 0) {\n                throw new RangeError(\"The parameter can't be negative.\");\n            }\n            stop.call(nativeAudioScheduledSourceNode, when);\n        };\n    })(nativeAudioScheduledSourceNode.stop);\n};\n//# sourceMappingURL=wrap-audio-scheduled-source-node-stop-method-negative-parameters.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapChannelSplitterNode\": () => (/* binding */ wrapChannelSplitterNode)\n/* harmony export */ });\n/* harmony import */ var _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n\nconst wrapChannelSplitterNode = (channelSplitterNode) => {\n    const channelCount = channelSplitterNode.numberOfOutputs;\n    // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.\n    Object.defineProperty(channelSplitterNode, 'channelCount', {\n        get: () => channelCount,\n        set: (value) => {\n            if (value !== channelCount) {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n        }\n    });\n    // Bug #30: Safari does not throw an error when attempting to change the channelCountMode to something other than explicit.\n    Object.defineProperty(channelSplitterNode, 'channelCountMode', {\n        get: () => 'explicit',\n        set: (value) => {\n            if (value !== 'explicit') {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n        }\n    });\n    // Bug #32: Safari does not throw an error when attempting to change the channelInterpretation to something other than discrete.\n    Object.defineProperty(channelSplitterNode, 'channelInterpretation', {\n        get: () => 'discrete',\n        set: (value) => {\n            if (value !== 'discrete') {\n                throw (0,_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidStateError)();\n            }\n        }\n    });\n};\n//# sourceMappingURL=wrap-channel-splitter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-channel-splitter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapEventListener\": () => (/* binding */ wrapEventListener)\n/* harmony export */ });\nconst wrapEventListener = (target, eventListener) => {\n    return (event) => {\n        const descriptor = { value: target };\n        Object.defineProperties(event, {\n            currentTarget: descriptor,\n            target: descriptor\n        });\n        if (typeof eventListener === 'function') {\n            return eventListener.call(target, event);\n        }\n        return eventListener.handleEvent.call(target, event);\n    };\n};\n//# sourceMappingURL=wrap-event-listener.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"wrapIIRFilterNodeGetFrequencyResponseMethod\": () => (/* binding */ wrapIIRFilterNodeGetFrequencyResponseMethod)\n/* harmony export */ });\n/* harmony import */ var _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../factories/invalid-access-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js\");\n\nconst wrapIIRFilterNodeGetFrequencyResponseMethod = (nativeIIRFilterNode) => {\n    nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse) => {\n        return (frequencyHz, magResponse, phaseResponse) => {\n            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) {\n                throw (0,_factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_0__.createInvalidAccessError)();\n            }\n            return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);\n        };\n    })(nativeIIRFilterNode.getFrequencyResponse);\n};\n//# sourceMappingURL=wrap-iir-filter-node-get-frequency-response-method.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/helpers/wrap-iir-filter-node-get-frequency-response-method.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-listener.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-descriptor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-scheduled-source-node-event-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-scheduled-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-event-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-processor-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-processor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=automation.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=base-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=common-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=common-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-target.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/index.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/index.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _analyser_node__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./analyser-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-node.js\");\n/* harmony import */ var _analyser_options__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./analyser-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/analyser-options.js\");\n/* harmony import */ var _audio_buffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./audio-buffer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer.js\");\n/* harmony import */ var _audio_buffer_options__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./audio-buffer-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-options.js\");\n/* harmony import */ var _audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./audio-buffer-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-node-renderer.js\");\n/* harmony import */ var _audio_buffer_source_options__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./audio-buffer-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-buffer-source-options.js\");\n/* harmony import */ var _audio_context__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context.js\");\n/* harmony import */ var _audio_context_options__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./audio-context-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-context-options.js\");\n/* harmony import */ var _audio_destination_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-destination-node.js\");\n/* harmony import */ var _audio_listener__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./audio-listener */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-listener.js\");\n/* harmony import */ var _audio_node__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./audio-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node.js\");\n/* harmony import */ var _audio_node_options__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./audio-node-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-options.js\");\n/* harmony import */ var _audio_node_renderer__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./audio-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-node-renderer.js\");\n/* harmony import */ var _audio_param__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./audio-param */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param.js\");\n/* harmony import */ var _audio_param_descriptor__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./audio-param-descriptor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-descriptor.js\");\n/* harmony import */ var _audio_param_renderer__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./audio-param-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-param-renderer.js\");\n/* harmony import */ var _audio_scheduled_source_node__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./audio-scheduled-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node.js\");\n/* harmony import */ var _audio_scheduled_source_node_event_map__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./audio-scheduled-source-node-event-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-scheduled-source-node-event-map.js\");\n/* harmony import */ var _audio_worklet__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./audio-worklet */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet.js\");\n/* harmony import */ var _audio_worklet_node__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node.js\");\n/* harmony import */ var _audio_worklet_node_event_map__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./audio-worklet-node-event-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-event-map.js\");\n/* harmony import */ var _audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-node-options.js\");\n/* harmony import */ var _audio_worklet_processor__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./audio-worklet-processor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor.js\");\n/* harmony import */ var _audio_worklet_processor_constructor__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./audio-worklet-processor-constructor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/audio-worklet-processor-constructor.js\");\n/* harmony import */ var _automation__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./automation */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/automation.js\");\n/* harmony import */ var _base_audio_context__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./base-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/base-audio-context.js\");\n/* harmony import */ var _biquad_filter_node__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-node.js\");\n/* harmony import */ var _biquad_filter_options__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./biquad-filter-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/biquad-filter-options.js\");\n/* harmony import */ var _channel_merger_options__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./channel-merger-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/channel-merger-options.js\");\n/* harmony import */ var _channel_splitter_options__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./channel-splitter-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/channel-splitter-options.js\");\n/* harmony import */ var _common_audio_context__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./common-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/common-audio-context.js\");\n/* harmony import */ var _common_offline_audio_context__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./common-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/common-offline-audio-context.js\");\n/* harmony import */ var _constant_source_node__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./constant-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node.js\");\n/* harmony import */ var _constant_source_node_renderer__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./constant-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-node-renderer.js\");\n/* harmony import */ var _constant_source_options__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./constant-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/constant-source-options.js\");\n/* harmony import */ var _convolver_node__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./convolver-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-node.js\");\n/* harmony import */ var _convolver_options__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./convolver-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/convolver-options.js\");\n/* harmony import */ var _delay_node__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./delay-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/delay-node.js\");\n/* harmony import */ var _delay_options__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./delay-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/delay-options.js\");\n/* harmony import */ var _dynamics_compressor_node__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./dynamics-compressor-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-node.js\");\n/* harmony import */ var _dynamics_compressor_options__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./dynamics-compressor-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/dynamics-compressor-options.js\");\n/* harmony import */ var _event_target__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./event-target */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/event-target.js\");\n/* harmony import */ var _gain_node__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./gain-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/gain-node.js\");\n/* harmony import */ var _gain_options__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./gain-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/gain-options.js\");\n/* harmony import */ var _iir_filter_node__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./iir-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-node.js\");\n/* harmony import */ var _iir_filter_options__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./iir-filter-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/iir-filter-options.js\");\n/* harmony import */ var _media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./media-element-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js\");\n/* harmony import */ var _media_element_audio_source_options__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./media-element-audio-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js\");\n/* harmony import */ var _media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./media-stream-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js\");\n/* harmony import */ var _media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./media-stream-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js\");\n/* harmony import */ var _media_stream_audio_source_options__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./media-stream-audio-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js\");\n/* harmony import */ var _media_stream_track_audio_source_node__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./media-stream-track-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js\");\n/* harmony import */ var _media_stream_track_audio_source_options__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./media-stream-track-audio-source-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js\");\n/* harmony import */ var _minimal_audio_context__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./minimal-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js\");\n/* harmony import */ var _minimal_base_audio_context__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./minimal-base-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js\");\n/* harmony import */ var _minimal_base_audio_context_event_map__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./minimal-base-audio-context-event-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js\");\n/* harmony import */ var _minimal_offline_audio_context__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./minimal-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js\");\n/* harmony import */ var _native_audio_node_faker__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./native-audio-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js\");\n/* harmony import */ var _native_audio_worklet_node_faker__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./native-audio-worklet-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js\");\n/* harmony import */ var _native_constant_source_node_faker__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./native-constant-source-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js\");\n/* harmony import */ var _native_convolver_node_faker__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./native-convolver-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js\");\n/* harmony import */ var _native_iir_filter_node_faker__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./native-iir-filter-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js\");\n/* harmony import */ var _native_panner_node_faker__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./native-panner-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js\");\n/* harmony import */ var _native_stereo_panner_node_faker__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./native-stereo-panner-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js\");\n/* harmony import */ var _native_wave_shaper_node_faker__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./native-wave-shaper-node-faker */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js\");\n/* harmony import */ var _offline_audio_completion_event__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./offline-audio-completion-event */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js\");\n/* harmony import */ var _offline_audio_context__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js\");\n/* harmony import */ var _offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js\");\n/* harmony import */ var _offline_audio_context_options__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./offline-audio-context-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js\");\n/* harmony import */ var _oscillator_node__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./oscillator-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js\");\n/* harmony import */ var _oscillator_node_renderer__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./oscillator-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js\");\n/* harmony import */ var _oscillator_options__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./oscillator-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js\");\n/* harmony import */ var _panner_node__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./panner-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js\");\n/* harmony import */ var _panner_options__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./panner-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js\");\n/* harmony import */ var _periodic_wave__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./periodic-wave */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js\");\n/* harmony import */ var _periodic_wave_constraints__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./periodic-wave-constraints */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js\");\n/* harmony import */ var _periodic_wave_options__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./periodic-wave-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js\");\n/* harmony import */ var _read_only_map__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./read-only-map */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js\");\n/* harmony import */ var _stereo_panner_node__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./stereo-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js\");\n/* harmony import */ var _stereo_panner_options__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./stereo-panner-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js\");\n/* harmony import */ var _wave_shaper_node__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./wave-shaper-node */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js\");\n/* harmony import */ var _wave_shaper_options__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./wave-shaper-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js\");\n/* harmony import */ var _worklet_options__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./worklet-options */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/index.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-element-audio-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-destination-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-audio-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/media-stream-track-audio-source-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context-event-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context-event-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-base-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/minimal-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-audio-worklet-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-constant-source-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-convolver-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-iir-filter-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-panner-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-stereo-panner-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-faker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/native-wave-shaper-node-faker.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-completion-event.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-completion-event.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/oscillator-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/panner-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-constraints.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-constraints.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/periodic-wave.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=read-only-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/read-only-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/stereo-panner-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/wave-shaper-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// @todo This is currently named IWorkletOptions and not IAudioWorkletOptions because it defines the options of a generic Worklet.\n\n//# sourceMappingURL=worklet-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/interfaces/worklet-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/module.js":
/*!************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/module.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AnalyserNode\": () => (/* binding */ analyserNodeConstructor),\n/* harmony export */   \"AudioBuffer\": () => (/* binding */ audioBufferConstructor),\n/* harmony export */   \"AudioBufferSourceNode\": () => (/* binding */ audioBufferSourceNodeConstructor),\n/* harmony export */   \"AudioContext\": () => (/* binding */ audioContextConstructor),\n/* harmony export */   \"AudioWorkletNode\": () => (/* binding */ audioWorkletNodeConstructor),\n/* harmony export */   \"BiquadFilterNode\": () => (/* binding */ biquadFilterNodeConstructor),\n/* harmony export */   \"ChannelMergerNode\": () => (/* binding */ channelMergerNodeConstructor),\n/* harmony export */   \"ChannelSplitterNode\": () => (/* binding */ channelSplitterNodeConstructor),\n/* harmony export */   \"ConstantSourceNode\": () => (/* binding */ constantSourceNodeConstructor),\n/* harmony export */   \"ConvolverNode\": () => (/* binding */ convolverNodeConstructor),\n/* harmony export */   \"DelayNode\": () => (/* binding */ delayNodeConstructor),\n/* harmony export */   \"DynamicsCompressorNode\": () => (/* binding */ dynamicsCompressorNodeConstructor),\n/* harmony export */   \"GainNode\": () => (/* binding */ gainNodeConstructor),\n/* harmony export */   \"IIRFilterNode\": () => (/* binding */ iIRFilterNodeConstructor),\n/* harmony export */   \"MediaElementAudioSourceNode\": () => (/* binding */ mediaElementAudioSourceNodeConstructor),\n/* harmony export */   \"MediaStreamAudioDestinationNode\": () => (/* binding */ mediaStreamAudioDestinationNodeConstructor),\n/* harmony export */   \"MediaStreamAudioSourceNode\": () => (/* binding */ mediaStreamAudioSourceNodeConstructor),\n/* harmony export */   \"MediaStreamTrackAudioSourceNode\": () => (/* binding */ mediaStreamTrackAudioSourceNodeConstructor),\n/* harmony export */   \"MinimalAudioContext\": () => (/* binding */ minimalAudioContextConstructor),\n/* harmony export */   \"MinimalOfflineAudioContext\": () => (/* binding */ minimalOfflineAudioContextConstructor),\n/* harmony export */   \"OfflineAudioContext\": () => (/* binding */ offlineAudioContextConstructor),\n/* harmony export */   \"OscillatorNode\": () => (/* binding */ oscillatorNodeConstructor),\n/* harmony export */   \"PannerNode\": () => (/* binding */ pannerNodeConstructor),\n/* harmony export */   \"PeriodicWave\": () => (/* binding */ periodicWaveConstructor),\n/* harmony export */   \"StereoPannerNode\": () => (/* binding */ stereoPannerNodeConstructor),\n/* harmony export */   \"WaveShaperNode\": () => (/* binding */ waveShaperNodeConstructor),\n/* harmony export */   \"addAudioWorkletModule\": () => (/* binding */ addAudioWorkletModule),\n/* harmony export */   \"decodeAudioData\": () => (/* binding */ decodeAudioData),\n/* harmony export */   \"isAnyAudioContext\": () => (/* binding */ isAnyAudioContext),\n/* harmony export */   \"isAnyAudioNode\": () => (/* binding */ isAnyAudioNode),\n/* harmony export */   \"isAnyAudioParam\": () => (/* binding */ isAnyAudioParam),\n/* harmony export */   \"isAnyOfflineAudioContext\": () => (/* binding */ isAnyOfflineAudioContext),\n/* harmony export */   \"isSupported\": () => (/* binding */ isSupported)\n/* harmony export */ });\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! automation-events */ \"./node_modules/automation-events/build/es5/bundle.js\");\n/* harmony import */ var automation_events__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(automation_events__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _factories_abort_error__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./factories/abort-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/abort-error.js\");\n/* harmony import */ var _factories_add_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./factories/add-active-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-active-input-connection-to-audio-node.js\");\n/* harmony import */ var _factories_add_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./factories/add-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-audio-node-connections.js\");\n/* harmony import */ var _factories_add_audio_param_connections__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./factories/add-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-audio-param-connections.js\");\n/* harmony import */ var _factories_add_audio_worklet_module__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./factories/add-audio-worklet-module */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-audio-worklet-module.js\");\n/* harmony import */ var _factories_add_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./factories/add-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-connection-to-audio-node.js\");\n/* harmony import */ var _factories_add_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./factories/add-passive-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-passive-input-connection-to-audio-node.js\");\n/* harmony import */ var _factories_add_silent_connection__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./factories/add-silent-connection */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-silent-connection.js\");\n/* harmony import */ var _factories_add_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./factories/add-unrendered-audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/add-unrendered-audio-worklet-node.js\");\n/* harmony import */ var _factories_analyser_node_constructor__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./factories/analyser-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-constructor.js\");\n/* harmony import */ var _factories_analyser_node_renderer_factory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./factories/analyser-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/analyser-node-renderer-factory.js\");\n/* harmony import */ var _factories_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./factories/audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-constructor.js\");\n/* harmony import */ var _factories_audio_buffer_source_node_constructor__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./factories/audio-buffer-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-constructor.js\");\n/* harmony import */ var _factories_audio_buffer_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./factories/audio-buffer-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-buffer-source-node-renderer-factory.js\");\n/* harmony import */ var _factories_audio_context_constructor__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./factories/audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-context-constructor.js\");\n/* harmony import */ var _factories_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./factories/audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-constructor.js\");\n/* harmony import */ var _factories_audio_destination_node_renderer_factory__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./factories/audio-destination-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-destination-node-renderer-factory.js\");\n/* harmony import */ var _factories_audio_listener_factory__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./factories/audio-listener-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-listener-factory.js\");\n/* harmony import */ var _factories_audio_node_constructor__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./factories/audio-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-node-constructor.js\");\n/* harmony import */ var _factories_audio_param_factory__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./factories/audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-param-factory.js\");\n/* harmony import */ var _factories_audio_param_renderer__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./factories/audio-param-renderer */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-param-renderer.js\");\n/* harmony import */ var _factories_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./factories/audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-constructor.js\");\n/* harmony import */ var _factories_audio_worklet_node_renderer_factory__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./factories/audio-worklet-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/audio-worklet-node-renderer-factory.js\");\n/* harmony import */ var _factories_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./factories/base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/base-audio-context-constructor.js\");\n/* harmony import */ var _factories_biquad_filter_node_constructor__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./factories/biquad-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-constructor.js\");\n/* harmony import */ var _factories_biquad_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./factories/biquad-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/biquad-filter-node-renderer-factory.js\");\n/* harmony import */ var _factories_cache_test_result__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./factories/cache-test-result */ \"./node_modules/standardized-audio-context/build/es2019/factories/cache-test-result.js\");\n/* harmony import */ var _factories_channel_merger_node_constructor__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./factories/channel-merger-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-constructor.js\");\n/* harmony import */ var _factories_channel_merger_node_renderer_factory__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./factories/channel-merger-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-merger-node-renderer-factory.js\");\n/* harmony import */ var _factories_channel_splitter_node_constructor__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./factories/channel-splitter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-constructor.js\");\n/* harmony import */ var _factories_channel_splitter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./factories/channel-splitter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/channel-splitter-node-renderer-factory.js\");\n/* harmony import */ var _factories_connect_audio_param__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./factories/connect-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/connect-audio-param.js\");\n/* harmony import */ var _factories_connect_multiple_outputs__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./factories/connect-multiple-outputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/connect-multiple-outputs.js\");\n/* harmony import */ var _factories_connected_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./factories/connected-native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/connected-native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _factories_constant_source_node_constructor__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./factories/constant-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-constructor.js\");\n/* harmony import */ var _factories_constant_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./factories/constant-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/constant-source-node-renderer-factory.js\");\n/* harmony import */ var _factories_convert_number_to_unsigned_long__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./factories/convert-number-to-unsigned-long */ \"./node_modules/standardized-audio-context/build/es2019/factories/convert-number-to-unsigned-long.js\");\n/* harmony import */ var _factories_convolver_node_constructor__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./factories/convolver-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-constructor.js\");\n/* harmony import */ var _factories_convolver_node_renderer_factory__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./factories/convolver-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/convolver-node-renderer-factory.js\");\n/* harmony import */ var _factories_create_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./factories/create-native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/create-native-offline-audio-context.js\");\n/* harmony import */ var _factories_data_clone_error__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./factories/data-clone-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/data-clone-error.js\");\n/* harmony import */ var _factories_decode_audio_data__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./factories/decode-audio-data */ \"./node_modules/standardized-audio-context/build/es2019/factories/decode-audio-data.js\");\n/* harmony import */ var _factories_decrement_cycle_counter__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./factories/decrement-cycle-counter */ \"./node_modules/standardized-audio-context/build/es2019/factories/decrement-cycle-counter.js\");\n/* harmony import */ var _factories_delay_node_constructor__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./factories/delay-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/delay-node-constructor.js\");\n/* harmony import */ var _factories_delay_node_renderer_factory__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./factories/delay-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/delay-node-renderer-factory.js\");\n/* harmony import */ var _factories_delete_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./factories/delete-active-input-connection-to-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/delete-active-input-connection-to-audio-node.js\");\n/* harmony import */ var _factories_delete_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./factories/delete-unrendered-audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/delete-unrendered-audio-worklet-node.js\");\n/* harmony import */ var _factories_detect_cycles__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./factories/detect-cycles */ \"./node_modules/standardized-audio-context/build/es2019/factories/detect-cycles.js\");\n/* harmony import */ var _factories_disconnect_multiple_outputs__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./factories/disconnect-multiple-outputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/disconnect-multiple-outputs.js\");\n/* harmony import */ var _factories_dynamics_compressor_node_constructor__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./factories/dynamics-compressor-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-constructor.js\");\n/* harmony import */ var _factories_dynamics_compressor_node_renderer_factory__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./factories/dynamics-compressor-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/dynamics-compressor-node-renderer-factory.js\");\n/* harmony import */ var _factories_encoding_error__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./factories/encoding-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/encoding-error.js\");\n/* harmony import */ var _factories_evaluate_source__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./factories/evaluate-source */ \"./node_modules/standardized-audio-context/build/es2019/factories/evaluate-source.js\");\n/* harmony import */ var _factories_event_target_constructor__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./factories/event-target-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/event-target-constructor.js\");\n/* harmony import */ var _factories_expose_current_frame_and_current_time__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./factories/expose-current-frame-and-current-time */ \"./node_modules/standardized-audio-context/build/es2019/factories/expose-current-frame-and-current-time.js\");\n/* harmony import */ var _factories_fetch_source__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./factories/fetch-source */ \"./node_modules/standardized-audio-context/build/es2019/factories/fetch-source.js\");\n/* harmony import */ var _factories_gain_node_constructor__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./factories/gain-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/gain-node-constructor.js\");\n/* harmony import */ var _factories_gain_node_renderer_factory__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./factories/gain-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/gain-node-renderer-factory.js\");\n/* harmony import */ var _factories_get_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./factories/get-active-audio-worklet-node-inputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-active-audio-worklet-node-inputs.js\");\n/* harmony import */ var _factories_get_audio_node_renderer__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./factories/get-audio-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-renderer.js\");\n/* harmony import */ var _factories_get_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./factories/get-audio-node-tail-time */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-audio-node-tail-time.js\");\n/* harmony import */ var _factories_get_audio_param_renderer__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./factories/get-audio-param-renderer */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-audio-param-renderer.js\");\n/* harmony import */ var _factories_get_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./factories/get-backup-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-backup-offline-audio-context.js\");\n/* harmony import */ var _factories_get_native_context__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./factories/get-native-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-native-context.js\");\n/* harmony import */ var _factories_get_or_create_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./factories/get-or-create-backup-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-or-create-backup-offline-audio-context.js\");\n/* harmony import */ var _factories_get_unrendered_audio_worklet_nodes__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./factories/get-unrendered-audio-worklet-nodes */ \"./node_modules/standardized-audio-context/build/es2019/factories/get-unrendered-audio-worklet-nodes.js\");\n/* harmony import */ var _factories_iir_filter_node_constructor__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./factories/iir-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-constructor.js\");\n/* harmony import */ var _factories_iir_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./factories/iir-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/iir-filter-node-renderer-factory.js\");\n/* harmony import */ var _factories_increment_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./factories/increment-cycle-counter-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/increment-cycle-counter-factory.js\");\n/* harmony import */ var _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./factories/index-size-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/index-size-error.js\");\n/* harmony import */ var _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./factories/invalid-access-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-access-error.js\");\n/* harmony import */ var _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./factories/invalid-state-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/invalid-state-error.js\");\n/* harmony import */ var _factories_is_any_audio_context__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./factories/is-any-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-context.js\");\n/* harmony import */ var _factories_is_any_audio_node__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./factories/is-any-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-node.js\");\n/* harmony import */ var _factories_is_any_audio_param__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./factories/is-any-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-audio-param.js\");\n/* harmony import */ var _factories_is_any_offline_audio_context__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./factories/is-any-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-any-offline-audio-context.js\");\n/* harmony import */ var _factories_is_native_audio_context__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./factories/is-native-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-context.js\");\n/* harmony import */ var _factories_is_native_audio_node__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./factories/is-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-node.js\");\n/* harmony import */ var _factories_is_native_audio_param__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./factories/is-native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-audio-param.js\");\n/* harmony import */ var _factories_is_native_context__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./factories/is-native-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-context.js\");\n/* harmony import */ var _factories_is_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./factories/is-native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-native-offline-audio-context.js\");\n/* harmony import */ var _factories_is_secure_context__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./factories/is-secure-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-secure-context.js\");\n/* harmony import */ var _factories_is_supported_promise__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./factories/is-supported-promise */ \"./node_modules/standardized-audio-context/build/es2019/factories/is-supported-promise.js\");\n/* harmony import */ var _factories_media_element_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./factories/media-element-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-element-audio-source-node-constructor.js\");\n/* harmony import */ var _factories_media_stream_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./factories/media-stream-audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-destination-node-constructor.js\");\n/* harmony import */ var _factories_media_stream_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./factories/media-stream-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-stream-audio-source-node-constructor.js\");\n/* harmony import */ var _factories_media_stream_track_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./factories/media-stream-track-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/media-stream-track-audio-source-node-constructor.js\");\n/* harmony import */ var _factories_minimal_audio_context_constructor__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./factories/minimal-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/minimal-audio-context-constructor.js\");\n/* harmony import */ var _factories_minimal_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_89__ = __webpack_require__(/*! ./factories/minimal-base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/minimal-base-audio-context-constructor.js\");\n/* harmony import */ var _factories_minimal_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_90__ = __webpack_require__(/*! ./factories/minimal-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/minimal-offline-audio-context-constructor.js\");\n/* harmony import */ var _factories_monitor_connections__WEBPACK_IMPORTED_MODULE_91__ = __webpack_require__(/*! ./factories/monitor-connections */ \"./node_modules/standardized-audio-context/build/es2019/factories/monitor-connections.js\");\n/* harmony import */ var _factories_native_analyser_node_factory__WEBPACK_IMPORTED_MODULE_92__ = __webpack_require__(/*! ./factories/native-analyser-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-analyser-node-factory.js\");\n/* harmony import */ var _factories_native_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_93__ = __webpack_require__(/*! ./factories/native-audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-constructor.js\");\n/* harmony import */ var _factories_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_94__ = __webpack_require__(/*! ./factories/native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _factories_native_audio_context_constructor__WEBPACK_IMPORTED_MODULE_95__ = __webpack_require__(/*! ./factories/native-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-context-constructor.js\");\n/* harmony import */ var _factories_native_audio_destination_node__WEBPACK_IMPORTED_MODULE_96__ = __webpack_require__(/*! ./factories/native-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-destination-node.js\");\n/* harmony import */ var _factories_native_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_97__ = __webpack_require__(/*! ./factories/native-audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-constructor.js\");\n/* harmony import */ var _factories_native_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_98__ = __webpack_require__(/*! ./factories/native-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-factory.js\");\n/* harmony import */ var _factories_native_audio_worklet_node_faker_factory__WEBPACK_IMPORTED_MODULE_99__ = __webpack_require__(/*! ./factories/native-audio-worklet-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-audio-worklet-node-faker-factory.js\");\n/* harmony import */ var _factories_native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_100__ = __webpack_require__(/*! ./factories/native-biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-biquad-filter-node.js\");\n/* harmony import */ var _factories_native_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_101__ = __webpack_require__(/*! ./factories/native-channel-merger-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-channel-merger-node-factory.js\");\n/* harmony import */ var _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__ = __webpack_require__(/*! ./factories/native-channel-splitter-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-channel-splitter-node.js\");\n/* harmony import */ var _factories_native_constant_source_node_factory__WEBPACK_IMPORTED_MODULE_103__ = __webpack_require__(/*! ./factories/native-constant-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-factory.js\");\n/* harmony import */ var _factories_native_constant_source_node_faker_factory__WEBPACK_IMPORTED_MODULE_104__ = __webpack_require__(/*! ./factories/native-constant-source-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-constant-source-node-faker-factory.js\");\n/* harmony import */ var _factories_native_convolver_node_factory__WEBPACK_IMPORTED_MODULE_105__ = __webpack_require__(/*! ./factories/native-convolver-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-convolver-node-factory.js\");\n/* harmony import */ var _factories_native_delay_node__WEBPACK_IMPORTED_MODULE_106__ = __webpack_require__(/*! ./factories/native-delay-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-delay-node.js\");\n/* harmony import */ var _factories_native_dynamics_compressor_node_factory__WEBPACK_IMPORTED_MODULE_107__ = __webpack_require__(/*! ./factories/native-dynamics-compressor-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-dynamics-compressor-node-factory.js\");\n/* harmony import */ var _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__ = __webpack_require__(/*! ./factories/native-gain-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-gain-node.js\");\n/* harmony import */ var _factories_native_iir_filter_node_factory__WEBPACK_IMPORTED_MODULE_109__ = __webpack_require__(/*! ./factories/native-iir-filter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-factory.js\");\n/* harmony import */ var _factories_native_iir_filter_node_faker_factory__WEBPACK_IMPORTED_MODULE_110__ = __webpack_require__(/*! ./factories/native-iir-filter-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-iir-filter-node-faker-factory.js\");\n/* harmony import */ var _factories_native_media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_111__ = __webpack_require__(/*! ./factories/native-media-element-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-element-audio-source-node.js\");\n/* harmony import */ var _factories_native_media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_112__ = __webpack_require__(/*! ./factories/native-media-stream-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-destination-node.js\");\n/* harmony import */ var _factories_native_media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_113__ = __webpack_require__(/*! ./factories/native-media-stream-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-audio-source-node.js\");\n/* harmony import */ var _factories_native_media_stream_track_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_114__ = __webpack_require__(/*! ./factories/native-media-stream-track-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-media-stream-track-audio-source-node-factory.js\");\n/* harmony import */ var _factories_native_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_115__ = __webpack_require__(/*! ./factories/native-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-offline-audio-context-constructor.js\");\n/* harmony import */ var _factories_native_oscillator_node_factory__WEBPACK_IMPORTED_MODULE_116__ = __webpack_require__(/*! ./factories/native-oscillator-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-oscillator-node-factory.js\");\n/* harmony import */ var _factories_native_panner_node_factory__WEBPACK_IMPORTED_MODULE_117__ = __webpack_require__(/*! ./factories/native-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-factory.js\");\n/* harmony import */ var _factories_native_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_118__ = __webpack_require__(/*! ./factories/native-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-panner-node-faker-factory.js\");\n/* harmony import */ var _factories_native_periodic_wave_factory__WEBPACK_IMPORTED_MODULE_119__ = __webpack_require__(/*! ./factories/native-periodic-wave-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-periodic-wave-factory.js\");\n/* harmony import */ var _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__ = __webpack_require__(/*! ./factories/native-script-processor-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-script-processor-node.js\");\n/* harmony import */ var _factories_native_stereo_panner_node_factory__WEBPACK_IMPORTED_MODULE_121__ = __webpack_require__(/*! ./factories/native-stereo-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-factory.js\");\n/* harmony import */ var _factories_native_stereo_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_122__ = __webpack_require__(/*! ./factories/native-stereo-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-stereo-panner-node-faker-factory.js\");\n/* harmony import */ var _factories_native_wave_shaper_node_factory__WEBPACK_IMPORTED_MODULE_123__ = __webpack_require__(/*! ./factories/native-wave-shaper-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-factory.js\");\n/* harmony import */ var _factories_native_wave_shaper_node_faker_factory__WEBPACK_IMPORTED_MODULE_124__ = __webpack_require__(/*! ./factories/native-wave-shaper-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/native-wave-shaper-node-faker-factory.js\");\n/* harmony import */ var _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__ = __webpack_require__(/*! ./factories/not-supported-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/not-supported-error.js\");\n/* harmony import */ var _factories_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_126__ = __webpack_require__(/*! ./factories/offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/offline-audio-context-constructor.js\");\n/* harmony import */ var _factories_oscillator_node_constructor__WEBPACK_IMPORTED_MODULE_127__ = __webpack_require__(/*! ./factories/oscillator-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-constructor.js\");\n/* harmony import */ var _factories_oscillator_node_renderer_factory__WEBPACK_IMPORTED_MODULE_128__ = __webpack_require__(/*! ./factories/oscillator-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/oscillator-node-renderer-factory.js\");\n/* harmony import */ var _factories_panner_node_constructor__WEBPACK_IMPORTED_MODULE_129__ = __webpack_require__(/*! ./factories/panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/panner-node-constructor.js\");\n/* harmony import */ var _factories_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_130__ = __webpack_require__(/*! ./factories/panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/panner-node-renderer-factory.js\");\n/* harmony import */ var _factories_periodic_wave_constructor__WEBPACK_IMPORTED_MODULE_131__ = __webpack_require__(/*! ./factories/periodic-wave-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/periodic-wave-constructor.js\");\n/* harmony import */ var _factories_render_automation__WEBPACK_IMPORTED_MODULE_132__ = __webpack_require__(/*! ./factories/render-automation */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-automation.js\");\n/* harmony import */ var _factories_render_inputs_of_audio_node__WEBPACK_IMPORTED_MODULE_133__ = __webpack_require__(/*! ./factories/render-inputs-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-node.js\");\n/* harmony import */ var _factories_render_inputs_of_audio_param__WEBPACK_IMPORTED_MODULE_134__ = __webpack_require__(/*! ./factories/render-inputs-of-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-inputs-of-audio-param.js\");\n/* harmony import */ var _factories_render_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_135__ = __webpack_require__(/*! ./factories/render-native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/factories/render-native-offline-audio-context.js\");\n/* harmony import */ var _factories_set_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_136__ = __webpack_require__(/*! ./factories/set-active-audio-worklet-node-inputs */ \"./node_modules/standardized-audio-context/build/es2019/factories/set-active-audio-worklet-node-inputs.js\");\n/* harmony import */ var _factories_set_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_137__ = __webpack_require__(/*! ./factories/set-audio-node-tail-time */ \"./node_modules/standardized-audio-context/build/es2019/factories/set-audio-node-tail-time.js\");\n/* harmony import */ var _factories_start_rendering__WEBPACK_IMPORTED_MODULE_138__ = __webpack_require__(/*! ./factories/start-rendering */ \"./node_modules/standardized-audio-context/build/es2019/factories/start-rendering.js\");\n/* harmony import */ var _factories_stereo_panner_node_constructor__WEBPACK_IMPORTED_MODULE_139__ = __webpack_require__(/*! ./factories/stereo-panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-constructor.js\");\n/* harmony import */ var _factories_stereo_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_140__ = __webpack_require__(/*! ./factories/stereo-panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/stereo-panner-node-renderer-factory.js\");\n/* harmony import */ var _factories_test_audio_buffer_constructor_support__WEBPACK_IMPORTED_MODULE_141__ = __webpack_require__(/*! ./factories/test-audio-buffer-constructor-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-constructor-support.js\");\n/* harmony import */ var _factories_test_audio_buffer_copy_channel_methods_subarray_support__WEBPACK_IMPORTED_MODULE_142__ = __webpack_require__(/*! ./factories/test-audio-buffer-copy-channel-methods-subarray-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-buffer-copy-channel-methods-subarray-support.js\");\n/* harmony import */ var _factories_test_audio_context_close_method_support__WEBPACK_IMPORTED_MODULE_143__ = __webpack_require__(/*! ./factories/test-audio-context-close-method-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-close-method-support.js\");\n/* harmony import */ var _factories_test_audio_context_decode_audio_data_method_type_error_support__WEBPACK_IMPORTED_MODULE_144__ = __webpack_require__(/*! ./factories/test-audio-context-decode-audio-data-method-type-error-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-decode-audio-data-method-type-error-support.js\");\n/* harmony import */ var _factories_test_audio_context_options_support__WEBPACK_IMPORTED_MODULE_145__ = __webpack_require__(/*! ./factories/test-audio-context-options-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-context-options-support.js\");\n/* harmony import */ var _factories_test_audio_node_connect_method_support__WEBPACK_IMPORTED_MODULE_146__ = __webpack_require__(/*! ./factories/test-audio-node-connect-method-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-node-connect-method-support.js\");\n/* harmony import */ var _factories_test_audio_worklet_processor_no_outputs_support__WEBPACK_IMPORTED_MODULE_147__ = __webpack_require__(/*! ./factories/test-audio-worklet-processor-no-outputs-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-no-outputs-support.js\");\n/* harmony import */ var _factories_test_audio_worklet_processor_post_message_support__WEBPACK_IMPORTED_MODULE_148__ = __webpack_require__(/*! ./factories/test-audio-worklet-processor-post-message-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-audio-worklet-processor-post-message-support.js\");\n/* harmony import */ var _factories_test_channel_merger_node_channel_count_support__WEBPACK_IMPORTED_MODULE_149__ = __webpack_require__(/*! ./factories/test-channel-merger-node-channel-count-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-channel-merger-node-channel-count-support.js\");\n/* harmony import */ var _factories_test_constant_source_node_accurate_scheduling_support__WEBPACK_IMPORTED_MODULE_150__ = __webpack_require__(/*! ./factories/test-constant-source-node-accurate-scheduling-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-constant-source-node-accurate-scheduling-support.js\");\n/* harmony import */ var _factories_test_convolver_node_buffer_reassignability_support__WEBPACK_IMPORTED_MODULE_151__ = __webpack_require__(/*! ./factories/test-convolver-node-buffer-reassignability-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-buffer-reassignability-support.js\");\n/* harmony import */ var _factories_test_convolver_node_channel_count_support__WEBPACK_IMPORTED_MODULE_152__ = __webpack_require__(/*! ./factories/test-convolver-node-channel-count-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-convolver-node-channel-count-support.js\");\n/* harmony import */ var _factories_test_is_secure_context_support__WEBPACK_IMPORTED_MODULE_153__ = __webpack_require__(/*! ./factories/test-is-secure-context-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-is-secure-context-support.js\");\n/* harmony import */ var _factories_test_media_stream_audio_source_node_media_stream_without_audio_track_support__WEBPACK_IMPORTED_MODULE_154__ = __webpack_require__(/*! ./factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js\");\n/* harmony import */ var _factories_test_offline_audio_context_current_time_support__WEBPACK_IMPORTED_MODULE_155__ = __webpack_require__(/*! ./factories/test-offline-audio-context-current-time-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-offline-audio-context-current-time-support.js\");\n/* harmony import */ var _factories_test_stereo_panner_node_default_value_support__WEBPACK_IMPORTED_MODULE_156__ = __webpack_require__(/*! ./factories/test-stereo-panner-node-default-value-support */ \"./node_modules/standardized-audio-context/build/es2019/factories/test-stereo-panner-node-default-value-support.js\");\n/* harmony import */ var _factories_unknown_error__WEBPACK_IMPORTED_MODULE_157__ = __webpack_require__(/*! ./factories/unknown-error */ \"./node_modules/standardized-audio-context/build/es2019/factories/unknown-error.js\");\n/* harmony import */ var _factories_wave_shaper_node_constructor__WEBPACK_IMPORTED_MODULE_158__ = __webpack_require__(/*! ./factories/wave-shaper-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-constructor.js\");\n/* harmony import */ var _factories_wave_shaper_node_renderer_factory__WEBPACK_IMPORTED_MODULE_159__ = __webpack_require__(/*! ./factories/wave-shaper-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/factories/wave-shaper-node-renderer-factory.js\");\n/* harmony import */ var _factories_window__WEBPACK_IMPORTED_MODULE_160__ = __webpack_require__(/*! ./factories/window */ \"./node_modules/standardized-audio-context/build/es2019/factories/window.js\");\n/* harmony import */ var _factories_wrap_audio_buffer_copy_channel_methods__WEBPACK_IMPORTED_MODULE_161__ = __webpack_require__(/*! ./factories/wrap-audio-buffer-copy-channel-methods */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods.js\");\n/* harmony import */ var _factories_wrap_audio_buffer_copy_channel_methods_out_of_bounds__WEBPACK_IMPORTED_MODULE_162__ = __webpack_require__(/*! ./factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds.js\");\n/* harmony import */ var _factories_wrap_audio_buffer_source_node_stop_method_nullified_buffer__WEBPACK_IMPORTED_MODULE_163__ = __webpack_require__(/*! ./factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer.js\");\n/* harmony import */ var _factories_wrap_channel_merger_node__WEBPACK_IMPORTED_MODULE_164__ = __webpack_require__(/*! ./factories/wrap-channel-merger-node */ \"./node_modules/standardized-audio-context/build/es2019/factories/wrap-channel-merger-node.js\");\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_165__ = __webpack_require__(/*! ./globals */ \"./node_modules/standardized-audio-context/build/es2019/globals.js\");\n/* harmony import */ var _helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__ = __webpack_require__(/*! ./helpers/connect-native-audio-node-to-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/connect-native-audio-node-to-native-audio-node.js\");\n/* harmony import */ var _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__ = __webpack_require__(/*! ./helpers/disconnect-native-audio-node-from-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/disconnect-native-audio-node-from-native-audio-node.js\");\n/* harmony import */ var _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__ = __webpack_require__(/*! ./helpers/get-audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-node-connections.js\");\n/* harmony import */ var _helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_169__ = __webpack_require__(/*! ./helpers/get-audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-audio-param-connections.js\");\n/* harmony import */ var _helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_170__ = __webpack_require__(/*! ./helpers/get-event-listeners-of-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-event-listeners-of-audio-node.js\");\n/* harmony import */ var _helpers_get_first_sample__WEBPACK_IMPORTED_MODULE_171__ = __webpack_require__(/*! ./helpers/get-first-sample */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-first-sample.js\");\n/* harmony import */ var _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__ = __webpack_require__(/*! ./helpers/get-native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-node.js\");\n/* harmony import */ var _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_173__ = __webpack_require__(/*! ./helpers/get-native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-native-audio-param.js\");\n/* harmony import */ var _helpers_get_value_for_key__WEBPACK_IMPORTED_MODULE_174__ = __webpack_require__(/*! ./helpers/get-value-for-key */ \"./node_modules/standardized-audio-context/build/es2019/helpers/get-value-for-key.js\");\n/* harmony import */ var _helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__ = __webpack_require__(/*! ./helpers/insert-element-in-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/insert-element-in-set.js\");\n/* harmony import */ var _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__ = __webpack_require__(/*! ./helpers/is-active-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-active-audio-node.js\");\n/* harmony import */ var _helpers_is_dc_curve__WEBPACK_IMPORTED_MODULE_177__ = __webpack_require__(/*! ./helpers/is-dc-curve */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-dc-curve.js\");\n/* harmony import */ var _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__ = __webpack_require__(/*! ./helpers/is-part-of-a-cycle */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-part-of-a-cycle.js\");\n/* harmony import */ var _helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_179__ = __webpack_require__(/*! ./helpers/is-passive-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/helpers/is-passive-audio-node.js\");\n/* harmony import */ var _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__ = __webpack_require__(/*! ./helpers/overwrite-accessors */ \"./node_modules/standardized-audio-context/build/es2019/helpers/overwrite-accessors.js\");\n/* harmony import */ var _helpers_pick_element_from_set__WEBPACK_IMPORTED_MODULE_181__ = __webpack_require__(/*! ./helpers/pick-element-from-set */ \"./node_modules/standardized-audio-context/build/es2019/helpers/pick-element-from-set.js\");\n/* harmony import */ var _helpers_sanitize_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_182__ = __webpack_require__(/*! ./helpers/sanitize-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-audio-worklet-node-options.js\");\n/* harmony import */ var _helpers_sanitize_channel_splitter_options__WEBPACK_IMPORTED_MODULE_183__ = __webpack_require__(/*! ./helpers/sanitize-channel-splitter-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-channel-splitter-options.js\");\n/* harmony import */ var _helpers_sanitize_periodic_wave_options__WEBPACK_IMPORTED_MODULE_184__ = __webpack_require__(/*! ./helpers/sanitize-periodic-wave-options */ \"./node_modules/standardized-audio-context/build/es2019/helpers/sanitize-periodic-wave-options.js\");\n/* harmony import */ var _helpers_set_value_at_time_until_possible__WEBPACK_IMPORTED_MODULE_185__ = __webpack_require__(/*! ./helpers/set-value-at-time-until-possible */ \"./node_modules/standardized-audio-context/build/es2019/helpers/set-value-at-time-until-possible.js\");\n/* harmony import */ var _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_186__ = __webpack_require__(/*! ./helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support.js\");\n/* harmony import */ var _helpers_test_audio_buffer_source_node_start_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_187__ = __webpack_require__(/*! ./helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support.js\");\n/* harmony import */ var _helpers_test_audio_buffer_source_node_start_method_offset_clamping_support__WEBPACK_IMPORTED_MODULE_188__ = __webpack_require__(/*! ./helpers/test-audio-buffer-source-node-start-method-offset-clamping-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-start-method-offset-clamping-support.js\");\n/* harmony import */ var _helpers_test_audio_buffer_source_node_stop_method_nullified_buffer_support__WEBPACK_IMPORTED_MODULE_189__ = __webpack_require__(/*! ./helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support.js\");\n/* harmony import */ var _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__ = __webpack_require__(/*! ./helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support.js\");\n/* harmony import */ var _helpers_test_audio_scheduled_source_node_stop_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_191__ = __webpack_require__(/*! ./helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support.js\");\n/* harmony import */ var _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__ = __webpack_require__(/*! ./helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support.js\");\n/* harmony import */ var _helpers_test_audio_worklet_node_options_clonability__WEBPACK_IMPORTED_MODULE_193__ = __webpack_require__(/*! ./helpers/test-audio-worklet-node-options-clonability */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-audio-worklet-node-options-clonability.js\");\n/* harmony import */ var _helpers_test_dom_exception_constructor_support__WEBPACK_IMPORTED_MODULE_194__ = __webpack_require__(/*! ./helpers/test-dom-exception-constructor-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-dom-exception-constructor-support.js\");\n/* harmony import */ var _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_195__ = __webpack_require__(/*! ./helpers/test-promise-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-promise-support.js\");\n/* harmony import */ var _helpers_test_transferables_support__WEBPACK_IMPORTED_MODULE_196__ = __webpack_require__(/*! ./helpers/test-transferables-support */ \"./node_modules/standardized-audio-context/build/es2019/helpers/test-transferables-support.js\");\n/* harmony import */ var _helpers_wrap_audio_buffer_source_node_start_method_offset_clamping__WEBPACK_IMPORTED_MODULE_197__ = __webpack_require__(/*! ./helpers/wrap-audio-buffer-source-node-start-method-offset-clamping */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-buffer-source-node-start-method-offset-clamping.js\");\n/* harmony import */ var _helpers_wrap_audio_scheduled_source_node_stop_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_198__ = __webpack_require__(/*! ./helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls.js\");\n/* harmony import */ var _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__ = __webpack_require__(/*! ./helpers/wrap-event-listener */ \"./node_modules/standardized-audio-context/build/es2019/helpers/wrap-event-listener.js\");\n/* harmony import */ var _interfaces_index__WEBPACK_IMPORTED_MODULE_200__ = __webpack_require__(/*! ./interfaces/index */ \"./node_modules/standardized-audio-context/build/es2019/interfaces/index.js\");\n/* harmony import */ var _types_index__WEBPACK_IMPORTED_MODULE_201__ = __webpack_require__(/*! ./types/index */ \"./node_modules/standardized-audio-context/build/es2019/types/index.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/*\n * @todo Explicitly referencing the barrel file seems to be necessary when enabling the\n * isolatedModules compiler option.\n */\n\n\nconst addActiveInputConnectionToAudioNode = (0,_factories_add_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_2__.createAddActiveInputConnectionToAudioNode)(_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet);\nconst addPassiveInputConnectionToAudioNode = (0,_factories_add_passive_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_7__.createAddPassiveInputConnectionToAudioNode)(_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet);\nconst deleteActiveInputConnectionToAudioNode = (0,_factories_delete_active_input_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_46__.createDeleteActiveInputConnectionToAudioNode)(_helpers_pick_element_from_set__WEBPACK_IMPORTED_MODULE_181__.pickElementFromSet);\nconst audioNodeTailTimeStore = new WeakMap();\nconst getAudioNodeTailTime = (0,_factories_get_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_61__.createGetAudioNodeTailTime)(audioNodeTailTimeStore);\nconst cacheTestResult = (0,_factories_cache_test_result__WEBPACK_IMPORTED_MODULE_27__.createCacheTestResult)(new Map(), new WeakMap());\nconst window = (0,_factories_window__WEBPACK_IMPORTED_MODULE_160__.createWindow)();\nconst createNativeAnalyserNode = (0,_factories_native_analyser_node_factory__WEBPACK_IMPORTED_MODULE_92__.createNativeAnalyserNodeFactory)(cacheTestResult, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst getAudioNodeRenderer = (0,_factories_get_audio_node_renderer__WEBPACK_IMPORTED_MODULE_60__.createGetAudioNodeRenderer)(_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections);\nconst renderInputsOfAudioNode = (0,_factories_render_inputs_of_audio_node__WEBPACK_IMPORTED_MODULE_133__.createRenderInputsOfAudioNode)(_helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, getAudioNodeRenderer, _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__.isPartOfACycle);\nconst createAnalyserNodeRenderer = (0,_factories_analyser_node_renderer_factory__WEBPACK_IMPORTED_MODULE_11__.createAnalyserNodeRendererFactory)(createNativeAnalyserNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst getNativeContext = (0,_factories_get_native_context__WEBPACK_IMPORTED_MODULE_64__.createGetNativeContext)(_globals__WEBPACK_IMPORTED_MODULE_165__.CONTEXT_STORE);\nconst nativeOfflineAudioContextConstructor = (0,_factories_native_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_115__.createNativeOfflineAudioContextConstructor)(window);\nconst isNativeOfflineAudioContext = (0,_factories_is_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_81__.createIsNativeOfflineAudioContext)(nativeOfflineAudioContextConstructor);\nconst audioParamAudioNodeStore = new WeakMap();\nconst eventTargetConstructor = (0,_factories_event_target_constructor__WEBPACK_IMPORTED_MODULE_54__.createEventTargetConstructor)(_helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst nativeAudioContextConstructor = (0,_factories_native_audio_context_constructor__WEBPACK_IMPORTED_MODULE_95__.createNativeAudioContextConstructor)(window);\nconst isNativeAudioContext = (0,_factories_is_native_audio_context__WEBPACK_IMPORTED_MODULE_77__.createIsNativeAudioContext)(nativeAudioContextConstructor);\nconst isNativeAudioNode = (0,_factories_is_native_audio_node__WEBPACK_IMPORTED_MODULE_78__.createIsNativeAudioNode)(window);\nconst isNativeAudioParam = (0,_factories_is_native_audio_param__WEBPACK_IMPORTED_MODULE_79__.createIsNativeAudioParam)(window);\nconst nativeAudioWorkletNodeConstructor = (0,_factories_native_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_97__.createNativeAudioWorkletNodeConstructor)(window);\nconst audioNodeConstructor = (0,_factories_audio_node_constructor__WEBPACK_IMPORTED_MODULE_19__.createAudioNodeConstructor)((0,_factories_add_audio_node_connections__WEBPACK_IMPORTED_MODULE_3__.createAddAudioNodeConnections)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_NODE_CONNECTIONS_STORE), (0,_factories_add_connection_to_audio_node__WEBPACK_IMPORTED_MODULE_6__.createAddConnectionToAudioNode)(addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, _helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__.connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__.disconnectNativeAudioNodeFromNativeAudioNode, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, getAudioNodeTailTime, _helpers_get_event_listeners_of_audio_node__WEBPACK_IMPORTED_MODULE_170__.getEventListenersOfAudioNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, _helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet, _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__.isActiveAudioNode, _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__.isPartOfACycle, _helpers_is_passive_audio_node__WEBPACK_IMPORTED_MODULE_179__.isPassiveAudioNode), cacheTestResult, (0,_factories_increment_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_69__.createIncrementCycleCounterFactory)(_globals__WEBPACK_IMPORTED_MODULE_165__.CYCLE_COUNTERS, _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__.disconnectNativeAudioNodeFromNativeAudioNode, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_173__.getNativeAudioParam, _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__.isActiveAudioNode), _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__.createInvalidAccessError, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, (0,_factories_decrement_cycle_counter__WEBPACK_IMPORTED_MODULE_43__.createDecrementCycleCounter)(_helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__.connectNativeAudioNodeToNativeAudioNode, _globals__WEBPACK_IMPORTED_MODULE_165__.CYCLE_COUNTERS, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, _helpers_get_native_audio_param__WEBPACK_IMPORTED_MODULE_173__.getNativeAudioParam, getNativeContext, _helpers_is_active_audio_node__WEBPACK_IMPORTED_MODULE_176__.isActiveAudioNode, isNativeOfflineAudioContext), (0,_factories_detect_cycles__WEBPACK_IMPORTED_MODULE_48__.createDetectCycles)(audioParamAudioNodeStore, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, _helpers_get_value_for_key__WEBPACK_IMPORTED_MODULE_174__.getValueForKey), eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor);\nconst analyserNodeConstructor = (0,_factories_analyser_node_constructor__WEBPACK_IMPORTED_MODULE_10__.createAnalyserNodeConstructor)(audioNodeConstructor, createAnalyserNodeRenderer, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext);\n\nconst audioBufferStore = new WeakSet();\nconst nativeAudioBufferConstructor = (0,_factories_native_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_93__.createNativeAudioBufferConstructor)(window);\nconst convertNumberToUnsignedLong = (0,_factories_convert_number_to_unsigned_long__WEBPACK_IMPORTED_MODULE_37__.createConvertNumberToUnsignedLong)(new Uint32Array(1));\nconst wrapAudioBufferCopyChannelMethods = (0,_factories_wrap_audio_buffer_copy_channel_methods__WEBPACK_IMPORTED_MODULE_161__.createWrapAudioBufferCopyChannelMethods)(convertNumberToUnsignedLong, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst wrapAudioBufferCopyChannelMethodsOutOfBounds = (0,_factories_wrap_audio_buffer_copy_channel_methods_out_of_bounds__WEBPACK_IMPORTED_MODULE_162__.createWrapAudioBufferCopyChannelMethodsOutOfBounds)(convertNumberToUnsignedLong);\nconst audioBufferConstructor = (0,_factories_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_12__.createAudioBufferConstructor)(audioBufferStore, cacheTestResult, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, (0,_factories_test_audio_buffer_constructor_support__WEBPACK_IMPORTED_MODULE_141__.createTestAudioBufferConstructorSupport)(nativeAudioBufferConstructor), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\n\nconst addSilentConnection = (0,_factories_add_silent_connection__WEBPACK_IMPORTED_MODULE_8__.createAddSilentConnection)(_factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode);\nconst renderInputsOfAudioParam = (0,_factories_render_inputs_of_audio_param__WEBPACK_IMPORTED_MODULE_134__.createRenderInputsOfAudioParam)(getAudioNodeRenderer, _helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_169__.getAudioParamConnections, _helpers_is_part_of_a_cycle__WEBPACK_IMPORTED_MODULE_178__.isPartOfACycle);\nconst connectAudioParam = (0,_factories_connect_audio_param__WEBPACK_IMPORTED_MODULE_32__.createConnectAudioParam)(renderInputsOfAudioParam);\nconst createNativeAudioBufferSourceNode = (0,_factories_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_94__.createNativeAudioBufferSourceNodeFactory)(addSilentConnection, cacheTestResult, _helpers_test_audio_buffer_source_node_start_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_187__.testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, _helpers_test_audio_buffer_source_node_start_method_offset_clamping_support__WEBPACK_IMPORTED_MODULE_188__.testAudioBufferSourceNodeStartMethodOffsetClampingSupport, _helpers_test_audio_buffer_source_node_stop_method_nullified_buffer_support__WEBPACK_IMPORTED_MODULE_189__.testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _helpers_test_audio_scheduled_source_node_stop_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_191__.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, _helpers_wrap_audio_buffer_source_node_start_method_offset_clamping__WEBPACK_IMPORTED_MODULE_197__.wrapAudioBufferSourceNodeStartMethodOffsetClamping, (0,_factories_wrap_audio_buffer_source_node_stop_method_nullified_buffer__WEBPACK_IMPORTED_MODULE_163__.createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer)(_helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors), _helpers_wrap_audio_scheduled_source_node_stop_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_198__.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);\nconst renderAutomation = (0,_factories_render_automation__WEBPACK_IMPORTED_MODULE_132__.createRenderAutomation)((0,_factories_get_audio_param_renderer__WEBPACK_IMPORTED_MODULE_62__.createGetAudioParamRenderer)(_helpers_get_audio_param_connections__WEBPACK_IMPORTED_MODULE_169__.getAudioParamConnections), renderInputsOfAudioParam);\nconst createAudioBufferSourceNodeRenderer = (0,_factories_audio_buffer_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_14__.createAudioBufferSourceNodeRendererFactory)(connectAudioParam, createNativeAudioBufferSourceNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst createAudioParam = (0,_factories_audio_param_factory__WEBPACK_IMPORTED_MODULE_20__.createAudioParamFactory)((0,_factories_add_audio_param_connections__WEBPACK_IMPORTED_MODULE_4__.createAddAudioParamConnections)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_PARAM_CONNECTIONS_STORE), audioParamAudioNodeStore, _globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_PARAM_STORE, _factories_audio_param_renderer__WEBPACK_IMPORTED_MODULE_21__.createAudioParamRenderer, automation_events__WEBPACK_IMPORTED_MODULE_0__.createCancelAndHoldAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createCancelScheduledValuesAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createExponentialRampToValueAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createLinearRampToValueAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createSetTargetAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createSetValueAutomationEvent, automation_events__WEBPACK_IMPORTED_MODULE_0__.createSetValueCurveAutomationEvent, nativeAudioContextConstructor, _helpers_set_value_at_time_until_possible__WEBPACK_IMPORTED_MODULE_185__.setValueAtTimeUntilPossible);\nconst audioBufferSourceNodeConstructor = (0,_factories_audio_buffer_source_node_constructor__WEBPACK_IMPORTED_MODULE_13__.createAudioBufferSourceNodeConstructor)(audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\n\nconst audioDestinationNodeConstructor = (0,_factories_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_16__.createAudioDestinationNodeConstructor)(audioNodeConstructor, _factories_audio_destination_node_renderer_factory__WEBPACK_IMPORTED_MODULE_17__.createAudioDestinationNodeRenderer, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, (0,_factories_native_audio_destination_node__WEBPACK_IMPORTED_MODULE_96__.createNativeAudioDestinationNodeFactory)(_factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors), getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode);\nconst createBiquadFilterNodeRenderer = (0,_factories_biquad_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_26__.createBiquadFilterNodeRendererFactory)(connectAudioParam, _factories_native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_100__.createNativeBiquadFilterNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst setAudioNodeTailTime = (0,_factories_set_audio_node_tail_time__WEBPACK_IMPORTED_MODULE_137__.createSetAudioNodeTailTime)(audioNodeTailTimeStore);\nconst biquadFilterNodeConstructor = (0,_factories_biquad_filter_node_constructor__WEBPACK_IMPORTED_MODULE_25__.createBiquadFilterNodeConstructor)(audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, _factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__.createInvalidAccessError, _factories_native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_100__.createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst monitorConnections = (0,_factories_monitor_connections__WEBPACK_IMPORTED_MODULE_91__.createMonitorConnections)(_helpers_insert_element_in_set__WEBPACK_IMPORTED_MODULE_175__.insertElementInSet, isNativeAudioNode);\nconst wrapChannelMergerNode = (0,_factories_wrap_channel_merger_node__WEBPACK_IMPORTED_MODULE_164__.createWrapChannelMergerNode)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, monitorConnections);\nconst createNativeChannelMergerNode = (0,_factories_native_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_101__.createNativeChannelMergerNodeFactory)(nativeAudioContextConstructor, wrapChannelMergerNode);\nconst createChannelMergerNodeRenderer = (0,_factories_channel_merger_node_renderer_factory__WEBPACK_IMPORTED_MODULE_29__.createChannelMergerNodeRendererFactory)(createNativeChannelMergerNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst channelMergerNodeConstructor = (0,_factories_channel_merger_node_constructor__WEBPACK_IMPORTED_MODULE_28__.createChannelMergerNodeConstructor)(audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext);\nconst createChannelSplitterNodeRenderer = (0,_factories_channel_splitter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_31__.createChannelSplitterNodeRendererFactory)(_factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst channelSplitterNodeConstructor = (0,_factories_channel_splitter_node_constructor__WEBPACK_IMPORTED_MODULE_30__.createChannelSplitterNodeConstructor)(audioNodeConstructor, createChannelSplitterNodeRenderer, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, _helpers_sanitize_channel_splitter_options__WEBPACK_IMPORTED_MODULE_183__.sanitizeChannelSplitterOptions);\nconst createNativeConstantSourceNodeFaker = (0,_factories_native_constant_source_node_faker_factory__WEBPACK_IMPORTED_MODULE_104__.createNativeConstantSourceNodeFakerFactory)(addSilentConnection, createNativeAudioBufferSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, monitorConnections);\nconst createNativeConstantSourceNode = (0,_factories_native_constant_source_node_factory__WEBPACK_IMPORTED_MODULE_103__.createNativeConstantSourceNodeFactory)(addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport);\nconst createConstantSourceNodeRenderer = (0,_factories_constant_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_36__.createConstantSourceNodeRendererFactory)(connectAudioParam, createNativeConstantSourceNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst constantSourceNodeConstructor = (0,_factories_constant_source_node_constructor__WEBPACK_IMPORTED_MODULE_35__.createConstantSourceNodeConstructor)(audioNodeConstructor, createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst createNativeConvolverNode = (0,_factories_native_convolver_node_factory__WEBPACK_IMPORTED_MODULE_105__.createNativeConvolverNodeFactory)(_factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors);\nconst createConvolverNodeRenderer = (0,_factories_convolver_node_renderer_factory__WEBPACK_IMPORTED_MODULE_39__.createConvolverNodeRendererFactory)(createNativeConvolverNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst convolverNodeConstructor = (0,_factories_convolver_node_constructor__WEBPACK_IMPORTED_MODULE_38__.createConvolverNodeConstructor)(audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createDelayNodeRenderer = (0,_factories_delay_node_renderer_factory__WEBPACK_IMPORTED_MODULE_45__.createDelayNodeRendererFactory)(connectAudioParam, _factories_native_delay_node__WEBPACK_IMPORTED_MODULE_106__.createNativeDelayNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst delayNodeConstructor = (0,_factories_delay_node_constructor__WEBPACK_IMPORTED_MODULE_44__.createDelayNodeConstructor)(audioNodeConstructor, createAudioParam, createDelayNodeRenderer, _factories_native_delay_node__WEBPACK_IMPORTED_MODULE_106__.createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createNativeDynamicsCompressorNode = (0,_factories_native_dynamics_compressor_node_factory__WEBPACK_IMPORTED_MODULE_107__.createNativeDynamicsCompressorNodeFactory)(_factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError);\nconst createDynamicsCompressorNodeRenderer = (0,_factories_dynamics_compressor_node_renderer_factory__WEBPACK_IMPORTED_MODULE_51__.createDynamicsCompressorNodeRendererFactory)(connectAudioParam, createNativeDynamicsCompressorNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst dynamicsCompressorNodeConstructor = (0,_factories_dynamics_compressor_node_constructor__WEBPACK_IMPORTED_MODULE_50__.createDynamicsCompressorNodeConstructor)(audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createGainNodeRenderer = (0,_factories_gain_node_renderer_factory__WEBPACK_IMPORTED_MODULE_58__.createGainNodeRendererFactory)(connectAudioParam, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst gainNodeConstructor = (0,_factories_gain_node_constructor__WEBPACK_IMPORTED_MODULE_57__.createGainNodeConstructor)(audioNodeConstructor, createAudioParam, createGainNodeRenderer, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeIIRFilterNodeFaker = (0,_factories_native_iir_filter_node_faker_factory__WEBPACK_IMPORTED_MODULE_110__.createNativeIIRFilterNodeFakerFactory)(_factories_invalid_access_error__WEBPACK_IMPORTED_MODULE_71__.createInvalidAccessError, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError);\nconst renderNativeOfflineAudioContext = (0,_factories_render_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_135__.createRenderNativeOfflineAudioContext)(cacheTestResult, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, (0,_factories_test_offline_audio_context_current_time_support__WEBPACK_IMPORTED_MODULE_155__.createTestOfflineAudioContextCurrentTimeSupport)(_factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, nativeOfflineAudioContextConstructor));\nconst createIIRFilterNodeRenderer = (0,_factories_iir_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_68__.createIIRFilterNodeRendererFactory)(createNativeAudioBufferSourceNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst createNativeIIRFilterNode = (0,_factories_native_iir_filter_node_factory__WEBPACK_IMPORTED_MODULE_109__.createNativeIIRFilterNodeFactory)(createNativeIIRFilterNodeFaker);\nconst iIRFilterNodeConstructor = (0,_factories_iir_filter_node_constructor__WEBPACK_IMPORTED_MODULE_67__.createIIRFilterNodeConstructor)(audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createAudioListener = (0,_factories_audio_listener_factory__WEBPACK_IMPORTED_MODULE_18__.createAudioListenerFactory)(createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _helpers_get_first_sample__WEBPACK_IMPORTED_MODULE_171__.getFirstSample, isNativeOfflineAudioContext, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors);\nconst unrenderedAudioWorkletNodeStore = new WeakMap();\nconst minimalBaseAudioContextConstructor = (0,_factories_minimal_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_89__.createMinimalBaseAudioContextConstructor)(audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst createNativeOscillatorNode = (0,_factories_native_oscillator_node_factory__WEBPACK_IMPORTED_MODULE_116__.createNativeOscillatorNodeFactory)(addSilentConnection, cacheTestResult, _helpers_test_audio_scheduled_source_node_start_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_190__.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _helpers_test_audio_scheduled_source_node_stop_method_consecutive_calls_support__WEBPACK_IMPORTED_MODULE_191__.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, _helpers_test_audio_scheduled_source_node_stop_method_negative_parameters_support__WEBPACK_IMPORTED_MODULE_192__.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, _helpers_wrap_audio_scheduled_source_node_stop_method_consecutive_calls__WEBPACK_IMPORTED_MODULE_198__.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);\nconst createOscillatorNodeRenderer = (0,_factories_oscillator_node_renderer_factory__WEBPACK_IMPORTED_MODULE_128__.createOscillatorNodeRendererFactory)(connectAudioParam, createNativeOscillatorNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst oscillatorNodeConstructor = (0,_factories_oscillator_node_constructor__WEBPACK_IMPORTED_MODULE_127__.createOscillatorNodeConstructor)(audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener);\nconst createConnectedNativeAudioBufferSourceNode = (0,_factories_connected_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_34__.createConnectedNativeAudioBufferSourceNodeFactory)(createNativeAudioBufferSourceNode);\nconst createNativeWaveShaperNodeFaker = (0,_factories_native_wave_shaper_node_faker_factory__WEBPACK_IMPORTED_MODULE_124__.createNativeWaveShaperNodeFakerFactory)(createConnectedNativeAudioBufferSourceNode, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _helpers_is_dc_curve__WEBPACK_IMPORTED_MODULE_177__.isDCCurve, monitorConnections);\nconst createNativeWaveShaperNode = (0,_factories_native_wave_shaper_node_factory__WEBPACK_IMPORTED_MODULE_123__.createNativeWaveShaperNodeFactory)(createConnectedNativeAudioBufferSourceNode, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeWaveShaperNodeFaker, _helpers_is_dc_curve__WEBPACK_IMPORTED_MODULE_177__.isDCCurve, monitorConnections, nativeAudioContextConstructor, _helpers_overwrite_accessors__WEBPACK_IMPORTED_MODULE_180__.overwriteAccessors);\nconst createNativePannerNodeFaker = (0,_factories_native_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_118__.createNativePannerNodeFakerFactory)(_helpers_connect_native_audio_node_to_native_audio_node__WEBPACK_IMPORTED_MODULE_166__.connectNativeAudioNodeToNativeAudioNode, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeChannelMergerNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, createNativeWaveShaperNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _helpers_disconnect_native_audio_node_from_native_audio_node__WEBPACK_IMPORTED_MODULE_167__.disconnectNativeAudioNodeFromNativeAudioNode, _helpers_get_first_sample__WEBPACK_IMPORTED_MODULE_171__.getFirstSample, monitorConnections);\nconst createNativePannerNode = (0,_factories_native_panner_node_factory__WEBPACK_IMPORTED_MODULE_117__.createNativePannerNodeFactory)(createNativePannerNodeFaker);\nconst createPannerNodeRenderer = (0,_factories_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_130__.createPannerNodeRendererFactory)(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, createNativePannerNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst pannerNodeConstructor = (0,_factories_panner_node_constructor__WEBPACK_IMPORTED_MODULE_129__.createPannerNodeConstructor)(audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst createNativePeriodicWave = (0,_factories_native_periodic_wave_factory__WEBPACK_IMPORTED_MODULE_119__.createNativePeriodicWaveFactory)(_factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst periodicWaveConstructor = (0,_factories_periodic_wave_constructor__WEBPACK_IMPORTED_MODULE_131__.createPeriodicWaveConstructor)(createNativePeriodicWave, getNativeContext, new WeakSet(), _helpers_sanitize_periodic_wave_options__WEBPACK_IMPORTED_MODULE_184__.sanitizePeriodicWaveOptions);\nconst nativeStereoPannerNodeFakerFactory = (0,_factories_native_stereo_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_122__.createNativeStereoPannerNodeFakerFactory)(createNativeChannelMergerNode, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, createNativeWaveShaperNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, monitorConnections);\nconst createNativeStereoPannerNode = (0,_factories_native_stereo_panner_node_factory__WEBPACK_IMPORTED_MODULE_121__.createNativeStereoPannerNodeFactory)(nativeStereoPannerNodeFakerFactory, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError);\nconst createStereoPannerNodeRenderer = (0,_factories_stereo_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_140__.createStereoPannerNodeRendererFactory)(connectAudioParam, createNativeStereoPannerNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);\nconst stereoPannerNodeConstructor = (0,_factories_stereo_panner_node_constructor__WEBPACK_IMPORTED_MODULE_139__.createStereoPannerNodeConstructor)(audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);\nconst createWaveShaperNodeRenderer = (0,_factories_wave_shaper_node_renderer_factory__WEBPACK_IMPORTED_MODULE_159__.createWaveShaperNodeRendererFactory)(createNativeWaveShaperNode, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, renderInputsOfAudioNode);\nconst waveShaperNodeConstructor = (0,_factories_wave_shaper_node_constructor__WEBPACK_IMPORTED_MODULE_158__.createWaveShaperNodeConstructor)(audioNodeConstructor, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);\nconst isSecureContext = (0,_factories_is_secure_context__WEBPACK_IMPORTED_MODULE_82__.createIsSecureContext)(window);\nconst exposeCurrentFrameAndCurrentTime = (0,_factories_expose_current_frame_and_current_time__WEBPACK_IMPORTED_MODULE_55__.createExposeCurrentFrameAndCurrentTime)(window);\nconst backupOfflineAudioContextStore = new WeakMap();\nconst getOrCreateBackupOfflineAudioContext = (0,_factories_get_or_create_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_65__.createGetOrCreateBackupOfflineAudioContext)(backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor);\n// The addAudioWorkletModule() function is only available in a SecureContext.\nconst addAudioWorkletModule = isSecureContext\n    ? (0,_factories_add_audio_worklet_module__WEBPACK_IMPORTED_MODULE_5__.createAddAudioWorkletModule)(cacheTestResult, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, (0,_factories_evaluate_source__WEBPACK_IMPORTED_MODULE_53__.createEvaluateSource)(window), exposeCurrentFrameAndCurrentTime, (0,_factories_fetch_source__WEBPACK_IMPORTED_MODULE_56__.createFetchSource)(_factories_abort_error__WEBPACK_IMPORTED_MODULE_1__.createAbortError), getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, new WeakMap(), new WeakMap(), (0,_factories_test_audio_worklet_processor_post_message_support__WEBPACK_IMPORTED_MODULE_148__.createTestAudioWorkletProcessorPostMessageSupport)(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), \n    // @todo window is guaranteed to be defined because isSecureContext checks that as well.\n    window)\n    : undefined;\nconst isNativeContext = (0,_factories_is_native_context__WEBPACK_IMPORTED_MODULE_80__.createIsNativeContext)(isNativeAudioContext, isNativeOfflineAudioContext);\nconst decodeAudioData = (0,_factories_decode_audio_data__WEBPACK_IMPORTED_MODULE_42__.createDecodeAudioData)(audioBufferStore, cacheTestResult, _factories_data_clone_error__WEBPACK_IMPORTED_MODULE_41__.createDataCloneError, _factories_encoding_error__WEBPACK_IMPORTED_MODULE_52__.createEncodingError, new WeakSet(), getNativeContext, isNativeContext, _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_186__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, _helpers_test_promise_support__WEBPACK_IMPORTED_MODULE_195__.testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nconst baseAudioContextConstructor = (0,_factories_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_24__.createBaseAudioContextConstructor)(addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor);\nconst mediaElementAudioSourceNodeConstructor = (0,_factories_media_element_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_84__.createMediaElementAudioSourceNodeConstructor)(audioNodeConstructor, _factories_native_media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_111__.createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);\nconst mediaStreamAudioDestinationNodeConstructor = (0,_factories_media_stream_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_85__.createMediaStreamAudioDestinationNodeConstructor)(audioNodeConstructor, _factories_native_media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_112__.createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext);\nconst mediaStreamAudioSourceNodeConstructor = (0,_factories_media_stream_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_86__.createMediaStreamAudioSourceNodeConstructor)(audioNodeConstructor, _factories_native_media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_113__.createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);\nconst createNativeMediaStreamTrackAudioSourceNode = (0,_factories_native_media_stream_track_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_114__.createNativeMediaStreamTrackAudioSourceNodeFactory)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, isNativeOfflineAudioContext);\nconst mediaStreamTrackAudioSourceNodeConstructor = (0,_factories_media_stream_track_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_87__.createMediaStreamTrackAudioSourceNodeConstructor)(audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext);\nconst audioContextConstructor = (0,_factories_audio_context_constructor__WEBPACK_IMPORTED_MODULE_15__.createAudioContextConstructor)(baseAudioContextConstructor, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _factories_unknown_error__WEBPACK_IMPORTED_MODULE_157__.createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor);\n\nconst getUnrenderedAudioWorkletNodes = (0,_factories_get_unrendered_audio_worklet_nodes__WEBPACK_IMPORTED_MODULE_66__.createGetUnrenderedAudioWorkletNodes)(unrenderedAudioWorkletNodeStore);\nconst addUnrenderedAudioWorkletNode = (0,_factories_add_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_9__.createAddUnrenderedAudioWorkletNode)(getUnrenderedAudioWorkletNodes);\nconst connectMultipleOutputs = (0,_factories_connect_multiple_outputs__WEBPACK_IMPORTED_MODULE_33__.createConnectMultipleOutputs)(_factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst deleteUnrenderedAudioWorkletNode = (0,_factories_delete_unrendered_audio_worklet_node__WEBPACK_IMPORTED_MODULE_47__.createDeleteUnrenderedAudioWorkletNode)(getUnrenderedAudioWorkletNodes);\nconst disconnectMultipleOutputs = (0,_factories_disconnect_multiple_outputs__WEBPACK_IMPORTED_MODULE_49__.createDisconnectMultipleOutputs)(_factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError);\nconst activeAudioWorkletNodeInputsStore = new WeakMap();\nconst getActiveAudioWorkletNodeInputs = (0,_factories_get_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_59__.createGetActiveAudioWorkletNodeInputs)(activeAudioWorkletNodeInputsStore, _helpers_get_value_for_key__WEBPACK_IMPORTED_MODULE_174__.getValueForKey);\nconst createNativeAudioWorkletNodeFaker = (0,_factories_native_audio_worklet_node_faker_factory__WEBPACK_IMPORTED_MODULE_99__.createNativeAudioWorkletNodeFakerFactory)(connectMultipleOutputs, _factories_index_size_error__WEBPACK_IMPORTED_MODULE_70__.createIndexSizeError, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeChannelMergerNode, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, createNativeConstantSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_native_script_processor_node__WEBPACK_IMPORTED_MODULE_120__.createNativeScriptProcessorNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections);\nconst createNativeAudioWorkletNode = (0,_factories_native_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_98__.createNativeAudioWorkletNodeFactory)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeAudioWorkletNodeFaker, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, monitorConnections);\nconst createAudioWorkletNodeRenderer = (0,_factories_audio_worklet_node_renderer_factory__WEBPACK_IMPORTED_MODULE_23__.createAudioWorkletNodeRendererFactory)(connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, _factories_native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_102__.createNativeChannelSplitterNode, createNativeConstantSourceNode, _factories_native_gain_node__WEBPACK_IMPORTED_MODULE_108__.createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, _helpers_get_native_audio_node__WEBPACK_IMPORTED_MODULE_172__.getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);\nconst getBackupOfflineAudioContext = (0,_factories_get_backup_offline_audio_context__WEBPACK_IMPORTED_MODULE_63__.createGetBackupOfflineAudioContext)(backupOfflineAudioContextStore);\nconst setActiveAudioWorkletNodeInputs = (0,_factories_set_active_audio_worklet_node_inputs__WEBPACK_IMPORTED_MODULE_136__.createSetActiveAudioWorkletNodeInputs)(activeAudioWorkletNodeInputsStore);\n// The AudioWorkletNode constructor is only available in a SecureContext.\nconst audioWorkletNodeConstructor = isSecureContext\n    ? (0,_factories_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_22__.createAudioWorkletNodeConstructor)(addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, _helpers_get_audio_node_connections__WEBPACK_IMPORTED_MODULE_168__.getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, _helpers_sanitize_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_182__.sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, _helpers_test_audio_worklet_node_options_clonability__WEBPACK_IMPORTED_MODULE_193__.testAudioWorkletNodeOptionsClonability, _helpers_wrap_event_listener__WEBPACK_IMPORTED_MODULE_199__.wrapEventListener)\n    : undefined;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst minimalAudioContextConstructor = (0,_factories_minimal_audio_context_constructor__WEBPACK_IMPORTED_MODULE_88__.createMinimalAudioContextConstructor)(_factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, _factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, _factories_unknown_error__WEBPACK_IMPORTED_MODULE_157__.createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor);\n\nconst createNativeOfflineAudioContext = (0,_factories_create_native_offline_audio_context__WEBPACK_IMPORTED_MODULE_40__.createCreateNativeOfflineAudioContext)(_factories_not_supported_error__WEBPACK_IMPORTED_MODULE_125__.createNotSupportedError, nativeOfflineAudioContextConstructor);\nconst startRendering = (0,_factories_start_rendering__WEBPACK_IMPORTED_MODULE_138__.createStartRendering)(audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, _helpers_test_audio_buffer_copy_channel_methods_out_of_bounds_support__WEBPACK_IMPORTED_MODULE_186__.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);\nconst minimalOfflineAudioContextConstructor = (0,_factories_minimal_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_90__.createMinimalOfflineAudioContextConstructor)(cacheTestResult, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering);\n\nconst offlineAudioContextConstructor = (0,_factories_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_126__.createOfflineAudioContextConstructor)(baseAudioContextConstructor, cacheTestResult, _factories_invalid_state_error__WEBPACK_IMPORTED_MODULE_72__.createInvalidStateError, createNativeOfflineAudioContext, startRendering);\n\n\n\n\n\n\nconst isAnyAudioContext = (0,_factories_is_any_audio_context__WEBPACK_IMPORTED_MODULE_73__.createIsAnyAudioContext)(_globals__WEBPACK_IMPORTED_MODULE_165__.CONTEXT_STORE, isNativeAudioContext);\nconst isAnyAudioNode = (0,_factories_is_any_audio_node__WEBPACK_IMPORTED_MODULE_74__.createIsAnyAudioNode)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_NODE_STORE, isNativeAudioNode);\nconst isAnyAudioParam = (0,_factories_is_any_audio_param__WEBPACK_IMPORTED_MODULE_75__.createIsAnyAudioParam)(_globals__WEBPACK_IMPORTED_MODULE_165__.AUDIO_PARAM_STORE, isNativeAudioParam);\nconst isAnyOfflineAudioContext = (0,_factories_is_any_offline_audio_context__WEBPACK_IMPORTED_MODULE_76__.createIsAnyOfflineAudioContext)(_globals__WEBPACK_IMPORTED_MODULE_165__.CONTEXT_STORE, isNativeOfflineAudioContext);\nconst isSupported = () => (0,_factories_is_supported_promise__WEBPACK_IMPORTED_MODULE_83__.createIsSupportedPromise)(cacheTestResult, (0,_factories_test_audio_buffer_copy_channel_methods_subarray_support__WEBPACK_IMPORTED_MODULE_142__.createTestAudioBufferCopyChannelMethodsSubarraySupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_audio_context_close_method_support__WEBPACK_IMPORTED_MODULE_143__.createTestAudioContextCloseMethodSupport)(nativeAudioContextConstructor), (0,_factories_test_audio_context_decode_audio_data_method_type_error_support__WEBPACK_IMPORTED_MODULE_144__.createTestAudioContextDecodeAudioDataMethodTypeErrorSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_audio_context_options_support__WEBPACK_IMPORTED_MODULE_145__.createTestAudioContextOptionsSupport)(nativeAudioContextConstructor), (0,_factories_test_audio_node_connect_method_support__WEBPACK_IMPORTED_MODULE_146__.createTestAudioNodeConnectMethodSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_audio_worklet_processor_no_outputs_support__WEBPACK_IMPORTED_MODULE_147__.createTestAudioWorkletProcessorNoOutputsSupport)(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), (0,_factories_test_channel_merger_node_channel_count_support__WEBPACK_IMPORTED_MODULE_149__.createTestChannelMergerNodeChannelCountSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_constant_source_node_accurate_scheduling_support__WEBPACK_IMPORTED_MODULE_150__.createTestConstantSourceNodeAccurateSchedulingSupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_convolver_node_buffer_reassignability_support__WEBPACK_IMPORTED_MODULE_151__.createTestConvolverNodeBufferReassignabilitySupport)(nativeOfflineAudioContextConstructor), (0,_factories_test_convolver_node_channel_count_support__WEBPACK_IMPORTED_MODULE_152__.createTestConvolverNodeChannelCountSupport)(nativeOfflineAudioContextConstructor), _helpers_test_dom_exception_constructor_support__WEBPACK_IMPORTED_MODULE_194__.testDomExceptionConstructorSupport, (0,_factories_test_is_secure_context_support__WEBPACK_IMPORTED_MODULE_153__.createTestIsSecureContextSupport)(window), (0,_factories_test_media_stream_audio_source_node_media_stream_without_audio_track_support__WEBPACK_IMPORTED_MODULE_154__.createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)(nativeAudioContextConstructor), (0,_factories_test_stereo_panner_node_default_value_support__WEBPACK_IMPORTED_MODULE_156__.createTestStereoPannerNodeDefaultValueSupport)(nativeOfflineAudioContextConstructor), _helpers_test_transferables_support__WEBPACK_IMPORTED_MODULE_196__.testTransferablesSupport);\n//# sourceMappingURL=module.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/module.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/read-only-map.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/read-only-map.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ReadOnlyMap\": () => (/* binding */ ReadOnlyMap)\n/* harmony export */ });\nclass ReadOnlyMap {\n    constructor(parameters) {\n        this._map = new Map(parameters);\n    }\n    get size() {\n        return this._map.size;\n    }\n    entries() {\n        return this._map.entries();\n    }\n    forEach(callback, thisArg = null) {\n        return this._map.forEach((value, key) => callback.call(thisArg, value, key, this));\n    }\n    get(name) {\n        return this._map.get(name);\n    }\n    has(name) {\n        return this._map.has(name);\n    }\n    keys() {\n        return this._map.keys();\n    }\n    values() {\n        return this._map.values();\n    }\n}\n//# sourceMappingURL=read-only-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/read-only-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=abort-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=active-audio-worklet-node-inputs-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=active-input-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-active-input-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-active-input-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-node-connections-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-node-connections-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-param-connections-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-param-connections-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-worklet-module-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-audio-worklet-module-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-passive-input-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-passive-input-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-silent-connection-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-silent-connection-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-unrendered-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=add-unrendered-audio-worklet-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=analyser-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=any-audio-buffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/any-context.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/any-context.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=any-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/any-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-source-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-buffer-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-latency-category.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-context-state.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-destination-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-listener-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-listener-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-connections-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-output-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-node-tail-time-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-audio-node-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-connections-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-connections.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-output-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-param-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=audio-worklet-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=backup-offline-audio-context-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=base-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=biquad-filter-type.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=cache-test-result-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=cache-test-result-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-count-mode.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-interpretation.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-merger-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=channel-splitter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-audio-param-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-audio-param-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-multiple-outputs-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-multiple-outputs-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connect-native-audio-node-to-native-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connected-native-audio-buffer-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=connected-native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constant-source-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/constructor.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/constructor.js ***!
  \***********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/context-store.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/context-store.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=context-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/context-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/context.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/context.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convert-number-to-unsigned-long-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convert-number-to-unsigned-long-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=convolver-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=create-native-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=create-native-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=cycle-counters.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=data-clone-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-audio-data-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-audio-data-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-error-callback.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decode-success-callback.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decrement-cycle-counter-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=decrement-cycle-counter-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delay-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-active-input-connection-to-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-active-input-connection-to-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-unrendered-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=delete-unrendered-audio-worklet-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=detect-cycles-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=detect-cycles-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=disconnect-multiple-outputs-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=disconnect-multiple-outputs-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=disconnect-native-audio-node-from-native-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=distance-model-type.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=dynamics-compressor-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=encoding-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=error-event-handler.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=evaluate-audio-worklet-global-scope-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=evaluate-source-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=evaluate-source-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/event-handler.js":
/*!*************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/event-handler.js ***!
  \*************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-handler.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/event-handler.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-target-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=event-target-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=expose-current-frame-and-current-time-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=expose-current-frame-and-current-time-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=fetch-source-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=fetch-source-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=gain-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-active-audio-worklet-node-inputs-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-active-audio-worklet-node-inputs-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-connections-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-renderer-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-tail-time-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-node-tail-time-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-param-connections-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-param-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-audio-param-renderer-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-backup-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-backup-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-event-listeners-of-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-first-sample-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-audio-param-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-native-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-or-create-backup-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-or-create-backup-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-unrendered-audio-worklet-nodes-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-unrendered-audio-worklet-nodes-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=get-value-for-key-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=iir-filter-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=increment-cycle-counter-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=increment-cycle-counter-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=increment-cycle-counter-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=index-size-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/index.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/index.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _abort_error_factory__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./abort-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/abort-error-factory.js\");\n/* harmony import */ var _active_audio_worklet_node_inputs_store__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./active-audio-worklet-node-inputs-store */ \"./node_modules/standardized-audio-context/build/es2019/types/active-audio-worklet-node-inputs-store.js\");\n/* harmony import */ var _active_input_connection__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./active-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/active-input-connection.js\");\n/* harmony import */ var _add_active_input_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./add-active-input-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-factory.js\");\n/* harmony import */ var _add_active_input_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./add-active-input-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-active-input-connection-to-audio-node-function.js\");\n/* harmony import */ var _add_audio_node_connections_factory__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./add-audio-node-connections-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-factory.js\");\n/* harmony import */ var _add_audio_node_connections_function__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./add-audio-node-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-node-connections-function.js\");\n/* harmony import */ var _add_audio_param_connections_factory__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./add-audio-param-connections-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-factory.js\");\n/* harmony import */ var _add_audio_param_connections_function__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./add-audio-param-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-param-connections-function.js\");\n/* harmony import */ var _add_audio_worklet_module_factory__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./add-audio-worklet-module-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-factory.js\");\n/* harmony import */ var _add_audio_worklet_module_function__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./add-audio-worklet-module-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-audio-worklet-module-function.js\");\n/* harmony import */ var _add_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./add-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-factory.js\");\n/* harmony import */ var _add_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./add-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-connection-to-audio-node-function.js\");\n/* harmony import */ var _add_passive_input_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./add-passive-input-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-factory.js\");\n/* harmony import */ var _add_passive_input_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./add-passive-input-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-passive-input-connection-to-audio-node-function.js\");\n/* harmony import */ var _add_silent_connection_factory__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./add-silent-connection-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-factory.js\");\n/* harmony import */ var _add_silent_connection_function__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./add-silent-connection-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-silent-connection-function.js\");\n/* harmony import */ var _add_unrendered_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./add-unrendered-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-factory.js\");\n/* harmony import */ var _add_unrendered_audio_worklet_node_function__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./add-unrendered-audio-worklet-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/add-unrendered-audio-worklet-node-function.js\");\n/* harmony import */ var _analyser_node_constructor__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./analyser-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor.js\");\n/* harmony import */ var _analyser_node_constructor_factory__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./analyser-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-constructor-factory.js\");\n/* harmony import */ var _analyser_node_renderer_factory__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./analyser-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory.js\");\n/* harmony import */ var _analyser_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./analyser-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/analyser-node-renderer-factory-factory.js\");\n/* harmony import */ var _any_audio_buffer__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./any-audio-buffer */ \"./node_modules/standardized-audio-context/build/es2019/types/any-audio-buffer.js\");\n/* harmony import */ var _any_context__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./any-context */ \"./node_modules/standardized-audio-context/build/es2019/types/any-context.js\");\n/* harmony import */ var _audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor.js\");\n/* harmony import */ var _audio_buffer_constructor_factory__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./audio-buffer-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-constructor-factory.js\");\n/* harmony import */ var _audio_buffer_source_node_constructor__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./audio-buffer-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor.js\");\n/* harmony import */ var _audio_buffer_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./audio-buffer-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-constructor-factory.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory.js\");\n/* harmony import */ var _audio_buffer_source_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./audio-buffer-source-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-source-node-renderer-factory-factory.js\");\n/* harmony import */ var _audio_buffer_store__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./audio-buffer-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-buffer-store.js\");\n/* harmony import */ var _audio_context_constructor__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor.js\");\n/* harmony import */ var _audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-constructor-factory.js\");\n/* harmony import */ var _audio_context_latency_category__WEBPACK_IMPORTED_MODULE_35__ = __webpack_require__(/*! ./audio-context-latency-category */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-latency-category.js\");\n/* harmony import */ var _audio_context_state__WEBPACK_IMPORTED_MODULE_36__ = __webpack_require__(/*! ./audio-context-state */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-context-state.js\");\n/* harmony import */ var _audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_37__ = __webpack_require__(/*! ./audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor.js\");\n/* harmony import */ var _audio_destination_node_constructor_factory__WEBPACK_IMPORTED_MODULE_38__ = __webpack_require__(/*! ./audio-destination-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-constructor-factory.js\");\n/* harmony import */ var _audio_destination_node_renderer_factory__WEBPACK_IMPORTED_MODULE_39__ = __webpack_require__(/*! ./audio-destination-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-destination-node-renderer-factory.js\");\n/* harmony import */ var _audio_listener_factory__WEBPACK_IMPORTED_MODULE_40__ = __webpack_require__(/*! ./audio-listener-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory.js\");\n/* harmony import */ var _audio_listener_factory_factory__WEBPACK_IMPORTED_MODULE_41__ = __webpack_require__(/*! ./audio-listener-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-listener-factory-factory.js\");\n/* harmony import */ var _audio_node_connections__WEBPACK_IMPORTED_MODULE_42__ = __webpack_require__(/*! ./audio-node-connections */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections.js\");\n/* harmony import */ var _audio_node_connections_store__WEBPACK_IMPORTED_MODULE_43__ = __webpack_require__(/*! ./audio-node-connections-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-connections-store.js\");\n/* harmony import */ var _audio_node_constructor__WEBPACK_IMPORTED_MODULE_44__ = __webpack_require__(/*! ./audio-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor.js\");\n/* harmony import */ var _audio_node_constructor_factory__WEBPACK_IMPORTED_MODULE_45__ = __webpack_require__(/*! ./audio-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-constructor-factory.js\");\n/* harmony import */ var _audio_node_output_connection__WEBPACK_IMPORTED_MODULE_46__ = __webpack_require__(/*! ./audio-node-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-output-connection.js\");\n/* harmony import */ var _audio_node_renderer__WEBPACK_IMPORTED_MODULE_47__ = __webpack_require__(/*! ./audio-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-renderer.js\");\n/* harmony import */ var _audio_node_store__WEBPACK_IMPORTED_MODULE_48__ = __webpack_require__(/*! ./audio-node-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-store.js\");\n/* harmony import */ var _audio_node_tail_time_store__WEBPACK_IMPORTED_MODULE_49__ = __webpack_require__(/*! ./audio-node-tail-time-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-node-tail-time-store.js\");\n/* harmony import */ var _audio_param_audio_node_store__WEBPACK_IMPORTED_MODULE_50__ = __webpack_require__(/*! ./audio-param-audio-node-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-audio-node-store.js\");\n/* harmony import */ var _audio_param_connections__WEBPACK_IMPORTED_MODULE_51__ = __webpack_require__(/*! ./audio-param-connections */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections.js\");\n/* harmony import */ var _audio_param_connections_store__WEBPACK_IMPORTED_MODULE_52__ = __webpack_require__(/*! ./audio-param-connections-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-connections-store.js\");\n/* harmony import */ var _audio_param_factory__WEBPACK_IMPORTED_MODULE_53__ = __webpack_require__(/*! ./audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory.js\");\n/* harmony import */ var _audio_param_factory_factory__WEBPACK_IMPORTED_MODULE_54__ = __webpack_require__(/*! ./audio-param-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-factory-factory.js\");\n/* harmony import */ var _audio_param_map__WEBPACK_IMPORTED_MODULE_55__ = __webpack_require__(/*! ./audio-param-map */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-map.js\");\n/* harmony import */ var _audio_param_output_connection__WEBPACK_IMPORTED_MODULE_56__ = __webpack_require__(/*! ./audio-param-output-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-output-connection.js\");\n/* harmony import */ var _audio_param_renderer_factory__WEBPACK_IMPORTED_MODULE_57__ = __webpack_require__(/*! ./audio-param-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-renderer-factory.js\");\n/* harmony import */ var _audio_param_store__WEBPACK_IMPORTED_MODULE_58__ = __webpack_require__(/*! ./audio-param-store */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-param-store.js\");\n/* harmony import */ var _audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_59__ = __webpack_require__(/*! ./audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor.js\");\n/* harmony import */ var _audio_worklet_node_constructor_factory__WEBPACK_IMPORTED_MODULE_60__ = __webpack_require__(/*! ./audio-worklet-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-constructor-factory.js\");\n/* harmony import */ var _audio_worklet_node_renderer_factory__WEBPACK_IMPORTED_MODULE_61__ = __webpack_require__(/*! ./audio-worklet-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory.js\");\n/* harmony import */ var _audio_worklet_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_62__ = __webpack_require__(/*! ./audio-worklet-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/audio-worklet-node-renderer-factory-factory.js\");\n/* harmony import */ var _backup_offline_audio_context_store__WEBPACK_IMPORTED_MODULE_63__ = __webpack_require__(/*! ./backup-offline-audio-context-store */ \"./node_modules/standardized-audio-context/build/es2019/types/backup-offline-audio-context-store.js\");\n/* harmony import */ var _base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_64__ = __webpack_require__(/*! ./base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor.js\");\n/* harmony import */ var _base_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_65__ = __webpack_require__(/*! ./base-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/base-audio-context-constructor-factory.js\");\n/* harmony import */ var _biquad_filter_node_constructor__WEBPACK_IMPORTED_MODULE_66__ = __webpack_require__(/*! ./biquad-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor.js\");\n/* harmony import */ var _biquad_filter_node_constructor_factory__WEBPACK_IMPORTED_MODULE_67__ = __webpack_require__(/*! ./biquad-filter-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-constructor-factory.js\");\n/* harmony import */ var _biquad_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_68__ = __webpack_require__(/*! ./biquad-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory.js\");\n/* harmony import */ var _biquad_filter_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_69__ = __webpack_require__(/*! ./biquad-filter-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-node-renderer-factory-factory.js\");\n/* harmony import */ var _biquad_filter_type__WEBPACK_IMPORTED_MODULE_70__ = __webpack_require__(/*! ./biquad-filter-type */ \"./node_modules/standardized-audio-context/build/es2019/types/biquad-filter-type.js\");\n/* harmony import */ var _channel_count_mode__WEBPACK_IMPORTED_MODULE_71__ = __webpack_require__(/*! ./channel-count-mode */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-count-mode.js\");\n/* harmony import */ var _channel_interpretation__WEBPACK_IMPORTED_MODULE_72__ = __webpack_require__(/*! ./channel-interpretation */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-interpretation.js\");\n/* harmony import */ var _channel_merger_node_constructor__WEBPACK_IMPORTED_MODULE_73__ = __webpack_require__(/*! ./channel-merger-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor.js\");\n/* harmony import */ var _channel_merger_node_constructor_factory__WEBPACK_IMPORTED_MODULE_74__ = __webpack_require__(/*! ./channel-merger-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-constructor-factory.js\");\n/* harmony import */ var _channel_merger_node_renderer_factory__WEBPACK_IMPORTED_MODULE_75__ = __webpack_require__(/*! ./channel-merger-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory.js\");\n/* harmony import */ var _channel_merger_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_76__ = __webpack_require__(/*! ./channel-merger-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-merger-node-renderer-factory-factory.js\");\n/* harmony import */ var _channel_splitter_node_constructor__WEBPACK_IMPORTED_MODULE_77__ = __webpack_require__(/*! ./channel-splitter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor.js\");\n/* harmony import */ var _channel_splitter_node_constructor_factory__WEBPACK_IMPORTED_MODULE_78__ = __webpack_require__(/*! ./channel-splitter-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-constructor-factory.js\");\n/* harmony import */ var _channel_splitter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_79__ = __webpack_require__(/*! ./channel-splitter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory.js\");\n/* harmony import */ var _channel_splitter_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_80__ = __webpack_require__(/*! ./channel-splitter-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/channel-splitter-node-renderer-factory-factory.js\");\n/* harmony import */ var _cache_test_result_factory__WEBPACK_IMPORTED_MODULE_81__ = __webpack_require__(/*! ./cache-test-result-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-factory.js\");\n/* harmony import */ var _cache_test_result_function__WEBPACK_IMPORTED_MODULE_82__ = __webpack_require__(/*! ./cache-test-result-function */ \"./node_modules/standardized-audio-context/build/es2019/types/cache-test-result-function.js\");\n/* harmony import */ var _connect_audio_param_factory__WEBPACK_IMPORTED_MODULE_83__ = __webpack_require__(/*! ./connect-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-factory.js\");\n/* harmony import */ var _connect_audio_param_function__WEBPACK_IMPORTED_MODULE_84__ = __webpack_require__(/*! ./connect-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-audio-param-function.js\");\n/* harmony import */ var _connect_multiple_outputs_factory__WEBPACK_IMPORTED_MODULE_85__ = __webpack_require__(/*! ./connect-multiple-outputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-factory.js\");\n/* harmony import */ var _connect_multiple_outputs_function__WEBPACK_IMPORTED_MODULE_86__ = __webpack_require__(/*! ./connect-multiple-outputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-multiple-outputs-function.js\");\n/* harmony import */ var _connect_native_audio_node_to_native_audio_node_function__WEBPACK_IMPORTED_MODULE_87__ = __webpack_require__(/*! ./connect-native-audio-node-to-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/connect-native-audio-node-to-native-audio-node-function.js\");\n/* harmony import */ var _connected_native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_88__ = __webpack_require__(/*! ./connected-native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _connected_native_audio_buffer_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_89__ = __webpack_require__(/*! ./connected-native-audio-buffer-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/connected-native-audio-buffer-source-node-factory-factory.js\");\n/* harmony import */ var _constant_source_node_constructor__WEBPACK_IMPORTED_MODULE_90__ = __webpack_require__(/*! ./constant-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor.js\");\n/* harmony import */ var _constant_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_91__ = __webpack_require__(/*! ./constant-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-constructor-factory.js\");\n/* harmony import */ var _constant_source_node_renderer__WEBPACK_IMPORTED_MODULE_92__ = __webpack_require__(/*! ./constant-source-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer.js\");\n/* harmony import */ var _constant_source_node_renderer_factory__WEBPACK_IMPORTED_MODULE_93__ = __webpack_require__(/*! ./constant-source-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory.js\");\n/* harmony import */ var _constant_source_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_94__ = __webpack_require__(/*! ./constant-source-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/constant-source-node-renderer-factory-factory.js\");\n/* harmony import */ var _constructor__WEBPACK_IMPORTED_MODULE_95__ = __webpack_require__(/*! ./constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/constructor.js\");\n/* harmony import */ var _context__WEBPACK_IMPORTED_MODULE_96__ = __webpack_require__(/*! ./context */ \"./node_modules/standardized-audio-context/build/es2019/types/context.js\");\n/* harmony import */ var _context_store__WEBPACK_IMPORTED_MODULE_97__ = __webpack_require__(/*! ./context-store */ \"./node_modules/standardized-audio-context/build/es2019/types/context-store.js\");\n/* harmony import */ var _convert_number_to_unsigned_long_factory__WEBPACK_IMPORTED_MODULE_98__ = __webpack_require__(/*! ./convert-number-to-unsigned-long-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-factory.js\");\n/* harmony import */ var _convert_number_to_unsigned_long_function__WEBPACK_IMPORTED_MODULE_99__ = __webpack_require__(/*! ./convert-number-to-unsigned-long-function */ \"./node_modules/standardized-audio-context/build/es2019/types/convert-number-to-unsigned-long-function.js\");\n/* harmony import */ var _convolver_node_constructor__WEBPACK_IMPORTED_MODULE_100__ = __webpack_require__(/*! ./convolver-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor.js\");\n/* harmony import */ var _convolver_node_constructor_factory__WEBPACK_IMPORTED_MODULE_101__ = __webpack_require__(/*! ./convolver-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-constructor-factory.js\");\n/* harmony import */ var _convolver_node_renderer_factory__WEBPACK_IMPORTED_MODULE_102__ = __webpack_require__(/*! ./convolver-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory.js\");\n/* harmony import */ var _convolver_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_103__ = __webpack_require__(/*! ./convolver-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/convolver-node-renderer-factory-factory.js\");\n/* harmony import */ var _create_native_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_104__ = __webpack_require__(/*! ./create-native-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-factory.js\");\n/* harmony import */ var _create_native_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_105__ = __webpack_require__(/*! ./create-native-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/create-native-offline-audio-context-function.js\");\n/* harmony import */ var _cycle_counters__WEBPACK_IMPORTED_MODULE_106__ = __webpack_require__(/*! ./cycle-counters */ \"./node_modules/standardized-audio-context/build/es2019/types/cycle-counters.js\");\n/* harmony import */ var _data_clone_error_factory__WEBPACK_IMPORTED_MODULE_107__ = __webpack_require__(/*! ./data-clone-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/data-clone-error-factory.js\");\n/* harmony import */ var _decode_audio_data_factory__WEBPACK_IMPORTED_MODULE_108__ = __webpack_require__(/*! ./decode-audio-data-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-factory.js\");\n/* harmony import */ var _decode_audio_data_function__WEBPACK_IMPORTED_MODULE_109__ = __webpack_require__(/*! ./decode-audio-data-function */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-audio-data-function.js\");\n/* harmony import */ var _decode_error_callback__WEBPACK_IMPORTED_MODULE_110__ = __webpack_require__(/*! ./decode-error-callback */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-error-callback.js\");\n/* harmony import */ var _decode_success_callback__WEBPACK_IMPORTED_MODULE_111__ = __webpack_require__(/*! ./decode-success-callback */ \"./node_modules/standardized-audio-context/build/es2019/types/decode-success-callback.js\");\n/* harmony import */ var _decrement_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_112__ = __webpack_require__(/*! ./decrement-cycle-counter-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-factory.js\");\n/* harmony import */ var _decrement_cycle_counter_function__WEBPACK_IMPORTED_MODULE_113__ = __webpack_require__(/*! ./decrement-cycle-counter-function */ \"./node_modules/standardized-audio-context/build/es2019/types/decrement-cycle-counter-function.js\");\n/* harmony import */ var _delay_node_constructor__WEBPACK_IMPORTED_MODULE_114__ = __webpack_require__(/*! ./delay-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor.js\");\n/* harmony import */ var _delay_node_constructor_factory__WEBPACK_IMPORTED_MODULE_115__ = __webpack_require__(/*! ./delay-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-constructor-factory.js\");\n/* harmony import */ var _delay_node_renderer_factory__WEBPACK_IMPORTED_MODULE_116__ = __webpack_require__(/*! ./delay-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory.js\");\n/* harmony import */ var _delay_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_117__ = __webpack_require__(/*! ./delay-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delay-node-renderer-factory-factory.js\");\n/* harmony import */ var _delete_active_input_connection_to_audio_node_factory__WEBPACK_IMPORTED_MODULE_118__ = __webpack_require__(/*! ./delete-active-input-connection-to-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-factory.js\");\n/* harmony import */ var _delete_active_input_connection_to_audio_node_function__WEBPACK_IMPORTED_MODULE_119__ = __webpack_require__(/*! ./delete-active-input-connection-to-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-active-input-connection-to-audio-node-function.js\");\n/* harmony import */ var _delete_unrendered_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_120__ = __webpack_require__(/*! ./delete-unrendered-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-factory.js\");\n/* harmony import */ var _delete_unrendered_audio_worklet_node_function__WEBPACK_IMPORTED_MODULE_121__ = __webpack_require__(/*! ./delete-unrendered-audio-worklet-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/delete-unrendered-audio-worklet-node-function.js\");\n/* harmony import */ var _detect_cycles_factory__WEBPACK_IMPORTED_MODULE_122__ = __webpack_require__(/*! ./detect-cycles-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-factory.js\");\n/* harmony import */ var _detect_cycles_function__WEBPACK_IMPORTED_MODULE_123__ = __webpack_require__(/*! ./detect-cycles-function */ \"./node_modules/standardized-audio-context/build/es2019/types/detect-cycles-function.js\");\n/* harmony import */ var _disconnect_multiple_outputs_factory__WEBPACK_IMPORTED_MODULE_124__ = __webpack_require__(/*! ./disconnect-multiple-outputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-factory.js\");\n/* harmony import */ var _disconnect_multiple_outputs_function__WEBPACK_IMPORTED_MODULE_125__ = __webpack_require__(/*! ./disconnect-multiple-outputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/disconnect-multiple-outputs-function.js\");\n/* harmony import */ var _disconnect_native_audio_node_from_native_audio_node_function__WEBPACK_IMPORTED_MODULE_126__ = __webpack_require__(/*! ./disconnect-native-audio-node-from-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/disconnect-native-audio-node-from-native-audio-node-function.js\");\n/* harmony import */ var _distance_model_type__WEBPACK_IMPORTED_MODULE_127__ = __webpack_require__(/*! ./distance-model-type */ \"./node_modules/standardized-audio-context/build/es2019/types/distance-model-type.js\");\n/* harmony import */ var _dynamics_compressor_node_constructor__WEBPACK_IMPORTED_MODULE_128__ = __webpack_require__(/*! ./dynamics-compressor-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor.js\");\n/* harmony import */ var _dynamics_compressor_node_constructor_factory__WEBPACK_IMPORTED_MODULE_129__ = __webpack_require__(/*! ./dynamics-compressor-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-constructor-factory.js\");\n/* harmony import */ var _dynamics_compressor_node_renderer_factory__WEBPACK_IMPORTED_MODULE_130__ = __webpack_require__(/*! ./dynamics-compressor-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory.js\");\n/* harmony import */ var _dynamics_compressor_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_131__ = __webpack_require__(/*! ./dynamics-compressor-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/dynamics-compressor-node-renderer-factory-factory.js\");\n/* harmony import */ var _encoding_error_factory__WEBPACK_IMPORTED_MODULE_132__ = __webpack_require__(/*! ./encoding-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/encoding-error-factory.js\");\n/* harmony import */ var _error_event_handler__WEBPACK_IMPORTED_MODULE_133__ = __webpack_require__(/*! ./error-event-handler */ \"./node_modules/standardized-audio-context/build/es2019/types/error-event-handler.js\");\n/* harmony import */ var _evaluate_audio_worklet_global_scope_function__WEBPACK_IMPORTED_MODULE_134__ = __webpack_require__(/*! ./evaluate-audio-worklet-global-scope-function */ \"./node_modules/standardized-audio-context/build/es2019/types/evaluate-audio-worklet-global-scope-function.js\");\n/* harmony import */ var _evaluate_source_factory__WEBPACK_IMPORTED_MODULE_135__ = __webpack_require__(/*! ./evaluate-source-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-factory.js\");\n/* harmony import */ var _evaluate_source_function__WEBPACK_IMPORTED_MODULE_136__ = __webpack_require__(/*! ./evaluate-source-function */ \"./node_modules/standardized-audio-context/build/es2019/types/evaluate-source-function.js\");\n/* harmony import */ var _event_handler__WEBPACK_IMPORTED_MODULE_137__ = __webpack_require__(/*! ./event-handler */ \"./node_modules/standardized-audio-context/build/es2019/types/event-handler.js\");\n/* harmony import */ var _event_target_constructor__WEBPACK_IMPORTED_MODULE_138__ = __webpack_require__(/*! ./event-target-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor.js\");\n/* harmony import */ var _event_target_constructor_factory__WEBPACK_IMPORTED_MODULE_139__ = __webpack_require__(/*! ./event-target-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/event-target-constructor-factory.js\");\n/* harmony import */ var _expose_current_frame_and_current_time_factory__WEBPACK_IMPORTED_MODULE_140__ = __webpack_require__(/*! ./expose-current-frame-and-current-time-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-factory.js\");\n/* harmony import */ var _expose_current_frame_and_current_time_function__WEBPACK_IMPORTED_MODULE_141__ = __webpack_require__(/*! ./expose-current-frame-and-current-time-function */ \"./node_modules/standardized-audio-context/build/es2019/types/expose-current-frame-and-current-time-function.js\");\n/* harmony import */ var _fetch_source_factory__WEBPACK_IMPORTED_MODULE_142__ = __webpack_require__(/*! ./fetch-source-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/fetch-source-factory.js\");\n/* harmony import */ var _fetch_source_function__WEBPACK_IMPORTED_MODULE_143__ = __webpack_require__(/*! ./fetch-source-function */ \"./node_modules/standardized-audio-context/build/es2019/types/fetch-source-function.js\");\n/* harmony import */ var _gain_node_constructor__WEBPACK_IMPORTED_MODULE_144__ = __webpack_require__(/*! ./gain-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor.js\");\n/* harmony import */ var _gain_node_constructor_factory__WEBPACK_IMPORTED_MODULE_145__ = __webpack_require__(/*! ./gain-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-constructor-factory.js\");\n/* harmony import */ var _gain_node_renderer_factory__WEBPACK_IMPORTED_MODULE_146__ = __webpack_require__(/*! ./gain-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory.js\");\n/* harmony import */ var _gain_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_147__ = __webpack_require__(/*! ./gain-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/gain-node-renderer-factory-factory.js\");\n/* harmony import */ var _get_active_audio_worklet_node_inputs_factory__WEBPACK_IMPORTED_MODULE_148__ = __webpack_require__(/*! ./get-active-audio-worklet-node-inputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-factory.js\");\n/* harmony import */ var _get_active_audio_worklet_node_inputs_function__WEBPACK_IMPORTED_MODULE_149__ = __webpack_require__(/*! ./get-active-audio-worklet-node-inputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-active-audio-worklet-node-inputs-function.js\");\n/* harmony import */ var _get_audio_node_connections_function__WEBPACK_IMPORTED_MODULE_150__ = __webpack_require__(/*! ./get-audio-node-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-connections-function.js\");\n/* harmony import */ var _get_audio_node_renderer_factory__WEBPACK_IMPORTED_MODULE_151__ = __webpack_require__(/*! ./get-audio-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-factory.js\");\n/* harmony import */ var _get_audio_node_renderer_function__WEBPACK_IMPORTED_MODULE_152__ = __webpack_require__(/*! ./get-audio-node-renderer-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-renderer-function.js\");\n/* harmony import */ var _get_audio_node_tail_time_factory__WEBPACK_IMPORTED_MODULE_153__ = __webpack_require__(/*! ./get-audio-node-tail-time-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-factory.js\");\n/* harmony import */ var _get_audio_node_tail_time_function__WEBPACK_IMPORTED_MODULE_154__ = __webpack_require__(/*! ./get-audio-node-tail-time-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-node-tail-time-function.js\");\n/* harmony import */ var _get_audio_param_connections_function__WEBPACK_IMPORTED_MODULE_155__ = __webpack_require__(/*! ./get-audio-param-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-connections-function.js\");\n/* harmony import */ var _get_audio_param_renderer_factory__WEBPACK_IMPORTED_MODULE_156__ = __webpack_require__(/*! ./get-audio-param-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-factory.js\");\n/* harmony import */ var _get_audio_param_renderer_function__WEBPACK_IMPORTED_MODULE_157__ = __webpack_require__(/*! ./get-audio-param-renderer-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-audio-param-renderer-function.js\");\n/* harmony import */ var _get_backup_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_158__ = __webpack_require__(/*! ./get-backup-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-factory.js\");\n/* harmony import */ var _get_backup_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_159__ = __webpack_require__(/*! ./get-backup-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-backup-offline-audio-context-function.js\");\n/* harmony import */ var _get_event_listeners_of_audio_node_function__WEBPACK_IMPORTED_MODULE_160__ = __webpack_require__(/*! ./get-event-listeners-of-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-event-listeners-of-audio-node-function.js\");\n/* harmony import */ var _get_first_sample_function__WEBPACK_IMPORTED_MODULE_161__ = __webpack_require__(/*! ./get-first-sample-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-first-sample-function.js\");\n/* harmony import */ var _get_native_audio_node_function__WEBPACK_IMPORTED_MODULE_162__ = __webpack_require__(/*! ./get-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-node-function.js\");\n/* harmony import */ var _get_native_audio_param_function__WEBPACK_IMPORTED_MODULE_163__ = __webpack_require__(/*! ./get-native-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-audio-param-function.js\");\n/* harmony import */ var _get_native_context_factory__WEBPACK_IMPORTED_MODULE_164__ = __webpack_require__(/*! ./get-native-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-context-factory.js\");\n/* harmony import */ var _get_native_context_function__WEBPACK_IMPORTED_MODULE_165__ = __webpack_require__(/*! ./get-native-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-native-context-function.js\");\n/* harmony import */ var _get_or_create_backup_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_166__ = __webpack_require__(/*! ./get-or-create-backup-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-factory.js\");\n/* harmony import */ var _get_or_create_backup_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_167__ = __webpack_require__(/*! ./get-or-create-backup-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-or-create-backup-offline-audio-context-function.js\");\n/* harmony import */ var _get_unrendered_audio_worklet_nodes_factory__WEBPACK_IMPORTED_MODULE_168__ = __webpack_require__(/*! ./get-unrendered-audio-worklet-nodes-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-factory.js\");\n/* harmony import */ var _get_unrendered_audio_worklet_nodes_function__WEBPACK_IMPORTED_MODULE_169__ = __webpack_require__(/*! ./get-unrendered-audio-worklet-nodes-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-unrendered-audio-worklet-nodes-function.js\");\n/* harmony import */ var _get_value_for_key_function__WEBPACK_IMPORTED_MODULE_170__ = __webpack_require__(/*! ./get-value-for-key-function */ \"./node_modules/standardized-audio-context/build/es2019/types/get-value-for-key-function.js\");\n/* harmony import */ var _iir_filter_node_constructor__WEBPACK_IMPORTED_MODULE_171__ = __webpack_require__(/*! ./iir-filter-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor.js\");\n/* harmony import */ var _iir_filter_node_constructor_factory__WEBPACK_IMPORTED_MODULE_172__ = __webpack_require__(/*! ./iir-filter-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-constructor-factory.js\");\n/* harmony import */ var _iir_filter_node_renderer_factory__WEBPACK_IMPORTED_MODULE_173__ = __webpack_require__(/*! ./iir-filter-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory.js\");\n/* harmony import */ var _iir_filter_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_174__ = __webpack_require__(/*! ./iir-filter-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/iir-filter-node-renderer-factory-factory.js\");\n/* harmony import */ var _increment_cycle_counter_factory__WEBPACK_IMPORTED_MODULE_175__ = __webpack_require__(/*! ./increment-cycle-counter-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory.js\");\n/* harmony import */ var _increment_cycle_counter_factory_factory__WEBPACK_IMPORTED_MODULE_176__ = __webpack_require__(/*! ./increment-cycle-counter-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-factory-factory.js\");\n/* harmony import */ var _increment_cycle_counter_function__WEBPACK_IMPORTED_MODULE_177__ = __webpack_require__(/*! ./increment-cycle-counter-function */ \"./node_modules/standardized-audio-context/build/es2019/types/increment-cycle-counter-function.js\");\n/* harmony import */ var _index_size_error_factory__WEBPACK_IMPORTED_MODULE_178__ = __webpack_require__(/*! ./index-size-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/index-size-error-factory.js\");\n/* harmony import */ var _insert_element_in_set_function__WEBPACK_IMPORTED_MODULE_179__ = __webpack_require__(/*! ./insert-element-in-set-function */ \"./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js\");\n/* harmony import */ var _internal_state_event_listener__WEBPACK_IMPORTED_MODULE_180__ = __webpack_require__(/*! ./internal-state-event-listener */ \"./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js\");\n/* harmony import */ var _invalid_access_error_factory__WEBPACK_IMPORTED_MODULE_181__ = __webpack_require__(/*! ./invalid-access-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js\");\n/* harmony import */ var _invalid_state_error_factory__WEBPACK_IMPORTED_MODULE_182__ = __webpack_require__(/*! ./invalid-state-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js\");\n/* harmony import */ var _is_active_audio_node_function__WEBPACK_IMPORTED_MODULE_183__ = __webpack_require__(/*! ./is-active-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js\");\n/* harmony import */ var _is_any_audio_context_factory__WEBPACK_IMPORTED_MODULE_184__ = __webpack_require__(/*! ./is-any-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js\");\n/* harmony import */ var _is_any_audio_context_function__WEBPACK_IMPORTED_MODULE_185__ = __webpack_require__(/*! ./is-any-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js\");\n/* harmony import */ var _is_any_audio_node_factory__WEBPACK_IMPORTED_MODULE_186__ = __webpack_require__(/*! ./is-any-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js\");\n/* harmony import */ var _is_any_audio_node_function__WEBPACK_IMPORTED_MODULE_187__ = __webpack_require__(/*! ./is-any-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js\");\n/* harmony import */ var _is_any_audio_param_factory__WEBPACK_IMPORTED_MODULE_188__ = __webpack_require__(/*! ./is-any-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js\");\n/* harmony import */ var _is_any_audio_param_function__WEBPACK_IMPORTED_MODULE_189__ = __webpack_require__(/*! ./is-any-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js\");\n/* harmony import */ var _is_any_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_190__ = __webpack_require__(/*! ./is-any-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js\");\n/* harmony import */ var _is_any_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_191__ = __webpack_require__(/*! ./is-any-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js\");\n/* harmony import */ var _is_dc_curve_function__WEBPACK_IMPORTED_MODULE_192__ = __webpack_require__(/*! ./is-dc-curve-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js\");\n/* harmony import */ var _is_native_audio_context_factory__WEBPACK_IMPORTED_MODULE_193__ = __webpack_require__(/*! ./is-native-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js\");\n/* harmony import */ var _is_native_audio_context_function__WEBPACK_IMPORTED_MODULE_194__ = __webpack_require__(/*! ./is-native-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js\");\n/* harmony import */ var _is_native_audio_node_factory__WEBPACK_IMPORTED_MODULE_195__ = __webpack_require__(/*! ./is-native-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js\");\n/* harmony import */ var _is_native_audio_node_function__WEBPACK_IMPORTED_MODULE_196__ = __webpack_require__(/*! ./is-native-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js\");\n/* harmony import */ var _is_native_audio_param_factory__WEBPACK_IMPORTED_MODULE_197__ = __webpack_require__(/*! ./is-native-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js\");\n/* harmony import */ var _is_native_audio_param_function__WEBPACK_IMPORTED_MODULE_198__ = __webpack_require__(/*! ./is-native-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js\");\n/* harmony import */ var _is_native_context_factory__WEBPACK_IMPORTED_MODULE_199__ = __webpack_require__(/*! ./is-native-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js\");\n/* harmony import */ var _is_native_context_function__WEBPACK_IMPORTED_MODULE_200__ = __webpack_require__(/*! ./is-native-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js\");\n/* harmony import */ var _is_native_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_201__ = __webpack_require__(/*! ./is-native-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js\");\n/* harmony import */ var _is_native_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_202__ = __webpack_require__(/*! ./is-native-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js\");\n/* harmony import */ var _is_part_of_a_cycle_function__WEBPACK_IMPORTED_MODULE_203__ = __webpack_require__(/*! ./is-part-of-a-cycle-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js\");\n/* harmony import */ var _is_passive_audio_node_function__WEBPACK_IMPORTED_MODULE_204__ = __webpack_require__(/*! ./is-passive-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js\");\n/* harmony import */ var _is_secure_context_factory__WEBPACK_IMPORTED_MODULE_205__ = __webpack_require__(/*! ./is-secure-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js\");\n/* harmony import */ var _is_supported_promise_factory__WEBPACK_IMPORTED_MODULE_206__ = __webpack_require__(/*! ./is-supported-promise-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js\");\n/* harmony import */ var _media_element_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_207__ = __webpack_require__(/*! ./media-element-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js\");\n/* harmony import */ var _media_element_audio_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_208__ = __webpack_require__(/*! ./media-element-audio-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js\");\n/* harmony import */ var _media_stream_audio_destination_node_constructor__WEBPACK_IMPORTED_MODULE_209__ = __webpack_require__(/*! ./media-stream-audio-destination-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js\");\n/* harmony import */ var _media_stream_audio_destination_node_constructor_factory__WEBPACK_IMPORTED_MODULE_210__ = __webpack_require__(/*! ./media-stream-audio-destination-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js\");\n/* harmony import */ var _media_stream_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_211__ = __webpack_require__(/*! ./media-stream-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js\");\n/* harmony import */ var _media_stream_audio_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_212__ = __webpack_require__(/*! ./media-stream-audio-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js\");\n/* harmony import */ var _media_stream_track_audio_source_node_constructor__WEBPACK_IMPORTED_MODULE_213__ = __webpack_require__(/*! ./media-stream-track-audio-source-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js\");\n/* harmony import */ var _media_stream_track_audio_source_node_constructor_factory__WEBPACK_IMPORTED_MODULE_214__ = __webpack_require__(/*! ./media-stream-track-audio-source-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js\");\n/* harmony import */ var _minimal_audio_context_constructor__WEBPACK_IMPORTED_MODULE_215__ = __webpack_require__(/*! ./minimal-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js\");\n/* harmony import */ var _minimal_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_216__ = __webpack_require__(/*! ./minimal-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js\");\n/* harmony import */ var _minimal_base_audio_context_constructor__WEBPACK_IMPORTED_MODULE_217__ = __webpack_require__(/*! ./minimal-base-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js\");\n/* harmony import */ var _minimal_base_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_218__ = __webpack_require__(/*! ./minimal-base-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js\");\n/* harmony import */ var _minimal_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_219__ = __webpack_require__(/*! ./minimal-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js\");\n/* harmony import */ var _minimal_offline_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_220__ = __webpack_require__(/*! ./minimal-offline-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js\");\n/* harmony import */ var _monitor_connections_factory__WEBPACK_IMPORTED_MODULE_221__ = __webpack_require__(/*! ./monitor-connections-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js\");\n/* harmony import */ var _monitor_connections_function__WEBPACK_IMPORTED_MODULE_222__ = __webpack_require__(/*! ./monitor-connections-function */ \"./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js\");\n/* harmony import */ var _native_analyser_node__WEBPACK_IMPORTED_MODULE_223__ = __webpack_require__(/*! ./native-analyser-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js\");\n/* harmony import */ var _native_analyser_node_factory__WEBPACK_IMPORTED_MODULE_224__ = __webpack_require__(/*! ./native-analyser-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js\");\n/* harmony import */ var _native_analyser_node_factory_factory__WEBPACK_IMPORTED_MODULE_225__ = __webpack_require__(/*! ./native-analyser-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js\");\n/* harmony import */ var _native_audio_buffer__WEBPACK_IMPORTED_MODULE_226__ = __webpack_require__(/*! ./native-audio-buffer */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js\");\n/* harmony import */ var _native_audio_buffer_constructor__WEBPACK_IMPORTED_MODULE_227__ = __webpack_require__(/*! ./native-audio-buffer-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js\");\n/* harmony import */ var _native_audio_buffer_constructor_factory__WEBPACK_IMPORTED_MODULE_228__ = __webpack_require__(/*! ./native-audio-buffer-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js\");\n/* harmony import */ var _native_audio_buffer_source_node__WEBPACK_IMPORTED_MODULE_229__ = __webpack_require__(/*! ./native-audio-buffer-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js\");\n/* harmony import */ var _native_audio_buffer_source_node_factory__WEBPACK_IMPORTED_MODULE_230__ = __webpack_require__(/*! ./native-audio-buffer-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js\");\n/* harmony import */ var _native_audio_buffer_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_231__ = __webpack_require__(/*! ./native-audio-buffer-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js\");\n/* harmony import */ var _native_audio_context__WEBPACK_IMPORTED_MODULE_232__ = __webpack_require__(/*! ./native-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js\");\n/* harmony import */ var _native_audio_context_constructor__WEBPACK_IMPORTED_MODULE_233__ = __webpack_require__(/*! ./native-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js\");\n/* harmony import */ var _native_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_234__ = __webpack_require__(/*! ./native-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js\");\n/* harmony import */ var _native_audio_destination_node__WEBPACK_IMPORTED_MODULE_235__ = __webpack_require__(/*! ./native-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js\");\n/* harmony import */ var _native_audio_destination_node_factory__WEBPACK_IMPORTED_MODULE_236__ = __webpack_require__(/*! ./native-audio-destination-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js\");\n/* harmony import */ var _native_audio_destination_node_factory_factory__WEBPACK_IMPORTED_MODULE_237__ = __webpack_require__(/*! ./native-audio-destination-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js\");\n/* harmony import */ var _native_audio_listener__WEBPACK_IMPORTED_MODULE_238__ = __webpack_require__(/*! ./native-audio-listener */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js\");\n/* harmony import */ var _native_audio_node__WEBPACK_IMPORTED_MODULE_239__ = __webpack_require__(/*! ./native-audio-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js\");\n/* harmony import */ var _native_audio_param__WEBPACK_IMPORTED_MODULE_240__ = __webpack_require__(/*! ./native-audio-param */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js\");\n/* harmony import */ var _native_audio_param_map__WEBPACK_IMPORTED_MODULE_241__ = __webpack_require__(/*! ./native-audio-param-map */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js\");\n/* harmony import */ var _native_audio_worklet__WEBPACK_IMPORTED_MODULE_242__ = __webpack_require__(/*! ./native-audio-worklet */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js\");\n/* harmony import */ var _native_audio_worklet_node__WEBPACK_IMPORTED_MODULE_243__ = __webpack_require__(/*! ./native-audio-worklet-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js\");\n/* harmony import */ var _native_audio_worklet_node_constructor__WEBPACK_IMPORTED_MODULE_244__ = __webpack_require__(/*! ./native-audio-worklet-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js\");\n/* harmony import */ var _native_audio_worklet_node_constructor_factory__WEBPACK_IMPORTED_MODULE_245__ = __webpack_require__(/*! ./native-audio-worklet-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_factory__WEBPACK_IMPORTED_MODULE_246__ = __webpack_require__(/*! ./native-audio-worklet-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_factory_factory__WEBPACK_IMPORTED_MODULE_247__ = __webpack_require__(/*! ./native-audio-worklet-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_faker_factory__WEBPACK_IMPORTED_MODULE_248__ = __webpack_require__(/*! ./native-audio-worklet-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_249__ = __webpack_require__(/*! ./native-audio-worklet-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js\");\n/* harmony import */ var _native_audio_worklet_node_options__WEBPACK_IMPORTED_MODULE_250__ = __webpack_require__(/*! ./native-audio-worklet-node-options */ \"./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js\");\n/* harmony import */ var _native_biquad_filter_node__WEBPACK_IMPORTED_MODULE_251__ = __webpack_require__(/*! ./native-biquad-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js\");\n/* harmony import */ var _native_biquad_filter_node_factory__WEBPACK_IMPORTED_MODULE_252__ = __webpack_require__(/*! ./native-biquad-filter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js\");\n/* harmony import */ var _native_channel_merger_node__WEBPACK_IMPORTED_MODULE_253__ = __webpack_require__(/*! ./native-channel-merger-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js\");\n/* harmony import */ var _native_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_254__ = __webpack_require__(/*! ./native-channel-merger-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js\");\n/* harmony import */ var _native_channel_merger_node_factory_factory__WEBPACK_IMPORTED_MODULE_255__ = __webpack_require__(/*! ./native-channel-merger-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js\");\n/* harmony import */ var _native_channel_splitter_node__WEBPACK_IMPORTED_MODULE_256__ = __webpack_require__(/*! ./native-channel-splitter-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js\");\n/* harmony import */ var _native_channel_splitter_node_factory__WEBPACK_IMPORTED_MODULE_257__ = __webpack_require__(/*! ./native-channel-splitter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js\");\n/* harmony import */ var _native_constant_source_node__WEBPACK_IMPORTED_MODULE_258__ = __webpack_require__(/*! ./native-constant-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js\");\n/* harmony import */ var _native_constant_source_node_factory__WEBPACK_IMPORTED_MODULE_259__ = __webpack_require__(/*! ./native-constant-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js\");\n/* harmony import */ var _native_constant_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_260__ = __webpack_require__(/*! ./native-constant-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js\");\n/* harmony import */ var _native_constant_source_node_faker_factory__WEBPACK_IMPORTED_MODULE_261__ = __webpack_require__(/*! ./native-constant-source-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js\");\n/* harmony import */ var _native_constant_source_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_262__ = __webpack_require__(/*! ./native-constant-source-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js\");\n/* harmony import */ var _native_context__WEBPACK_IMPORTED_MODULE_263__ = __webpack_require__(/*! ./native-context */ \"./node_modules/standardized-audio-context/build/es2019/types/native-context.js\");\n/* harmony import */ var _native_convolver_node__WEBPACK_IMPORTED_MODULE_264__ = __webpack_require__(/*! ./native-convolver-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js\");\n/* harmony import */ var _native_convolver_node_factory__WEBPACK_IMPORTED_MODULE_265__ = __webpack_require__(/*! ./native-convolver-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js\");\n/* harmony import */ var _native_convolver_node_factory_factory__WEBPACK_IMPORTED_MODULE_266__ = __webpack_require__(/*! ./native-convolver-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js\");\n/* harmony import */ var _native_delay_node_factory__WEBPACK_IMPORTED_MODULE_267__ = __webpack_require__(/*! ./native-delay-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js\");\n/* harmony import */ var _native_delay_node__WEBPACK_IMPORTED_MODULE_268__ = __webpack_require__(/*! ./native-delay-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js\");\n/* harmony import */ var _native_dynamics_compressor_node__WEBPACK_IMPORTED_MODULE_269__ = __webpack_require__(/*! ./native-dynamics-compressor-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js\");\n/* harmony import */ var _native_dynamics_compressor_node_factory__WEBPACK_IMPORTED_MODULE_270__ = __webpack_require__(/*! ./native-dynamics-compressor-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js\");\n/* harmony import */ var _native_dynamics_compressor_node_factory_factory__WEBPACK_IMPORTED_MODULE_271__ = __webpack_require__(/*! ./native-dynamics-compressor-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js\");\n/* harmony import */ var _native_event_target__WEBPACK_IMPORTED_MODULE_272__ = __webpack_require__(/*! ./native-event-target */ \"./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js\");\n/* harmony import */ var _native_gain_node__WEBPACK_IMPORTED_MODULE_273__ = __webpack_require__(/*! ./native-gain-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js\");\n/* harmony import */ var _native_gain_node_factory__WEBPACK_IMPORTED_MODULE_274__ = __webpack_require__(/*! ./native-gain-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js\");\n/* harmony import */ var _native_iir_filter_node__WEBPACK_IMPORTED_MODULE_275__ = __webpack_require__(/*! ./native-iir-filter-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js\");\n/* harmony import */ var _native_iir_filter_node_factory__WEBPACK_IMPORTED_MODULE_276__ = __webpack_require__(/*! ./native-iir-filter-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js\");\n/* harmony import */ var _native_iir_filter_node_factory_factory__WEBPACK_IMPORTED_MODULE_277__ = __webpack_require__(/*! ./native-iir-filter-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js\");\n/* harmony import */ var _native_iir_filter_node_faker_factory__WEBPACK_IMPORTED_MODULE_278__ = __webpack_require__(/*! ./native-iir-filter-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js\");\n/* harmony import */ var _native_iir_filter_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_279__ = __webpack_require__(/*! ./native-iir-filter-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js\");\n/* harmony import */ var _native_media_element_audio_source_node__WEBPACK_IMPORTED_MODULE_280__ = __webpack_require__(/*! ./native-media-element-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js\");\n/* harmony import */ var _native_media_element_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_281__ = __webpack_require__(/*! ./native-media-element-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js\");\n/* harmony import */ var _native_media_stream_audio_destination_node__WEBPACK_IMPORTED_MODULE_282__ = __webpack_require__(/*! ./native-media-stream-audio-destination-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js\");\n/* harmony import */ var _native_media_stream_audio_destination_node_factory__WEBPACK_IMPORTED_MODULE_283__ = __webpack_require__(/*! ./native-media-stream-audio-destination-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js\");\n/* harmony import */ var _native_media_stream_audio_source_node__WEBPACK_IMPORTED_MODULE_284__ = __webpack_require__(/*! ./native-media-stream-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js\");\n/* harmony import */ var _native_media_stream_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_285__ = __webpack_require__(/*! ./native-media-stream-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js\");\n/* harmony import */ var _native_media_stream_track_audio_source_node__WEBPACK_IMPORTED_MODULE_286__ = __webpack_require__(/*! ./native-media-stream-track-audio-source-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js\");\n/* harmony import */ var _native_media_stream_track_audio_source_node_factory__WEBPACK_IMPORTED_MODULE_287__ = __webpack_require__(/*! ./native-media-stream-track-audio-source-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js\");\n/* harmony import */ var _native_media_stream_track_audio_source_node_factory_factory__WEBPACK_IMPORTED_MODULE_288__ = __webpack_require__(/*! ./native-media-stream-track-audio-source-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js\");\n/* harmony import */ var _native_offline_audio_context__WEBPACK_IMPORTED_MODULE_289__ = __webpack_require__(/*! ./native-offline-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js\");\n/* harmony import */ var _native_offline_audio_context_constructor__WEBPACK_IMPORTED_MODULE_290__ = __webpack_require__(/*! ./native-offline-audio-context-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js\");\n/* harmony import */ var _native_offline_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_291__ = __webpack_require__(/*! ./native-offline-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js\");\n/* harmony import */ var _native_oscillator_node__WEBPACK_IMPORTED_MODULE_292__ = __webpack_require__(/*! ./native-oscillator-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js\");\n/* harmony import */ var _native_oscillator_node_factory__WEBPACK_IMPORTED_MODULE_293__ = __webpack_require__(/*! ./native-oscillator-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js\");\n/* harmony import */ var _native_oscillator_node_factory_factory__WEBPACK_IMPORTED_MODULE_294__ = __webpack_require__(/*! ./native-oscillator-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js\");\n/* harmony import */ var _native_panner_node__WEBPACK_IMPORTED_MODULE_295__ = __webpack_require__(/*! ./native-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js\");\n/* harmony import */ var _native_panner_node_factory__WEBPACK_IMPORTED_MODULE_296__ = __webpack_require__(/*! ./native-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js\");\n/* harmony import */ var _native_panner_node_factory_factory__WEBPACK_IMPORTED_MODULE_297__ = __webpack_require__(/*! ./native-panner-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js\");\n/* harmony import */ var _native_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_298__ = __webpack_require__(/*! ./native-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js\");\n/* harmony import */ var _native_panner_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_299__ = __webpack_require__(/*! ./native-panner-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js\");\n/* harmony import */ var _native_periodic_wave__WEBPACK_IMPORTED_MODULE_300__ = __webpack_require__(/*! ./native-periodic-wave */ \"./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js\");\n/* harmony import */ var _native_periodic_wave_factory__WEBPACK_IMPORTED_MODULE_301__ = __webpack_require__(/*! ./native-periodic-wave-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js\");\n/* harmony import */ var _native_periodic_wave_factory_factory__WEBPACK_IMPORTED_MODULE_302__ = __webpack_require__(/*! ./native-periodic-wave-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js\");\n/* harmony import */ var _native_script_processor_node__WEBPACK_IMPORTED_MODULE_303__ = __webpack_require__(/*! ./native-script-processor-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js\");\n/* harmony import */ var _native_script_processor_node_factory__WEBPACK_IMPORTED_MODULE_304__ = __webpack_require__(/*! ./native-script-processor-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js\");\n/* harmony import */ var _native_stereo_panner_node__WEBPACK_IMPORTED_MODULE_305__ = __webpack_require__(/*! ./native-stereo-panner-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js\");\n/* harmony import */ var _native_stereo_panner_node_factory__WEBPACK_IMPORTED_MODULE_306__ = __webpack_require__(/*! ./native-stereo-panner-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js\");\n/* harmony import */ var _native_stereo_panner_node_factory_factory__WEBPACK_IMPORTED_MODULE_307__ = __webpack_require__(/*! ./native-stereo-panner-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js\");\n/* harmony import */ var _native_stereo_panner_node_faker_factory__WEBPACK_IMPORTED_MODULE_308__ = __webpack_require__(/*! ./native-stereo-panner-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js\");\n/* harmony import */ var _native_stereo_panner_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_309__ = __webpack_require__(/*! ./native-stereo-panner-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js\");\n/* harmony import */ var _native_wave_shaper_node__WEBPACK_IMPORTED_MODULE_310__ = __webpack_require__(/*! ./native-wave-shaper-node */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js\");\n/* harmony import */ var _native_wave_shaper_node_factory__WEBPACK_IMPORTED_MODULE_311__ = __webpack_require__(/*! ./native-wave-shaper-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js\");\n/* harmony import */ var _native_wave_shaper_node_factory_factory__WEBPACK_IMPORTED_MODULE_312__ = __webpack_require__(/*! ./native-wave-shaper-node-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js\");\n/* harmony import */ var _native_wave_shaper_node_faker_factory__WEBPACK_IMPORTED_MODULE_313__ = __webpack_require__(/*! ./native-wave-shaper-node-faker-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js\");\n/* harmony import */ var _native_wave_shaper_node_faker_factory_factory__WEBPACK_IMPORTED_MODULE_314__ = __webpack_require__(/*! ./native-wave-shaper-node-faker-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js\");\n/* harmony import */ var _not_supported_error_factory__WEBPACK_IMPORTED_MODULE_315__ = __webpack_require__(/*! ./not-supported-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js\");\n/* harmony import */ var _offline_audio_context_constructor_factory__WEBPACK_IMPORTED_MODULE_316__ = __webpack_require__(/*! ./offline-audio-context-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js\");\n/* harmony import */ var _oscillator_node_constructor__WEBPACK_IMPORTED_MODULE_317__ = __webpack_require__(/*! ./oscillator-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js\");\n/* harmony import */ var _oscillator_node_constructor_factory__WEBPACK_IMPORTED_MODULE_318__ = __webpack_require__(/*! ./oscillator-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js\");\n/* harmony import */ var _oscillator_node_renderer__WEBPACK_IMPORTED_MODULE_319__ = __webpack_require__(/*! ./oscillator-node-renderer */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js\");\n/* harmony import */ var _oscillator_node_renderer_factory__WEBPACK_IMPORTED_MODULE_320__ = __webpack_require__(/*! ./oscillator-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js\");\n/* harmony import */ var _oscillator_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_321__ = __webpack_require__(/*! ./oscillator-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js\");\n/* harmony import */ var _oscillator_type__WEBPACK_IMPORTED_MODULE_322__ = __webpack_require__(/*! ./oscillator-type */ \"./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js\");\n/* harmony import */ var _output_connection__WEBPACK_IMPORTED_MODULE_323__ = __webpack_require__(/*! ./output-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/output-connection.js\");\n/* harmony import */ var _over_sample_type__WEBPACK_IMPORTED_MODULE_324__ = __webpack_require__(/*! ./over-sample-type */ \"./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js\");\n/* harmony import */ var _overwrite_accessors_function__WEBPACK_IMPORTED_MODULE_325__ = __webpack_require__(/*! ./overwrite-accessors-function */ \"./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js\");\n/* harmony import */ var _panner_node_constructor__WEBPACK_IMPORTED_MODULE_326__ = __webpack_require__(/*! ./panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js\");\n/* harmony import */ var _panner_node_constructor_factory__WEBPACK_IMPORTED_MODULE_327__ = __webpack_require__(/*! ./panner-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js\");\n/* harmony import */ var _panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_328__ = __webpack_require__(/*! ./panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js\");\n/* harmony import */ var _panner_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_329__ = __webpack_require__(/*! ./panner-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js\");\n/* harmony import */ var _panning_model_type__WEBPACK_IMPORTED_MODULE_330__ = __webpack_require__(/*! ./panning-model-type */ \"./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js\");\n/* harmony import */ var _passive_audio_node_input_connection__WEBPACK_IMPORTED_MODULE_331__ = __webpack_require__(/*! ./passive-audio-node-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js\");\n/* harmony import */ var _passive_audio_param_input_connection__WEBPACK_IMPORTED_MODULE_332__ = __webpack_require__(/*! ./passive-audio-param-input-connection */ \"./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js\");\n/* harmony import */ var _periodic_wave_constructor__WEBPACK_IMPORTED_MODULE_333__ = __webpack_require__(/*! ./periodic-wave-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js\");\n/* harmony import */ var _periodic_wave_constructor_factory__WEBPACK_IMPORTED_MODULE_334__ = __webpack_require__(/*! ./periodic-wave-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js\");\n/* harmony import */ var _pick_element_from_set_function__WEBPACK_IMPORTED_MODULE_335__ = __webpack_require__(/*! ./pick-element-from-set-function */ \"./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js\");\n/* harmony import */ var _render_automation_factory__WEBPACK_IMPORTED_MODULE_336__ = __webpack_require__(/*! ./render-automation-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js\");\n/* harmony import */ var _render_automation_function__WEBPACK_IMPORTED_MODULE_337__ = __webpack_require__(/*! ./render-automation-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js\");\n/* harmony import */ var _render_inputs_of_audio_node_factory__WEBPACK_IMPORTED_MODULE_338__ = __webpack_require__(/*! ./render-inputs-of-audio-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js\");\n/* harmony import */ var _render_inputs_of_audio_node_function__WEBPACK_IMPORTED_MODULE_339__ = __webpack_require__(/*! ./render-inputs-of-audio-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js\");\n/* harmony import */ var _render_inputs_of_audio_param_factory__WEBPACK_IMPORTED_MODULE_340__ = __webpack_require__(/*! ./render-inputs-of-audio-param-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js\");\n/* harmony import */ var _render_inputs_of_audio_param_function__WEBPACK_IMPORTED_MODULE_341__ = __webpack_require__(/*! ./render-inputs-of-audio-param-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js\");\n/* harmony import */ var _render_native_offline_audio_context_factory__WEBPACK_IMPORTED_MODULE_342__ = __webpack_require__(/*! ./render-native-offline-audio-context-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js\");\n/* harmony import */ var _render_native_offline_audio_context_function__WEBPACK_IMPORTED_MODULE_343__ = __webpack_require__(/*! ./render-native-offline-audio-context-function */ \"./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js\");\n/* harmony import */ var _sanitize_audio_worklet_node_options_function__WEBPACK_IMPORTED_MODULE_344__ = __webpack_require__(/*! ./sanitize-audio-worklet-node-options-function */ \"./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js\");\n/* harmony import */ var _sanitize_channel_splitter_options_function__WEBPACK_IMPORTED_MODULE_345__ = __webpack_require__(/*! ./sanitize-channel-splitter-options-function */ \"./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js\");\n/* harmony import */ var _sanitize_periodic_wave_options_function__WEBPACK_IMPORTED_MODULE_346__ = __webpack_require__(/*! ./sanitize-periodic-wave-options-function */ \"./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js\");\n/* harmony import */ var _set_active_audio_worklet_node_inputs_factory__WEBPACK_IMPORTED_MODULE_347__ = __webpack_require__(/*! ./set-active-audio-worklet-node-inputs-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js\");\n/* harmony import */ var _set_active_audio_worklet_node_inputs_function__WEBPACK_IMPORTED_MODULE_348__ = __webpack_require__(/*! ./set-active-audio-worklet-node-inputs-function */ \"./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js\");\n/* harmony import */ var _set_audio_node_tail_time_factory__WEBPACK_IMPORTED_MODULE_349__ = __webpack_require__(/*! ./set-audio-node-tail-time-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js\");\n/* harmony import */ var _set_audio_node_tail_time_function__WEBPACK_IMPORTED_MODULE_350__ = __webpack_require__(/*! ./set-audio-node-tail-time-function */ \"./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js\");\n/* harmony import */ var _set_value_at_time_until_possible_function__WEBPACK_IMPORTED_MODULE_351__ = __webpack_require__(/*! ./set-value-at-time-until-possible-function */ \"./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js\");\n/* harmony import */ var _start_rendering_factory__WEBPACK_IMPORTED_MODULE_352__ = __webpack_require__(/*! ./start-rendering-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js\");\n/* harmony import */ var _start_rendering_function__WEBPACK_IMPORTED_MODULE_353__ = __webpack_require__(/*! ./start-rendering-function */ \"./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js\");\n/* harmony import */ var _stereo_panner_node_constructor__WEBPACK_IMPORTED_MODULE_354__ = __webpack_require__(/*! ./stereo-panner-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js\");\n/* harmony import */ var _stereo_panner_node_constructor_factory__WEBPACK_IMPORTED_MODULE_355__ = __webpack_require__(/*! ./stereo-panner-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js\");\n/* harmony import */ var _stereo_panner_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_356__ = __webpack_require__(/*! ./stereo-panner-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js\");\n/* harmony import */ var _stereo_panner_node_renderer_factory__WEBPACK_IMPORTED_MODULE_357__ = __webpack_require__(/*! ./stereo-panner-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js\");\n/* harmony import */ var _test_audio_buffer_copy_channel_methods_subarray_support_factory__WEBPACK_IMPORTED_MODULE_358__ = __webpack_require__(/*! ./test-audio-buffer-copy-channel-methods-subarray-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js\");\n/* harmony import */ var _test_audio_buffer_constructor_support_factory__WEBPACK_IMPORTED_MODULE_359__ = __webpack_require__(/*! ./test-audio-buffer-constructor-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js\");\n/* harmony import */ var _test_audio_context_close_method_support_factory__WEBPACK_IMPORTED_MODULE_360__ = __webpack_require__(/*! ./test-audio-context-close-method-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js\");\n/* harmony import */ var _test_audio_context_decode_audio_data_method_type_error_support_factory__WEBPACK_IMPORTED_MODULE_361__ = __webpack_require__(/*! ./test-audio-context-decode-audio-data-method-type-error-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js\");\n/* harmony import */ var _test_audio_context_options_support_factory__WEBPACK_IMPORTED_MODULE_362__ = __webpack_require__(/*! ./test-audio-context-options-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js\");\n/* harmony import */ var _test_audio_node_connect_method_support_factory__WEBPACK_IMPORTED_MODULE_363__ = __webpack_require__(/*! ./test-audio-node-connect-method-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js\");\n/* harmony import */ var _test_audio_worklet_node_options_clonability_function__WEBPACK_IMPORTED_MODULE_364__ = __webpack_require__(/*! ./test-audio-worklet-node-options-clonability-function */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js\");\n/* harmony import */ var _test_audio_worklet_processor_no_outputs_support_factory__WEBPACK_IMPORTED_MODULE_365__ = __webpack_require__(/*! ./test-audio-worklet-processor-no-outputs-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js\");\n/* harmony import */ var _test_audio_worklet_processor_post_message_support_factory__WEBPACK_IMPORTED_MODULE_366__ = __webpack_require__(/*! ./test-audio-worklet-processor-post-message-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js\");\n/* harmony import */ var _test_channel_merger_node_channel_count_support_factory__WEBPACK_IMPORTED_MODULE_367__ = __webpack_require__(/*! ./test-channel-merger-node-channel-count-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js\");\n/* harmony import */ var _test_constant_source_node_accurate_scheduling_support_factory__WEBPACK_IMPORTED_MODULE_368__ = __webpack_require__(/*! ./test-constant-source-node-accurate-scheduling-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js\");\n/* harmony import */ var _test_convolver_node_buffer_reassignability_support_factory__WEBPACK_IMPORTED_MODULE_369__ = __webpack_require__(/*! ./test-convolver-node-buffer-reassignability-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js\");\n/* harmony import */ var _test_convolver_node_channel_count_support_factory__WEBPACK_IMPORTED_MODULE_370__ = __webpack_require__(/*! ./test-convolver-node-channel-count-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js\");\n/* harmony import */ var _test_is_secure_context_support_factory__WEBPACK_IMPORTED_MODULE_371__ = __webpack_require__(/*! ./test-is-secure-context-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js\");\n/* harmony import */ var _test_media_stream_audio_source_node_media_stream_without_audio_track_support__WEBPACK_IMPORTED_MODULE_372__ = __webpack_require__(/*! ./test-media-stream-audio-source-node-media-stream-without-audio-track-support */ \"./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js\");\n/* harmony import */ var _test_offline_audio_context_current_time_support_factory__WEBPACK_IMPORTED_MODULE_373__ = __webpack_require__(/*! ./test-offline-audio-context-current-time-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js\");\n/* harmony import */ var _test_stereo_panner_node_default_value_support_factory__WEBPACK_IMPORTED_MODULE_374__ = __webpack_require__(/*! ./test-stereo-panner-node-default-value-support-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js\");\n/* harmony import */ var _unknown_error_factory__WEBPACK_IMPORTED_MODULE_375__ = __webpack_require__(/*! ./unknown-error-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js\");\n/* harmony import */ var _unrendered_audio_worklet_node_store__WEBPACK_IMPORTED_MODULE_376__ = __webpack_require__(/*! ./unrendered-audio-worklet-node-store */ \"./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js\");\n/* harmony import */ var _unrendered_audio_worklet_nodes__WEBPACK_IMPORTED_MODULE_377__ = __webpack_require__(/*! ./unrendered-audio-worklet-nodes */ \"./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js\");\n/* harmony import */ var _wave_shaper_node_constructor__WEBPACK_IMPORTED_MODULE_378__ = __webpack_require__(/*! ./wave-shaper-node-constructor */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js\");\n/* harmony import */ var _wave_shaper_node_constructor_factory__WEBPACK_IMPORTED_MODULE_379__ = __webpack_require__(/*! ./wave-shaper-node-constructor-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js\");\n/* harmony import */ var _wave_shaper_node_renderer_factory_factory__WEBPACK_IMPORTED_MODULE_380__ = __webpack_require__(/*! ./wave-shaper-node-renderer-factory-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js\");\n/* harmony import */ var _wave_shaper_node_renderer_factory__WEBPACK_IMPORTED_MODULE_381__ = __webpack_require__(/*! ./wave-shaper-node-renderer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js\");\n/* harmony import */ var _window__WEBPACK_IMPORTED_MODULE_382__ = __webpack_require__(/*! ./window */ \"./node_modules/standardized-audio-context/build/es2019/types/window.js\");\n/* harmony import */ var _window_factory__WEBPACK_IMPORTED_MODULE_383__ = __webpack_require__(/*! ./window-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/window-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_factory__WEBPACK_IMPORTED_MODULE_384__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_function__WEBPACK_IMPORTED_MODULE_385__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_out_of_bounds_factory__WEBPACK_IMPORTED_MODULE_386__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_copy_channel_methods_out_of_bounds_function__WEBPACK_IMPORTED_MODULE_387__ = __webpack_require__(/*! ./wrap-audio-buffer-copy-channel-methods-out-of-bounds-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js\");\n/* harmony import */ var _wrap_audio_buffer_source_node_start_method_offset_clamping_function__WEBPACK_IMPORTED_MODULE_388__ = __webpack_require__(/*! ./wrap-audio-buffer-source-node-start-method-offset-clamping-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js\");\n/* harmony import */ var _wrap_audio_buffer_source_node_stop_method_nullified_buffer_factory__WEBPACK_IMPORTED_MODULE_389__ = __webpack_require__(/*! ./wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js\");\n/* harmony import */ var _wrap_audio_buffer_source_node_stop_method_nullified_buffer_function__WEBPACK_IMPORTED_MODULE_390__ = __webpack_require__(/*! ./wrap-audio-buffer-source-node-stop-method-nullified-buffer-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js\");\n/* harmony import */ var _wrap_audio_scheduled_source_node_stop_method_consecutive_calls_function__WEBPACK_IMPORTED_MODULE_391__ = __webpack_require__(/*! ./wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js\");\n/* harmony import */ var _wrap_channel_merger_node_factory__WEBPACK_IMPORTED_MODULE_392__ = __webpack_require__(/*! ./wrap-channel-merger-node-factory */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js\");\n/* harmony import */ var _wrap_channel_merger_node_function__WEBPACK_IMPORTED_MODULE_393__ = __webpack_require__(/*! ./wrap-channel-merger-node-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js\");\n/* harmony import */ var _wrap_event_listener_function__WEBPACK_IMPORTED_MODULE_394__ = __webpack_require__(/*! ./wrap-event-listener-function */ \"./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/index.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=insert-element-in-set-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/insert-element-in-set-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=internal-state-event-listener.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/internal-state-event-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=invalid-access-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/invalid-access-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=invalid-state-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/invalid-state-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-active-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-active-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-param-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-audio-param-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-any-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-any-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-dc-curve-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-dc-curve-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-param-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-audio-param-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-native-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-native-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-part-of-a-cycle-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-part-of-a-cycle-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-passive-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-passive-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-secure-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-secure-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=is-supported-promise-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/is-supported-promise-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-element-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-element-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-destination-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-destination-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-destination-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-stream-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js":
/*!********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js ***!
  \********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=media-stream-track-audio-source-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/media-stream-track-audio-source-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/minimal-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-base-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/minimal-base-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-offline-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=minimal-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/minimal-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=monitor-connections-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=monitor-connections-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/monitor-connections-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-analyser-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-analyser-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-analyser-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-analyser-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-buffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-buffer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-destination-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-destination-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-destination-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-listener.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-listener.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-param-map.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-param-map.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-param.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node-options.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node-options.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-audio-worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-audio-worklet.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-biquad-filter-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-biquad-filter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-biquad-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-merger-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-merger-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-merger-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-channel-merger-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-splitter-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-channel-splitter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-channel-splitter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-constant-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-constant-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-context.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-context.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js":
/*!*****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js ***!
  \*****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-convolver-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-convolver-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-delay-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-delay-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-delay-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-delay-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-dynamics-compressor-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-dynamics-compressor-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-dynamics-compressor-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-dynamics-compressor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js":
/*!*******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js ***!
  \*******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-event-target.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-event-target.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-gain-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-gain-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-gain-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-gain-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-iir-filter-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-iir-filter-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-element-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-element-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-element-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js":
/*!**************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js ***!
  \**************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-destination-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-destination-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-destination-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js":
/*!***********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js ***!
  \***********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-track-audio-source-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js ***!
  \***************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-track-audio-source-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-media-stream-track-audio-source-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-media-stream-track-audio-source-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js":
/*!************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js ***!
  \************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-offline-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-offline-audio-context-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-offline-audio-context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-offline-audio-context.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-oscillator-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-oscillator-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js":
/*!**********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js ***!
  \**********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-oscillator-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-oscillator-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js":
/*!**********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js ***!
  \**********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-panner-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-periodic-wave-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-periodic-wave-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js":
/*!********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js ***!
  \********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-periodic-wave.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-periodic-wave.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-script-processor-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-script-processor-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-script-processor-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-stereo-panner-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-stereo-panner-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-faker-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node-faker-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node-faker-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=native-wave-shaper-node.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/native-wave-shaper-node.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=not-supported-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/not-supported-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=offline-audio-context-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/offline-audio-context-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js":
/*!***************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js ***!
  \***************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js":
/*!****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js ***!
  \****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-node-renderer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/oscillator-node-renderer.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=oscillator-type.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/oscillator-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/output-connection.js":
/*!*****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/output-connection.js ***!
  \*****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=output-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/output-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js":
/*!****************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js ***!
  \****************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=over-sample-type.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/over-sample-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=overwrite-accessors-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/overwrite-accessors-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js":
/*!*******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js ***!
  \*******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js":
/*!******************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js ***!
  \******************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=panning-model-type.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/panning-model-type.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=passive-audio-node-input-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/passive-audio-node-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=passive-audio-param-input-connection.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/passive-audio-param-input-connection.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=periodic-wave-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/periodic-wave-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=pick-element-from-set-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/pick-element-from-set-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js":
/*!*************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js ***!
  \*************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-automation-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-automation-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js":
/*!**************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js ***!
  \**************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-automation-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-automation-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-param-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js":
/*!*************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js ***!
  \*************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-inputs-of-audio-param-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-inputs-of-audio-param-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-native-offline-audio-context-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=render-native-offline-audio-context-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/render-native-offline-audio-context-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=sanitize-audio-worklet-node-options-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/sanitize-audio-worklet-node-options-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=sanitize-channel-splitter-options-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/sanitize-channel-splitter-options-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js":
/*!***************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js ***!
  \***************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=sanitize-periodic-wave-options-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/sanitize-periodic-wave-options-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js":
/*!********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js ***!
  \********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-active-audio-worklet-node-inputs-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-active-audio-worklet-node-inputs-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/set-active-audio-worklet-node-inputs-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-audio-node-tail-time-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-audio-node-tail-time-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/set-audio-node-tail-time-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=set-value-at-time-until-possible-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/set-value-at-time-until-possible-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js":
/*!***********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js ***!
  \***********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=start-rendering-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/start-rendering-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js":
/*!************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js ***!
  \************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=start-rendering-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/start-rendering-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js":
/*!*******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js ***!
  \*******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=stereo-panner-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/stereo-panner-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js ***!
  \*********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-buffer-constructor-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-constructor-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js":
/*!***************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js ***!
  \***************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-buffer-copy-channel-methods-subarray-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-buffer-copy-channel-methods-subarray-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-context-close-method-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-close-method-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js":
/*!**********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js ***!
  \**********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-context-decode-audio-data-method-type-error-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-decode-audio-data-method-type-error-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js":
/*!******************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js ***!
  \******************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-context-options-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-context-options-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-node-connect-method-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-node-connect-method-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js":
/*!****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js ***!
  \****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-worklet-node-options-clonability-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-node-options-clonability-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-worklet-processor-no-outputs-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-no-outputs-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js":
/*!*********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js ***!
  \*********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-audio-worklet-processor-post-message-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-audio-worklet-processor-post-message-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js":
/*!******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js ***!
  \******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-channel-merger-node-channel-count-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-channel-merger-node-channel-count-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-constant-source-node-accurate-scheduling-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-constant-source-node-accurate-scheduling-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js":
/*!**********************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js ***!
  \**********************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-convolver-node-buffer-reassignability-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-buffer-reassignability-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js":
/*!*************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js ***!
  \*************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-convolver-node-channel-count-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-convolver-node-channel-count-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js":
/*!**************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js ***!
  \**************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-is-secure-context-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-is-secure-context-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js":
/*!****************************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js ***!
  \****************************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-media-stream-audio-source-node-media-stream-without-audio-track-support.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-media-stream-audio-source-node-media-stream-without-audio-track-support.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js":
/*!*******************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js ***!
  \*******************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-offline-audio-context-current-time-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-offline-audio-context-current-time-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js":
/*!*****************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js ***!
  \*****************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=test-stereo-panner-node-default-value-support-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/test-stereo-panner-node-default-value-support-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js":
/*!*********************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js ***!
  \*********************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=unknown-error-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/unknown-error-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js":
/*!***********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js ***!
  \***********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=unrendered-audio-worklet-node-store.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-node-store.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js":
/*!******************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js ***!
  \******************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=unrendered-audio-worklet-nodes.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/unrendered-audio-worklet-nodes.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js":
/*!************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js ***!
  \************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-constructor-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-constructor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-constructor.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js":
/*!*****************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js ***!
  \*****************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-renderer-factory-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wave-shaper-node-renderer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wave-shaper-node-renderer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/window-factory.js":
/*!**************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/window-factory.js ***!
  \**************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=window-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/window-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/window.js":
/*!******************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/window.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=window.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/window.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js":
/*!**********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js ***!
  \**********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js":
/*!***********************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js ***!
  \***********************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js":
/*!************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js ***!
  \************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js":
/*!*************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js ***!
  \*************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-copy-channel-methods-out-of-bounds-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-source-node-start-method-offset-clamping-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-start-method-offset-clamping-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js":
/*!******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js ***!
  \******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js":
/*!*******************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js ***!
  \*******************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-buffer-source-node-stop-method-nullified-buffer-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js":
/*!***********************************************************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js ***!
  \***********************************************************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js":
/*!********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js ***!
  \********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-channel-merger-node-factory.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-factory.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js":
/*!*********************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js ***!
  \*********************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-channel-merger-node-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-channel-merger-node-function.js?");

/***/ }),

/***/ "./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js":
/*!****************************************************************************************************!*\
  !*** ./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js ***!
  \****************************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=wrap-event-listener-function.js.map\n\n//# sourceURL=webpack://Something/./node_modules/standardized-audio-context/build/es2019/types/wrap-event-listener-function.js?");

/***/ }),

/***/ "./src/css/main.css":
/*!**************************!*\
  !*** ./src/css/main.css ***!
  \**************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js */ \"./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/styleDomAPI.js */ \"./node_modules/style-loader/dist/runtime/styleDomAPI.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/insertBySelector.js */ \"./node_modules/style-loader/dist/runtime/insertBySelector.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js */ \"./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/insertStyleElement.js */ \"./node_modules/style-loader/dist/runtime/insertStyleElement.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/styleTagTransform.js */ \"./node_modules/style-loader/dist/runtime/styleTagTransform.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__);\n/* harmony import */ var _node_modules_css_loader_dist_cjs_js_main_css__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! !!../../node_modules/css-loader/dist/cjs.js!./main.css */ \"./node_modules/css-loader/dist/cjs.js!./src/css/main.css\");\n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n\nvar options = {};\n\noptions.styleTagTransform = (_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default());\noptions.setAttributes = (_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default());\n\n      options.insert = _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default().bind(null, \"head\");\n    \noptions.domAPI = (_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default());\noptions.insertStyleElement = (_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default());\n\nvar update = _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default()(_node_modules_css_loader_dist_cjs_js_main_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"], options);\n\n\n\n\n       /* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_node_modules_css_loader_dist_cjs_js_main_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"] && _node_modules_css_loader_dist_cjs_js_main_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals ? _node_modules_css_loader_dist_cjs_js_main_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals : undefined);\n\n\n//# sourceURL=webpack://Something/./src/css/main.css?");

/***/ }),

/***/ "./src/css/normalise.css":
/*!*******************************!*\
  !*** ./src/css/normalise.css ***!
  \*******************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js */ \"./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/styleDomAPI.js */ \"./node_modules/style-loader/dist/runtime/styleDomAPI.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/insertBySelector.js */ \"./node_modules/style-loader/dist/runtime/insertBySelector.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js */ \"./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/insertStyleElement.js */ \"./node_modules/style-loader/dist/runtime/insertStyleElement.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4__);\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! !../../node_modules/style-loader/dist/runtime/styleTagTransform.js */ \"./node_modules/style-loader/dist/runtime/styleTagTransform.js\");\n/* harmony import */ var _node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default = /*#__PURE__*/__webpack_require__.n(_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5__);\n/* harmony import */ var _node_modules_css_loader_dist_cjs_js_normalise_css__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! !!../../node_modules/css-loader/dist/cjs.js!./normalise.css */ \"./node_modules/css-loader/dist/cjs.js!./src/css/normalise.css\");\n\n      \n      \n      \n      \n      \n      \n      \n      \n      \n\nvar options = {};\n\noptions.styleTagTransform = (_node_modules_style_loader_dist_runtime_styleTagTransform_js__WEBPACK_IMPORTED_MODULE_5___default());\noptions.setAttributes = (_node_modules_style_loader_dist_runtime_setAttributesWithoutAttributes_js__WEBPACK_IMPORTED_MODULE_3___default());\n\n      options.insert = _node_modules_style_loader_dist_runtime_insertBySelector_js__WEBPACK_IMPORTED_MODULE_2___default().bind(null, \"head\");\n    \noptions.domAPI = (_node_modules_style_loader_dist_runtime_styleDomAPI_js__WEBPACK_IMPORTED_MODULE_1___default());\noptions.insertStyleElement = (_node_modules_style_loader_dist_runtime_insertStyleElement_js__WEBPACK_IMPORTED_MODULE_4___default());\n\nvar update = _node_modules_style_loader_dist_runtime_injectStylesIntoStyleTag_js__WEBPACK_IMPORTED_MODULE_0___default()(_node_modules_css_loader_dist_cjs_js_normalise_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"], options);\n\n\n\n\n       /* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (_node_modules_css_loader_dist_cjs_js_normalise_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"] && _node_modules_css_loader_dist_cjs_js_normalise_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals ? _node_modules_css_loader_dist_cjs_js_normalise_css__WEBPACK_IMPORTED_MODULE_6__[\"default\"].locals : undefined);\n\n\n//# sourceURL=webpack://Something/./src/css/normalise.css?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js":
/*!****************************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar stylesInDOM = [];\n\nfunction getIndexByIdentifier(identifier) {\n  var result = -1;\n\n  for (var i = 0; i < stylesInDOM.length; i++) {\n    if (stylesInDOM[i].identifier === identifier) {\n      result = i;\n      break;\n    }\n  }\n\n  return result;\n}\n\nfunction modulesToDom(list, options) {\n  var idCountMap = {};\n  var identifiers = [];\n\n  for (var i = 0; i < list.length; i++) {\n    var item = list[i];\n    var id = options.base ? item[0] + options.base : item[0];\n    var count = idCountMap[id] || 0;\n    var identifier = \"\".concat(id, \" \").concat(count);\n    idCountMap[id] = count + 1;\n    var indexByIdentifier = getIndexByIdentifier(identifier);\n    var obj = {\n      css: item[1],\n      media: item[2],\n      sourceMap: item[3],\n      supports: item[4],\n      layer: item[5]\n    };\n\n    if (indexByIdentifier !== -1) {\n      stylesInDOM[indexByIdentifier].references++;\n      stylesInDOM[indexByIdentifier].updater(obj);\n    } else {\n      var updater = addElementStyle(obj, options);\n      options.byIndex = i;\n      stylesInDOM.splice(i, 0, {\n        identifier: identifier,\n        updater: updater,\n        references: 1\n      });\n    }\n\n    identifiers.push(identifier);\n  }\n\n  return identifiers;\n}\n\nfunction addElementStyle(obj, options) {\n  var api = options.domAPI(options);\n  api.update(obj);\n\n  var updater = function updater(newObj) {\n    if (newObj) {\n      if (newObj.css === obj.css && newObj.media === obj.media && newObj.sourceMap === obj.sourceMap && newObj.supports === obj.supports && newObj.layer === obj.layer) {\n        return;\n      }\n\n      api.update(obj = newObj);\n    } else {\n      api.remove();\n    }\n  };\n\n  return updater;\n}\n\nmodule.exports = function (list, options) {\n  options = options || {};\n  list = list || [];\n  var lastIdentifiers = modulesToDom(list, options);\n  return function update(newList) {\n    newList = newList || [];\n\n    for (var i = 0; i < lastIdentifiers.length; i++) {\n      var identifier = lastIdentifiers[i];\n      var index = getIndexByIdentifier(identifier);\n      stylesInDOM[index].references--;\n    }\n\n    var newLastIdentifiers = modulesToDom(newList, options);\n\n    for (var _i = 0; _i < lastIdentifiers.length; _i++) {\n      var _identifier = lastIdentifiers[_i];\n\n      var _index = getIndexByIdentifier(_identifier);\n\n      if (stylesInDOM[_index].references === 0) {\n        stylesInDOM[_index].updater();\n\n        stylesInDOM.splice(_index, 1);\n      }\n    }\n\n    lastIdentifiers = newLastIdentifiers;\n  };\n};\n\n//# sourceURL=webpack://Something/./node_modules/style-loader/dist/runtime/injectStylesIntoStyleTag.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/insertBySelector.js":
/*!********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/insertBySelector.js ***!
  \********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar memo = {};\n/* istanbul ignore next  */\n\nfunction getTarget(target) {\n  if (typeof memo[target] === \"undefined\") {\n    var styleTarget = document.querySelector(target); // Special case to return head of iframe instead of iframe itself\n\n    if (window.HTMLIFrameElement && styleTarget instanceof window.HTMLIFrameElement) {\n      try {\n        // This will throw an exception if access to iframe is blocked\n        // due to cross-origin restrictions\n        styleTarget = styleTarget.contentDocument.head;\n      } catch (e) {\n        // istanbul ignore next\n        styleTarget = null;\n      }\n    }\n\n    memo[target] = styleTarget;\n  }\n\n  return memo[target];\n}\n/* istanbul ignore next  */\n\n\nfunction insertBySelector(insert, style) {\n  var target = getTarget(insert);\n\n  if (!target) {\n    throw new Error(\"Couldn't find a style target. This probably means that the value for the 'insert' parameter is invalid.\");\n  }\n\n  target.appendChild(style);\n}\n\nmodule.exports = insertBySelector;\n\n//# sourceURL=webpack://Something/./node_modules/style-loader/dist/runtime/insertBySelector.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/insertStyleElement.js":
/*!**********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/insertStyleElement.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction insertStyleElement(options) {\n  var element = document.createElement(\"style\");\n  options.setAttributes(element, options.attributes);\n  options.insert(element, options.options);\n  return element;\n}\n\nmodule.exports = insertStyleElement;\n\n//# sourceURL=webpack://Something/./node_modules/style-loader/dist/runtime/insertStyleElement.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js ***!
  \**********************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction setAttributesWithoutAttributes(styleElement) {\n  var nonce =  true ? __webpack_require__.nc : 0;\n\n  if (nonce) {\n    styleElement.setAttribute(\"nonce\", nonce);\n  }\n}\n\nmodule.exports = setAttributesWithoutAttributes;\n\n//# sourceURL=webpack://Something/./node_modules/style-loader/dist/runtime/setAttributesWithoutAttributes.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/styleDomAPI.js":
/*!***************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/styleDomAPI.js ***!
  \***************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction apply(styleElement, options, obj) {\n  var css = \"\";\n\n  if (obj.supports) {\n    css += \"@supports (\".concat(obj.supports, \") {\");\n  }\n\n  if (obj.media) {\n    css += \"@media \".concat(obj.media, \" {\");\n  }\n\n  var needLayer = typeof obj.layer !== \"undefined\";\n\n  if (needLayer) {\n    css += \"@layer\".concat(obj.layer.length > 0 ? \" \".concat(obj.layer) : \"\", \" {\");\n  }\n\n  css += obj.css;\n\n  if (needLayer) {\n    css += \"}\";\n  }\n\n  if (obj.media) {\n    css += \"}\";\n  }\n\n  if (obj.supports) {\n    css += \"}\";\n  }\n\n  var sourceMap = obj.sourceMap;\n\n  if (sourceMap && typeof btoa !== \"undefined\") {\n    css += \"\\n/*# sourceMappingURL=data:application/json;base64,\".concat(btoa(unescape(encodeURIComponent(JSON.stringify(sourceMap)))), \" */\");\n  } // For old IE\n\n  /* istanbul ignore if  */\n\n\n  options.styleTagTransform(css, styleElement, options.options);\n}\n\nfunction removeStyleElement(styleElement) {\n  // istanbul ignore if\n  if (styleElement.parentNode === null) {\n    return false;\n  }\n\n  styleElement.parentNode.removeChild(styleElement);\n}\n/* istanbul ignore next  */\n\n\nfunction domAPI(options) {\n  var styleElement = options.insertStyleElement(options);\n  return {\n    update: function update(obj) {\n      apply(styleElement, options, obj);\n    },\n    remove: function remove() {\n      removeStyleElement(styleElement);\n    }\n  };\n}\n\nmodule.exports = domAPI;\n\n//# sourceURL=webpack://Something/./node_modules/style-loader/dist/runtime/styleDomAPI.js?");

/***/ }),

/***/ "./node_modules/style-loader/dist/runtime/styleTagTransform.js":
/*!*********************************************************************!*\
  !*** ./node_modules/style-loader/dist/runtime/styleTagTransform.js ***!
  \*********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* istanbul ignore next  */\nfunction styleTagTransform(css, styleElement) {\n  if (styleElement.styleSheet) {\n    styleElement.styleSheet.cssText = css;\n  } else {\n    while (styleElement.firstChild) {\n      styleElement.removeChild(styleElement.firstChild);\n    }\n\n    styleElement.appendChild(document.createTextNode(css));\n  }\n}\n\nmodule.exports = styleTagTransform;\n\n//# sourceURL=webpack://Something/./node_modules/style-loader/dist/runtime/styleTagTransform.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/classes.js":
/*!************************************************!*\
  !*** ./node_modules/tone/build/esm/classes.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.AMOscillator),\n/* harmony export */   \"AMSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.AMSynth),\n/* harmony export */   \"Abs\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Abs),\n/* harmony export */   \"Add\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Add),\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.AmplitudeEnvelope),\n/* harmony export */   \"Analyser\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Analyser),\n/* harmony export */   \"AudioToGain\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.AudioToGain),\n/* harmony export */   \"AutoFilter\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.AutoFilter),\n/* harmony export */   \"AutoPanner\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.AutoPanner),\n/* harmony export */   \"AutoWah\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.AutoWah),\n/* harmony export */   \"BaseContext\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.BaseContext),\n/* harmony export */   \"BiquadFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.BiquadFilter),\n/* harmony export */   \"BitCrusher\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.BitCrusher),\n/* harmony export */   \"Channel\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Channel),\n/* harmony export */   \"Chebyshev\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Chebyshev),\n/* harmony export */   \"Chorus\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Chorus),\n/* harmony export */   \"Clock\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Clock),\n/* harmony export */   \"Compressor\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Compressor),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Context),\n/* harmony export */   \"Convolver\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Convolver),\n/* harmony export */   \"CrossFade\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.CrossFade),\n/* harmony export */   \"DCMeter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.DCMeter),\n/* harmony export */   \"Delay\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Delay),\n/* harmony export */   \"Distortion\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Distortion),\n/* harmony export */   \"DuoSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.DuoSynth),\n/* harmony export */   \"EQ3\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.EQ3),\n/* harmony export */   \"Emitter\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Emitter),\n/* harmony export */   \"Envelope\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Envelope),\n/* harmony export */   \"FFT\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.FFT),\n/* harmony export */   \"FMOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.FMOscillator),\n/* harmony export */   \"FMSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.FMSynth),\n/* harmony export */   \"FatOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.FatOscillator),\n/* harmony export */   \"FeedbackCombFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.FeedbackCombFilter),\n/* harmony export */   \"FeedbackDelay\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.FeedbackDelay),\n/* harmony export */   \"Filter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Filter),\n/* harmony export */   \"Follower\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Follower),\n/* harmony export */   \"Freeverb\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Freeverb),\n/* harmony export */   \"Frequency\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.FrequencyClass),\n/* harmony export */   \"FrequencyEnvelope\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.FrequencyEnvelope),\n/* harmony export */   \"FrequencyShifter\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.FrequencyShifter),\n/* harmony export */   \"Gain\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Gain),\n/* harmony export */   \"GainToAudio\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.GainToAudio),\n/* harmony export */   \"Gate\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Gate),\n/* harmony export */   \"GrainPlayer\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.GrainPlayer),\n/* harmony export */   \"GreaterThan\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.GreaterThan),\n/* harmony export */   \"GreaterThanZero\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.GreaterThanZero),\n/* harmony export */   \"IntervalTimeline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.IntervalTimeline),\n/* harmony export */   \"JCReverb\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.JCReverb),\n/* harmony export */   \"LFO\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.LFO),\n/* harmony export */   \"Limiter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Limiter),\n/* harmony export */   \"Loop\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Loop),\n/* harmony export */   \"LowpassCombFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.LowpassCombFilter),\n/* harmony export */   \"MembraneSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.MembraneSynth),\n/* harmony export */   \"Merge\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Merge),\n/* harmony export */   \"MetalSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.MetalSynth),\n/* harmony export */   \"Meter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Meter),\n/* harmony export */   \"MidSideCompressor\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MidSideCompressor),\n/* harmony export */   \"MidSideMerge\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MidSideMerge),\n/* harmony export */   \"MidSideSplit\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MidSideSplit),\n/* harmony export */   \"Midi\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Midi),\n/* harmony export */   \"MidiClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.MidiClass),\n/* harmony export */   \"Mono\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Mono),\n/* harmony export */   \"MonoSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.MonoSynth),\n/* harmony export */   \"MultibandCompressor\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MultibandCompressor),\n/* harmony export */   \"MultibandSplit\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.MultibandSplit),\n/* harmony export */   \"Multiply\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Multiply),\n/* harmony export */   \"Negate\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Negate),\n/* harmony export */   \"Noise\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Noise),\n/* harmony export */   \"NoiseSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.NoiseSynth),\n/* harmony export */   \"Offline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Offline),\n/* harmony export */   \"OfflineContext\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.OfflineContext),\n/* harmony export */   \"OmniOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.OmniOscillator),\n/* harmony export */   \"OnePoleFilter\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.OnePoleFilter),\n/* harmony export */   \"Oscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Oscillator),\n/* harmony export */   \"PWMOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.PWMOscillator),\n/* harmony export */   \"PanVol\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.PanVol),\n/* harmony export */   \"Panner\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Panner),\n/* harmony export */   \"Panner3D\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Panner3D),\n/* harmony export */   \"Param\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Param),\n/* harmony export */   \"Part\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Part),\n/* harmony export */   \"Pattern\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Pattern),\n/* harmony export */   \"Phaser\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Phaser),\n/* harmony export */   \"PingPongDelay\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.PingPongDelay),\n/* harmony export */   \"PitchShift\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.PitchShift),\n/* harmony export */   \"Player\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Player),\n/* harmony export */   \"Players\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.Players),\n/* harmony export */   \"PluckSynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.PluckSynth),\n/* harmony export */   \"PolySynth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.PolySynth),\n/* harmony export */   \"Pow\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Pow),\n/* harmony export */   \"PulseOscillator\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.PulseOscillator),\n/* harmony export */   \"Recorder\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Recorder),\n/* harmony export */   \"Reverb\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Reverb),\n/* harmony export */   \"Sampler\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.Sampler),\n/* harmony export */   \"Scale\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Scale),\n/* harmony export */   \"ScaleExp\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.ScaleExp),\n/* harmony export */   \"Sequence\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.Sequence),\n/* harmony export */   \"Signal\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Signal),\n/* harmony export */   \"Solo\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Solo),\n/* harmony export */   \"Split\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Split),\n/* harmony export */   \"StateTimeline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.StateTimeline),\n/* harmony export */   \"StereoWidener\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.StereoWidener),\n/* harmony export */   \"Subtract\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Subtract),\n/* harmony export */   \"SyncedSignal\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.SyncedSignal),\n/* harmony export */   \"Synth\": () => (/* reexport safe */ _instrument_index__WEBPACK_IMPORTED_MODULE_3__.Synth),\n/* harmony export */   \"Ticks\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Ticks),\n/* harmony export */   \"TicksClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TicksClass),\n/* harmony export */   \"Time\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Time),\n/* harmony export */   \"TimeClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TimeClass),\n/* harmony export */   \"Timeline\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Timeline),\n/* harmony export */   \"ToneAudioBuffer\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer),\n/* harmony export */   \"ToneAudioBuffers\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffers),\n/* harmony export */   \"ToneAudioNode\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode),\n/* harmony export */   \"ToneBufferSource\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.ToneBufferSource),\n/* harmony export */   \"ToneEvent\": () => (/* reexport safe */ _event_index__WEBPACK_IMPORTED_MODULE_4__.ToneEvent),\n/* harmony export */   \"ToneOscillatorNode\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.ToneOscillatorNode),\n/* harmony export */   \"TransportTime\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.TransportTimeClass),\n/* harmony export */   \"Tremolo\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Tremolo),\n/* harmony export */   \"Unit\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.Unit),\n/* harmony export */   \"UserMedia\": () => (/* reexport safe */ _source_index__WEBPACK_IMPORTED_MODULE_1__.UserMedia),\n/* harmony export */   \"Vibrato\": () => (/* reexport safe */ _effect_index__WEBPACK_IMPORTED_MODULE_5__.Vibrato),\n/* harmony export */   \"Volume\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Volume),\n/* harmony export */   \"WaveShaper\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.WaveShaper),\n/* harmony export */   \"Waveform\": () => (/* reexport safe */ _component_index__WEBPACK_IMPORTED_MODULE_6__.Waveform),\n/* harmony export */   \"Zero\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.Zero),\n/* harmony export */   \"connect\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.connect),\n/* harmony export */   \"connectSeries\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.connectSeries),\n/* harmony export */   \"connectSignal\": () => (/* reexport safe */ _signal_index__WEBPACK_IMPORTED_MODULE_2__.connectSignal),\n/* harmony export */   \"dbToGain\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.dbToGain),\n/* harmony export */   \"debug\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.debug),\n/* harmony export */   \"defaultArg\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.defaultArg),\n/* harmony export */   \"disconnect\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.disconnect),\n/* harmony export */   \"ftom\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.ftom),\n/* harmony export */   \"gainToDb\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.gainToDb),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.intervalToFrequencyRatio),\n/* harmony export */   \"isArray\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isArray),\n/* harmony export */   \"isBoolean\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isBoolean),\n/* harmony export */   \"isDefined\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isDefined),\n/* harmony export */   \"isFunction\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isFunction),\n/* harmony export */   \"isNote\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isNote),\n/* harmony export */   \"isNumber\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isNumber),\n/* harmony export */   \"isObject\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isObject),\n/* harmony export */   \"isString\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isString),\n/* harmony export */   \"isUndef\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.isUndef),\n/* harmony export */   \"mtof\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.mtof),\n/* harmony export */   \"optionsFromArguments\": () => (/* reexport safe */ _core_index__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)\n/* harmony export */ });\n/* harmony import */ var _core_index__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core/index */ \"./node_modules/tone/build/esm/core/index.js\");\n/* harmony import */ var _source_index__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./source/index */ \"./node_modules/tone/build/esm/source/index.js\");\n/* harmony import */ var _signal_index__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./signal/index */ \"./node_modules/tone/build/esm/signal/index.js\");\n/* harmony import */ var _instrument_index__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./instrument/index */ \"./node_modules/tone/build/esm/instrument/index.js\");\n/* harmony import */ var _event_index__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./event/index */ \"./node_modules/tone/build/esm/event/index.js\");\n/* harmony import */ var _effect_index__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./effect/index */ \"./node_modules/tone/build/esm/effect/index.js\");\n/* harmony import */ var _component_index__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./component/index */ \"./node_modules/tone/build/esm/component/index.js\");\n\n\n\n\n\n\n\n//# sourceMappingURL=classes.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/classes.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Analyser.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Analyser.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Analyser\": () => (/* binding */ Analyser)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _channel_Split__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).\n * Extracts FFT or Waveform data from the incoming signal.\n * @category Component\n */\nclass Analyser extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Analyser.getDefaults(), arguments, [\"type\", \"size\"]));\n        this.name = \"Analyser\";\n        /**\n         * The analyser node.\n         */\n        this._analysers = [];\n        /**\n         * The buffer that the FFT data is written to\n         */\n        this._buffers = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Analyser.getDefaults(), arguments, [\"type\", \"size\"]);\n        this.input = this.output = this._gain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        this._split = new _channel_Split__WEBPACK_IMPORTED_MODULE_2__.Split({\n            context: this.context,\n            channels: options.channels,\n        });\n        this.input.connect(this._split);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assertRange)(options.channels, 1);\n        // create the analysers\n        for (let channel = 0; channel < options.channels; channel++) {\n            this._analysers[channel] = this.context.createAnalyser();\n            this._split.connect(this._analysers[channel], channel, 0);\n        }\n        // set the values initially\n        this.size = options.size;\n        this.type = options.type;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            size: 1024,\n            smoothing: 0.8,\n            type: \"fft\",\n            channels: 1,\n        });\n    }\n    /**\n     * Run the analysis given the current settings. If [[channels]] = 1,\n     * it will return a Float32Array. If [[channels]] > 1, it will\n     * return an array of Float32Arrays where each index in the array\n     * represents the analysis done on a channel.\n     */\n    getValue() {\n        this._analysers.forEach((analyser, index) => {\n            const buffer = this._buffers[index];\n            if (this._type === \"fft\") {\n                analyser.getFloatFrequencyData(buffer);\n            }\n            else if (this._type === \"waveform\") {\n                analyser.getFloatTimeDomainData(buffer);\n            }\n        });\n        if (this.channels === 1) {\n            return this._buffers[0];\n        }\n        else {\n            return this._buffers;\n        }\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     */\n    get size() {\n        return this._analysers[0].frequencyBinCount;\n    }\n    set size(size) {\n        this._analysers.forEach((analyser, index) => {\n            analyser.fftSize = size * 2;\n            this._buffers[index] = new Float32Array(size);\n        });\n    }\n    /**\n     * The number of channels the analyser does the analysis on. Channel\n     * separation is done using [[Split]]\n     */\n    get channels() {\n        return this._analysers.length;\n    }\n    /**\n     * The analysis function returned by analyser.getValue(), either \"fft\" or \"waveform\".\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(type === \"waveform\" || type === \"fft\", `Analyser: invalid type: ${type}`);\n        this._type = type;\n    }\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing() {\n        return this._analysers[0].smoothingTimeConstant;\n    }\n    set smoothing(val) {\n        this._analysers.forEach(a => a.smoothingTimeConstant = val);\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._analysers.forEach(a => a.disconnect());\n        this._split.dispose();\n        this._gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Analyser.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/Analyser.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/DCMeter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/DCMeter.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DCMeter\": () => (/* binding */ DCMeter)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n\n\n/**\n * DCMeter gets the raw value of the input signal at the current time.\n *\n * @example\n * const meter = new Tone.DCMeter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * const level = meter.getValue();\n * @category Component\n */\nclass DCMeter extends _MeterBase__WEBPACK_IMPORTED_MODULE_1__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(DCMeter.getDefaults(), arguments));\n        this.name = \"DCMeter\";\n        this._analyser.type = \"waveform\";\n        this._analyser.size = 256;\n    }\n    /**\n     * Get the signal value of the incoming signal\n     */\n    getValue() {\n        const value = this._analyser.getValue();\n        return value[0];\n    }\n}\n//# sourceMappingURL=DCMeter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/DCMeter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/FFT.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/FFT.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FFT\": () => (/* binding */ FFT)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * Get the current frequency data of the connected audio source using a fast Fourier transform.\n * @category Component\n */\nclass FFT extends _MeterBase__WEBPACK_IMPORTED_MODULE_3__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(FFT.getDefaults(), arguments, [\"size\"]));\n        this.name = \"FFT\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(FFT.getDefaults(), arguments, [\"size\"]);\n        this.normalRange = options.normalRange;\n        this._analyser.type = \"fft\";\n        this.size = options.size;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            normalRange: false,\n            size: 1024,\n            smoothing: 0.8,\n        });\n    }\n    /**\n     * Gets the current frequency data from the connected audio source.\n     * Returns the frequency data of length [[size]] as a Float32Array of decibel values.\n     */\n    getValue() {\n        const values = this._analyser.getValue();\n        return values.map(v => this.normalRange ? (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__.dbToGain)(v) : v);\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by [[getValue]] (i.e. the number of\n     * frequency bins). Large FFT sizes may be costly to compute.\n     */\n    get size() {\n        return this._analyser.size;\n    }\n    set size(size) {\n        this._analyser.size = size;\n    }\n    /**\n     * 0 represents no time averaging with the last analysis frame.\n     */\n    get smoothing() {\n        return this._analyser.smoothing;\n    }\n    set smoothing(val) {\n        this._analyser.smoothing = val;\n    }\n    /**\n     * Returns the frequency value in hertz of each of the indices of the FFT's [[getValue]] response.\n     * @example\n     * const fft = new Tone.FFT(32);\n     * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));\n     */\n    getFrequencyOfIndex(index) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(0 <= index && index < this.size, `index must be greater than or equal to 0 and less than ${this.size}`);\n        return index * this.context.sampleRate / (this.size * 2);\n    }\n}\n//# sourceMappingURL=FFT.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/FFT.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Follower.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Follower.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Follower\": () => (/* binding */ Follower)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../filter/OnePoleFilter */ \"./node_modules/tone/build/esm/component/filter/OnePoleFilter.js\");\n/* harmony import */ var _signal_Abs__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Abs */ \"./node_modules/tone/build/esm/signal/Abs.js\");\n\n\n\n\n/**\n * Follower is a simple envelope follower.\n * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.\n * ```\n *          +-----+    +---------------+\n * Input +--> Abs +----> OnePoleFilter +--> Output\n *          +-----+    +---------------+\n * ```\n * @category Component\n */\nclass Follower extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Follower.getDefaults(), arguments, [\"smoothing\"]));\n        this.name = \"Follower\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Follower.getDefaults(), arguments, [\"smoothing\"]);\n        this._abs = this.input = new _signal_Abs__WEBPACK_IMPORTED_MODULE_3__.Abs({ context: this.context });\n        this._lowpass = this.output = new _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_2__.OnePoleFilter({\n            context: this.context,\n            frequency: 1 / this.toSeconds(options.smoothing),\n            type: \"lowpass\"\n        });\n        this._abs.connect(this._lowpass);\n        this._smoothing = options.smoothing;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            smoothing: 0.05\n        });\n    }\n    /**\n     * The amount of time it takes a value change to arrive at the updated value.\n     */\n    get smoothing() {\n        return this._smoothing;\n    }\n    set smoothing(smoothing) {\n        this._smoothing = smoothing;\n        this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);\n    }\n    dispose() {\n        super.dispose();\n        this._abs.dispose();\n        this._lowpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Follower.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/Follower.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Meter.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Meter.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Meter\": () => (/* binding */ Meter)\n/* harmony export */ });\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _Analyser__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Analyser */ \"./node_modules/tone/build/esm/component/analysis/Analyser.js\");\n\n\n\n\n\n/**\n * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)\n * of an input signal. It can also get the raw value of the input signal.\n *\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia();\n * mic.open();\n * // connect mic to the meter\n * mic.connect(meter);\n * // the current level of the mic\n * setInterval(() => console.log(meter.getValue()), 100);\n * @category Component\n */\nclass Meter extends _MeterBase__WEBPACK_IMPORTED_MODULE_2__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Meter.getDefaults(), arguments, [\"smoothing\"]));\n        this.name = \"Meter\";\n        /**\n         * The previous frame's value\n         */\n        this._rms = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Meter.getDefaults(), arguments, [\"smoothing\"]);\n        this.input = this.output = this._analyser = new _Analyser__WEBPACK_IMPORTED_MODULE_4__.Analyser({\n            context: this.context,\n            size: 256,\n            type: \"waveform\",\n            channels: options.channels,\n        });\n        this.smoothing = options.smoothing,\n            this.normalRange = options.normalRange;\n    }\n    static getDefaults() {\n        return Object.assign(_MeterBase__WEBPACK_IMPORTED_MODULE_2__.MeterBase.getDefaults(), {\n            smoothing: 0.8,\n            normalRange: false,\n            channels: 1,\n        });\n    }\n    /**\n     * Use [[getValue]] instead. For the previous getValue behavior, use DCMeter.\n     * @deprecated\n     */\n    getLevel() {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.warn)(\"'getLevel' has been changed to 'getValue'\");\n        return this.getValue();\n    }\n    /**\n     * Get the current value of the incoming signal.\n     * Output is in decibels when [[normalRange]] is `false`.\n     * If [[channels]] = 1, then the output is a single number\n     * representing the value of the input signal. When [[channels]] > 1,\n     * then each channel is returned as a value in a number array.\n     */\n    getValue() {\n        const aValues = this._analyser.getValue();\n        const channelValues = this.channels === 1 ? [aValues] : aValues;\n        const vals = channelValues.map(values => {\n            const totalSquared = values.reduce((total, current) => total + current * current, 0);\n            const rms = Math.sqrt(totalSquared / values.length);\n            // the rms can only fall at the rate of the smoothing\n            // but can jump up instantly\n            this._rms = Math.max(rms, this._rms * this.smoothing);\n            return this.normalRange ? this._rms : (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_0__.gainToDb)(this._rms);\n        });\n        if (this.channels === 1) {\n            return vals[0];\n        }\n        else {\n            return vals;\n        }\n    }\n    /**\n     * The number of channels of analysis.\n     */\n    get channels() {\n        return this._analyser.channels;\n    }\n    dispose() {\n        super.dispose();\n        this._analyser.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Meter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/Meter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/MeterBase.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/MeterBase.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MeterBase\": () => (/* binding */ MeterBase)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Analyser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Analyser */ \"./node_modules/tone/build/esm/component/analysis/Analyser.js\");\n\n\n\n/**\n * The base class for Metering classes.\n */\nclass MeterBase extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(MeterBase.getDefaults(), arguments));\n        this.name = \"MeterBase\";\n        this.input = this.output = this._analyser = new _Analyser__WEBPACK_IMPORTED_MODULE_2__.Analyser({\n            context: this.context,\n            size: 256,\n            type: \"waveform\",\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._analyser.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MeterBase.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/MeterBase.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/analysis/Waveform.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/analysis/Waveform.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Waveform\": () => (/* binding */ Waveform)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _MeterBase__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MeterBase */ \"./node_modules/tone/build/esm/component/analysis/MeterBase.js\");\n\n\n/**\n * Get the current waveform data of the connected audio source.\n * @category Component\n */\nclass Waveform extends _MeterBase__WEBPACK_IMPORTED_MODULE_1__.MeterBase {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Waveform.getDefaults(), arguments, [\"size\"]));\n        this.name = \"Waveform\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Waveform.getDefaults(), arguments, [\"size\"]);\n        this._analyser.type = \"waveform\";\n        this.size = options.size;\n    }\n    static getDefaults() {\n        return Object.assign(_MeterBase__WEBPACK_IMPORTED_MODULE_1__.MeterBase.getDefaults(), {\n            size: 1024,\n        });\n    }\n    /**\n     * Return the waveform for the current time as a Float32Array where each value in the array\n     * represents a sample in the waveform.\n     */\n    getValue() {\n        return this._analyser.getValue();\n    }\n    /**\n     * The size of analysis. This must be a power of two in the range 16 to 16384.\n     * Determines the size of the array returned by [[getValue]].\n     */\n    get size() {\n        return this._analyser.size;\n    }\n    set size(size) {\n        this._analyser.size = size;\n    }\n}\n//# sourceMappingURL=Waveform.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/analysis/Waveform.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Channel.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Channel.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Channel\": () => (/* binding */ Channel)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Solo__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Solo */ \"./node_modules/tone/build/esm/component/channel/Solo.js\");\n/* harmony import */ var _PanVol__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./PanVol */ \"./node_modules/tone/build/esm/component/channel/PanVol.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n\n\n\n\n\n\n/**\n * Channel provides a channel strip interface with volume, pan, solo and mute controls.\n * See [[PanVol]] and [[Solo]]\n * @example\n * // pan the incoming signal left and drop the volume 12db\n * const channel = new Tone.Channel(-0.25, -12);\n * @category Component\n */\nclass Channel extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Channel.getDefaults(), arguments, [\"volume\", \"pan\"]));\n        this.name = \"Channel\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Channel.getDefaults(), arguments, [\"volume\", \"pan\"]);\n        this._solo = this.input = new _Solo__WEBPACK_IMPORTED_MODULE_2__.Solo({\n            solo: options.solo,\n            context: this.context,\n        });\n        this._panVol = this.output = new _PanVol__WEBPACK_IMPORTED_MODULE_3__.PanVol({\n            context: this.context,\n            pan: options.pan,\n            volume: options.volume,\n            mute: options.mute,\n            channelCount: options.channelCount\n        });\n        this.pan = this._panVol.pan;\n        this.volume = this._panVol.volume;\n        this._solo.connect(this._panVol);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"pan\", \"volume\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            pan: 0,\n            volume: 0,\n            mute: false,\n            solo: false,\n            channelCount: 1,\n        });\n    }\n    /**\n     * Solo/unsolo the channel. Soloing is only relative to other [[Channels]] and [[Solo]] instances\n     */\n    get solo() {\n        return this._solo.solo;\n    }\n    set solo(solo) {\n        this._solo.solo = solo;\n    }\n    /**\n     * If the current instance is muted, i.e. another instance is soloed,\n     * or the channel is muted\n     */\n    get muted() {\n        return this._solo.muted || this.mute;\n    }\n    /**\n     * Mute/unmute the volume\n     */\n    get mute() {\n        return this._panVol.mute;\n    }\n    set mute(mute) {\n        this._panVol.mute = mute;\n    }\n    /**\n     * Get the gain node belonging to the bus name. Create it if\n     * it doesn't exist\n     * @param name The bus name\n     */\n    _getBus(name) {\n        if (!Channel.buses.has(name)) {\n            Channel.buses.set(name, new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context }));\n        }\n        return Channel.buses.get(name);\n    }\n    /**\n     * Send audio to another channel using a string. `send` is a lot like\n     * [[connect]], except it uses a string instead of an object. This can\n     * be useful in large applications to decouple sections since [[send]]\n     * and [[receive]] can be invoked separately in order to connect an object\n     * @param name The channel name to send the audio\n     * @param volume The amount of the signal to send.\n     * \tDefaults to 0db, i.e. send the entire signal\n     * @returns Returns the gain node of this connection.\n     */\n    send(name, volume = 0) {\n        const bus = this._getBus(name);\n        const sendKnob = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({\n            context: this.context,\n            units: \"decibels\",\n            gain: volume,\n        });\n        this.connect(sendKnob);\n        sendKnob.connect(bus);\n        return sendKnob;\n    }\n    /**\n     * Receive audio from a channel which was connected with [[send]].\n     * @param name The channel name to receive audio from.\n     */\n    receive(name) {\n        const bus = this._getBus(name);\n        bus.connect(this);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._panVol.dispose();\n        this.pan.dispose();\n        this.volume.dispose();\n        this._solo.dispose();\n        return this;\n    }\n}\n/**\n * Store the send/receive channels by name.\n */\nChannel.buses = new Map();\n//# sourceMappingURL=Channel.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Channel.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/CrossFade.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/CrossFade.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"CrossFade\": () => (/* binding */ CrossFade)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_GainToAudio__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/GainToAudio */ \"./node_modules/tone/build/esm/signal/GainToAudio.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n\n\n\n/**\n * Tone.Crossfade provides equal power fading between two inputs.\n * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).\n * ```\n *                                             +---------+\n *                                            +> input a +>--+\n * +-----------+   +---------------------+     |         |   |\n * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |\n * +-----------+   |                     |     +---------+   |\n *               +-> pan               R +>-+                |   +--------+\n *               | +---------------------+  |                +---> output +>\n *  +------+     |                          |  +---------+   |   +--------+\n *  | fade +>----+                          | +> input b +>--+\n *  +------+                                |  |         |\n *                                          +--> gain    |\n *                                             +---------+\n * ```\n * @example\n * const crossFade = new Tone.CrossFade().toDestination();\n * // connect two inputs Tone.to a/b\n * const inputA = new Tone.Oscillator(440, \"square\").connect(crossFade.a).start();\n * const inputB = new Tone.Oscillator(440, \"sine\").connect(crossFade.b).start();\n * // use the fade to control the mix between the two\n * crossFade.fade.value = 0.5;\n * @category Component\n */\nclass CrossFade extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(CrossFade.getDefaults(), arguments, [\"fade\"])));\n        this.name = \"CrossFade\";\n        /**\n         * The crossfading is done by a StereoPannerNode\n         */\n        this._panner = this.context.createStereoPanner();\n        /**\n         * Split the output of the panner node into two values used to control the gains.\n         */\n        this._split = this.context.createChannelSplitter(2);\n        /**\n         * Convert the fade value into an audio range value so it can be connected\n         * to the panner.pan AudioParam\n         */\n        this._g2a = new _signal_GainToAudio__WEBPACK_IMPORTED_MODULE_4__.GainToAudio({ context: this.context });\n        /**\n         * The input which is at full level when fade = 0\n         */\n        this.a = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The input which is at full level when fade = 1\n         */\n        this.b = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The output is a mix between `a` and `b` at the ratio of `fade`\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._internalChannels = [this.a, this.b];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(CrossFade.getDefaults(), arguments, [\"fade\"]);\n        this.fade = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"normalRange\",\n            value: options.fade,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"fade\");\n        this.context.getConstant(1).connect(this._panner);\n        this._panner.connect(this._split);\n        // this is necessary for standardized-audio-context\n        // doesn't make any difference for the native AudioContext\n        // https://github.com/chrisguttandin/standardized-audio-context/issues/647\n        this._panner.channelCount = 1;\n        this._panner.channelCountMode = \"explicit\";\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(this._split, this.a.gain, 0);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(this._split, this.b.gain, 1);\n        this.fade.chain(this._g2a, this._panner.pan);\n        this.a.connect(this.output);\n        this.b.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            fade: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.a.dispose();\n        this.b.dispose();\n        this.output.dispose();\n        this.fade.dispose();\n        this._g2a.dispose();\n        this._panner.disconnect();\n        this._split.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=CrossFade.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/CrossFade.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Merge.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Merge.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Merge\": () => (/* binding */ Merge)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n/**\n * Merge brings multiple mono input channels into a single multichannel output channel.\n *\n * @example\n * const merge = new Tone.Merge().toDestination();\n * // routing a sine tone in the left channel\n * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();\n * // and noise in the right channel\n * const noise = new Tone.Noise().connect(merge, 0, 1).start();;\n * @category Component\n */\nclass Merge extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Merge.getDefaults(), arguments, [\"channels\"]));\n        this.name = \"Merge\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Merge.getDefaults(), arguments, [\"channels\"]);\n        this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            channels: 2,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._merger.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Merge.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Merge.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/MidSideMerge.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/MidSideMerge.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideMerge\": () => (/* binding */ MidSideMerge)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Merge__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _signal_Add__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n\n/**\n * MidSideMerge merges the mid and side signal after they've been separated by [[MidSideSplit]]\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n * @category Component\n */\nclass MidSideMerge extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_6__.optionsFromArguments)(MidSideMerge.getDefaults(), arguments));\n        this.name = \"MidSideMerge\";\n        this.mid = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context });\n        this.side = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context });\n        this._left = new _signal_Add__WEBPACK_IMPORTED_MODULE_2__.Add({ context: this.context });\n        this._leftMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2\n        });\n        this._right = new _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__.Subtract({ context: this.context });\n        this._rightMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2\n        });\n        this._merge = this.output = new _Merge__WEBPACK_IMPORTED_MODULE_1__.Merge({ context: this.context });\n        this.mid.fan(this._left);\n        this.side.connect(this._left.addend);\n        this.mid.connect(this._right);\n        this.side.connect(this._right.subtrahend);\n        this._left.connect(this._leftMult);\n        this._right.connect(this._rightMult);\n        this._leftMult.connect(this._merge, 0, 0);\n        this._rightMult.connect(this._merge, 0, 1);\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._leftMult.dispose();\n        this._rightMult.dispose();\n        this._left.dispose();\n        this._right.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideMerge.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/MidSideMerge.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/MidSideSplit.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/MidSideSplit.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideSplit\": () => (/* binding */ MidSideSplit)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Split__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _signal_Add__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n/**\n * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels).\n * ```\n * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right\n * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right\n * ```\n * @category Component\n */\nclass MidSideSplit extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_5__.optionsFromArguments)(MidSideSplit.getDefaults(), arguments));\n        this.name = \"MidSideSplit\";\n        this._split = this.input = new _Split__WEBPACK_IMPORTED_MODULE_1__.Split({\n            channels: 2,\n            context: this.context\n        });\n        this._midAdd = new _signal_Add__WEBPACK_IMPORTED_MODULE_2__.Add({ context: this.context });\n        this.mid = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2,\n        });\n        this._sideSubtract = new _signal_Subtract__WEBPACK_IMPORTED_MODULE_4__.Subtract({ context: this.context });\n        this.side = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            value: Math.SQRT1_2,\n        });\n        this._split.connect(this._midAdd, 0);\n        this._split.connect(this._midAdd.addend, 1);\n        this._split.connect(this._sideSubtract, 0);\n        this._split.connect(this._sideSubtract.subtrahend, 1);\n        this._midAdd.connect(this.mid);\n        this._sideSubtract.connect(this.side);\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._midAdd.dispose();\n        this._sideSubtract.dispose();\n        this._split.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideSplit.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/MidSideSplit.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Mono.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Mono.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Mono\": () => (/* binding */ Mono)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Merge__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n\n\n\n\n/**\n * Mono coerces the incoming mono or stereo signal into a mono signal\n * where both left and right channels have the same value. This can be useful\n * for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).\n * @category Component\n */\nclass Mono extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Mono.getDefaults(), arguments));\n        this.name = \"Mono\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._merge = this.output = new _Merge__WEBPACK_IMPORTED_MODULE_3__.Merge({\n            channels: 2,\n            context: this.context,\n        });\n        this.input.connect(this._merge, 0, 0);\n        this.input.connect(this._merge, 0, 1);\n    }\n    dispose() {\n        super.dispose();\n        this._merge.dispose();\n        this.input.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Mono.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Mono.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/MultibandSplit.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/MultibandSplit.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MultibandSplit\": () => (/* binding */ MultibandSplit)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _filter_Filter__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n\n\n\n\n\n\n/**\n * Split the incoming signal into three bands (low, mid, high)\n * with two crossover frequency controls.\n * ```\n *            +----------------------+\n *          +-> input < lowFrequency +------------------> low\n *          | +----------------------+\n *          |\n *          | +--------------------------------------+\n * input ---+-> lowFrequency < input < highFrequency +--> mid\n *          | +--------------------------------------+\n *          |\n *          | +-----------------------+\n *          +-> highFrequency < input +-----------------> high\n *            +-----------------------+\n * ```\n * @category Component\n */\nclass MultibandSplit extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandSplit.getDefaults(), arguments, [\"lowFrequency\", \"highFrequency\"]));\n        this.name = \"MultibandSplit\";\n        /**\n         * the input\n         */\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * no output node, use either low, mid or high outputs\n         */\n        this.output = undefined;\n        /**\n         * The low band.\n         */\n        this.low = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"lowpass\",\n        });\n        /**\n         * the lower filter of the mid band\n         */\n        this._lowMidFilter = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"highpass\",\n        });\n        /**\n         * The mid band output.\n         */\n        this.mid = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"lowpass\",\n        });\n        /**\n         * The high band output.\n         */\n        this.high = new _filter_Filter__WEBPACK_IMPORTED_MODULE_5__.Filter({\n            context: this.context,\n            frequency: 0,\n            type: \"highpass\",\n        });\n        this._internalChannels = [this.low, this.mid, this.high];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandSplit.getDefaults(), arguments, [\"lowFrequency\", \"highFrequency\"]);\n        this.lowFrequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.lowFrequency,\n        });\n        this.highFrequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.highFrequency,\n        });\n        this.Q = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"positive\",\n            value: options.Q,\n        });\n        this.input.fan(this.low, this.high);\n        this.input.chain(this._lowMidFilter, this.mid);\n        // the frequency control signal\n        this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);\n        this.highFrequency.fan(this.mid.frequency, this.high.frequency);\n        // the Q value\n        this.Q.connect(this.low.Q);\n        this.Q.connect(this._lowMidFilter.Q);\n        this.Q.connect(this.mid.Q);\n        this.Q.connect(this.high.Q);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            Q: 1,\n            highFrequency: 2500,\n            lowFrequency: 400,\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.writable)(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n        this.low.dispose();\n        this._lowMidFilter.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.lowFrequency.dispose();\n        this.highFrequency.dispose();\n        this.Q.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MultibandSplit.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/MultibandSplit.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/PanVol.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/PanVol.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PanVol\": () => (/* binding */ PanVol)\n/* harmony export */ });\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Panner__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Panner */ \"./node_modules/tone/build/esm/component/channel/Panner.js\");\n/* harmony import */ var _Volume__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n\n\n\n\n\n/**\n * PanVol is a Tone.Panner and Tone.Volume in one.\n * @example\n * // pan the incoming signal left and drop the volume\n * const panVol = new Tone.PanVol(-0.25, -12).toDestination();\n * const osc = new Tone.Oscillator().connect(panVol).start();\n * @category Component\n */\nclass PanVol extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(PanVol.getDefaults(), arguments, [\"pan\", \"volume\"]));\n        this.name = \"PanVol\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(PanVol.getDefaults(), arguments, [\"pan\", \"volume\"]);\n        this._panner = this.input = new _Panner__WEBPACK_IMPORTED_MODULE_3__.Panner({\n            context: this.context,\n            pan: options.pan,\n            channelCount: options.channelCount,\n        });\n        this.pan = this._panner.pan;\n        this._volume = this.output = new _Volume__WEBPACK_IMPORTED_MODULE_4__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        // connections\n        this._panner.connect(this._volume);\n        this.mute = options.mute;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_0__.readOnly)(this, [\"pan\", \"volume\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            pan: 0,\n            volume: 0,\n            channelCount: 1,\n        });\n    }\n    /**\n     * Mute/unmute the volume\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    dispose() {\n        super.dispose();\n        this._panner.dispose();\n        this.pan.dispose();\n        this._volume.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PanVol.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/PanVol.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Panner.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Panner.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Panner\": () => (/* binding */ Panner)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.\n * @example\n * return Tone.Offline(() => {\n * // move the input signal from right to left\n * \tconst panner = new Tone.Panner(1).toDestination();\n * \tpanner.pan.rampTo(-1, 0.5);\n * \tconst osc = new Tone.Oscillator(100).connect(panner).start();\n * }, 0.5, 2);\n * @category Component\n */\nclass Panner extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner.getDefaults(), arguments, [\"pan\"])));\n        this.name = \"Panner\";\n        /**\n         * the panner node\n         */\n        this._panner = this.context.createStereoPanner();\n        this.input = this._panner;\n        this.output = this._panner;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner.getDefaults(), arguments, [\"pan\"]);\n        this.pan = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.pan,\n            value: options.pan,\n            minValue: -1,\n            maxValue: 1,\n        });\n        // this is necessary for standardized-audio-context\n        // doesn't make any difference for the native AudioContext\n        // https://github.com/chrisguttandin/standardized-audio-context/issues/647\n        this._panner.channelCount = options.channelCount;\n        this._panner.channelCountMode = \"explicit\";\n        // initial value\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"pan\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            pan: 0,\n            channelCount: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._panner.disconnect();\n        this.pan.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Panner.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Panner.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Panner3D.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Panner3D.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Panner3D\": () => (/* binding */ Panner3D)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Listener__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/Listener */ \"./node_modules/tone/build/esm/core/context/Listener.js\");\n\n\n\n\n/**\n * A spatialized panner node which supports equalpower or HRTF panning.\n * @category Component\n */\nclass Panner3D extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner3D.getDefaults(), arguments, [\"positionX\", \"positionY\", \"positionZ\"]));\n        this.name = \"Panner3D\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Panner3D.getDefaults(), arguments, [\"positionX\", \"positionY\", \"positionZ\"]);\n        this._panner = this.input = this.output = this.context.createPanner();\n        // set some values\n        this.panningModel = options.panningModel;\n        this.maxDistance = options.maxDistance;\n        this.distanceModel = options.distanceModel;\n        this.coneOuterGain = options.coneOuterGain;\n        this.coneOuterAngle = options.coneOuterAngle;\n        this.coneInnerAngle = options.coneInnerAngle;\n        this.refDistance = options.refDistance;\n        this.rolloffFactor = options.rolloffFactor;\n        this.positionX = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.positionX,\n            value: options.positionX,\n        });\n        this.positionY = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.positionY,\n            value: options.positionY,\n        });\n        this.positionZ = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.positionZ,\n            value: options.positionZ,\n        });\n        this.orientationX = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.orientationX,\n            value: options.orientationX,\n        });\n        this.orientationY = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.orientationY,\n            value: options.orientationY,\n        });\n        this.orientationZ = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._panner.orientationZ,\n            value: options.orientationZ,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            coneInnerAngle: 360,\n            coneOuterAngle: 360,\n            coneOuterGain: 0,\n            distanceModel: \"inverse\",\n            maxDistance: 10000,\n            orientationX: 0,\n            orientationY: 0,\n            orientationZ: 0,\n            panningModel: \"equalpower\",\n            positionX: 0,\n            positionY: 0,\n            positionZ: 0,\n            refDistance: 1,\n            rolloffFactor: 1,\n        });\n    }\n    /**\n     * Sets the position of the source in 3d space.\n     */\n    setPosition(x, y, z) {\n        this.positionX.value = x;\n        this.positionY.value = y;\n        this.positionZ.value = z;\n        return this;\n    }\n    /**\n     * Sets the orientation of the source in 3d space.\n     */\n    setOrientation(x, y, z) {\n        this.orientationX.value = x;\n        this.orientationY.value = y;\n        this.orientationZ.value = z;\n        return this;\n    }\n    /**\n     * The panning model. Either \"equalpower\" or \"HRTF\".\n     */\n    get panningModel() {\n        return this._panner.panningModel;\n    }\n    set panningModel(val) {\n        this._panner.panningModel = val;\n    }\n    /**\n     * A reference distance for reducing volume as source move further from the listener\n     */\n    get refDistance() {\n        return this._panner.refDistance;\n    }\n    set refDistance(val) {\n        this._panner.refDistance = val;\n    }\n    /**\n     * Describes how quickly the volume is reduced as source moves away from listener.\n     */\n    get rolloffFactor() {\n        return this._panner.rolloffFactor;\n    }\n    set rolloffFactor(val) {\n        this._panner.rolloffFactor = val;\n    }\n    /**\n     * The distance model used by,  \"linear\", \"inverse\", or \"exponential\".\n     */\n    get distanceModel() {\n        return this._panner.distanceModel;\n    }\n    set distanceModel(val) {\n        this._panner.distanceModel = val;\n    }\n    /**\n     * The angle, in degrees, inside of which there will be no volume reduction\n     */\n    get coneInnerAngle() {\n        return this._panner.coneInnerAngle;\n    }\n    set coneInnerAngle(val) {\n        this._panner.coneInnerAngle = val;\n    }\n    /**\n     * The angle, in degrees, outside of which the volume will be reduced\n     * to a constant value of coneOuterGain\n     */\n    get coneOuterAngle() {\n        return this._panner.coneOuterAngle;\n    }\n    set coneOuterAngle(val) {\n        this._panner.coneOuterAngle = val;\n    }\n    /**\n     * The gain outside of the coneOuterAngle\n     */\n    get coneOuterGain() {\n        return this._panner.coneOuterGain;\n    }\n    set coneOuterGain(val) {\n        this._panner.coneOuterGain = val;\n    }\n    /**\n     * The maximum distance between source and listener,\n     * after which the volume will not be reduced any further.\n     */\n    get maxDistance() {\n        return this._panner.maxDistance;\n    }\n    set maxDistance(val) {\n        this._panner.maxDistance = val;\n    }\n    dispose() {\n        super.dispose();\n        this._panner.disconnect();\n        this.orientationX.dispose();\n        this.orientationY.dispose();\n        this.orientationZ.dispose();\n        this.positionX.dispose();\n        this.positionY.dispose();\n        this.positionZ.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Panner3D.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Panner3D.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Recorder.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Recorder.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Recorder\": () => (/* binding */ Recorder)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n/**\n * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer\n * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.\n * This is only natively supported in Chrome and Firefox.\n * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n * @example\n * const recorder = new Tone.Recorder();\n * const synth = new Tone.Synth().connect(recorder);\n * // start recording\n * recorder.start();\n * // generate a few notes\n * synth.triggerAttackRelease(\"C3\", 0.5);\n * synth.triggerAttackRelease(\"C4\", 0.5, \"+1\");\n * synth.triggerAttackRelease(\"C5\", 0.5, \"+2\");\n * // wait for the notes to end and stop the recording\n * setTimeout(async () => {\n * \t// the recorded audio is returned as a blob\n * \tconst recording = await recorder.stop();\n * \t// download the recording by creating an anchor element and blob url\n * \tconst url = URL.createObjectURL(recording);\n * \tconst anchor = document.createElement(\"a\");\n * \tanchor.download = \"recording.webm\";\n * \tanchor.href = url;\n * \tanchor.click();\n * }, 4000);\n * @category Component\n */\nclass Recorder extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Recorder.getDefaults(), arguments));\n        this.name = \"Recorder\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Recorder.getDefaults(), arguments);\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({\n            context: this.context\n        });\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(Recorder.supported, \"Media Recorder API is not available\");\n        this._stream = this.context.createMediaStreamDestination();\n        this.input.connect(this._stream);\n        this._recorder = new MediaRecorder(this._stream.stream, {\n            mimeType: options.mimeType\n        });\n    }\n    static getDefaults() {\n        return _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults();\n    }\n    /**\n     * The mime type is the format that the audio is encoded in. For Chrome\n     * that is typically webm encoded as \"vorbis\".\n     */\n    get mimeType() {\n        return this._recorder.mimeType;\n    }\n    /**\n     * Test if your platform supports the Media Recorder API. If it's not available,\n     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].\n     */\n    static get supported() {\n        return _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_3__.theWindow !== null && Reflect.has(_core_context_AudioContext__WEBPACK_IMPORTED_MODULE_3__.theWindow, \"MediaRecorder\");\n    }\n    /**\n     * Get the playback state of the Recorder, either \"started\", \"stopped\" or \"paused\"\n     */\n    get state() {\n        if (this._recorder.state === \"inactive\") {\n            return \"stopped\";\n        }\n        else if (this._recorder.state === \"paused\") {\n            return \"paused\";\n        }\n        else {\n            return \"started\";\n        }\n    }\n    /**\n     * Start the Recorder. Returns a promise which resolves\n     * when the recorder has started.\n     */\n    start() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_5__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(this.state !== \"started\", \"Recorder is already started\");\n            const startPromise = new Promise(done => {\n                const handleStart = () => {\n                    this._recorder.removeEventListener(\"start\", handleStart, false);\n                    done();\n                };\n                this._recorder.addEventListener(\"start\", handleStart, false);\n            });\n            this._recorder.start();\n            return yield startPromise;\n        });\n    }\n    /**\n     * Stop the recorder. Returns a promise with the recorded content until this point\n     * encoded as [[mimeType]]\n     */\n    stop() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_5__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(this.state !== \"stopped\", \"Recorder is not started\");\n            const dataPromise = new Promise(done => {\n                const handleData = (e) => {\n                    this._recorder.removeEventListener(\"dataavailable\", handleData, false);\n                    done(e.data);\n                };\n                this._recorder.addEventListener(\"dataavailable\", handleData, false);\n            });\n            this._recorder.stop();\n            return yield dataPromise;\n        });\n    }\n    /**\n     * Pause the recorder\n     */\n    pause() {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(this.state === \"started\", \"Recorder must be started\");\n        this._recorder.pause();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this._stream.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Recorder.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Recorder.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Solo.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Solo.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Solo\": () => (/* binding */ Solo)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n/**\n * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,\n * it will mute all other instances of Solo.\n * @example\n * const soloA = new Tone.Solo().toDestination();\n * const oscA = new Tone.Oscillator(\"C4\", \"sawtooth\").connect(soloA);\n * const soloB = new Tone.Solo().toDestination();\n * const oscB = new Tone.Oscillator(\"E4\", \"square\").connect(soloB);\n * soloA.solo = true;\n * // no audio will pass through soloB\n * @category Component\n */\nclass Solo extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Solo.getDefaults(), arguments, [\"solo\"]));\n        this.name = \"Solo\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Solo.getDefaults(), arguments, [\"solo\"]);\n        this.input = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n        });\n        if (!Solo._allSolos.has(this.context)) {\n            Solo._allSolos.set(this.context, new Set());\n        }\n        Solo._allSolos.get(this.context).add(this);\n        // set initially\n        this.solo = options.solo;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            solo: false,\n        });\n    }\n    /**\n     * Isolates this instance and mutes all other instances of Solo.\n     * Only one instance can be soloed at a time. A soloed\n     * instance will report `solo=false` when another instance is soloed.\n     */\n    get solo() {\n        return this._isSoloed();\n    }\n    set solo(solo) {\n        if (solo) {\n            this._addSolo();\n        }\n        else {\n            this._removeSolo();\n        }\n        Solo._allSolos.get(this.context).forEach(instance => instance._updateSolo());\n    }\n    /**\n     * If the current instance is muted, i.e. another instance is soloed\n     */\n    get muted() {\n        return this.input.gain.value === 0;\n    }\n    /**\n     * Add this to the soloed array\n     */\n    _addSolo() {\n        if (!Solo._soloed.has(this.context)) {\n            Solo._soloed.set(this.context, new Set());\n        }\n        Solo._soloed.get(this.context).add(this);\n    }\n    /**\n     * Remove this from the soloed array\n     */\n    _removeSolo() {\n        if (Solo._soloed.has(this.context)) {\n            Solo._soloed.get(this.context).delete(this);\n        }\n    }\n    /**\n     * Is this on the soloed array\n     */\n    _isSoloed() {\n        return Solo._soloed.has(this.context) && Solo._soloed.get(this.context).has(this);\n    }\n    /**\n     * Returns true if no one is soloed\n     */\n    _noSolos() {\n        // either does not have any soloed added\n        return !Solo._soloed.has(this.context) ||\n            // or has a solo set but doesn't include any items\n            (Solo._soloed.has(this.context) && Solo._soloed.get(this.context).size === 0);\n    }\n    /**\n     * Solo the current instance and unsolo all other instances.\n     */\n    _updateSolo() {\n        if (this._isSoloed()) {\n            this.input.gain.value = 1;\n        }\n        else if (this._noSolos()) {\n            // no one is soloed\n            this.input.gain.value = 1;\n        }\n        else {\n            this.input.gain.value = 0;\n        }\n    }\n    dispose() {\n        super.dispose();\n        Solo._allSolos.get(this.context).delete(this);\n        this._removeSolo();\n        return this;\n    }\n}\n/**\n * Hold all of the solo'ed tracks belonging to a specific context\n */\nSolo._allSolos = new Map();\n/**\n * Hold the currently solo'ed instance(s)\n */\nSolo._soloed = new Map();\n//# sourceMappingURL=Solo.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Solo.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Split.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Split.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Split\": () => (/* binding */ Split)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n/**\n * Split splits an incoming signal into the number of given channels.\n *\n * @example\n * const split = new Tone.Split();\n * // stereoSignal.connect(split);\n * @category Component\n */\nclass Split extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Split.getDefaults(), arguments, [\"channels\"]));\n        this.name = \"Split\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Split.getDefaults(), arguments, [\"channels\"]);\n        this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);\n        this._internalChannels = [this._splitter];\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            channels: 2,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._splitter.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Split.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Split.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/channel/Volume.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/channel/Volume.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Volume\": () => (/* binding */ Volume)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Volume is a simple volume node, useful for creating a volume fader.\n *\n * @example\n * const vol = new Tone.Volume(-12).toDestination();\n * const osc = new Tone.Oscillator().connect(vol).start();\n * @category Component\n */\nclass Volume extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Volume.getDefaults(), arguments, [\"volume\"]));\n        this.name = \"Volume\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Volume.getDefaults(), arguments, [\"volume\"]);\n        this.input = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.volume,\n            units: \"decibels\",\n        });\n        this.volume = this.output.gain;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"volume\");\n        this._unmutedVolume = options.volume;\n        // set the mute initially\n        this.mute = options.mute;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const vol = new Tone.Volume(-12).toDestination();\n     * const osc = new Tone.Oscillator().connect(vol).start();\n     * // mute the output\n     * vol.mute = true;\n     */\n    get mute() {\n        return this.volume.value === -Infinity;\n    }\n    set mute(mute) {\n        if (!this.mute && mute) {\n            this._unmutedVolume = this.volume.value;\n            // maybe it should ramp here?\n            this.volume.value = -Infinity;\n        }\n        else if (this.mute && !mute) {\n            this.volume.value = this._unmutedVolume;\n        }\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Volume.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/channel/Volume.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/Compressor.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/Compressor.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Compressor\": () => (/* binding */ Compressor)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Compressor is a thin wrapper around the Web Audio\n * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).\n * Compression reduces the volume of loud sounds or amplifies quiet sounds\n * by narrowing or \"compressing\" an audio signal's dynamic range.\n * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).\n * @example\n * const comp = new Tone.Compressor(-30, 3);\n * @category Component\n */\nclass Compressor extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Compressor.getDefaults(), arguments, [\"threshold\", \"ratio\"]));\n        this.name = \"Compressor\";\n        /**\n         * the compressor node\n         */\n        this._compressor = this.context.createDynamicsCompressor();\n        this.input = this._compressor;\n        this.output = this._compressor;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Compressor.getDefaults(), arguments, [\"threshold\", \"ratio\"]);\n        this.threshold = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.threshold.minValue,\n            maxValue: this._compressor.threshold.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.threshold,\n            units: \"decibels\",\n            value: options.threshold,\n        });\n        this.attack = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.attack.minValue,\n            maxValue: this._compressor.attack.maxValue,\n            context: this.context,\n            param: this._compressor.attack,\n            units: \"time\",\n            value: options.attack,\n        });\n        this.release = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.release.minValue,\n            maxValue: this._compressor.release.maxValue,\n            context: this.context,\n            param: this._compressor.release,\n            units: \"time\",\n            value: options.release,\n        });\n        this.knee = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.knee.minValue,\n            maxValue: this._compressor.knee.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.knee,\n            units: \"decibels\",\n            value: options.knee,\n        });\n        this.ratio = new _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            minValue: this._compressor.ratio.minValue,\n            maxValue: this._compressor.ratio.maxValue,\n            context: this.context,\n            convert: false,\n            param: this._compressor.ratio,\n            units: \"positive\",\n            value: options.ratio,\n        });\n        // set the defaults\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"knee\", \"release\", \"attack\", \"ratio\", \"threshold\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            attack: 0.003,\n            knee: 30,\n            ratio: 12,\n            release: 0.25,\n            threshold: -24,\n        });\n    }\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).\n     */\n    get reduction() {\n        return this._compressor.reduction;\n    }\n    dispose() {\n        super.dispose();\n        this._compressor.disconnect();\n        this.attack.dispose();\n        this.release.dispose();\n        this.threshold.dispose();\n        this.ratio.dispose();\n        this.knee.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Compressor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/dynamics/Compressor.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/Gate.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/Gate.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Gate\": () => (/* binding */ Gate)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _signal_GreaterThan__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../signal/GreaterThan */ \"./node_modules/tone/build/esm/signal/GreaterThan.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _analysis_Follower__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../analysis/Follower */ \"./node_modules/tone/build/esm/component/analysis/Follower.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n\n\n\n\n\n\n/**\n * Gate only passes a signal through when the incoming\n * signal exceeds a specified threshold. It uses [[Follower]] to follow the ampltiude\n * of the incoming signal and compares it to the [[threshold]] value using [[GreaterThan]].\n *\n * @example\n * const gate = new Tone.Gate(-30, 0.2).toDestination();\n * const mic = new Tone.UserMedia().connect(gate);\n * // the gate will only pass through the incoming\n * // signal when it's louder than -30db\n * @category Component\n */\nclass Gate extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Gate.getDefaults(), arguments, [\"threshold\", \"smoothing\"])));\n        this.name = \"Gate\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Gate.getDefaults(), arguments, [\"threshold\", \"smoothing\"]);\n        this._follower = new _analysis_Follower__WEBPACK_IMPORTED_MODULE_3__.Follower({\n            context: this.context,\n            smoothing: options.smoothing,\n        });\n        this._gt = new _signal_GreaterThan__WEBPACK_IMPORTED_MODULE_1__.GreaterThan({\n            context: this.context,\n            value: (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.dbToGain)(options.threshold),\n        });\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._gate = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        // connections\n        this.input.connect(this._gate);\n        // the control signal\n        this.input.chain(this._follower, this._gt, this._gate.gain);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            smoothing: 0.1,\n            threshold: -40\n        });\n    }\n    /**\n     * The threshold of the gate in decibels\n     */\n    get threshold() {\n        return (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.gainToDb)(this._gt.value);\n    }\n    set threshold(thresh) {\n        this._gt.value = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.dbToGain)(thresh);\n    }\n    /**\n     * The attack/decay speed of the gate. See [[Follower.smoothing]]\n     */\n    get smoothing() {\n        return this._follower.smoothing;\n    }\n    set smoothing(smoothingTime) {\n        this._follower.smoothing = smoothingTime;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this._follower.dispose();\n        this._gt.dispose();\n        this._gate.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Gate.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/dynamics/Gate.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/Limiter.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/Limiter.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Limiter\": () => (/* binding */ Limiter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Compressor__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n;\n/**\n * Limiter will limit the loudness of an incoming signal.\n * Under the hood it's composed of a [[Compressor]] with a fast attack\n * and release and max compression ratio.\n *\n * @example\n * const limiter = new Tone.Limiter(-20).toDestination();\n * const oscillator = new Tone.Oscillator().connect(limiter);\n * oscillator.start();\n * @category Component\n */\nclass Limiter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Limiter.getDefaults(), arguments, [\"threshold\"])));\n        this.name = \"Limiter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Limiter.getDefaults(), arguments, [\"threshold\"]);\n        this._compressor = this.input = this.output = new _Compressor__WEBPACK_IMPORTED_MODULE_2__.Compressor({\n            context: this.context,\n            ratio: 20,\n            attack: 0.003,\n            release: 0.01,\n            threshold: options.threshold\n        });\n        this.threshold = this._compressor.threshold;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"threshold\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            threshold: -12\n        });\n    }\n    /**\n     * A read-only decibel value for metering purposes, representing the current amount of gain\n     * reduction that the compressor is applying to the signal.\n     */\n    get reduction() {\n        return this._compressor.reduction;\n    }\n    dispose() {\n        super.dispose();\n        this._compressor.dispose();\n        this.threshold.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Limiter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/dynamics/Limiter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideCompressor\": () => (/* binding */ MidSideCompressor)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Compressor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../channel/MidSideSplit */ \"./node_modules/tone/build/esm/component/channel/MidSideSplit.js\");\n/* harmony import */ var _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../channel/MidSideMerge */ \"./node_modules/tone/build/esm/component/channel/MidSideMerge.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * MidSideCompressor applies two different compressors to the [[mid]]\n * and [[side]] signal components of the input. See [[MidSideSplit]] and [[MidSideMerge]].\n * @category Component\n */\nclass MidSideCompressor extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MidSideCompressor.getDefaults(), arguments)));\n        this.name = \"MidSideCompressor\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MidSideCompressor.getDefaults(), arguments);\n        this._midSideSplit = this.input = new _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_3__.MidSideSplit({ context: this.context });\n        this._midSideMerge = this.output = new _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_4__.MidSideMerge({ context: this.context });\n        this.mid = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.mid, { context: this.context }));\n        this.side = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.side, { context: this.context }));\n        this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);\n        this._midSideSplit.side.chain(this.side, this._midSideMerge.side);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"mid\", \"side\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            mid: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n            side: {\n                ratio: 6,\n                threshold: -30,\n                release: 0.25,\n                attack: 0.03,\n                knee: 10\n            }\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.mid.dispose();\n        this.side.dispose();\n        this._midSideSplit.dispose();\n        this._midSideMerge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideCompressor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MultibandCompressor\": () => (/* binding */ MultibandCompressor)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Compressor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../channel/MultibandSplit */ \"./node_modules/tone/build/esm/component/channel/MultibandSplit.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n\n\n\n\n\n\n/**\n * A compressor with separate controls over low/mid/high dynamics. See [[Compressor]] and [[MultibandSplit]]\n *\n * @example\n * const multiband = new Tone.MultibandCompressor({\n * \tlowFrequency: 200,\n * \thighFrequency: 1300,\n * \tlow: {\n * \t\tthreshold: -12\n * \t}\n * });\n * @category Component\n */\nclass MultibandCompressor extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandCompressor.getDefaults(), arguments)));\n        this.name = \"MultibandCompressor\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(MultibandCompressor.getDefaults(), arguments);\n        this._splitter = this.input = new _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__.MultibandSplit({\n            context: this.context,\n            lowFrequency: options.lowFrequency,\n            highFrequency: options.highFrequency\n        });\n        this.lowFrequency = this._splitter.lowFrequency;\n        this.highFrequency = this._splitter.highFrequency;\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({ context: this.context });\n        this.low = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.low, { context: this.context }));\n        this.mid = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.mid, { context: this.context }));\n        this.high = new _Compressor__WEBPACK_IMPORTED_MODULE_1__.Compressor(Object.assign(options.high, { context: this.context }));\n        // connect the compressor\n        this._splitter.low.chain(this.low, this.output);\n        this._splitter.mid.chain(this.mid, this.output);\n        this._splitter.high.chain(this.high, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"high\", \"mid\", \"low\", \"highFrequency\", \"lowFrequency\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            lowFrequency: 250,\n            highFrequency: 2000,\n            low: {\n                ratio: 6,\n                threshold: -30,\n                release: 0.25,\n                attack: 0.03,\n                knee: 10\n            },\n            mid: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n            high: {\n                ratio: 3,\n                threshold: -24,\n                release: 0.03,\n                attack: 0.02,\n                knee: 16\n            },\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._splitter.dispose();\n        this.low.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.output.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MultibandCompressor.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* binding */ AmplitudeEnvelope)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Envelope__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n\n\n\n/**\n * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.\n * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts\n * an audio signal as the input and will apply the envelope to the amplitude\n * of the signal.\n * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst ampEnv = new Tone.AmplitudeEnvelope({\n * \t\tattack: 0.1,\n * \t\tdecay: 0.2,\n * \t\tsustain: 1.0,\n * \t\trelease: 0.8\n * \t}).toDestination();\n * \t// create an oscillator and connect it\n * \tconst osc = new Tone.Oscillator().connect(ampEnv).start();\n * \t// trigger the envelopes attack and release \"8t\" apart\n * \tampEnv.triggerAttackRelease(\"8t\");\n * }, 1.5, 1);\n * @category Component\n */\nclass AmplitudeEnvelope extends _Envelope__WEBPACK_IMPORTED_MODULE_2__.Envelope {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AmplitudeEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"AmplitudeEnvelope\";\n        this._gainNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        this.output = this._gainNode;\n        this.input = this._gainNode;\n        this._sig.connect(this._gainNode.gain);\n        this.output = this._gainNode;\n        this.input = this._gainNode;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._gainNode.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AmplitudeEnvelope.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/envelope/Envelope.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/envelope/Envelope.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Envelope\": () => (/* binding */ Envelope)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n\n\n/**\n * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)\n * envelope generator. Envelope outputs a signal which\n * can be connected to an AudioParam or Tone.Signal.\n * ```\n *           /\\\n *          /  \\\n *         /    \\\n *        /      \\\n *       /        \\___________\n *      /                     \\\n *     /                       \\\n *    /                         \\\n *   /                           \\\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst env = new Tone.Envelope({\n * \t\tattack: 0.1,\n * \t\tdecay: 0.2,\n * \t\tsustain: 0.5,\n * \t\trelease: 0.8,\n * \t}).toDestination();\n * \tenv.triggerAttackRelease(0.5);\n * }, 1.5, 1);\n * @category Component\n */\nclass Envelope extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Envelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"Envelope\";\n        /**\n         * the signal which is output.\n         */\n        this._sig = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: 0,\n        });\n        /**\n         * The output signal of the envelope\n         */\n        this.output = this._sig;\n        /**\n         * Envelope has no input\n         */\n        this.input = undefined;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Envelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]);\n        this.attack = options.attack;\n        this.decay = options.decay;\n        this.sustain = options.sustain;\n        this.release = options.release;\n        this.attackCurve = options.attackCurve;\n        this.releaseCurve = options.releaseCurve;\n        this.decayCurve = options.decayCurve;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            attack: 0.01,\n            attackCurve: \"linear\",\n            decay: 0.1,\n            decayCurve: \"exponential\",\n            release: 1,\n            releaseCurve: \"exponential\",\n            sustain: 0.5,\n        });\n    }\n    /**\n     * Read the current value of the envelope. Useful for\n     * synchronizing visual output to the envelope.\n     */\n    get value() {\n        return this.getValueAtTime(this.now());\n    }\n    /**\n     * Get the curve\n     * @param  curve\n     * @param  direction  In/Out\n     * @return The curve name\n     */\n    _getCurve(curve, direction) {\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(curve)) {\n            return curve;\n        }\n        else {\n            // look up the name in the curves array\n            let curveName;\n            for (curveName in EnvelopeCurves) {\n                if (EnvelopeCurves[curveName][direction] === curve) {\n                    return curveName;\n                }\n            }\n            // return the custom curve\n            return curve;\n        }\n    }\n    /**\n     * Assign a the curve to the given name using the direction\n     * @param  name\n     * @param  direction In/Out\n     * @param  curve\n     */\n    _setCurve(name, direction, curve) {\n        // check if it's a valid type\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(curve) && Reflect.has(EnvelopeCurves, curve)) {\n            const curveDef = EnvelopeCurves[curve];\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isObject)(curveDef)) {\n                if (name !== \"_decayCurve\") {\n                    this[name] = curveDef[direction];\n                }\n            }\n            else {\n                this[name] = curveDef;\n            }\n        }\n        else if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(curve) && name !== \"_decayCurve\") {\n            this[name] = curve;\n        }\n        else {\n            throw new Error(\"Envelope: invalid curve: \" + curve);\n        }\n    }\n    /**\n     * The shape of the attack.\n     * Can be any of these strings:\n     * * \"linear\"\n     * * \"exponential\"\n     * * \"sine\"\n     * * \"cosine\"\n     * * \"bounce\"\n     * * \"ripple\"\n     * * \"step\"\n     *\n     * Can also be an array which describes the curve. Values\n     * in the array are evenly subdivided and linearly\n     * interpolated over the duration of the attack.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope(0.4).toDestination();\n     * \tenv.attackCurve = \"linear\";\n     * \tenv.triggerAttack();\n     * }, 1, 1);\n     */\n    get attackCurve() {\n        return this._getCurve(this._attackCurve, \"In\");\n    }\n    set attackCurve(curve) {\n        this._setCurve(\"_attackCurve\", \"In\", curve);\n    }\n    /**\n     * The shape of the release. See the attack curve types.\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope({\n     * \t\trelease: 0.8\n     * \t}).toDestination();\n     * \tenv.triggerAttack();\n     * \t// release curve could also be defined by an array\n     * \tenv.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];\n     * \tenv.triggerRelease(0.2);\n     * }, 1, 1);\n     */\n    get releaseCurve() {\n        return this._getCurve(this._releaseCurve, \"Out\");\n    }\n    set releaseCurve(curve) {\n        this._setCurve(\"_releaseCurve\", \"Out\", curve);\n    }\n    /**\n     * The shape of the decay either \"linear\" or \"exponential\"\n     * @example\n     * return Tone.Offline(() => {\n     * \tconst env = new Tone.Envelope({\n     * \t\tsustain: 0.1,\n     * \t\tdecay: 0.5\n     * \t}).toDestination();\n     * \tenv.decayCurve = \"linear\";\n     * \tenv.triggerAttack();\n     * }, 1, 1);\n     */\n    get decayCurve() {\n        return this._decayCurve;\n    }\n    set decayCurve(curve) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)([\"linear\", \"exponential\"].some(c => c === curve), `Invalid envelope curve: ${curve}`);\n        this._decayCurve = curve;\n    }\n    /**\n     * Trigger the attack/decay portion of the ADSR envelope.\n     * @param  time When the attack should start.\n     * @param velocity The velocity of the envelope scales the vales.\n     *                             number between 0-1\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the attack 0.5 seconds from now with a velocity of 0.2\n     * env.triggerAttack(\"+0.5\", 0.2);\n     */\n    triggerAttack(time, velocity = 1) {\n        this.log(\"triggerAttack\", time, velocity);\n        time = this.toSeconds(time);\n        const originalAttack = this.toSeconds(this.attack);\n        let attack = originalAttack;\n        const decay = this.toSeconds(this.decay);\n        // check if it's not a complete attack\n        const currentValue = this.getValueAtTime(time);\n        if (currentValue > 0) {\n            // subtract the current value from the attack time\n            const attackRate = 1 / attack;\n            const remainingDistance = 1 - currentValue;\n            // the attack is now the remaining time\n            attack = remainingDistance / attackRate;\n        }\n        // attack\n        if (attack < this.sampleTime) {\n            this._sig.cancelScheduledValues(time);\n            // case where the attack time is 0 should set instantly\n            this._sig.setValueAtTime(velocity, time);\n        }\n        else if (this._attackCurve === \"linear\") {\n            this._sig.linearRampTo(velocity, attack, time);\n        }\n        else if (this._attackCurve === \"exponential\") {\n            this._sig.targetRampTo(velocity, attack, time);\n        }\n        else {\n            this._sig.cancelAndHoldAtTime(time);\n            let curve = this._attackCurve;\n            // find the starting position in the curve\n            for (let i = 1; i < curve.length; i++) {\n                // the starting index is between the two values\n                if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {\n                    curve = this._attackCurve.slice(i);\n                    // the first index is the current value\n                    curve[0] = currentValue;\n                    break;\n                }\n            }\n            this._sig.setValueCurveAtTime(curve, time, attack, velocity);\n        }\n        // decay\n        if (decay && this.sustain < 1) {\n            const decayValue = velocity * this.sustain;\n            const decayStart = time + attack;\n            this.log(\"decay\", decayStart);\n            if (this._decayCurve === \"linear\") {\n                this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);\n            }\n            else {\n                this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);\n            }\n        }\n        return this;\n    }\n    /**\n     * Triggers the release of the envelope.\n     * @param  time When the release portion of the envelope should start.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator({\n     * \ttype: \"sawtooth\"\n     * }).connect(env).start();\n     * env.triggerAttack();\n     * // trigger the release half a second after the attack\n     * env.triggerRelease(\"+0.5\");\n     */\n    triggerRelease(time) {\n        this.log(\"triggerRelease\", time);\n        time = this.toSeconds(time);\n        const currentValue = this.getValueAtTime(time);\n        if (currentValue > 0) {\n            const release = this.toSeconds(this.release);\n            if (release < this.sampleTime) {\n                this._sig.setValueAtTime(0, time);\n            }\n            else if (this._releaseCurve === \"linear\") {\n                this._sig.linearRampTo(0, release, time);\n            }\n            else if (this._releaseCurve === \"exponential\") {\n                this._sig.targetRampTo(0, release, time);\n            }\n            else {\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(this._releaseCurve), \"releaseCurve must be either 'linear', 'exponential' or an array\");\n                this._sig.cancelAndHoldAtTime(time);\n                this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);\n            }\n        }\n        return this;\n    }\n    /**\n     * Get the scheduled value at the given time. This will\n     * return the unconverted (raw) value.\n     * @example\n     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);\n     * env.triggerAttackRelease(2);\n     * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);\n     */\n    getValueAtTime(time) {\n        return this._sig.getValueAtTime(time);\n    }\n    /**\n     * triggerAttackRelease is shorthand for triggerAttack, then waiting\n     * some duration, then triggerRelease.\n     * @param duration The duration of the sustain.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity of the envelope.\n     * @example\n     * const env = new Tone.AmplitudeEnvelope().toDestination();\n     * const osc = new Tone.Oscillator().connect(env).start();\n     * // trigger the release 0.5 seconds after the attack\n     * env.triggerAttackRelease(0.5);\n     */\n    triggerAttackRelease(duration, time, velocity = 1) {\n        time = this.toSeconds(time);\n        this.triggerAttack(time, velocity);\n        this.triggerRelease(time + this.toSeconds(duration));\n        return this;\n    }\n    /**\n     * Cancels all scheduled envelope changes after the given time.\n     */\n    cancel(after) {\n        this._sig.cancelScheduledValues(this.toSeconds(after));\n        return this;\n    }\n    /**\n     * Connect the envelope to a destination node.\n     */\n    connect(destination, outputNumber = 0, inputNumber = 0) {\n        (0,_signal_Signal__WEBPACK_IMPORTED_MODULE_3__.connectSignal)(this, destination, outputNumber, inputNumber);\n        return this;\n    }\n    /**\n     * Render the envelope curve to an array of the given length.\n     * Good for visualizing the envelope curve. Rescales the duration of the\n     * envelope to fit the length.\n     */\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            const duration = length / this.context.sampleRate;\n            const context = new _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__.OfflineContext(1, duration, this.context.sampleRate);\n            // normalize the ADSR for the given duration with 20% sustain time\n            const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);\n            const envelopeDuration = attackPortion + this.toSeconds(this.release);\n            const sustainTime = envelopeDuration * 0.1;\n            const totalDuration = envelopeDuration + sustainTime;\n            // @ts-ignore\n            const clone = new this.constructor(Object.assign(this.get(), {\n                attack: duration * this.toSeconds(this.attack) / totalDuration,\n                decay: duration * this.toSeconds(this.decay) / totalDuration,\n                release: duration * this.toSeconds(this.release) / totalDuration,\n                context\n            }));\n            clone._sig.toDestination();\n            clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);\n            const buffer = yield context.render();\n            return buffer.getChannelData(0);\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._sig.dispose();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.timeRange)(0)\n], Envelope.prototype, \"attack\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.timeRange)(0)\n], Envelope.prototype, \"decay\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.range)(0, 1)\n], Envelope.prototype, \"sustain\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_7__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_6__.timeRange)(0)\n], Envelope.prototype, \"release\", void 0);\n/**\n * Generate some complex envelope curves.\n */\nconst EnvelopeCurves = (() => {\n    const curveLen = 128;\n    let i;\n    let k;\n    // cosine curve\n    const cosineCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        cosineCurve[i] = Math.sin((i / (curveLen - 1)) * (Math.PI / 2));\n    }\n    // ripple curve\n    const rippleCurve = [];\n    const rippleCurveFreq = 6.4;\n    for (i = 0; i < curveLen - 1; i++) {\n        k = (i / (curveLen - 1));\n        const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;\n        rippleCurve[i] = sineWave / 10 + k * 0.83;\n    }\n    rippleCurve[curveLen - 1] = 1;\n    // stairs curve\n    const stairsCurve = [];\n    const steps = 5;\n    for (i = 0; i < curveLen; i++) {\n        stairsCurve[i] = Math.ceil((i / (curveLen - 1)) * steps) / steps;\n    }\n    // in-out easing curve\n    const sineCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        k = i / (curveLen - 1);\n        sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));\n    }\n    // a bounce curve\n    const bounceCurve = [];\n    for (i = 0; i < curveLen; i++) {\n        k = i / (curveLen - 1);\n        const freq = Math.pow(k, 3) * 4 + 0.2;\n        const val = Math.cos(freq * Math.PI * 2 * k);\n        bounceCurve[i] = Math.abs(val * (1 - k));\n    }\n    /**\n     * Invert a value curve to make it work for the release\n     */\n    function invertCurve(curve) {\n        const out = new Array(curve.length);\n        for (let j = 0; j < curve.length; j++) {\n            out[j] = 1 - curve[j];\n        }\n        return out;\n    }\n    /**\n     * reverse the curve\n     */\n    function reverseCurve(curve) {\n        return curve.slice(0).reverse();\n    }\n    /**\n     * attack and release curve arrays\n     */\n    return {\n        bounce: {\n            In: invertCurve(bounceCurve),\n            Out: bounceCurve,\n        },\n        cosine: {\n            In: cosineCurve,\n            Out: reverseCurve(cosineCurve),\n        },\n        exponential: \"exponential\",\n        linear: \"linear\",\n        ripple: {\n            In: rippleCurve,\n            Out: invertCurve(rippleCurve),\n        },\n        sine: {\n            In: sineCurve,\n            Out: invertCurve(sineCurve),\n        },\n        step: {\n            In: stairsCurve,\n            Out: invertCurve(stairsCurve),\n        },\n    };\n})();\n//# sourceMappingURL=Envelope.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/envelope/Envelope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FrequencyEnvelope\": () => (/* binding */ FrequencyEnvelope)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Envelope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Pow__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Pow */ \"./node_modules/tone/build/esm/signal/Pow.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * FrequencyEnvelope is an [[Envelope]] which ramps between [[baseFrequency]]\n * and [[octaves]]. It can also have an optional [[exponent]] to adjust the curve\n * which it ramps.\n * @example\n * const oscillator = new Tone.Oscillator().toDestination().start();\n * const freqEnv = new Tone.FrequencyEnvelope({\n * \tattack: 0.2,\n * \tbaseFrequency: \"C2\",\n * \toctaves: 4\n * });\n * freqEnv.connect(oscillator.frequency);\n * freqEnv.triggerAttack();\n * @category Component\n */\nclass FrequencyEnvelope extends _Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FrequencyEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]));\n        this.name = \"FrequencyEnvelope\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FrequencyEnvelope.getDefaults(), arguments, [\"attack\", \"decay\", \"sustain\", \"release\"]);\n        this._octaves = options.octaves;\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._exponent = this.input = new _signal_Pow__WEBPACK_IMPORTED_MODULE_3__.Pow({\n            context: this.context,\n            value: options.exponent\n        });\n        this._scale = this.output = new _signal_Scale__WEBPACK_IMPORTED_MODULE_2__.Scale({\n            context: this.context,\n            min: this._baseFrequency,\n            max: this._baseFrequency * Math.pow(2, this._octaves),\n        });\n        this._sig.chain(this._exponent, this._scale);\n    }\n    static getDefaults() {\n        return Object.assign(_Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope.getDefaults(), {\n            baseFrequency: 200,\n            exponent: 1,\n            octaves: 4,\n        });\n    }\n    /**\n     * The envelope's minimum output value. This is the value which it\n     * starts at.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(min) {\n        const freq = this.toFrequency(min);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assertRange)(freq, 0);\n        this._baseFrequency = freq;\n        this._scale.min = this._baseFrequency;\n        // update the max value when the min changes\n        this.octaves = this._octaves;\n    }\n    /**\n     * The number of octaves above the baseFrequency that the\n     * envelope will scale to.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        this._scale.max = this._baseFrequency * Math.pow(2, octaves);\n    }\n    /**\n     * The envelope's exponent value.\n     */\n    get exponent() {\n        return this._exponent.value;\n    }\n    set exponent(exponent) {\n        this._exponent.value = exponent;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._exponent.dispose();\n        this._scale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FrequencyEnvelope.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/BiquadFilter.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/BiquadFilter.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BiquadFilter\": () => (/* binding */ BiquadFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n/**\n * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).\n * BiquadFilter is similar to [[Filter]] but doesn't have the option to set the \"rolloff\" value.\n * @category Component\n */\nclass BiquadFilter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(BiquadFilter.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"BiquadFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(BiquadFilter.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this._filter = this.context.createBiquadFilter();\n        this.input = this.output = this._filter;\n        this.Q = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"number\",\n            value: options.Q,\n            param: this._filter.Q,\n        });\n        this.frequency = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n            param: this._filter.frequency,\n        });\n        this.detune = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n            param: this._filter.detune,\n        });\n        this.gain = new _core_context_Param__WEBPACK_IMPORTED_MODULE_2__.Param({\n            context: this.context,\n            units: \"decibels\",\n            convert: false,\n            value: options.gain,\n            param: this._filter.gain,\n        });\n        this.type = options.type;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            Q: 1,\n            type: \"lowpass\",\n            frequency: 350,\n            detune: 0,\n            gain: 0,\n        });\n    }\n    /**\n     * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the\n     * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)\n     */\n    get type() {\n        return this._filter.type;\n    }\n    set type(type) {\n        const types = [\"lowpass\", \"highpass\", \"bandpass\",\n            \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", \"peaking\"];\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);\n        this._filter.type = type;\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        // start with all 1s\n        const freqValues = new Float32Array(len);\n        for (let i = 0; i < len; i++) {\n            const norm = Math.pow(i / len, 2);\n            const freq = norm * (20000 - 20) + 20;\n            freqValues[i] = freq;\n        }\n        const magValues = new Float32Array(len);\n        const phaseValues = new Float32Array(len);\n        // clone the filter to remove any connections which may be changing the value\n        const filterClone = this.context.createBiquadFilter();\n        filterClone.type = this.type;\n        filterClone.Q.value = this.Q.value;\n        filterClone.frequency.value = this.frequency.value;\n        filterClone.gain.value = this.gain.value;\n        filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);\n        return magValues;\n    }\n    dispose() {\n        super.dispose();\n        this._filter.disconnect();\n        this.Q.dispose();\n        this.frequency.dispose();\n        this.gain.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=BiquadFilter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/BiquadFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/Convolver.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/Convolver.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Convolver\": () => (/* binding */ Convolver)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * Convolver is a wrapper around the Native Web Audio\n * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).\n * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on\n * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).\n *\n * @example\n * // initializing the convolver with an impulse response\n * const convolver = new Tone.Convolver(\"./path/to/ir.wav\").toDestination();\n * @category Component\n */\nclass Convolver extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Convolver.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"Convolver\";\n        /**\n         * The native ConvolverNode\n         */\n        this._convolver = this.context.createConvolver();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Convolver.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this._buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffer(options.url, buffer => {\n            this.buffer = buffer;\n            options.onload();\n        });\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        // set if it's already loaded, set it immediately\n        if (this._buffer.loaded) {\n            this.buffer = this._buffer;\n        }\n        // initially set normalization\n        this.normalize = options.normalize;\n        // connect it up\n        this.input.chain(this._convolver, this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            normalize: true,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n        });\n    }\n    /**\n     * Load an impulse response url as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     */\n    load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_5__.__awaiter)(this, void 0, void 0, function* () {\n            this.buffer = yield this._buffer.load(url);\n        });\n    }\n    /**\n     * The convolver's buffer\n     */\n    get buffer() {\n        if (this._buffer.length) {\n            return this._buffer;\n        }\n        else {\n            return null;\n        }\n    }\n    set buffer(buffer) {\n        if (buffer) {\n            this._buffer.set(buffer);\n        }\n        // if it's already got a buffer, create a new one\n        if (this._convolver.buffer) {\n            // disconnect the old one\n            this.input.disconnect();\n            this._convolver.disconnect();\n            // create and connect a new one\n            this._convolver = this.context.createConvolver();\n            this.input.chain(this._convolver, this.output);\n        }\n        const buff = this._buffer.get();\n        this._convolver.buffer = buff ? buff : null;\n    }\n    /**\n     * The normalize property of the ConvolverNode interface is a boolean that\n     * controls whether the impulse response from the buffer will be scaled by\n     * an equal-power normalization when the buffer attribute is set, or not.\n     */\n    get normalize() {\n        return this._convolver.normalize;\n    }\n    set normalize(norm) {\n        this._convolver.normalize = norm;\n    }\n    dispose() {\n        super.dispose();\n        this._buffer.dispose();\n        this._convolver.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Convolver.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/Convolver.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/EQ3.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/EQ3.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EQ3\": () => (/* binding */ EQ3)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../channel/MultibandSplit */ \"./node_modules/tone/build/esm/component/channel/MultibandSplit.js\");\n\n\n\n\n\n/**\n * EQ3 provides 3 equalizer bins: Low/Mid/High.\n * @category Component\n */\nclass EQ3 extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(EQ3.getDefaults(), arguments, [\"low\", \"mid\", \"high\"]));\n        this.name = \"EQ3\";\n        /**\n         * the output\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._internalChannels = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(EQ3.getDefaults(), arguments, [\"low\", \"mid\", \"high\"]);\n        this.input = this._multibandSplit = new _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_4__.MultibandSplit({\n            context: this.context,\n            highFrequency: options.highFrequency,\n            lowFrequency: options.lowFrequency,\n        });\n        this._lowGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.low,\n            units: \"decibels\",\n        });\n        this._midGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.mid,\n            units: \"decibels\",\n        });\n        this._highGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.high,\n            units: \"decibels\",\n        });\n        this.low = this._lowGain.gain;\n        this.mid = this._midGain.gain;\n        this.high = this._highGain.gain;\n        this.Q = this._multibandSplit.Q;\n        this.lowFrequency = this._multibandSplit.lowFrequency;\n        this.highFrequency = this._multibandSplit.highFrequency;\n        // the frequency bands\n        this._multibandSplit.low.chain(this._lowGain, this.output);\n        this._multibandSplit.mid.chain(this._midGain, this.output);\n        this._multibandSplit.high.chain(this._highGain, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n        this._internalChannels = [this._multibandSplit];\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            high: 0,\n            highFrequency: 2500,\n            low: 0,\n            lowFrequency: 400,\n            mid: 0,\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.writable)(this, [\"low\", \"mid\", \"high\", \"lowFrequency\", \"highFrequency\"]);\n        this._multibandSplit.dispose();\n        this.lowFrequency.dispose();\n        this.highFrequency.dispose();\n        this._lowGain.dispose();\n        this._midGain.dispose();\n        this._highGain.dispose();\n        this.low.dispose();\n        this.mid.dispose();\n        this.high.dispose();\n        this.Q.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=EQ3.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/EQ3.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js":
/*!****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FeedbackCombFilter\": () => (/* binding */ FeedbackCombFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/worklet/ToneAudioWorklet */ \"./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js\");\n/* harmony import */ var _FeedbackCombFilter_worklet__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./FeedbackCombFilter.worklet */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js\");\n\n\n\n\n\n\n\n/**\n * Comb filters are basic building blocks for physical modeling. Read more\n * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).\n *\n * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the\n * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the\n * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.\n * @category Component\n */\nclass FeedbackCombFilter extends _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_5__.ToneAudioWorklet {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(FeedbackCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\"]));\n        this.name = \"FeedbackCombFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(FeedbackCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\"]);\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this.delayTime = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            value: options.delayTime,\n            units: \"time\",\n            minValue: 0,\n            maxValue: 1,\n            param: this._dummyParam,\n            swappable: true,\n        });\n        this.resonance = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            value: options.resonance,\n            units: \"normalRange\",\n            param: this._dummyParam,\n            swappable: true,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"resonance\", \"delayTime\"]);\n    }\n    _audioWorkletName() {\n        return _FeedbackCombFilter_worklet__WEBPACK_IMPORTED_MODULE_6__.workletName;\n    }\n    /**\n     * The default parameters\n     */\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode.getDefaults(), {\n            delayTime: 0.1,\n            resonance: 0.5,\n        });\n    }\n    onReady(node) {\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.connectSeries)(this.input, node, this.output);\n        const delayTime = node.parameters.get(\"delayTime\");\n        ;\n        this.delayTime.setParam(delayTime);\n        const feedback = node.parameters.get(\"feedback\");\n        ;\n        this.resonance.setParam(feedback);\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.delayTime.dispose();\n        this.resonance.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackCombFilter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js":
/*!************************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"workletName\": () => (/* binding */ workletName)\n/* harmony export */ });\n/* harmony import */ var _core_worklet_SingleIOProcessor_worklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/worklet/SingleIOProcessor.worklet */ \"./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js\");\n/* harmony import */ var _core_worklet_DelayLine_worklet__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/worklet/DelayLine.worklet */ \"./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js\");\n/* harmony import */ var _core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/worklet/WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\n\nconst workletName = \"feedback-comb-filter\";\nconst feedbackCombFilter = /* javascript */ `\n\tclass FeedbackCombFilterWorklet extends SingleIOProcessor {\n\n\t\tconstructor(options) {\n\t\t\tsuper(options);\n\t\t\tthis.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);\n\t\t}\n\n\t\tstatic get parameterDescriptors() {\n\t\t\treturn [{\n\t\t\t\tname: \"delayTime\",\n\t\t\t\tdefaultValue: 0.1,\n\t\t\t\tminValue: 0,\n\t\t\t\tmaxValue: 1,\n\t\t\t\tautomationRate: \"k-rate\"\n\t\t\t}, {\n\t\t\t\tname: \"feedback\",\n\t\t\t\tdefaultValue: 0.5,\n\t\t\t\tminValue: 0,\n\t\t\t\tmaxValue: 0.9999,\n\t\t\t\tautomationRate: \"k-rate\"\n\t\t\t}];\n\t\t}\n\n\t\tgenerate(input, channel, parameters) {\n\t\t\tconst delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);\n\t\t\tthis.delayLine.push(channel, input + delayedSample * parameters.feedback);\n\t\t\treturn delayedSample;\n\t\t}\n\t}\n`;\n(0,_core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__.registerProcessor)(workletName, feedbackCombFilter);\n//# sourceMappingURL=FeedbackCombFilter.worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/Filter.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/Filter.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Filter\": () => (/* binding */ Filter)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _BiquadFilter__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./BiquadFilter */ \"./node_modules/tone/build/esm/component/filter/BiquadFilter.js\");\n\n\n\n\n\n\n\n\n/**\n * Tone.Filter is a filter which allows for all of the same native methods\n * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).\n * Tone.Filter has the added ability to set the filter rolloff at -12\n * (default), -24 and -48.\n * @example\n * const filter = new Tone.Filter(1500, \"highpass\").toDestination();\n * filter.frequency.rampTo(20000, 10);\n * const noise = new Tone.Noise().connect(filter).start();\n * @category Component\n */\nclass Filter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Filter.getDefaults(), arguments, [\"frequency\", \"type\", \"rolloff\"]));\n        this.name = \"Filter\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        this._filters = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Filter.getDefaults(), arguments, [\"frequency\", \"type\", \"rolloff\"]);\n        this._filters = [];\n        this.Q = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"positive\",\n            value: options.Q,\n        });\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this.gain = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({\n            context: this.context,\n            units: \"decibels\",\n            convert: false,\n            value: options.gain,\n        });\n        this._type = options.type;\n        this.rolloff = options.rolloff;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"detune\", \"frequency\", \"gain\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            Q: 1,\n            detune: 0,\n            frequency: 350,\n            gain: 0,\n            rolloff: -12,\n            type: \"lowpass\",\n        });\n    }\n    /**\n     * The type of the filter. Types: \"lowpass\", \"highpass\",\n     * \"bandpass\", \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", or \"peaking\".\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        const types = [\"lowpass\", \"highpass\", \"bandpass\",\n            \"lowshelf\", \"highshelf\", \"notch\", \"allpass\", \"peaking\"];\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);\n        this._type = type;\n        this._filters.forEach(filter => filter.type = type);\n    }\n    /**\n     * The rolloff of the filter which is the drop in db\n     * per octave. Implemented internally by cascading filters.\n     * Only accepts the values -12, -24, -48 and -96.\n     */\n    get rolloff() {\n        return this._rolloff;\n    }\n    set rolloff(rolloff) {\n        const rolloffNum = (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isNumber)(rolloff) ? rolloff : parseInt(rolloff, 10);\n        const possibilities = [-12, -24, -48, -96];\n        let cascadingCount = possibilities.indexOf(rolloffNum);\n        // check the rolloff is valid\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(cascadingCount !== -1, `rolloff can only be ${possibilities.join(\", \")}`);\n        cascadingCount += 1;\n        this._rolloff = rolloffNum;\n        this.input.disconnect();\n        this._filters.forEach(filter => filter.disconnect());\n        this._filters = new Array(cascadingCount);\n        for (let count = 0; count < cascadingCount; count++) {\n            const filter = new _BiquadFilter__WEBPACK_IMPORTED_MODULE_7__.BiquadFilter({\n                context: this.context,\n            });\n            filter.type = this._type;\n            this.frequency.connect(filter.frequency);\n            this.detune.connect(filter.detune);\n            this.Q.connect(filter.Q);\n            this.gain.connect(filter.gain);\n            this._filters[count] = filter;\n        }\n        this._internalChannels = this._filters;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connectSeries)(this.input, ...this._internalChannels, this.output);\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        const filterClone = new _BiquadFilter__WEBPACK_IMPORTED_MODULE_7__.BiquadFilter({\n            frequency: this.frequency.value,\n            gain: this.gain.value,\n            Q: this.Q.value,\n            type: this._type,\n            detune: this.detune.value,\n        });\n        // start with all 1s\n        const totalResponse = new Float32Array(len).map(() => 1);\n        this._filters.forEach(() => {\n            const response = filterClone.getFrequencyResponse(len);\n            response.forEach((val, i) => totalResponse[i] *= val);\n        });\n        filterClone.dispose();\n        return totalResponse;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._filters.forEach(filter => {\n            filter.dispose();\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.writable)(this, [\"detune\", \"frequency\", \"gain\", \"Q\"]);\n        this.frequency.dispose();\n        this.Q.dispose();\n        this.detune.dispose();\n        this.gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Filter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/Filter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LowpassCombFilter\": () => (/* binding */ LowpassCombFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FeedbackCombFilter */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js\");\n/* harmony import */ var _OnePoleFilter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./OnePoleFilter */ \"./node_modules/tone/build/esm/component/filter/OnePoleFilter.js\");\n\n\n\n\n/**\n * A lowpass feedback comb filter. It is similar to\n * [[FeedbackCombFilter]], but includes a lowpass filter.\n * @category Component\n */\nclass LowpassCombFilter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(LowpassCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\", \"dampening\"]));\n        this.name = \"LowpassCombFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(LowpassCombFilter.getDefaults(), arguments, [\"delayTime\", \"resonance\", \"dampening\"]);\n        this._combFilter = this.output = new _FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_2__.FeedbackCombFilter({\n            context: this.context,\n            delayTime: options.delayTime,\n            resonance: options.resonance,\n        });\n        this.delayTime = this._combFilter.delayTime;\n        this.resonance = this._combFilter.resonance;\n        this._lowpass = this.input = new _OnePoleFilter__WEBPACK_IMPORTED_MODULE_3__.OnePoleFilter({\n            context: this.context,\n            frequency: options.dampening,\n            type: \"lowpass\",\n        });\n        // connections\n        this._lowpass.connect(this._combFilter);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            dampening: 3000,\n            delayTime: 0.1,\n            resonance: 0.5,\n        });\n    }\n    /**\n     * The dampening control of the feedback\n     */\n    get dampening() {\n        return this._lowpass.frequency;\n    }\n    set dampening(fq) {\n        this._lowpass.frequency = fq;\n    }\n    dispose() {\n        super.dispose();\n        this._combFilter.dispose();\n        this._lowpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LowpassCombFilter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/OnePoleFilter.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/OnePoleFilter.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OnePoleFilter\": () => (/* binding */ OnePoleFilter)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n\n\n\n/**\n * A one pole filter with 6db-per-octave rolloff. Either \"highpass\" or \"lowpass\".\n * Note that changing the type or frequency may result in a discontinuity which\n * can sound like a click or pop.\n * References:\n * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/\n * * http://www.dspguide.com/ch19/2.htm\n * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts\n * @category Component\n */\nclass OnePoleFilter extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(OnePoleFilter.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"OnePoleFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(OnePoleFilter.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this._frequency = options.frequency;\n        this._type = options.type;\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._createFilter();\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            frequency: 880,\n            type: \"lowpass\"\n        });\n    }\n    /**\n     * Create a filter and dispose the old one\n     */\n    _createFilter() {\n        const oldFilter = this._filter;\n        const freq = this.toFrequency(this._frequency);\n        const t = 1 / (2 * Math.PI * freq);\n        if (this._type === \"lowpass\") {\n            const a0 = 1 / (t * this.context.sampleRate);\n            const b1 = a0 - 1;\n            this._filter = this.context.createIIRFilter([a0, 0], [1, b1]);\n        }\n        else {\n            const b1 = 1 / (t * this.context.sampleRate) - 1;\n            this._filter = this.context.createIIRFilter([1, -1], [1, b1]);\n        }\n        this.input.chain(this._filter, this.output);\n        if (oldFilter) {\n            // dispose it on the next block\n            this.context.setTimeout(() => {\n                if (!this.disposed) {\n                    this.input.disconnect(oldFilter);\n                    oldFilter.disconnect();\n                }\n            }, this.blockTime);\n        }\n    }\n    /**\n     * The frequency value.\n     */\n    get frequency() {\n        return this._frequency;\n    }\n    set frequency(fq) {\n        this._frequency = fq;\n        this._createFilter();\n    }\n    /**\n     * The OnePole Filter type, either \"highpass\" or \"lowpass\"\n     */\n    get type() {\n        return this._type;\n    }\n    set type(t) {\n        this._type = t;\n        this._createFilter();\n    }\n    /**\n     * Get the frequency response curve. This curve represents how the filter\n     * responses to frequencies between 20hz-20khz.\n     * @param  len The number of values to return\n     * @return The frequency response curve between 20-20kHz\n     */\n    getFrequencyResponse(len = 128) {\n        const freqValues = new Float32Array(len);\n        for (let i = 0; i < len; i++) {\n            const norm = Math.pow(i / len, 2);\n            const freq = norm * (20000 - 20) + 20;\n            freqValues[i] = freq;\n        }\n        const magValues = new Float32Array(len);\n        const phaseValues = new Float32Array(len);\n        this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);\n        return magValues;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this._filter.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=OnePoleFilter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/OnePoleFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PhaseShiftAllpass\": () => (/* binding */ PhaseShiftAllpass)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n/**\n * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform\n * using two Allpass filter banks whose outputs have a phase difference of 90.\n * Here the `offset90` phase is offset by +90 in relation to `output`.\n * Coefficients and structure was developed by Olli Niemitalo.\n * For more details see: http://yehar.com/blog/?p=368\n * @category Component\n */\nclass PhaseShiftAllpass extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"PhaseShiftAllpass\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * The phase shifted output\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * The PhaseShifted allpass output\n         */\n        this.offset90 = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        const allpassBank1Values = [0.6923878, 0.9360654322959, 0.9882295226860, 0.9987488452737];\n        const allpassBank2Values = [0.4021921162426, 0.8561710882420, 0.9722909545651, 0.9952884791278];\n        this._bank0 = this._createAllPassFilterBank(allpassBank1Values);\n        this._bank1 = this._createAllPassFilterBank(allpassBank2Values);\n        this._oneSampleDelay = this.context.createIIRFilter([0.0, 1.0], [1.0, 0.0]);\n        // connect Allpass filter banks\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connectSeries)(this.input, ...this._bank0, this._oneSampleDelay, this.output);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connectSeries)(this.input, ...this._bank1, this.offset90);\n    }\n    /**\n     * Create all of the IIR filters from an array of values using the coefficient calculation.\n     */\n    _createAllPassFilterBank(bankValues) {\n        const nodes = bankValues.map(value => {\n            const coefficients = [[value * value, 0, -1], [1, 0, -(value * value)]];\n            return this.context.createIIRFilter(coefficients[0], coefficients[1]);\n        });\n        return nodes;\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.offset90.dispose();\n        this._bank0.forEach(f => f.disconnect());\n        this._bank1.forEach(f => f.disconnect());\n        this._oneSampleDelay.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=PhaseShiftAllpass.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/component/index.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/component/index.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* reexport safe */ _envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_25__.AmplitudeEnvelope),\n/* harmony export */   \"Analyser\": () => (/* reexport safe */ _analysis_Analyser__WEBPACK_IMPORTED_MODULE_0__.Analyser),\n/* harmony export */   \"BiquadFilter\": () => (/* reexport safe */ _filter_BiquadFilter__WEBPACK_IMPORTED_MODULE_34__.BiquadFilter),\n/* harmony export */   \"Channel\": () => (/* reexport safe */ _channel_Channel__WEBPACK_IMPORTED_MODULE_6__.Channel),\n/* harmony export */   \"Compressor\": () => (/* reexport safe */ _dynamics_Compressor__WEBPACK_IMPORTED_MODULE_20__.Compressor),\n/* harmony export */   \"Convolver\": () => (/* reexport safe */ _filter_Convolver__WEBPACK_IMPORTED_MODULE_33__.Convolver),\n/* harmony export */   \"CrossFade\": () => (/* reexport safe */ _channel_CrossFade__WEBPACK_IMPORTED_MODULE_7__.CrossFade),\n/* harmony export */   \"DCMeter\": () => (/* reexport safe */ _analysis_DCMeter__WEBPACK_IMPORTED_MODULE_3__.DCMeter),\n/* harmony export */   \"EQ3\": () => (/* reexport safe */ _filter_EQ3__WEBPACK_IMPORTED_MODULE_28__.EQ3),\n/* harmony export */   \"Envelope\": () => (/* reexport safe */ _envelope_Envelope__WEBPACK_IMPORTED_MODULE_26__.Envelope),\n/* harmony export */   \"FFT\": () => (/* reexport safe */ _analysis_FFT__WEBPACK_IMPORTED_MODULE_2__.FFT),\n/* harmony export */   \"FeedbackCombFilter\": () => (/* reexport safe */ _filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_31__.FeedbackCombFilter),\n/* harmony export */   \"Filter\": () => (/* reexport safe */ _filter_Filter__WEBPACK_IMPORTED_MODULE_29__.Filter),\n/* harmony export */   \"Follower\": () => (/* reexport safe */ _analysis_Follower__WEBPACK_IMPORTED_MODULE_5__.Follower),\n/* harmony export */   \"FrequencyEnvelope\": () => (/* reexport safe */ _envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_27__.FrequencyEnvelope),\n/* harmony export */   \"Gate\": () => (/* reexport safe */ _dynamics_Gate__WEBPACK_IMPORTED_MODULE_21__.Gate),\n/* harmony export */   \"Limiter\": () => (/* reexport safe */ _dynamics_Limiter__WEBPACK_IMPORTED_MODULE_22__.Limiter),\n/* harmony export */   \"LowpassCombFilter\": () => (/* reexport safe */ _filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_32__.LowpassCombFilter),\n/* harmony export */   \"Merge\": () => (/* reexport safe */ _channel_Merge__WEBPACK_IMPORTED_MODULE_8__.Merge),\n/* harmony export */   \"Meter\": () => (/* reexport safe */ _analysis_Meter__WEBPACK_IMPORTED_MODULE_1__.Meter),\n/* harmony export */   \"MidSideCompressor\": () => (/* reexport safe */ _dynamics_MidSideCompressor__WEBPACK_IMPORTED_MODULE_23__.MidSideCompressor),\n/* harmony export */   \"MidSideMerge\": () => (/* reexport safe */ _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_9__.MidSideMerge),\n/* harmony export */   \"MidSideSplit\": () => (/* reexport safe */ _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_10__.MidSideSplit),\n/* harmony export */   \"Mono\": () => (/* reexport safe */ _channel_Mono__WEBPACK_IMPORTED_MODULE_11__.Mono),\n/* harmony export */   \"MultibandCompressor\": () => (/* reexport safe */ _dynamics_MultibandCompressor__WEBPACK_IMPORTED_MODULE_24__.MultibandCompressor),\n/* harmony export */   \"MultibandSplit\": () => (/* reexport safe */ _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_12__.MultibandSplit),\n/* harmony export */   \"OnePoleFilter\": () => (/* reexport safe */ _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_30__.OnePoleFilter),\n/* harmony export */   \"PanVol\": () => (/* reexport safe */ _channel_PanVol__WEBPACK_IMPORTED_MODULE_15__.PanVol),\n/* harmony export */   \"Panner\": () => (/* reexport safe */ _channel_Panner__WEBPACK_IMPORTED_MODULE_13__.Panner),\n/* harmony export */   \"Panner3D\": () => (/* reexport safe */ _channel_Panner3D__WEBPACK_IMPORTED_MODULE_14__.Panner3D),\n/* harmony export */   \"Recorder\": () => (/* reexport safe */ _channel_Recorder__WEBPACK_IMPORTED_MODULE_16__.Recorder),\n/* harmony export */   \"Solo\": () => (/* reexport safe */ _channel_Solo__WEBPACK_IMPORTED_MODULE_17__.Solo),\n/* harmony export */   \"Split\": () => (/* reexport safe */ _channel_Split__WEBPACK_IMPORTED_MODULE_18__.Split),\n/* harmony export */   \"Volume\": () => (/* reexport safe */ _channel_Volume__WEBPACK_IMPORTED_MODULE_19__.Volume),\n/* harmony export */   \"Waveform\": () => (/* reexport safe */ _analysis_Waveform__WEBPACK_IMPORTED_MODULE_4__.Waveform)\n/* harmony export */ });\n/* harmony import */ var _analysis_Analyser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./analysis/Analyser */ \"./node_modules/tone/build/esm/component/analysis/Analyser.js\");\n/* harmony import */ var _analysis_Meter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./analysis/Meter */ \"./node_modules/tone/build/esm/component/analysis/Meter.js\");\n/* harmony import */ var _analysis_FFT__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./analysis/FFT */ \"./node_modules/tone/build/esm/component/analysis/FFT.js\");\n/* harmony import */ var _analysis_DCMeter__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./analysis/DCMeter */ \"./node_modules/tone/build/esm/component/analysis/DCMeter.js\");\n/* harmony import */ var _analysis_Waveform__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./analysis/Waveform */ \"./node_modules/tone/build/esm/component/analysis/Waveform.js\");\n/* harmony import */ var _analysis_Follower__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./analysis/Follower */ \"./node_modules/tone/build/esm/component/analysis/Follower.js\");\n/* harmony import */ var _channel_Channel__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./channel/Channel */ \"./node_modules/tone/build/esm/component/channel/Channel.js\");\n/* harmony import */ var _channel_CrossFade__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _channel_Merge__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./channel/MidSideMerge */ \"./node_modules/tone/build/esm/component/channel/MidSideMerge.js\");\n/* harmony import */ var _channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./channel/MidSideSplit */ \"./node_modules/tone/build/esm/component/channel/MidSideSplit.js\");\n/* harmony import */ var _channel_Mono__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./channel/Mono */ \"./node_modules/tone/build/esm/component/channel/Mono.js\");\n/* harmony import */ var _channel_MultibandSplit__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./channel/MultibandSplit */ \"./node_modules/tone/build/esm/component/channel/MultibandSplit.js\");\n/* harmony import */ var _channel_Panner__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./channel/Panner */ \"./node_modules/tone/build/esm/component/channel/Panner.js\");\n/* harmony import */ var _channel_Panner3D__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./channel/Panner3D */ \"./node_modules/tone/build/esm/component/channel/Panner3D.js\");\n/* harmony import */ var _channel_PanVol__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./channel/PanVol */ \"./node_modules/tone/build/esm/component/channel/PanVol.js\");\n/* harmony import */ var _channel_Recorder__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./channel/Recorder */ \"./node_modules/tone/build/esm/component/channel/Recorder.js\");\n/* harmony import */ var _channel_Solo__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./channel/Solo */ \"./node_modules/tone/build/esm/component/channel/Solo.js\");\n/* harmony import */ var _channel_Split__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _channel_Volume__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _dynamics_Compressor__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./dynamics/Compressor */ \"./node_modules/tone/build/esm/component/dynamics/Compressor.js\");\n/* harmony import */ var _dynamics_Gate__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./dynamics/Gate */ \"./node_modules/tone/build/esm/component/dynamics/Gate.js\");\n/* harmony import */ var _dynamics_Limiter__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./dynamics/Limiter */ \"./node_modules/tone/build/esm/component/dynamics/Limiter.js\");\n/* harmony import */ var _dynamics_MidSideCompressor__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./dynamics/MidSideCompressor */ \"./node_modules/tone/build/esm/component/dynamics/MidSideCompressor.js\");\n/* harmony import */ var _dynamics_MultibandCompressor__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./dynamics/MultibandCompressor */ \"./node_modules/tone/build/esm/component/dynamics/MultibandCompressor.js\");\n/* harmony import */ var _envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _envelope_Envelope__WEBPACK_IMPORTED_MODULE_26__ = __webpack_require__(/*! ./envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_27__ = __webpack_require__(/*! ./envelope/FrequencyEnvelope */ \"./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js\");\n/* harmony import */ var _filter_EQ3__WEBPACK_IMPORTED_MODULE_28__ = __webpack_require__(/*! ./filter/EQ3 */ \"./node_modules/tone/build/esm/component/filter/EQ3.js\");\n/* harmony import */ var _filter_Filter__WEBPACK_IMPORTED_MODULE_29__ = __webpack_require__(/*! ./filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _filter_OnePoleFilter__WEBPACK_IMPORTED_MODULE_30__ = __webpack_require__(/*! ./filter/OnePoleFilter */ \"./node_modules/tone/build/esm/component/filter/OnePoleFilter.js\");\n/* harmony import */ var _filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_31__ = __webpack_require__(/*! ./filter/FeedbackCombFilter */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js\");\n/* harmony import */ var _filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_32__ = __webpack_require__(/*! ./filter/LowpassCombFilter */ \"./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js\");\n/* harmony import */ var _filter_Convolver__WEBPACK_IMPORTED_MODULE_33__ = __webpack_require__(/*! ./filter/Convolver */ \"./node_modules/tone/build/esm/component/filter/Convolver.js\");\n/* harmony import */ var _filter_BiquadFilter__WEBPACK_IMPORTED_MODULE_34__ = __webpack_require__(/*! ./filter/BiquadFilter */ \"./node_modules/tone/build/esm/component/filter/BiquadFilter.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/component/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/Global.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/build/esm/core/Global.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getContext\": () => (/* binding */ getContext),\n/* harmony export */   \"setContext\": () => (/* binding */ setContext),\n/* harmony export */   \"start\": () => (/* binding */ start)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../version */ \"./node_modules/tone/build/esm/version.js\");\n/* harmony import */ var _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _context_Context__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./context/Context */ \"./node_modules/tone/build/esm/core/context/Context.js\");\n/* harmony import */ var _context_DummyContext__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./context/DummyContext */ \"./node_modules/tone/build/esm/core/context/DummyContext.js\");\n/* harmony import */ var _context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n\n\n\n\n\n\n/**\n * This dummy context is used to avoid throwing immediate errors when importing in Node.js\n */\nconst dummyContext = new _context_DummyContext__WEBPACK_IMPORTED_MODULE_3__.DummyContext();\n/**\n * The global audio context which is getable and assignable through\n * getContext and setContext\n */\nlet globalContext = dummyContext;\n/**\n * Returns the default system-wide [[Context]]\n * @category Core\n */\nfunction getContext() {\n    if (globalContext === dummyContext && _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.hasAudioContext) {\n        setContext(new _context_Context__WEBPACK_IMPORTED_MODULE_2__.Context());\n    }\n    return globalContext;\n}\n/**\n * Set the default audio context\n * @category Core\n */\nfunction setContext(context) {\n    if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_5__.isAudioContext)(context)) {\n        globalContext = new _context_Context__WEBPACK_IMPORTED_MODULE_2__.Context(context);\n    }\n    else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_5__.isOfflineAudioContext)(context)) {\n        globalContext = new _context_OfflineContext__WEBPACK_IMPORTED_MODULE_4__.OfflineContext(context);\n    }\n    else {\n        globalContext = context;\n    }\n}\n/**\n * Most browsers will not play _any_ audio until a user\n * clicks something (like a play button). Invoke this method\n * on a click or keypress event handler to start the audio context.\n * More about the Autoplay policy\n * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)\n * @example\n * document.querySelector(\"button\").addEventListener(\"click\", async () => {\n * \tawait Tone.start();\n * \tconsole.log(\"context started\");\n * });\n * @category Core\n */\nfunction start() {\n    return globalContext.resume();\n}\n/**\n * Log Tone.js + version in the console.\n */\nif (_context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow && !_context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow.TONE_SILENCE_LOGGING) {\n    let prefix = \"v\";\n    if (_version__WEBPACK_IMPORTED_MODULE_0__.version === \"dev\") {\n        prefix = \"\";\n    }\n    const printString = ` * Tone.js ${prefix}${_version__WEBPACK_IMPORTED_MODULE_0__.version} * `;\n    // eslint-disable-next-line no-console\n    console.log(`%c${printString}`, \"background: #000; color: #fff\");\n}\n//# sourceMappingURL=Global.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/Global.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/Tone.js":
/*!**************************************************!*\
  !*** ./node_modules/tone/build/esm/core/Tone.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Tone\": () => (/* binding */ Tone)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../version */ \"./node_modules/tone/build/esm/version.js\");\n/* harmony import */ var _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/**\n * Tone.js\n * @author Yotam Mann\n * @license http://opensource.org/licenses/MIT MIT License\n * @copyright 2014-2019 Yotam Mann\n */\n\n\n\n/**\n * @class  Tone is the base class of all other classes.\n * @category Core\n * @constructor\n */\nclass Tone {\n    constructor() {\n        //-------------------------------------\n        // \tDEBUGGING\n        //-------------------------------------\n        /**\n         * Set this debug flag to log all events that happen in this class.\n         */\n        this.debug = false;\n        //-------------------------------------\n        // \tDISPOSING\n        //-------------------------------------\n        /**\n         * Indicates if the instance was disposed\n         */\n        this._wasDisposed = false;\n    }\n    /**\n     * Returns all of the default options belonging to the class.\n     */\n    static getDefaults() {\n        return {};\n    }\n    /**\n     * Prints the outputs to the console log for debugging purposes.\n     * Prints the contents only if either the object has a property\n     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS\n     * is set to the name of the class.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * // prints all logs originating from this oscillator\n     * osc.debug = true;\n     * // calls to start/stop will print in the console\n     * osc.start();\n     */\n    log(...args) {\n        // if the object is either set to debug = true\n        // or if there is a string on the Tone.global.with the class name\n        if (this.debug || (_context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow && this.toString() === _context_AudioContext__WEBPACK_IMPORTED_MODULE_1__.theWindow.TONE_DEBUG_CLASS)) {\n            (0,_util_Debug__WEBPACK_IMPORTED_MODULE_2__.log)(this, ...args);\n        }\n    }\n    /**\n     * disconnect and dispose.\n     */\n    dispose() {\n        this._wasDisposed = true;\n        return this;\n    }\n    /**\n     * Indicates if the instance was disposed. 'Disposing' an\n     * instance means that all of the Web Audio nodes that were\n     * created for the instance are disconnected and freed for garbage collection.\n     */\n    get disposed() {\n        return this._wasDisposed;\n    }\n    /**\n     * Convert the class to a string\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.toString());\n     */\n    toString() {\n        return this.name;\n    }\n}\n/**\n * The version number semver\n */\nTone.version = _version__WEBPACK_IMPORTED_MODULE_0__.version;\n//# sourceMappingURL=Tone.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/Tone.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/Clock.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/Clock.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Clock\": () => (/* binding */ Clock)\n/* harmony export */ });\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_StateTimeline__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _TickSource__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./TickSource */ \"./node_modules/tone/build/esm/core/clock/TickSource.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n/**\n * A sample accurate clock which provides a callback at the given rate.\n * While the callback is not sample-accurate (it is still susceptible to\n * loose JS timing), the time passed in as the argument to the callback\n * is precise. For most applications, it is better to use Tone.Transport\n * instead of the Clock by itself since you can synchronize multiple callbacks.\n * @example\n * // the callback will be invoked approximately once a second\n * // and will print the time exactly once a second apart.\n * const clock = new Tone.Clock(time => {\n * \tconsole.log(time);\n * }, 1);\n * clock.start();\n * @category Core\n */\nclass Clock extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Clock.getDefaults(), arguments, [\"callback\", \"frequency\"]));\n        this.name = \"Clock\";\n        /**\n         * The callback function to invoke at the scheduled tick.\n         */\n        this.callback = _util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp;\n        /**\n         * The last time the loop callback was invoked\n         */\n        this._lastUpdate = 0;\n        /**\n         * Keep track of the playback state\n         */\n        this._state = new _util_StateTimeline__WEBPACK_IMPORTED_MODULE_4__.StateTimeline(\"stopped\");\n        /**\n         * Context bound reference to the _loop method\n         * This is necessary to remove the event in the end.\n         */\n        this._boundLoop = this._loop.bind(this);\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Clock.getDefaults(), arguments, [\"callback\", \"frequency\"]);\n        this.callback = options.callback;\n        this._tickSource = new _TickSource__WEBPACK_IMPORTED_MODULE_5__.TickSource({\n            context: this.context,\n            frequency: options.frequency,\n            units: options.units,\n        });\n        this._lastUpdate = 0;\n        this.frequency = this._tickSource.frequency;\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"frequency\");\n        // add an initial state\n        this._state.setStateAtTime(\"stopped\", 0);\n        // bind a callback to the worker thread\n        this.context.on(\"tick\", this._boundLoop);\n    }\n    static getDefaults() {\n        return Object.assign(_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext.getDefaults(), {\n            callback: _util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp,\n            frequency: 1,\n            units: \"hertz\",\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state() {\n        return this._state.getValueAtTime(this.now());\n    }\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset  Where the tick counter starts counting from.\n     */\n    start(time, offset) {\n        // make sure the context is running\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertContextRunning)(this.context);\n        // start the loop\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        if (this._state.getValueAtTime(computedTime) !== \"started\") {\n            this._state.setStateAtTime(\"started\", computedTime);\n            this._tickSource.start(computedTime, offset);\n            if (computedTime < this._lastUpdate) {\n                this.emit(\"start\", computedTime, offset);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     * @example\n     * const clock = new Tone.Clock(time => {\n     * \tconsole.log(time);\n     * }, 1);\n     * clock.start();\n     * // stop the clock after 10 seconds\n     * clock.stop(\"+10\");\n     */\n    stop(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"stop\", computedTime);\n        this._state.cancel(computedTime);\n        this._state.setStateAtTime(\"stopped\", computedTime);\n        this._tickSource.stop(computedTime);\n        if (computedTime < this._lastUpdate) {\n            this.emit(\"stop\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            this._state.setStateAtTime(\"paused\", computedTime);\n            this._tickSource.pause(computedTime);\n            if (computedTime < this._lastUpdate) {\n                this.emit(\"pause\", computedTime);\n            }\n        }\n        return this;\n    }\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked.\n     */\n    get ticks() {\n        return Math.ceil(this.getTicksAtTime(this.now()));\n    }\n    set ticks(t) {\n        this._tickSource.ticks = t;\n    }\n    /**\n     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves\n     */\n    get seconds() {\n        return this._tickSource.seconds;\n    }\n    set seconds(s) {\n        this._tickSource.seconds = s;\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        return this._tickSource.getSecondsAtTime(time);\n    }\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks, time) {\n        this._tickSource.setTicksAtTime(ticks, time);\n        return this;\n    }\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick, before = this.now()) {\n        return this._tickSource.getTimeOfTick(tick, before);\n    }\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time) {\n        return this._tickSource.getTicksAtTime(time);\n    }\n    /**\n     * Get the time of the next tick\n     * @param  offset The tick number.\n     */\n    nextTickTime(offset, when) {\n        const computedTime = this.toSeconds(when);\n        const currentTick = this.getTicksAtTime(computedTime);\n        return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);\n    }\n    /**\n     * The scheduling loop.\n     */\n    _loop() {\n        const startTime = this._lastUpdate;\n        const endTime = this.now();\n        this._lastUpdate = endTime;\n        this.log(\"loop\", startTime, endTime);\n        if (startTime !== endTime) {\n            // the state change events\n            this._state.forEachBetween(startTime, endTime, e => {\n                switch (e.state) {\n                    case \"started\":\n                        const offset = this._tickSource.getTicksAtTime(e.time);\n                        this.emit(\"start\", e.time, offset);\n                        break;\n                    case \"stopped\":\n                        if (e.time !== 0) {\n                            this.emit(\"stop\", e.time);\n                        }\n                        break;\n                    case \"paused\":\n                        this.emit(\"pause\", e.time);\n                        break;\n                }\n            });\n            // the tick callbacks\n            this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks) => {\n                this.callback(time, ticks);\n            });\n        }\n    }\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     * @example\n     * const clock = new Tone.Clock();\n     * clock.start(\"+0.1\");\n     * clock.getStateAtTime(\"+0.1\"); // returns \"started\"\n     */\n    getStateAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        return this._state.getValueAtTime(computedTime);\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.context.off(\"tick\", this._boundLoop);\n        this._tickSource.dispose();\n        this._state.dispose();\n        return this;\n    }\n}\n_util_Emitter__WEBPACK_IMPORTED_MODULE_2__.Emitter.mixin(Clock);\n//# sourceMappingURL=Clock.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/Clock.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TickParam.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TickParam.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TickParam\": () => (/* binding */ TickParam)\n/* harmony export */ });\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n/**\n * A Param class just for computing ticks. Similar to the [[Param]] class,\n * but offers conversion to BPM values as well as ability to compute tick\n * duration and elapsed ticks\n */\nclass TickParam extends _context_Param__WEBPACK_IMPORTED_MODULE_0__.Param {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickParam.getDefaults(), arguments, [\"value\"]));\n        this.name = \"TickParam\";\n        /**\n         * The timeline which tracks all of the automations.\n         */\n        this._events = new _util_Timeline__WEBPACK_IMPORTED_MODULE_2__.Timeline(Infinity);\n        /**\n         * The internal holder for the multiplier value\n         */\n        this._multiplier = 1;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickParam.getDefaults(), arguments, [\"value\"]);\n        // set the multiplier\n        this._multiplier = options.multiplier;\n        // clear the ticks from the beginning\n        this._events.cancel(0);\n        // set an initial event\n        this._events.add({\n            ticks: 0,\n            time: 0,\n            type: \"setValueAtTime\",\n            value: this._fromType(options.value),\n        });\n        this.setValueAtTime(options.value, 0);\n    }\n    static getDefaults() {\n        return Object.assign(_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param.getDefaults(), {\n            multiplier: 1,\n            units: \"hertz\",\n            value: 1,\n        });\n    }\n    setTargetAtTime(value, time, constant) {\n        // approximate it with multiple linear ramps\n        time = this.toSeconds(time);\n        this.setRampPoint(time);\n        const computedValue = this._fromType(value);\n        // start from previously scheduled value\n        const prevEvent = this._events.get(time);\n        const segments = Math.round(Math.max(1 / constant, 1));\n        for (let i = 0; i <= segments; i++) {\n            const segTime = constant * i + time;\n            const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);\n            this.linearRampToValueAtTime(this._toType(rampVal), segTime);\n        }\n        return this;\n    }\n    setValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        super.setValueAtTime(value, time);\n        const event = this._events.get(computedTime);\n        const previousEvent = this._events.previousEvent(event);\n        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);\n        event.ticks = Math.max(ticksUntilTime, 0);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        super.linearRampToValueAtTime(value, time);\n        const event = this._events.get(computedTime);\n        const previousEvent = this._events.previousEvent(event);\n        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);\n        event.ticks = Math.max(ticksUntilTime, 0);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        // aproximate it with multiple linear ramps\n        time = this.toSeconds(time);\n        const computedVal = this._fromType(value);\n        // start from previously scheduled value\n        const prevEvent = this._events.get(time);\n        // approx 10 segments per second\n        const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));\n        const segmentDur = ((time - prevEvent.time) / segments);\n        for (let i = 0; i <= segments; i++) {\n            const segTime = segmentDur * i + prevEvent.time;\n            const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);\n            this.linearRampToValueAtTime(this._toType(rampVal), segTime);\n        }\n        return this;\n    }\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  event The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    _getTicksUntilEvent(event, time) {\n        if (event === null) {\n            event = {\n                ticks: 0,\n                time: 0,\n                type: \"setValueAtTime\",\n                value: 0,\n            };\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__.isUndef)(event.ticks)) {\n            const previousEvent = this._events.previousEvent(event);\n            event.ticks = this._getTicksUntilEvent(previousEvent, event.time);\n        }\n        const val0 = this._fromType(this.getValueAtTime(event.time));\n        let val1 = this._fromType(this.getValueAtTime(time));\n        // if it's right on the line, take the previous value\n        const onTheLineEvent = this._events.get(time);\n        if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === \"setValueAtTime\") {\n            val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));\n        }\n        return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;\n    }\n    /**\n     * Returns the tick value at the time. Takes into account\n     * any automation curves scheduled on the signal.\n     * @param  time The time to get the tick count at\n     * @return The number of ticks which have elapsed at the time given any automations.\n     */\n    getTicksAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const event = this._events.get(computedTime);\n        return Math.max(this._getTicksUntilEvent(event, computedTime), 0);\n    }\n    /**\n     * Return the elapsed time of the number of ticks from the given time\n     * @param ticks The number of ticks to calculate\n     * @param  time The time to get the next tick from\n     * @return The duration of the number of ticks from the given time in seconds\n     */\n    getDurationOfTicks(ticks, time) {\n        const computedTime = this.toSeconds(time);\n        const currentTick = this.getTicksAtTime(time);\n        return this.getTimeOfTick(currentTick + ticks) - computedTime;\n    }\n    /**\n     * Given a tick, returns the time that tick occurs at.\n     * @return The time that the tick occurs.\n     */\n    getTimeOfTick(tick) {\n        const before = this._events.get(tick, \"ticks\");\n        const after = this._events.getAfter(tick, \"ticks\");\n        if (before && before.ticks === tick) {\n            return before.time;\n        }\n        else if (before && after &&\n            after.type === \"linearRampToValueAtTime\" &&\n            before.value !== after.value) {\n            const val0 = this._fromType(this.getValueAtTime(before.time));\n            const val1 = this._fromType(this.getValueAtTime(after.time));\n            const delta = (val1 - val0) / (after.time - before.time);\n            const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));\n            const sol1 = (-val0 + k) / delta;\n            const sol2 = (-val0 - k) / delta;\n            return (sol1 > 0 ? sol1 : sol2) + before.time;\n        }\n        else if (before) {\n            if (before.value === 0) {\n                return Infinity;\n            }\n            else {\n                return before.time + (tick - before.ticks) / before.value;\n            }\n        }\n        else {\n            return tick / this._initialValue;\n        }\n    }\n    /**\n     * Convert some number of ticks their the duration in seconds accounting\n     * for any automation curves starting at the given time.\n     * @param  ticks The number of ticks to convert to seconds.\n     * @param  when  When along the automation timeline to convert the ticks.\n     * @return The duration in seconds of the ticks.\n     */\n    ticksToTime(ticks, when) {\n        return this.getDurationOfTicks(ticks, when);\n    }\n    /**\n     * The inverse of [[ticksToTime]]. Convert a duration in\n     * seconds to the corresponding number of ticks accounting for any\n     * automation curves starting at the given time.\n     * @param  duration The time interval to convert to ticks.\n     * @param  when When along the automation timeline to convert the ticks.\n     * @return The duration in ticks.\n     */\n    timeToTicks(duration, when) {\n        const computedTime = this.toSeconds(when);\n        const computedDuration = this.toSeconds(duration);\n        const startTicks = this.getTicksAtTime(computedTime);\n        const endTicks = this.getTicksAtTime(computedTime + computedDuration);\n        return endTicks - startTicks;\n    }\n    /**\n     * Convert from the type when the unit value is BPM\n     */\n    _fromType(val) {\n        if (this.units === \"bpm\" && this.multiplier) {\n            return 1 / (60 / val / this.multiplier);\n        }\n        else {\n            return super._fromType(val);\n        }\n    }\n    /**\n     * Special case of type conversion where the units === \"bpm\"\n     */\n    _toType(val) {\n        if (this.units === \"bpm\" && this.multiplier) {\n            return (val / this.multiplier) * 60;\n        }\n        else {\n            return super._toType(val);\n        }\n    }\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier() {\n        return this._multiplier;\n    }\n    set multiplier(m) {\n        // get and reset the current value with the new multiplier\n        // might be necessary to clear all the previous values\n        const currentVal = this.value;\n        this._multiplier = m;\n        this.cancelScheduledValues(0);\n        this.setValueAtTime(currentVal, 0);\n    }\n}\n//# sourceMappingURL=TickParam.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/TickParam.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TickSignal.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TickSignal.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TickSignal\": () => (/* binding */ TickSignal)\n/* harmony export */ });\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _TickParam__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TickParam */ \"./node_modules/tone/build/esm/core/clock/TickParam.js\");\n\n\n\n/**\n * TickSignal extends Tone.Signal, but adds the capability\n * to calculate the number of elapsed ticks. exponential and target curves\n * are approximated with multiple linear ramps.\n *\n * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,\n * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)\n * describing integrating timing functions for tempo calculations.\n */\nclass TickSignal extends _signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSignal.getDefaults(), arguments, [\"value\"]));\n        this.name = \"TickSignal\";\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSignal.getDefaults(), arguments, [\"value\"]);\n        this.input = this._param = new _TickParam__WEBPACK_IMPORTED_MODULE_2__.TickParam({\n            context: this.context,\n            convert: options.convert,\n            multiplier: options.multiplier,\n            param: this._constantSource.offset,\n            units: options.units,\n            value: options.value,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal.getDefaults(), {\n            multiplier: 1,\n            units: \"hertz\",\n            value: 1,\n        });\n    }\n    ticksToTime(ticks, when) {\n        return this._param.ticksToTime(ticks, when);\n    }\n    timeToTicks(duration, when) {\n        return this._param.timeToTicks(duration, when);\n    }\n    getTimeOfTick(tick) {\n        return this._param.getTimeOfTick(tick);\n    }\n    getDurationOfTicks(ticks, time) {\n        return this._param.getDurationOfTicks(ticks, time);\n    }\n    getTicksAtTime(time) {\n        return this._param.getTicksAtTime(time);\n    }\n    /**\n     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.\n     */\n    get multiplier() {\n        return this._param.multiplier;\n    }\n    set multiplier(m) {\n        this._param.multiplier = m;\n    }\n    dispose() {\n        super.dispose();\n        this._param.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=TickSignal.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/TickSignal.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TickSource.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TickSource.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TickSource\": () => (/* binding */ TickSource)\n/* harmony export */ });\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _TickSignal__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./TickSignal */ \"./node_modules/tone/build/esm/core/clock/TickSignal.js\");\n/* harmony import */ var _util_Math__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n/**\n * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.\n */\nclass TickSource extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSource.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"TickSource\";\n        /**\n         * The state timeline\n         */\n        this._state = new _util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__.StateTimeline();\n        /**\n         * The offset values of the ticks\n         */\n        this._tickOffset = new _util_Timeline__WEBPACK_IMPORTED_MODULE_4__.Timeline();\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(TickSource.getDefaults(), arguments, [\"frequency\"]);\n        this.frequency = new _TickSignal__WEBPACK_IMPORTED_MODULE_6__.TickSignal({\n            context: this.context,\n            units: options.units,\n            value: options.frequency,\n        });\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"frequency\");\n        // set the initial state\n        this._state.setStateAtTime(\"stopped\", 0);\n        // add the first event\n        this.setTicksAtTime(0, 0);\n    }\n    static getDefaults() {\n        return Object.assign({\n            frequency: 1,\n            units: \"hertz\",\n        }, _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext.getDefaults());\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\" or \"paused\".\n     */\n    get state() {\n        return this.getStateAtTime(this.now());\n    }\n    /**\n     * Start the clock at the given time. Optionally pass in an offset\n     * of where to start the tick counter from.\n     * @param  time    The time the clock should start\n     * @param offset The number of ticks to start the source at\n     */\n    start(time, offset) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) !== \"started\") {\n            this._state.setStateAtTime(\"started\", computedTime);\n            if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(offset)) {\n                this.setTicksAtTime(offset, computedTime);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the clock. Stopping the clock resets the tick counter to 0.\n     * @param time The time when the clock should stop.\n     */\n    stop(time) {\n        const computedTime = this.toSeconds(time);\n        // cancel the previous stop\n        if (this._state.getValueAtTime(computedTime) === \"stopped\") {\n            const event = this._state.get(computedTime);\n            if (event && event.time > 0) {\n                this._tickOffset.cancel(event.time);\n                this._state.cancel(event.time);\n            }\n        }\n        this._state.cancel(computedTime);\n        this._state.setStateAtTime(\"stopped\", computedTime);\n        this.setTicksAtTime(0, computedTime);\n        return this;\n    }\n    /**\n     * Pause the clock. Pausing does not reset the tick counter.\n     * @param time The time when the clock should stop.\n     */\n    pause(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            this._state.setStateAtTime(\"paused\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.\n     * @param time When to clear the events after\n     */\n    cancel(time) {\n        time = this.toSeconds(time);\n        this._state.cancel(time);\n        this._tickOffset.cancel(time);\n        return this;\n    }\n    /**\n     * Get the elapsed ticks at the given time\n     * @param  time  When to get the tick value\n     * @return The number of ticks\n     */\n    getTicksAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const stopEvent = this._state.getLastState(\"stopped\", computedTime);\n        // this event allows forEachBetween to iterate until the current time\n        const tmpEvent = { state: \"paused\", time: computedTime };\n        this._state.add(tmpEvent);\n        // keep track of the previous offset event\n        let lastState = stopEvent;\n        let elapsedTicks = 0;\n        // iterate through all the events since the last stop\n        this._state.forEachBetween(stopEvent.time, computedTime + this.sampleTime, e => {\n            let periodStartTime = lastState.time;\n            // if there is an offset event in this period use that\n            const offsetEvent = this._tickOffset.get(e.time);\n            if (offsetEvent && offsetEvent.time >= lastState.time) {\n                elapsedTicks = offsetEvent.ticks;\n                periodStartTime = offsetEvent.time;\n            }\n            if (lastState.state === \"started\" && e.state !== \"started\") {\n                elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);\n            }\n            lastState = e;\n        });\n        // remove the temporary event\n        this._state.remove(tmpEvent);\n        // return the ticks\n        return elapsedTicks;\n    }\n    /**\n     * The number of times the callback was invoked. Starts counting at 0\n     * and increments after the callback was invoked. Returns -1 when stopped.\n     */\n    get ticks() {\n        return this.getTicksAtTime(this.now());\n    }\n    set ticks(t) {\n        this.setTicksAtTime(t, this.now());\n    }\n    /**\n     * The time since ticks=0 that the TickSource has been running. Accounts\n     * for tempo curves\n     */\n    get seconds() {\n        return this.getSecondsAtTime(this.now());\n    }\n    set seconds(s) {\n        const now = this.now();\n        const ticks = this.frequency.timeToTicks(s, now);\n        this.setTicksAtTime(ticks, now);\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        time = this.toSeconds(time);\n        const stopEvent = this._state.getLastState(\"stopped\", time);\n        // this event allows forEachBetween to iterate until the current time\n        const tmpEvent = { state: \"paused\", time };\n        this._state.add(tmpEvent);\n        // keep track of the previous offset event\n        let lastState = stopEvent;\n        let elapsedSeconds = 0;\n        // iterate through all the events since the last stop\n        this._state.forEachBetween(stopEvent.time, time + this.sampleTime, e => {\n            let periodStartTime = lastState.time;\n            // if there is an offset event in this period use that\n            const offsetEvent = this._tickOffset.get(e.time);\n            if (offsetEvent && offsetEvent.time >= lastState.time) {\n                elapsedSeconds = offsetEvent.seconds;\n                periodStartTime = offsetEvent.time;\n            }\n            if (lastState.state === \"started\" && e.state !== \"started\") {\n                elapsedSeconds += e.time - periodStartTime;\n            }\n            lastState = e;\n        });\n        // remove the temporary event\n        this._state.remove(tmpEvent);\n        // return the ticks\n        return elapsedSeconds;\n    }\n    /**\n     * Set the clock's ticks at the given time.\n     * @param  ticks The tick value to set\n     * @param  time  When to set the tick value\n     */\n    setTicksAtTime(ticks, time) {\n        time = this.toSeconds(time);\n        this._tickOffset.cancel(time);\n        this._tickOffset.add({\n            seconds: this.frequency.getDurationOfTicks(ticks, time),\n            ticks,\n            time,\n        });\n        return this;\n    }\n    /**\n     * Returns the scheduled state at the given time.\n     * @param  time  The time to query.\n     */\n    getStateAtTime(time) {\n        time = this.toSeconds(time);\n        return this._state.getValueAtTime(time);\n    }\n    /**\n     * Get the time of the given tick. The second argument\n     * is when to test before. Since ticks can be set (with setTicksAtTime)\n     * there may be multiple times for a given tick value.\n     * @param  tick The tick number.\n     * @param  before When to measure the tick value from.\n     * @return The time of the tick\n     */\n    getTimeOfTick(tick, before = this.now()) {\n        const offset = this._tickOffset.get(before);\n        const event = this._state.get(before);\n        const startTime = Math.max(offset.time, event.time);\n        const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;\n        return this.frequency.getTimeOfTick(absoluteTicks);\n    }\n    /**\n     * Invoke the callback event at all scheduled ticks between the\n     * start time and the end time\n     * @param  startTime  The beginning of the search range\n     * @param  endTime    The end of the search range\n     * @param  callback   The callback to invoke with each tick\n     */\n    forEachTickBetween(startTime, endTime, callback) {\n        // only iterate through the sections where it is \"started\"\n        let lastStateEvent = this._state.get(startTime);\n        this._state.forEachBetween(startTime, endTime, event => {\n            if (lastStateEvent && lastStateEvent.state === \"started\" && event.state !== \"started\") {\n                this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);\n            }\n            lastStateEvent = event;\n        });\n        let error = null;\n        if (lastStateEvent && lastStateEvent.state === \"started\") {\n            const maxStartTime = Math.max(lastStateEvent.time, startTime);\n            // figure out the difference between the frequency ticks and the\n            const startTicks = this.frequency.getTicksAtTime(maxStartTime);\n            const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);\n            const diff = startTicks - ticksAtStart;\n            let offset = Math.ceil(diff) - diff;\n            // guard against floating point issues\n            offset = (0,_util_Math__WEBPACK_IMPORTED_MODULE_7__.EQ)(offset, 1) ? 0 : offset;\n            let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);\n            while (nextTickTime < endTime) {\n                try {\n                    callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));\n                }\n                catch (e) {\n                    error = e;\n                    break;\n                }\n                nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);\n            }\n        }\n        if (error) {\n            throw error;\n        }\n        return this;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._state.dispose();\n        this._tickOffset.dispose();\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=TickSource.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/TickSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/Ticker.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/Ticker.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Ticker\": () => (/* binding */ Ticker)\n/* harmony export */ });\n/**\n * A class which provides a reliable callback using either\n * a Web Worker, or if that isn't supported, falls back to setTimeout.\n */\nclass Ticker {\n    constructor(callback, type, updateInterval) {\n        this._callback = callback;\n        this._type = type;\n        this._updateInterval = updateInterval;\n        // create the clock source for the first time\n        this._createClock();\n    }\n    /**\n     * Generate a web worker\n     */\n    _createWorker() {\n        const blob = new Blob([\n            /* javascript */ `\n\t\t\t// the initial timeout time\n\t\t\tlet timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};\n\t\t\t// onmessage callback\n\t\t\tself.onmessage = function(msg){\n\t\t\t\ttimeoutTime = parseInt(msg.data);\n\t\t\t};\n\t\t\t// the tick function which posts a message\n\t\t\t// and schedules a new tick\n\t\t\tfunction tick(){\n\t\t\t\tsetTimeout(tick, timeoutTime);\n\t\t\t\tself.postMessage('tick');\n\t\t\t}\n\t\t\t// call tick initially\n\t\t\ttick();\n\t\t\t`\n        ], { type: \"text/javascript\" });\n        const blobUrl = URL.createObjectURL(blob);\n        const worker = new Worker(blobUrl);\n        worker.onmessage = this._callback.bind(this);\n        this._worker = worker;\n    }\n    /**\n     * Create a timeout loop\n     */\n    _createTimeout() {\n        this._timeout = setTimeout(() => {\n            this._createTimeout();\n            this._callback();\n        }, this._updateInterval * 1000);\n    }\n    /**\n     * Create the clock source.\n     */\n    _createClock() {\n        if (this._type === \"worker\") {\n            try {\n                this._createWorker();\n            }\n            catch (e) {\n                // workers not supported, fallback to timeout\n                this._type = \"timeout\";\n                this._createClock();\n            }\n        }\n        else if (this._type === \"timeout\") {\n            this._createTimeout();\n        }\n    }\n    /**\n     * Clean up the current clock source\n     */\n    _disposeClock() {\n        if (this._timeout) {\n            clearTimeout(this._timeout);\n            this._timeout = 0;\n        }\n        if (this._worker) {\n            this._worker.terminate();\n            this._worker.onmessage = null;\n        }\n    }\n    /**\n     * The rate in seconds the ticker will update\n     */\n    get updateInterval() {\n        return this._updateInterval;\n    }\n    set updateInterval(interval) {\n        this._updateInterval = Math.max(interval, 128 / 44100);\n        if (this._type === \"worker\") {\n            this._worker.postMessage(Math.max(interval * 1000, 1));\n        }\n    }\n    /**\n     * The type of the ticker, either a worker or a timeout\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._disposeClock();\n        this._type = type;\n        this._createClock();\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        this._disposeClock();\n    }\n}\n//# sourceMappingURL=Ticker.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/Ticker.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/Transport.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/Transport.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Transport\": () => (/* binding */ Transport)\n/* harmony export */ });\n/* harmony import */ var _core_type_Time__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/type/Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n/* harmony import */ var _core_util_TimelineValue__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/TimelineValue */ \"./node_modules/tone/build/esm/core/util/TimelineValue.js\");\n/* harmony import */ var _context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../context/ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n/* harmony import */ var _context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _type_Ticks__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../util/IntervalTimeline */ \"./node_modules/tone/build/esm/core/util/IntervalTimeline.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Clock__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Clock */ \"./node_modules/tone/build/esm/core/clock/Clock.js\");\n/* harmony import */ var _TransportEvent__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./TransportEvent */ \"./node_modules/tone/build/esm/core/clock/TransportEvent.js\");\n/* harmony import */ var _TransportRepeatEvent__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./TransportRepeatEvent */ \"./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Transport for timing musical events.\n * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)\n * Transport timing events pass in the exact time of the scheduled event\n * in the argument of the callback function. Pass that time value to the object\n * you're scheduling. <br><br>\n * A single transport is created for you when the library is initialized.\n * <br><br>\n * The transport emits the events: \"start\", \"stop\", \"pause\", and \"loop\" which are\n * called with the time of that event as the argument.\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination();\n * // repeated event every 8th note\n * Tone.Transport.scheduleRepeat((time) => {\n * \t// use the callback time to schedule events\n * \tosc.start(time).stop(time + 0.1);\n * }, \"8n\");\n * // transport must be started before it starts invoking events\n * Tone.Transport.start();\n * @category Core\n */\nclass Transport extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_4__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(Transport.getDefaults(), arguments));\n        this.name = \"Transport\";\n        //-------------------------------------\n        // \tLOOPING\n        //-------------------------------------\n        /**\n         * If the transport loops or not.\n         */\n        this._loop = new _core_util_TimelineValue__WEBPACK_IMPORTED_MODULE_1__.TimelineValue(false);\n        /**\n         * The loop start position in ticks\n         */\n        this._loopStart = 0;\n        /**\n         * The loop end position in ticks\n         */\n        this._loopEnd = 0;\n        //-------------------------------------\n        // \tTIMELINE EVENTS\n        //-------------------------------------\n        /**\n         * All the events in an object to keep track by ID\n         */\n        this._scheduledEvents = {};\n        /**\n         * The scheduled events.\n         */\n        this._timeline = new _util_Timeline__WEBPACK_IMPORTED_MODULE_11__.Timeline();\n        /**\n         * Repeated events\n         */\n        this._repeatedEvents = new _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_10__.IntervalTimeline();\n        /**\n         * All of the synced Signals\n         */\n        this._syncedSignals = [];\n        /**\n         * The swing amount\n         */\n        this._swingAmount = 0;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(Transport.getDefaults(), arguments);\n        // CLOCK/TEMPO\n        this._ppq = options.ppq;\n        this._clock = new _Clock__WEBPACK_IMPORTED_MODULE_13__.Clock({\n            callback: this._processTick.bind(this),\n            context: this.context,\n            frequency: 0,\n            units: \"bpm\",\n        });\n        this._bindClockEvents();\n        this.bpm = this._clock.frequency;\n        this._clock.frequency.multiplier = options.ppq;\n        this.bpm.setValueAtTime(options.bpm, 0);\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_9__.readOnly)(this, \"bpm\");\n        this._timeSignature = options.timeSignature;\n        // SWING\n        this._swingTicks = options.ppq / 2; // 8n\n    }\n    static getDefaults() {\n        return Object.assign(_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_4__.ToneWithContext.getDefaults(), {\n            bpm: 120,\n            loopEnd: \"4m\",\n            loopStart: 0,\n            ppq: 192,\n            swing: 0,\n            swingSubdivision: \"8n\",\n            timeSignature: 4,\n        });\n    }\n    //-------------------------------------\n    // \tTICKS\n    //-------------------------------------\n    /**\n     * called on every tick\n     * @param  tickTime clock relative tick time\n     */\n    _processTick(tickTime, ticks) {\n        // do the loop test\n        if (this._loop.get(tickTime)) {\n            if (ticks >= this._loopEnd) {\n                this.emit(\"loopEnd\", tickTime);\n                this._clock.setTicksAtTime(this._loopStart, tickTime);\n                ticks = this._loopStart;\n                this.emit(\"loopStart\", tickTime, this._clock.getSecondsAtTime(tickTime));\n                this.emit(\"loop\", tickTime);\n            }\n        }\n        // handle swing\n        if (this._swingAmount > 0 &&\n            ticks % this._ppq !== 0 && // not on a downbeat\n            ticks % (this._swingTicks * 2) !== 0) {\n            // add some swing\n            const progress = (ticks % (this._swingTicks * 2)) / (this._swingTicks * 2);\n            const amount = Math.sin((progress) * Math.PI) * this._swingAmount;\n            tickTime += new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;\n        }\n        // invoke the timeline events scheduled on this tick\n        this._timeline.forEachAtTime(ticks, event => event.invoke(tickTime));\n    }\n    //-------------------------------------\n    // \tSCHEDULABLE EVENTS\n    //-------------------------------------\n    /**\n     * Schedule an event along the timeline.\n     * @param callback The callback to be invoked at the time.\n     * @param time The time to invoke the callback at.\n     * @return The id of the event which can be used for canceling the event.\n     * @example\n     * // schedule an event on the 16th measure\n     * Tone.Transport.schedule((time) => {\n     * \t// invoked on measure 16\n     * \tconsole.log(\"measure 16!\");\n     * }, \"16:0:0\");\n     */\n    schedule(callback, time) {\n        const event = new _TransportEvent__WEBPACK_IMPORTED_MODULE_14__.TransportEvent(this, {\n            callback,\n            time: new _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__.TransportTimeClass(this.context, time).toTicks(),\n        });\n        return this._addEvent(event, this._timeline);\n    }\n    /**\n     * Schedule a repeated event along the timeline. The event will fire\n     * at the `interval` starting at the `startTime` and for the specified\n     * `duration`.\n     * @param  callback   The callback to invoke.\n     * @param  interval   The duration between successive callbacks. Must be a positive number.\n     * @param  startTime  When along the timeline the events should start being invoked.\n     * @param  duration How long the event should repeat.\n     * @return  The ID of the scheduled event. Use this to cancel the event.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // a callback invoked every eighth note after the first measure\n     * Tone.Transport.scheduleRepeat((time) => {\n     * \tosc.start(time).stop(time + 0.1);\n     * }, \"8n\", \"1m\");\n     */\n    scheduleRepeat(callback, interval, startTime, duration = Infinity) {\n        const event = new _TransportRepeatEvent__WEBPACK_IMPORTED_MODULE_15__.TransportRepeatEvent(this, {\n            callback,\n            duration: new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, duration).toTicks(),\n            interval: new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, interval).toTicks(),\n            time: new _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__.TransportTimeClass(this.context, startTime).toTicks(),\n        });\n        // kick it off if the Transport is started\n        // @ts-ignore\n        return this._addEvent(event, this._repeatedEvents);\n    }\n    /**\n     * Schedule an event that will be removed after it is invoked.\n     * @param callback The callback to invoke once.\n     * @param time The time the callback should be invoked.\n     * @returns The ID of the scheduled event.\n     */\n    scheduleOnce(callback, time) {\n        const event = new _TransportEvent__WEBPACK_IMPORTED_MODULE_14__.TransportEvent(this, {\n            callback,\n            once: true,\n            time: new _type_TransportTime__WEBPACK_IMPORTED_MODULE_6__.TransportTimeClass(this.context, time).toTicks(),\n        });\n        return this._addEvent(event, this._timeline);\n    }\n    /**\n     * Clear the passed in event id from the timeline\n     * @param eventId The id of the event.\n     */\n    clear(eventId) {\n        if (this._scheduledEvents.hasOwnProperty(eventId)) {\n            const item = this._scheduledEvents[eventId.toString()];\n            item.timeline.remove(item.event);\n            item.event.dispose();\n            delete this._scheduledEvents[eventId.toString()];\n        }\n        return this;\n    }\n    /**\n     * Add an event to the correct timeline. Keep track of the\n     * timeline it was added to.\n     * @returns the event id which was just added\n     */\n    _addEvent(event, timeline) {\n        this._scheduledEvents[event.id.toString()] = {\n            event,\n            timeline,\n        };\n        timeline.add(event);\n        return event.id;\n    }\n    /**\n     * Remove scheduled events from the timeline after\n     * the given time. Repeated events will be removed\n     * if their startTime is after the given time\n     * @param after Clear all events after this time.\n     */\n    cancel(after = 0) {\n        const computedAfter = this.toTicks(after);\n        this._timeline.forEachFrom(computedAfter, event => this.clear(event.id));\n        this._repeatedEvents.forEachFrom(computedAfter, event => this.clear(event.id));\n        return this;\n    }\n    //-------------------------------------\n    // \tSTART/STOP/PAUSE\n    //-------------------------------------\n    /**\n     * Bind start/stop/pause events from the clock and emit them.\n     */\n    _bindClockEvents() {\n        this._clock.on(\"start\", (time, offset) => {\n            offset = new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, offset).toSeconds();\n            this.emit(\"start\", time, offset);\n        });\n        this._clock.on(\"stop\", (time) => {\n            this.emit(\"stop\", time);\n        });\n        this._clock.on(\"pause\", (time) => {\n            this.emit(\"pause\", time);\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\", \"stopped\", or \"paused\"\n     */\n    get state() {\n        return this._clock.getStateAtTime(this.now());\n    }\n    /**\n     * Start the transport and all sources synced to the transport.\n     * @param  time The time when the transport should start.\n     * @param  offset The timeline offset to start the transport.\n     * @example\n     * // start the transport in one second starting at beginning of the 5th measure.\n     * Tone.Transport.start(\"+1\", \"4:0:0\");\n     */\n    start(time, offset) {\n        let offsetTicks;\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_12__.isDefined)(offset)) {\n            offsetTicks = this.toTicks(offset);\n        }\n        // start the clock\n        this._clock.start(time, offsetTicks);\n        return this;\n    }\n    /**\n     * Stop the transport and all sources synced to the transport.\n     * @param time The time when the transport should stop.\n     * @example\n     * Tone.Transport.stop();\n     */\n    stop(time) {\n        this._clock.stop(time);\n        return this;\n    }\n    /**\n     * Pause the transport and all sources synced to the transport.\n     */\n    pause(time) {\n        this._clock.pause(time);\n        return this;\n    }\n    /**\n     * Toggle the current state of the transport. If it is\n     * started, it will stop it, otherwise it will start the Transport.\n     * @param  time The time of the event\n     */\n    toggle(time) {\n        time = this.toSeconds(time);\n        if (this._clock.getStateAtTime(time) !== \"started\") {\n            this.start(time);\n        }\n        else {\n            this.stop(time);\n        }\n        return this;\n    }\n    //-------------------------------------\n    // \tSETTERS/GETTERS\n    //-------------------------------------\n    /**\n     * The time signature as just the numerator over 4.\n     * For example 4/4 would be just 4 and 6/8 would be 3.\n     * @example\n     * // common time\n     * Tone.Transport.timeSignature = 4;\n     * // 7/8\n     * Tone.Transport.timeSignature = [7, 8];\n     * // this will be reduced to a single number\n     * Tone.Transport.timeSignature; // returns 3.5\n     */\n    get timeSignature() {\n        return this._timeSignature;\n    }\n    set timeSignature(timeSig) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_12__.isArray)(timeSig)) {\n            timeSig = (timeSig[0] / timeSig[1]) * 4;\n        }\n        this._timeSignature = timeSig;\n    }\n    /**\n     * When the Transport.loop = true, this is the starting position of the loop.\n     */\n    get loopStart() {\n        return new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, this._loopStart, \"i\").toSeconds();\n    }\n    set loopStart(startPosition) {\n        this._loopStart = this.toTicks(startPosition);\n    }\n    /**\n     * When the Transport.loop = true, this is the ending position of the loop.\n     */\n    get loopEnd() {\n        return new _core_type_Time__WEBPACK_IMPORTED_MODULE_0__.TimeClass(this.context, this._loopEnd, \"i\").toSeconds();\n    }\n    set loopEnd(endPosition) {\n        this._loopEnd = this.toTicks(endPosition);\n    }\n    /**\n     * If the transport loops or not.\n     */\n    get loop() {\n        return this._loop.get(this.now());\n    }\n    set loop(loop) {\n        this._loop.set(loop, this.now());\n    }\n    /**\n     * Set the loop start and stop at the same time.\n     * @example\n     * // loop over the first measure\n     * Tone.Transport.setLoopPoints(0, \"1m\");\n     * Tone.Transport.loop = true;\n     */\n    setLoopPoints(startPosition, endPosition) {\n        this.loopStart = startPosition;\n        this.loopEnd = endPosition;\n        return this;\n    }\n    /**\n     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.\n     */\n    get swing() {\n        return this._swingAmount;\n    }\n    set swing(amount) {\n        // scale the values to a normal range\n        this._swingAmount = amount;\n    }\n    /**\n     * Set the subdivision which the swing will be applied to.\n     * The default value is an 8th note. Value must be less\n     * than a quarter note.\n     */\n    get swingSubdivision() {\n        return new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, this._swingTicks).toNotation();\n    }\n    set swingSubdivision(subdivision) {\n        this._swingTicks = this.toTicks(subdivision);\n    }\n    /**\n     * The Transport's position in Bars:Beats:Sixteenths.\n     * Setting the value will jump to that position right away.\n     */\n    get position() {\n        const now = this.now();\n        const ticks = this._clock.getTicksAtTime(now);\n        return new _type_Ticks__WEBPACK_IMPORTED_MODULE_5__.TicksClass(this.context, ticks).toBarsBeatsSixteenths();\n    }\n    set position(progress) {\n        const ticks = this.toTicks(progress);\n        this.ticks = ticks;\n    }\n    /**\n     * The Transport's position in seconds\n     * Setting the value will jump to that position right away.\n     */\n    get seconds() {\n        return this._clock.seconds;\n    }\n    set seconds(s) {\n        const now = this.now();\n        const ticks = this._clock.frequency.timeToTicks(s, now);\n        this.ticks = ticks;\n    }\n    /**\n     * The Transport's loop position as a normalized value. Always\n     * returns 0 if the transport if loop is not true.\n     */\n    get progress() {\n        if (this.loop) {\n            const now = this.now();\n            const ticks = this._clock.getTicksAtTime(now);\n            return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The transports current tick position.\n     */\n    get ticks() {\n        return this._clock.ticks;\n    }\n    set ticks(t) {\n        if (this._clock.ticks !== t) {\n            const now = this.now();\n            // stop everything synced to the transport\n            if (this.state === \"started\") {\n                const ticks = this._clock.getTicksAtTime(now);\n                // schedule to start on the next tick, #573\n                const remainingTick = this._clock.frequency.getDurationOfTicks(Math.ceil(ticks) - ticks, now);\n                const time = now + remainingTick;\n                this.emit(\"stop\", time);\n                this._clock.setTicksAtTime(t, time);\n                // restart it with the new time\n                this.emit(\"start\", time, this._clock.getSecondsAtTime(time));\n            }\n            else {\n                this._clock.setTicksAtTime(t, now);\n            }\n        }\n    }\n    /**\n     * Get the clock's ticks at the given time.\n     * @param  time  When to get the tick value\n     * @return The tick value at the given time.\n     */\n    getTicksAtTime(time) {\n        return Math.round(this._clock.getTicksAtTime(time));\n    }\n    /**\n     * Return the elapsed seconds at the given time.\n     * @param  time  When to get the elapsed seconds\n     * @return  The number of elapsed seconds\n     */\n    getSecondsAtTime(time) {\n        return this._clock.getSecondsAtTime(time);\n    }\n    /**\n     * Pulses Per Quarter note. This is the smallest resolution\n     * the Transport timing supports. This should be set once\n     * on initialization and not set again. Changing this value\n     * after other objects have been created can cause problems.\n     */\n    get PPQ() {\n        return this._clock.frequency.multiplier;\n    }\n    set PPQ(ppq) {\n        this._clock.frequency.multiplier = ppq;\n    }\n    //-------------------------------------\n    // \tSYNCING\n    //-------------------------------------\n    /**\n     * Returns the time aligned to the next subdivision\n     * of the Transport. If the Transport is not started,\n     * it will return 0.\n     * Note: this will not work precisely during tempo ramps.\n     * @param  subdivision  The subdivision to quantize to\n     * @return  The context time of the next subdivision.\n     * @example\n     * // the transport must be started, otherwise returns 0\n     * Tone.Transport.start();\n     * Tone.Transport.nextSubdivision(\"4n\");\n     */\n    nextSubdivision(subdivision) {\n        subdivision = this.toTicks(subdivision);\n        if (this.state !== \"started\") {\n            // if the transport's not started, return 0\n            return 0;\n        }\n        else {\n            const now = this.now();\n            // the remainder of the current ticks and the subdivision\n            const transportPos = this.getTicksAtTime(now);\n            const remainingTicks = subdivision - transportPos % subdivision;\n            return this._clock.nextTickTime(remainingTicks, now);\n        }\n    }\n    /**\n     * Attaches the signal to the tempo control signal so that\n     * any changes in the tempo will change the signal in the same\n     * ratio.\n     *\n     * @param signal\n     * @param ratio Optionally pass in the ratio between the two signals.\n     * \t\t\tOtherwise it will be computed based on their current values.\n     */\n    syncSignal(signal, ratio) {\n        if (!ratio) {\n            // get the sync ratio\n            const now = this.now();\n            if (signal.getValueAtTime(now) !== 0) {\n                const bpm = this.bpm.getValueAtTime(now);\n                const computedFreq = 1 / (60 / bpm / this.PPQ);\n                ratio = signal.getValueAtTime(now) / computedFreq;\n            }\n            else {\n                ratio = 0;\n            }\n        }\n        const ratioSignal = new _context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain(ratio);\n        // @ts-ignore\n        this.bpm.connect(ratioSignal);\n        // @ts-ignore\n        ratioSignal.connect(signal._param);\n        this._syncedSignals.push({\n            initial: signal.value,\n            ratio: ratioSignal,\n            signal,\n        });\n        signal.value = 0;\n        return this;\n    }\n    /**\n     * Unsyncs a previously synced signal from the transport's control.\n     * See Transport.syncSignal.\n     */\n    unsyncSignal(signal) {\n        for (let i = this._syncedSignals.length - 1; i >= 0; i--) {\n            const syncedSignal = this._syncedSignals[i];\n            if (syncedSignal.signal === signal) {\n                syncedSignal.ratio.dispose();\n                syncedSignal.signal.value = syncedSignal.initial;\n                this._syncedSignals.splice(i, 1);\n            }\n        }\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._clock.dispose();\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_9__.writable)(this, \"bpm\");\n        this._timeline.dispose();\n        this._repeatedEvents.dispose();\n        return this;\n    }\n}\n_util_Emitter__WEBPACK_IMPORTED_MODULE_8__.Emitter.mixin(Transport);\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.transport = new Transport({ context });\n});\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.transport.dispose();\n});\n//# sourceMappingURL=Transport.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/Transport.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TransportEvent.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TransportEvent.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TransportEvent\": () => (/* binding */ TransportEvent)\n/* harmony export */ });\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n/**\n * TransportEvent is an internal class used by [[Transport]]\n * to schedule events. Do no invoke this class directly, it is\n * handled from within Tone.Transport.\n */\nclass TransportEvent {\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport, opts) {\n        /**\n         * The unique id of the event\n         */\n        this.id = TransportEvent._eventId++;\n        const options = Object.assign(TransportEvent.getDefaults(), opts);\n        this.transport = transport;\n        this.callback = options.callback;\n        this._once = options.once;\n        this.time = options.time;\n    }\n    static getDefaults() {\n        return {\n            callback: _util_Interface__WEBPACK_IMPORTED_MODULE_0__.noOp,\n            once: false,\n            time: 0,\n        };\n    }\n    /**\n     * Invoke the event callback.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time) {\n        if (this.callback) {\n            this.callback(time);\n            if (this._once) {\n                this.transport.clear(this.id);\n            }\n        }\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        this.callback = undefined;\n        return this;\n    }\n}\n/**\n * Current ID counter\n */\nTransportEvent._eventId = 0;\n//# sourceMappingURL=TransportEvent.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/TransportEvent.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TransportRepeatEvent\": () => (/* binding */ TransportRepeatEvent)\n/* harmony export */ });\n/* harmony import */ var _type_Ticks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _TransportEvent__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TransportEvent */ \"./node_modules/tone/build/esm/core/clock/TransportEvent.js\");\n\n\n/**\n * TransportRepeatEvent is an internal class used by Tone.Transport\n * to schedule repeat events. This class should not be instantiated directly.\n */\nclass TransportRepeatEvent extends _TransportEvent__WEBPACK_IMPORTED_MODULE_1__.TransportEvent {\n    /**\n     * @param transport The transport object which the event belongs to\n     */\n    constructor(transport, opts) {\n        super(transport, opts);\n        /**\n         * The ID of the current timeline event\n         */\n        this._currentId = -1;\n        /**\n         * The ID of the next timeline event\n         */\n        this._nextId = -1;\n        /**\n         * The time of the next event\n         */\n        this._nextTick = this.time;\n        /**\n         * a reference to the bound start method\n         */\n        this._boundRestart = this._restart.bind(this);\n        const options = Object.assign(TransportRepeatEvent.getDefaults(), opts);\n        this.duration = new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(transport.context, options.duration).valueOf();\n        this._interval = new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(transport.context, options.interval).valueOf();\n        this._nextTick = options.time;\n        this.transport.on(\"start\", this._boundRestart);\n        this.transport.on(\"loopStart\", this._boundRestart);\n        this.context = this.transport.context;\n        this._restart();\n    }\n    static getDefaults() {\n        return Object.assign({}, _TransportEvent__WEBPACK_IMPORTED_MODULE_1__.TransportEvent.getDefaults(), {\n            duration: Infinity,\n            interval: 1,\n            once: false,\n        });\n    }\n    /**\n     * Invoke the callback. Returns the tick time which\n     * the next event should be scheduled at.\n     * @param  time  The AudioContext time in seconds of the event\n     */\n    invoke(time) {\n        // create more events if necessary\n        this._createEvents(time);\n        // call the super class\n        super.invoke(time);\n    }\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    _createEvents(time) {\n        // schedule the next event\n        const ticks = this.transport.getTicksAtTime(time);\n        if (ticks >= this.time && ticks >= this._nextTick && this._nextTick + this._interval < this.time + this.duration) {\n            this._nextTick += this._interval;\n            this._currentId = this._nextId;\n            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._nextTick).toSeconds());\n        }\n    }\n    /**\n     * Push more events onto the timeline to keep up with the position of the timeline\n     */\n    _restart(time) {\n        this.transport.clear(this._currentId);\n        this.transport.clear(this._nextId);\n        this._nextTick = this.time;\n        const ticks = this.transport.getTicksAtTime(time);\n        if (ticks > this.time) {\n            this._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;\n        }\n        this._currentId = this.transport.scheduleOnce(this.invoke.bind(this), new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._nextTick).toSeconds());\n        this._nextTick += this._interval;\n        this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new _type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._nextTick).toSeconds());\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.transport.clear(this._currentId);\n        this.transport.clear(this._nextId);\n        this.transport.off(\"start\", this._boundRestart);\n        this.transport.off(\"loopStart\", this._boundRestart);\n        return this;\n    }\n}\n//# sourceMappingURL=TransportRepeatEvent.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/clock/TransportRepeatEvent.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/AudioContext.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/AudioContext.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"createAudioContext\": () => (/* binding */ createAudioContext),\n/* harmony export */   \"createAudioWorkletNode\": () => (/* binding */ createAudioWorkletNode),\n/* harmony export */   \"createOfflineAudioContext\": () => (/* binding */ createOfflineAudioContext),\n/* harmony export */   \"hasAudioContext\": () => (/* binding */ hasAudioContext),\n/* harmony export */   \"supported\": () => (/* reexport safe */ standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isSupported),\n/* harmony export */   \"theWindow\": () => (/* binding */ theWindow)\n/* harmony export */ });\n/* harmony import */ var standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! standardized-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/module.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n/**\n * Create a new AudioContext\n */\nfunction createAudioContext(options) {\n    return new standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.AudioContext(options);\n}\n/**\n * Create a new OfflineAudioContext\n */\nfunction createOfflineAudioContext(channels, length, sampleRate) {\n    return new standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.OfflineAudioContext(channels, length, sampleRate);\n}\n/**\n * A reference to the window object\n * @hidden\n */\nconst theWindow = typeof self === \"object\" ? self : null;\n/**\n * If the browser has a window object which has an AudioContext\n * @hidden\n */\nconst hasAudioContext = theWindow &&\n    (theWindow.hasOwnProperty(\"AudioContext\") || theWindow.hasOwnProperty(\"webkitAudioContext\"));\nfunction createAudioWorkletNode(context, name, options) {\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_1__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isDefined)(standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.AudioWorkletNode), \"This node only works in a secure context (https or localhost)\");\n    // @ts-ignore\n    return new standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.AudioWorkletNode(context, name, options);\n}\n/**\n * This promise resolves to a boolean which indicates if the\n * functionality is supported within the currently used browse.\n * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)\n */\n\n//# sourceMappingURL=AudioContext.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/AudioContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/BaseContext.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/BaseContext.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseContext\": () => (/* binding */ BaseContext)\n/* harmony export */ });\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n\nclass BaseContext extends _util_Emitter__WEBPACK_IMPORTED_MODULE_0__.Emitter {\n    constructor() {\n        super(...arguments);\n        this.isOffline = false;\n    }\n    /*\n     * This is a placeholder so that JSON.stringify does not throw an error\n     * This matches what JSON.stringify(audioContext) returns on a native\n     * audioContext instance.\n     */\n    toJSON() {\n        return {};\n    }\n}\n//# sourceMappingURL=BaseContext.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/BaseContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Context.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Context.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Context\": () => (/* binding */ Context)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _clock_Ticker__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../clock/Ticker */ \"./node_modules/tone/build/esm/core/clock/Ticker.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _AudioContext__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _ContextInitialization__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n/* harmony import */ var _BaseContext__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./BaseContext */ \"./node_modules/tone/build/esm/core/context/BaseContext.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * Wrapper around the native AudioContext.\n * @category Core\n */\nclass Context extends _BaseContext__WEBPACK_IMPORTED_MODULE_7__.BaseContext {\n    constructor() {\n        super();\n        this.name = \"Context\";\n        /**\n         * An object containing all of the constants AudioBufferSourceNodes\n         */\n        this._constants = new Map();\n        /**\n         * All of the setTimeout events.\n         */\n        this._timeouts = new _util_Timeline__WEBPACK_IMPORTED_MODULE_3__.Timeline();\n        /**\n         * The timeout id counter\n         */\n        this._timeoutIds = 0;\n        /**\n         * Private indicator if the context has been initialized\n         */\n        this._initialized = false;\n        /**\n         * Indicates if the context is an OfflineAudioContext or an AudioContext\n         */\n        this.isOffline = false;\n        //--------------------------------------------\n        // AUDIO WORKLET\n        //--------------------------------------------\n        /**\n         * Maps a module name to promise of the addModule method\n         */\n        this._workletModules = new Map();\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Context.getDefaults(), arguments, [\n            \"context\",\n        ]);\n        if (options.context) {\n            this._context = options.context;\n        }\n        else {\n            this._context = (0,_AudioContext__WEBPACK_IMPORTED_MODULE_5__.createAudioContext)({\n                latencyHint: options.latencyHint,\n            });\n        }\n        this._ticker = new _clock_Ticker__WEBPACK_IMPORTED_MODULE_0__.Ticker(this.emit.bind(this, \"tick\"), options.clockSource, options.updateInterval);\n        this.on(\"tick\", this._timeoutLoop.bind(this));\n        // fwd events from the context\n        this._context.onstatechange = () => {\n            this.emit(\"statechange\", this.state);\n        };\n        this._setLatencyHint(options.latencyHint);\n        this.lookAhead = options.lookAhead;\n    }\n    static getDefaults() {\n        return {\n            clockSource: \"worker\",\n            latencyHint: \"interactive\",\n            lookAhead: 0.1,\n            updateInterval: 0.05,\n        };\n    }\n    /**\n     * Finish setting up the context. **You usually do not need to do this manually.**\n     */\n    initialize() {\n        if (!this._initialized) {\n            // add any additional modules\n            (0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_6__.initializeContext)(this);\n            this._initialized = true;\n        }\n        return this;\n    }\n    //---------------------------\n    // BASE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAnalyser() {\n        return this._context.createAnalyser();\n    }\n    createOscillator() {\n        return this._context.createOscillator();\n    }\n    createBufferSource() {\n        return this._context.createBufferSource();\n    }\n    createBiquadFilter() {\n        return this._context.createBiquadFilter();\n    }\n    createBuffer(numberOfChannels, length, sampleRate) {\n        return this._context.createBuffer(numberOfChannels, length, sampleRate);\n    }\n    createChannelMerger(numberOfInputs) {\n        return this._context.createChannelMerger(numberOfInputs);\n    }\n    createChannelSplitter(numberOfOutputs) {\n        return this._context.createChannelSplitter(numberOfOutputs);\n    }\n    createConstantSource() {\n        return this._context.createConstantSource();\n    }\n    createConvolver() {\n        return this._context.createConvolver();\n    }\n    createDelay(maxDelayTime) {\n        return this._context.createDelay(maxDelayTime);\n    }\n    createDynamicsCompressor() {\n        return this._context.createDynamicsCompressor();\n    }\n    createGain() {\n        return this._context.createGain();\n    }\n    createIIRFilter(feedForward, feedback) {\n        // @ts-ignore\n        return this._context.createIIRFilter(feedForward, feedback);\n    }\n    createPanner() {\n        return this._context.createPanner();\n    }\n    createPeriodicWave(real, imag, constraints) {\n        return this._context.createPeriodicWave(real, imag, constraints);\n    }\n    createStereoPanner() {\n        return this._context.createStereoPanner();\n    }\n    createWaveShaper() {\n        return this._context.createWaveShaper();\n    }\n    createMediaStreamSource(stream) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaStreamSource(stream);\n    }\n    createMediaElementSource(element) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaElementSource(element);\n    }\n    createMediaStreamDestination() {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context), \"Not available if OfflineAudioContext\");\n        const context = this._context;\n        return context.createMediaStreamDestination();\n    }\n    decodeAudioData(audioData) {\n        return this._context.decodeAudioData(audioData);\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get currentTime() {\n        return this._context.currentTime;\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get state() {\n        return this._context.state;\n    }\n    /**\n     * The current time in seconds of the AudioContext.\n     */\n    get sampleRate() {\n        return this._context.sampleRate;\n    }\n    /**\n     * The listener\n     */\n    get listener() {\n        this.initialize();\n        return this._listener;\n    }\n    set listener(l) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"The listener cannot be set after initialization.\");\n        this._listener = l;\n    }\n    /**\n     * There is only one Transport per Context. It is created on initialization.\n     */\n    get transport() {\n        this.initialize();\n        return this._transport;\n    }\n    set transport(t) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"The transport cannot be set after initialization.\");\n        this._transport = t;\n    }\n    /**\n     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.\n     */\n    get draw() {\n        this.initialize();\n        return this._draw;\n    }\n    set draw(d) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"Draw cannot be set after initialization.\");\n        this._draw = d;\n    }\n    /**\n     * A reference to the Context's destination node.\n     */\n    get destination() {\n        this.initialize();\n        return this._destination;\n    }\n    set destination(d) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)(!this._initialized, \"The destination cannot be set after initialization.\");\n        this._destination = d;\n    }\n    /**\n     * Create an audio worklet node from a name and options. The module\n     * must first be loaded using [[addAudioWorkletModule]].\n     */\n    createAudioWorkletNode(name, options) {\n        return (0,_AudioContext__WEBPACK_IMPORTED_MODULE_5__.createAudioWorkletNode)(this.rawContext, name, options);\n    }\n    /**\n     * Add an AudioWorkletProcessor module\n     * @param url The url of the module\n     * @param name The name of the module\n     */\n    addAudioWorkletModule(url, name) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this.rawContext.audioWorklet), \"AudioWorkletNode is only available in a secure context (https or localhost)\");\n            if (!this._workletModules.has(name)) {\n                this._workletModules.set(name, this.rawContext.audioWorklet.addModule(url));\n            }\n            yield this._workletModules.get(name);\n        });\n    }\n    /**\n     * Returns a promise which resolves when all of the worklets have been loaded on this context\n     */\n    workletsAreReady() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            const promises = [];\n            this._workletModules.forEach((promise) => promises.push(promise));\n            yield Promise.all(promises);\n        });\n    }\n    //---------------------------\n    // TICKER\n    //---------------------------\n    /**\n     * How often the interval callback is invoked.\n     * This number corresponds to how responsive the scheduling\n     * can be. context.updateInterval + context.lookAhead gives you the\n     * total latency between scheduling an event and hearing it.\n     */\n    get updateInterval() {\n        return this._ticker.updateInterval;\n    }\n    set updateInterval(interval) {\n        this._ticker.updateInterval = interval;\n    }\n    /**\n     * What the source of the clock is, either \"worker\" (default),\n     * \"timeout\", or \"offline\" (none).\n     */\n    get clockSource() {\n        return this._ticker.type;\n    }\n    set clockSource(type) {\n        this._ticker.type = type;\n    }\n    /**\n     * The type of playback, which affects tradeoffs between audio\n     * output latency and responsiveness.\n     * In addition to setting the value in seconds, the latencyHint also\n     * accepts the strings \"interactive\" (prioritizes low latency),\n     * \"playback\" (prioritizes sustained playback), \"balanced\" (balances\n     * latency and performance).\n     * @example\n     * // prioritize sustained playback\n     * const context = new Tone.Context({ latencyHint: \"playback\" });\n     * // set this context as the global Context\n     * Tone.setContext(context);\n     * // the global context is gettable with Tone.getContext()\n     * console.log(Tone.getContext().latencyHint);\n     */\n    get latencyHint() {\n        return this._latencyHint;\n    }\n    /**\n     * Update the lookAhead and updateInterval based on the latencyHint\n     */\n    _setLatencyHint(hint) {\n        let lookAheadValue = 0;\n        this._latencyHint = hint;\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isString)(hint)) {\n            switch (hint) {\n                case \"interactive\":\n                    lookAheadValue = 0.1;\n                    break;\n                case \"playback\":\n                    lookAheadValue = 0.5;\n                    break;\n                case \"balanced\":\n                    lookAheadValue = 0.25;\n                    break;\n            }\n        }\n        this.lookAhead = lookAheadValue;\n        this.updateInterval = lookAheadValue / 2;\n    }\n    /**\n     * The unwrapped AudioContext or OfflineAudioContext\n     */\n    get rawContext() {\n        return this._context;\n    }\n    /**\n     * The current audio context time plus a short [[lookAhead]].\n     */\n    now() {\n        return this._context.currentTime + this.lookAhead;\n    }\n    /**\n     * The current audio context time without the [[lookAhead]].\n     * In most cases it is better to use [[now]] instead of [[immediate]] since\n     * with [[now]] the [[lookAhead]] is applied equally to _all_ components including internal components,\n     * to making sure that everything is scheduled in sync. Mixing [[now]] and [[immediate]]\n     * can cause some timing issues. If no lookAhead is desired, you can set the [[lookAhead]] to `0`.\n     */\n    immediate() {\n        return this._context.currentTime;\n    }\n    /**\n     * Starts the audio context from a suspended state. This is required\n     * to initially start the AudioContext. See [[Tone.start]]\n     */\n    resume() {\n        if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context)) {\n            return this._context.resume();\n        }\n        else {\n            return Promise.resolve();\n        }\n    }\n    /**\n     * Close the context. Once closed, the context can no longer be used and\n     * any AudioNodes created from the context will be silent.\n     */\n    close() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioContext)(this._context)) {\n                yield this._context.close();\n            }\n            if (this._initialized) {\n                (0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_6__.closeContext)(this);\n            }\n        });\n    }\n    /**\n     * **Internal** Generate a looped buffer at some constant value.\n     */\n    getConstant(val) {\n        if (this._constants.has(val)) {\n            return this._constants.get(val);\n        }\n        else {\n            const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);\n            const arr = buffer.getChannelData(0);\n            for (let i = 0; i < arr.length; i++) {\n                arr[i] = val;\n            }\n            const constant = this._context.createBufferSource();\n            constant.channelCount = 1;\n            constant.channelCountMode = \"explicit\";\n            constant.buffer = buffer;\n            constant.loop = true;\n            constant.start(0);\n            this._constants.set(val, constant);\n            return constant;\n        }\n    }\n    /**\n     * Clean up. Also closes the audio context.\n     */\n    dispose() {\n        super.dispose();\n        this._ticker.dispose();\n        this._timeouts.dispose();\n        Object.keys(this._constants).map((val) => this._constants[val].disconnect());\n        return this;\n    }\n    //---------------------------\n    // TIMEOUTS\n    //---------------------------\n    /**\n     * The private loop which keeps track of the context scheduled timeouts\n     * Is invoked from the clock source\n     */\n    _timeoutLoop() {\n        const now = this.now();\n        let firstEvent = this._timeouts.peek();\n        while (this._timeouts.length && firstEvent && firstEvent.time <= now) {\n            // invoke the callback\n            firstEvent.callback();\n            // shift the first event off\n            this._timeouts.shift();\n            // get the next one\n            firstEvent = this._timeouts.peek();\n        }\n    }\n    /**\n     * A setTimeout which is guaranteed by the clock source.\n     * Also runs in the offline context.\n     * @param  fn       The callback to invoke\n     * @param  timeout  The timeout in seconds\n     * @returns ID to use when invoking Context.clearTimeout\n     */\n    setTimeout(fn, timeout) {\n        this._timeoutIds++;\n        const now = this.now();\n        this._timeouts.add({\n            callback: fn,\n            id: this._timeoutIds,\n            time: now + timeout,\n        });\n        return this._timeoutIds;\n    }\n    /**\n     * Clears a previously scheduled timeout with Tone.context.setTimeout\n     * @param  id  The ID returned from setTimeout\n     */\n    clearTimeout(id) {\n        this._timeouts.forEach((event) => {\n            if (event.id === id) {\n                this._timeouts.remove(event);\n            }\n        });\n        return this;\n    }\n    /**\n     * Clear the function scheduled by [[setInterval]]\n     */\n    clearInterval(id) {\n        return this.clearTimeout(id);\n    }\n    /**\n     * Adds a repeating event to the context's callback clock\n     */\n    setInterval(fn, interval) {\n        const id = ++this._timeoutIds;\n        const intervalFn = () => {\n            const now = this.now();\n            this._timeouts.add({\n                callback: () => {\n                    // invoke the callback\n                    fn();\n                    // invoke the event to repeat it\n                    intervalFn();\n                },\n                id,\n                time: now + interval,\n            });\n        };\n        // kick it off\n        intervalFn();\n        return id;\n    }\n}\n//# sourceMappingURL=Context.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Context.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ContextInitialization.js":
/*!***************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ContextInitialization.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"closeContext\": () => (/* binding */ closeContext),\n/* harmony export */   \"initializeContext\": () => (/* binding */ initializeContext),\n/* harmony export */   \"onContextClose\": () => (/* binding */ onContextClose),\n/* harmony export */   \"onContextInit\": () => (/* binding */ onContextInit)\n/* harmony export */ });\n//-------------------------------------\n// INITIALIZING NEW CONTEXT\n//-------------------------------------\n/**\n * Array of callbacks to invoke when a new context is created\n */\nconst notifyNewContext = [];\n/**\n * Used internally to setup a new Context\n */\nfunction onContextInit(cb) {\n    notifyNewContext.push(cb);\n}\n/**\n * Invoke any classes which need to also be initialized when a new context is created.\n */\nfunction initializeContext(ctx) {\n    // add any additional modules\n    notifyNewContext.forEach(cb => cb(ctx));\n}\n/**\n * Array of callbacks to invoke when a new context is created\n */\nconst notifyCloseContext = [];\n/**\n * Used internally to tear down a Context\n */\nfunction onContextClose(cb) {\n    notifyCloseContext.push(cb);\n}\nfunction closeContext(ctx) {\n    // add any additional modules\n    notifyCloseContext.forEach(cb => cb(ctx));\n}\n//# sourceMappingURL=ContextInitialization.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/ContextInitialization.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Delay.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Delay.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Delay\": () => (/* binding */ Delay)\n/* harmony export */ });\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n/**\n * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).\n * @category Core\n * @example\n * return Tone.Offline(() => {\n * \tconst delay = new Tone.Delay(0.1).toDestination();\n * \t// connect the signal to both the delay and the destination\n * \tconst pulse = new Tone.PulseOscillator().connect(delay).toDestination();\n * \t// start and stop the pulse\n * \tpulse.start(0).stop(0.01);\n * }, 0.5, 1);\n */\nclass Delay extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Delay.getDefaults(), arguments, [\"delayTime\", \"maxDelay\"]));\n        this.name = \"Delay\";\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Delay.getDefaults(), arguments, [\"delayTime\", \"maxDelay\"]);\n        const maxDelayInSeconds = this.toSeconds(options.maxDelay);\n        this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));\n        this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);\n        this.delayTime = new _context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            param: this._delayNode.delayTime,\n            units: \"time\",\n            value: options.delayTime,\n            minValue: 0,\n            maxValue: this.maxDelay,\n        });\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"delayTime\");\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults(), {\n            delayTime: 0,\n            maxDelay: 1,\n        });\n    }\n    /**\n     * The maximum delay time. This cannot be changed after\n     * the value is passed into the constructor.\n     */\n    get maxDelay() {\n        return this._maxDelay;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._delayNode.disconnect();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Delay.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Delay.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Destination.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Destination.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Destination\": () => (/* binding */ Destination)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n/* harmony import */ var _Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n\n/**\n * A single master output which is connected to the\n * AudioDestinationNode (aka your speakers).\n * It provides useful conveniences such as the ability\n * to set the volume and mute the entire application.\n * It also gives you the ability to apply master effects to your application.\n *\n * @example\n * const oscillator = new Tone.Oscillator().start();\n * // the audio will go from the oscillator to the speakers\n * oscillator.connect(Tone.getDestination());\n * // a convenience for connecting to the master output is also provided:\n * oscillator.toDestination();\n * @category Core\n */\nclass Destination extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Destination.getDefaults(), arguments));\n        this.name = \"Destination\";\n        this.input = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({ context: this.context });\n        this.output = new _Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        /**\n         * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.\n         * @example\n         * const osc = new Tone.Oscillator().toDestination();\n         * osc.start();\n         * // ramp the volume down to silent over 10 seconds\n         * Tone.getDestination().volume.rampTo(-Infinity, 10);\n         */\n        this.volume = this.input.volume;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Destination.getDefaults(), arguments);\n        (0,_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.connectSeries)(this.input, this.output, this.context.rawContext.destination);\n        this.mute = options.mute;\n        this._internalChannels = [this.input, this.context.rawContext.destination, this.output];\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const oscillator = new Tone.Oscillator().start().toDestination();\n     * setTimeout(() => {\n     * \t// mute the output\n     * \tTone.Destination.mute = true;\n     * }, 1000);\n     */\n    get mute() {\n        return this.input.mute;\n    }\n    set mute(mute) {\n        this.input.mute = mute;\n    }\n    /**\n     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously\n     * chained in the master effects chain.\n     * @param args All arguments will be connected in a row and the Master will be routed through it.\n     * @example\n     * // route all audio through a filter and compressor\n     * const lowpass = new Tone.Filter(800, \"lowpass\");\n     * const compressor = new Tone.Compressor(-18);\n     * Tone.Destination.chain(lowpass, compressor);\n     */\n    chain(...args) {\n        this.input.disconnect();\n        args.unshift(this.input);\n        args.push(this.output);\n        (0,_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.connectSeries)(...args);\n        return this;\n    }\n    /**\n     * The maximum number of channels the system can output\n     * @example\n     * console.log(Tone.Destination.maxChannelCount);\n     */\n    get maxChannelCount() {\n        return this.context.rawContext.destination.maxChannelCount;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this.volume.dispose();\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.destination = new Destination({ context });\n});\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.destination.dispose();\n});\n//# sourceMappingURL=Destination.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Destination.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/DummyContext.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/DummyContext.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DummyContext\": () => (/* binding */ DummyContext)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _BaseContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BaseContext */ \"./node_modules/tone/build/esm/core/context/BaseContext.js\");\n\n\nclass DummyContext extends _BaseContext__WEBPACK_IMPORTED_MODULE_0__.BaseContext {\n    constructor() {\n        super(...arguments);\n        this.lookAhead = 0;\n        this.latencyHint = 0;\n        this.isOffline = false;\n    }\n    //---------------------------\n    // BASE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAnalyser() {\n        return {};\n    }\n    createOscillator() {\n        return {};\n    }\n    createBufferSource() {\n        return {};\n    }\n    createBiquadFilter() {\n        return {};\n    }\n    createBuffer(_numberOfChannels, _length, _sampleRate) {\n        return {};\n    }\n    createChannelMerger(_numberOfInputs) {\n        return {};\n    }\n    createChannelSplitter(_numberOfOutputs) {\n        return {};\n    }\n    createConstantSource() {\n        return {};\n    }\n    createConvolver() {\n        return {};\n    }\n    createDelay(_maxDelayTime) {\n        return {};\n    }\n    createDynamicsCompressor() {\n        return {};\n    }\n    createGain() {\n        return {};\n    }\n    createIIRFilter(_feedForward, _feedback) {\n        return {};\n    }\n    createPanner() {\n        return {};\n    }\n    createPeriodicWave(_real, _imag, _constraints) {\n        return {};\n    }\n    createStereoPanner() {\n        return {};\n    }\n    createWaveShaper() {\n        return {};\n    }\n    createMediaStreamSource(_stream) {\n        return {};\n    }\n    createMediaElementSource(_element) {\n        return {};\n    }\n    createMediaStreamDestination() {\n        return {};\n    }\n    decodeAudioData(_audioData) {\n        return Promise.resolve({});\n    }\n    //---------------------------\n    // TONE AUDIO CONTEXT METHODS\n    //---------------------------\n    createAudioWorkletNode(_name, _options) {\n        return {};\n    }\n    get rawContext() {\n        return {};\n    }\n    addAudioWorkletModule(_url, _name) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_1__.__awaiter)(this, void 0, void 0, function* () {\n            return Promise.resolve();\n        });\n    }\n    resume() {\n        return Promise.resolve();\n    }\n    setTimeout(_fn, _timeout) {\n        return 0;\n    }\n    clearTimeout(_id) {\n        return this;\n    }\n    setInterval(_fn, _interval) {\n        return 0;\n    }\n    clearInterval(_id) {\n        return this;\n    }\n    getConstant(_val) {\n        return {};\n    }\n    get currentTime() {\n        return 0;\n    }\n    get state() {\n        return {};\n    }\n    get sampleRate() {\n        return 0;\n    }\n    get listener() {\n        return {};\n    }\n    get transport() {\n        return {};\n    }\n    get draw() {\n        return {};\n    }\n    set draw(_d) { }\n    get destination() {\n        return {};\n    }\n    set destination(_d) { }\n    now() {\n        return 0;\n    }\n    immediate() {\n        return 0;\n    }\n}\n//# sourceMappingURL=DummyContext.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/DummyContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Gain.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Gain.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Gain\": () => (/* binding */ Gain)\n/* harmony export */ });\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n/**\n * A thin wrapper around the Native Web Audio GainNode.\n * The GainNode is a basic building block of the Web Audio\n * API and is useful for routing audio and adjusting gains.\n * @category Core\n * @example\n * return Tone.Offline(() => {\n * \tconst gainNode = new Tone.Gain(0).toDestination();\n * \tconst osc = new Tone.Oscillator(30).connect(gainNode).start();\n * \tgainNode.gain.rampTo(1, 0.1);\n * \tgainNode.gain.rampTo(0, 0.4, 0.2);\n * }, 0.7, 1);\n */\nclass Gain extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Gain.getDefaults(), arguments, [\"gain\", \"units\"]));\n        this.name = \"Gain\";\n        /**\n         * The wrapped GainNode.\n         */\n        this._gainNode = this.context.createGain();\n        // input = output\n        this.input = this._gainNode;\n        this.output = this._gainNode;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Gain.getDefaults(), arguments, [\"gain\", \"units\"]);\n        this.gain = new _context_Param__WEBPACK_IMPORTED_MODULE_0__.Param({\n            context: this.context,\n            convert: options.convert,\n            param: this._gainNode.gain,\n            units: options.units,\n            value: options.gain,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        (0,_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"gain\");\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults(), {\n            convert: true,\n            gain: 1,\n            units: \"gain\",\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._gainNode.disconnect();\n        this.gain.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Gain.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Gain.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Listener.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Listener.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Listener\": () => (/* binding */ Listener)\n/* harmony export */ });\n/* harmony import */ var _ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n\n\n\n/**\n * Tone.Listener is a thin wrapper around the AudioListener. Listener combined\n * with [[Panner3D]] makes up the Web Audio API's 3D panning system. Panner3D allows you\n * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from\n * a first-person perspective. There is only one listener per audio context.\n */\nclass Listener extends _ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super(...arguments);\n        this.name = \"Listener\";\n        this.positionX = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionX,\n        });\n        this.positionY = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionY,\n        });\n        this.positionZ = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.positionZ,\n        });\n        this.forwardX = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardX,\n        });\n        this.forwardY = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardY,\n        });\n        this.forwardZ = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.forwardZ,\n        });\n        this.upX = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upX,\n        });\n        this.upY = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upY,\n        });\n        this.upZ = new _Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this.context.rawContext.listener.upZ,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            positionX: 0,\n            positionY: 0,\n            positionZ: 0,\n            forwardX: 0,\n            forwardY: 0,\n            forwardZ: -1,\n            upX: 0,\n            upY: 1,\n            upZ: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.positionX.dispose();\n        this.positionY.dispose();\n        this.positionZ.dispose();\n        this.forwardX.dispose();\n        this.forwardY.dispose();\n        this.forwardZ.dispose();\n        this.upX.dispose();\n        this.upY.dispose();\n        this.upZ.dispose();\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.listener = new Listener({ context });\n});\n(0,_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.listener.dispose();\n});\n//# sourceMappingURL=Listener.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Listener.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Offline.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Offline.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Offline\": () => (/* binding */ Offline)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _OfflineContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n\n\n\n\n/**\n * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.\n * The OfflineAudioContext is capable of rendering much faster than real time in many cases.\n * The callback function also passes in an offline instance of [[Context]] which can be used\n * to schedule events along the Transport.\n * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.\n * @param  duration     the amount of time to record for.\n * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.\n * @example\n * // render 2 seconds of the oscillator\n * Tone.Offline(() => {\n * \t// only nodes created in this callback will be recorded\n * \tconst oscillator = new Tone.Oscillator().toDestination().start(0);\n * }, 2).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @example\n * // can also schedule events along the Transport\n * // using the passed in Offline Transport\n * Tone.Offline(({ transport }) => {\n * \tconst osc = new Tone.Oscillator().toDestination();\n * \ttransport.schedule(time => {\n * \t\tosc.start(time).stop(time + 0.1);\n * \t}, 1);\n * \t// make sure to start the transport\n * \ttransport.start(0.2);\n * }, 4).then((buffer) => {\n * \t// do something with the output buffer\n * \tconsole.log(buffer);\n * });\n * @category Core\n */\nfunction Offline(callback, duration, channels = 2, sampleRate = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().sampleRate) {\n    return (0,tslib__WEBPACK_IMPORTED_MODULE_3__.__awaiter)(this, void 0, void 0, function* () {\n        // set the OfflineAudioContext based on the current context\n        const originalContext = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)();\n        const context = new _OfflineContext__WEBPACK_IMPORTED_MODULE_1__.OfflineContext(channels, duration, sampleRate);\n        (0,_Global__WEBPACK_IMPORTED_MODULE_0__.setContext)(context);\n        // invoke the callback/scheduling\n        yield callback(context);\n        // then render the audio\n        const bufferPromise = context.render();\n        // return the original AudioContext\n        (0,_Global__WEBPACK_IMPORTED_MODULE_0__.setContext)(originalContext);\n        // await the rendering\n        const buffer = yield bufferPromise;\n        // return the audio\n        return new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer(buffer);\n    });\n}\n//# sourceMappingURL=Offline.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Offline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/OfflineContext.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/OfflineContext.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OfflineContext\": () => (/* binding */ OfflineContext)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _context_AudioContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _context_Context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../context/Context */ \"./node_modules/tone/build/esm/core/context/Context.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n\n\n\n\n\n/**\n * Wrapper around the OfflineAudioContext\n * @category Core\n * @example\n * // generate a single channel, 0.5 second buffer\n * const context = new Tone.OfflineContext(1, 0.5, 44100);\n * const osc = new Tone.Oscillator({ context });\n * context.render().then(buffer => {\n * \tconsole.log(buffer.numberOfChannels, buffer.duration);\n * });\n */\nclass OfflineContext extends _context_Context__WEBPACK_IMPORTED_MODULE_1__.Context {\n    constructor() {\n        super({\n            clockSource: \"offline\",\n            context: (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isOfflineAudioContext)(arguments[0]) ?\n                arguments[0] : (0,_context_AudioContext__WEBPACK_IMPORTED_MODULE_0__.createOfflineAudioContext)(arguments[0], arguments[1] * arguments[2], arguments[2]),\n            lookAhead: 0,\n            updateInterval: (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isOfflineAudioContext)(arguments[0]) ?\n                128 / arguments[0].sampleRate : 128 / arguments[2],\n        });\n        this.name = \"OfflineContext\";\n        /**\n         * An artificial clock source\n         */\n        this._currentTime = 0;\n        this.isOffline = true;\n        this._duration = (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isOfflineAudioContext)(arguments[0]) ?\n            arguments[0].length / arguments[0].sampleRate : arguments[1];\n    }\n    /**\n     * Override the now method to point to the internal clock time\n     */\n    now() {\n        return this._currentTime;\n    }\n    /**\n     * Same as this.now()\n     */\n    get currentTime() {\n        return this._currentTime;\n    }\n    /**\n     * Render just the clock portion of the audio context.\n     */\n    _renderClock(asynchronous) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_4__.__awaiter)(this, void 0, void 0, function* () {\n            let index = 0;\n            while (this._duration - this._currentTime >= 0) {\n                // invoke all the callbacks on that time\n                this.emit(\"tick\");\n                // increment the clock in block-sized chunks\n                this._currentTime += 128 / this.sampleRate;\n                // yield once a second of audio\n                index++;\n                const yieldEvery = Math.floor(this.sampleRate / 128);\n                if (asynchronous && index % yieldEvery === 0) {\n                    yield new Promise(done => setTimeout(done, 1));\n                }\n            }\n        });\n    }\n    /**\n     * Render the output of the OfflineContext\n     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.\n     */\n    render(asynchronous = true) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_4__.__awaiter)(this, void 0, void 0, function* () {\n            yield this.workletsAreReady();\n            yield this._renderClock(asynchronous);\n            const buffer = yield this._context.startRendering();\n            return new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__.ToneAudioBuffer(buffer);\n        });\n    }\n    /**\n     * Close the context\n     */\n    close() {\n        return Promise.resolve();\n    }\n}\n//# sourceMappingURL=OfflineContext.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/OfflineContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/Param.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/Param.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Param\": () => (/* binding */ Param)\n/* harmony export */ });\n/* harmony import */ var _type_Conversions__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _ToneWithContext__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Math__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * Param wraps the native Web Audio's AudioParam to provide\n * additional unit conversion functionality. It also\n * serves as a base-class for classes which have a single,\n * automatable parameter.\n * @category Core\n */\nclass Param extends _ToneWithContext__WEBPACK_IMPORTED_MODULE_5__.ToneWithContext {\n    constructor() {\n        super((0,_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Param.getDefaults(), arguments, [\"param\", \"units\", \"convert\"]));\n        this.name = \"Param\";\n        this.overridden = false;\n        /**\n         * The minimum output value\n         */\n        this._minOutput = 1e-7;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Param.getDefaults(), arguments, [\"param\", \"units\", \"convert\"]);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(options.param) &&\n            ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioParam)(options.param) || options.param instanceof Param), \"param must be an AudioParam\");\n        while (!(0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_1__.isAudioParam)(options.param)) {\n            options.param = options.param._param;\n        }\n        this._swappable = (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(options.swappable) ? options.swappable : false;\n        if (this._swappable) {\n            this.input = this.context.createGain();\n            // initialize\n            this._param = options.param;\n            this.input.connect(this._param);\n        }\n        else {\n            this._param = this.input = options.param;\n        }\n        this._events = new _util_Timeline__WEBPACK_IMPORTED_MODULE_3__.Timeline(1000);\n        this._initialValue = this._param.defaultValue;\n        this.units = options.units;\n        this.convert = options.convert;\n        this._minValue = options.minValue;\n        this._maxValue = options.maxValue;\n        // if the value is defined, set it immediately\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(options.value) && options.value !== this._toType(this._initialValue)) {\n            this.setValueAtTime(options.value, 0);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(_ToneWithContext__WEBPACK_IMPORTED_MODULE_5__.ToneWithContext.getDefaults(), {\n            convert: true,\n            units: \"number\",\n        });\n    }\n    get value() {\n        const now = this.now();\n        return this.getValueAtTime(now);\n    }\n    set value(value) {\n        this.cancelScheduledValues(this.now());\n        this.setValueAtTime(value, this.now());\n    }\n    get minValue() {\n        // if it's not the default minValue, return it\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this._minValue)) {\n            return this._minValue;\n        }\n        else if (this.units === \"time\" || this.units === \"frequency\" ||\n            this.units === \"normalRange\" || this.units === \"positive\" ||\n            this.units === \"transportTime\" || this.units === \"ticks\" ||\n            this.units === \"bpm\" || this.units === \"hertz\" || this.units === \"samples\") {\n            return 0;\n        }\n        else if (this.units === \"audioRange\") {\n            return -1;\n        }\n        else if (this.units === \"decibels\") {\n            return -Infinity;\n        }\n        else {\n            return this._param.minValue;\n        }\n    }\n    get maxValue() {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this._maxValue)) {\n            return this._maxValue;\n        }\n        else if (this.units === \"normalRange\" ||\n            this.units === \"audioRange\") {\n            return 1;\n        }\n        else {\n            return this._param.maxValue;\n        }\n    }\n    /**\n     * Type guard based on the unit name\n     */\n    _is(arg, type) {\n        return this.units === type;\n    }\n    /**\n     * Make sure the value is always in the defined range\n     */\n    _assertRange(value) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this.maxValue) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(this.minValue)) {\n            (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(value, this._fromType(this.minValue), this._fromType(this.maxValue));\n        }\n        return value;\n    }\n    /**\n     * Convert the given value from the type specified by Param.units\n     * into the destination value (such as Gain or Frequency).\n     */\n    _fromType(val) {\n        if (this.convert && !this.overridden) {\n            if (this._is(val, \"time\")) {\n                return this.toSeconds(val);\n            }\n            else if (this._is(val, \"decibels\")) {\n                return (0,_type_Conversions__WEBPACK_IMPORTED_MODULE_0__.dbToGain)(val);\n            }\n            else if (this._is(val, \"frequency\")) {\n                return this.toFrequency(val);\n            }\n            else {\n                return val;\n            }\n        }\n        else if (this.overridden) {\n            // if it's overridden, should only schedule 0s\n            return 0;\n        }\n        else {\n            return val;\n        }\n    }\n    /**\n     * Convert the parameters value into the units specified by Param.units.\n     */\n    _toType(val) {\n        if (this.convert && this.units === \"decibels\") {\n            return (0,_type_Conversions__WEBPACK_IMPORTED_MODULE_0__.gainToDb)(val);\n        }\n        else {\n            return val;\n        }\n    }\n    //-------------------------------------\n    // ABSTRACT PARAM INTERFACE\n    // all docs are generated from ParamInterface.ts\n    //-------------------------------------\n    setValueAtTime(value, time) {\n        const computedTime = this.toSeconds(time);\n        const numericValue = this._fromType(value);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);\n        this._assertRange(numericValue);\n        this.log(this.units, \"setValueAtTime\", value, computedTime);\n        this._events.add({\n            time: computedTime,\n            type: \"setValueAtTime\",\n            value: numericValue,\n        });\n        this._param.setValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    getValueAtTime(time) {\n        const computedTime = Math.max(this.toSeconds(time), 0);\n        const after = this._events.getAfter(computedTime);\n        const before = this._events.get(computedTime);\n        let value = this._initialValue;\n        // if it was set by\n        if (before === null) {\n            value = this._initialValue;\n        }\n        else if (before.type === \"setTargetAtTime\" && (after === null || after.type === \"setValueAtTime\")) {\n            const previous = this._events.getBefore(before.time);\n            let previousVal;\n            if (previous === null) {\n                previousVal = this._initialValue;\n            }\n            else {\n                previousVal = previous.value;\n            }\n            if (before.type === \"setTargetAtTime\") {\n                value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);\n            }\n        }\n        else if (after === null) {\n            value = before.value;\n        }\n        else if (after.type === \"linearRampToValueAtTime\" || after.type === \"exponentialRampToValueAtTime\") {\n            let beforeValue = before.value;\n            if (before.type === \"setTargetAtTime\") {\n                const previous = this._events.getBefore(before.time);\n                if (previous === null) {\n                    beforeValue = this._initialValue;\n                }\n                else {\n                    beforeValue = previous.value;\n                }\n            }\n            if (after.type === \"linearRampToValueAtTime\") {\n                value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);\n            }\n            else {\n                value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);\n            }\n        }\n        else {\n            value = before.value;\n        }\n        return this._toType(value);\n    }\n    setRampPoint(time) {\n        time = this.toSeconds(time);\n        let currentVal = this.getValueAtTime(time);\n        this.cancelAndHoldAtTime(time);\n        if (this._fromType(currentVal) === 0) {\n            currentVal = this._toType(this._minOutput);\n        }\n        this.setValueAtTime(currentVal, time);\n        return this;\n    }\n    linearRampToValueAtTime(value, endTime) {\n        const numericValue = this._fromType(value);\n        const computedTime = this.toSeconds(endTime);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);\n        this._assertRange(numericValue);\n        this._events.add({\n            time: computedTime,\n            type: \"linearRampToValueAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"linearRampToValueAtTime\", value, computedTime);\n        this._param.linearRampToValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, endTime) {\n        let numericValue = this._fromType(value);\n        // the value can't be 0\n        numericValue = (0,_util_Math__WEBPACK_IMPORTED_MODULE_6__.EQ)(numericValue, 0) ? this._minOutput : numericValue;\n        this._assertRange(numericValue);\n        const computedTime = this.toSeconds(endTime);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);\n        // store the event\n        this._events.add({\n            time: computedTime,\n            type: \"exponentialRampToValueAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"exponentialRampToValueAtTime\", value, computedTime);\n        this._param.exponentialRampToValueAtTime(numericValue, computedTime);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        startTime = this.toSeconds(startTime);\n        this.setRampPoint(startTime);\n        this.exponentialApproachValueAtTime(value, startTime, rampTime);\n        return this;\n    }\n    exponentialApproachValueAtTime(value, time, rampTime) {\n        time = this.toSeconds(time);\n        rampTime = this.toSeconds(rampTime);\n        const timeConstant = Math.log(rampTime + 1) / Math.log(200);\n        this.setTargetAtTime(value, time, timeConstant);\n        // at 90% start a linear ramp to the final value\n        this.cancelAndHoldAtTime(time + rampTime * 0.9);\n        this.linearRampToValueAtTime(value, time + rampTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        const numericValue = this._fromType(value);\n        // The value will never be able to approach without timeConstant > 0.\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(timeConstant) && timeConstant > 0, \"timeConstant must be a number greater than 0\");\n        const computedTime = this.toSeconds(startTime);\n        this._assertRange(numericValue);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);\n        this._events.add({\n            constant: timeConstant,\n            time: computedTime,\n            type: \"setTargetAtTime\",\n            value: numericValue,\n        });\n        this.log(this.units, \"setTargetAtTime\", value, computedTime, timeConstant);\n        this._param.setTargetAtTime(numericValue, computedTime, timeConstant);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling = 1) {\n        duration = this.toSeconds(duration);\n        startTime = this.toSeconds(startTime);\n        const startingValue = this._fromType(values[0]) * scaling;\n        this.setValueAtTime(this._toType(startingValue), startTime);\n        const segTime = duration / (values.length - 1);\n        for (let i = 1; i < values.length; i++) {\n            const numericValue = this._fromType(values[i]) * scaling;\n            this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);\n        }\n        return this;\n    }\n    cancelScheduledValues(time) {\n        const computedTime = this.toSeconds(time);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);\n        this._events.cancel(computedTime);\n        this._param.cancelScheduledValues(computedTime);\n        this.log(this.units, \"cancelScheduledValues\", computedTime);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        const computedTime = this.toSeconds(time);\n        const valueAtTime = this._fromType(this.getValueAtTime(computedTime));\n        // remove the schedule events\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);\n        this.log(this.units, \"cancelAndHoldAtTime\", computedTime, \"value=\" + valueAtTime);\n        // if there is an event at the given computedTime\n        // and that even is not a \"set\"\n        const before = this._events.get(computedTime);\n        const after = this._events.getAfter(computedTime);\n        if (before && (0,_util_Math__WEBPACK_IMPORTED_MODULE_6__.EQ)(before.time, computedTime)) {\n            // remove everything after\n            if (after) {\n                this._param.cancelScheduledValues(after.time);\n                this._events.cancel(after.time);\n            }\n            else {\n                this._param.cancelAndHoldAtTime(computedTime);\n                this._events.cancel(computedTime + this.sampleTime);\n            }\n        }\n        else if (after) {\n            this._param.cancelScheduledValues(after.time);\n            // cancel the next event(s)\n            this._events.cancel(after.time);\n            if (after.type === \"linearRampToValueAtTime\") {\n                this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);\n            }\n            else if (after.type === \"exponentialRampToValueAtTime\") {\n                this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);\n            }\n        }\n        // set the value at the given time\n        this._events.add({\n            time: computedTime,\n            type: \"setValueAtTime\",\n            value: valueAtTime,\n        });\n        this._param.setValueAtTime(valueAtTime, computedTime);\n        return this;\n    }\n    rampTo(value, rampTime = 0.1, startTime) {\n        if (this.units === \"frequency\" || this.units === \"bpm\" || this.units === \"decibels\") {\n            this.exponentialRampTo(value, rampTime, startTime);\n        }\n        else {\n            this.linearRampTo(value, rampTime, startTime);\n        }\n        return this;\n    }\n    /**\n     * Apply all of the previously scheduled events to the passed in Param or AudioParam.\n     * The applied values will start at the context's current time and schedule\n     * all of the events which are scheduled on this Param onto the passed in param.\n     */\n    apply(param) {\n        const now = this.context.currentTime;\n        // set the param's value at the current time and schedule everything else\n        param.setValueAtTime(this.getValueAtTime(now), now);\n        // if the previous event was a curve, then set the rest of it\n        const previousEvent = this._events.get(now);\n        if (previousEvent && previousEvent.type === \"setTargetAtTime\") {\n            // approx it until the next event with linear ramps\n            const nextEvent = this._events.getAfter(previousEvent.time);\n            // or for 2 seconds if there is no event\n            const endTime = nextEvent ? nextEvent.time : now + 2;\n            const subdivisions = (endTime - now) / 10;\n            for (let i = now; i < endTime; i += subdivisions) {\n                param.linearRampToValueAtTime(this.getValueAtTime(i), i);\n            }\n        }\n        this._events.forEachAfter(this.context.currentTime, event => {\n            if (event.type === \"cancelScheduledValues\") {\n                param.cancelScheduledValues(event.time);\n            }\n            else if (event.type === \"setTargetAtTime\") {\n                param.setTargetAtTime(event.value, event.time, event.constant);\n            }\n            else {\n                param[event.type](event.value, event.time);\n            }\n        });\n        return this;\n    }\n    /**\n     * Replace the Param's internal AudioParam. Will apply scheduled curves\n     * onto the parameter and replace the connections.\n     */\n    setParam(param) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assert)(this._swappable, \"The Param must be assigned as 'swappable' in the constructor\");\n        const input = this.input;\n        input.disconnect(this._param);\n        this.apply(param);\n        this._param = param;\n        input.connect(this._param);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._events.dispose();\n        return this;\n    }\n    get defaultValue() {\n        return this._toType(this._param.defaultValue);\n    }\n    //-------------------------------------\n    // \tAUTOMATION CURVE CALCULATIONS\n    // \tMIT License, copyright (c) 2014 Jordan Santell\n    //-------------------------------------\n    // Calculates the the value along the curve produced by setTargetAtTime\n    _exponentialApproach(t0, v0, v1, timeConstant, t) {\n        return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);\n    }\n    // Calculates the the value along the curve produced by linearRampToValueAtTime\n    _linearInterpolate(t0, v0, t1, v1, t) {\n        return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));\n    }\n    // Calculates the the value along the curve produced by exponentialRampToValueAtTime\n    _exponentialInterpolate(t0, v0, t1, v1, t) {\n        return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));\n    }\n}\n//# sourceMappingURL=Param.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/Param.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioBuffer\": () => (/* binding */ ToneAudioBuffer)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all\n * classes that make requests for audio files such as Tone.Player,\n * Tone.Sampler and Tone.Convolver.\n * @example\n * const buffer = new Tone.ToneAudioBuffer(\"https://tonejs.github.io/audio/casio/A1.mp3\", () => {\n * \tconsole.log(\"loaded\");\n * });\n * @category Core\n */\nclass ToneAudioBuffer extends _Tone__WEBPACK_IMPORTED_MODULE_1__.Tone {\n    constructor() {\n        super();\n        this.name = \"ToneAudioBuffer\";\n        /**\n         * Callback when the buffer is loaded.\n         */\n        this.onload = _util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneAudioBuffer.getDefaults(), arguments, [\"url\", \"onload\", \"onerror\"]);\n        this.reverse = options.reverse;\n        this.onload = options.onload;\n        if (options.url && (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isAudioBuffer)(options.url) || options.url instanceof ToneAudioBuffer) {\n            this.set(options.url);\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isString)(options.url)) {\n            // initiate the download\n            this.load(options.url).catch(options.onerror);\n        }\n    }\n    static getDefaults() {\n        return {\n            onerror: _util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            onload: _util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            reverse: false,\n        };\n    }\n    /**\n     * The sample rate of the AudioBuffer\n     */\n    get sampleRate() {\n        if (this._buffer) {\n            return this._buffer.sampleRate;\n        }\n        else {\n            return (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().sampleRate;\n        }\n    }\n    /**\n     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.\n     */\n    set(buffer) {\n        if (buffer instanceof ToneAudioBuffer) {\n            // if it's loaded, set it\n            if (buffer.loaded) {\n                this._buffer = buffer.get();\n            }\n            else {\n                // otherwise when it's loaded, invoke it's callback\n                buffer.onload = () => {\n                    this.set(buffer);\n                    this.onload(this);\n                };\n            }\n        }\n        else {\n            this._buffer = buffer;\n        }\n        // reverse it initially\n        if (this._reversed) {\n            this._reverse();\n        }\n        return this;\n    }\n    /**\n     * The audio buffer stored in the object.\n     */\n    get() {\n        return this._buffer;\n    }\n    /**\n     * Makes an fetch request for the selected url then decodes the file as an audio buffer.\n     * Invokes the callback once the audio buffer loads.\n     * @param url The url of the buffer to load. filetype support depends on the browser.\n     * @returns A Promise which resolves with this ToneAudioBuffer\n     */\n    load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            const doneLoading = ToneAudioBuffer.load(url).then(audioBuffer => {\n                this.set(audioBuffer);\n                // invoke the onload method\n                this.onload(this);\n            });\n            ToneAudioBuffer.downloads.push(doneLoading);\n            try {\n                yield doneLoading;\n            }\n            finally {\n                // remove the downloaded file\n                const index = ToneAudioBuffer.downloads.indexOf(doneLoading);\n                ToneAudioBuffer.downloads.splice(index, 1);\n            }\n            return this;\n        });\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._buffer = undefined;\n        return this;\n    }\n    /**\n     * Set the audio buffer from the array.\n     * To create a multichannel AudioBuffer, pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     */\n    fromArray(array) {\n        const isMultidimensional = (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(array) && array[0].length > 0;\n        const channels = isMultidimensional ? array.length : 1;\n        const len = isMultidimensional ? array[0].length : array.length;\n        const context = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)();\n        const buffer = context.createBuffer(channels, len, context.sampleRate);\n        const multiChannelArray = !isMultidimensional && channels === 1 ?\n            [array] : array;\n        for (let c = 0; c < channels; c++) {\n            buffer.copyToChannel(multiChannelArray[c], c);\n        }\n        this._buffer = buffer;\n        return this;\n    }\n    /**\n     * Sums multiple channels into 1 channel\n     * @param chanNum Optionally only copy a single channel from the array.\n     */\n    toMono(chanNum) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(chanNum)) {\n            this.fromArray(this.toArray(chanNum));\n        }\n        else {\n            let outputArray = new Float32Array(this.length);\n            const numChannels = this.numberOfChannels;\n            for (let channel = 0; channel < numChannels; channel++) {\n                const channelArray = this.toArray(channel);\n                for (let i = 0; i < channelArray.length; i++) {\n                    outputArray[i] += channelArray[i];\n                }\n            }\n            // divide by the number of channels\n            outputArray = outputArray.map(sample => sample / numChannels);\n            this.fromArray(outputArray);\n        }\n        return this;\n    }\n    /**\n     * Get the buffer as an array. Single channel buffers will return a 1-dimensional\n     * Float32Array, and multichannel buffers will return multidimensional arrays.\n     * @param channel Optionally only copy a single channel from the array.\n     */\n    toArray(channel) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(channel)) {\n            return this.getChannelData(channel);\n        }\n        else if (this.numberOfChannels === 1) {\n            return this.toArray(0);\n        }\n        else {\n            const ret = [];\n            for (let c = 0; c < this.numberOfChannels; c++) {\n                ret[c] = this.getChannelData(c);\n            }\n            return ret;\n        }\n    }\n    /**\n     * Returns the Float32Array representing the PCM audio data for the specific channel.\n     * @param  channel  The channel number to return\n     * @return The audio as a TypedArray\n     */\n    getChannelData(channel) {\n        if (this._buffer) {\n            return this._buffer.getChannelData(channel);\n        }\n        else {\n            return new Float32Array(0);\n        }\n    }\n    /**\n     * Cut a subsection of the array and return a buffer of the\n     * subsection. Does not modify the original buffer\n     * @param start The time to start the slice\n     * @param end The end time to slice. If none is given will default to the end of the buffer\n     */\n    slice(start, end = this.duration) {\n        const startSamples = Math.floor(start * this.sampleRate);\n        const endSamples = Math.floor(end * this.sampleRate);\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(startSamples < endSamples, \"The start time must be less than the end time\");\n        const length = endSamples - startSamples;\n        const retBuffer = (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().createBuffer(this.numberOfChannels, length, this.sampleRate);\n        for (let channel = 0; channel < this.numberOfChannels; channel++) {\n            retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);\n        }\n        return new ToneAudioBuffer(retBuffer);\n    }\n    /**\n     * Reverse the buffer.\n     */\n    _reverse() {\n        if (this.loaded) {\n            for (let i = 0; i < this.numberOfChannels; i++) {\n                this.getChannelData(i).reverse();\n            }\n        }\n        return this;\n    }\n    /**\n     * If the buffer is loaded or not\n     */\n    get loaded() {\n        return this.length > 0;\n    }\n    /**\n     * The duration of the buffer in seconds.\n     */\n    get duration() {\n        if (this._buffer) {\n            return this._buffer.duration;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The length of the buffer in samples\n     */\n    get length() {\n        if (this._buffer) {\n            return this._buffer.length;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The number of discrete audio channels. Returns 0 if no buffer is loaded.\n     */\n    get numberOfChannels() {\n        if (this._buffer) {\n            return this._buffer.numberOfChannels;\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * Reverse the buffer.\n     */\n    get reverse() {\n        return this._reversed;\n    }\n    set reverse(rev) {\n        if (this._reversed !== rev) {\n            this._reversed = rev;\n            this._reverse();\n        }\n    }\n    /**\n     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,\n     * pass in a multidimensional array.\n     * @param array The array to fill the audio buffer\n     * @return A ToneAudioBuffer created from the array\n     */\n    static fromArray(array) {\n        return (new ToneAudioBuffer()).fromArray(array);\n    }\n    /**\n     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer\n     * @param  url The url to load.\n     * @return A promise which resolves to a ToneAudioBuffer\n     */\n    static fromUrl(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            const buffer = new ToneAudioBuffer();\n            return yield buffer.load(url);\n        });\n    }\n    /**\n     * Loads a url using fetch and returns the AudioBuffer.\n     */\n    static load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            // test if the url contains multiple extensions\n            const matches = url.match(/\\[([^\\]\\[]+\\|.+)\\]$/);\n            if (matches) {\n                const extensions = matches[1].split(\"|\");\n                let extension = extensions[0];\n                for (const ext of extensions) {\n                    if (ToneAudioBuffer.supportsType(ext)) {\n                        extension = ext;\n                        break;\n                    }\n                }\n                url = url.replace(matches[0], extension);\n            }\n            // make sure there is a slash between the baseUrl and the url\n            const baseUrl = ToneAudioBuffer.baseUrl === \"\" || ToneAudioBuffer.baseUrl.endsWith(\"/\") ? ToneAudioBuffer.baseUrl : ToneAudioBuffer.baseUrl + \"/\";\n            const response = yield fetch(baseUrl + url);\n            if (!response.ok) {\n                throw new Error(`could not load url: ${url}`);\n            }\n            const arrayBuffer = yield response.arrayBuffer();\n            const audioBuffer = yield (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().decodeAudioData(arrayBuffer);\n            return audioBuffer;\n        });\n    }\n    /**\n     * Checks a url's extension to see if the current browser can play that file type.\n     * @param url The url/extension to test\n     * @return If the file extension can be played\n     * @static\n     * @example\n     * Tone.ToneAudioBuffer.supportsType(\"wav\"); // returns true\n     * Tone.ToneAudioBuffer.supportsType(\"path/to/file.wav\"); // returns true\n     */\n    static supportsType(url) {\n        const extensions = url.split(\".\");\n        const extension = extensions[extensions.length - 1];\n        const response = document.createElement(\"audio\").canPlayType(\"audio/\" + extension);\n        return response !== \"\";\n    }\n    /**\n     * Returns a Promise which resolves when all of the buffers have loaded\n     */\n    static loaded() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            // this makes sure that the function is always async\n            yield Promise.resolve();\n            while (ToneAudioBuffer.downloads.length) {\n                yield ToneAudioBuffer.downloads[0];\n            }\n        });\n    }\n}\n//-------------------------------------\n// STATIC METHODS\n//-------------------------------------\n/**\n * A path which is prefixed before every url.\n */\nToneAudioBuffer.baseUrl = \"\";\n/**\n * All of the downloads\n */\nToneAudioBuffer.downloads = [];\n//# sourceMappingURL=ToneAudioBuffer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioBuffers\": () => (/* binding */ ToneAudioBuffers)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n/**\n * A data structure for holding multiple buffers in a Map-like datastructure.\n *\n * @example\n * const pianoSamples = new Tone.ToneAudioBuffers({\n * \tA1: \"https://tonejs.github.io/audio/casio/A1.mp3\",\n * \tA2: \"https://tonejs.github.io/audio/casio/A2.mp3\",\n * }, () => {\n * \tconst player = new Tone.Player().toDestination();\n * \t// play one of the samples when they all load\n * \tplayer.buffer = pianoSamples.get(\"A2\");\n * \tplayer.start();\n * });\n * @example\n * // To pass in additional parameters in the second parameter\n * const buffers = new Tone.ToneAudioBuffers({\n * \t urls: {\n * \t\t A1: \"A1.mp3\",\n * \t\t A2: \"A2.mp3\",\n * \t },\n * \t onload: () => console.log(\"loaded\"),\n * \t baseUrl: \"https://tonejs.github.io/audio/casio/\"\n * });\n * @category Core\n */\nclass ToneAudioBuffers extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super();\n        this.name = \"ToneAudioBuffers\";\n        /**\n         * All of the buffers\n         */\n        this._buffers = new Map();\n        /**\n         * Keep track of the number of loaded buffers\n         */\n        this._loadingCount = 0;\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(ToneAudioBuffers.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\");\n        this.baseUrl = options.baseUrl;\n        // add each one\n        Object.keys(options.urls).forEach(name => {\n            this._loadingCount++;\n            const url = options.urls[name];\n            this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);\n        });\n    }\n    static getDefaults() {\n        return {\n            baseUrl: \"\",\n            onerror: _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            onload: _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            urls: {},\n        };\n    }\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param  name  The key or index of the buffer.\n     */\n    has(name) {\n        return this._buffers.has(name.toString());\n    }\n    /**\n     * Get a buffer by name. If an array was loaded,\n     * then use the array index.\n     * @param  name  The key or index of the buffer.\n     */\n    get(name) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);\n        return this._buffers.get(name.toString());\n    }\n    /**\n     * A buffer was loaded. decrement the counter.\n     */\n    _bufferLoaded(callback) {\n        this._loadingCount--;\n        if (this._loadingCount === 0 && callback) {\n            callback();\n        }\n    }\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded() {\n        return Array.from(this._buffers).every(([_, buffer]) => buffer.loaded);\n    }\n    /**\n     * Add a buffer by name and url to the Buffers\n     * @param  name      A unique name to give the buffer\n     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     * @param  onerror  Invoked if the buffer can't be loaded\n     */\n    add(name, url, callback = _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp, onerror = _util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__.isString)(url)) {\n            this._buffers.set(name.toString(), new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_4__.ToneAudioBuffer(this.baseUrl + url, callback, onerror));\n        }\n        else {\n            this._buffers.set(name.toString(), new _ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_4__.ToneAudioBuffer(url, callback, onerror));\n        }\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._buffers.forEach(buffer => buffer.dispose());\n        this._buffers.clear();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneAudioBuffers.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneAudioNode.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneAudioNode.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioNode\": () => (/* binding */ ToneAudioNode),\n/* harmony export */   \"connect\": () => (/* binding */ connect),\n/* harmony export */   \"connectSeries\": () => (/* binding */ connectSeries),\n/* harmony export */   \"disconnect\": () => (/* binding */ disconnect)\n/* harmony export */ });\n/* harmony import */ var _util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Param__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _ToneWithContext__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n/**\n * ToneAudioNode is the base class for classes which process audio.\n */\nclass ToneAudioNode extends _ToneWithContext__WEBPACK_IMPORTED_MODULE_3__.ToneWithContext {\n    constructor() {\n        super(...arguments);\n        /**\n         * The name of the class\n         */\n        this.name = \"ToneAudioNode\";\n        /**\n         * List all of the node that must be set to match the ChannelProperties\n         */\n        this._internalChannels = [];\n    }\n    /**\n     * The number of inputs feeding into the AudioNode.\n     * For source nodes, this will be 0.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfInputs);\n     */\n    get numberOfInputs() {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.input)) {\n            if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(this.input) || this.input instanceof _Param__WEBPACK_IMPORTED_MODULE_2__.Param) {\n                return 1;\n            }\n            else {\n                return this.input.numberOfInputs;\n            }\n        }\n        else {\n            return 0;\n        }\n    }\n    /**\n     * The number of outputs of the AudioNode.\n     * @example\n     * const node = new Tone.Gain();\n     * console.log(node.numberOfOutputs);\n     */\n    get numberOfOutputs() {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.output)) {\n            return this.output.numberOfOutputs;\n        }\n        else {\n            return 0;\n        }\n    }\n    //-------------------------------------\n    // AUDIO PROPERTIES\n    //-------------------------------------\n    /**\n     * Used to decide which nodes to get/set properties on\n     */\n    _isAudioNode(node) {\n        return (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(node) && (node instanceof ToneAudioNode || (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(node));\n    }\n    /**\n     * Get all of the audio nodes (either internal or input/output) which together\n     * make up how the class node responds to channel input/output\n     */\n    _getInternalNodes() {\n        const nodeList = this._internalChannels.slice(0);\n        if (this._isAudioNode(this.input)) {\n            nodeList.push(this.input);\n        }\n        if (this._isAudioNode(this.output)) {\n            if (this.input !== this.output) {\n                nodeList.push(this.output);\n            }\n        }\n        return nodeList;\n    }\n    /**\n     * Set the audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     * @param options\n     */\n    _setChannelProperties(options) {\n        const nodeList = this._getInternalNodes();\n        nodeList.forEach(node => {\n            node.channelCount = options.channelCount;\n            node.channelCountMode = options.channelCountMode;\n            node.channelInterpretation = options.channelInterpretation;\n        });\n    }\n    /**\n     * Get the current audio options for this node such as channelInterpretation\n     * channelCount, etc.\n     */\n    _getChannelProperties() {\n        const nodeList = this._getInternalNodes();\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(nodeList.length > 0, \"ToneAudioNode does not have any internal nodes\");\n        // use the first node to get properties\n        // they should all be the same\n        const node = nodeList[0];\n        return {\n            channelCount: node.channelCount,\n            channelCountMode: node.channelCountMode,\n            channelInterpretation: node.channelInterpretation,\n        };\n    }\n    /**\n     * channelCount is the number of channels used when up-mixing and down-mixing\n     * connections to any inputs to the node. The default value is 2 except for\n     * specific nodes where its value is specially determined.\n     */\n    get channelCount() {\n        return this._getChannelProperties().channelCount;\n    }\n    set channelCount(channelCount) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelCount }));\n    }\n    /**\n     * channelCountMode determines how channels will be counted when up-mixing and\n     * down-mixing connections to any inputs to the node.\n     * The default value is \"max\". This attribute has no effect for nodes with no inputs.\n     * * \"max\" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.\n     * * \"clamped-max\" - computedNumberOfChannels is determined as for \"max\" and then clamped to a maximum value of the given channelCount.\n     * * \"explicit\" - computedNumberOfChannels is the exact value as specified by the channelCount.\n     */\n    get channelCountMode() {\n        return this._getChannelProperties().channelCountMode;\n    }\n    set channelCountMode(channelCountMode) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelCountMode }));\n    }\n    /**\n     * channelInterpretation determines how individual channels will be treated\n     * when up-mixing and down-mixing connections to any inputs to the node.\n     * The default value is \"speakers\".\n     */\n    get channelInterpretation() {\n        return this._getChannelProperties().channelInterpretation;\n    }\n    set channelInterpretation(channelInterpretation) {\n        const props = this._getChannelProperties();\n        // merge it with the other properties\n        this._setChannelProperties(Object.assign(props, { channelInterpretation }));\n    }\n    //-------------------------------------\n    // CONNECTIONS\n    //-------------------------------------\n    /**\n     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode\n     * @param destination The output to connect to\n     * @param outputNum The output to connect from\n     * @param inputNum The input to connect to\n     */\n    connect(destination, outputNum = 0, inputNum = 0) {\n        connect(this, destination, outputNum, inputNum);\n        return this;\n    }\n    /**\n     * Connect the output to the context's destination node.\n     * @example\n     * const osc = new Tone.Oscillator(\"C2\").start();\n     * osc.toDestination();\n     */\n    toDestination() {\n        this.connect(this.context.destination);\n        return this;\n    }\n    /**\n     * Connect the output to the context's destination node.\n     * See [[toDestination]]\n     * @deprecated\n     */\n    toMaster() {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.warn)(\"toMaster() has been renamed toDestination()\");\n        return this.toDestination();\n    }\n    /**\n     * disconnect the output\n     */\n    disconnect(destination, outputNum = 0, inputNum = 0) {\n        disconnect(this, destination, outputNum, inputNum);\n        return this;\n    }\n    /**\n     * Connect the output of this node to the rest of the nodes in series.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3\");\n     * player.autostart = true;\n     * const filter = new Tone.AutoFilter(4).start();\n     * const distortion = new Tone.Distortion(0.5);\n     * // connect the player to the filter, distortion and then to the master output\n     * player.chain(filter, distortion, Tone.Destination);\n     */\n    chain(...nodes) {\n        connectSeries(this, ...nodes);\n        return this;\n    }\n    /**\n     * connect the output of this node to the rest of the nodes in parallel.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3\");\n     * player.autostart = true;\n     * const pitchShift = new Tone.PitchShift(4).toDestination();\n     * const filter = new Tone.Filter(\"G5\").toDestination();\n     * // connect a node to the pitch shift and filter in parallel\n     * player.fan(pitchShift, filter);\n     */\n    fan(...nodes) {\n        nodes.forEach(node => this.connect(node));\n        return this;\n    }\n    /**\n     * Dispose and disconnect\n     */\n    dispose() {\n        super.dispose();\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.input)) {\n            if (this.input instanceof ToneAudioNode) {\n                this.input.dispose();\n            }\n            else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(this.input)) {\n                this.input.disconnect();\n            }\n        }\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this.output)) {\n            if (this.output instanceof ToneAudioNode) {\n                this.output.dispose();\n            }\n            else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(this.output)) {\n                this.output.disconnect();\n            }\n        }\n        this._internalChannels = [];\n        return this;\n    }\n}\n//-------------------------------------\n// CONNECTIONS\n//-------------------------------------\n/**\n * connect together all of the arguments in series\n * @param nodes\n */\nfunction connectSeries(...nodes) {\n    const first = nodes.shift();\n    nodes.reduce((prev, current) => {\n        if (prev instanceof ToneAudioNode) {\n            prev.connect(current);\n        }\n        else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(prev)) {\n            connect(prev, current);\n        }\n        return current;\n    }, first);\n}\n/**\n * Connect two nodes together so that signal flows from the\n * first node to the second. Optionally specify the input and output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nfunction connect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(srcNode), \"Cannot connect from undefined node\");\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(dstNode), \"Cannot connect to undefined node\");\n    if (dstNode instanceof ToneAudioNode || (0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(dstNode)) {\n        (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(dstNode.numberOfInputs > 0, \"Cannot connect to node with no inputs\");\n    }\n    (0,_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(srcNode.numberOfOutputs > 0, \"Cannot connect from node with no outputs\");\n    // resolve the input of the dstNode\n    while ((dstNode instanceof ToneAudioNode || dstNode instanceof _Param__WEBPACK_IMPORTED_MODULE_2__.Param)) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(dstNode.input)) {\n            dstNode = dstNode.input;\n        }\n    }\n    while (srcNode instanceof ToneAudioNode) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(srcNode.output)) {\n            srcNode = srcNode.output;\n        }\n    }\n    // make the connection\n    if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(dstNode)) {\n        srcNode.connect(dstNode, outputNumber);\n    }\n    else {\n        srcNode.connect(dstNode, outputNumber, inputNumber);\n    }\n}\n/**\n * Disconnect a node from all nodes or optionally include a destination node and input/output channels.\n * @param srcNode The source node\n * @param dstNode The destination node\n * @param outputNumber The output channel of the srcNode\n * @param inputNumber The input channel of the dstNode\n */\nfunction disconnect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {\n    // resolve the destination node\n    if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(dstNode)) {\n        while (dstNode instanceof ToneAudioNode) {\n            dstNode = dstNode.input;\n        }\n    }\n    // resolve the src node\n    while (!((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(srcNode))) {\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(srcNode.output)) {\n            srcNode = srcNode.output;\n        }\n    }\n    if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(dstNode)) {\n        srcNode.disconnect(dstNode, outputNumber);\n    }\n    else if ((0,_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(dstNode)) {\n        srcNode.disconnect(dstNode, outputNumber, inputNumber);\n    }\n    else {\n        srcNode.disconnect();\n    }\n}\n//# sourceMappingURL=ToneAudioNode.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/ToneAudioNode.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/context/ToneWithContext.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/context/ToneWithContext.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneWithContext\": () => (/* binding */ ToneWithContext)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _type_Frequency__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _type_Time__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../type/Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n/* harmony import */ var _type_TransportTime__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n\n\n\n/**\n * The Base class for all nodes that have an AudioContext.\n */\nclass ToneWithContext extends _Tone__WEBPACK_IMPORTED_MODULE_1__.Tone {\n    constructor() {\n        super();\n        const options = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_5__.optionsFromArguments)(ToneWithContext.getDefaults(), arguments, [\"context\"]);\n        if (this.defaultContext) {\n            this.context = this.defaultContext;\n        }\n        else {\n            this.context = options.context;\n        }\n    }\n    static getDefaults() {\n        return {\n            context: (0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(),\n        };\n    }\n    /**\n     * Return the current time of the Context clock plus the lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.now());\n     * }, 100);\n     */\n    now() {\n        return this.context.currentTime + this.context.lookAhead;\n    }\n    /**\n     * Return the current time of the Context clock without any lookAhead.\n     * @example\n     * setInterval(() => {\n     * \tconsole.log(Tone.immediate());\n     * }, 100);\n     */\n    immediate() {\n        return this.context.currentTime;\n    }\n    /**\n     * The duration in seconds of one sample.\n     * @example\n     * console.log(Tone.Transport.sampleTime);\n     */\n    get sampleTime() {\n        return 1 / this.context.sampleRate;\n    }\n    /**\n     * The number of seconds of 1 processing block (128 samples)\n     * @example\n     * console.log(Tone.Destination.blockTime);\n     */\n    get blockTime() {\n        return 128 / this.context.sampleRate;\n    }\n    /**\n     * Convert the incoming time to seconds.\n     * This is calculated against the current [[Tone.Transport]] bpm\n     * @example\n     * const gain = new Tone.Gain();\n     * setInterval(() => console.log(gain.toSeconds(\"4n\")), 100);\n     * // ramp the tempo to 60 bpm over 30 seconds\n     * Tone.getTransport().bpm.rampTo(60, 30);\n     */\n    toSeconds(time) {\n        return new _type_Time__WEBPACK_IMPORTED_MODULE_3__.TimeClass(this.context, time).toSeconds();\n    }\n    /**\n     * Convert the input to a frequency number\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toFrequency(\"4n\"));\n     */\n    toFrequency(freq) {\n        return new _type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, freq).toFrequency();\n    }\n    /**\n     * Convert the input time into ticks\n     * @example\n     * const gain = new Tone.Gain();\n     * console.log(gain.toTicks(\"4n\"));\n     */\n    toTicks(time) {\n        return new _type_TransportTime__WEBPACK_IMPORTED_MODULE_4__.TransportTimeClass(this.context, time).toTicks();\n    }\n    //-------------------------------------\n    // \tGET/SET\n    //-------------------------------------\n    /**\n     * Get a subset of the properties which are in the partial props\n     */\n    _getPartialProperties(props) {\n        const options = this.get();\n        // remove attributes from the prop that are not in the partial\n        Object.keys(options).forEach(name => {\n            if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isUndef)(props[name])) {\n                delete options[name];\n            }\n        });\n        return options;\n    }\n    /**\n     * Get the object's attributes.\n     * @example\n     * const osc = new Tone.Oscillator();\n     * console.log(osc.get());\n     */\n    get() {\n        const defaults = (0,_util_Defaults__WEBPACK_IMPORTED_MODULE_5__.getDefaultsFromInstance)(this);\n        Object.keys(defaults).forEach(attribute => {\n            if (Reflect.has(this, attribute)) {\n                const member = this[attribute];\n                if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(member) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(member.value) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(member.setValueAtTime)) {\n                    defaults[attribute] = member.value;\n                }\n                else if (member instanceof ToneWithContext) {\n                    defaults[attribute] = member._getPartialProperties(defaults[attribute]);\n                    // otherwise make sure it's a serializable type\n                }\n                else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isArray)(member) || (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isNumber)(member) || (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isString)(member) || (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isBoolean)(member)) {\n                    defaults[attribute] = member;\n                }\n                else {\n                    // remove all undefined and unserializable attributes\n                    delete defaults[attribute];\n                }\n            }\n        });\n        return defaults;\n    }\n    /**\n     * Set multiple properties at once with an object.\n     * @example\n     * const filter = new Tone.Filter().toDestination();\n     * // set values using an object\n     * filter.set({\n     * \tfrequency: \"C6\",\n     * \ttype: \"highpass\"\n     * });\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3\").connect(filter);\n     * player.autostart = true;\n     */\n    set(props) {\n        Object.keys(props).forEach(attribute => {\n            if (Reflect.has(this, attribute) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(this[attribute])) {\n                if (this[attribute] && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(this[attribute].value) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isDefined)(this[attribute].setValueAtTime)) {\n                    // small optimization\n                    if (this[attribute].value !== props[attribute]) {\n                        this[attribute].value = props[attribute];\n                    }\n                }\n                else if (this[attribute] instanceof ToneWithContext) {\n                    this[attribute].set(props[attribute]);\n                }\n                else {\n                    this[attribute] = props[attribute];\n                }\n            }\n        });\n        return this;\n    }\n}\n//# sourceMappingURL=ToneWithContext.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/context/ToneWithContext.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/index.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/core/index.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BaseContext\": () => (/* reexport safe */ _context_BaseContext__WEBPACK_IMPORTED_MODULE_2__.BaseContext),\n/* harmony export */   \"Clock\": () => (/* reexport safe */ _clock_Clock__WEBPACK_IMPORTED_MODULE_0__.Clock),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _context_Context__WEBPACK_IMPORTED_MODULE_1__.Context),\n/* harmony export */   \"Delay\": () => (/* reexport safe */ _context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay),\n/* harmony export */   \"Emitter\": () => (/* reexport safe */ _util_Emitter__WEBPACK_IMPORTED_MODULE_17__.Emitter),\n/* harmony export */   \"Frequency\": () => (/* reexport safe */ _type_Frequency__WEBPACK_IMPORTED_MODULE_11__.Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* reexport safe */ _type_Frequency__WEBPACK_IMPORTED_MODULE_11__.FrequencyClass),\n/* harmony export */   \"Gain\": () => (/* reexport safe */ _context_Gain__WEBPACK_IMPORTED_MODULE_4__.Gain),\n/* harmony export */   \"IntervalTimeline\": () => (/* reexport safe */ _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_18__.IntervalTimeline),\n/* harmony export */   \"Midi\": () => (/* reexport safe */ _type_Midi__WEBPACK_IMPORTED_MODULE_12__.Midi),\n/* harmony export */   \"MidiClass\": () => (/* reexport safe */ _type_Midi__WEBPACK_IMPORTED_MODULE_12__.MidiClass),\n/* harmony export */   \"Offline\": () => (/* reexport safe */ _context_Offline__WEBPACK_IMPORTED_MODULE_5__.Offline),\n/* harmony export */   \"OfflineContext\": () => (/* reexport safe */ _context_OfflineContext__WEBPACK_IMPORTED_MODULE_6__.OfflineContext),\n/* harmony export */   \"Param\": () => (/* reexport safe */ _context_Param__WEBPACK_IMPORTED_MODULE_7__.Param),\n/* harmony export */   \"StateTimeline\": () => (/* reexport safe */ _util_StateTimeline__WEBPACK_IMPORTED_MODULE_19__.StateTimeline),\n/* harmony export */   \"Ticks\": () => (/* reexport safe */ _type_Ticks__WEBPACK_IMPORTED_MODULE_14__.Ticks),\n/* harmony export */   \"TicksClass\": () => (/* reexport safe */ _type_Ticks__WEBPACK_IMPORTED_MODULE_14__.TicksClass),\n/* harmony export */   \"Time\": () => (/* reexport safe */ _type_Time__WEBPACK_IMPORTED_MODULE_13__.Time),\n/* harmony export */   \"TimeClass\": () => (/* reexport safe */ _type_Time__WEBPACK_IMPORTED_MODULE_13__.TimeClass),\n/* harmony export */   \"Timeline\": () => (/* reexport safe */ _util_Timeline__WEBPACK_IMPORTED_MODULE_20__.Timeline),\n/* harmony export */   \"ToneAudioBuffer\": () => (/* reexport safe */ _context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_8__.ToneAudioBuffer),\n/* harmony export */   \"ToneAudioBuffers\": () => (/* reexport safe */ _context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_9__.ToneAudioBuffers),\n/* harmony export */   \"ToneAudioNode\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.ToneAudioNode),\n/* harmony export */   \"TransportTime\": () => (/* reexport safe */ _type_TransportTime__WEBPACK_IMPORTED_MODULE_15__.TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* reexport safe */ _type_TransportTime__WEBPACK_IMPORTED_MODULE_15__.TransportTimeClass),\n/* harmony export */   \"Unit\": () => (/* reexport module object */ _type_Units__WEBPACK_IMPORTED_MODULE_24__),\n/* harmony export */   \"connect\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.connect),\n/* harmony export */   \"connectSeries\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.connectSeries),\n/* harmony export */   \"dbToGain\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.dbToGain),\n/* harmony export */   \"debug\": () => (/* reexport module object */ _util_Debug__WEBPACK_IMPORTED_MODULE_25__),\n/* harmony export */   \"defaultArg\": () => (/* reexport safe */ _util_Defaults__WEBPACK_IMPORTED_MODULE_23__.defaultArg),\n/* harmony export */   \"disconnect\": () => (/* reexport safe */ _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__.disconnect),\n/* harmony export */   \"ftom\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.ftom),\n/* harmony export */   \"gainToDb\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.gainToDb),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.intervalToFrequencyRatio),\n/* harmony export */   \"isArray\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isArray),\n/* harmony export */   \"isBoolean\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isBoolean),\n/* harmony export */   \"isDefined\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isDefined),\n/* harmony export */   \"isFunction\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isFunction),\n/* harmony export */   \"isNote\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isNote),\n/* harmony export */   \"isNumber\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isNumber),\n/* harmony export */   \"isObject\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isObject),\n/* harmony export */   \"isString\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isString),\n/* harmony export */   \"isUndef\": () => (/* reexport safe */ _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__.isUndef),\n/* harmony export */   \"mtof\": () => (/* reexport safe */ _type_Conversions__WEBPACK_IMPORTED_MODULE_22__.mtof),\n/* harmony export */   \"optionsFromArguments\": () => (/* reexport safe */ _util_Defaults__WEBPACK_IMPORTED_MODULE_23__.optionsFromArguments)\n/* harmony export */ });\n/* harmony import */ var _clock_Clock__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./clock/Clock */ \"./node_modules/tone/build/esm/core/clock/Clock.js\");\n/* harmony import */ var _context_Context__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./context/Context */ \"./node_modules/tone/build/esm/core/context/Context.js\");\n/* harmony import */ var _context_BaseContext__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./context/BaseContext */ \"./node_modules/tone/build/esm/core/context/BaseContext.js\");\n/* harmony import */ var _context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _context_Gain__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _context_Offline__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./context/Offline */ \"./node_modules/tone/build/esm/core/context/Offline.js\");\n/* harmony import */ var _context_OfflineContext__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _context_Param__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _type_Frequency__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _type_Midi__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./type/Midi */ \"./node_modules/tone/build/esm/core/type/Midi.js\");\n/* harmony import */ var _type_Time__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./type/Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n/* harmony import */ var _type_Ticks__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _type_TransportTime__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _util_Draw__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./util/Draw */ \"./node_modules/tone/build/esm/core/util/Draw.js\");\n/* harmony import */ var _util_Emitter__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./util/Emitter */ \"./node_modules/tone/build/esm/core/util/Emitter.js\");\n/* harmony import */ var _util_IntervalTimeline__WEBPACK_IMPORTED_MODULE_18__ = __webpack_require__(/*! ./util/IntervalTimeline */ \"./node_modules/tone/build/esm/core/util/IntervalTimeline.js\");\n/* harmony import */ var _util_StateTimeline__WEBPACK_IMPORTED_MODULE_19__ = __webpack_require__(/*! ./util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _util_Timeline__WEBPACK_IMPORTED_MODULE_20__ = __webpack_require__(/*! ./util/Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_21__ = __webpack_require__(/*! ./util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _type_Conversions__WEBPACK_IMPORTED_MODULE_22__ = __webpack_require__(/*! ./type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _util_Defaults__WEBPACK_IMPORTED_MODULE_23__ = __webpack_require__(/*! ./util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _type_Units__WEBPACK_IMPORTED_MODULE_24__ = __webpack_require__(/*! ./type/Units */ \"./node_modules/tone/build/esm/core/type/Units.js\");\n/* harmony import */ var _util_Debug__WEBPACK_IMPORTED_MODULE_25__ = __webpack_require__(/*! ./util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n// export * from \"./clock/Transport\";\n\n\n\n// export * from \"./context/Destination\";\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n// get the units and export them under the \"Unit\" namespace\n\n\n// export the debug stuff as Debug\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Conversions.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Conversions.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"dbToGain\": () => (/* binding */ dbToGain),\n/* harmony export */   \"equalPowerScale\": () => (/* binding */ equalPowerScale),\n/* harmony export */   \"ftom\": () => (/* binding */ ftom),\n/* harmony export */   \"ftomf\": () => (/* binding */ ftomf),\n/* harmony export */   \"gainToDb\": () => (/* binding */ gainToDb),\n/* harmony export */   \"getA4\": () => (/* binding */ getA4),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* binding */ intervalToFrequencyRatio),\n/* harmony export */   \"mtof\": () => (/* binding */ mtof),\n/* harmony export */   \"setA4\": () => (/* binding */ setA4)\n/* harmony export */ });\n/**\n * Equal power gain scale. Good for cross-fading.\n * @param  percent (0-1)\n */\nfunction equalPowerScale(percent) {\n    const piFactor = 0.5 * Math.PI;\n    return Math.sin(percent * piFactor);\n}\n/**\n * Convert decibels into gain.\n */\nfunction dbToGain(db) {\n    return Math.pow(10, db / 20);\n}\n/**\n * Convert gain to decibels.\n */\nfunction gainToDb(gain) {\n    return 20 * (Math.log(gain) / Math.LN10);\n}\n/**\n * Convert an interval (in semitones) to a frequency ratio.\n * @param interval the number of semitones above the base note\n * @example\n * Tone.intervalToFrequencyRatio(0); // 1\n * Tone.intervalToFrequencyRatio(12); // 2\n * Tone.intervalToFrequencyRatio(-12); // 0.5\n */\nfunction intervalToFrequencyRatio(interval) {\n    return Math.pow(2, (interval / 12));\n}\n/**\n * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n * to generate all the other pitch values from notes. A4's values in Hertz.\n */\nlet A4 = 440;\nfunction getA4() {\n    return A4;\n}\nfunction setA4(freq) {\n    A4 = freq;\n}\n/**\n * Convert a frequency value to a MIDI note.\n * @param frequency The value to frequency value to convert.\n * @example\n * Tone.ftom(440); // returns 69\n */\nfunction ftom(frequency) {\n    return Math.round(ftomf(frequency));\n}\n/**\n * Convert a frequency to a floating point midi value\n */\nfunction ftomf(frequency) {\n    return 69 + 12 * Math.log2(frequency / A4);\n}\n/**\n * Convert a MIDI note to frequency value.\n * @param  midi The midi number to convert.\n * @return The corresponding frequency value\n * @example\n * Tone.mtof(69); // 440\n */\nfunction mtof(midi) {\n    return A4 * Math.pow(2, (midi - 69) / 12);\n}\n//# sourceMappingURL=Conversions.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/Conversions.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Frequency.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Frequency.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Frequency\": () => (/* binding */ Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* binding */ FrequencyClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _Time__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n\n\n\n\n/**\n * Frequency is a primitive type for encoding Frequency values.\n * Eventually all time values are evaluated to hertz using the `valueOf` method.\n * @example\n * Tone.Frequency(\"C3\"); // 261\n * Tone.Frequency(38, \"midi\");\n * Tone.Frequency(\"C3\").transpose(4);\n * @category Unit\n */\nclass FrequencyClass extends _Time__WEBPACK_IMPORTED_MODULE_2__.TimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"Frequency\";\n        this.defaultUnits = \"hz\";\n    }\n    /**\n     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used\n     * to generate all the other pitch values from notes. A4's values in Hertz.\n     */\n    static get A4() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.getA4)();\n    }\n    static set A4(freq) {\n        (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.setA4)(freq);\n    }\n    //-------------------------------------\n    // \tAUGMENT BASE EXPRESSIONS\n    //-------------------------------------\n    _getExpressions() {\n        return Object.assign({}, super._getExpressions(), {\n            midi: {\n                regexp: /^(\\d+(?:\\.\\d+)?midi)/,\n                method(value) {\n                    if (this.defaultUnits === \"midi\") {\n                        return value;\n                    }\n                    else {\n                        return FrequencyClass.mtof(value);\n                    }\n                },\n            },\n            note: {\n                regexp: /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,\n                method(pitch, octave) {\n                    const index = noteToScaleIndex[pitch.toLowerCase()];\n                    const noteNumber = index + (parseInt(octave, 10) + 1) * 12;\n                    if (this.defaultUnits === \"midi\") {\n                        return noteNumber;\n                    }\n                    else {\n                        return FrequencyClass.mtof(noteNumber);\n                    }\n                },\n            },\n            tr: {\n                regexp: /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?/,\n                method(m, q, s) {\n                    let total = 1;\n                    if (m && m !== \"0\") {\n                        total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n                    }\n                    if (q && q !== \"0\") {\n                        total *= this._beatsToUnits(parseFloat(q));\n                    }\n                    if (s && s !== \"0\") {\n                        total *= this._beatsToUnits(parseFloat(s) / 4);\n                    }\n                    return total;\n                },\n            },\n        });\n    }\n    //-------------------------------------\n    // \tEXPRESSIONS\n    //-------------------------------------\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return  A new transposed frequency\n     * @example\n     * Tone.Frequency(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval) {\n        return new FrequencyClass(this.context, this.valueOf() * (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.intervalToFrequencyRatio)(interval));\n    }\n    /**\n     * Takes an array of semitone intervals and returns\n     * an array of frequencies transposed by those intervals.\n     * @return  Returns an array of Frequencies\n     * @example\n     * Tone.Frequency(\"A4\").harmonize([0, 3, 7]); // [\"A4\", \"C5\", \"E5\"]\n     */\n    harmonize(intervals) {\n        return intervals.map(interval => {\n            return this.transpose(interval);\n        });\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS\n    //-------------------------------------\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Frequency(\"C4\").toMidi(); // 60\n     */\n    toMidi() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(this.valueOf());\n    }\n    /**\n     * Return the value of the frequency in Scientific Pitch Notation\n     * @example\n     * Tone.Frequency(69, \"midi\").toNote(); // \"A4\"\n     */\n    toNote() {\n        const freq = this.toFrequency();\n        const log = Math.log2(freq / FrequencyClass.A4);\n        let noteNumber = Math.round(12 * log) + 57;\n        const octave = Math.floor(noteNumber / 12);\n        if (octave < 0) {\n            noteNumber += -12 * octave;\n        }\n        const noteName = scaleIndexToNote[noteNumber % 12];\n        return noteName + octave.toString();\n    }\n    /**\n     * Return the duration of one cycle in seconds.\n     */\n    toSeconds() {\n        return 1 / super.toSeconds();\n    }\n    /**\n     * Return the duration of one cycle in ticks\n     */\n    toTicks() {\n        const quarterTime = this._beatsToUnits(1);\n        const quarters = this.valueOf() / quarterTime;\n        return Math.floor(quarters * this._getPPQ());\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS HELPERS\n    //-------------------------------------\n    /**\n     * With no arguments, return 0\n     */\n    _noArg() {\n        return 0;\n    }\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return freq;\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return 1 / ((ticks * 60) / (this._getBpm() * this._getPPQ()));\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return 1 / super._beatsToUnits(beats);\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return 1 / seconds;\n    }\n    /**\n     * Convert a MIDI note to frequency value.\n     * @param  midi The midi number to convert.\n     * @return The corresponding frequency value\n     */\n    static mtof(midi) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.mtof)(midi);\n    }\n    /**\n     * Convert a frequency value to a MIDI note.\n     * @param frequency The value to frequency value to convert.\n     */\n    static ftom(frequency) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(frequency);\n    }\n}\n//-------------------------------------\n// \tFREQUENCY CONVERSIONS\n//-------------------------------------\n/**\n * Note to scale index.\n * @hidden\n */\nconst noteToScaleIndex = {\n    cbb: -2, cb: -1, c: 0, \"c#\": 1, cx: 2,\n    dbb: 0, db: 1, d: 2, \"d#\": 3, dx: 4,\n    ebb: 2, eb: 3, e: 4, \"e#\": 5, ex: 6,\n    fbb: 3, fb: 4, f: 5, \"f#\": 6, fx: 7,\n    gbb: 5, gb: 6, g: 7, \"g#\": 8, gx: 9,\n    abb: 7, ab: 8, a: 9, \"a#\": 10, ax: 11,\n    bbb: 9, bb: 10, b: 11, \"b#\": 12, bx: 13,\n};\n/**\n * scale index to note (sharps)\n * @hidden\n */\nconst scaleIndexToNote = [\"C\", \"C#\", \"D\", \"D#\", \"E\", \"F\", \"F#\", \"G\", \"G#\", \"A\", \"A#\", \"B\"];\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n * @example\n * const midi = Tone.Frequency(\"C3\").toMidi();\n * console.log(midi);\n * @example\n * const hertz = Tone.Frequency(38, \"midi\").toFrequency();\n * console.log(hertz);\n */\nfunction Frequency(value, units) {\n    return new FrequencyClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Frequency.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/Frequency.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Midi.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Midi.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Midi\": () => (/* binding */ Midi),\n/* harmony export */   \"MidiClass\": () => (/* binding */ MidiClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _Frequency__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n\n\n\n/**\n * Midi is a primitive type for encoding Time values.\n * Midi can be constructed with or without the `new` keyword. Midi can be passed\n * into the parameter of any method which takes time as an argument.\n * @category Unit\n */\nclass MidiClass extends _Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"MidiClass\";\n        this.defaultUnits = \"midi\";\n    }\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._frequencyToUnits(freq));\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._ticksToUnits(ticks));\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._beatsToUnits(beats));\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(super._secondsToUnits(seconds));\n    }\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toMidi(); // 60\n     */\n    toMidi() {\n        return this.valueOf();\n    }\n    /**\n     * Return the value of the frequency as a MIDI note\n     * @example\n     * Tone.Midi(60).toFrequency(); // 261.6255653005986\n     */\n    toFrequency() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.mtof)(this.toMidi());\n    }\n    /**\n     * Transposes the frequency by the given number of semitones.\n     * @return A new transposed MidiClass\n     * @example\n     * Tone.Midi(\"A4\").transpose(3); // \"C5\"\n     */\n    transpose(interval) {\n        return new MidiClass(this.context, this.toMidi() + interval);\n    }\n}\n/**\n * Convert a value into a FrequencyClass object.\n * @category Unit\n */\nfunction Midi(value, units) {\n    return new MidiClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Midi.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/Midi.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/NoteUnits.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/NoteUnits.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n// this file contains all of the valid note names for all pitches between C-4 and C11\n\n//# sourceMappingURL=NoteUnits.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/NoteUnits.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Ticks.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Ticks.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Ticks\": () => (/* binding */ Ticks),\n/* harmony export */   \"TicksClass\": () => (/* binding */ TicksClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _TransportTime__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n\n\n/**\n * Ticks is a primitive type for encoding Time values.\n * Ticks can be constructed with or without the `new` keyword. Ticks can be passed\n * into the parameter of any method which takes time as an argument.\n * @example\n * const t = Tone.Ticks(\"4n\"); // a quarter note as ticks\n * @category Unit\n */\nclass TicksClass extends _TransportTime__WEBPACK_IMPORTED_MODULE_1__.TransportTimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"Ticks\";\n        this.defaultUnits = \"i\";\n    }\n    /**\n     * Get the current time in the given units\n     */\n    _now() {\n        return this.context.transport.ticks;\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return this._getPPQ() * beats;\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return ticks;\n    }\n    /**\n     * Return the time in ticks\n     */\n    toTicks() {\n        return this.valueOf();\n    }\n    /**\n     * Return the time in seconds\n     */\n    toSeconds() {\n        return (this.valueOf() / this._getPPQ()) * (60 / this._getBpm());\n    }\n}\n/**\n * Convert a time representation to ticks\n * @category Unit\n */\nfunction Ticks(value, units) {\n    return new TicksClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Ticks.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/Ticks.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Time.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Time.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Time\": () => (/* binding */ Time),\n/* harmony export */   \"TimeClass\": () => (/* binding */ TimeClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _TimeBase__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./TimeBase */ \"./node_modules/tone/build/esm/core/type/TimeBase.js\");\n\n\n\n/**\n * TimeClass is a primitive type for encoding and decoding Time values.\n * TimeClass can be passed into the parameter of any method which takes time as an argument.\n * @param  val    The time value.\n * @param  units  The units of the value.\n * @example\n * const time = Tone.Time(\"4n\"); // a quarter note\n * @category Unit\n */\nclass TimeClass extends _TimeBase__WEBPACK_IMPORTED_MODULE_2__.TimeBaseClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"TimeClass\";\n    }\n    _getExpressions() {\n        return Object.assign(super._getExpressions(), {\n            now: {\n                method: (capture) => {\n                    return this._now() + new this.constructor(this.context, capture).valueOf();\n                },\n                regexp: /^\\+(.+)/,\n            },\n            quantize: {\n                method: (capture) => {\n                    const quantTo = new TimeClass(this.context, capture).valueOf();\n                    return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));\n                },\n                regexp: /^@(.+)/,\n            },\n        });\n    }\n    /**\n     * Quantize the time by the given subdivision. Optionally add a\n     * percentage which will move the time value towards the ideal\n     * quantized value by that percentage.\n     * @param  subdiv    The subdivision to quantize to\n     * @param  percent  Move the time value towards the quantized value by a percentage.\n     * @example\n     * Tone.Time(21).quantize(2); // returns 22\n     * Tone.Time(0.6).quantize(\"4n\", 0.5); // returns 0.55\n     */\n    quantize(subdiv, percent = 1) {\n        const subdivision = new this.constructor(this.context, subdiv).valueOf();\n        const value = this.valueOf();\n        const multiple = Math.round(value / subdivision);\n        const ideal = multiple * subdivision;\n        const diff = ideal - value;\n        return value + diff * percent;\n    }\n    //-------------------------------------\n    // CONVERSIONS\n    //-------------------------------------\n    /**\n     * Convert a Time to Notation. The notation values are will be the\n     * closest representation between 1m to 128th note.\n     * @return {Notation}\n     * @example\n     * // if the Transport is at 120bpm:\n     * Tone.Time(2).toNotation(); // returns \"1m\"\n     */\n    toNotation() {\n        const time = this.toSeconds();\n        const testNotations = [\"1m\"];\n        for (let power = 1; power < 9; power++) {\n            const subdiv = Math.pow(2, power);\n            testNotations.push(subdiv + \"n.\");\n            testNotations.push(subdiv + \"n\");\n            testNotations.push(subdiv + \"t\");\n        }\n        testNotations.push(\"0\");\n        // find the closets notation representation\n        let closest = testNotations[0];\n        let closestSeconds = new TimeClass(this.context, testNotations[0]).toSeconds();\n        testNotations.forEach(notation => {\n            const notationSeconds = new TimeClass(this.context, notation).toSeconds();\n            if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {\n                closest = notation;\n                closestSeconds = notationSeconds;\n            }\n        });\n        return closest;\n    }\n    /**\n     * Return the time encoded as Bars:Beats:Sixteenths.\n     */\n    toBarsBeatsSixteenths() {\n        const quarterTime = this._beatsToUnits(1);\n        let quarters = this.valueOf() / quarterTime;\n        quarters = parseFloat(quarters.toFixed(4));\n        const measures = Math.floor(quarters / this._getTimeSignature());\n        let sixteenths = (quarters % 1) * 4;\n        quarters = Math.floor(quarters) % this._getTimeSignature();\n        const sixteenthString = sixteenths.toString();\n        if (sixteenthString.length > 3) {\n            // the additional parseFloat removes insignificant trailing zeroes\n            sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));\n        }\n        const progress = [measures, quarters, sixteenths];\n        return progress.join(\":\");\n    }\n    /**\n     * Return the time in ticks.\n     */\n    toTicks() {\n        const quarterTime = this._beatsToUnits(1);\n        const quarters = this.valueOf() / quarterTime;\n        return Math.round(quarters * this._getPPQ());\n    }\n    /**\n     * Return the time in seconds.\n     */\n    toSeconds() {\n        return this.valueOf();\n    }\n    /**\n     * Return the value as a midi note.\n     */\n    toMidi() {\n        return (0,_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftom)(this.toFrequency());\n    }\n    _now() {\n        return this.context.now();\n    }\n}\n/**\n * Create a TimeClass from a time string or number. The time is computed against the\n * global Tone.Context. To use a specific context, use [[TimeClass]]\n * @param value A value which represents time\n * @param units The value's units if they can't be inferred by the value.\n * @category Unit\n * @example\n * const time = Tone.Time(\"4n\").toSeconds();\n * console.log(time);\n * @example\n * const note = Tone.Time(1).toNotation();\n * console.log(note);\n * @example\n * const freq = Tone.Time(0.5).toFrequency();\n * console.log(freq);\n */\nfunction Time(value, units) {\n    return new TimeClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=Time.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/Time.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/TimeBase.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/TimeBase.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TimeBaseClass\": () => (/* binding */ TimeBaseClass)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n/**\n * TimeBase is a flexible encoding of time which can be evaluated to and from a string.\n */\nclass TimeBaseClass extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    /**\n     * @param context The context associated with the time value. Used to compute\n     * Transport and context-relative timing.\n     * @param  value  The time value as a number, string or object\n     * @param  units  Unit values\n     */\n    constructor(context, value, units) {\n        super();\n        /**\n         * The default units\n         */\n        this.defaultUnits = \"s\";\n        this._val = value;\n        this._units = units;\n        this.context = context;\n        this._expressions = this._getExpressions();\n    }\n    /**\n     * All of the time encoding expressions\n     */\n    _getExpressions() {\n        return {\n            hz: {\n                method: (value) => {\n                    return this._frequencyToUnits(parseFloat(value));\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)hz$/i,\n            },\n            i: {\n                method: (value) => {\n                    return this._ticksToUnits(parseInt(value, 10));\n                },\n                regexp: /^(\\d+)i$/i,\n            },\n            m: {\n                method: (value) => {\n                    return this._beatsToUnits(parseInt(value, 10) * this._getTimeSignature());\n                },\n                regexp: /^(\\d+)m$/i,\n            },\n            n: {\n                method: (value, dot) => {\n                    const numericValue = parseInt(value, 10);\n                    const scalar = dot === \".\" ? 1.5 : 1;\n                    if (numericValue === 1) {\n                        return this._beatsToUnits(this._getTimeSignature()) * scalar;\n                    }\n                    else {\n                        return this._beatsToUnits(4 / numericValue) * scalar;\n                    }\n                },\n                regexp: /^(\\d+)n(\\.?)$/i,\n            },\n            number: {\n                method: (value) => {\n                    return this._expressions[this.defaultUnits].method.call(this, value);\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)$/,\n            },\n            s: {\n                method: (value) => {\n                    return this._secondsToUnits(parseFloat(value));\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?)s$/,\n            },\n            samples: {\n                method: (value) => {\n                    return parseInt(value, 10) / this.context.sampleRate;\n                },\n                regexp: /^(\\d+)samples$/,\n            },\n            t: {\n                method: (value) => {\n                    const numericValue = parseInt(value, 10);\n                    return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));\n                },\n                regexp: /^(\\d+)t$/i,\n            },\n            tr: {\n                method: (m, q, s) => {\n                    let total = 0;\n                    if (m && m !== \"0\") {\n                        total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));\n                    }\n                    if (q && q !== \"0\") {\n                        total += this._beatsToUnits(parseFloat(q));\n                    }\n                    if (s && s !== \"0\") {\n                        total += this._beatsToUnits(parseFloat(s) / 4);\n                    }\n                    return total;\n                },\n                regexp: /^(\\d+(?:\\.\\d+)?):(\\d+(?:\\.\\d+)?):?(\\d+(?:\\.\\d+)?)?$/,\n            },\n        };\n    }\n    //-------------------------------------\n    // \tVALUE OF\n    //-------------------------------------\n    /**\n     * Evaluate the time value. Returns the time in seconds.\n     */\n    valueOf() {\n        if (this._val instanceof TimeBaseClass) {\n            this.fromType(this._val);\n        }\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._val)) {\n            return this._noArg();\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isString)(this._val) && (0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._units)) {\n            for (const units in this._expressions) {\n                if (this._expressions[units].regexp.test(this._val.trim())) {\n                    this._units = units;\n                    break;\n                }\n            }\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(this._val)) {\n            let total = 0;\n            for (const typeName in this._val) {\n                if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this._val[typeName])) {\n                    const quantity = this._val[typeName];\n                    // @ts-ignore\n                    const time = (new this.constructor(this.context, typeName)).valueOf() * quantity;\n                    total += time;\n                }\n            }\n            return total;\n        }\n        if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(this._units)) {\n            const expr = this._expressions[this._units];\n            const matching = this._val.toString().trim().match(expr.regexp);\n            if (matching) {\n                return expr.method.apply(this, matching.slice(1));\n            }\n            else {\n                return expr.method.call(this, this._val);\n            }\n        }\n        else if ((0,_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isString)(this._val)) {\n            return parseFloat(this._val);\n        }\n        else {\n            return this._val;\n        }\n    }\n    //-------------------------------------\n    // \tUNIT CONVERSIONS\n    //-------------------------------------\n    /**\n     * Returns the value of a frequency in the current units\n     */\n    _frequencyToUnits(freq) {\n        return 1 / freq;\n    }\n    /**\n     * Return the value of the beats in the current units\n     */\n    _beatsToUnits(beats) {\n        return (60 / this._getBpm()) * beats;\n    }\n    /**\n     * Returns the value of a second in the current units\n     */\n    _secondsToUnits(seconds) {\n        return seconds;\n    }\n    /**\n     * Returns the value of a tick in the current time units\n     */\n    _ticksToUnits(ticks) {\n        return (ticks * (this._beatsToUnits(1)) / this._getPPQ());\n    }\n    /**\n     * With no arguments, return 'now'\n     */\n    _noArg() {\n        return this._now();\n    }\n    //-------------------------------------\n    // \tTEMPO CONVERSIONS\n    //-------------------------------------\n    /**\n     * Return the bpm\n     */\n    _getBpm() {\n        return this.context.transport.bpm.value;\n    }\n    /**\n     * Return the timeSignature\n     */\n    _getTimeSignature() {\n        return this.context.transport.timeSignature;\n    }\n    /**\n     * Return the PPQ or 192 if Transport is not available\n     */\n    _getPPQ() {\n        return this.context.transport.PPQ;\n    }\n    //-------------------------------------\n    // \tCONVERSION INTERFACE\n    //-------------------------------------\n    /**\n     * Coerce a time type into this units type.\n     * @param type Any time type units\n     */\n    fromType(type) {\n        this._units = undefined;\n        switch (this.defaultUnits) {\n            case \"s\":\n                this._val = type.toSeconds();\n                break;\n            case \"i\":\n                this._val = type.toTicks();\n                break;\n            case \"hz\":\n                this._val = type.toFrequency();\n                break;\n            case \"midi\":\n                this._val = type.toMidi();\n                break;\n        }\n        return this;\n    }\n    /**\n     * Return the value in hertz\n     */\n    toFrequency() {\n        return 1 / this.toSeconds();\n    }\n    /**\n     * Return the time in samples\n     */\n    toSamples() {\n        return this.toSeconds() * this.context.sampleRate;\n    }\n    /**\n     * Return the time in milliseconds.\n     */\n    toMilliseconds() {\n        return this.toSeconds() * 1000;\n    }\n}\n//# sourceMappingURL=TimeBase.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/TimeBase.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/TransportTime.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/TransportTime.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TransportTime\": () => (/* binding */ TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* binding */ TransportTimeClass)\n/* harmony export */ });\n/* harmony import */ var _Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _Time__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Time */ \"./node_modules/tone/build/esm/core/type/Time.js\");\n\n\n/**\n * TransportTime is a the time along the Transport's\n * timeline. It is similar to Tone.Time, but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nclass TransportTimeClass extends _Time__WEBPACK_IMPORTED_MODULE_1__.TimeClass {\n    constructor() {\n        super(...arguments);\n        this.name = \"TransportTime\";\n    }\n    /**\n     * Return the current time in whichever context is relevant\n     */\n    _now() {\n        return this.context.transport.seconds;\n    }\n}\n/**\n * TransportTime is a the time along the Transport's\n * timeline. It is similar to [[Time]], but instead of evaluating\n * against the AudioContext's clock, it is evaluated against\n * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).\n * @category Unit\n */\nfunction TransportTime(value, units) {\n    return new TransportTimeClass((0,_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)(), value, units);\n}\n//# sourceMappingURL=TransportTime.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/TransportTime.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/type/Units.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/type/Units.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _NoteUnits__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./NoteUnits */ \"./node_modules/tone/build/esm/core/type/NoteUnits.js\");\n\n//# sourceMappingURL=Units.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/type/Units.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isAudioBuffer\": () => (/* binding */ isAudioBuffer),\n/* harmony export */   \"isAudioContext\": () => (/* binding */ isAudioContext),\n/* harmony export */   \"isAudioNode\": () => (/* binding */ isAudioNode),\n/* harmony export */   \"isAudioParam\": () => (/* binding */ isAudioParam),\n/* harmony export */   \"isOfflineAudioContext\": () => (/* binding */ isOfflineAudioContext)\n/* harmony export */ });\n/* harmony import */ var standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! standardized-audio-context */ \"./node_modules/standardized-audio-context/build/es2019/module.js\");\n\n/**\n * Test if the given value is an instanceof AudioParam\n */\nfunction isAudioParam(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyAudioParam)(arg);\n}\n/**\n * Test if the given value is an instanceof AudioNode\n */\nfunction isAudioNode(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyAudioNode)(arg);\n}\n/**\n * Test if the arg is instanceof an OfflineAudioContext\n */\nfunction isOfflineAudioContext(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyOfflineAudioContext)(arg);\n}\n/**\n * Test if the arg is an instanceof AudioContext\n */\nfunction isAudioContext(arg) {\n    return (0,standardized_audio_context__WEBPACK_IMPORTED_MODULE_0__.isAnyAudioContext)(arg);\n}\n/**\n * Test if the arg is instanceof an AudioBuffer\n */\nfunction isAudioBuffer(arg) {\n    return arg instanceof AudioBuffer;\n}\n//# sourceMappingURL=AdvancedTypeCheck.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Debug.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Debug.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"assert\": () => (/* binding */ assert),\n/* harmony export */   \"assertContextRunning\": () => (/* binding */ assertContextRunning),\n/* harmony export */   \"assertRange\": () => (/* binding */ assertRange),\n/* harmony export */   \"log\": () => (/* binding */ log),\n/* harmony export */   \"setLogger\": () => (/* binding */ setLogger),\n/* harmony export */   \"warn\": () => (/* binding */ warn)\n/* harmony export */ });\n/**\n * Assert that the statement is true, otherwise invoke the error.\n * @param statement\n * @param error The message which is passed into an Error\n */\nfunction assert(statement, error) {\n    if (!statement) {\n        throw new Error(error);\n    }\n}\n/**\n * Make sure that the given value is within the range\n */\nfunction assertRange(value, gte, lte = Infinity) {\n    if (!(gte <= value && value <= lte)) {\n        throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);\n    }\n}\n/**\n * Make sure that the given value is within the range\n */\nfunction assertContextRunning(context) {\n    // add a warning if the context is not started\n    if (!context.isOffline && context.state !== \"running\") {\n        warn(\"The AudioContext is \\\"suspended\\\". Invoke Tone.start() from a user action to start the audio.\");\n    }\n}\n/**\n * The default logger is the console\n */\nlet defaultLogger = console;\n/**\n * Set the logging interface\n */\nfunction setLogger(logger) {\n    defaultLogger = logger;\n}\n/**\n * Log anything\n */\nfunction log(...args) {\n    defaultLogger.log(...args);\n}\n/**\n * Warn anything\n */\nfunction warn(...args) {\n    defaultLogger.warn(...args);\n}\n//# sourceMappingURL=Debug.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Debug.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Decorator.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Decorator.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"range\": () => (/* binding */ range),\n/* harmony export */   \"timeRange\": () => (/* binding */ timeRange)\n/* harmony export */ });\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n/**\n * Assert that the number is in the given range.\n */\nfunction range(min, max = Infinity) {\n    const valueMap = new WeakMap();\n    return function (target, propertyKey) {\n        Reflect.defineProperty(target, propertyKey, {\n            configurable: true,\n            enumerable: true,\n            get: function () {\n                return valueMap.get(this);\n            },\n            set: function (newValue) {\n                (0,_Debug__WEBPACK_IMPORTED_MODULE_0__.assertRange)(newValue, min, max);\n                valueMap.set(this, newValue);\n            }\n        });\n    };\n}\n/**\n * Convert the time to seconds and assert that the time is in between the two\n * values when being set.\n */\nfunction timeRange(min, max = Infinity) {\n    const valueMap = new WeakMap();\n    return function (target, propertyKey) {\n        Reflect.defineProperty(target, propertyKey, {\n            configurable: true,\n            enumerable: true,\n            get: function () {\n                return valueMap.get(this);\n            },\n            set: function (newValue) {\n                (0,_Debug__WEBPACK_IMPORTED_MODULE_0__.assertRange)(this.toSeconds(newValue), min, max);\n                valueMap.set(this, newValue);\n            }\n        });\n    };\n}\n//# sourceMappingURL=Decorator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Decorator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Defaults.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Defaults.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"deepEquals\": () => (/* binding */ deepEquals),\n/* harmony export */   \"deepMerge\": () => (/* binding */ deepMerge),\n/* harmony export */   \"defaultArg\": () => (/* binding */ defaultArg),\n/* harmony export */   \"getDefaultsFromInstance\": () => (/* binding */ getDefaultsFromInstance),\n/* harmony export */   \"omitFromObject\": () => (/* binding */ omitFromObject),\n/* harmony export */   \"optionsFromArguments\": () => (/* binding */ optionsFromArguments)\n/* harmony export */ });\n/* harmony import */ var _AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n/**\n * Some objects should not be merged\n */\nfunction noCopy(key, arg) {\n    return key === \"value\" || (0,_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioParam)(arg) || (0,_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioNode)(arg) || (0,_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_0__.isAudioBuffer)(arg);\n}\nfunction deepMerge(target, ...sources) {\n    if (!sources.length) {\n        return target;\n    }\n    const source = sources.shift();\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(target) && (0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(source)) {\n        for (const key in source) {\n            if (noCopy(key, source[key])) {\n                target[key] = source[key];\n            }\n            else if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(source[key])) {\n                if (!target[key]) {\n                    Object.assign(target, { [key]: {} });\n                }\n                deepMerge(target[key], source[key]);\n            }\n            else {\n                Object.assign(target, { [key]: source[key] });\n            }\n        }\n    }\n    // @ts-ignore\n    return deepMerge(target, ...sources);\n}\n/**\n * Returns true if the two arrays have the same value for each of the elements\n */\nfunction deepEquals(arrayA, arrayB) {\n    return arrayA.length === arrayB.length && arrayA.every((element, index) => arrayB[index] === element);\n}\n/**\n * Convert an args array into an object.\n */\nfunction optionsFromArguments(defaults, argsArray, keys = [], objKey) {\n    const opts = {};\n    const args = Array.from(argsArray);\n    // if the first argument is an object and has an object key\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(args[0]) && objKey && !Reflect.has(args[0], objKey)) {\n        // if it's not part of the defaults\n        const partOfDefaults = Object.keys(args[0]).some(key => Reflect.has(defaults, key));\n        if (!partOfDefaults) {\n            // merge that key\n            deepMerge(opts, { [objKey]: args[0] });\n            // remove the obj key from the keys\n            keys.splice(keys.indexOf(objKey), 1);\n            // shift the first argument off\n            args.shift();\n        }\n    }\n    if (args.length === 1 && (0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isObject)(args[0])) {\n        deepMerge(opts, args[0]);\n    }\n    else {\n        for (let i = 0; i < keys.length; i++) {\n            if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(args[i])) {\n                opts[keys[i]] = args[i];\n            }\n        }\n    }\n    return deepMerge(defaults, opts);\n}\n/**\n * Return this instances default values by calling Constructor.getDefaults()\n */\nfunction getDefaultsFromInstance(instance) {\n    return instance.constructor.getDefaults();\n}\n/**\n * Returns the fallback if the given object is undefined.\n * Take an array of arguments and return a formatted options object.\n */\nfunction defaultArg(given, fallback) {\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(given)) {\n        return fallback;\n    }\n    else {\n        return given;\n    }\n}\n/**\n * Remove all of the properties belonging to omit from obj.\n */\nfunction omitFromObject(obj, omit) {\n    omit.forEach(prop => {\n        if (Reflect.has(obj, prop)) {\n            delete obj[prop];\n        }\n    });\n    return obj;\n}\n//# sourceMappingURL=Defaults.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Defaults.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Draw.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Draw.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Draw\": () => (/* binding */ Draw)\n/* harmony export */ });\n/* harmony import */ var _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _Timeline__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../context/ContextInitialization */ \"./node_modules/tone/build/esm/core/context/ContextInitialization.js\");\n\n\n\n/**\n * Draw is useful for synchronizing visuals and audio events.\n * Callbacks from Tone.Transport or any of the Tone.Event classes\n * always happen _before_ the scheduled time and are not synchronized\n * to the animation frame so they are not good for triggering tightly\n * synchronized visuals and sound. Draw makes it easy to schedule\n * callbacks using the AudioContext time and uses requestAnimationFrame.\n * @example\n * Tone.Transport.schedule((time) => {\n * \t// use the time argument to schedule a callback with Draw\n * \tTone.Draw.schedule(() => {\n * \t\t// do drawing or DOM manipulation here\n * \t\tconsole.log(time);\n * \t}, time);\n * }, \"+0.5\");\n * Tone.Transport.start();\n * @category Core\n */\nclass Draw extends _context_ToneWithContext__WEBPACK_IMPORTED_MODULE_0__.ToneWithContext {\n    constructor() {\n        super(...arguments);\n        this.name = \"Draw\";\n        /**\n         * The duration after which events are not invoked.\n         */\n        this.expiration = 0.25;\n        /**\n         * The amount of time before the scheduled time\n         * that the callback can be invoked. Default is\n         * half the time of an animation frame (0.008 seconds).\n         */\n        this.anticipation = 0.008;\n        /**\n         * All of the events.\n         */\n        this._events = new _Timeline__WEBPACK_IMPORTED_MODULE_1__.Timeline();\n        /**\n         * The draw loop\n         */\n        this._boundDrawLoop = this._drawLoop.bind(this);\n        /**\n         * The animation frame id\n         */\n        this._animationFrame = -1;\n    }\n    /**\n     * Schedule a function at the given time to be invoked\n     * on the nearest animation frame.\n     * @param  callback  Callback is invoked at the given time.\n     * @param  time      The time relative to the AudioContext time to invoke the callback.\n     * @example\n     * Tone.Transport.scheduleRepeat(time => {\n     * \tTone.Draw.schedule(() => console.log(time), time);\n     * }, 1);\n     * Tone.Transport.start();\n     */\n    schedule(callback, time) {\n        this._events.add({\n            callback,\n            time: this.toSeconds(time),\n        });\n        // start the draw loop on the first event\n        if (this._events.length === 1) {\n            this._animationFrame = requestAnimationFrame(this._boundDrawLoop);\n        }\n        return this;\n    }\n    /**\n     * Cancel events scheduled after the given time\n     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.\n     */\n    cancel(after) {\n        this._events.cancel(this.toSeconds(after));\n        return this;\n    }\n    /**\n     * The draw loop\n     */\n    _drawLoop() {\n        const now = this.context.currentTime;\n        while (this._events.length && this._events.peek().time - this.anticipation <= now) {\n            const event = this._events.shift();\n            if (event && now - event.time <= this.expiration) {\n                event.callback();\n            }\n        }\n        if (this._events.length > 0) {\n            this._animationFrame = requestAnimationFrame(this._boundDrawLoop);\n        }\n    }\n    dispose() {\n        super.dispose();\n        this._events.dispose();\n        cancelAnimationFrame(this._animationFrame);\n        return this;\n    }\n}\n//-------------------------------------\n// \tINITIALIZATION\n//-------------------------------------\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextInit)(context => {\n    context.draw = new Draw({ context });\n});\n(0,_context_ContextInitialization__WEBPACK_IMPORTED_MODULE_2__.onContextClose)(context => {\n    context.draw.dispose();\n});\n//# sourceMappingURL=Draw.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Draw.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Emitter.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Emitter.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Emitter\": () => (/* binding */ Emitter)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n/**\n * Emitter gives classes which extend it\n * the ability to listen for and emit events.\n * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).\n * MIT (c) 2011 Jerome Etienne.\n * @category Core\n */\nclass Emitter extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super(...arguments);\n        this.name = \"Emitter\";\n    }\n    /**\n     * Bind a callback to a specific event.\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    on(event, callback) {\n        // split the event\n        const events = event.split(/\\W+/);\n        events.forEach(eventName => {\n            if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._events)) {\n                this._events = {};\n            }\n            if (!this._events.hasOwnProperty(eventName)) {\n                this._events[eventName] = [];\n            }\n            this._events[eventName].push(callback);\n        });\n        return this;\n    }\n    /**\n     * Bind a callback which is only invoked once\n     * @param  event     The name of the event to listen for.\n     * @param  callback  The callback to invoke when the event is emitted\n     */\n    once(event, callback) {\n        const boundCallback = (...args) => {\n            // invoke the callback\n            callback(...args);\n            // remove the event\n            this.off(event, boundCallback);\n        };\n        this.on(event, boundCallback);\n        return this;\n    }\n    /**\n     * Remove the event listener.\n     * @param  event     The event to stop listening to.\n     * @param  callback  The callback which was bound to the event with Emitter.on.\n     *                   If no callback is given, all callbacks events are removed.\n     */\n    off(event, callback) {\n        const events = event.split(/\\W+/);\n        events.forEach(eventName => {\n            if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(this._events)) {\n                this._events = {};\n            }\n            if (this._events.hasOwnProperty(event)) {\n                if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isUndef)(callback)) {\n                    this._events[event] = [];\n                }\n                else {\n                    const eventList = this._events[event];\n                    for (let i = eventList.length - 1; i >= 0; i--) {\n                        if (eventList[i] === callback) {\n                            eventList.splice(i, 1);\n                        }\n                    }\n                }\n            }\n        });\n        return this;\n    }\n    /**\n     * Invoke all of the callbacks bound to the event\n     * with any arguments passed in.\n     * @param  event  The name of the event.\n     * @param args The arguments to pass to the functions listening.\n     */\n    emit(event, ...args) {\n        if (this._events) {\n            if (this._events.hasOwnProperty(event)) {\n                const eventList = this._events[event].slice(0);\n                for (let i = 0, len = eventList.length; i < len; i++) {\n                    eventList[i].apply(this, args);\n                }\n            }\n        }\n        return this;\n    }\n    /**\n     * Add Emitter functions (on/off/emit) to the object\n     */\n    static mixin(constr) {\n        // instance._events = {};\n        [\"on\", \"once\", \"off\", \"emit\"].forEach(name => {\n            const property = Object.getOwnPropertyDescriptor(Emitter.prototype, name);\n            Object.defineProperty(constr.prototype, name, property);\n        });\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._events = undefined;\n        return this;\n    }\n}\n//# sourceMappingURL=Emitter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Emitter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Interface.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Interface.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"noOp\": () => (/* binding */ noOp),\n/* harmony export */   \"readOnly\": () => (/* binding */ readOnly),\n/* harmony export */   \"writable\": () => (/* binding */ writable)\n/* harmony export */ });\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n/**\n * Make the property not writable using `defineProperty`. Internal use only.\n */\nfunction readOnly(target, property) {\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_0__.isArray)(property)) {\n        property.forEach(str => readOnly(target, str));\n    }\n    else {\n        Object.defineProperty(target, property, {\n            enumerable: true,\n            writable: false,\n        });\n    }\n}\n/**\n * Make an attribute writeable. Internal use only.\n */\nfunction writable(target, property) {\n    if ((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_0__.isArray)(property)) {\n        property.forEach(str => writable(target, str));\n    }\n    else {\n        Object.defineProperty(target, property, {\n            writable: true,\n        });\n    }\n}\nconst noOp = () => {\n    // no operation here!\n};\n//# sourceMappingURL=Interface.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Interface.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/IntervalTimeline.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/IntervalTimeline.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"IntervalTimeline\": () => (/* binding */ IntervalTimeline)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n/**\n * Similar to Tone.Timeline, but all events represent\n * intervals with both \"time\" and \"duration\" times. The\n * events are placed in a tree structure optimized\n * for querying an intersection point with the timeline\n * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)\n * to represent the data.\n */\nclass IntervalTimeline extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super(...arguments);\n        this.name = \"IntervalTimeline\";\n        /**\n         * The root node of the inteval tree\n         */\n        this._root = null;\n        /**\n         * Keep track of the length of the timeline.\n         */\n        this._length = 0;\n    }\n    /**\n     * The event to add to the timeline. All events must\n     * have a time and duration value\n     * @param  event  The event to add to the timeline\n     */\n    add(event) {\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(event.time), \"Events must have a time property\");\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isDefined)(event.duration), \"Events must have a duration parameter\");\n        event.time = event.time.valueOf();\n        let node = new IntervalNode(event.time, event.time + event.duration, event);\n        if (this._root === null) {\n            this._root = node;\n        }\n        else {\n            this._root.insert(node);\n        }\n        this._length++;\n        // Restructure tree to be balanced\n        while (node !== null) {\n            node.updateHeight();\n            node.updateMax();\n            this._rebalance(node);\n            node = node.parent;\n        }\n        return this;\n    }\n    /**\n     * Remove an event from the timeline.\n     * @param  event  The event to remove from the timeline\n     */\n    remove(event) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(event.time, results);\n            for (const node of results) {\n                if (node.event === event) {\n                    this._removeNode(node);\n                    this._length--;\n                    break;\n                }\n            }\n        }\n        return this;\n    }\n    /**\n     * The number of items in the timeline.\n     * @readOnly\n     */\n    get length() {\n        return this._length;\n    }\n    /**\n     * Remove events whose time time is after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after) {\n        this.forEachFrom(after, event => this.remove(event));\n        return this;\n    }\n    /**\n     * Set the root node as the given node\n     */\n    _setRoot(node) {\n        this._root = node;\n        if (this._root !== null) {\n            this._root.parent = null;\n        }\n    }\n    /**\n     * Replace the references to the node in the node's parent\n     * with the replacement node.\n     */\n    _replaceNodeInParent(node, replacement) {\n        if (node.parent !== null) {\n            if (node.isLeftChild()) {\n                node.parent.left = replacement;\n            }\n            else {\n                node.parent.right = replacement;\n            }\n            this._rebalance(node.parent);\n        }\n        else {\n            this._setRoot(replacement);\n        }\n    }\n    /**\n     * Remove the node from the tree and replace it with\n     * a successor which follows the schema.\n     */\n    _removeNode(node) {\n        if (node.left === null && node.right === null) {\n            this._replaceNodeInParent(node, null);\n        }\n        else if (node.right === null) {\n            this._replaceNodeInParent(node, node.left);\n        }\n        else if (node.left === null) {\n            this._replaceNodeInParent(node, node.right);\n        }\n        else {\n            const balance = node.getBalance();\n            let replacement;\n            let temp = null;\n            if (balance > 0) {\n                if (node.left.right === null) {\n                    replacement = node.left;\n                    replacement.right = node.right;\n                    temp = replacement;\n                }\n                else {\n                    replacement = node.left.right;\n                    while (replacement.right !== null) {\n                        replacement = replacement.right;\n                    }\n                    if (replacement.parent) {\n                        replacement.parent.right = replacement.left;\n                        temp = replacement.parent;\n                        replacement.left = node.left;\n                        replacement.right = node.right;\n                    }\n                }\n            }\n            else if (node.right.left === null) {\n                replacement = node.right;\n                replacement.left = node.left;\n                temp = replacement;\n            }\n            else {\n                replacement = node.right.left;\n                while (replacement.left !== null) {\n                    replacement = replacement.left;\n                }\n                if (replacement.parent) {\n                    replacement.parent.left = replacement.right;\n                    temp = replacement.parent;\n                    replacement.left = node.left;\n                    replacement.right = node.right;\n                }\n            }\n            if (node.parent !== null) {\n                if (node.isLeftChild()) {\n                    node.parent.left = replacement;\n                }\n                else {\n                    node.parent.right = replacement;\n                }\n            }\n            else {\n                this._setRoot(replacement);\n            }\n            if (temp) {\n                this._rebalance(temp);\n            }\n        }\n        node.dispose();\n    }\n    /**\n     * Rotate the tree to the left\n     */\n    _rotateLeft(node) {\n        const parent = node.parent;\n        const isLeftChild = node.isLeftChild();\n        // Make node.right the new root of this sub tree (instead of node)\n        const pivotNode = node.right;\n        if (pivotNode) {\n            node.right = pivotNode.left;\n            pivotNode.left = node;\n        }\n        if (parent !== null) {\n            if (isLeftChild) {\n                parent.left = pivotNode;\n            }\n            else {\n                parent.right = pivotNode;\n            }\n        }\n        else {\n            this._setRoot(pivotNode);\n        }\n    }\n    /**\n     * Rotate the tree to the right\n     */\n    _rotateRight(node) {\n        const parent = node.parent;\n        const isLeftChild = node.isLeftChild();\n        // Make node.left the new root of this sub tree (instead of node)\n        const pivotNode = node.left;\n        if (pivotNode) {\n            node.left = pivotNode.right;\n            pivotNode.right = node;\n        }\n        if (parent !== null) {\n            if (isLeftChild) {\n                parent.left = pivotNode;\n            }\n            else {\n                parent.right = pivotNode;\n            }\n        }\n        else {\n            this._setRoot(pivotNode);\n        }\n    }\n    /**\n     * Balance the BST\n     */\n    _rebalance(node) {\n        const balance = node.getBalance();\n        if (balance > 1 && node.left) {\n            if (node.left.getBalance() < 0) {\n                this._rotateLeft(node.left);\n            }\n            else {\n                this._rotateRight(node);\n            }\n        }\n        else if (balance < -1 && node.right) {\n            if (node.right.getBalance() > 0) {\n                this._rotateRight(node.right);\n            }\n            else {\n                this._rotateLeft(node);\n            }\n        }\n    }\n    /**\n     * Get an event whose time and duration span the give time. Will\n     * return the match whose \"time\" value is closest to the given time.\n     * @return  The event which spans the desired time\n     */\n    get(time) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(time, results);\n            if (results.length > 0) {\n                let max = results[0];\n                for (let i = 1; i < results.length; i++) {\n                    if (results[i].low > max.low) {\n                        max = results[i];\n                    }\n                }\n                return max.event;\n            }\n        }\n        return null;\n    }\n    /**\n     * Iterate over everything in the timeline.\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback) {\n        if (this._root !== null) {\n            const allNodes = [];\n            this._root.traverse(node => allNodes.push(node));\n            allNodes.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array in which the given time\n     * overlaps with the time and duration time of the event.\n     * @param  time The time to check if items are overlapping\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time, callback) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.search(time, results);\n            results.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array in which the time is greater\n     * than or equal to the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time, callback) {\n        if (this._root !== null) {\n            const results = [];\n            this._root.searchAfter(time, results);\n            results.forEach(node => {\n                if (node.event) {\n                    callback(node.event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        if (this._root !== null) {\n            this._root.traverse(node => node.dispose());\n        }\n        this._root = null;\n        return this;\n    }\n}\n//-------------------------------------\n// \tINTERVAL NODE HELPER\n//-------------------------------------\n/**\n * Represents a node in the binary search tree, with the addition\n * of a \"high\" value which keeps track of the highest value of\n * its children.\n * References:\n * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/\n * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf\n * @param low\n * @param high\n */\nclass IntervalNode {\n    constructor(low, high, event) {\n        // the nodes to the left\n        this._left = null;\n        // the nodes to the right\n        this._right = null;\n        // the parent node\n        this.parent = null;\n        // the number of child nodes\n        this.height = 0;\n        this.event = event;\n        // the low value\n        this.low = low;\n        // the high value\n        this.high = high;\n        // the high value for this and all child nodes\n        this.max = this.high;\n    }\n    /**\n     * Insert a node into the correct spot in the tree\n     */\n    insert(node) {\n        if (node.low <= this.low) {\n            if (this.left === null) {\n                this.left = node;\n            }\n            else {\n                this.left.insert(node);\n            }\n        }\n        else if (this.right === null) {\n            this.right = node;\n        }\n        else {\n            this.right.insert(node);\n        }\n    }\n    /**\n     * Search the tree for nodes which overlap\n     * with the given point\n     * @param  point  The point to query\n     * @param  results  The array to put the results\n     */\n    search(point, results) {\n        // If p is to the right of the rightmost point of any interval\n        // in this node and all children, there won't be any matches.\n        if (point > this.max) {\n            return;\n        }\n        // Search left children\n        if (this.left !== null) {\n            this.left.search(point, results);\n        }\n        // Check this node\n        if (this.low <= point && this.high > point) {\n            results.push(this);\n        }\n        // If p is to the left of the time of this interval,\n        // then it can't be in any child to the right.\n        if (this.low > point) {\n            return;\n        }\n        // Search right children\n        if (this.right !== null) {\n            this.right.search(point, results);\n        }\n    }\n    /**\n     * Search the tree for nodes which are less\n     * than the given point\n     * @param  point  The point to query\n     * @param  results  The array to put the results\n     */\n    searchAfter(point, results) {\n        // Check this node\n        if (this.low >= point) {\n            results.push(this);\n            if (this.left !== null) {\n                this.left.searchAfter(point, results);\n            }\n        }\n        // search the right side\n        if (this.right !== null) {\n            this.right.searchAfter(point, results);\n        }\n    }\n    /**\n     * Invoke the callback on this element and both it's branches\n     * @param  {Function}  callback\n     */\n    traverse(callback) {\n        callback(this);\n        if (this.left !== null) {\n            this.left.traverse(callback);\n        }\n        if (this.right !== null) {\n            this.right.traverse(callback);\n        }\n    }\n    /**\n     * Update the height of the node\n     */\n    updateHeight() {\n        if (this.left !== null && this.right !== null) {\n            this.height = Math.max(this.left.height, this.right.height) + 1;\n        }\n        else if (this.right !== null) {\n            this.height = this.right.height + 1;\n        }\n        else if (this.left !== null) {\n            this.height = this.left.height + 1;\n        }\n        else {\n            this.height = 0;\n        }\n    }\n    /**\n     * Update the height of the node\n     */\n    updateMax() {\n        this.max = this.high;\n        if (this.left !== null) {\n            this.max = Math.max(this.max, this.left.max);\n        }\n        if (this.right !== null) {\n            this.max = Math.max(this.max, this.right.max);\n        }\n    }\n    /**\n     * The balance is how the leafs are distributed on the node\n     * @return  Negative numbers are balanced to the right\n     */\n    getBalance() {\n        let balance = 0;\n        if (this.left !== null && this.right !== null) {\n            balance = this.left.height - this.right.height;\n        }\n        else if (this.left !== null) {\n            balance = this.left.height + 1;\n        }\n        else if (this.right !== null) {\n            balance = -(this.right.height + 1);\n        }\n        return balance;\n    }\n    /**\n     * @returns true if this node is the left child of its parent\n     */\n    isLeftChild() {\n        return this.parent !== null && this.parent.left === this;\n    }\n    /**\n     * get/set the left node\n     */\n    get left() {\n        return this._left;\n    }\n    set left(node) {\n        this._left = node;\n        if (node !== null) {\n            node.parent = this;\n        }\n        this.updateHeight();\n        this.updateMax();\n    }\n    /**\n     * get/set the right node\n     */\n    get right() {\n        return this._right;\n    }\n    set right(node) {\n        this._right = node;\n        if (node !== null) {\n            node.parent = this;\n        }\n        this.updateHeight();\n        this.updateMax();\n    }\n    /**\n     * null out references.\n     */\n    dispose() {\n        this.parent = null;\n        this._left = null;\n        this._right = null;\n        this.event = null;\n    }\n}\n//# sourceMappingURL=IntervalTimeline.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/IntervalTimeline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Math.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Math.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EQ\": () => (/* binding */ EQ),\n/* harmony export */   \"GT\": () => (/* binding */ GT),\n/* harmony export */   \"GTE\": () => (/* binding */ GTE),\n/* harmony export */   \"LT\": () => (/* binding */ LT),\n/* harmony export */   \"clamp\": () => (/* binding */ clamp)\n/* harmony export */ });\n/**\n * The threshold for correctness for operators. Less than one sample even\n * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).\n */\nconst EPSILON = 1e-6;\n/**\n * Test if A is greater than B\n */\nfunction GT(a, b) {\n    return a > b + EPSILON;\n}\n/**\n * Test if A is greater than or equal to B\n */\nfunction GTE(a, b) {\n    return GT(a, b) || EQ(a, b);\n}\n/**\n * Test if A is less than B\n */\nfunction LT(a, b) {\n    return a + EPSILON < b;\n}\n/**\n * Test if A is less than B\n */\nfunction EQ(a, b) {\n    return Math.abs(a - b) < EPSILON;\n}\n/**\n * Clamp the value within the given range\n */\nfunction clamp(value, min, max) {\n    return Math.max(Math.min(value, max), min);\n}\n//# sourceMappingURL=Math.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Math.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/StateTimeline.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/StateTimeline.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StateTimeline\": () => (/* binding */ StateTimeline)\n/* harmony export */ });\n/* harmony import */ var _Timeline__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n/**\n * A Timeline State. Provides the methods: `setStateAtTime(\"state\", time)` and `getValueAtTime(time)`\n * @param initial The initial state of the StateTimeline.  Defaults to `undefined`\n */\nclass StateTimeline extends _Timeline__WEBPACK_IMPORTED_MODULE_0__.Timeline {\n    constructor(initial = \"stopped\") {\n        super();\n        this.name = \"StateTimeline\";\n        this._initial = initial;\n        this.setStateAtTime(this._initial, 0);\n    }\n    /**\n     * Returns the scheduled state scheduled before or at\n     * the given time.\n     * @param  time  The time to query.\n     * @return  The name of the state input in setStateAtTime.\n     */\n    getValueAtTime(time) {\n        const event = this.get(time);\n        if (event !== null) {\n            return event.state;\n        }\n        else {\n            return this._initial;\n        }\n    }\n    /**\n     * Add a state to the timeline.\n     * @param  state The name of the state to set.\n     * @param  time  The time to query.\n     * @param options Any additional options that are needed in the timeline.\n     */\n    setStateAtTime(state, time, options) {\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_1__.assertRange)(time, 0);\n        this.add(Object.assign({}, options, {\n            state,\n            time,\n        }));\n        return this;\n    }\n    /**\n     * Return the event before the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check before\n     * @return  The event with the given state before the time\n     */\n    getLastState(state, time) {\n        // time = this.toSeconds(time);\n        const index = this._search(time);\n        for (let i = index; i >= 0; i--) {\n            const event = this._timeline[i];\n            if (event.state === state) {\n                return event;\n            }\n        }\n    }\n    /**\n     * Return the event after the time with the given state\n     * @param  state The state to look for\n     * @param  time  When to check from\n     * @return  The event with the given state after the time\n     */\n    getNextState(state, time) {\n        // time = this.toSeconds(time);\n        const index = this._search(time);\n        if (index !== -1) {\n            for (let i = index; i < this._timeline.length; i++) {\n                const event = this._timeline[i];\n                if (event.state === state) {\n                    return event;\n                }\n            }\n        }\n    }\n}\n//# sourceMappingURL=StateTimeline.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/StateTimeline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/Timeline.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/Timeline.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Timeline\": () => (/* binding */ Timeline)\n/* harmony export */ });\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n/* harmony import */ var _Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _Math__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n/**\n * A Timeline class for scheduling and maintaining state\n * along a timeline. All events must have a \"time\" property.\n * Internally, events are stored in time order for fast\n * retrieval.\n */\nclass Timeline extends _Tone__WEBPACK_IMPORTED_MODULE_0__.Tone {\n    constructor() {\n        super();\n        this.name = \"Timeline\";\n        /**\n         * The array of scheduled timeline events\n         */\n        this._timeline = [];\n        const options = (0,_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Timeline.getDefaults(), arguments, [\"memory\"]);\n        this.memory = options.memory;\n        this.increasing = options.increasing;\n    }\n    static getDefaults() {\n        return {\n            memory: Infinity,\n            increasing: false,\n        };\n    }\n    /**\n     * The number of items in the timeline.\n     */\n    get length() {\n        return this._timeline.length;\n    }\n    /**\n     * Insert an event object onto the timeline. Events must have a \"time\" attribute.\n     * @param event  The event object to insert into the timeline.\n     */\n    add(event) {\n        // the event needs to have a time attribute\n        (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(Reflect.has(event, \"time\"), \"Timeline: events must have a time attribute\");\n        event.time = event.time.valueOf();\n        if (this.increasing && this.length) {\n            const lastValue = this._timeline[this.length - 1];\n            (0,_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)((0,_Math__WEBPACK_IMPORTED_MODULE_3__.GTE)(event.time, lastValue.time), \"The time must be greater than or equal to the last scheduled time\");\n            this._timeline.push(event);\n        }\n        else {\n            const index = this._search(event.time);\n            this._timeline.splice(index + 1, 0, event);\n        }\n        // if the length is more than the memory, remove the previous ones\n        if (this.length > this.memory) {\n            const diff = this.length - this.memory;\n            this._timeline.splice(0, diff);\n        }\n        return this;\n    }\n    /**\n     * Remove an event from the timeline.\n     * @param  {Object}  event  The event object to remove from the list.\n     * @returns {Timeline} this\n     */\n    remove(event) {\n        const index = this._timeline.indexOf(event);\n        if (index !== -1) {\n            this._timeline.splice(index, 1);\n        }\n        return this;\n    }\n    /**\n     * Get the nearest event whose time is less than or equal to the given time.\n     * @param  time  The time to query.\n     */\n    get(time, param = \"time\") {\n        const index = this._search(time, param);\n        if (index !== -1) {\n            return this._timeline[index];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Return the first event in the timeline without removing it\n     * @returns {Object} The first event object\n     */\n    peek() {\n        return this._timeline[0];\n    }\n    /**\n     * Return the first event in the timeline and remove it\n     */\n    shift() {\n        return this._timeline.shift();\n    }\n    /**\n     * Get the event which is scheduled after the given time.\n     * @param  time  The time to query.\n     */\n    getAfter(time, param = \"time\") {\n        const index = this._search(time, param);\n        if (index + 1 < this._timeline.length) {\n            return this._timeline[index + 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Get the event before the event at the given time.\n     * @param  time  The time to query.\n     */\n    getBefore(time) {\n        const len = this._timeline.length;\n        // if it's after the last item, return the last item\n        if (len > 0 && this._timeline[len - 1].time < time) {\n            return this._timeline[len - 1];\n        }\n        const index = this._search(time);\n        if (index - 1 >= 0) {\n            return this._timeline[index - 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Cancel events at and after the given time\n     * @param  after  The time to query.\n     */\n    cancel(after) {\n        if (this._timeline.length > 1) {\n            let index = this._search(after);\n            if (index >= 0) {\n                if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[index].time, after)) {\n                    // get the first item with that time\n                    for (let i = index; i >= 0; i--) {\n                        if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[i].time, after)) {\n                            index = i;\n                        }\n                        else {\n                            break;\n                        }\n                    }\n                    this._timeline = this._timeline.slice(0, index);\n                }\n                else {\n                    this._timeline = this._timeline.slice(0, index + 1);\n                }\n            }\n            else {\n                this._timeline = [];\n            }\n        }\n        else if (this._timeline.length === 1) {\n            // the first item's time\n            if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.GTE)(this._timeline[0].time, after)) {\n                this._timeline = [];\n            }\n        }\n        return this;\n    }\n    /**\n     * Cancel events before or equal to the given time.\n     * @param  time  The time to cancel before.\n     */\n    cancelBefore(time) {\n        const index = this._search(time);\n        if (index >= 0) {\n            this._timeline = this._timeline.slice(index + 1);\n        }\n        return this;\n    }\n    /**\n     * Returns the previous event if there is one. null otherwise\n     * @param  event The event to find the previous one of\n     * @return The event right before the given event\n     */\n    previousEvent(event) {\n        const index = this._timeline.indexOf(event);\n        if (index > 0) {\n            return this._timeline[index - 1];\n        }\n        else {\n            return null;\n        }\n    }\n    /**\n     * Does a binary search on the timeline array and returns the\n     * nearest event index whose time is after or equal to the given time.\n     * If a time is searched before the first index in the timeline, -1 is returned.\n     * If the time is after the end, the index of the last item is returned.\n     */\n    _search(time, param = \"time\") {\n        if (this._timeline.length === 0) {\n            return -1;\n        }\n        let beginning = 0;\n        const len = this._timeline.length;\n        let end = len;\n        if (len > 0 && this._timeline[len - 1][param] <= time) {\n            return len - 1;\n        }\n        while (beginning < end) {\n            // calculate the midpoint for roughly equal partition\n            let midPoint = Math.floor(beginning + (end - beginning) / 2);\n            const event = this._timeline[midPoint];\n            const nextEvent = this._timeline[midPoint + 1];\n            if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(event[param], time)) {\n                // choose the last one that has the same time\n                for (let i = midPoint; i < this._timeline.length; i++) {\n                    const testEvent = this._timeline[i];\n                    if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(testEvent[param], time)) {\n                        midPoint = i;\n                    }\n                    else {\n                        break;\n                    }\n                }\n                return midPoint;\n            }\n            else if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.LT)(event[param], time) && (0,_Math__WEBPACK_IMPORTED_MODULE_3__.GT)(nextEvent[param], time)) {\n                return midPoint;\n            }\n            else if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.GT)(event[param], time)) {\n                // search lower\n                end = midPoint;\n            }\n            else {\n                // search upper\n                beginning = midPoint + 1;\n            }\n        }\n        return -1;\n    }\n    /**\n     * Internal iterator. Applies extra safety checks for\n     * removing items from the array.\n     */\n    _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {\n        this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);\n    }\n    /**\n     * Iterate over everything in the array\n     * @param  callback The callback to invoke with every item\n     */\n    forEach(callback) {\n        this._iterate(callback);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at or before the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBefore(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const upperBound = this._search(time);\n        if (upperBound !== -1) {\n            this._iterate(callback, 0, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array after the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAfter(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const lowerBound = this._search(time);\n        this._iterate(callback, lowerBound + 1);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array between the startTime and endTime.\n     * The timerange is inclusive of the startTime, but exclusive of the endTime.\n     * range = [startTime, endTime).\n     * @param  startTime The time to check if items are before\n     * @param  endTime The end of the test interval.\n     * @param  callback The callback to invoke with every item\n     */\n    forEachBetween(startTime, endTime, callback) {\n        let lowerBound = this._search(startTime);\n        let upperBound = this._search(endTime);\n        if (lowerBound !== -1 && upperBound !== -1) {\n            if (this._timeline[lowerBound].time !== startTime) {\n                lowerBound += 1;\n            }\n            // exclusive of the end time\n            if (this._timeline[upperBound].time === endTime) {\n                upperBound -= 1;\n            }\n            this._iterate(callback, lowerBound, upperBound);\n        }\n        else if (lowerBound === -1) {\n            this._iterate(callback, 0, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at or after the given time. Similar to\n     * forEachAfter, but includes the item(s) at the given time.\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachFrom(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        let lowerBound = this._search(time);\n        // work backwards until the event time is less than time\n        while (lowerBound >= 0 && this._timeline[lowerBound].time >= time) {\n            lowerBound--;\n        }\n        this._iterate(callback, lowerBound + 1);\n        return this;\n    }\n    /**\n     * Iterate over everything in the array at the given time\n     * @param  time The time to check if items are before\n     * @param  callback The callback to invoke with every item\n     */\n    forEachAtTime(time, callback) {\n        // iterate over the items in reverse so that removing an item doesn't break things\n        const upperBound = this._search(time);\n        if (upperBound !== -1 && (0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[upperBound].time, time)) {\n            let lowerBound = upperBound;\n            for (let i = upperBound; i >= 0; i--) {\n                if ((0,_Math__WEBPACK_IMPORTED_MODULE_3__.EQ)(this._timeline[i].time, time)) {\n                    lowerBound = i;\n                }\n                else {\n                    break;\n                }\n            }\n            this._iterate(event => {\n                callback(event);\n            }, lowerBound, upperBound);\n        }\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._timeline = [];\n        return this;\n    }\n}\n//# sourceMappingURL=Timeline.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/Timeline.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/TimelineValue.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/TimelineValue.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"TimelineValue\": () => (/* binding */ TimelineValue)\n/* harmony export */ });\n/* harmony import */ var _Timeline__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Timeline */ \"./node_modules/tone/build/esm/core/util/Timeline.js\");\n/* harmony import */ var _Tone__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../Tone */ \"./node_modules/tone/build/esm/core/Tone.js\");\n\n\n/**\n * Represents a single value which is gettable and settable in a timed way\n */\nclass TimelineValue extends _Tone__WEBPACK_IMPORTED_MODULE_1__.Tone {\n    /**\n     * @param initialValue The value to return if there is no scheduled values\n     */\n    constructor(initialValue) {\n        super();\n        this.name = \"TimelineValue\";\n        /**\n         * The timeline which stores the values\n         */\n        this._timeline = new _Timeline__WEBPACK_IMPORTED_MODULE_0__.Timeline({ memory: 10 });\n        this._initialValue = initialValue;\n    }\n    /**\n     * Set the value at the given time\n     */\n    set(value, time) {\n        this._timeline.add({\n            value, time\n        });\n        return this;\n    }\n    /**\n     * Get the value at the given time\n     */\n    get(time) {\n        const event = this._timeline.get(time);\n        if (event) {\n            return event.value;\n        }\n        else {\n            return this._initialValue;\n        }\n    }\n}\n//# sourceMappingURL=TimelineValue.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/TimelineValue.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/util/TypeCheck.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/util/TypeCheck.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"isArray\": () => (/* binding */ isArray),\n/* harmony export */   \"isBoolean\": () => (/* binding */ isBoolean),\n/* harmony export */   \"isDefined\": () => (/* binding */ isDefined),\n/* harmony export */   \"isFunction\": () => (/* binding */ isFunction),\n/* harmony export */   \"isNote\": () => (/* binding */ isNote),\n/* harmony export */   \"isNumber\": () => (/* binding */ isNumber),\n/* harmony export */   \"isObject\": () => (/* binding */ isObject),\n/* harmony export */   \"isString\": () => (/* binding */ isString),\n/* harmony export */   \"isUndef\": () => (/* binding */ isUndef)\n/* harmony export */ });\n/**\n * Test if the arg is undefined\n */\nfunction isUndef(arg) {\n    return typeof arg === \"undefined\";\n}\n/**\n * Test if the arg is not undefined\n */\nfunction isDefined(arg) {\n    return !isUndef(arg);\n}\n/**\n * Test if the arg is a function\n */\nfunction isFunction(arg) {\n    return typeof arg === \"function\";\n}\n/**\n * Test if the argument is a number.\n */\nfunction isNumber(arg) {\n    return (typeof arg === \"number\");\n}\n/**\n * Test if the given argument is an object literal (i.e. `{}`);\n */\nfunction isObject(arg) {\n    return (Object.prototype.toString.call(arg) === \"[object Object]\" && arg.constructor === Object);\n}\n/**\n * Test if the argument is a boolean.\n */\nfunction isBoolean(arg) {\n    return (typeof arg === \"boolean\");\n}\n/**\n * Test if the argument is an Array\n */\nfunction isArray(arg) {\n    return (Array.isArray(arg));\n}\n/**\n * Test if the argument is a string.\n */\nfunction isString(arg) {\n    return (typeof arg === \"string\");\n}\n/**\n * Test if the argument is in the form of a note in scientific pitch notation.\n * e.g. \"C4\"\n */\nfunction isNote(arg) {\n    return isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);\n}\n//# sourceMappingURL=TypeCheck.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/util/TypeCheck.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\nconst delayLine = /* javascript */ `\n\t/**\n\t * A multichannel buffer for use within an AudioWorkletProcessor as a delay line\n\t */\n\tclass DelayLine {\n\t\t\n\t\tconstructor(size, channels) {\n\t\t\tthis.buffer = [];\n\t\t\tthis.writeHead = []\n\t\t\tthis.size = size;\n\n\t\t\t// create the empty channels\n\t\t\tfor (let i = 0; i < channels; i++) {\n\t\t\t\tthis.buffer[i] = new Float32Array(this.size);\n\t\t\t\tthis.writeHead[i] = 0;\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Push a value onto the end\n\t\t * @param channel number\n\t\t * @param value number\n\t\t */\n\t\tpush(channel, value) {\n\t\t\tthis.writeHead[channel] += 1;\n\t\t\tif (this.writeHead[channel] > this.size) {\n\t\t\t\tthis.writeHead[channel] = 0;\n\t\t\t}\n\t\t\tthis.buffer[channel][this.writeHead[channel]] = value;\n\t\t}\n\n\t\t/**\n\t\t * Get the recorded value of the channel given the delay\n\t\t * @param channel number\n\t\t * @param delay number delay samples\n\t\t */\n\t\tget(channel, delay) {\n\t\t\tlet readHead = this.writeHead[channel] - Math.floor(delay);\n\t\t\tif (readHead < 0) {\n\t\t\t\treadHead += this.size;\n\t\t\t}\n\t\t\treturn this.buffer[channel][readHead];\n\t\t}\n\t}\n`;\n(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__.addToWorklet)(delayLine);\n//# sourceMappingURL=DelayLine.worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/worklet/DelayLine.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js ***!
  \*******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"singleIOProcess\": () => (/* binding */ singleIOProcess)\n/* harmony export */ });\n/* harmony import */ var _ToneAudioWorkletProcessor_worklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ToneAudioWorkletProcessor.worklet */ \"./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js\");\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\nconst singleIOProcess = /* javascript */ `\n\t/**\n\t * Abstract class for a single input/output processor. \n\t * has a 'generate' function which processes one sample at a time\n\t */\n\tclass SingleIOProcessor extends ToneAudioWorkletProcessor {\n\n\t\tconstructor(options) {\n\t\t\tsuper(Object.assign(options, {\n\t\t\t\tnumberOfInputs: 1,\n\t\t\t\tnumberOfOutputs: 1\n\t\t\t}));\n\t\t\t/**\n\t\t\t * Holds the name of the parameter and a single value of that\n\t\t\t * parameter at the current sample\n\t\t\t * @type { [name: string]: number }\n\t\t\t */\n\t\t\tthis.params = {}\n\t\t}\n\n\t\t/**\n\t\t * Generate an output sample from the input sample and parameters\n\t\t * @abstract\n\t\t * @param input number\n\t\t * @param channel number\n\t\t * @param parameters { [name: string]: number }\n\t\t * @returns number\n\t\t */\n\t\tgenerate(){}\n\n\t\t/**\n\t\t * Update the private params object with the \n\t\t * values of the parameters at the given index\n\t\t * @param parameters { [name: string]: Float32Array },\n\t\t * @param index number\n\t\t */\n\t\tupdateParams(parameters, index) {\n\t\t\tfor (const paramName in parameters) {\n\t\t\t\tconst param = parameters[paramName];\n\t\t\t\tif (param.length > 1) {\n\t\t\t\t\tthis.params[paramName] = parameters[paramName][index];\n\t\t\t\t} else {\n\t\t\t\t\tthis.params[paramName] = parameters[paramName][0];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/**\n\t\t * Process a single frame of the audio\n\t\t * @param inputs Float32Array[][]\n\t\t * @param outputs Float32Array[][]\n\t\t */\n\t\tprocess(inputs, outputs, parameters) {\n\t\t\tconst input = inputs[0];\n\t\t\tconst output = outputs[0];\n\t\t\t// get the parameter values\n\t\t\tconst channelCount = Math.max(input && input.length || 0, output.length);\n\t\t\tfor (let sample = 0; sample < this.blockSize; sample++) {\n\t\t\t\tthis.updateParams(parameters, sample);\n\t\t\t\tfor (let channel = 0; channel < channelCount; channel++) {\n\t\t\t\t\tconst inputSample = input && input.length ? input[channel][sample] : 0;\n\t\t\t\t\toutput[channel][sample] = this.generate(inputSample, channel, this.params);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn !this.disposed;\n\t\t}\n\t};\n`;\n(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__.addToWorklet)(singleIOProcess);\n//# sourceMappingURL=SingleIOProcessor.worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js":
/*!**********************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneAudioWorklet\": () => (/* binding */ ToneAudioWorklet)\n/* harmony export */ });\n/* harmony import */ var _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\n\nclass ToneAudioWorklet extends _context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"ToneAudioWorklet\";\n        /**\n         * The constructor options for the node\n         */\n        this.workletOptions = {};\n        /**\n         * Callback which is invoked when there is an error in the processing\n         */\n        this.onprocessorerror = _util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp;\n        const blobUrl = URL.createObjectURL(new Blob([(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_2__.getWorkletGlobalScope)()], { type: \"text/javascript\" }));\n        const name = this._audioWorkletName();\n        this._dummyGain = this.context.createGain();\n        this._dummyParam = this._dummyGain.gain;\n        // Register the processor\n        this.context.addAudioWorkletModule(blobUrl, name).then(() => {\n            // create the worklet when it's read\n            if (!this.disposed) {\n                this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);\n                this._worklet.onprocessorerror = this.onprocessorerror.bind(this);\n                this.onReady(this._worklet);\n            }\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._dummyGain.disconnect();\n        if (this._worklet) {\n            this._worklet.port.postMessage(\"dispose\");\n            this._worklet.disconnect();\n        }\n        return this;\n    }\n}\n//# sourceMappingURL=ToneAudioWorklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js":
/*!***************************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js ***!
  \***************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\nconst toneAudioWorkletProcessor = /* javascript */ `\n\t/**\n\t * The base AudioWorkletProcessor for use in Tone.js. Works with the [[ToneAudioWorklet]]. \n\t */\n\tclass ToneAudioWorkletProcessor extends AudioWorkletProcessor {\n\n\t\tconstructor(options) {\n\t\t\t\n\t\t\tsuper(options);\n\t\t\t/**\n\t\t\t * If the processor was disposed or not. Keep alive until it's disposed.\n\t\t\t */\n\t\t\tthis.disposed = false;\n\t\t   \t/** \n\t\t\t * The number of samples in the processing block\n\t\t\t */\n\t\t\tthis.blockSize = 128;\n\t\t\t/**\n\t\t\t * the sample rate\n\t\t\t */\n\t\t\tthis.sampleRate = sampleRate;\n\n\t\t\tthis.port.onmessage = (event) => {\n\t\t\t\t// when it receives a dispose \n\t\t\t\tif (event.data === \"dispose\") {\n\t\t\t\t\tthis.disposed = true;\n\t\t\t\t}\n\t\t\t};\n\t\t}\n\t}\n`;\n(0,_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_0__.addToWorklet)(toneAudioWorkletProcessor);\n//# sourceMappingURL=ToneAudioWorkletProcessor.worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/worklet/ToneAudioWorkletProcessor.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"addToWorklet\": () => (/* binding */ addToWorklet),\n/* harmony export */   \"getWorkletGlobalScope\": () => (/* binding */ getWorkletGlobalScope),\n/* harmony export */   \"registerProcessor\": () => (/* binding */ registerProcessor)\n/* harmony export */ });\n/**\n * All of the classes or functions which are loaded into the AudioWorkletGlobalScope\n */\nconst workletContext = new Set();\n/**\n * Add a class to the AudioWorkletGlobalScope\n */\nfunction addToWorklet(classOrFunction) {\n    workletContext.add(classOrFunction);\n}\n/**\n * Register a processor in the AudioWorkletGlobalScope with the given name\n */\nfunction registerProcessor(name, classDesc) {\n    const processor = /* javascript */ `registerProcessor(\"${name}\", ${classDesc})`;\n    workletContext.add(processor);\n}\n/**\n * Get all of the modules which have been registered to the AudioWorkletGlobalScope\n */\nfunction getWorkletGlobalScope() {\n    return Array.from(workletContext).join(\"\\n\");\n}\n//# sourceMappingURL=WorkletGlobalScope.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/AutoFilter.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/AutoFilter.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoFilter\": () => (/* binding */ AutoFilter)\n/* harmony export */ });\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _LFOEffect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LFOEffect */ \"./node_modules/tone/build/esm/effect/LFOEffect.js\");\n\n\n\n/**\n * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.\n * Setting the LFO rate and depth allows for control over the filter modulation rate\n * and depth.\n *\n * @example\n * // create an autofilter and start it's LFO\n * const autoFilter = new Tone.AutoFilter(\"4n\").toDestination().start();\n * // route an oscillator through the filter and start it\n * const oscillator = new Tone.Oscillator().connect(autoFilter).start();\n * @category Effect\n */\nclass AutoFilter extends _LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoFilter.getDefaults(), arguments, [\"frequency\", \"baseFrequency\", \"octaves\"]));\n        this.name = \"AutoFilter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoFilter.getDefaults(), arguments, [\"frequency\", \"baseFrequency\", \"octaves\"]);\n        this.filter = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_0__.Filter(Object.assign(options.filter, {\n            context: this.context,\n        }));\n        // connections\n        this.connectEffect(this.filter);\n        this._lfo.connect(this.filter.frequency);\n        this.octaves = options.octaves;\n        this.baseFrequency = options.baseFrequency;\n    }\n    static getDefaults() {\n        return Object.assign(_LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect.getDefaults(), {\n            baseFrequency: 200,\n            octaves: 2.6,\n            filter: {\n                type: \"lowpass\",\n                rolloff: -12,\n                Q: 1,\n            }\n        });\n    }\n    /**\n     * The minimum value of the filter's cutoff frequency.\n     */\n    get baseFrequency() {\n        return this._lfo.min;\n    }\n    set baseFrequency(freq) {\n        this._lfo.min = this.toFrequency(freq);\n        // and set the max\n        this.octaves = this._octaves;\n    }\n    /**\n     * The maximum value of the filter's cutoff frequency.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(oct) {\n        this._octaves = oct;\n        this._lfo.max = this._lfo.min * Math.pow(2, oct);\n    }\n    dispose() {\n        super.dispose();\n        this.filter.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoFilter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/AutoFilter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/AutoPanner.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/AutoPanner.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoPanner\": () => (/* binding */ AutoPanner)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Panner__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Panner */ \"./node_modules/tone/build/esm/component/channel/Panner.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _LFOEffect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LFOEffect */ \"./node_modules/tone/build/esm/effect/LFOEffect.js\");\n\n\n\n/**\n * AutoPanner is a [[Panner]] with an [[LFO]] connected to the pan amount.\n * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).\n *\n * @example\n * // create an autopanner and start it\n * const autoPanner = new Tone.AutoPanner(\"4n\").toDestination().start();\n * // route an oscillator through the panner and start it\n * const oscillator = new Tone.Oscillator().connect(autoPanner).start();\n * @category Effect\n */\nclass AutoPanner extends _LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoPanner.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"AutoPanner\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AutoPanner.getDefaults(), arguments, [\"frequency\"]);\n        this._panner = new _component_channel_Panner__WEBPACK_IMPORTED_MODULE_0__.Panner({\n            context: this.context,\n            channelCount: options.channelCount\n        });\n        // connections\n        this.connectEffect(this._panner);\n        this._lfo.connect(this._panner.pan);\n        this._lfo.min = -1;\n        this._lfo.max = 1;\n    }\n    static getDefaults() {\n        return Object.assign(_LFOEffect__WEBPACK_IMPORTED_MODULE_2__.LFOEffect.getDefaults(), {\n            channelCount: 1\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._panner.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoPanner.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/AutoPanner.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/AutoWah.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/AutoWah.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoWah\": () => (/* binding */ AutoWah)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _component_analysis_Follower__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/analysis/Follower */ \"./node_modules/tone/build/esm/component/analysis/Follower.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _signal_ScaleExp__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/ScaleExp */ \"./node_modules/tone/build/esm/signal/ScaleExp.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n\n\n/**\n * AutoWah connects a [[Follower]] to a [[Filter]].\n * The frequency of the filter, follows the input amplitude curve.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).\n *\n * @example\n * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();\n * // initialize the synth and connect to autowah\n * const synth = new Tone.Synth().connect(autoWah);\n * // Q value influences the effect of the wah - default is 2\n * autoWah.Q.value = 6;\n * // more audible on higher notes\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Effect\n */\nclass AutoWah extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(AutoWah.getDefaults(), arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"]));\n        this.name = \"AutoWah\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(AutoWah.getDefaults(), arguments, [\"baseFrequency\", \"octaves\", \"sensitivity\"]);\n        this._follower = new _component_analysis_Follower__WEBPACK_IMPORTED_MODULE_2__.Follower({\n            context: this.context,\n            smoothing: options.follower,\n        });\n        this._sweepRange = new _signal_ScaleExp__WEBPACK_IMPORTED_MODULE_6__.ScaleExp({\n            context: this.context,\n            min: 0,\n            max: 1,\n            exponent: 0.5,\n        });\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._octaves = options.octaves;\n        this._inputBoost = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_4__.Gain({ context: this.context });\n        this._bandpass = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__.Filter({\n            context: this.context,\n            rolloff: -48,\n            frequency: 0,\n            Q: options.Q,\n        });\n        this._peaking = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__.Filter({\n            context: this.context,\n            type: \"peaking\"\n        });\n        this._peaking.gain.value = options.gain;\n        this.gain = this._peaking.gain;\n        this.Q = this._bandpass.Q;\n        // the control signal path\n        this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);\n        this._sweepRange.connect(this._bandpass.frequency);\n        this._sweepRange.connect(this._peaking.frequency);\n        // the filtered path\n        this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);\n        // set the initial value\n        this._setSweepRange();\n        this.sensitivity = options.sensitivity;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_7__.readOnly)(this, [\"gain\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            baseFrequency: 100,\n            octaves: 6,\n            sensitivity: 0,\n            Q: 2,\n            gain: 2,\n            follower: 0.2,\n        });\n    }\n    /**\n     * The number of octaves that the filter will sweep above the baseFrequency.\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        this._setSweepRange();\n    }\n    /**\n     * The follower's smoothing time\n     */\n    get follower() {\n        return this._follower.smoothing;\n    }\n    set follower(follower) {\n        this._follower.smoothing = follower;\n    }\n    /**\n     * The base frequency from which the sweep will start from.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(baseFreq) {\n        this._baseFrequency = this.toFrequency(baseFreq);\n        this._setSweepRange();\n    }\n    /**\n     * The sensitivity to control how responsive to the input signal the filter is.\n     */\n    get sensitivity() {\n        return (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.gainToDb)(1 / this._inputBoost.gain.value);\n    }\n    set sensitivity(sensitivity) {\n        this._inputBoost.gain.value = 1 / (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_5__.dbToGain)(sensitivity);\n    }\n    /**\n     * sets the sweep range of the scaler\n     */\n    _setSweepRange() {\n        this._sweepRange.min = this._baseFrequency;\n        this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);\n    }\n    dispose() {\n        super.dispose();\n        this._follower.dispose();\n        this._sweepRange.dispose();\n        this._bandpass.dispose();\n        this._peaking.dispose();\n        this._inputBoost.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AutoWah.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/AutoWah.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/BitCrusher.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/BitCrusher.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BitCrusher\": () => (/* binding */ BitCrusher)\n/* harmony export */ });\n/* harmony import */ var _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/worklet/ToneAudioWorklet */ \"./node_modules/tone/build/esm/core/worklet/ToneAudioWorklet.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _BitCrusher_worklet__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./BitCrusher.worklet */ \"./node_modules/tone/build/esm/effect/BitCrusher.worklet.js\");\n\n\n\n\n\n\n\n/**\n * BitCrusher down-samples the incoming signal to a different bit depth.\n * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing\n * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).\n * @example\n * // initialize crusher and route a synth through it\n * const crusher = new Tone.BitCrusher(4).toDestination();\n * const synth = new Tone.Synth().connect(crusher);\n * synth.triggerAttackRelease(\"C2\", 2);\n *\n * @category Effect\n */\nclass BitCrusher extends _Effect__WEBPACK_IMPORTED_MODULE_1__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusher.getDefaults(), arguments, [\"bits\"]));\n        this.name = \"BitCrusher\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusher.getDefaults(), arguments, [\"bits\"]);\n        this._bitCrusherWorklet = new BitCrusherWorklet({\n            context: this.context,\n            bits: options.bits,\n        });\n        // connect it up\n        this.connectEffect(this._bitCrusherWorklet);\n        this.bits = this._bitCrusherWorklet.bits;\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_1__.Effect.getDefaults(), {\n            bits: 4,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._bitCrusherWorklet.dispose();\n        return this;\n    }\n}\n/**\n * Internal class which creates an AudioWorklet to do the bit crushing\n */\nclass BitCrusherWorklet extends _core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_0__.ToneAudioWorklet {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusherWorklet.getDefaults(), arguments));\n        this.name = \"BitCrusherWorklet\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(BitCrusherWorklet.getDefaults(), arguments);\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.bits = new _core_context_Param__WEBPACK_IMPORTED_MODULE_5__.Param({\n            context: this.context,\n            value: options.bits,\n            units: \"positive\",\n            minValue: 1,\n            maxValue: 16,\n            param: this._dummyParam,\n            swappable: true,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_core_worklet_ToneAudioWorklet__WEBPACK_IMPORTED_MODULE_0__.ToneAudioWorklet.getDefaults(), {\n            bits: 12,\n        });\n    }\n    _audioWorkletName() {\n        return _BitCrusher_worklet__WEBPACK_IMPORTED_MODULE_6__.workletName;\n    }\n    onReady(node) {\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.connectSeries)(this.input, node, this.output);\n        const bits = node.parameters.get(\"bits\");\n        this.bits.setParam(bits);\n    }\n    dispose() {\n        super.dispose();\n        this.input.dispose();\n        this.output.dispose();\n        this.bits.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=BitCrusher.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/BitCrusher.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/BitCrusher.worklet.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/BitCrusher.worklet.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"bitCrusherWorklet\": () => (/* binding */ bitCrusherWorklet),\n/* harmony export */   \"workletName\": () => (/* binding */ workletName)\n/* harmony export */ });\n/* harmony import */ var _core_worklet_SingleIOProcessor_worklet__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/worklet/SingleIOProcessor.worklet */ \"./node_modules/tone/build/esm/core/worklet/SingleIOProcessor.worklet.js\");\n/* harmony import */ var _core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/worklet/WorkletGlobalScope */ \"./node_modules/tone/build/esm/core/worklet/WorkletGlobalScope.js\");\n\n\nconst workletName = \"bit-crusher\";\nconst bitCrusherWorklet = /* javascript */ `\n\tclass BitCrusherWorklet extends SingleIOProcessor {\n\n\t\tstatic get parameterDescriptors() {\n\t\t\treturn [{\n\t\t\t\tname: \"bits\",\n\t\t\t\tdefaultValue: 12,\n\t\t\t\tminValue: 1,\n\t\t\t\tmaxValue: 16,\n\t\t\t\tautomationRate: 'k-rate'\n\t\t\t}];\n\t\t}\n\n\t\tgenerate(input, _channel, parameters) {\n\t\t\tconst step = Math.pow(0.5, parameters.bits - 1);\n\t\t\tconst val = step * Math.floor(input / step + 0.5);\n\t\t\treturn val;\n\t\t}\n\t}\n`;\n(0,_core_worklet_WorkletGlobalScope__WEBPACK_IMPORTED_MODULE_1__.registerProcessor)(workletName, bitCrusherWorklet);\n//# sourceMappingURL=BitCrusher.worklet.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/BitCrusher.worklet.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Chebyshev.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Chebyshev.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Chebyshev\": () => (/* binding */ Chebyshev)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n\n/**\n * Chebyshev is a waveshaper which is good\n * for making different types of distortion sounds.\n * Note that odd orders sound very different from even ones,\n * and order = 1 is no change.\n * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).\n * @example\n * // create a new cheby\n * const cheby = new Tone.Chebyshev(50).toDestination();\n * // create a monosynth connected to our cheby\n * const synth = new Tone.MonoSynth().connect(cheby);\n * synth.triggerAttackRelease(\"C2\", 0.4);\n * @category Effect\n */\nclass Chebyshev extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chebyshev.getDefaults(), arguments, [\"order\"]));\n        this.name = \"Chebyshev\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chebyshev.getDefaults(), arguments, [\"order\"]);\n        this._shaper = new _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_2__.WaveShaper({\n            context: this.context,\n            length: 4096\n        });\n        this._order = options.order;\n        this.connectEffect(this._shaper);\n        this.order = options.order;\n        this.oversample = options.oversample;\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            order: 1,\n            oversample: \"none\"\n        });\n    }\n    /**\n     * get the coefficient for that degree\n     * @param  x the x value\n     * @param  degree\n     * @param  memo memoize the computed value. this speeds up computation greatly.\n     */\n    _getCoefficient(x, degree, memo) {\n        if (memo.has(degree)) {\n            return memo.get(degree);\n        }\n        else if (degree === 0) {\n            memo.set(degree, 0);\n        }\n        else if (degree === 1) {\n            memo.set(degree, x);\n        }\n        else {\n            memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));\n        }\n        return memo.get(degree);\n    }\n    /**\n     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming\n     * signal through a Tone.WaveShaper. The equations are in the form:\n     * ```\n     * order 2: 2x^2 + 1\n     * order 3: 4x^3 + 3x\n     * ```\n     * @min 1\n     * @max 100\n     */\n    get order() {\n        return this._order;\n    }\n    set order(order) {\n        this._order = order;\n        this._shaper.setMap((x => {\n            return this._getCoefficient(x, order, new Map());\n        }));\n    }\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        this._shaper.oversample = oversampling;\n    }\n    dispose() {\n        super.dispose();\n        this._shaper.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Chebyshev.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Chebyshev.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Chorus.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Chorus.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Chorus\": () => (/* binding */ Chorus)\n/* harmony export */ });\n/* harmony import */ var _effect_StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../effect/StereoFeedbackEffect */ \"./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Chorus is a stereo chorus effect composed of a left and right delay with an [[LFO]] applied to the delayTime of each channel.\n * When [[feedback]] is set to a value larger than 0, you also get Flanger-type effects.\n * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).\n * Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).\n *\n * @example\n * const chorus = new Tone.Chorus(4, 2.5, 0.5).toDestination().start();\n * const synth = new Tone.PolySynth().connect(chorus);\n * synth.triggerAttackRelease([\"C3\", \"E3\", \"G3\"], \"8n\");\n *\n * @category Effect\n */\nclass Chorus extends _effect_StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoFeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chorus.getDefaults(), arguments, [\"frequency\", \"delayTime\", \"depth\"]));\n        this.name = \"Chorus\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Chorus.getDefaults(), arguments, [\"frequency\", \"delayTime\", \"depth\"]);\n        this._depth = options.depth;\n        this._delayTime = options.delayTime / 1000;\n        this._lfoL = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n        });\n        this._lfoR = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n            phase: 180\n        });\n        this._delayNodeL = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({ context: this.context });\n        this._delayNodeR = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({ context: this.context });\n        this.frequency = this._lfoL.frequency;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\"]);\n        // have one LFO frequency control the other\n        this._lfoL.frequency.connect(this._lfoR.frequency);\n        // connections\n        this.connectEffectLeft(this._delayNodeL);\n        this.connectEffectRight(this._delayNodeR);\n        // lfo setup\n        this._lfoL.connect(this._delayNodeL.delayTime);\n        this._lfoR.connect(this._delayNodeR.delayTime);\n        // set the initial values\n        this.depth = this._depth;\n        this.type = options.type;\n        this.spread = options.spread;\n    }\n    static getDefaults() {\n        return Object.assign(_effect_StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoFeedbackEffect.getDefaults(), {\n            frequency: 1.5,\n            delayTime: 3.5,\n            depth: 0.7,\n            type: \"sine\",\n            spread: 180,\n            feedback: 0,\n            wet: 0.5,\n        });\n    }\n    /**\n     * The depth of the effect. A depth of 1 makes the delayTime\n     * modulate between 0 and 2*delayTime (centered around the delayTime).\n     */\n    get depth() {\n        return this._depth;\n    }\n    set depth(depth) {\n        this._depth = depth;\n        const deviation = this._delayTime * depth;\n        this._lfoL.min = Math.max(this._delayTime - deviation, 0);\n        this._lfoL.max = this._delayTime + deviation;\n        this._lfoR.min = Math.max(this._delayTime - deviation, 0);\n        this._lfoR.max = this._delayTime + deviation;\n    }\n    /**\n     * The delayTime in milliseconds of the chorus. A larger delayTime\n     * will give a more pronounced effect. Nominal range a delayTime\n     * is between 2 and 20ms.\n     */\n    get delayTime() {\n        return this._delayTime * 1000;\n    }\n    set delayTime(delayTime) {\n        this._delayTime = delayTime / 1000;\n        this.depth = this._depth;\n    }\n    /**\n     * The oscillator type of the LFO.\n     */\n    get type() {\n        return this._lfoL.type;\n    }\n    set type(type) {\n        this._lfoL.type = type;\n        this._lfoR.type = type;\n    }\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread() {\n        return this._lfoR.phase - this._lfoL.phase;\n    }\n    set spread(spread) {\n        this._lfoL.phase = 90 - (spread / 2);\n        this._lfoR.phase = (spread / 2) + 90;\n    }\n    /**\n     * Start the effect.\n     */\n    start(time) {\n        this._lfoL.start(time);\n        this._lfoR.start(time);\n        return this;\n    }\n    /**\n     * Stop the lfo\n     */\n    stop(time) {\n        this._lfoL.stop(time);\n        this._lfoR.stop(time);\n        return this;\n    }\n    /**\n     * Sync the filter to the transport. See [[LFO.sync]]\n     */\n    sync() {\n        this._lfoL.sync();\n        this._lfoR.sync();\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync() {\n        this._lfoL.unsync();\n        this._lfoR.unsync();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._delayNodeL.dispose();\n        this._delayNodeR.dispose();\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Chorus.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Chorus.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Distortion.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Distortion.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Distortion\": () => (/* binding */ Distortion)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n\n\n\n/**\n * A simple distortion effect using Tone.WaveShaper.\n * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).\n *\n * @example\n * const dist = new Tone.Distortion(0.8).toDestination();\n * const fm = new Tone.FMSynth().connect(dist);\n * fm.triggerAttackRelease(\"A1\", \"8n\");\n * @category Effect\n */\nclass Distortion extends _Effect__WEBPACK_IMPORTED_MODULE_2__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Distortion.getDefaults(), arguments, [\"distortion\"]));\n        this.name = \"Distortion\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Distortion.getDefaults(), arguments, [\"distortion\"]);\n        this._shaper = new _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            length: 4096,\n        });\n        this._distortion = options.distortion;\n        this.connectEffect(this._shaper);\n        this.distortion = options.distortion;\n        this.oversample = options.oversample;\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect.getDefaults(), {\n            distortion: 0.4,\n            oversample: \"none\",\n        });\n    }\n    /**\n     * The amount of distortion. Nominal range is between 0 and 1.\n     */\n    get distortion() {\n        return this._distortion;\n    }\n    set distortion(amount) {\n        this._distortion = amount;\n        const k = amount * 100;\n        const deg = Math.PI / 180;\n        this._shaper.setMap((x) => {\n            if (Math.abs(x) < 0.001) {\n                // should output 0 when input is 0\n                return 0;\n            }\n            else {\n                return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));\n            }\n        });\n    }\n    /**\n     * The oversampling of the effect. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        this._shaper.oversample = oversampling;\n    }\n    dispose() {\n        super.dispose();\n        this._shaper.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Distortion.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Distortion.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Effect.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Effect.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Effect\": () => (/* binding */ Effect)\n/* harmony export */ });\n/* harmony import */ var _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Effect is the base class for effects. Connect the effect between\n * the effectSend and effectReturn GainNodes, then control the amount of\n * effect which goes to the output using the wet control.\n */\nclass Effect extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"Effect\";\n        /**\n         * the drywet knob to control the amount of effect\n         */\n        this._dryWet = new _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_0__.CrossFade({ context: this.context });\n        /**\n         * The wet control is how much of the effected\n         * will pass through to the output. 1 = 100% effected\n         * signal, 0 = 100% dry signal.\n         */\n        this.wet = this._dryWet.fade;\n        /**\n         * connect the effectSend to the input of hte effect\n         */\n        this.effectSend = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        /**\n         * connect the output of the effect to the effectReturn\n         */\n        this.effectReturn = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        /**\n         * The effect input node\n         */\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        /**\n         * The effect output\n         */\n        this.output = this._dryWet;\n        // connections\n        this.input.fan(this._dryWet.a, this.effectSend);\n        this.effectReturn.connect(this._dryWet.b);\n        this.wet.setValueAtTime(options.wet, 0);\n        this._internalChannels = [this.effectReturn, this.effectSend];\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"wet\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode.getDefaults(), {\n            wet: 1,\n        });\n    }\n    /**\n     * chains the effect in between the effectSend and effectReturn\n     */\n    connectEffect(effect) {\n        // add it to the internal channels\n        this._internalChannels.push(effect);\n        this.effectSend.chain(effect, this.effectReturn);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._dryWet.dispose();\n        this.effectSend.dispose();\n        this.effectReturn.dispose();\n        this.wet.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Effect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Effect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/FeedbackDelay.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/FeedbackDelay.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FeedbackDelay\": () => (/* binding */ FeedbackDelay)\n/* harmony export */ });\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _FeedbackEffect__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./FeedbackEffect */ \"./node_modules/tone/build/esm/effect/FeedbackEffect.js\");\n\n\n\n\n/**\n * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.\n *\n * @param delayTime The delay applied to the incoming signal.\n * @param feedback The amount of the effected signal which is fed back through the delay.\n * @example\n * const feedbackDelay = new Tone.FeedbackDelay(\"8n\", 0.5).toDestination();\n * const tom = new Tone.MembraneSynth({\n * \toctaves: 4,\n * \tpitchDecay: 0.1\n * }).connect(feedbackDelay);\n * tom.triggerAttackRelease(\"A2\", \"32n\");\n * @category Effect\n */\nclass FeedbackDelay extends _FeedbackEffect__WEBPACK_IMPORTED_MODULE_3__.FeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FeedbackDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]));\n        this.name = \"FeedbackDelay\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FeedbackDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]);\n        this._delayNode = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_0__.Delay({\n            context: this.context,\n            delayTime: options.delayTime,\n            maxDelay: options.maxDelay,\n        });\n        this.delayTime = this._delayNode.delayTime;\n        // connect it up\n        this.connectEffect(this._delayNode);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, \"delayTime\");\n    }\n    static getDefaults() {\n        return Object.assign(_FeedbackEffect__WEBPACK_IMPORTED_MODULE_3__.FeedbackEffect.getDefaults(), {\n            delayTime: 0.25,\n            maxDelay: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._delayNode.dispose();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackDelay.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/FeedbackDelay.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/FeedbackEffect.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/FeedbackEffect.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FeedbackEffect\": () => (/* binding */ FeedbackEffect)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n\n\n\n/**\n * FeedbackEffect provides a loop between an audio source and its own output.\n * This is a base-class for feedback effects.\n */\nclass FeedbackEffect extends _Effect__WEBPACK_IMPORTED_MODULE_2__.Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"FeedbackEffect\";\n        this._feedbackGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.feedback,\n            units: \"normalRange\",\n        });\n        this.feedback = this._feedbackGain.gain;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, \"feedback\");\n        // the feedback loop\n        this.effectReturn.chain(this._feedbackGain, this.effectSend);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect.getDefaults(), {\n            feedback: 0.125,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._feedbackGain.dispose();\n        this.feedback.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FeedbackEffect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/FeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Freeverb.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Freeverb.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Freeverb\": () => (/* binding */ Freeverb)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/filter/LowpassCombFilter */ \"./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js\");\n\n\n\n\n\n/**\n * An array of comb filter delay values from Freeverb implementation\n */\nconst combFilterTunings = [1557 / 44100, 1617 / 44100, 1491 / 44100, 1422 / 44100, 1277 / 44100, 1356 / 44100, 1188 / 44100, 1116 / 44100];\n/**\n * An array of allpass filter frequency values from Freeverb implementation\n */\nconst allpassFilterFrequencies = [225, 556, 441, 341];\n/**\n * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).\n * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).\n * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].\n * @example\n * const freeverb = new Tone.Freeverb().toDestination();\n * freeverb.dampening = 1000;\n * // routing synth through the reverb\n * const synth = new Tone.NoiseSynth().connect(freeverb);\n * synth.triggerAttackRelease(0.05);\n * @category Effect\n */\nclass Freeverb extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Freeverb.getDefaults(), arguments, [\"roomSize\", \"dampening\"]));\n        this.name = \"Freeverb\";\n        /**\n         * the comb filters\n         */\n        this._combFilters = [];\n        /**\n         * the allpass filters on the left\n         */\n        this._allpassFiltersL = [];\n        /**\n         * the allpass filters on the right\n         */\n        this._allpassFiltersR = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Freeverb.getDefaults(), arguments, [\"roomSize\", \"dampening\"]);\n        this.roomSize = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.roomSize,\n            units: \"normalRange\",\n        });\n        // make the allpass filters on the right\n        this._allpassFiltersL = allpassFilterFrequencies.map(freq => {\n            const allpassL = this.context.createBiquadFilter();\n            allpassL.type = \"allpass\";\n            allpassL.frequency.value = freq;\n            return allpassL;\n        });\n        // make the allpass filters on the left\n        this._allpassFiltersR = allpassFilterFrequencies.map(freq => {\n            const allpassR = this.context.createBiquadFilter();\n            allpassR.type = \"allpass\";\n            allpassR.frequency.value = freq;\n            return allpassR;\n        });\n        // make the comb filters\n        this._combFilters = combFilterTunings.map((delayTime, index) => {\n            const lfpf = new _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_4__.LowpassCombFilter({\n                context: this.context,\n                dampening: options.dampening,\n                delayTime,\n            });\n            if (index < combFilterTunings.length / 2) {\n                this.connectEffectLeft(lfpf, ...this._allpassFiltersL);\n            }\n            else {\n                this.connectEffectRight(lfpf, ...this._allpassFiltersR);\n            }\n            this.roomSize.connect(lfpf.resonance);\n            return lfpf;\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"roomSize\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            roomSize: 0.7,\n            dampening: 3000\n        });\n    }\n    /**\n     * The amount of dampening of the reverberant signal.\n     */\n    get dampening() {\n        return this._combFilters[0].dampening;\n    }\n    set dampening(d) {\n        this._combFilters.forEach(c => c.dampening = d);\n    }\n    dispose() {\n        super.dispose();\n        this._allpassFiltersL.forEach(al => al.disconnect());\n        this._allpassFiltersR.forEach(ar => ar.disconnect());\n        this._combFilters.forEach(cf => cf.dispose());\n        this.roomSize.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Freeverb.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Freeverb.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/FrequencyShifter.js":
/*!****************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/FrequencyShifter.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FrequencyShifter\": () => (/* binding */ FrequencyShifter)\n/* harmony export */ });\n/* harmony import */ var _component_filter_PhaseShiftAllpass__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/filter/PhaseShiftAllpass */ \"./node_modules/tone/build/esm/component/filter/PhaseShiftAllpass.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _effect_Effect__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _signal_Add__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Negate__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../signal/Negate */ \"./node_modules/tone/build/esm/signal/Negate.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _source_oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/oscillator/Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _source_oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../source/oscillator/ToneOscillatorNode */ \"./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js\");\n\n\n\n\n\n\n\n\n\n/**\n * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.\n * The amount can be changed at audio rate and the effect is applied in real time.\n * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.\n * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,\n * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.\n * The algorithm will produces some aliasing towards the high end, especially if your source material\n * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling\n * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might\n * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.\n * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/\n *\n * @example\n * const input = new Tone.Oscillator(230, \"sawtooth\").start();\n * const shift = new Tone.FrequencyShifter(42).toDestination();\n * input.connect(shift);\n * @category Effect\n */\nclass FrequencyShifter extends _effect_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FrequencyShifter.getDefaults(), arguments, [\"frequency\"]));\n        this.name = \"FrequencyShifter\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FrequencyShifter.getDefaults(), arguments, [\"frequency\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_6__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n            minValue: -this.context.sampleRate / 2,\n            maxValue: this.context.sampleRate / 2,\n        });\n        this._sine = new _source_oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_8__.ToneOscillatorNode({\n            context: this.context,\n            type: \"sine\",\n        });\n        this._cosine = new _source_oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_7__.Oscillator({\n            context: this.context,\n            phase: -90,\n            type: \"sine\",\n        });\n        this._sineMultiply = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__.Multiply({ context: this.context });\n        this._cosineMultiply = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__.Multiply({ context: this.context });\n        this._negate = new _signal_Negate__WEBPACK_IMPORTED_MODULE_5__.Negate({ context: this.context });\n        this._add = new _signal_Add__WEBPACK_IMPORTED_MODULE_3__.Add({ context: this.context });\n        this._phaseShifter = new _component_filter_PhaseShiftAllpass__WEBPACK_IMPORTED_MODULE_0__.PhaseShiftAllpass({ context: this.context });\n        this.effectSend.connect(this._phaseShifter);\n        // connect the carrier frequency signal to the two oscillators\n        this.frequency.fan(this._sine.frequency, this._cosine.frequency);\n        this._phaseShifter.offset90.connect(this._cosineMultiply);\n        this._cosine.connect(this._cosineMultiply.factor);\n        this._phaseShifter.connect(this._sineMultiply);\n        this._sine.connect(this._sineMultiply.factor);\n        this._sineMultiply.connect(this._negate);\n        this._cosineMultiply.connect(this._add);\n        this._negate.connect(this._add.addend);\n        this._add.connect(this.effectReturn);\n        // start the oscillators at the same time\n        const now = this.immediate();\n        this._sine.start(now);\n        this._cosine.start(now);\n    }\n    static getDefaults() {\n        return Object.assign(_effect_Effect__WEBPACK_IMPORTED_MODULE_2__.Effect.getDefaults(), {\n            frequency: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this._add.dispose();\n        this._cosine.dispose();\n        this._cosineMultiply.dispose();\n        this._negate.dispose();\n        this._phaseShifter.dispose();\n        this._sine.dispose();\n        this._sineMultiply.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FrequencyShifter.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/FrequencyShifter.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/JCReverb.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/JCReverb.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"JCReverb\": () => (/* binding */ JCReverb)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _component_filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/filter/FeedbackCombFilter */ \"./node_modules/tone/build/esm/component/filter/FeedbackCombFilter.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * an array of the comb filter delay time values\n */\nconst combFilterDelayTimes = [1687 / 25000, 1601 / 25000, 2053 / 25000, 2251 / 25000];\n/**\n * the resonances of each of the comb filters\n */\nconst combFilterResonances = [0.773, 0.802, 0.753, 0.733];\n/**\n * the allpass filter frequencies\n */\nconst allpassFilterFreqs = [347, 113, 37];\n/**\n * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)\n * tuned by John Chowning in 1970.\n * It is made up of three allpass filters and four [[FeedbackCombFilter]].\n * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].\n * @example\n * const reverb = new Tone.JCReverb(0.4).toDestination();\n * const delay = new Tone.FeedbackDelay(0.5);\n * // connecting the synth to reverb through delay\n * const synth = new Tone.DuoSynth().chain(delay, reverb);\n * synth.triggerAttackRelease(\"A4\", \"8n\");\n *\n * @category Effect\n */\nclass JCReverb extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(JCReverb.getDefaults(), arguments, [\"roomSize\"]));\n        this.name = \"JCReverb\";\n        /**\n         * a series of allpass filters\n         */\n        this._allpassFilters = [];\n        /**\n         * parallel feedback comb filters\n         */\n        this._feedbackCombFilters = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(JCReverb.getDefaults(), arguments, [\"roomSize\"]);\n        this.roomSize = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.roomSize,\n            units: \"normalRange\",\n        });\n        this._scaleRoomSize = new _signal_Scale__WEBPACK_IMPORTED_MODULE_2__.Scale({\n            context: this.context,\n            min: -0.733,\n            max: 0.197,\n        });\n        // make the allpass filters\n        this._allpassFilters = allpassFilterFreqs.map(freq => {\n            const allpass = this.context.createBiquadFilter();\n            allpass.type = \"allpass\";\n            allpass.frequency.value = freq;\n            return allpass;\n        });\n        // and the comb filters\n        this._feedbackCombFilters = combFilterDelayTimes.map((delayTime, index) => {\n            const fbcf = new _component_filter_FeedbackCombFilter__WEBPACK_IMPORTED_MODULE_4__.FeedbackCombFilter({\n                context: this.context,\n                delayTime,\n            });\n            this._scaleRoomSize.connect(fbcf.resonance);\n            fbcf.resonance.value = combFilterResonances[index];\n            if (index < combFilterDelayTimes.length / 2) {\n                this.connectEffectLeft(...this._allpassFilters, fbcf);\n            }\n            else {\n                this.connectEffectRight(...this._allpassFilters, fbcf);\n            }\n            return fbcf;\n        });\n        // chain the allpass filters together\n        this.roomSize.connect(this._scaleRoomSize);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"roomSize\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            roomSize: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._allpassFilters.forEach(apf => apf.disconnect());\n        this._feedbackCombFilters.forEach(fbcf => fbcf.dispose());\n        this.roomSize.dispose();\n        this._scaleRoomSize.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=JCReverb.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/JCReverb.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/LFOEffect.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/LFOEffect.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LFOEffect\": () => (/* binding */ LFOEffect)\n/* harmony export */ });\n/* harmony import */ var _effect_Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../effect/Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n/**\n * Base class for LFO-based effects.\n */\nclass LFOEffect extends _effect_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"LFOEffect\";\n        this._lfo = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            amplitude: options.depth,\n        });\n        this.depth = this._lfo.amplitude;\n        this.frequency = this._lfo.frequency;\n        this.type = options.type;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"frequency\", \"depth\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_effect_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            frequency: 1,\n            type: \"sine\",\n            depth: 1,\n        });\n    }\n    /**\n     * Start the effect.\n     */\n    start(time) {\n        this._lfo.start(time);\n        return this;\n    }\n    /**\n     * Stop the lfo\n     */\n    stop(time) {\n        this._lfo.stop(time);\n        return this;\n    }\n    /**\n     * Sync the filter to the transport. See [[LFO.sync]]\n     */\n    sync() {\n        this._lfo.sync();\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport.\n     */\n    unsync() {\n        this._lfo.unsync();\n        return this;\n    }\n    /**\n     * The type of the LFO's oscillator: See [[Oscillator.type]]\n     * @example\n     * const autoFilter = new Tone.AutoFilter().start().toDestination();\n     * const noise = new Tone.Noise().start().connect(autoFilter);\n     * autoFilter.type = \"square\";\n     */\n    get type() {\n        return this._lfo.type;\n    }\n    set type(type) {\n        this._lfo.type = type;\n    }\n    dispose() {\n        super.dispose();\n        this._lfo.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LFOEffect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/LFOEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/MidSideEffect.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/MidSideEffect.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MidSideEffect\": () => (/* binding */ MidSideEffect)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _component_channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/channel/MidSideSplit */ \"./node_modules/tone/build/esm/component/channel/MidSideSplit.js\");\n/* harmony import */ var _component_channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/channel/MidSideMerge */ \"./node_modules/tone/build/esm/component/channel/MidSideMerge.js\");\n\n\n\n/**\n * Mid/Side processing separates the the 'mid' signal\n * (which comes out of both the left and the right channel)\n * and the 'side' (which only comes out of the the side channels)\n * and effects them separately before being recombined.\n * Applies a Mid/Side seperation and recombination.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * This is a base-class for Mid/Side Effects.\n * @category Effect\n */\nclass MidSideEffect extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor(options) {\n        super(options);\n        this.name = \"MidSideEffect\";\n        this._midSideMerge = new _component_channel_MidSideMerge__WEBPACK_IMPORTED_MODULE_2__.MidSideMerge({ context: this.context });\n        this._midSideSplit = new _component_channel_MidSideSplit__WEBPACK_IMPORTED_MODULE_1__.MidSideSplit({ context: this.context });\n        this._midSend = this._midSideSplit.mid;\n        this._sideSend = this._midSideSplit.side;\n        this._midReturn = this._midSideMerge.mid;\n        this._sideReturn = this._midSideMerge.side;\n        // the connections\n        this.effectSend.connect(this._midSideSplit);\n        this._midSideMerge.connect(this.effectReturn);\n    }\n    /**\n     * Connect the mid chain of the effect\n     */\n    connectEffectMid(...nodes) {\n        this._midSend.chain(...nodes, this._midReturn);\n    }\n    /**\n     * Connect the side chain of the effect\n     */\n    connectEffectSide(...nodes) {\n        this._sideSend.chain(...nodes, this._sideReturn);\n    }\n    dispose() {\n        super.dispose();\n        this._midSideSplit.dispose();\n        this._midSideMerge.dispose();\n        this._midSend.dispose();\n        this._sideSend.dispose();\n        this._midReturn.dispose();\n        this._sideReturn.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MidSideEffect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/MidSideEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Phaser.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Phaser.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Phaser\": () => (/* binding */ Phaser)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Phaser is a phaser effect. Phasers work by changing the phase\n * of different frequency components of an incoming signal. Read more on\n * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).\n * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).\n * @example\n * const phaser = new Tone.Phaser({\n * \tfrequency: 15,\n * \toctaves: 5,\n * \tbaseFrequency: 1000\n * }).toDestination();\n * const synth = new Tone.FMSynth().connect(phaser);\n * synth.triggerAttackRelease(\"E3\", \"2n\");\n * @category Effect\n */\nclass Phaser extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Phaser.getDefaults(), arguments, [\"frequency\", \"octaves\", \"baseFrequency\"]));\n        this.name = \"Phaser\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Phaser.getDefaults(), arguments, [\"frequency\", \"octaves\", \"baseFrequency\"]);\n        this._lfoL = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1\n        });\n        this._lfoR = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            frequency: options.frequency,\n            min: 0,\n            max: 1,\n            phase: 180,\n        });\n        this._baseFrequency = this.toFrequency(options.baseFrequency);\n        this._octaves = options.octaves;\n        this.Q = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.Q,\n            units: \"positive\",\n        });\n        this._filtersL = this._makeFilters(options.stages, this._lfoL);\n        this._filtersR = this._makeFilters(options.stages, this._lfoR);\n        this.frequency = this._lfoL.frequency;\n        this.frequency.value = options.frequency;\n        // connect them up\n        this.connectEffectLeft(...this._filtersL);\n        this.connectEffectRight(...this._filtersR);\n        // control the frequency with one LFO\n        this._lfoL.frequency.connect(this._lfoR.frequency);\n        // set the options\n        this.baseFrequency = options.baseFrequency;\n        this.octaves = options.octaves;\n        // start the lfo\n        this._lfoL.start();\n        this._lfoR.start();\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\", \"Q\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            frequency: 0.5,\n            octaves: 3,\n            stages: 10,\n            Q: 10,\n            baseFrequency: 350,\n        });\n    }\n    _makeFilters(stages, connectToFreq) {\n        const filters = [];\n        // make all the filters\n        for (let i = 0; i < stages; i++) {\n            const filter = this.context.createBiquadFilter();\n            filter.type = \"allpass\";\n            this.Q.connect(filter.Q);\n            connectToFreq.connect(filter.frequency);\n            filters.push(filter);\n        }\n        return filters;\n    }\n    /**\n     * The number of octaves the phase goes above the baseFrequency\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(octaves) {\n        this._octaves = octaves;\n        const max = this._baseFrequency * Math.pow(2, octaves);\n        this._lfoL.max = max;\n        this._lfoR.max = max;\n    }\n    /**\n     * The the base frequency of the filters.\n     */\n    get baseFrequency() {\n        return this._baseFrequency;\n    }\n    set baseFrequency(freq) {\n        this._baseFrequency = this.toFrequency(freq);\n        this._lfoL.min = this._baseFrequency;\n        this._lfoR.min = this._baseFrequency;\n        this.octaves = this._octaves;\n    }\n    dispose() {\n        super.dispose();\n        this.Q.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._filtersL.forEach(f => f.disconnect());\n        this._filtersR.forEach(f => f.disconnect());\n        this.frequency.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Phaser.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Phaser.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/PingPongDelay.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/PingPongDelay.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PingPongDelay\": () => (/* binding */ PingPongDelay)\n/* harmony export */ });\n/* harmony import */ var _StereoXFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoXFeedbackEffect */ \"./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * PingPongDelay is a feedback delay effect where the echo is heard\n * first in one channel and next in the opposite channel. In a stereo\n * system these are the right and left channels.\n * PingPongDelay in more simplified terms is two Tone.FeedbackDelays\n * with independent delay values. Each delay is routed to one channel\n * (left or right), and the channel triggered second will always\n * trigger at the same interval after the first.\n * @example\n * const pingPong = new Tone.PingPongDelay(\"4n\", 0.2).toDestination();\n * const drum = new Tone.MembraneSynth().connect(pingPong);\n * drum.triggerAttackRelease(\"C4\", \"32n\");\n * @category Effect\n */\nclass PingPongDelay extends _StereoXFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoXFeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PingPongDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]));\n        this.name = \"PingPongDelay\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PingPongDelay.getDefaults(), arguments, [\"delayTime\", \"feedback\"]);\n        this._leftDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__.Delay({\n            context: this.context,\n            maxDelay: options.maxDelay,\n        });\n        this._rightDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__.Delay({\n            context: this.context,\n            maxDelay: options.maxDelay\n        });\n        this._rightPreDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_2__.Delay({\n            context: this.context,\n            maxDelay: options.maxDelay\n        });\n        this.delayTime = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"time\",\n            value: options.delayTime,\n        });\n        // connect it up\n        this.connectEffectLeft(this._leftDelay);\n        this.connectEffectRight(this._rightPreDelay, this._rightDelay);\n        this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);\n        // rearranged the feedback to be after the rightPreDelay\n        this._feedbackL.disconnect();\n        this._feedbackL.connect(this._rightDelay);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"delayTime\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoXFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoXFeedbackEffect.getDefaults(), {\n            delayTime: 0.25,\n            maxDelay: 1\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._leftDelay.dispose();\n        this._rightDelay.dispose();\n        this._rightPreDelay.dispose();\n        this.delayTime.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PingPongDelay.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/PingPongDelay.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/PitchShift.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/PitchShift.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PitchShift\": () => (/* binding */ PitchShift)\n/* harmony export */ });\n/* harmony import */ var _FeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./FeedbackEffect */ \"./node_modules/tone/build/esm/effect/FeedbackEffect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n\n\n\n\n\n\n\n\n/**\n * PitchShift does near-realtime pitch shifting to the incoming signal.\n * The effect is achieved by speeding up or slowing down the delayTime\n * of a DelayNode using a sawtooth wave.\n * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).\n * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).\n * @category Effect\n */\nclass PitchShift extends _FeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.FeedbackEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PitchShift.getDefaults(), arguments, [\"pitch\"]));\n        this.name = \"PitchShift\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PitchShift.getDefaults(), arguments, [\"pitch\"]);\n        this._frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_5__.Signal({ context: this.context });\n        this._delayA = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            maxDelay: 1,\n            context: this.context\n        });\n        this._lfoA = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            min: 0,\n            max: 0.1,\n            type: \"sawtooth\"\n        }).connect(this._delayA.delayTime);\n        this._delayB = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            maxDelay: 1,\n            context: this.context\n        });\n        this._lfoB = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            min: 0,\n            max: 0.1,\n            type: \"sawtooth\",\n            phase: 180\n        }).connect(this._delayB.delayTime);\n        this._crossFade = new _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_4__.CrossFade({ context: this.context });\n        this._crossFadeLFO = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            min: 0,\n            max: 1,\n            type: \"triangle\",\n            phase: 90\n        }).connect(this._crossFade.fade);\n        this._feedbackDelay = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            delayTime: options.delayTime,\n            context: this.context,\n        });\n        this.delayTime = this._feedbackDelay.delayTime;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_6__.readOnly)(this, \"delayTime\");\n        this._pitch = options.pitch;\n        this._windowSize = options.windowSize;\n        // connect the two delay lines up\n        this._delayA.connect(this._crossFade.a);\n        this._delayB.connect(this._crossFade.b);\n        // connect the frequency\n        this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);\n        // route the input\n        this.effectSend.fan(this._delayA, this._delayB);\n        this._crossFade.chain(this._feedbackDelay, this.effectReturn);\n        // start the LFOs at the same time\n        const now = this.now();\n        this._lfoA.start(now);\n        this._lfoB.start(now);\n        this._crossFadeLFO.start(now);\n        // set the initial value\n        this.windowSize = this._windowSize;\n    }\n    static getDefaults() {\n        return Object.assign(_FeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.FeedbackEffect.getDefaults(), {\n            pitch: 0,\n            windowSize: 0.1,\n            delayTime: 0,\n            feedback: 0\n        });\n    }\n    /**\n     * Repitch the incoming signal by some interval (measured in semi-tones).\n     * @example\n     * const pitchShift = new Tone.PitchShift().toDestination();\n     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();\n     * pitchShift.pitch = -12; // down one octave\n     * pitchShift.pitch = 7; // up a fifth\n     */\n    get pitch() {\n        return this._pitch;\n    }\n    set pitch(interval) {\n        this._pitch = interval;\n        let factor = 0;\n        if (interval < 0) {\n            this._lfoA.min = 0;\n            this._lfoA.max = this._windowSize;\n            this._lfoB.min = 0;\n            this._lfoB.max = this._windowSize;\n            factor = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_7__.intervalToFrequencyRatio)(interval - 1) + 1;\n        }\n        else {\n            this._lfoA.min = this._windowSize;\n            this._lfoA.max = 0;\n            this._lfoB.min = this._windowSize;\n            this._lfoB.max = 0;\n            factor = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_7__.intervalToFrequencyRatio)(interval) - 1;\n        }\n        this._frequency.value = factor * (1.2 / this._windowSize);\n    }\n    /**\n     * The window size corresponds roughly to the sample length in a looping sampler.\n     * Smaller values are desirable for a less noticeable delay time of the pitch shifted\n     * signal, but larger values will result in smoother pitch shifting for larger intervals.\n     * A nominal range of 0.03 to 0.1 is recommended.\n     */\n    get windowSize() {\n        return this._windowSize;\n    }\n    set windowSize(size) {\n        this._windowSize = this.toSeconds(size);\n        this.pitch = this._pitch;\n    }\n    dispose() {\n        super.dispose();\n        this._frequency.dispose();\n        this._delayA.dispose();\n        this._delayB.dispose();\n        this._lfoA.dispose();\n        this._lfoB.dispose();\n        this._crossFade.dispose();\n        this._crossFadeLFO.dispose();\n        this._feedbackDelay.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PitchShift.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/PitchShift.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Reverb.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Reverb.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Reverb\": () => (/* binding */ Reverb)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _component_channel_Merge__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_Noise__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Simple convolution created with decaying noise.\n * Generates an Impulse Response Buffer\n * with Tone.Offline then feeds the IR into ConvolverNode.\n * The impulse response generation is async, so you have\n * to wait until [[ready]] resolves before it will make a sound.\n *\n * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).\n * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.\n *\n * @category Effect\n */\nclass Reverb extends _Effect__WEBPACK_IMPORTED_MODULE_4__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Reverb.getDefaults(), arguments, [\"decay\"]));\n        this.name = \"Reverb\";\n        /**\n         * Convolver node\n         */\n        this._convolver = this.context.createConvolver();\n        /**\n         * Resolves when the reverb buffer is generated. Whenever either [[decay]]\n         * or [[preDelay]] are set, you have to wait until [[ready]] resolves\n         * before the IR is generated with the latest values.\n         */\n        this.ready = Promise.resolve();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Reverb.getDefaults(), arguments, [\"decay\"]);\n        this._decay = options.decay;\n        this._preDelay = options.preDelay;\n        this.generate();\n        this.connectEffect(this._convolver);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_4__.Effect.getDefaults(), {\n            decay: 1.5,\n            preDelay: 0.01,\n        });\n    }\n    /**\n     * The duration of the reverb.\n     */\n    get decay() {\n        return this._decay;\n    }\n    set decay(time) {\n        time = this.toSeconds(time);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(time, 0.001);\n        this._decay = time;\n        this.generate();\n    }\n    /**\n     * The amount of time before the reverb is fully ramped in.\n     */\n    get preDelay() {\n        return this._preDelay;\n    }\n    set preDelay(time) {\n        time = this.toSeconds(time);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(time, 0);\n        this._preDelay = time;\n        this.generate();\n    }\n    /**\n     * Generate the Impulse Response. Returns a promise while the IR is being generated.\n     * @return Promise which returns this object.\n     */\n    generate() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            const previousReady = this.ready;\n            // create a noise burst which decays over the duration in each channel\n            const context = new _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_5__.OfflineContext(2, this._decay + this._preDelay, this.context.sampleRate);\n            const noiseL = new _source_Noise__WEBPACK_IMPORTED_MODULE_3__.Noise({ context });\n            const noiseR = new _source_Noise__WEBPACK_IMPORTED_MODULE_3__.Noise({ context });\n            const merge = new _component_channel_Merge__WEBPACK_IMPORTED_MODULE_0__.Merge({ context });\n            noiseL.connect(merge, 0, 0);\n            noiseR.connect(merge, 0, 1);\n            const gainNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context }).toDestination();\n            merge.connect(gainNode);\n            noiseL.start(0);\n            noiseR.start(0);\n            // predelay\n            gainNode.gain.setValueAtTime(0, 0);\n            gainNode.gain.setValueAtTime(1, this._preDelay);\n            // decay\n            gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);\n            // render the buffer\n            const renderPromise = context.render();\n            this.ready = renderPromise.then(_core_util_Interface__WEBPACK_IMPORTED_MODULE_6__.noOp);\n            // wait for the previous `ready` to resolve\n            yield previousReady;\n            // set the buffer\n            this._convolver.buffer = (yield renderPromise).get();\n            return this;\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._convolver.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=Reverb.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Reverb.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoEffect.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoEffect.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoEffect\": () => (/* binding */ StereoEffect)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/channel/CrossFade */ \"./node_modules/tone/build/esm/component/channel/CrossFade.js\");\n/* harmony import */ var _component_channel_Split__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _component_channel_Merge__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * Base class for Stereo effects.\n */\nclass StereoEffect extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        this.name = \"StereoEffect\";\n        this.input = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_3__.Gain({ context: this.context });\n        // force mono sources to be stereo\n        this.input.channelCount = 2;\n        this.input.channelCountMode = \"explicit\";\n        this._dryWet = this.output = new _component_channel_CrossFade__WEBPACK_IMPORTED_MODULE_1__.CrossFade({\n            context: this.context,\n            fade: options.wet\n        });\n        this.wet = this._dryWet.fade;\n        this._split = new _component_channel_Split__WEBPACK_IMPORTED_MODULE_2__.Split({ context: this.context, channels: 2 });\n        this._merge = new _component_channel_Merge__WEBPACK_IMPORTED_MODULE_4__.Merge({ context: this.context, channels: 2 });\n        // connections\n        this.input.connect(this._split);\n        // dry wet connections\n        this.input.connect(this._dryWet.a);\n        this._merge.connect(this._dryWet.b);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"wet\"]);\n    }\n    /**\n     * Connect the left part of the effect\n     */\n    connectEffectLeft(...nodes) {\n        this._split.connect(nodes[0], 0, 0);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(...nodes);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(nodes[nodes.length - 1], this._merge, 0, 0);\n    }\n    /**\n     * Connect the right part of the effect\n     */\n    connectEffectRight(...nodes) {\n        this._split.connect(nodes[0], 1, 0);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(...nodes);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(nodes[nodes.length - 1], this._merge, 0, 1);\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            wet: 1,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._dryWet.dispose();\n        this._split.dispose();\n        this._merge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoEffect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/StereoEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js":
/*!********************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoFeedbackEffect\": () => (/* binding */ StereoFeedbackEffect)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _component_channel_Split__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../component/channel/Split */ \"./node_modules/tone/build/esm/component/channel/Split.js\");\n/* harmony import */ var _component_channel_Merge__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../component/channel/Merge */ \"./node_modules/tone/build/esm/component/channel/Merge.js\");\n\n\n\n\n\n\n/**\n * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.\n */\nclass StereoFeedbackEffect extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor(options) {\n        super(options);\n        this.feedback = new _signal_Signal__WEBPACK_IMPORTED_MODULE_1__.Signal({\n            context: this.context,\n            value: options.feedback,\n            units: \"normalRange\"\n        });\n        this._feedbackL = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._feedbackR = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._feedbackSplit = new _component_channel_Split__WEBPACK_IMPORTED_MODULE_4__.Split({ context: this.context, channels: 2 });\n        this._feedbackMerge = new _component_channel_Merge__WEBPACK_IMPORTED_MODULE_5__.Merge({ context: this.context, channels: 2 });\n        this._merge.connect(this._feedbackSplit);\n        this._feedbackMerge.connect(this._split);\n        // the left output connected to the left input\n        this._feedbackSplit.connect(this._feedbackL, 0, 0);\n        this._feedbackL.connect(this._feedbackMerge, 0, 0);\n        // the right output connected to the right input\n        this._feedbackSplit.connect(this._feedbackR, 1, 0);\n        this._feedbackR.connect(this._feedbackMerge, 0, 1);\n        // the feedback control\n        this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"feedback\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            feedback: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.feedback.dispose();\n        this._feedbackL.dispose();\n        this._feedbackR.dispose();\n        this._feedbackSplit.dispose();\n        this._feedbackMerge.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoFeedbackEffect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoWidener.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoWidener.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoWidener\": () => (/* binding */ StereoWidener)\n/* harmony export */ });\n/* harmony import */ var _effect_MidSideEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../effect/MidSideEffect */ \"./node_modules/tone/build/esm/effect/MidSideEffect.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Subtract__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n\n\n\n/**\n * Applies a width factor to the mid/side seperation.\n * 0 is all mid and 1 is all side.\n * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).\n * ```\n * Mid *= 2*(1-width)<br>\n * Side *= 2*width\n * ```\n * @category Effect\n */\nclass StereoWidener extends _effect_MidSideEffect__WEBPACK_IMPORTED_MODULE_0__.MidSideEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(StereoWidener.getDefaults(), arguments, [\"width\"]));\n        this.name = \"StereoWidener\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(StereoWidener.getDefaults(), arguments, [\"width\"]);\n        this.width = new _signal_Signal__WEBPACK_IMPORTED_MODULE_1__.Signal({\n            context: this.context,\n            value: options.width,\n            units: \"normalRange\",\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"width\"]);\n        this._twoTimesWidthMid = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: 2,\n        });\n        this._twoTimesWidthSide = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: 2,\n        });\n        this._midMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({ context: this.context });\n        this._twoTimesWidthMid.connect(this._midMult.factor);\n        this.connectEffectMid(this._midMult);\n        this._oneMinusWidth = new _signal_Subtract__WEBPACK_IMPORTED_MODULE_3__.Subtract({ context: this.context });\n        this._oneMinusWidth.connect(this._twoTimesWidthMid);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_6__.connect)(this.context.getConstant(1), this._oneMinusWidth);\n        this.width.connect(this._oneMinusWidth.subtrahend);\n        this._sideMult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({ context: this.context });\n        this.width.connect(this._twoTimesWidthSide);\n        this._twoTimesWidthSide.connect(this._sideMult.factor);\n        this.connectEffectSide(this._sideMult);\n    }\n    static getDefaults() {\n        return Object.assign(_effect_MidSideEffect__WEBPACK_IMPORTED_MODULE_0__.MidSideEffect.getDefaults(), {\n            width: 0.5,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.width.dispose();\n        this._midMult.dispose();\n        this._sideMult.dispose();\n        this._twoTimesWidthMid.dispose();\n        this._twoTimesWidthSide.dispose();\n        this._oneMinusWidth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=StereoWidener.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/StereoWidener.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"StereoXFeedbackEffect\": () => (/* binding */ StereoXFeedbackEffect)\n/* harmony export */ });\n/* harmony import */ var _StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoFeedbackEffect */ \"./node_modules/tone/build/esm/effect/StereoFeedbackEffect.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n/**\n * Just like a [[StereoFeedbackEffect]], but the feedback is routed from left to right\n * and right to left instead of on the same channel.\n * ```\n * +--------------------------------+ feedbackL <-----------------------------------+\n * |                                                                                |\n * +-->                          +----->        +---->                          +-----+\n *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |\n * +-->                          +----->        +---->                          +---+ |\n * |                                                                                  |\n * +--------------------------------+ feedbackR <-------------------------------------+\n * ```\n */\nclass StereoXFeedbackEffect extends _StereoFeedbackEffect__WEBPACK_IMPORTED_MODULE_0__.StereoFeedbackEffect {\n    constructor(options) {\n        super(options);\n        // the left output connected to the right input\n        this._feedbackL.disconnect();\n        this._feedbackL.connect(this._feedbackMerge, 0, 1);\n        // the left output connected to the right input\n        this._feedbackR.disconnect();\n        this._feedbackR.connect(this._feedbackMerge, 0, 0);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"feedback\"]);\n    }\n}\n//# sourceMappingURL=StereoXFeedbackEffect.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/StereoXFeedbackEffect.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Tremolo.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Tremolo.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Tremolo\": () => (/* binding */ Tremolo)\n/* harmony export */ });\n/* harmony import */ var _StereoEffect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StereoEffect */ \"./node_modules/tone/build/esm/effect/StereoEffect.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n\n/**\n * Tremolo modulates the amplitude of an incoming signal using an [[LFO]].\n * The effect is a stereo effect where the modulation phase is inverted in each channel.\n *\n * @example\n * // create a tremolo and start it's LFO\n * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();\n * // route an oscillator through the tremolo and start it\n * const oscillator = new Tone.Oscillator().connect(tremolo).start();\n *\n * @category Effect\n */\nclass Tremolo extends _StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Tremolo.getDefaults(), arguments, [\"frequency\", \"depth\"]));\n        this.name = \"Tremolo\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(Tremolo.getDefaults(), arguments, [\"frequency\", \"depth\"]);\n        this._lfoL = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__.LFO({\n            context: this.context,\n            type: options.type,\n            min: 1,\n            max: 0,\n        });\n        this._lfoR = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_1__.LFO({\n            context: this.context,\n            type: options.type,\n            min: 1,\n            max: 0,\n        });\n        this._amplitudeL = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this._amplitudeR = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({ context: this.context });\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.frequency,\n            units: \"frequency\",\n        });\n        this.depth = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            value: options.depth,\n            units: \"normalRange\",\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, [\"frequency\", \"depth\"]);\n        this.connectEffectLeft(this._amplitudeL);\n        this.connectEffectRight(this._amplitudeR);\n        this._lfoL.connect(this._amplitudeL.gain);\n        this._lfoR.connect(this._amplitudeR.gain);\n        this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);\n        this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);\n        this.spread = options.spread;\n    }\n    static getDefaults() {\n        return Object.assign(_StereoEffect__WEBPACK_IMPORTED_MODULE_0__.StereoEffect.getDefaults(), {\n            frequency: 10,\n            type: \"sine\",\n            depth: 0.5,\n            spread: 180,\n        });\n    }\n    /**\n     * Start the tremolo.\n     */\n    start(time) {\n        this._lfoL.start(time);\n        this._lfoR.start(time);\n        return this;\n    }\n    /**\n     * Stop the tremolo.\n     */\n    stop(time) {\n        this._lfoL.stop(time);\n        this._lfoR.stop(time);\n        return this;\n    }\n    /**\n     * Sync the effect to the transport.\n     */\n    sync() {\n        this._lfoL.sync();\n        this._lfoR.sync();\n        this.context.transport.syncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Unsync the filter from the transport\n     */\n    unsync() {\n        this._lfoL.unsync();\n        this._lfoR.unsync();\n        this.context.transport.unsyncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * The oscillator type.\n     */\n    get type() {\n        return this._lfoL.type;\n    }\n    set type(type) {\n        this._lfoL.type = type;\n        this._lfoR.type = type;\n    }\n    /**\n     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.\n     * When set to 180, LFO's will be panned hard left and right respectively.\n     */\n    get spread() {\n        return this._lfoR.phase - this._lfoL.phase; // 180\n    }\n    set spread(spread) {\n        this._lfoL.phase = 90 - (spread / 2);\n        this._lfoR.phase = (spread / 2) + 90;\n    }\n    dispose() {\n        super.dispose();\n        this._lfoL.dispose();\n        this._lfoR.dispose();\n        this._amplitudeL.dispose();\n        this._amplitudeR.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Tremolo.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Tremolo.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/Vibrato.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/Vibrato.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Vibrato\": () => (/* binding */ Vibrato)\n/* harmony export */ });\n/* harmony import */ var _Effect__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Effect */ \"./node_modules/tone/build/esm/effect/Effect.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/Delay */ \"./node_modules/tone/build/esm/core/context/Delay.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO\n * modulates the delayTime of the delay, causing the pitch to rise and fall.\n * @category Effect\n */\nclass Vibrato extends _Effect__WEBPACK_IMPORTED_MODULE_0__.Effect {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Vibrato.getDefaults(), arguments, [\"frequency\", \"depth\"]));\n        this.name = \"Vibrato\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Vibrato.getDefaults(), arguments, [\"frequency\", \"depth\"]);\n        this._delayNode = new _core_context_Delay__WEBPACK_IMPORTED_MODULE_3__.Delay({\n            context: this.context,\n            delayTime: 0,\n            maxDelay: options.maxDelay,\n        });\n        this._lfo = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_2__.LFO({\n            context: this.context,\n            type: options.type,\n            min: 0,\n            max: options.maxDelay,\n            frequency: options.frequency,\n            phase: -90 // offse the phase so the resting position is in the center\n        }).start().connect(this._delayNode.delayTime);\n        this.frequency = this._lfo.frequency;\n        this.depth = this._lfo.amplitude;\n        this.depth.value = options.depth;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\", \"depth\"]);\n        this.effectSend.chain(this._delayNode, this.effectReturn);\n    }\n    static getDefaults() {\n        return Object.assign(_Effect__WEBPACK_IMPORTED_MODULE_0__.Effect.getDefaults(), {\n            maxDelay: 0.005,\n            frequency: 5,\n            depth: 0.1,\n            type: \"sine\"\n        });\n    }\n    /**\n     * Type of oscillator attached to the Vibrato.\n     */\n    get type() {\n        return this._lfo.type;\n    }\n    set type(type) {\n        this._lfo.type = type;\n    }\n    dispose() {\n        super.dispose();\n        this._delayNode.dispose();\n        this._lfo.dispose();\n        this.frequency.dispose();\n        this.depth.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Vibrato.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/Vibrato.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/effect/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/effect/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AutoFilter\": () => (/* reexport safe */ _AutoFilter__WEBPACK_IMPORTED_MODULE_0__.AutoFilter),\n/* harmony export */   \"AutoPanner\": () => (/* reexport safe */ _AutoPanner__WEBPACK_IMPORTED_MODULE_1__.AutoPanner),\n/* harmony export */   \"AutoWah\": () => (/* reexport safe */ _AutoWah__WEBPACK_IMPORTED_MODULE_2__.AutoWah),\n/* harmony export */   \"BitCrusher\": () => (/* reexport safe */ _BitCrusher__WEBPACK_IMPORTED_MODULE_3__.BitCrusher),\n/* harmony export */   \"Chebyshev\": () => (/* reexport safe */ _Chebyshev__WEBPACK_IMPORTED_MODULE_4__.Chebyshev),\n/* harmony export */   \"Chorus\": () => (/* reexport safe */ _Chorus__WEBPACK_IMPORTED_MODULE_5__.Chorus),\n/* harmony export */   \"Distortion\": () => (/* reexport safe */ _Distortion__WEBPACK_IMPORTED_MODULE_6__.Distortion),\n/* harmony export */   \"FeedbackDelay\": () => (/* reexport safe */ _FeedbackDelay__WEBPACK_IMPORTED_MODULE_7__.FeedbackDelay),\n/* harmony export */   \"Freeverb\": () => (/* reexport safe */ _Freeverb__WEBPACK_IMPORTED_MODULE_9__.Freeverb),\n/* harmony export */   \"FrequencyShifter\": () => (/* reexport safe */ _FrequencyShifter__WEBPACK_IMPORTED_MODULE_8__.FrequencyShifter),\n/* harmony export */   \"JCReverb\": () => (/* reexport safe */ _JCReverb__WEBPACK_IMPORTED_MODULE_10__.JCReverb),\n/* harmony export */   \"Phaser\": () => (/* reexport safe */ _Phaser__WEBPACK_IMPORTED_MODULE_13__.Phaser),\n/* harmony export */   \"PingPongDelay\": () => (/* reexport safe */ _PingPongDelay__WEBPACK_IMPORTED_MODULE_11__.PingPongDelay),\n/* harmony export */   \"PitchShift\": () => (/* reexport safe */ _PitchShift__WEBPACK_IMPORTED_MODULE_12__.PitchShift),\n/* harmony export */   \"Reverb\": () => (/* reexport safe */ _Reverb__WEBPACK_IMPORTED_MODULE_14__.Reverb),\n/* harmony export */   \"StereoWidener\": () => (/* reexport safe */ _StereoWidener__WEBPACK_IMPORTED_MODULE_15__.StereoWidener),\n/* harmony export */   \"Tremolo\": () => (/* reexport safe */ _Tremolo__WEBPACK_IMPORTED_MODULE_16__.Tremolo),\n/* harmony export */   \"Vibrato\": () => (/* reexport safe */ _Vibrato__WEBPACK_IMPORTED_MODULE_17__.Vibrato)\n/* harmony export */ });\n/* harmony import */ var _AutoFilter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AutoFilter */ \"./node_modules/tone/build/esm/effect/AutoFilter.js\");\n/* harmony import */ var _AutoPanner__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AutoPanner */ \"./node_modules/tone/build/esm/effect/AutoPanner.js\");\n/* harmony import */ var _AutoWah__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AutoWah */ \"./node_modules/tone/build/esm/effect/AutoWah.js\");\n/* harmony import */ var _BitCrusher__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./BitCrusher */ \"./node_modules/tone/build/esm/effect/BitCrusher.js\");\n/* harmony import */ var _Chebyshev__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Chebyshev */ \"./node_modules/tone/build/esm/effect/Chebyshev.js\");\n/* harmony import */ var _Chorus__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Chorus */ \"./node_modules/tone/build/esm/effect/Chorus.js\");\n/* harmony import */ var _Distortion__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Distortion */ \"./node_modules/tone/build/esm/effect/Distortion.js\");\n/* harmony import */ var _FeedbackDelay__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./FeedbackDelay */ \"./node_modules/tone/build/esm/effect/FeedbackDelay.js\");\n/* harmony import */ var _FrequencyShifter__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./FrequencyShifter */ \"./node_modules/tone/build/esm/effect/FrequencyShifter.js\");\n/* harmony import */ var _Freeverb__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Freeverb */ \"./node_modules/tone/build/esm/effect/Freeverb.js\");\n/* harmony import */ var _JCReverb__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./JCReverb */ \"./node_modules/tone/build/esm/effect/JCReverb.js\");\n/* harmony import */ var _PingPongDelay__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./PingPongDelay */ \"./node_modules/tone/build/esm/effect/PingPongDelay.js\");\n/* harmony import */ var _PitchShift__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./PitchShift */ \"./node_modules/tone/build/esm/effect/PitchShift.js\");\n/* harmony import */ var _Phaser__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./Phaser */ \"./node_modules/tone/build/esm/effect/Phaser.js\");\n/* harmony import */ var _Reverb__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./Reverb */ \"./node_modules/tone/build/esm/effect/Reverb.js\");\n/* harmony import */ var _StereoWidener__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./StereoWidener */ \"./node_modules/tone/build/esm/effect/StereoWidener.js\");\n/* harmony import */ var _Tremolo__WEBPACK_IMPORTED_MODULE_16__ = __webpack_require__(/*! ./Tremolo */ \"./node_modules/tone/build/esm/effect/Tremolo.js\");\n/* harmony import */ var _Vibrato__WEBPACK_IMPORTED_MODULE_17__ = __webpack_require__(/*! ./Vibrato */ \"./node_modules/tone/build/esm/effect/Vibrato.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/effect/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Loop.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Loop.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Loop\": () => (/* binding */ Loop)\n/* harmony export */ });\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n/* harmony import */ var _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Loop creates a looped callback at the\n * specified interval. The callback can be\n * started, stopped and scheduled along\n * the Transport's timeline.\n * @example\n * const loop = new Tone.Loop((time) => {\n * \t// triggered every eighth note.\n * \tconsole.log(time);\n * }, \"8n\").start(0);\n * Tone.Transport.start();\n * @category Event\n */\nclass Loop extends _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Loop.getDefaults(), arguments, [\"callback\", \"interval\"]));\n        this.name = \"Loop\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Loop.getDefaults(), arguments, [\"callback\", \"interval\"]);\n        this._event = new _ToneEvent__WEBPACK_IMPORTED_MODULE_0__.ToneEvent({\n            context: this.context,\n            callback: this._tick.bind(this),\n            loop: true,\n            loopEnd: options.interval,\n            playbackRate: options.playbackRate,\n            probability: options.probability\n        });\n        this.callback = options.callback;\n        // set the iterations\n        this.iterations = options.iterations;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext.getDefaults(), {\n            interval: \"4n\",\n            callback: _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp,\n            playbackRate: 1,\n            iterations: Infinity,\n            probability: 1,\n            mute: false,\n            humanize: false\n        });\n    }\n    /**\n     * Start the loop at the specified time along the Transport's timeline.\n     * @param  time  When to start the Loop.\n     */\n    start(time) {\n        this._event.start(time);\n        return this;\n    }\n    /**\n     * Stop the loop at the given time.\n     * @param  time  When to stop the Loop.\n     */\n    stop(time) {\n        this._event.stop(time);\n        return this;\n    }\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time) {\n        this._event.cancel(time);\n        return this;\n    }\n    /**\n     * Internal function called when the notes should be called\n     * @param time  The time the event occurs\n     */\n    _tick(time) {\n        this.callback(time);\n    }\n    /**\n     * The state of the Loop, either started or stopped.\n     */\n    get state() {\n        return this._event.state;\n    }\n    /**\n     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.\n     */\n    get progress() {\n        return this._event.progress;\n    }\n    /**\n     * The time between successive callbacks.\n     * @example\n     * const loop = new Tone.Loop();\n     * loop.interval = \"8n\"; // loop every 8n\n     */\n    get interval() {\n        return this._event.loopEnd;\n    }\n    set interval(interval) {\n        this._event.loopEnd = interval;\n    }\n    /**\n     * The playback rate of the loop. The normal playback rate is 1 (no change).\n     * A `playbackRate` of 2 would be twice as fast.\n     */\n    get playbackRate() {\n        return this._event.playbackRate;\n    }\n    set playbackRate(rate) {\n        this._event.playbackRate = rate;\n    }\n    /**\n     * Random variation +/-0.01s to the scheduled time.\n     * Or give it a time value which it will randomize by.\n     */\n    get humanize() {\n        return this._event.humanize;\n    }\n    set humanize(variation) {\n        this._event.humanize = variation;\n    }\n    /**\n     * The probably of the callback being invoked.\n     */\n    get probability() {\n        return this._event.probability;\n    }\n    set probability(prob) {\n        this._event.probability = prob;\n    }\n    /**\n     * Muting the Loop means that no callbacks are invoked.\n     */\n    get mute() {\n        return this._event.mute;\n    }\n    set mute(mute) {\n        this._event.mute = mute;\n    }\n    /**\n     * The number of iterations of the loop. The default value is `Infinity` (loop forever).\n     */\n    get iterations() {\n        if (this._event.loop === true) {\n            return Infinity;\n        }\n        else {\n            return this._event.loop;\n        }\n    }\n    set iterations(iters) {\n        if (iters === Infinity) {\n            this._event.loop = true;\n        }\n        else {\n            this._event.loop = iters;\n        }\n    }\n    dispose() {\n        super.dispose();\n        this._event.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Loop.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/Loop.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Part.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Part.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Part\": () => (/* binding */ Part)\n/* harmony export */ });\n/* harmony import */ var _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n\n\n\n\n\n\n/**\n * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.\n *\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const part = new Tone.Part(((time, note) => {\n * \t// the notes given as the second element in the array\n * \t// will be passed in as the second argument\n * \tsynth.triggerAttackRelease(note, \"8n\", time);\n * }), [[0, \"C2\"], [\"0:2\", \"C3\"], [\"0:3:2\", \"G2\"]]);\n * Tone.Transport.start();\n * @example\n * const synth = new Tone.Synth().toDestination();\n * // use an array of objects as long as the object has a \"time\" attribute\n * const part = new Tone.Part(((time, value) => {\n * \t// the value is an object which contains both the note and the velocity\n * \tsynth.triggerAttackRelease(value.note, \"8n\", time, value.velocity);\n * }), [{ time: 0, note: \"C3\", velocity: 0.9 },\n * \t{ time: \"0:2\", note: \"C4\", velocity: 0.5 }\n * ]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nclass Part extends _ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Part.getDefaults(), arguments, [\"callback\", \"events\"]));\n        this.name = \"Part\";\n        /**\n         * Tracks the scheduled events\n         */\n        this._state = new _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_3__.StateTimeline(\"stopped\");\n        /**\n         * The events that belong to this part\n         */\n        this._events = new Set();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Part.getDefaults(), arguments, [\"callback\", \"events\"]);\n        // make sure things are assigned in the right order\n        this._state.increasing = true;\n        // add the events\n        options.events.forEach(event => {\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isArray)(event)) {\n                this.add(event[0], event[1]);\n            }\n            else {\n                this.add(event);\n            }\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent.getDefaults(), {\n            events: [],\n        });\n    }\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset from the start of the part to begin playing at.\n     */\n    start(time, offset) {\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) !== \"started\") {\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.defaultArg)(offset, this._loop ? this._loopStart : 0);\n            if (this._loop) {\n                offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.defaultArg)(offset, this._loopStart);\n            }\n            else {\n                offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.defaultArg)(offset, 0);\n            }\n            const computedOffset = this.toTicks(offset);\n            this._state.add({\n                id: -1,\n                offset: computedOffset,\n                state: \"started\",\n                time: ticks,\n            });\n            this._forEach(event => {\n                this._startNote(event, ticks, computedOffset);\n            });\n        }\n        return this;\n    }\n    /**\n     * Start the event in the given event at the correct time given\n     * the ticks and offset and looping.\n     * @param  event\n     * @param  ticks\n     * @param  offset\n     */\n    _startNote(event, ticks, offset) {\n        ticks -= offset;\n        if (this._loop) {\n            if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {\n                if (event.startOffset < offset) {\n                    // start it on the next loop\n                    ticks += this._getLoopDuration();\n                }\n                event.start(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, ticks));\n            }\n            else if (event.startOffset < this._loopStart && event.startOffset >= offset) {\n                event.loop = false;\n                event.start(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, ticks));\n            }\n        }\n        else if (event.startOffset >= offset) {\n            event.start(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, ticks));\n        }\n    }\n    get startOffset() {\n        return this._startOffset;\n    }\n    set startOffset(offset) {\n        this._startOffset = offset;\n        this._forEach(event => {\n            event.startOffset += this._startOffset;\n        });\n    }\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time) {\n        const ticks = this.toTicks(time);\n        this._state.cancel(ticks);\n        this._state.setStateAtTime(\"stopped\", ticks);\n        this._forEach(event => {\n            event.stop(time);\n        });\n        return this;\n    }\n    /**\n     * Get/Set an Event's value at the given time.\n     * If a value is passed in and no event exists at\n     * the given time, one will be created with that value.\n     * If two events are at the same time, the first one will\n     * be returned.\n     * @example\n     * const part = new Tone.Part();\n     * part.at(\"1m\"); // returns the part at the first measure\n     * part.at(\"2m\", \"C2\"); // set the value at \"2m\" to C2.\n     * // if an event didn't exist at that time, it will be created.\n     * @param time The time of the event to get or set.\n     * @param value If a value is passed in, the value of the event at the given time will be set to it.\n     */\n    at(time, value) {\n        const timeInTicks = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_1__.TransportTimeClass(this.context, time).toTicks();\n        const tickTime = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, 1).toSeconds();\n        const iterator = this._events.values();\n        let result = iterator.next();\n        while (!result.done) {\n            const event = result.value;\n            if (Math.abs(timeInTicks - event.startOffset) < tickTime) {\n                if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(value)) {\n                    event.value = value;\n                }\n                return event;\n            }\n            result = iterator.next();\n        }\n        // if there was no event at that time, create one\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(value)) {\n            this.add(time, value);\n            // return the new event\n            return this.at(time);\n        }\n        else {\n            return null;\n        }\n    }\n    add(time, value) {\n        // extract the parameters\n        if (time instanceof Object && Reflect.has(time, \"time\")) {\n            value = time;\n            time = value.time;\n        }\n        const ticks = this.toTicks(time);\n        let event;\n        if (value instanceof _ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent) {\n            event = value;\n            event.callback = this._tick.bind(this);\n        }\n        else {\n            event = new _ToneEvent__WEBPACK_IMPORTED_MODULE_5__.ToneEvent({\n                callback: this._tick.bind(this),\n                context: this.context,\n                value,\n            });\n        }\n        // the start offset\n        event.startOffset = ticks;\n        // initialize the values\n        event.set({\n            humanize: this.humanize,\n            loop: this.loop,\n            loopEnd: this.loopEnd,\n            loopStart: this.loopStart,\n            playbackRate: this.playbackRate,\n            probability: this.probability,\n        });\n        this._events.add(event);\n        // start the note if it should be played right now\n        this._restartEvent(event);\n        return this;\n    }\n    /**\n     * Restart the given event\n     */\n    _restartEvent(event) {\n        this._state.forEach((stateEvent) => {\n            if (stateEvent.state === \"started\") {\n                this._startNote(event, stateEvent.time, stateEvent.offset);\n            }\n            else {\n                // stop the note\n                event.stop(new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, stateEvent.time));\n            }\n        });\n    }\n    remove(time, value) {\n        // extract the parameters\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isObject)(time) && time.hasOwnProperty(\"time\")) {\n            value = time;\n            time = value.time;\n        }\n        time = this.toTicks(time);\n        this._events.forEach(event => {\n            if (event.startOffset === time) {\n                if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isUndef)(value) || ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_4__.isDefined)(value) && event.value === value)) {\n                    this._events.delete(event);\n                    event.dispose();\n                }\n            }\n        });\n        return this;\n    }\n    /**\n     * Remove all of the notes from the group.\n     */\n    clear() {\n        this._forEach(event => event.dispose());\n        this._events.clear();\n        return this;\n    }\n    /**\n     * Cancel scheduled state change events: i.e. \"start\" and \"stop\".\n     * @param after The time after which to cancel the scheduled events.\n     */\n    cancel(after) {\n        this._forEach(event => event.cancel(after));\n        this._state.cancel(this.toTicks(after));\n        return this;\n    }\n    /**\n     * Iterate over all of the events\n     */\n    _forEach(callback) {\n        if (this._events) {\n            this._events.forEach(event => {\n                if (event instanceof Part) {\n                    event._forEach(callback);\n                }\n                else {\n                    callback(event);\n                }\n            });\n        }\n        return this;\n    }\n    /**\n     * Set the attribute of all of the events\n     * @param  attr  the attribute to set\n     * @param  value      The value to set it to\n     */\n    _setAll(attr, value) {\n        this._forEach(event => {\n            event[attr] = value;\n        });\n    }\n    /**\n     * Internal tick method\n     * @param  time  The time of the event in seconds\n     */\n    _tick(time, value) {\n        if (!this.mute) {\n            this.callback(time, value);\n        }\n    }\n    /**\n     * Determine if the event should be currently looping\n     * given the loop boundries of this Part.\n     * @param  event  The event to test\n     */\n    _testLoopBoundries(event) {\n        if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) {\n            event.cancel(0);\n        }\n        else if (event.state === \"stopped\") {\n            // reschedule it if it's stopped\n            this._restartEvent(event);\n        }\n    }\n    get probability() {\n        return this._probability;\n    }\n    set probability(prob) {\n        this._probability = prob;\n        this._setAll(\"probability\", prob);\n    }\n    get humanize() {\n        return this._humanize;\n    }\n    set humanize(variation) {\n        this._humanize = variation;\n        this._setAll(\"humanize\", variation);\n    }\n    /**\n     * If the part should loop or not\n     * between Part.loopStart and\n     * Part.loopEnd. If set to true,\n     * the part will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     * @example\n     * const part = new Tone.Part();\n     * // loop the part 8 times\n     * part.loop = 8;\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        this._loop = loop;\n        this._forEach(event => {\n            event.loopStart = this.loopStart;\n            event.loopEnd = this.loopEnd;\n            event.loop = loop;\n            this._testLoopBoundries(event);\n        });\n    }\n    /**\n     * The loopEnd point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopEnd() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._loopEnd).toSeconds();\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = this.toTicks(loopEnd);\n        if (this._loop) {\n            this._forEach(event => {\n                event.loopEnd = loopEnd;\n                this._testLoopBoundries(event);\n            });\n        }\n    }\n    /**\n     * The loopStart point determines when it will\n     * loop if Part.loop is true.\n     */\n    get loopStart() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._loopStart).toSeconds();\n    }\n    set loopStart(loopStart) {\n        this._loopStart = this.toTicks(loopStart);\n        if (this._loop) {\n            this._forEach(event => {\n                event.loopStart = this.loopStart;\n                this._testLoopBoundries(event);\n            });\n        }\n    }\n    /**\n     * The playback rate of the part\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        this._setAll(\"playbackRate\", rate);\n    }\n    /**\n     * The number of scheduled notes in the part.\n     */\n    get length() {\n        return this._events.size;\n    }\n    dispose() {\n        super.dispose();\n        this.clear();\n        return this;\n    }\n}\n//# sourceMappingURL=Part.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/Part.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Pattern.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Pattern.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Pattern\": () => (/* binding */ Pattern)\n/* harmony export */ });\n/* harmony import */ var _Loop__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Loop */ \"./node_modules/tone/build/esm/event/Loop.js\");\n/* harmony import */ var _PatternGenerator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./PatternGenerator */ \"./node_modules/tone/build/esm/event/PatternGenerator.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Pattern arpeggiates between the given notes\n * in a number of patterns.\n * @example\n * const pattern = new Tone.Pattern((time, note) => {\n * \t// the order of the notes passed in depends on the pattern\n * }, [\"C2\", \"D4\", \"E5\", \"A6\"], \"upDown\");\n * @category Event\n */\nclass Pattern extends _Loop__WEBPACK_IMPORTED_MODULE_0__.Loop {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Pattern.getDefaults(), arguments, [\"callback\", \"values\", \"pattern\"]));\n        this.name = \"Pattern\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Pattern.getDefaults(), arguments, [\"callback\", \"values\", \"pattern\"]);\n        this.callback = options.callback;\n        this._values = options.values;\n        this._pattern = (0,_PatternGenerator__WEBPACK_IMPORTED_MODULE_1__.PatternGenerator)(options.values, options.pattern);\n        this._type = options.pattern;\n    }\n    static getDefaults() {\n        return Object.assign(_Loop__WEBPACK_IMPORTED_MODULE_0__.Loop.getDefaults(), {\n            pattern: \"up\",\n            values: [],\n            callback: _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.noOp,\n        });\n    }\n    /**\n     * Internal function called when the notes should be called\n     */\n    _tick(time) {\n        const value = this._pattern.next();\n        this._value = value.value;\n        this.callback(time, this._value);\n    }\n    /**\n     * The array of events.\n     */\n    get values() {\n        return this._values;\n    }\n    set values(val) {\n        this._values = val;\n        // reset the pattern\n        this.pattern = this._type;\n    }\n    /**\n     * The current value of the pattern.\n     */\n    get value() {\n        return this._value;\n    }\n    /**\n     * The pattern type. See Tone.CtrlPattern for the full list of patterns.\n     */\n    get pattern() {\n        return this._type;\n    }\n    set pattern(pattern) {\n        this._type = pattern;\n        this._pattern = (0,_PatternGenerator__WEBPACK_IMPORTED_MODULE_1__.PatternGenerator)(this._values, this._type);\n    }\n}\n//# sourceMappingURL=Pattern.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/Pattern.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/PatternGenerator.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/event/PatternGenerator.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PatternGenerator\": () => (/* binding */ PatternGenerator)\n/* harmony export */ });\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n/**\n * Start at the first value and go up to the last\n */\nfunction* upPatternGen(values) {\n    let index = 0;\n    while (index < values.length) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        index++;\n    }\n}\n/**\n * Start at the last value and go down to 0\n */\nfunction* downPatternGen(values) {\n    let index = values.length - 1;\n    while (index >= 0) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        index--;\n    }\n}\n/**\n * Infinitely yield the generator\n */\nfunction* infiniteGen(values, gen) {\n    while (true) {\n        yield* gen(values);\n    }\n}\n/**\n * Make sure that the index is in the given range\n */\nfunction clampToArraySize(index, values) {\n    return (0,_core_util_Math__WEBPACK_IMPORTED_MODULE_1__.clamp)(index, 0, values.length - 1);\n}\n/**\n * Alternate between two generators\n */\nfunction* alternatingGenerator(values, directionUp) {\n    let index = directionUp ? 0 : values.length - 1;\n    while (true) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        if (directionUp) {\n            index++;\n            if (index >= values.length - 1) {\n                directionUp = false;\n            }\n        }\n        else {\n            index--;\n            if (index <= 0) {\n                directionUp = true;\n            }\n        }\n    }\n}\n/**\n * Starting from the bottom move up 2, down 1\n */\nfunction* jumpUp(values) {\n    let index = 0;\n    let stepIndex = 0;\n    while (index < values.length) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        stepIndex++;\n        index += (stepIndex % 2 ? 2 : -1);\n    }\n}\n/**\n * Starting from the top move down 2, up 1\n */\nfunction* jumpDown(values) {\n    let index = values.length - 1;\n    let stepIndex = 0;\n    while (index >= 0) {\n        index = clampToArraySize(index, values);\n        yield values[index];\n        stepIndex++;\n        index += (stepIndex % 2 ? -2 : 1);\n    }\n}\n/**\n * Choose a random index each time\n */\nfunction* randomGen(values) {\n    while (true) {\n        const randomIndex = Math.floor(Math.random() * values.length);\n        yield values[randomIndex];\n    }\n}\n/**\n * Randomly go through all of the values once before choosing a new random order\n */\nfunction* randomOnce(values) {\n    // create an array of indices\n    const copy = [];\n    for (let i = 0; i < values.length; i++) {\n        copy.push(i);\n    }\n    while (copy.length > 0) {\n        // random choose an index, and then remove it so it's not chosen again\n        const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);\n        const index = clampToArraySize(randVal[0], values);\n        yield values[index];\n    }\n}\n/**\n * Randomly choose to walk up or down 1 index in the values array\n */\nfunction* randomWalk(values) {\n    // randomly choose a starting index in the values array\n    let index = Math.floor(Math.random() * values.length);\n    while (true) {\n        if (index === 0) {\n            index++; // at bottom of array, so force upward step\n        }\n        else if (index === values.length - 1) {\n            index--; // at top of array, so force downward step\n        }\n        else if (Math.random() < 0.5) { // else choose random downward or upward step\n            index--;\n        }\n        else {\n            index++;\n        }\n        yield values[index];\n    }\n}\n/**\n * PatternGenerator returns a generator which will iterate over the given array\n * of values and yield the items according to the passed in pattern\n * @param values An array of values to iterate over\n * @param pattern The name of the pattern use when iterating over\n * @param index Where to start in the offset of the values array\n */\nfunction* PatternGenerator(values, pattern = \"up\", index = 0) {\n    // safeguards\n    (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_0__.assert)(values.length > 0, \"The array must have more than one value in it\");\n    switch (pattern) {\n        case \"up\":\n            yield* infiniteGen(values, upPatternGen);\n        case \"down\":\n            yield* infiniteGen(values, downPatternGen);\n        case \"upDown\":\n            yield* alternatingGenerator(values, true);\n        case \"downUp\":\n            yield* alternatingGenerator(values, false);\n        case \"alternateUp\":\n            yield* infiniteGen(values, jumpUp);\n        case \"alternateDown\":\n            yield* infiniteGen(values, jumpDown);\n        case \"random\":\n            yield* randomGen(values);\n        case \"randomOnce\":\n            yield* infiniteGen(values, randomOnce);\n        case \"randomWalk\":\n            yield* randomWalk(values);\n    }\n}\n//# sourceMappingURL=PatternGenerator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/PatternGenerator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/Sequence.js":
/*!*******************************************************!*\
  !*** ./node_modules/tone/build/esm/event/Sequence.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Sequence\": () => (/* binding */ Sequence)\n/* harmony export */ });\n/* harmony import */ var _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Part__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Part */ \"./node_modules/tone/build/esm/event/Part.js\");\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n\n\n\n\n\n/**\n * A sequence is an alternate notation of a part. Instead\n * of passing in an array of [time, event] pairs, pass\n * in an array of events which will be spaced at the\n * given subdivision. Sub-arrays will subdivide that beat\n * by the number of items are in the array.\n * Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)\n * @example\n * const synth = new Tone.Synth().toDestination();\n * const seq = new Tone.Sequence((time, note) => {\n * \tsynth.triggerAttackRelease(note, 0.1, time);\n * \t// subdivisions are given as subarrays\n * }, [\"C4\", [\"E4\", \"D4\", \"E4\"], \"G4\", [\"A4\", \"G4\"]]).start(0);\n * Tone.Transport.start();\n * @category Event\n */\nclass Sequence extends _ToneEvent__WEBPACK_IMPORTED_MODULE_4__.ToneEvent {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Sequence.getDefaults(), arguments, [\"callback\", \"events\", \"subdivision\"]));\n        this.name = \"Sequence\";\n        /**\n         * The object responsible for scheduling all of the events\n         */\n        this._part = new _Part__WEBPACK_IMPORTED_MODULE_3__.Part({\n            callback: this._seqCallback.bind(this),\n            context: this.context,\n        });\n        /**\n         * private reference to all of the sequence proxies\n         */\n        this._events = [];\n        /**\n         * The proxied array\n         */\n        this._eventsArray = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Sequence.getDefaults(), arguments, [\"callback\", \"events\", \"subdivision\"]);\n        this._subdivision = this.toTicks(options.subdivision);\n        this.events = options.events;\n        // set all of the values\n        this.loop = options.loop;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this.playbackRate = options.playbackRate;\n        this.probability = options.probability;\n        this.humanize = options.humanize;\n        this.mute = options.mute;\n        this.playbackRate = options.playbackRate;\n    }\n    static getDefaults() {\n        return Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(_ToneEvent__WEBPACK_IMPORTED_MODULE_4__.ToneEvent.getDefaults(), [\"value\"]), {\n            events: [],\n            loop: true,\n            loopEnd: 0,\n            loopStart: 0,\n            subdivision: \"8n\",\n        });\n    }\n    /**\n     * The internal callback for when an event is invoked\n     */\n    _seqCallback(time, value) {\n        if (value !== null) {\n            this.callback(time, value);\n        }\n    }\n    /**\n     * The sequence\n     */\n    get events() {\n        return this._events;\n    }\n    set events(s) {\n        this.clear();\n        this._eventsArray = s;\n        this._events = this._createSequence(this._eventsArray);\n        this._eventsUpdated();\n    }\n    /**\n     * Start the part at the given time.\n     * @param  time    When to start the part.\n     * @param  offset  The offset index to start at\n     */\n    start(time, offset) {\n        this._part.start(time, offset ? this._indexTime(offset) : offset);\n        return this;\n    }\n    /**\n     * Stop the part at the given time.\n     * @param  time  When to stop the part.\n     */\n    stop(time) {\n        this._part.stop(time);\n        return this;\n    }\n    /**\n     * The subdivision of the sequence. This can only be\n     * set in the constructor. The subdivision is the\n     * interval between successive steps.\n     */\n    get subdivision() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, this._subdivision).toSeconds();\n    }\n    /**\n     * Create a sequence proxy which can be monitored to create subsequences\n     */\n    _createSequence(array) {\n        return new Proxy(array, {\n            get: (target, property) => {\n                // property is index in this case\n                return target[property];\n            },\n            set: (target, property, value) => {\n                if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(property) && isFinite(parseInt(property, 10))) {\n                    if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(value)) {\n                        target[property] = this._createSequence(value);\n                    }\n                    else {\n                        target[property] = value;\n                    }\n                }\n                else {\n                    target[property] = value;\n                }\n                this._eventsUpdated();\n                // return true to accept the changes\n                return true;\n            },\n        });\n    }\n    /**\n     * When the sequence has changed, all of the events need to be recreated\n     */\n    _eventsUpdated() {\n        this._part.clear();\n        this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);\n        // update the loopEnd\n        this.loopEnd = this.loopEnd;\n    }\n    /**\n     * reschedule all of the events that need to be rescheduled\n     */\n    _rescheduleSequence(sequence, subdivision, startOffset) {\n        sequence.forEach((value, index) => {\n            const eventOffset = index * (subdivision) + startOffset;\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(value)) {\n                this._rescheduleSequence(value, subdivision / value.length, eventOffset);\n            }\n            else {\n                const startTime = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, eventOffset, \"i\").toSeconds();\n                this._part.add(startTime, value);\n            }\n        });\n    }\n    /**\n     * Get the time of the index given the Sequence's subdivision\n     * @param  index\n     * @return The time of that index\n     */\n    _indexTime(index) {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_0__.TicksClass(this.context, index * (this._subdivision) + this.startOffset).toSeconds();\n    }\n    /**\n     * Clear all of the events\n     */\n    clear() {\n        this._part.clear();\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._part.dispose();\n        return this;\n    }\n    //-------------------------------------\n    // PROXY CALLS\n    //-------------------------------------\n    get loop() {\n        return this._part.loop;\n    }\n    set loop(l) {\n        this._part.loop = l;\n    }\n    /**\n     * The index at which the sequence should start looping\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(index) {\n        this._loopStart = index;\n        this._part.loopStart = this._indexTime(index);\n    }\n    /**\n     * The index at which the sequence should end looping\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(index) {\n        this._loopEnd = index;\n        if (index === 0) {\n            this._part.loopEnd = this._indexTime(this._eventsArray.length);\n        }\n        else {\n            this._part.loopEnd = this._indexTime(index);\n        }\n    }\n    get startOffset() {\n        return this._part.startOffset;\n    }\n    set startOffset(start) {\n        this._part.startOffset = start;\n    }\n    get playbackRate() {\n        return this._part.playbackRate;\n    }\n    set playbackRate(rate) {\n        this._part.playbackRate = rate;\n    }\n    get probability() {\n        return this._part.probability;\n    }\n    set probability(prob) {\n        this._part.probability = prob;\n    }\n    get progress() {\n        return this._part.progress;\n    }\n    get humanize() {\n        return this._part.humanize;\n    }\n    set humanize(variation) {\n        this._part.humanize = variation;\n    }\n    /**\n     * The number of scheduled events\n     */\n    get length() {\n        return this._part.length;\n    }\n}\n//# sourceMappingURL=Sequence.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/Sequence.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/ToneEvent.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/event/ToneEvent.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneEvent\": () => (/* binding */ ToneEvent)\n/* harmony export */ });\n/* harmony import */ var _core_clock_Transport__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/clock/Transport */ \"./node_modules/tone/build/esm/core/clock/Transport.js\");\n/* harmony import */ var _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneWithContext */ \"./node_modules/tone/build/esm/core/context/ToneWithContext.js\");\n/* harmony import */ var _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/type/Ticks */ \"./node_modules/tone/build/esm/core/type/Ticks.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n\n\n\n/**\n * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable\n * callback for a single or repeatable events along the timeline.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * const chordEvent = new Tone.ToneEvent(((time, chord) => {\n * \t// the chord as well as the exact time of the event\n * \t// are passed in as arguments to the callback function\n * \tsynth.triggerAttackRelease(chord, 0.5, time);\n * }), [\"D4\", \"E4\", \"F4\"]);\n * // start the chord at the beginning of the transport timeline\n * chordEvent.start();\n * // loop it every measure for 8 measures\n * chordEvent.loop = 8;\n * chordEvent.loopEnd = \"1m\";\n * @category Event\n */\nclass ToneEvent extends _core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneEvent.getDefaults(), arguments, [\"callback\", \"value\"]));\n        this.name = \"ToneEvent\";\n        /**\n         * Tracks the scheduled events\n         */\n        this._state = new _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_5__.StateTimeline(\"stopped\");\n        /**\n         * A delay time from when the event is scheduled to start\n         */\n        this._startOffset = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneEvent.getDefaults(), arguments, [\"callback\", \"value\"]);\n        this._loop = options.loop;\n        this.callback = options.callback;\n        this.value = options.value;\n        this._loopStart = this.toTicks(options.loopStart);\n        this._loopEnd = this.toTicks(options.loopEnd);\n        this._playbackRate = options.playbackRate;\n        this._probability = options.probability;\n        this._humanize = options.humanize;\n        this.mute = options.mute;\n        this._playbackRate = options.playbackRate;\n        this._state.increasing = true;\n        // schedule the events for the first time\n        this._rescheduleEvents();\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneWithContext__WEBPACK_IMPORTED_MODULE_1__.ToneWithContext.getDefaults(), {\n            callback: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            humanize: false,\n            loop: false,\n            loopEnd: \"1m\",\n            loopStart: 0,\n            mute: false,\n            playbackRate: 1,\n            probability: 1,\n            value: null,\n        });\n    }\n    /**\n     * Reschedule all of the events along the timeline\n     * with the updated values.\n     * @param after Only reschedules events after the given time.\n     */\n    _rescheduleEvents(after = -1) {\n        // if no argument is given, schedules all of the events\n        this._state.forEachFrom(after, event => {\n            let duration;\n            if (event.state === \"started\") {\n                if (event.id !== -1) {\n                    this.context.transport.clear(event.id);\n                }\n                const startTick = event.time + Math.round(this.startOffset / this._playbackRate);\n                if (this._loop === true || (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isNumber)(this._loop) && this._loop > 1) {\n                    duration = Infinity;\n                    if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isNumber)(this._loop)) {\n                        duration = (this._loop) * this._getLoopDuration();\n                    }\n                    const nextEvent = this._state.getAfter(startTick);\n                    if (nextEvent !== null) {\n                        duration = Math.min(duration, nextEvent.time - startTick);\n                    }\n                    if (duration !== Infinity) {\n                        // schedule a stop since it's finite duration\n                        this._state.setStateAtTime(\"stopped\", startTick + duration + 1, { id: -1 });\n                        duration = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, duration);\n                    }\n                    const interval = new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, this._getLoopDuration());\n                    event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, startTick), duration);\n                }\n                else {\n                    event.id = this.context.transport.schedule(this._tick.bind(this), new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, startTick));\n                }\n            }\n        });\n    }\n    /**\n     * Returns the playback state of the note, either \"started\" or \"stopped\".\n     */\n    get state() {\n        return this._state.getValueAtTime(this.context.transport.ticks);\n    }\n    /**\n     * The start from the scheduled start time.\n     */\n    get startOffset() {\n        return this._startOffset;\n    }\n    set startOffset(offset) {\n        this._startOffset = offset;\n    }\n    /**\n     * The probability of the notes being triggered.\n     */\n    get probability() {\n        return this._probability;\n    }\n    set probability(prob) {\n        this._probability = prob;\n    }\n    /**\n     * If set to true, will apply small random variation\n     * to the callback time. If the value is given as a time, it will randomize\n     * by that amount.\n     * @example\n     * const event = new Tone.ToneEvent();\n     * event.humanize = true;\n     */\n    get humanize() {\n        return this._humanize;\n    }\n    set humanize(variation) {\n        this._humanize = variation;\n    }\n    /**\n     * Start the note at the given time.\n     * @param  time  When the event should start.\n     */\n    start(time) {\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) === \"stopped\") {\n            this._state.add({\n                id: -1,\n                state: \"started\",\n                time: ticks,\n            });\n            this._rescheduleEvents(ticks);\n        }\n        return this;\n    }\n    /**\n     * Stop the Event at the given time.\n     * @param  time  When the event should stop.\n     */\n    stop(time) {\n        this.cancel(time);\n        const ticks = this.toTicks(time);\n        if (this._state.getValueAtTime(ticks) === \"started\") {\n            this._state.setStateAtTime(\"stopped\", ticks, { id: -1 });\n            const previousEvent = this._state.getBefore(ticks);\n            let reschedulTime = ticks;\n            if (previousEvent !== null) {\n                reschedulTime = previousEvent.time;\n            }\n            this._rescheduleEvents(reschedulTime);\n        }\n        return this;\n    }\n    /**\n     * Cancel all scheduled events greater than or equal to the given time\n     * @param  time  The time after which events will be cancel.\n     */\n    cancel(time) {\n        time = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(time, -Infinity);\n        const ticks = this.toTicks(time);\n        this._state.forEachFrom(ticks, event => {\n            this.context.transport.clear(event.id);\n        });\n        this._state.cancel(ticks);\n        return this;\n    }\n    /**\n     * The callback function invoker. Also\n     * checks if the Event is done playing\n     * @param  time  The time of the event in seconds\n     */\n    _tick(time) {\n        const ticks = this.context.transport.getTicksAtTime(time);\n        if (!this.mute && this._state.getValueAtTime(ticks) === \"started\") {\n            if (this.probability < 1 && Math.random() > this.probability) {\n                return;\n            }\n            if (this.humanize) {\n                let variation = 0.02;\n                if (!(0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_6__.isBoolean)(this.humanize)) {\n                    variation = this.toSeconds(this.humanize);\n                }\n                time += (Math.random() * 2 - 1) * variation;\n            }\n            this.callback(time, this.value);\n        }\n    }\n    /**\n     * Get the duration of the loop.\n     */\n    _getLoopDuration() {\n        return Math.round((this._loopEnd - this._loopStart) / this._playbackRate);\n    }\n    /**\n     * If the note should loop or not\n     * between ToneEvent.loopStart and\n     * ToneEvent.loopEnd. If set to true,\n     * the event will loop indefinitely,\n     * if set to a number greater than 1\n     * it will play a specific number of\n     * times, if set to false, 0 or 1, the\n     * part will only play once.\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        this._loop = loop;\n        this._rescheduleEvents();\n    }\n    /**\n     * The playback rate of the note. Defaults to 1.\n     * @example\n     * const note = new Tone.ToneEvent();\n     * note.loop = true;\n     * // repeat the note twice as fast\n     * note.playbackRate = 2;\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        this._rescheduleEvents();\n    }\n    /**\n     * The loopEnd point is the time the event will loop\n     * if ToneEvent.loop is true.\n     */\n    get loopEnd() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, this._loopEnd).toSeconds();\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = this.toTicks(loopEnd);\n        if (this._loop) {\n            this._rescheduleEvents();\n        }\n    }\n    /**\n     * The time when the loop should start.\n     */\n    get loopStart() {\n        return new _core_type_Ticks__WEBPACK_IMPORTED_MODULE_2__.TicksClass(this.context, this._loopStart).toSeconds();\n    }\n    set loopStart(loopStart) {\n        this._loopStart = this.toTicks(loopStart);\n        if (this._loop) {\n            this._rescheduleEvents();\n        }\n    }\n    /**\n     * The current progress of the loop interval.\n     * Returns 0 if the event is not started yet or\n     * it is not set to loop.\n     */\n    get progress() {\n        if (this._loop) {\n            const ticks = this.context.transport.ticks;\n            const lastEvent = this._state.get(ticks);\n            if (lastEvent !== null && lastEvent.state === \"started\") {\n                const loopDuration = this._getLoopDuration();\n                const progress = (ticks - lastEvent.time) % loopDuration;\n                return progress / loopDuration;\n            }\n            else {\n                return 0;\n            }\n        }\n        else {\n            return 0;\n        }\n    }\n    dispose() {\n        super.dispose();\n        this.cancel();\n        this._state.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneEvent.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/ToneEvent.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/event/index.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/build/esm/event/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Loop\": () => (/* reexport safe */ _Loop__WEBPACK_IMPORTED_MODULE_0__.Loop),\n/* harmony export */   \"Part\": () => (/* reexport safe */ _Part__WEBPACK_IMPORTED_MODULE_1__.Part),\n/* harmony export */   \"Pattern\": () => (/* reexport safe */ _Pattern__WEBPACK_IMPORTED_MODULE_2__.Pattern),\n/* harmony export */   \"Sequence\": () => (/* reexport safe */ _Sequence__WEBPACK_IMPORTED_MODULE_3__.Sequence),\n/* harmony export */   \"ToneEvent\": () => (/* reexport safe */ _ToneEvent__WEBPACK_IMPORTED_MODULE_4__.ToneEvent)\n/* harmony export */ });\n/* harmony import */ var _Loop__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Loop */ \"./node_modules/tone/build/esm/event/Loop.js\");\n/* harmony import */ var _Part__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Part */ \"./node_modules/tone/build/esm/event/Part.js\");\n/* harmony import */ var _Pattern__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Pattern */ \"./node_modules/tone/build/esm/event/Pattern.js\");\n/* harmony import */ var _Sequence__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Sequence */ \"./node_modules/tone/build/esm/event/Sequence.js\");\n/* harmony import */ var _ToneEvent__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneEvent */ \"./node_modules/tone/build/esm/event/ToneEvent.js\");\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/event/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/index.js":
/*!**********************************************!*\
  !*** ./node_modules/tone/build/esm/index.js ***!
  \**********************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AMOscillator),\n/* harmony export */   \"AMSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AMSynth),\n/* harmony export */   \"Abs\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Abs),\n/* harmony export */   \"Add\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Add),\n/* harmony export */   \"AmplitudeEnvelope\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AmplitudeEnvelope),\n/* harmony export */   \"Analyser\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Analyser),\n/* harmony export */   \"AudioToGain\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AudioToGain),\n/* harmony export */   \"AutoFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AutoFilter),\n/* harmony export */   \"AutoPanner\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AutoPanner),\n/* harmony export */   \"AutoWah\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.AutoWah),\n/* harmony export */   \"BaseContext\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.BaseContext),\n/* harmony export */   \"BiquadFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.BiquadFilter),\n/* harmony export */   \"BitCrusher\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.BitCrusher),\n/* harmony export */   \"Buffer\": () => (/* binding */ Buffer),\n/* harmony export */   \"BufferSource\": () => (/* binding */ BufferSource),\n/* harmony export */   \"Buffers\": () => (/* binding */ Buffers),\n/* harmony export */   \"Channel\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Channel),\n/* harmony export */   \"Chebyshev\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Chebyshev),\n/* harmony export */   \"Chorus\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Chorus),\n/* harmony export */   \"Clock\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Clock),\n/* harmony export */   \"Compressor\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Compressor),\n/* harmony export */   \"Context\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Context),\n/* harmony export */   \"Convolver\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Convolver),\n/* harmony export */   \"CrossFade\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.CrossFade),\n/* harmony export */   \"DCMeter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.DCMeter),\n/* harmony export */   \"Delay\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Delay),\n/* harmony export */   \"Destination\": () => (/* binding */ Destination),\n/* harmony export */   \"Distortion\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Distortion),\n/* harmony export */   \"Draw\": () => (/* binding */ Draw),\n/* harmony export */   \"DuoSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.DuoSynth),\n/* harmony export */   \"EQ3\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.EQ3),\n/* harmony export */   \"Emitter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Emitter),\n/* harmony export */   \"Envelope\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Envelope),\n/* harmony export */   \"FFT\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FFT),\n/* harmony export */   \"FMOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FMOscillator),\n/* harmony export */   \"FMSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FMSynth),\n/* harmony export */   \"FatOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FatOscillator),\n/* harmony export */   \"FeedbackCombFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FeedbackCombFilter),\n/* harmony export */   \"FeedbackDelay\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FeedbackDelay),\n/* harmony export */   \"Filter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Filter),\n/* harmony export */   \"Follower\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Follower),\n/* harmony export */   \"Freeverb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Freeverb),\n/* harmony export */   \"Frequency\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Frequency),\n/* harmony export */   \"FrequencyClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FrequencyClass),\n/* harmony export */   \"FrequencyEnvelope\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FrequencyEnvelope),\n/* harmony export */   \"FrequencyShifter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.FrequencyShifter),\n/* harmony export */   \"Gain\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Gain),\n/* harmony export */   \"GainToAudio\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GainToAudio),\n/* harmony export */   \"Gate\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Gate),\n/* harmony export */   \"GrainPlayer\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GrainPlayer),\n/* harmony export */   \"GreaterThan\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GreaterThan),\n/* harmony export */   \"GreaterThanZero\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.GreaterThanZero),\n/* harmony export */   \"IntervalTimeline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.IntervalTimeline),\n/* harmony export */   \"JCReverb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.JCReverb),\n/* harmony export */   \"LFO\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.LFO),\n/* harmony export */   \"Limiter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Limiter),\n/* harmony export */   \"Listener\": () => (/* binding */ Listener),\n/* harmony export */   \"Loop\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Loop),\n/* harmony export */   \"LowpassCombFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.LowpassCombFilter),\n/* harmony export */   \"Master\": () => (/* binding */ Master),\n/* harmony export */   \"MembraneSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MembraneSynth),\n/* harmony export */   \"Merge\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Merge),\n/* harmony export */   \"MetalSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MetalSynth),\n/* harmony export */   \"Meter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Meter),\n/* harmony export */   \"MidSideCompressor\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidSideCompressor),\n/* harmony export */   \"MidSideMerge\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidSideMerge),\n/* harmony export */   \"MidSideSplit\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidSideSplit),\n/* harmony export */   \"Midi\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Midi),\n/* harmony export */   \"MidiClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MidiClass),\n/* harmony export */   \"Mono\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Mono),\n/* harmony export */   \"MonoSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MonoSynth),\n/* harmony export */   \"MultibandCompressor\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MultibandCompressor),\n/* harmony export */   \"MultibandSplit\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.MultibandSplit),\n/* harmony export */   \"Multiply\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Multiply),\n/* harmony export */   \"Negate\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Negate),\n/* harmony export */   \"Noise\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Noise),\n/* harmony export */   \"NoiseSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.NoiseSynth),\n/* harmony export */   \"Offline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Offline),\n/* harmony export */   \"OfflineContext\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.OfflineContext),\n/* harmony export */   \"OmniOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.OmniOscillator),\n/* harmony export */   \"OnePoleFilter\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.OnePoleFilter),\n/* harmony export */   \"Oscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Oscillator),\n/* harmony export */   \"PWMOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PWMOscillator),\n/* harmony export */   \"PanVol\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PanVol),\n/* harmony export */   \"Panner\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Panner),\n/* harmony export */   \"Panner3D\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Panner3D),\n/* harmony export */   \"Param\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Param),\n/* harmony export */   \"Part\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Part),\n/* harmony export */   \"Pattern\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Pattern),\n/* harmony export */   \"Phaser\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Phaser),\n/* harmony export */   \"PingPongDelay\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PingPongDelay),\n/* harmony export */   \"PitchShift\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PitchShift),\n/* harmony export */   \"Player\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Player),\n/* harmony export */   \"Players\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Players),\n/* harmony export */   \"PluckSynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PluckSynth),\n/* harmony export */   \"PolySynth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PolySynth),\n/* harmony export */   \"Pow\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Pow),\n/* harmony export */   \"PulseOscillator\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.PulseOscillator),\n/* harmony export */   \"Recorder\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Recorder),\n/* harmony export */   \"Reverb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Reverb),\n/* harmony export */   \"Sampler\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Sampler),\n/* harmony export */   \"Scale\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Scale),\n/* harmony export */   \"ScaleExp\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ScaleExp),\n/* harmony export */   \"Sequence\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Sequence),\n/* harmony export */   \"Signal\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Signal),\n/* harmony export */   \"Solo\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Solo),\n/* harmony export */   \"Split\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Split),\n/* harmony export */   \"StateTimeline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.StateTimeline),\n/* harmony export */   \"StereoWidener\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.StereoWidener),\n/* harmony export */   \"Subtract\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Subtract),\n/* harmony export */   \"SyncedSignal\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.SyncedSignal),\n/* harmony export */   \"Synth\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Synth),\n/* harmony export */   \"Ticks\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Ticks),\n/* harmony export */   \"TicksClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TicksClass),\n/* harmony export */   \"Time\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Time),\n/* harmony export */   \"TimeClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TimeClass),\n/* harmony export */   \"Timeline\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Timeline),\n/* harmony export */   \"ToneAudioBuffer\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffer),\n/* harmony export */   \"ToneAudioBuffers\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffers),\n/* harmony export */   \"ToneAudioNode\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode),\n/* harmony export */   \"ToneBufferSource\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneBufferSource),\n/* harmony export */   \"ToneEvent\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneEvent),\n/* harmony export */   \"ToneOscillatorNode\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ToneOscillatorNode),\n/* harmony export */   \"Transport\": () => (/* binding */ Transport),\n/* harmony export */   \"TransportTime\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TransportTime),\n/* harmony export */   \"TransportTimeClass\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.TransportTimeClass),\n/* harmony export */   \"Tremolo\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Tremolo),\n/* harmony export */   \"Unit\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Unit),\n/* harmony export */   \"UserMedia\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.UserMedia),\n/* harmony export */   \"Vibrato\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Vibrato),\n/* harmony export */   \"Volume\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Volume),\n/* harmony export */   \"WaveShaper\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.WaveShaper),\n/* harmony export */   \"Waveform\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Waveform),\n/* harmony export */   \"Zero\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.Zero),\n/* harmony export */   \"connect\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.connect),\n/* harmony export */   \"connectSeries\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.connectSeries),\n/* harmony export */   \"connectSignal\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.connectSignal),\n/* harmony export */   \"context\": () => (/* binding */ context),\n/* harmony export */   \"dbToGain\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.dbToGain),\n/* harmony export */   \"debug\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.debug),\n/* harmony export */   \"defaultArg\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.defaultArg),\n/* harmony export */   \"disconnect\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.disconnect),\n/* harmony export */   \"ftom\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.ftom),\n/* harmony export */   \"gainToDb\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.gainToDb),\n/* harmony export */   \"getContext\": () => (/* reexport safe */ _core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext),\n/* harmony export */   \"getDestination\": () => (/* binding */ getDestination),\n/* harmony export */   \"getDraw\": () => (/* binding */ getDraw),\n/* harmony export */   \"getListener\": () => (/* binding */ getListener),\n/* harmony export */   \"getTransport\": () => (/* binding */ getTransport),\n/* harmony export */   \"immediate\": () => (/* binding */ immediate),\n/* harmony export */   \"intervalToFrequencyRatio\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.intervalToFrequencyRatio),\n/* harmony export */   \"isArray\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isArray),\n/* harmony export */   \"isBoolean\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isBoolean),\n/* harmony export */   \"isDefined\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isDefined),\n/* harmony export */   \"isFunction\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isFunction),\n/* harmony export */   \"isNote\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isNote),\n/* harmony export */   \"isNumber\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isNumber),\n/* harmony export */   \"isObject\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isObject),\n/* harmony export */   \"isString\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isString),\n/* harmony export */   \"isUndef\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.isUndef),\n/* harmony export */   \"loaded\": () => (/* binding */ loaded),\n/* harmony export */   \"mtof\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.mtof),\n/* harmony export */   \"now\": () => (/* binding */ now),\n/* harmony export */   \"optionsFromArguments\": () => (/* reexport safe */ _classes__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments),\n/* harmony export */   \"setContext\": () => (/* reexport safe */ _core_Global__WEBPACK_IMPORTED_MODULE_0__.setContext),\n/* harmony export */   \"start\": () => (/* reexport safe */ _core_Global__WEBPACK_IMPORTED_MODULE_0__.start),\n/* harmony export */   \"supported\": () => (/* reexport safe */ _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_4__.supported),\n/* harmony export */   \"version\": () => (/* reexport safe */ _version__WEBPACK_IMPORTED_MODULE_2__.version)\n/* harmony export */ });\n/* harmony import */ var _core_Global__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./core/Global */ \"./node_modules/tone/build/esm/core/Global.js\");\n/* harmony import */ var _classes__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./classes */ \"./node_modules/tone/build/esm/classes.js\");\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./version */ \"./node_modules/tone/build/esm/version.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_context_AudioContext__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./core/context/AudioContext */ \"./node_modules/tone/build/esm/core/context/AudioContext.js\");\n/* harmony import */ var _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./core/context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./source/buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n\n\n\n\n\n\n\n/**\n * The current audio context time of the global [[Context]].\n * See [[Context.now]]\n * @category Core\n */\nfunction now() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().now();\n}\n/**\n * The current audio context time of the global [[Context]] without the [[Context.lookAhead]]\n * See [[Context.immediate]]\n * @category Core\n */\nfunction immediate() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().immediate();\n}\n/**\n * The Transport object belonging to the global Tone.js Context.\n * See [[Transport]]\n * @category Core\n */\nconst Transport = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().transport;\n/**\n * The Transport object belonging to the global Tone.js Context.\n * See [[Transport]]\n * @category Core\n */\nfunction getTransport() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().transport;\n}\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * See [[Destination]]\n * @category Core\n */\nconst Destination = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().destination;\n/**\n * @deprecated Use [[Destination]]\n */\nconst Master = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().destination;\n/**\n * The Destination (output) belonging to the global Tone.js Context.\n * See [[Destination]]\n * @category Core\n */\nfunction getDestination() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().destination;\n}\n/**\n * The [[Listener]] belonging to the global Tone.js Context.\n * @category Core\n */\nconst Listener = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().listener;\n/**\n * The [[Listener]] belonging to the global Tone.js Context.\n * @category Core\n */\nfunction getListener() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().listener;\n}\n/**\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * See [[Draw]]\n * @category Core\n */\nconst Draw = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().draw;\n/**\n * Get the singleton attached to the global context.\n * Draw is used to synchronize the draw frame with the Transport's callbacks.\n * See [[Draw]]\n * @category Core\n */\nfunction getDraw() {\n    return (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)().draw;\n}\n/**\n * A reference to the global context\n * See [[Context]]\n */\nconst context = (0,_core_Global__WEBPACK_IMPORTED_MODULE_0__.getContext)();\n/**\n * Promise which resolves when all of the loading promises are resolved.\n * Alias for static [[ToneAudioBuffer.loaded]] method.\n * @category Core\n */\nfunction loaded() {\n    return _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__.ToneAudioBuffer.loaded();\n}\n// this fills in name changes from 13.x to 14.x\n\n\nconst Buffer = _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_3__.ToneAudioBuffer;\nconst Buffers = _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_5__.ToneAudioBuffers;\nconst BufferSource = _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_6__.ToneBufferSource;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/AMSynth.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/AMSynth.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMSynth\": () => (/* binding */ AMSynth)\n/* harmony export */ });\n/* harmony import */ var _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../signal/AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ModulationSynth */ \"./node_modules/tone/build/esm/instrument/ModulationSynth.js\");\n\n\n\n/**\n * AMSynth uses the output of one Tone.Synth to modulate the\n * amplitude of another Tone.Synth. The harmonicity (the ratio between\n * the two signals) affects the timbre of the output signal greatly.\n * Read more about Amplitude Modulation Synthesis on\n * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).\n *\n * @example\n * const synth = new Tone.AMSynth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"4n\");\n *\n * @category Instrument\n */\nclass AMSynth extends _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__.ModulationSynth {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AMSynth.getDefaults(), arguments));\n        this.name = \"AMSynth\";\n        this._modulationScale = new _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_0__.AudioToGain({\n            context: this.context,\n        });\n        // control the two voices frequency\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.detune.fan(this._carrier.detune, this._modulator.detune);\n        this._modulator.chain(this._modulationScale, this._modulationNode.gain);\n        this._carrier.chain(this._modulationNode, this.output);\n    }\n    dispose() {\n        super.dispose();\n        this._modulationScale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AMSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/AMSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/DuoSynth.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/DuoSynth.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"DuoSynth\": () => (/* binding */ DuoSynth)\n/* harmony export */ });\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _MonoSynth__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./MonoSynth */ \"./node_modules/tone/build/esm/instrument/MonoSynth.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../source/oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n\n\n/**\n * DuoSynth is a monophonic synth composed of two [[MonoSynths]] run in parallel with control over the\n * frequency ratio between the two voices and vibrato effect.\n * @example\n * const duoSynth = new Tone.DuoSynth().toDestination();\n * duoSynth.triggerAttackRelease(\"C4\", \"2n\");\n * @category Instrument\n */\nclass DuoSynth extends _Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(DuoSynth.getDefaults(), arguments));\n        this.name = \"DuoSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.optionsFromArguments)(DuoSynth.getDefaults(), arguments);\n        this.voice0 = new _MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth(Object.assign(options.voice0, {\n            context: this.context,\n            onsilence: () => this.onsilence(this)\n        }));\n        this.voice1 = new _MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth(Object.assign(options.voice1, {\n            context: this.context,\n        }));\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        this._vibrato = new _source_oscillator_LFO__WEBPACK_IMPORTED_MODULE_4__.LFO({\n            frequency: options.vibratoRate,\n            context: this.context,\n            min: -50,\n            max: 50\n        });\n        // start the vibrato immediately\n        this._vibrato.start();\n        this.vibratoRate = this._vibrato.frequency;\n        this._vibratoGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_5__.Gain({\n            context: this.context,\n            units: \"normalRange\",\n            gain: options.vibratoAmount\n        });\n        this.vibratoAmount = this._vibratoGain.gain;\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: 440\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune\n        });\n        // control the two voices frequency\n        this.frequency.connect(this.voice0.frequency);\n        this.frequency.chain(this.harmonicity, this.voice1.frequency);\n        this._vibrato.connect(this._vibratoGain);\n        this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);\n        this.detune.fan(this.voice0.detune, this.voice1.detune);\n        this.voice0.connect(this.output);\n        this.voice1.connect(this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, [\"voice0\", \"voice1\", \"frequency\", \"vibratoAmount\", \"vibratoRate\"]);\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.deepMerge)(_Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic.getDefaults(), {\n            vibratoAmount: 0.5,\n            vibratoRate: 5,\n            harmonicity: 1.5,\n            voice0: (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.deepMerge)((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.omitFromObject)(_MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth.getDefaults(), Object.keys(_Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic.getDefaults())), {\n                filterEnvelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                },\n                envelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                }\n            }),\n            voice1: (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.deepMerge)((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_7__.omitFromObject)(_MonoSynth__WEBPACK_IMPORTED_MODULE_1__.MonoSynth.getDefaults(), Object.keys(_Monophonic__WEBPACK_IMPORTED_MODULE_0__.Monophonic.getDefaults())), {\n                filterEnvelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                },\n                envelope: {\n                    attack: 0.01,\n                    decay: 0.0,\n                    sustain: 1,\n                    release: 0.5\n                }\n            }),\n        });\n    }\n    /**\n     * Trigger the attack portion of the note\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // @ts-ignore\n        this.voice0._triggerEnvelopeAttack(time, velocity);\n        // @ts-ignore\n        this.voice1._triggerEnvelopeAttack(time, velocity);\n    }\n    /**\n     * Trigger the release portion of the note\n     */\n    _triggerEnvelopeRelease(time) {\n        // @ts-ignore\n        this.voice0._triggerEnvelopeRelease(time);\n        // @ts-ignore\n        this.voice1._triggerEnvelopeRelease(time);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.voice0.dispose();\n        this.voice1.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._vibrato.dispose();\n        this.vibratoRate.dispose();\n        this._vibratoGain.dispose();\n        this.harmonicity.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=DuoSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/DuoSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/FMSynth.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/FMSynth.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FMSynth\": () => (/* binding */ FMSynth)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./ModulationSynth */ \"./node_modules/tone/build/esm/instrument/ModulationSynth.js\");\n\n\n\n/**\n * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates\n * the frequency of a second Tone.Synth. A lot of spectral content\n * can be explored using the modulationIndex parameter. Read more about\n * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).\n *\n * @example\n * const fmSynth = new Tone.FMSynth().toDestination();\n * fmSynth.triggerAttackRelease(\"C5\", \"4n\");\n *\n * @category Instrument\n */\nclass FMSynth extends _ModulationSynth__WEBPACK_IMPORTED_MODULE_2__.ModulationSynth {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FMSynth.getDefaults(), arguments));\n        this.name = \"FMSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FMSynth.getDefaults(), arguments);\n        this.modulationIndex = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__.Multiply({\n            context: this.context,\n            value: options.modulationIndex,\n        });\n        // control the two voices frequency\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.frequency.chain(this.modulationIndex, this._modulationNode);\n        this.detune.fan(this._carrier.detune, this._modulator.detune);\n        this._modulator.connect(this._modulationNode.gain);\n        this._modulationNode.connect(this._carrier.frequency);\n        this._carrier.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_ModulationSynth__WEBPACK_IMPORTED_MODULE_2__.ModulationSynth.getDefaults(), {\n            modulationIndex: 10,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.modulationIndex.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FMSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/FMSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Instrument.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Instrument.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Instrument\": () => (/* binding */ Instrument)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n/**\n * Base-class for all instruments\n */\nclass Instrument extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Instrument.getDefaults(), arguments));\n        /**\n         * Keep track of all events scheduled to the transport\n         * when the instrument is 'synced'\n         */\n        this._scheduledEvents = [];\n        /**\n         * If the instrument is currently synced\n         */\n        this._synced = false;\n        this._original_triggerAttack = this.triggerAttack;\n        this._original_triggerRelease = this.triggerRelease;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Instrument.getDefaults(), arguments);\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_3__.readOnly)(this, \"volume\");\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            volume: 0,\n        });\n    }\n    /**\n     * Sync the instrument to the Transport. All subsequent calls of\n     * [[triggerAttack]] and [[triggerRelease]] will be scheduled along the transport.\n     * @example\n     * const fmSynth = new Tone.FMSynth().toDestination();\n     * fmSynth.volume.value = -6;\n     * fmSynth.sync();\n     * // schedule 3 notes when the transport first starts\n     * fmSynth.triggerAttackRelease(\"C4\", \"8n\", 0);\n     * fmSynth.triggerAttackRelease(\"E4\", \"8n\", \"8n\");\n     * fmSynth.triggerAttackRelease(\"G4\", \"8n\", \"4n\");\n     * // start the transport to hear the notes\n     * Tone.Transport.start();\n     */\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 0);\n        }\n        return this;\n    }\n    /**\n     * set _sync\n     */\n    _syncState() {\n        let changed = false;\n        if (!this._synced) {\n            this._synced = true;\n            changed = true;\n        }\n        return changed;\n    }\n    /**\n     * Wrap the given method so that it can be synchronized\n     * @param method Which method to wrap and sync\n     * @param  timePosition What position the time argument appears in\n     */\n    _syncMethod(method, timePosition) {\n        const originalMethod = this[\"_original_\" + method] = this[method];\n        this[method] = (...args) => {\n            const time = args[timePosition];\n            const id = this.context.transport.schedule((t) => {\n                args[timePosition] = t;\n                originalMethod.apply(this, args);\n            }, time);\n            this._scheduledEvents.push(id);\n        };\n    }\n    /**\n     * Unsync the instrument from the Transport\n     */\n    unsync() {\n        this._scheduledEvents.forEach(id => this.context.transport.clear(id));\n        this._scheduledEvents = [];\n        if (this._synced) {\n            this._synced = false;\n            this.triggerAttack = this._original_triggerAttack;\n            this.triggerRelease = this._original_triggerRelease;\n        }\n        return this;\n    }\n    /**\n     * Trigger the attack and then the release after the duration.\n     * @param  note     The note to trigger.\n     * @param  duration How long the note should be held for before\n     *                         triggering the release. This value must be greater than 0.\n     * @param time  When the note should be triggered.\n     * @param  velocity The velocity the note should be triggered at.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger \"C4\" for the duration of an 8th note\n     * synth.triggerAttackRelease(\"C4\", \"8n\");\n     */\n    triggerAttackRelease(note, duration, time, velocity) {\n        const computedTime = this.toSeconds(time);\n        const computedDuration = this.toSeconds(duration);\n        this.triggerAttack(note, computedTime, velocity);\n        this.triggerRelease(computedTime + computedDuration);\n        return this;\n    }\n    /**\n     * clean up\n     * @returns {Instrument} this\n     */\n    dispose() {\n        super.dispose();\n        this._volume.dispose();\n        this.unsync();\n        this._scheduledEvents = [];\n        return this;\n    }\n}\n//# sourceMappingURL=Instrument.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/Instrument.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/MembraneSynth.js":
/*!*****************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/MembraneSynth.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MembraneSynth\": () => (/* binding */ MembraneSynth)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n\n/**\n * MembraneSynth makes kick and tom sounds using a single oscillator\n * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator\n * is routed through a Tone.AmplitudeEnvelope to the output. The drum\n * quality of the sound comes from the frequency envelope applied\n * during MembraneSynth.triggerAttack(note). The frequency envelope\n * starts at <code>note * .octaves</code> and ramps to <code>note</code>\n * over the duration of <code>.pitchDecay</code>.\n * @example\n * const synth = new Tone.MembraneSynth().toDestination();\n * synth.triggerAttackRelease(\"C2\", \"8n\");\n * @category Instrument\n */\nclass MembraneSynth extends _Synth__WEBPACK_IMPORTED_MODULE_4__.Synth {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(MembraneSynth.getDefaults(), arguments));\n        this.name = \"MembraneSynth\";\n        /**\n         * Portamento is ignored in this synth. use pitch decay instead.\n         */\n        this.portamento = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(MembraneSynth.getDefaults(), arguments);\n        this.pitchDecay = options.pitchDecay;\n        this.octaves = options.octaves;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"oscillator\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.deepMerge)(_Monophonic__WEBPACK_IMPORTED_MODULE_3__.Monophonic.getDefaults(), _Synth__WEBPACK_IMPORTED_MODULE_4__.Synth.getDefaults(), {\n            envelope: {\n                attack: 0.001,\n                attackCurve: \"exponential\",\n                decay: 0.4,\n                release: 1.4,\n                sustain: 0.01,\n            },\n            octaves: 10,\n            oscillator: {\n                type: \"sine\",\n            },\n            pitchDecay: 0.05,\n        });\n    }\n    setNote(note, time) {\n        const seconds = this.toSeconds(time);\n        const hertz = this.toFrequency(note instanceof _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__.FrequencyClass ? note.toFrequency() : note);\n        const maxNote = hertz * this.octaves;\n        this.oscillator.frequency.setValueAtTime(maxNote, seconds);\n        this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_6__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_5__.range)(0)\n], MembraneSynth.prototype, \"octaves\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_6__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_5__.timeRange)(0)\n], MembraneSynth.prototype, \"pitchDecay\", void 0);\n//# sourceMappingURL=MembraneSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/MembraneSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/MetalSynth.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/MetalSynth.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MetalSynth\": () => (/* binding */ MetalSynth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _source_oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../source/oscillator/FMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FMOscillator.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Inharmonic ratio of frequencies based on the Roland TR-808\n * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model\n */\nconst inharmRatios = [1.0, 1.483, 1.932, 2.546, 2.630, 3.897];\n/**\n * A highly inharmonic and spectrally complex source with a highpass filter\n * and amplitude envelope which is good for making metallophone sounds.\n * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).\n * Inspiration from [Sound on Sound](https://shorturl.at/rSZ12).\n * @category Instrument\n */\nclass MetalSynth extends _Monophonic__WEBPACK_IMPORTED_MODULE_10__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(MetalSynth.getDefaults(), arguments));\n        this.name = \"MetalSynth\";\n        /**\n         * The array of FMOscillators\n         */\n        this._oscillators = [];\n        /**\n         * The frequency multipliers\n         */\n        this._freqMultipliers = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.optionsFromArguments)(MetalSynth.getDefaults(), arguments);\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_8__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_8__.Signal({\n            context: this.context,\n            units: \"frequency\",\n        });\n        this._amplitude = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({\n            context: this.context,\n            gain: 0,\n        }).connect(this.output);\n        this._highpass = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_1__.Filter({\n            // Q: -3.0102999566398125,\n            Q: 0,\n            context: this.context,\n            type: \"highpass\",\n        }).connect(this._amplitude);\n        for (let i = 0; i < inharmRatios.length; i++) {\n            const osc = new _source_oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_9__.FMOscillator({\n                context: this.context,\n                harmonicity: options.harmonicity,\n                modulationIndex: options.modulationIndex,\n                modulationType: \"square\",\n                onstop: i === 0 ? () => this.onsilence(this) : _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n                type: \"square\",\n            });\n            osc.connect(this._highpass);\n            this._oscillators[i] = osc;\n            const mult = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_6__.Multiply({\n                context: this.context,\n                value: inharmRatios[i],\n            });\n            this._freqMultipliers[i] = mult;\n            this.frequency.chain(mult, osc.frequency);\n            this.detune.connect(osc.detune);\n        }\n        this._filterFreqScaler = new _signal_Scale__WEBPACK_IMPORTED_MODULE_7__.Scale({\n            context: this.context,\n            max: 7000,\n            min: this.toFrequency(options.resonance),\n        });\n        this.envelope = new _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_0__.Envelope({\n            attack: options.envelope.attack,\n            attackCurve: \"linear\",\n            context: this.context,\n            decay: options.envelope.decay,\n            release: options.envelope.release,\n            sustain: 0,\n        });\n        this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);\n        this.envelope.connect(this._amplitude.gain);\n        // set the octaves\n        this._octaves = options.octaves;\n        this.octaves = options.octaves;\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.deepMerge)(_Monophonic__WEBPACK_IMPORTED_MODULE_10__.Monophonic.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_0__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults())), {\n                attack: 0.001,\n                decay: 1.4,\n                release: 0.2,\n            }),\n            harmonicity: 5.1,\n            modulationIndex: 32,\n            octaves: 1.5,\n            resonance: 4000,\n        });\n    }\n    /**\n     * Trigger the attack.\n     * @param time When the attack should be triggered.\n     * @param velocity The velocity that the envelope should be triggered at.\n     */\n    _triggerEnvelopeAttack(time, velocity = 1) {\n        this.envelope.triggerAttack(time, velocity);\n        this._oscillators.forEach(osc => osc.start(time));\n        if (this.envelope.sustain === 0) {\n            this._oscillators.forEach(osc => {\n                osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));\n            });\n        }\n        return this;\n    }\n    /**\n     * Trigger the release of the envelope.\n     * @param time When the release should be triggered.\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this._oscillators.forEach(osc => osc.stop(time + this.toSeconds(this.envelope.release)));\n        return this;\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    /**\n     * The modulationIndex of the oscillators which make up the source.\n     * see [[FMOscillator.modulationIndex]]\n     * @min 1\n     * @max 100\n     */\n    get modulationIndex() {\n        return this._oscillators[0].modulationIndex.value;\n    }\n    set modulationIndex(val) {\n        this._oscillators.forEach(osc => (osc.modulationIndex.value = val));\n    }\n    /**\n     * The harmonicity of the oscillators which make up the source.\n     * see Tone.FMOscillator.harmonicity\n     * @min 0.1\n     * @max 10\n     */\n    get harmonicity() {\n        return this._oscillators[0].harmonicity.value;\n    }\n    set harmonicity(val) {\n        this._oscillators.forEach(osc => (osc.harmonicity.value = val));\n    }\n    /**\n     * The lower level of the highpass filter which is attached to the envelope.\n     * This value should be between [0, 7000]\n     * @min 0\n     * @max 7000\n     */\n    get resonance() {\n        return this._filterFreqScaler.min;\n    }\n    set resonance(val) {\n        this._filterFreqScaler.min = this.toFrequency(val);\n        this.octaves = this._octaves;\n    }\n    /**\n     * The number of octaves above the \"resonance\" frequency\n     * that the filter ramps during the attack/decay envelope\n     * @min 0\n     * @max 8\n     */\n    get octaves() {\n        return this._octaves;\n    }\n    set octaves(val) {\n        this._octaves = val;\n        this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);\n    }\n    dispose() {\n        super.dispose();\n        this._oscillators.forEach(osc => osc.dispose());\n        this._freqMultipliers.forEach(freqMult => freqMult.dispose());\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._filterFreqScaler.dispose();\n        this._amplitude.dispose();\n        this.envelope.dispose();\n        this._highpass.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MetalSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/MetalSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/ModulationSynth.js":
/*!*******************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/ModulationSynth.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ModulationSynth\": () => (/* binding */ ModulationSynth)\n/* harmony export */ });\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Base class for both AM and FM synths\n */\nclass ModulationSynth extends _Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.optionsFromArguments)(ModulationSynth.getDefaults(), arguments));\n        this.name = \"ModulationSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.optionsFromArguments)(ModulationSynth.getDefaults(), arguments);\n        this._carrier = new _Synth__WEBPACK_IMPORTED_MODULE_8__.Synth({\n            context: this.context,\n            oscillator: options.oscillator,\n            envelope: options.envelope,\n            onsilence: () => this.onsilence(this),\n            volume: -10,\n        });\n        this._modulator = new _Synth__WEBPACK_IMPORTED_MODULE_8__.Synth({\n            context: this.context,\n            oscillator: options.modulation,\n            envelope: options.modulationEnvelope,\n            volume: -10,\n        });\n        this.oscillator = this._carrier.oscillator;\n        this.envelope = this._carrier.envelope;\n        this.modulation = this._modulator.oscillator;\n        this.modulationEnvelope = this._modulator.envelope;\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal({\n            context: this.context,\n            units: \"frequency\",\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal({\n            context: this.context,\n            value: options.detune,\n            units: \"cents\"\n        });\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_1__.Multiply({\n            context: this.context,\n            value: options.harmonicity,\n            minValue: 0,\n        });\n        this._modulationNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_2__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_9__.readOnly)(this, [\"frequency\", \"harmonicity\", \"oscillator\", \"envelope\", \"modulation\", \"modulationEnvelope\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic.getDefaults(), {\n            harmonicity: 3,\n            oscillator: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator.getDefaults(), [\n                ...Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_7__.Source.getDefaults()),\n                \"frequency\",\n                \"detune\"\n            ]), {\n                type: \"sine\"\n            }),\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_3__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults())), {\n                attack: 0.01,\n                decay: 0.01,\n                sustain: 1,\n                release: 0.5\n            }),\n            modulation: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator.getDefaults(), [\n                ...Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_7__.Source.getDefaults()),\n                \"frequency\",\n                \"detune\"\n            ]), {\n                type: \"square\"\n            }),\n            modulationEnvelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_10__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_3__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults())), {\n                attack: 0.5,\n                decay: 0.0,\n                sustain: 1,\n                release: 0.5\n            })\n        });\n    }\n    /**\n     * Trigger the attack portion of the note\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // @ts-ignore\n        this._carrier._triggerEnvelopeAttack(time, velocity);\n        // @ts-ignore\n        this._modulator._triggerEnvelopeAttack(time, velocity);\n    }\n    /**\n     * Trigger the release portion of the note\n     */\n    _triggerEnvelopeRelease(time) {\n        // @ts-ignore\n        this._carrier._triggerEnvelopeRelease(time);\n        // @ts-ignore\n        this._modulator._triggerEnvelopeRelease(time);\n        return this;\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    dispose() {\n        super.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this.harmonicity.dispose();\n        this._modulationNode.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ModulationSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/ModulationSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/MonoSynth.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/MonoSynth.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MonoSynth\": () => (/* binding */ MonoSynth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _component_filter_Filter__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../component/filter/Filter */ \"./node_modules/tone/build/esm/component/filter/Filter.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _instrument_Monophonic__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../instrument/Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n/* harmony import */ var _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _component_envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../component/envelope/FrequencyEnvelope */ \"./node_modules/tone/build/esm/component/envelope/FrequencyEnvelope.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.\n * The amplitude of the Oscillator and the cutoff frequency of the\n * Filter are controlled by Envelopes.\n * <img src=\"https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240\">\n * @example\n * const synth = new Tone.MonoSynth({\n * \toscillator: {\n * \t\ttype: \"square\"\n * \t},\n * \tenvelope: {\n * \t\tattack: 0.1\n * \t}\n * }).toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nclass MonoSynth extends _instrument_Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(MonoSynth.getDefaults(), arguments));\n        this.name = \"MonoSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(MonoSynth.getDefaults(), arguments);\n        this.oscillator = new _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator(Object.assign(options.oscillator, {\n            context: this.context,\n            detune: options.detune,\n            onstop: () => this.onsilence(this),\n        }));\n        this.frequency = this.oscillator.frequency;\n        this.detune = this.oscillator.detune;\n        this.filter = new _component_filter_Filter__WEBPACK_IMPORTED_MODULE_2__.Filter(Object.assign(options.filter, { context: this.context }));\n        this.filterEnvelope = new _component_envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_8__.FrequencyEnvelope(Object.assign(options.filterEnvelope, { context: this.context }));\n        this.envelope = new _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__.AmplitudeEnvelope(Object.assign(options.envelope, { context: this.context }));\n        // connect the oscillators to the output\n        this.oscillator.chain(this.filter, this.envelope, this.output);\n        // connect the filter envelope\n        this.filterEnvelope.connect(this.filter.frequency);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"oscillator\", \"frequency\", \"detune\", \"filter\", \"filterEnvelope\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_instrument_Monophonic__WEBPACK_IMPORTED_MODULE_5__.Monophonic.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__.ToneAudioNode.getDefaults())), {\n                attack: 0.005,\n                decay: 0.1,\n                release: 1,\n                sustain: 0.9,\n            }),\n            filter: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_filter_Filter__WEBPACK_IMPORTED_MODULE_2__.Filter.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__.ToneAudioNode.getDefaults())), {\n                Q: 1,\n                rolloff: -12,\n                type: \"lowpass\",\n            }),\n            filterEnvelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_envelope_FrequencyEnvelope__WEBPACK_IMPORTED_MODULE_8__.FrequencyEnvelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_9__.ToneAudioNode.getDefaults())), {\n                attack: 0.6,\n                baseFrequency: 200,\n                decay: 0.2,\n                exponent: 2,\n                octaves: 3,\n                release: 2,\n                sustain: 0.5,\n            }),\n            oscillator: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_6__.OmniOscillator.getDefaults(), Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_7__.Source.getDefaults())), {\n                type: \"sawtooth\",\n            }),\n        });\n    }\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    _triggerEnvelopeAttack(time, velocity = 1) {\n        this.envelope.triggerAttack(time, velocity);\n        this.filterEnvelope.triggerAttack(time);\n        this.oscillator.start(time);\n        if (this.envelope.sustain === 0) {\n            const computedAttack = this.toSeconds(this.envelope.attack);\n            const computedDecay = this.toSeconds(this.envelope.decay);\n            this.oscillator.stop(time + computedAttack + computedDecay);\n        }\n    }\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this.filterEnvelope.triggerRelease(time);\n        this.oscillator.stop(time + this.toSeconds(this.envelope.release));\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    dispose() {\n        super.dispose();\n        this.oscillator.dispose();\n        this.envelope.dispose();\n        this.filterEnvelope.dispose();\n        this.filter.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=MonoSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/MonoSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Monophonic.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Monophonic.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Monophonic\": () => (/* binding */ Monophonic)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _instrument_Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n/**\n * Abstract base class for other monophonic instruments to extend.\n */\nclass Monophonic extends _instrument_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Monophonic.getDefaults(), arguments));\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Monophonic.getDefaults(), arguments);\n        this.portamento = options.portamento;\n        this.onsilence = options.onsilence;\n    }\n    static getDefaults() {\n        return Object.assign(_instrument_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            detune: 0,\n            onsilence: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            portamento: 0,\n        });\n    }\n    /**\n     * Trigger the attack of the note optionally with a given velocity.\n     * @param  note The note to trigger.\n     * @param  time When the note should start.\n     * @param  velocity The velocity scaler determines how \"loud\" the note will be triggered.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * // trigger the note a half second from now at half velocity\n     * synth.triggerAttack(\"C4\", \"+0.5\", 0.5);\n     */\n    triggerAttack(note, time, velocity = 1) {\n        this.log(\"triggerAttack\", note, time, velocity);\n        const seconds = this.toSeconds(time);\n        this._triggerEnvelopeAttack(seconds, velocity);\n        this.setNote(note, seconds);\n        return this;\n    }\n    /**\n     * Trigger the release portion of the envelope\n     * @param  time If no time is given, the release happens immediatly\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // trigger the release a second from now\n     * synth.triggerRelease(\"+1\");\n     */\n    triggerRelease(time) {\n        this.log(\"triggerRelease\", time);\n        const seconds = this.toSeconds(time);\n        this._triggerEnvelopeRelease(seconds);\n        return this;\n    }\n    /**\n     * Set the note at the given time. If no time is given, the note\n     * will set immediately.\n     * @param note The note to change to.\n     * @param  time The time when the note should be set.\n     * @example\n     * const synth = new Tone.Synth().toDestination();\n     * synth.triggerAttack(\"C4\");\n     * // change to F#6 in one quarter note from now.\n     * synth.setNote(\"F#6\", \"+4n\");\n     */\n    setNote(note, time) {\n        const computedTime = this.toSeconds(time);\n        const computedFrequency = note instanceof _core_type_Frequency__WEBPACK_IMPORTED_MODULE_0__.FrequencyClass ? note.toFrequency() : note;\n        if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {\n            const portTime = this.toSeconds(this.portamento);\n            this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);\n        }\n        else {\n            this.frequency.setValueAtTime(computedFrequency, computedTime);\n        }\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_5__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_4__.timeRange)(0)\n], Monophonic.prototype, \"portamento\", void 0);\n//# sourceMappingURL=Monophonic.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/Monophonic.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/NoiseSynth.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/NoiseSynth.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"NoiseSynth\": () => (/* binding */ NoiseSynth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_Noise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n\n\n\n\n\n\n\n/**\n * Tone.NoiseSynth is composed of [[Noise]] through an [[AmplitudeEnvelope]].\n * ```\n * +-------+   +-------------------+\n * | Noise +>--> AmplitudeEnvelope +>--> Output\n * +-------+   +-------------------+\n * ```\n * @example\n * const noiseSynth = new Tone.NoiseSynth().toDestination();\n * noiseSynth.triggerAttackRelease(\"8n\", 0.05);\n * @category Instrument\n */\nclass NoiseSynth extends _Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(NoiseSynth.getDefaults(), arguments));\n        this.name = \"NoiseSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(NoiseSynth.getDefaults(), arguments);\n        this.noise = new _source_Noise__WEBPACK_IMPORTED_MODULE_2__.Noise(Object.assign({\n            context: this.context,\n        }, options.noise));\n        this.envelope = new _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__.AmplitudeEnvelope(Object.assign({\n            context: this.context,\n        }, options.envelope));\n        // connect the noise to the output\n        this.noise.chain(this.envelope, this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_5__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_4__.ToneAudioNode.getDefaults())), {\n                decay: 0.1,\n                sustain: 0.0,\n            }),\n            noise: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(_source_Noise__WEBPACK_IMPORTED_MODULE_2__.Noise.getDefaults(), Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_6__.Source.getDefaults())), {\n                type: \"white\",\n            }),\n        });\n    }\n    /**\n     * Start the attack portion of the envelopes. Unlike other\n     * instruments, Tone.NoiseSynth doesn't have a note.\n     * @example\n     * const noiseSynth = new Tone.NoiseSynth().toDestination();\n     * noiseSynth.triggerAttack();\n     */\n    triggerAttack(time, velocity = 1) {\n        time = this.toSeconds(time);\n        // the envelopes\n        this.envelope.triggerAttack(time, velocity);\n        // start the noise\n        this.noise.start(time);\n        if (this.envelope.sustain === 0) {\n            this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));\n        }\n        return this;\n    }\n    /**\n     * Start the release portion of the envelopes.\n     */\n    triggerRelease(time) {\n        time = this.toSeconds(time);\n        this.envelope.triggerRelease(time);\n        this.noise.stop(time + this.toSeconds(this.envelope.release));\n        return this;\n    }\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 0);\n            this._syncMethod(\"triggerRelease\", 0);\n        }\n        return this;\n    }\n    triggerAttackRelease(duration, time, velocity = 1) {\n        time = this.toSeconds(time);\n        duration = this.toSeconds(duration);\n        this.triggerAttack(time, velocity);\n        this.triggerRelease(time + duration);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.noise.dispose();\n        this.envelope.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=NoiseSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/NoiseSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/PluckSynth.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/PluckSynth.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PluckSynth\": () => (/* binding */ PluckSynth)\n/* harmony export */ });\n/* harmony import */ var _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/filter/LowpassCombFilter */ \"./node_modules/tone/build/esm/component/filter/LowpassCombFilter.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_Noise__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../source/Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n\n\n\n\n\n/**\n * Karplus-String string synthesis.\n * @example\n * const plucky = new Tone.PluckSynth().toDestination();\n * plucky.triggerAttack(\"C4\", \"+0.5\");\n * plucky.triggerAttack(\"C3\", \"+1\");\n * plucky.triggerAttack(\"C2\", \"+1.5\");\n * plucky.triggerAttack(\"C1\", \"+2\");\n * @category Instrument\n */\nclass PluckSynth extends _Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PluckSynth.getDefaults(), arguments));\n        this.name = \"PluckSynth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PluckSynth.getDefaults(), arguments);\n        this._noise = new _source_Noise__WEBPACK_IMPORTED_MODULE_2__.Noise({\n            context: this.context,\n            type: \"pink\"\n        });\n        this.attackNoise = options.attackNoise;\n        this._lfcf = new _component_filter_LowpassCombFilter__WEBPACK_IMPORTED_MODULE_0__.LowpassCombFilter({\n            context: this.context,\n            dampening: options.dampening,\n            resonance: options.resonance,\n        });\n        this.resonance = options.resonance;\n        this.release = options.release;\n        this._noise.connect(this._lfcf);\n        this._lfcf.connect(this.output);\n    }\n    static getDefaults() {\n        return (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.deepMerge)(_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            attackNoise: 1,\n            dampening: 4000,\n            resonance: 0.7,\n            release: 1,\n        });\n    }\n    /**\n     * The dampening control. i.e. the lowpass filter frequency of the comb filter\n     * @min 0\n     * @max 7000\n     */\n    get dampening() {\n        return this._lfcf.dampening;\n    }\n    set dampening(fq) {\n        this._lfcf.dampening = fq;\n    }\n    triggerAttack(note, time) {\n        const freq = this.toFrequency(note);\n        time = this.toSeconds(time);\n        const delayAmount = 1 / freq;\n        this._lfcf.delayTime.setValueAtTime(delayAmount, time);\n        this._noise.start(time);\n        this._noise.stop(time + delayAmount * this.attackNoise);\n        this._lfcf.resonance.cancelScheduledValues(time);\n        this._lfcf.resonance.setValueAtTime(this.resonance, time);\n        return this;\n    }\n    /**\n     * Ramp down the [[resonance]] to 0 over the duration of the release time.\n     */\n    triggerRelease(time) {\n        this._lfcf.resonance.linearRampTo(0, this.release, time);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._noise.dispose();\n        this._lfcf.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PluckSynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/PluckSynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/PolySynth.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/PolySynth.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PolySynth\": () => (/* binding */ PolySynth)\n/* harmony export */ });\n/* harmony import */ var _core_type_Midi__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/type/Midi */ \"./node_modules/tone/build/esm/core/type/Midi.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Instrument__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n/**\n * PolySynth handles voice creation and allocation for any\n * instruments passed in as the second paramter. PolySynth is\n * not a synthesizer by itself, it merely manages voices of\n * one of the other types of synths, allowing any of the\n * monophonic synthesizers to be polyphonic.\n *\n * @example\n * const synth = new Tone.PolySynth().toDestination();\n * // set the attributes across all the voices using 'set'\n * synth.set({ detune: -1200 });\n * // play a chord\n * synth.triggerAttackRelease([\"C4\", \"E4\", \"A4\"], 1);\n * @category Instrument\n */\nclass PolySynth extends _Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PolySynth.getDefaults(), arguments, [\"voice\", \"options\"]));\n        this.name = \"PolySynth\";\n        /**\n         * The voices which are not currently in use\n         */\n        this._availableVoices = [];\n        /**\n         * The currently active voices\n         */\n        this._activeVoices = [];\n        /**\n         * All of the allocated voices for this synth.\n         */\n        this._voices = [];\n        /**\n         * The GC timeout. Held so that it could be cancelled when the node is disposed.\n         */\n        this._gcTimeout = -1;\n        /**\n         * A moving average of the number of active voices\n         */\n        this._averageActiveVoices = 0;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PolySynth.getDefaults(), arguments, [\"voice\", \"options\"]);\n        // check against the old API (pre 14.3.0)\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(!(0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isNumber)(options.voice), \"DEPRECATED: The polyphony count is no longer the first argument.\");\n        const defaults = options.voice.getDefaults();\n        this.options = Object.assign(defaults, options.options);\n        this.voice = options.voice;\n        this.maxPolyphony = options.maxPolyphony;\n        // create the first voice\n        this._dummyVoice = this._getNextAvailableVoice();\n        // remove it from the voices list\n        const index = this._voices.indexOf(this._dummyVoice);\n        this._voices.splice(index, 1);\n        // kick off the GC interval\n        this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);\n    }\n    static getDefaults() {\n        return Object.assign(_Instrument__WEBPACK_IMPORTED_MODULE_3__.Instrument.getDefaults(), {\n            maxPolyphony: 32,\n            options: {},\n            voice: _Synth__WEBPACK_IMPORTED_MODULE_4__.Synth,\n        });\n    }\n    /**\n     * The number of active voices.\n     */\n    get activeVoices() {\n        return this._activeVoices.length;\n    }\n    /**\n     * Invoked when the source is done making sound, so that it can be\n     * readded to the pool of available voices\n     */\n    _makeVoiceAvailable(voice) {\n        this._availableVoices.push(voice);\n        // remove the midi note from 'active voices'\n        const activeVoiceIndex = this._activeVoices.findIndex((e) => e.voice === voice);\n        this._activeVoices.splice(activeVoiceIndex, 1);\n    }\n    /**\n     * Get an available voice from the pool of available voices.\n     * If one is not available and the maxPolyphony limit is reached,\n     * steal a voice, otherwise return null.\n     */\n    _getNextAvailableVoice() {\n        // if there are available voices, return the first one\n        if (this._availableVoices.length) {\n            return this._availableVoices.shift();\n        }\n        else if (this._voices.length < this.maxPolyphony) {\n            // otherwise if there is still more maxPolyphony, make a new voice\n            const voice = new this.voice(Object.assign(this.options, {\n                context: this.context,\n                onsilence: this._makeVoiceAvailable.bind(this),\n            }));\n            voice.connect(this.output);\n            this._voices.push(voice);\n            return voice;\n        }\n        else {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.warn)(\"Max polyphony exceeded. Note dropped.\");\n        }\n    }\n    /**\n     * Occasionally check if there are any allocated voices which can be cleaned up.\n     */\n    _collectGarbage() {\n        this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);\n        if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {\n            // take off an available note\n            const firstAvail = this._availableVoices.shift();\n            const index = this._voices.indexOf(firstAvail);\n            this._voices.splice(index, 1);\n            if (!this.context.isOffline) {\n                firstAvail.dispose();\n            }\n        }\n    }\n    /**\n     * Internal method which triggers the attack\n     */\n    _triggerAttack(notes, time, velocity) {\n        notes.forEach(note => {\n            const midiNote = new _core_type_Midi__WEBPACK_IMPORTED_MODULE_0__.MidiClass(this.context, note).toMidi();\n            const voice = this._getNextAvailableVoice();\n            if (voice) {\n                voice.triggerAttack(note, time, velocity);\n                this._activeVoices.push({\n                    midi: midiNote, voice, released: false,\n                });\n                this.log(\"triggerAttack\", note, time);\n            }\n        });\n    }\n    /**\n     * Internal method which triggers the release\n     */\n    _triggerRelease(notes, time) {\n        notes.forEach(note => {\n            const midiNote = new _core_type_Midi__WEBPACK_IMPORTED_MODULE_0__.MidiClass(this.context, note).toMidi();\n            const event = this._activeVoices.find(({ midi, released }) => midi === midiNote && !released);\n            if (event) {\n                // trigger release on that note\n                event.voice.triggerRelease(time);\n                // mark it as released\n                event.released = true;\n                this.log(\"triggerRelease\", note, time);\n            }\n        });\n    }\n    /**\n     * Schedule the attack/release events. If the time is in the future, then it should set a timeout\n     * to wait for just-in-time scheduling\n     */\n    _scheduleEvent(type, notes, time, velocity) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(!this.disposed, \"Synth was already disposed\");\n        // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout\n        if (time <= this.now()) {\n            // do it immediately\n            if (type === \"attack\") {\n                this._triggerAttack(notes, time, velocity);\n            }\n            else {\n                this._triggerRelease(notes, time);\n            }\n        }\n        else {\n            // schedule it to start in the future\n            this.context.setTimeout(() => {\n                this._scheduleEvent(type, notes, time, velocity);\n            }, time - this.now());\n        }\n    }\n    /**\n     * Trigger the attack portion of the note\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  The start time of the note.\n     * @param velocity The velocity of the note.\n     * @example\n     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();\n     * // trigger a chord immediately with a velocity of 0.2\n     * synth.triggerAttack([\"Ab3\", \"C4\", \"F5\"], Tone.now(), 0.2);\n     */\n    triggerAttack(notes, time, velocity) {\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        const computedTime = this.toSeconds(time);\n        this._scheduleEvent(\"attack\", notes, computedTime, velocity);\n        return this;\n    }\n    /**\n     * Trigger the release of the note. Unlike monophonic instruments,\n     * a note (or array of notes) needs to be passed in as the first argument.\n     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.\n     * @param  time  When the release will be triggered.\n     * @example\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * poly.triggerAttack([\"Ab3\", \"C4\", \"F5\"]);\n     * // trigger the release of the given notes.\n     * poly.triggerRelease([\"Ab3\", \"C4\"], \"+1\");\n     * poly.triggerRelease(\"F5\", \"+3\");\n     */\n    triggerRelease(notes, time) {\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        const computedTime = this.toSeconds(time);\n        this._scheduleEvent(\"release\", notes, computedTime);\n        return this;\n    }\n    /**\n     * Trigger the attack and release after the specified duration\n     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.\n     * @param  duration the duration of the note\n     * @param  time  if no time is given, defaults to now\n     * @param  velocity the velocity of the attack (0-1)\n     * @example\n     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();\n     * // can pass in an array of durations as well\n     * poly.triggerAttackRelease([\"Eb3\", \"G4\", \"Bb4\", \"D5\"], [4, 3, 2, 1]);\n     */\n    triggerAttackRelease(notes, duration, time, velocity) {\n        const computedTime = this.toSeconds(time);\n        this.triggerAttack(notes, computedTime, velocity);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(duration)) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isArray)(notes), \"If the duration is an array, the notes must also be an array\");\n            notes = notes;\n            for (let i = 0; i < notes.length; i++) {\n                const d = duration[Math.min(i, duration.length - 1)];\n                const durationSeconds = this.toSeconds(d);\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(durationSeconds > 0, \"The duration must be greater than 0\");\n                this.triggerRelease(notes[i], computedTime + durationSeconds);\n            }\n        }\n        else {\n            const durationSeconds = this.toSeconds(duration);\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_5__.assert)(durationSeconds > 0, \"The duration must be greater than 0\");\n            this.triggerRelease(notes, computedTime + durationSeconds);\n        }\n        return this;\n    }\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 1);\n        }\n        return this;\n    }\n    /**\n     * Set a member/attribute of the voices\n     * @example\n     * const poly = new Tone.PolySynth().toDestination();\n     * // set all of the voices using an options object for the synth type\n     * poly.set({\n     * \tenvelope: {\n     * \t\tattack: 0.25\n     * \t}\n     * });\n     * poly.triggerAttackRelease(\"Bb3\", 0.2);\n     */\n    set(options) {\n        // remove options which are controlled by the PolySynth\n        const sanitizedOptions = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.omitFromObject)(options, [\"onsilence\", \"context\"]);\n        // store all of the options\n        this.options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.deepMerge)(this.options, sanitizedOptions);\n        this._voices.forEach(voice => voice.set(sanitizedOptions));\n        this._dummyVoice.set(sanitizedOptions);\n        return this;\n    }\n    get() {\n        return this._dummyVoice.get();\n    }\n    /**\n     * Trigger the release portion of all the currently active voices immediately.\n     * Useful for silencing the synth.\n     */\n    releaseAll(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeVoices.forEach(({ voice }) => {\n            voice.triggerRelease(computedTime);\n        });\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._dummyVoice.dispose();\n        this._voices.forEach(v => v.dispose());\n        this._activeVoices = [];\n        this._availableVoices = [];\n        this.context.clearInterval(this._gcTimeout);\n        return this;\n    }\n}\n//# sourceMappingURL=PolySynth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/PolySynth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Sampler.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Sampler.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Sampler\": () => (/* binding */ Sampler)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/type/Frequency */ \"./node_modules/tone/build/esm/core/type/Frequency.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _instrument_Instrument__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../instrument/Instrument */ \"./node_modules/tone/build/esm/instrument/Instrument.js\");\n/* harmony import */ var _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../source/buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n\n\n\n/**\n * Pass in an object which maps the note's pitch or midi value to the url,\n * then you can trigger the attack and release of that note like other instruments.\n * By automatically repitching the samples, it is possible to play pitches which\n * were not explicitly included which can save loading time.\n *\n * For sample or buffer playback where repitching is not necessary,\n * use [[Player]].\n * @example\n * const sampler = new Tone.Sampler({\n * \turls: {\n * \t\tA1: \"A1.mp3\",\n * \t\tA2: \"A2.mp3\",\n * \t},\n * \tbaseUrl: \"https://tonejs.github.io/audio/casio/\",\n * \tonload: () => {\n * \t\tsampler.triggerAttackRelease([\"C1\", \"E1\", \"G1\", \"B1\"], 0.5);\n * \t}\n * }).toDestination();\n * @category Instrument\n */\nclass Sampler extends _instrument_Instrument__WEBPACK_IMPORTED_MODULE_6__.Instrument {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Sampler.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\"));\n        this.name = \"Sampler\";\n        /**\n         * The object of all currently playing BufferSources\n         */\n        this._activeSources = new Map();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Sampler.getDefaults(), arguments, [\"urls\", \"onload\", \"baseUrl\"], \"urls\");\n        const urlMap = {};\n        Object.keys(options.urls).forEach((note) => {\n            const noteNumber = parseInt(note, 10);\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_9__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note)\n                || ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(noteNumber) && isFinite(noteNumber)), `url key is neither a note or midi pitch: ${note}`);\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note)) {\n                // convert the note name to MIDI\n                const mid = new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toMidi();\n                urlMap[mid] = options.urls[note];\n            }\n            else if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(noteNumber) && isFinite(noteNumber)) {\n                // otherwise if it's numbers assume it's midi\n                urlMap[noteNumber] = options.urls[noteNumber];\n            }\n        });\n        this._buffers = new _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffers({\n            urls: urlMap,\n            onload: options.onload,\n            baseUrl: options.baseUrl,\n            onerror: options.onerror,\n        });\n        this.attack = options.attack;\n        this.release = options.release;\n        this.curve = options.curve;\n        // invoke the callback if it's already loaded\n        if (this._buffers.loaded) {\n            // invoke onload deferred\n            Promise.resolve().then(options.onload);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(_instrument_Instrument__WEBPACK_IMPORTED_MODULE_6__.Instrument.getDefaults(), {\n            attack: 0,\n            baseUrl: \"\",\n            curve: \"exponential\",\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            release: 0.1,\n            urls: {},\n        });\n    }\n    /**\n     * Returns the difference in steps between the given midi note at the closets sample.\n     */\n    _findClosest(midi) {\n        // searches within 8 octaves of the given midi note\n        const MAX_INTERVAL = 96;\n        let interval = 0;\n        while (interval < MAX_INTERVAL) {\n            // check above and below\n            if (this._buffers.has(midi + interval)) {\n                return -interval;\n            }\n            else if (this._buffers.has(midi - interval)) {\n                return interval;\n            }\n            interval++;\n        }\n        throw new Error(`No available buffers for note: ${midi}`);\n    }\n    /**\n     * @param  notes\tThe note to play, or an array of notes.\n     * @param  time     When to play the note\n     * @param  velocity The velocity to play the sample back.\n     */\n    triggerAttack(notes, time, velocity = 1) {\n        this.log(\"triggerAttack\", notes, time, velocity);\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        notes.forEach(note => {\n            const midiFloat = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__.ftomf)(new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toFrequency());\n            const midi = Math.round(midiFloat);\n            const remainder = midiFloat - midi;\n            // find the closest note pitch\n            const difference = this._findClosest(midi);\n            const closestNote = midi - difference;\n            const buffer = this._buffers.get(closestNote);\n            const playbackRate = (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_1__.intervalToFrequencyRatio)(difference + remainder);\n            // play that note\n            const source = new _source_buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_7__.ToneBufferSource({\n                url: buffer,\n                context: this.context,\n                curve: this.curve,\n                fadeIn: this.attack,\n                fadeOut: this.release,\n                playbackRate,\n            }).connect(this.output);\n            source.start(time, 0, buffer.duration / playbackRate, velocity);\n            // add it to the active sources\n            if (!(0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(this._activeSources.get(midi))) {\n                this._activeSources.set(midi, []);\n            }\n            this._activeSources.get(midi).push(source);\n            // remove it when it's done\n            source.onended = () => {\n                if (this._activeSources && this._activeSources.has(midi)) {\n                    const sources = this._activeSources.get(midi);\n                    const index = sources.indexOf(source);\n                    if (index !== -1) {\n                        sources.splice(index, 1);\n                    }\n                }\n            };\n        });\n        return this;\n    }\n    /**\n     * @param  notes\tThe note to release, or an array of notes.\n     * @param  time     \tWhen to release the note.\n     */\n    triggerRelease(notes, time) {\n        this.log(\"triggerRelease\", notes, time);\n        if (!Array.isArray(notes)) {\n            notes = [notes];\n        }\n        notes.forEach(note => {\n            const midi = new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toMidi();\n            // find the note\n            if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {\n                const sources = this._activeSources.get(midi);\n                time = this.toSeconds(time);\n                sources.forEach(source => {\n                    source.stop(time);\n                });\n                this._activeSources.set(midi, []);\n            }\n        });\n        return this;\n    }\n    /**\n     * Release all currently active notes.\n     * @param  time     \tWhen to release the notes.\n     */\n    releaseAll(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeSources.forEach(sources => {\n            while (sources.length) {\n                const source = sources.shift();\n                source.stop(computedTime);\n            }\n        });\n        return this;\n    }\n    sync() {\n        if (this._syncState()) {\n            this._syncMethod(\"triggerAttack\", 1);\n            this._syncMethod(\"triggerRelease\", 1);\n        }\n        return this;\n    }\n    /**\n     * Invoke the attack phase, then after the duration, invoke the release.\n     * @param  notes\tThe note to play and release, or an array of notes.\n     * @param  duration The time the note should be held\n     * @param  time     When to start the attack\n     * @param  velocity The velocity of the attack\n     */\n    triggerAttackRelease(notes, duration, time, velocity = 1) {\n        const computedTime = this.toSeconds(time);\n        this.triggerAttack(notes, computedTime, velocity);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(duration)) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_9__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isArray)(notes), \"notes must be an array when duration is array\");\n            notes.forEach((note, index) => {\n                const d = duration[Math.min(index, duration.length - 1)];\n                this.triggerRelease(note, computedTime + this.toSeconds(d));\n            });\n        }\n        else {\n            this.triggerRelease(notes, computedTime + this.toSeconds(duration));\n        }\n        return this;\n    }\n    /**\n     * Add a note to the sampler.\n     * @param  note      The buffer's pitch.\n     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.\n     * @param  callback  The callback to invoke when the url is loaded.\n     */\n    add(note, url, callback) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_9__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note) || isFinite(note), `note must be a pitch or midi: ${note}`);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNote)(note)) {\n            // convert the note name to MIDI\n            const mid = new _core_type_Frequency__WEBPACK_IMPORTED_MODULE_2__.FrequencyClass(this.context, note).toMidi();\n            this._buffers.add(mid, url, callback);\n        }\n        else {\n            // otherwise if it's numbers assume it's midi\n            this._buffers.add(note, url, callback);\n        }\n        return this;\n    }\n    /**\n     * If the buffers are loaded or not\n     */\n    get loaded() {\n        return this._buffers.loaded;\n    }\n    /**\n     * Clean up\n     */\n    dispose() {\n        super.dispose();\n        this._buffers.dispose();\n        this._activeSources.forEach(sources => {\n            sources.forEach(source => source.dispose());\n        });\n        this._activeSources.clear();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_10__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_8__.timeRange)(0)\n], Sampler.prototype, \"attack\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_10__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_8__.timeRange)(0)\n], Sampler.prototype, \"release\", void 0);\n//# sourceMappingURL=Sampler.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/Sampler.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/Synth.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/Synth.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Synth\": () => (/* binding */ Synth)\n/* harmony export */ });\n/* harmony import */ var _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/envelope/AmplitudeEnvelope */ \"./node_modules/tone/build/esm/component/envelope/AmplitudeEnvelope.js\");\n/* harmony import */ var _component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/envelope/Envelope */ \"./node_modules/tone/build/esm/component/envelope/Envelope.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../source/oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Monophonic__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Monophonic */ \"./node_modules/tone/build/esm/instrument/Monophonic.js\");\n\n\n\n\n\n\n\n\n/**\n * Synth is composed simply of a [[OmniOscillator]] routed through an [[AmplitudeEnvelope]].\n * ```\n * +----------------+   +-------------------+\n * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output\n * +----------------+   +-------------------+\n * ```\n * @example\n * const synth = new Tone.Synth().toDestination();\n * synth.triggerAttackRelease(\"C4\", \"8n\");\n * @category Instrument\n */\nclass Synth extends _Monophonic__WEBPACK_IMPORTED_MODULE_7__.Monophonic {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Synth.getDefaults(), arguments));\n        this.name = \"Synth\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Synth.getDefaults(), arguments);\n        this.oscillator = new _source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_5__.OmniOscillator(Object.assign({\n            context: this.context,\n            detune: options.detune,\n            onstop: () => this.onsilence(this),\n        }, options.oscillator));\n        this.frequency = this.oscillator.frequency;\n        this.detune = this.oscillator.detune;\n        this.envelope = new _component_envelope_AmplitudeEnvelope__WEBPACK_IMPORTED_MODULE_0__.AmplitudeEnvelope(Object.assign({\n            context: this.context,\n        }, options.envelope));\n        // connect the oscillators to the output\n        this.oscillator.chain(this.envelope, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"oscillator\", \"frequency\", \"detune\", \"envelope\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Monophonic__WEBPACK_IMPORTED_MODULE_7__.Monophonic.getDefaults(), {\n            envelope: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_component_envelope_Envelope__WEBPACK_IMPORTED_MODULE_1__.Envelope.getDefaults(), Object.keys(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode.getDefaults())), {\n                attack: 0.005,\n                decay: 0.1,\n                release: 1,\n                sustain: 0.3,\n            }),\n            oscillator: Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.omitFromObject)(_source_oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_5__.OmniOscillator.getDefaults(), [...Object.keys(_source_Source__WEBPACK_IMPORTED_MODULE_6__.Source.getDefaults()), \"frequency\", \"detune\"]), {\n                type: \"triangle\",\n            }),\n        });\n    }\n    /**\n     * start the attack portion of the envelope\n     * @param time the time the attack should start\n     * @param velocity the velocity of the note (0-1)\n     */\n    _triggerEnvelopeAttack(time, velocity) {\n        // the envelopes\n        this.envelope.triggerAttack(time, velocity);\n        this.oscillator.start(time);\n        // if there is no release portion, stop the oscillator\n        if (this.envelope.sustain === 0) {\n            const computedAttack = this.toSeconds(this.envelope.attack);\n            const computedDecay = this.toSeconds(this.envelope.decay);\n            this.oscillator.stop(time + computedAttack + computedDecay);\n        }\n    }\n    /**\n     * start the release portion of the envelope\n     * @param time the time the release should start\n     */\n    _triggerEnvelopeRelease(time) {\n        this.envelope.triggerRelease(time);\n        this.oscillator.stop(time + this.toSeconds(this.envelope.release));\n    }\n    getLevelAtTime(time) {\n        time = this.toSeconds(time);\n        return this.envelope.getValueAtTime(time);\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this.oscillator.dispose();\n        this.envelope.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Synth.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/Synth.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/instrument/index.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/instrument/index.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMSynth\": () => (/* reexport safe */ _AMSynth__WEBPACK_IMPORTED_MODULE_0__.AMSynth),\n/* harmony export */   \"DuoSynth\": () => (/* reexport safe */ _DuoSynth__WEBPACK_IMPORTED_MODULE_1__.DuoSynth),\n/* harmony export */   \"FMSynth\": () => (/* reexport safe */ _FMSynth__WEBPACK_IMPORTED_MODULE_2__.FMSynth),\n/* harmony export */   \"MembraneSynth\": () => (/* reexport safe */ _MembraneSynth__WEBPACK_IMPORTED_MODULE_4__.MembraneSynth),\n/* harmony export */   \"MetalSynth\": () => (/* reexport safe */ _MetalSynth__WEBPACK_IMPORTED_MODULE_3__.MetalSynth),\n/* harmony export */   \"MonoSynth\": () => (/* reexport safe */ _MonoSynth__WEBPACK_IMPORTED_MODULE_5__.MonoSynth),\n/* harmony export */   \"NoiseSynth\": () => (/* reexport safe */ _NoiseSynth__WEBPACK_IMPORTED_MODULE_6__.NoiseSynth),\n/* harmony export */   \"PluckSynth\": () => (/* reexport safe */ _PluckSynth__WEBPACK_IMPORTED_MODULE_7__.PluckSynth),\n/* harmony export */   \"PolySynth\": () => (/* reexport safe */ _PolySynth__WEBPACK_IMPORTED_MODULE_8__.PolySynth),\n/* harmony export */   \"Sampler\": () => (/* reexport safe */ _Sampler__WEBPACK_IMPORTED_MODULE_9__.Sampler),\n/* harmony export */   \"Synth\": () => (/* reexport safe */ _Synth__WEBPACK_IMPORTED_MODULE_10__.Synth)\n/* harmony export */ });\n/* harmony import */ var _AMSynth__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AMSynth */ \"./node_modules/tone/build/esm/instrument/AMSynth.js\");\n/* harmony import */ var _DuoSynth__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./DuoSynth */ \"./node_modules/tone/build/esm/instrument/DuoSynth.js\");\n/* harmony import */ var _FMSynth__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./FMSynth */ \"./node_modules/tone/build/esm/instrument/FMSynth.js\");\n/* harmony import */ var _MetalSynth__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./MetalSynth */ \"./node_modules/tone/build/esm/instrument/MetalSynth.js\");\n/* harmony import */ var _MembraneSynth__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./MembraneSynth */ \"./node_modules/tone/build/esm/instrument/MembraneSynth.js\");\n/* harmony import */ var _MonoSynth__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./MonoSynth */ \"./node_modules/tone/build/esm/instrument/MonoSynth.js\");\n/* harmony import */ var _NoiseSynth__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./NoiseSynth */ \"./node_modules/tone/build/esm/instrument/NoiseSynth.js\");\n/* harmony import */ var _PluckSynth__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./PluckSynth */ \"./node_modules/tone/build/esm/instrument/PluckSynth.js\");\n/* harmony import */ var _PolySynth__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./PolySynth */ \"./node_modules/tone/build/esm/instrument/PolySynth.js\");\n/* harmony import */ var _Sampler__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Sampler */ \"./node_modules/tone/build/esm/instrument/Sampler.js\");\n/* harmony import */ var _Synth__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Synth */ \"./node_modules/tone/build/esm/instrument/Synth.js\");\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/instrument/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Abs.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Abs.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Abs\": () => (/* binding */ Abs)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n/**\n * Return the absolute value of an incoming signal.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst abs = new Tone.Abs().toDestination();\n * \tconst signal = new Tone.Signal(1);\n * \tsignal.rampTo(-1, 0.5);\n * \tsignal.connect(abs);\n * }, 0.5, 1);\n * @category Signal\n */\nclass Abs extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"Abs\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._abs = new _WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            mapping: val => {\n                if (Math.abs(val) < 0.001) {\n                    return 0;\n                }\n                else {\n                    return Math.abs(val);\n                }\n            },\n        });\n        /**\n         * The AudioRange input [-1, 1]\n         */\n        this.input = this._abs;\n        /**\n         * The output range [0, 1]\n         */\n        this.output = this._abs;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._abs.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Abs.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Abs.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Add.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Add.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Add\": () => (/* binding */ Add)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n\n/**\n * Add a signal and a number or two signals. When no value is\n * passed into the constructor, Tone.Add will sum input and `addend`\n * If a value is passed into the constructor, the it will be added to the input.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst add = new Tone.Add(2).toDestination();\n * \tadd.addend.setValueAtTime(1, 0.2);\n * \tconst signal = new Tone.Signal(2);\n * \t// add a signal and a scalar\n * \tsignal.connect(add);\n * \tsignal.setValueAtTime(1, 0.1);\n * }, 0.5, 1);\n * @category Signal\n */\nclass Add extends _Signal__WEBPACK_IMPORTED_MODULE_3__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Add.getDefaults(), arguments, [\"value\"])));\n        this.override = false;\n        this.name = \"Add\";\n        /**\n         * the summing node\n         */\n        this._sum = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        this.input = this._sum;\n        this.output = this._sum;\n        /**\n         * The value which is added to the input signal\n         */\n        this.addend = this._param;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(this._constantSource, this._sum);\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._sum.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Add.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Add.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/AudioToGain.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/AudioToGain.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AudioToGain\": () => (/* binding */ AudioToGain)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n/**\n * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].\n * See [[GainToAudio]].\n * @category Signal\n */\nclass AudioToGain extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"AudioToGain\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._norm = new _WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            mapping: x => (x + 1) / 2,\n        });\n        /**\n         * The AudioRange input [-1, 1]\n         */\n        this.input = this._norm;\n        /**\n         * The GainRange output [0, 1]\n         */\n        this.output = this._norm;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._norm.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AudioToGain.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/AudioToGain.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/GainToAudio.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/GainToAudio.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GainToAudio\": () => (/* binding */ GainToAudio)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n\n\n/**\n * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].\n * See [[AudioToGain]].\n * @category Signal\n */\nclass GainToAudio extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"GainToAudio\";\n        /**\n         * The node which converts the audio ranges\n         */\n        this._norm = new _WaveShaper__WEBPACK_IMPORTED_MODULE_1__.WaveShaper({\n            context: this.context,\n            mapping: x => Math.abs(x) * 2 - 1,\n        });\n        /**\n         * The NormalRange input [0, 1]\n         */\n        this.input = this._norm;\n        /**\n         * The AudioRange output [-1, 1]\n         */\n        this.output = this._norm;\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        this._norm.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GainToAudio.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/GainToAudio.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/GreaterThan.js":
/*!***********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/GreaterThan.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GreaterThan\": () => (/* binding */ GreaterThan)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Subtract__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _GreaterThanZero__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./GreaterThanZero */ \"./node_modules/tone/build/esm/signal/GreaterThanZero.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Output 1 if the signal is greater than the value, otherwise outputs 0.\n * can compare two signals or a signal and a number.\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst gt = new Tone.GreaterThan(2).toDestination();\n * \tconst sig = new Tone.Signal(4).connect(gt);\n * }, 0.1, 1);\n * @category Signal\n */\nclass GreaterThan extends _Signal__WEBPACK_IMPORTED_MODULE_2__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(GreaterThan.getDefaults(), arguments, [\"value\"])));\n        this.name = \"GreaterThan\";\n        this.override = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(GreaterThan.getDefaults(), arguments, [\"value\"]);\n        this._subtract = this.input = new _Subtract__WEBPACK_IMPORTED_MODULE_1__.Subtract({\n            context: this.context,\n            value: options.value\n        });\n        this._gtz = this.output = new _GreaterThanZero__WEBPACK_IMPORTED_MODULE_3__.GreaterThanZero({ context: this.context });\n        this.comparator = this._param = this._subtract.subtrahend;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, \"comparator\");\n        // connect\n        this._subtract.connect(this._gtz);\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._gtz.dispose();\n        this._subtract.dispose();\n        this.comparator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GreaterThan.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/GreaterThan.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/GreaterThanZero.js":
/*!***************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/GreaterThanZero.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GreaterThanZero\": () => (/* binding */ GreaterThanZero)\n/* harmony export */ });\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n\n\n\n\n/**\n * GreaterThanZero outputs 1 when the input is strictly greater than zero\n * @example\n * return Tone.Offline(() => {\n * \tconst gt0 = new Tone.GreaterThanZero().toDestination();\n * \tconst sig = new Tone.Signal(0.5).connect(gt0);\n * \tsig.setValueAtTime(-1, 0.05);\n * }, 0.1, 1);\n * @category Signal\n */\nclass GreaterThanZero extends _SignalOperator__WEBPACK_IMPORTED_MODULE_0__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(GreaterThanZero.getDefaults(), arguments)));\n        this.name = \"GreaterThanZero\";\n        this._thresh = this.output = new _WaveShaper__WEBPACK_IMPORTED_MODULE_2__.WaveShaper({\n            context: this.context,\n            length: 127,\n            mapping: (val) => {\n                if (val <= 0) {\n                    return 0;\n                }\n                else {\n                    return 1;\n                }\n            },\n        });\n        this._scale = this.input = new _Multiply__WEBPACK_IMPORTED_MODULE_1__.Multiply({\n            context: this.context,\n            value: 10000\n        });\n        // connections\n        this._scale.connect(this._thresh);\n    }\n    dispose() {\n        super.dispose();\n        this._scale.dispose();\n        this._thresh.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=GreaterThanZero.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/GreaterThanZero.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Multiply.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Multiply.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Multiply\": () => (/* binding */ Multiply)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n/**\n * Multiply two incoming signals. Or, if a number is given in the constructor,\n * multiplies the incoming signal by that value.\n *\n * @example\n * // multiply two signals\n * const mult = new Tone.Multiply();\n * const sigA = new Tone.Signal(3);\n * const sigB = new Tone.Signal(4);\n * sigA.connect(mult);\n * sigB.connect(mult.factor);\n * // output of mult is 12.\n * @example\n * // multiply a signal and a number\n * const mult = new Tone.Multiply(10);\n * const sig = new Tone.Signal(2).connect(mult);\n * // the output of mult is 20.\n * @category Signal\n */\nclass Multiply extends _Signal__WEBPACK_IMPORTED_MODULE_2__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Multiply.getDefaults(), arguments, [\"value\"])));\n        this.name = \"Multiply\";\n        /**\n         * Indicates if the value should be overridden on connection\n         */\n        this.override = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Multiply.getDefaults(), arguments, [\"value\"]);\n        this._mult = this.input = this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        this.factor = this._param = this._mult.gain;\n        this.factor.setValueAtTime(options.value, 0);\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._mult.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Multiply.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Multiply.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Negate.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Negate.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Negate\": () => (/* binding */ Negate)\n/* harmony export */ });\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n/**\n * Negate the incoming signal. i.e. an input signal of 10 will output -10\n *\n * @example\n * const neg = new Tone.Negate();\n * const sig = new Tone.Signal(-2).connect(neg);\n * // output of neg is positive 2.\n * @category Signal\n */\nclass Negate extends _SignalOperator__WEBPACK_IMPORTED_MODULE_1__.SignalOperator {\n    constructor() {\n        super(...arguments);\n        this.name = \"Negate\";\n        /**\n         * negation is done by multiplying by -1\n         */\n        this._multiply = new _Multiply__WEBPACK_IMPORTED_MODULE_0__.Multiply({\n            context: this.context,\n            value: -1,\n        });\n        /**\n         * The input and output are equal to the multiply node\n         */\n        this.input = this._multiply;\n        this.output = this._multiply;\n    }\n    /**\n     * clean up\n     * @returns {Negate} this\n     */\n    dispose() {\n        super.dispose();\n        this._multiply.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Negate.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Negate.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Pow.js":
/*!***************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Pow.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Pow\": () => (/* binding */ Pow)\n/* harmony export */ });\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n/**\n * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]\n *\n * @example\n * const pow = new Tone.Pow(2);\n * const sig = new Tone.Signal(0.5).connect(pow);\n * // output of pow is 0.25.\n * @category Signal\n */\nclass Pow extends _SignalOperator__WEBPACK_IMPORTED_MODULE_2__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Pow.getDefaults(), arguments, [\"value\"])));\n        this.name = \"Pow\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Pow.getDefaults(), arguments, [\"value\"]);\n        this._exponentScaler = this.input = this.output = new _WaveShaper__WEBPACK_IMPORTED_MODULE_0__.WaveShaper({\n            context: this.context,\n            mapping: this._expFunc(options.value),\n            length: 8192,\n        });\n        this._exponent = options.value;\n    }\n    static getDefaults() {\n        return Object.assign(_SignalOperator__WEBPACK_IMPORTED_MODULE_2__.SignalOperator.getDefaults(), {\n            value: 1,\n        });\n    }\n    /**\n     * the function which maps the waveshaper\n     * @param exponent exponent value\n     */\n    _expFunc(exponent) {\n        return (val) => {\n            return Math.pow(Math.abs(val), exponent);\n        };\n    }\n    /**\n     * The value of the exponent.\n     */\n    get value() {\n        return this._exponent;\n    }\n    set value(exponent) {\n        this._exponent = exponent;\n        this._exponentScaler.setMap(this._expFunc(this._exponent));\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._exponentScaler.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Pow.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Pow.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Scale.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Scale.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Scale\": () => (/* binding */ Scale)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Add__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n\n/**\n * Performs a linear scaling on an input signal.\n * Scales a NormalRange input to between\n * outputMin and outputMax.\n *\n * @example\n * const scale = new Tone.Scale(50, 100);\n * const signal = new Tone.Signal(0.5).connect(scale);\n * // the output of scale equals 75\n * @category Signal\n */\nclass Scale extends _SignalOperator__WEBPACK_IMPORTED_MODULE_3__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Scale.getDefaults(), arguments, [\"min\", \"max\"])));\n        this.name = \"Scale\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Scale.getDefaults(), arguments, [\"min\", \"max\"]);\n        this._mult = this.input = new _Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: options.max - options.min,\n        });\n        this._add = this.output = new _Add__WEBPACK_IMPORTED_MODULE_1__.Add({\n            context: this.context,\n            value: options.min,\n        });\n        this._min = options.min;\n        this._max = options.max;\n        this.input.connect(this.output);\n    }\n    static getDefaults() {\n        return Object.assign(_SignalOperator__WEBPACK_IMPORTED_MODULE_3__.SignalOperator.getDefaults(), {\n            max: 1,\n            min: 0,\n        });\n    }\n    /**\n     * The minimum output value. This number is output when the value input value is 0.\n     */\n    get min() {\n        return this._min;\n    }\n    set min(min) {\n        this._min = min;\n        this._setRange();\n    }\n    /**\n     * The maximum output value. This number is output when the value input value is 1.\n     */\n    get max() {\n        return this._max;\n    }\n    set max(max) {\n        this._max = max;\n        this._setRange();\n    }\n    /**\n     * set the values\n     */\n    _setRange() {\n        this._add.value = this._min;\n        this._mult.value = this._max - this._min;\n    }\n    dispose() {\n        super.dispose();\n        this._add.dispose();\n        this._mult.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Scale.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Scale.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/ScaleExp.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/ScaleExp.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ScaleExp\": () => (/* binding */ ScaleExp)\n/* harmony export */ });\n/* harmony import */ var _Scale__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _Pow__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Pow */ \"./node_modules/tone/build/esm/signal/Pow.js\");\n\n\n\n/**\n * Performs an exponential scaling on an input signal.\n * Scales a NormalRange value [0,1] exponentially\n * to the output range of outputMin to outputMax.\n * @example\n * const scaleExp = new Tone.ScaleExp(0, 100, 2);\n * const signal = new Tone.Signal(0.5).connect(scaleExp);\n * @category Signal\n */\nclass ScaleExp extends _Scale__WEBPACK_IMPORTED_MODULE_0__.Scale {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(ScaleExp.getDefaults(), arguments, [\"min\", \"max\", \"exponent\"])));\n        this.name = \"ScaleExp\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(ScaleExp.getDefaults(), arguments, [\"min\", \"max\", \"exponent\"]);\n        this.input = this._exp = new _Pow__WEBPACK_IMPORTED_MODULE_2__.Pow({\n            context: this.context,\n            value: options.exponent,\n        });\n        this._exp.connect(this._mult);\n    }\n    static getDefaults() {\n        return Object.assign(_Scale__WEBPACK_IMPORTED_MODULE_0__.Scale.getDefaults(), {\n            exponent: 1,\n        });\n    }\n    /**\n     * Instead of interpolating linearly between the [[min]] and\n     * [[max]] values, setting the exponent will interpolate between\n     * the two values with an exponential curve.\n     */\n    get exponent() {\n        return this._exp.value;\n    }\n    set exponent(exp) {\n        this._exp.value = exp;\n    }\n    dispose() {\n        super.dispose();\n        this._exp.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ScaleExp.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/ScaleExp.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Signal.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Signal.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Signal\": () => (/* binding */ Signal),\n/* harmony export */   \"connectSignal\": () => (/* binding */ connectSignal)\n/* harmony export */ });\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/AdvancedTypeCheck */ \"./node_modules/tone/build/esm/core/util/AdvancedTypeCheck.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _ToneConstantSource__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./ToneConstantSource */ \"./node_modules/tone/build/esm/signal/ToneConstantSource.js\");\n\n\n\n\n\n\n/**\n * A signal is an audio-rate value. Tone.Signal is a core component of the library.\n * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal\n * has all of the methods available to native Web Audio\n * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)\n * as well as additional conveniences. Read more about working with signals\n * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // a scheduleable signal which can be connected to control an AudioParam or another Signal\n * const signal = new Tone.Signal({\n * \tvalue: \"C4\",\n * \tunits: \"frequency\"\n * }).connect(osc.frequency);\n * // the scheduled ramp controls the connected signal\n * signal.rampTo(\"C2\", 4, \"+0.5\");\n * @category Signal\n */\nclass Signal extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Signal.getDefaults(), arguments, [\"value\", \"units\"]));\n        this.name = \"Signal\";\n        /**\n         * Indicates if the value should be overridden on connection.\n         */\n        this.override = true;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Signal.getDefaults(), arguments, [\"value\", \"units\"]);\n        this.output = this._constantSource = new _ToneConstantSource__WEBPACK_IMPORTED_MODULE_4__.ToneConstantSource({\n            context: this.context,\n            convert: options.convert,\n            offset: options.value,\n            units: options.units,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n        this._constantSource.start(0);\n        this.input = this._param = this._constantSource.offset;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            convert: true,\n            units: \"number\",\n            value: 0,\n        });\n    }\n    connect(destination, outputNum = 0, inputNum = 0) {\n        // start it only when connected to something\n        connectSignal(this, destination, outputNum, inputNum);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._param.dispose();\n        this._constantSource.dispose();\n        return this;\n    }\n    //-------------------------------------\n    // ABSTRACT PARAM INTERFACE\n    // just a proxy for the ConstantSourceNode's offset AudioParam\n    // all docs are generated from AbstractParam.ts\n    //-------------------------------------\n    setValueAtTime(value, time) {\n        this._param.setValueAtTime(value, time);\n        return this;\n    }\n    getValueAtTime(time) {\n        return this._param.getValueAtTime(time);\n    }\n    setRampPoint(time) {\n        this._param.setRampPoint(time);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        this._param.linearRampToValueAtTime(value, time);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        this._param.exponentialRampToValueAtTime(value, time);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        this._param.exponentialRampTo(value, rampTime, startTime);\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        this._param.linearRampTo(value, rampTime, startTime);\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        this._param.targetRampTo(value, rampTime, startTime);\n        return this;\n    }\n    exponentialApproachValueAtTime(value, time, rampTime) {\n        this._param.exponentialApproachValueAtTime(value, time, rampTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        this._param.setTargetAtTime(value, startTime, timeConstant);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling) {\n        this._param.setValueCurveAtTime(values, startTime, duration, scaling);\n        return this;\n    }\n    cancelScheduledValues(time) {\n        this._param.cancelScheduledValues(time);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        this._param.cancelAndHoldAtTime(time);\n        return this;\n    }\n    rampTo(value, rampTime, startTime) {\n        this._param.rampTo(value, rampTime, startTime);\n        return this;\n    }\n    get value() {\n        return this._param.value;\n    }\n    set value(value) {\n        this._param.value = value;\n    }\n    get convert() {\n        return this._param.convert;\n    }\n    set convert(convert) {\n        this._param.convert = convert;\n    }\n    get units() {\n        return this._param.units;\n    }\n    get overridden() {\n        return this._param.overridden;\n    }\n    set overridden(overridden) {\n        this._param.overridden = overridden;\n    }\n    get maxValue() {\n        return this._param.maxValue;\n    }\n    get minValue() {\n        return this._param.minValue;\n    }\n    /**\n     * See [[Param.apply]].\n     */\n    apply(param) {\n        this._param.apply(param);\n        return this;\n    }\n}\n/**\n * When connecting from a signal, it's necessary to zero out the node destination\n * node if that node is also a signal. If the destination is not 0, then the values\n * will be summed. This method insures that the output of the destination signal will\n * be the same as the source signal, making the destination signal a pass through node.\n * @param signal The output signal to connect from\n * @param destination the destination to connect to\n * @param outputNum the optional output number\n * @param inputNum the input number\n */\nfunction connectSignal(signal, destination, outputNum, inputNum) {\n    if (destination instanceof _core_context_Param__WEBPACK_IMPORTED_MODULE_0__.Param || (0,_core_util_AdvancedTypeCheck__WEBPACK_IMPORTED_MODULE_2__.isAudioParam)(destination) ||\n        (destination instanceof Signal && destination.override)) {\n        // cancel changes\n        destination.cancelScheduledValues(0);\n        // reset the value\n        destination.setValueAtTime(0, 0);\n        // mark the value as overridden\n        if (destination instanceof Signal) {\n            destination.overridden = true;\n        }\n    }\n    (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(signal, destination, outputNum, inputNum);\n}\n//# sourceMappingURL=Signal.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Signal.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/SignalOperator.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/SignalOperator.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SignalOperator\": () => (/* binding */ SignalOperator)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n/**\n * A signal operator has an input and output and modifies the signal.\n */\nclass SignalOperator extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(SignalOperator.getDefaults(), arguments, [\"context\"])));\n    }\n    connect(destination, outputNum = 0, inputNum = 0) {\n        (0,_Signal__WEBPACK_IMPORTED_MODULE_2__.connectSignal)(this, destination, outputNum, inputNum);\n        return this;\n    }\n}\n//# sourceMappingURL=SignalOperator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/SignalOperator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Subtract.js":
/*!********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Subtract.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Subtract\": () => (/* binding */ Subtract)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _signal_Negate__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../signal/Negate */ \"./node_modules/tone/build/esm/signal/Negate.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n\n\n\n\n\n/**\n * Subtract the signal connected to the input is subtracted from the signal connected\n * The subtrahend.\n *\n * @example\n * // subtract a scalar from a signal\n * const sub = new Tone.Subtract(1);\n * const sig = new Tone.Signal(4).connect(sub);\n * // the output of sub is 3.\n * @example\n * // subtract two signals\n * const sub = new Tone.Subtract();\n * const sigA = new Tone.Signal(10);\n * const sigB = new Tone.Signal(2.5);\n * sigA.connect(sub);\n * sigB.connect(sub.subtrahend);\n * // output of sub is 7.5\n * @category Signal\n */\nclass Subtract extends _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Subtract.getDefaults(), arguments, [\"value\"])));\n        this.override = false;\n        this.name = \"Subtract\";\n        /**\n         * the summing node\n         */\n        this._sum = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_1__.Gain({ context: this.context });\n        this.input = this._sum;\n        this.output = this._sum;\n        /**\n         * Negate the input of the second input before connecting it to the summing node.\n         */\n        this._neg = new _signal_Negate__WEBPACK_IMPORTED_MODULE_3__.Negate({ context: this.context });\n        /**\n         * The value which is subtracted from the main signal\n         */\n        this.subtrahend = this._param;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connectSeries)(this._constantSource, this._neg, this._sum);\n    }\n    static getDefaults() {\n        return Object.assign(_signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal.getDefaults(), {\n            value: 0,\n        });\n    }\n    dispose() {\n        super.dispose();\n        this._neg.dispose();\n        this._sum.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Subtract.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Subtract.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/SyncedSignal.js":
/*!************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/SyncedSignal.js ***!
  \************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"SyncedSignal\": () => (/* binding */ SyncedSignal)\n/* harmony export */ });\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/type/TransportTime */ \"./node_modules/tone/build/esm/core/type/TransportTime.js\");\n/* harmony import */ var _ToneConstantSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./ToneConstantSource */ \"./node_modules/tone/build/esm/signal/ToneConstantSource.js\");\n\n\n\n\n/**\n * Adds the ability to synchronize the signal to the [[Transport]]\n */\nclass SyncedSignal extends _Signal__WEBPACK_IMPORTED_MODULE_0__.Signal {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal.getDefaults(), arguments, [\"value\", \"units\"]));\n        this.name = \"SyncedSignal\";\n        /**\n         * Don't override when something is connected to the input\n         */\n        this.override = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(_Signal__WEBPACK_IMPORTED_MODULE_0__.Signal.getDefaults(), arguments, [\"value\", \"units\"]);\n        this._lastVal = options.value;\n        this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), \"1i\");\n        this._syncedCallback = this._anchorValue.bind(this);\n        this.context.transport.on(\"start\", this._syncedCallback);\n        this.context.transport.on(\"pause\", this._syncedCallback);\n        this.context.transport.on(\"stop\", this._syncedCallback);\n        // disconnect the constant source from the output and replace it with another one\n        this._constantSource.disconnect();\n        this._constantSource.stop(0);\n        // create a new one\n        this._constantSource = this.output = new _ToneConstantSource__WEBPACK_IMPORTED_MODULE_3__.ToneConstantSource({\n            context: this.context,\n            offset: options.value,\n            units: options.units,\n        }).start(0);\n        this.setValueAtTime(options.value, 0);\n    }\n    /**\n     * Callback which is invoked every tick.\n     */\n    _onTick(time) {\n        const val = super.getValueAtTime(this.context.transport.seconds);\n        // approximate ramp curves with linear ramps\n        if (this._lastVal !== val) {\n            this._lastVal = val;\n            this._constantSource.offset.setValueAtTime(val, time);\n        }\n    }\n    /**\n     * Anchor the value at the start and stop of the Transport\n     */\n    _anchorValue(time) {\n        const val = super.getValueAtTime(this.context.transport.seconds);\n        this._lastVal = val;\n        this._constantSource.offset.cancelAndHoldAtTime(time);\n        this._constantSource.offset.setValueAtTime(val, time);\n    }\n    getValueAtTime(time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        return super.getValueAtTime(computedTime);\n    }\n    setValueAtTime(value, time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.setValueAtTime(value, computedTime);\n        return this;\n    }\n    linearRampToValueAtTime(value, time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.linearRampToValueAtTime(value, computedTime);\n        return this;\n    }\n    exponentialRampToValueAtTime(value, time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.exponentialRampToValueAtTime(value, computedTime);\n        return this;\n    }\n    setTargetAtTime(value, startTime, timeConstant) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.setTargetAtTime(value, computedTime, timeConstant);\n        return this;\n    }\n    cancelScheduledValues(startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.cancelScheduledValues(computedTime);\n        return this;\n    }\n    setValueCurveAtTime(values, startTime, duration, scaling) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        duration = this.toSeconds(duration);\n        super.setValueCurveAtTime(values, computedTime, duration, scaling);\n        return this;\n    }\n    cancelAndHoldAtTime(time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.cancelAndHoldAtTime(computedTime);\n        return this;\n    }\n    setRampPoint(time) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, time).toSeconds();\n        super.setRampPoint(computedTime);\n        return this;\n    }\n    exponentialRampTo(value, rampTime, startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.exponentialRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    linearRampTo(value, rampTime, startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.linearRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    targetRampTo(value, rampTime, startTime) {\n        const computedTime = new _core_type_TransportTime__WEBPACK_IMPORTED_MODULE_2__.TransportTimeClass(this.context, startTime).toSeconds();\n        super.targetRampTo(value, rampTime, computedTime);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this.context.transport.clear(this._synced);\n        this.context.transport.off(\"start\", this._syncedCallback);\n        this.context.transport.off(\"pause\", this._syncedCallback);\n        this.context.transport.off(\"stop\", this._syncedCallback);\n        this._constantSource.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=SyncedSignal.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/SyncedSignal.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/ToneConstantSource.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/ToneConstantSource.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneConstantSource\": () => (/* binding */ ToneConstantSource)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _source_OneShotSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../source/OneShotSource */ \"./node_modules/tone/build/esm/source/OneShotSource.js\");\n\n\n\n\n/**\n * Wrapper around the native fire-and-forget ConstantSource.\n * Adds the ability to reschedule the stop method.\n * @category Signal\n */\nclass ToneConstantSource extends _source_OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneConstantSource.getDefaults(), arguments, [\"offset\"]));\n        this.name = \"ToneConstantSource\";\n        /**\n         * The signal generator\n         */\n        this._source = this.context.createConstantSource();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneConstantSource.getDefaults(), arguments, [\"offset\"]);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(this._source, this._gainNode);\n        this.offset = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            convert: options.convert,\n            param: this._source.offset,\n            units: options.units,\n            value: options.offset,\n            minValue: options.minValue,\n            maxValue: options.maxValue,\n        });\n    }\n    static getDefaults() {\n        return Object.assign(_source_OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource.getDefaults(), {\n            convert: true,\n            offset: 1,\n            units: \"number\",\n        });\n    }\n    /**\n     * Start the source node at the given time\n     * @param  time When to start the source\n     */\n    start(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        this._startGain(computedTime);\n        this._source.start(computedTime);\n        return this;\n    }\n    _stopSource(time) {\n        this._source.stop(time);\n    }\n    dispose() {\n        super.dispose();\n        if (this.state === \"started\") {\n            this.stop();\n        }\n        this._source.disconnect();\n        this.offset.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneConstantSource.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/ToneConstantSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/WaveShaper.js":
/*!**********************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/WaveShaper.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"WaveShaper\": () => (/* binding */ WaveShaper)\n/* harmony export */ });\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n\n\n/**\n * Wraps the native Web Audio API\n * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).\n *\n * @example\n * const osc = new Tone.Oscillator().toDestination().start();\n * // multiply the output of the signal by 2 using the waveshaper's function\n * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);\n * const signal = new Tone.Signal(440).connect(timesTwo);\n * @category Signal\n */\nclass WaveShaper extends _SignalOperator__WEBPACK_IMPORTED_MODULE_4__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(WaveShaper.getDefaults(), arguments, [\"mapping\", \"length\"])));\n        this.name = \"WaveShaper\";\n        /**\n         * the waveshaper node\n         */\n        this._shaper = this.context.createWaveShaper();\n        /**\n         * The input to the waveshaper node.\n         */\n        this.input = this._shaper;\n        /**\n         * The output from the waveshaper node\n         */\n        this.output = this._shaper;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(WaveShaper.getDefaults(), arguments, [\"mapping\", \"length\"]);\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isArray)(options.mapping) || options.mapping instanceof Float32Array) {\n            this.curve = Float32Array.from(options.mapping);\n        }\n        else if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_1__.isFunction)(options.mapping)) {\n            this.setMap(options.mapping, options.length);\n        }\n    }\n    static getDefaults() {\n        return Object.assign(_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal.getDefaults(), {\n            length: 1024,\n        });\n    }\n    /**\n     * Uses a mapping function to set the value of the curve.\n     * @param mapping The function used to define the values.\n     *                The mapping function take two arguments:\n     *                the first is the value at the current position\n     *                which goes from -1 to 1 over the number of elements\n     *                in the curve array. The second argument is the array position.\n     * @example\n     * const shaper = new Tone.WaveShaper();\n     * // map the input signal from [-1, 1] to [0, 10]\n     * shaper.setMap((val, index) => (val + 1) * 5);\n     */\n    setMap(mapping, length = 1024) {\n        const array = new Float32Array(length);\n        for (let i = 0, len = length; i < len; i++) {\n            const normalized = (i / (len - 1)) * 2 - 1;\n            array[i] = mapping(normalized, i);\n        }\n        this.curve = array;\n        return this;\n    }\n    /**\n     * The array to set as the waveshaper curve. For linear curves\n     * array length does not make much difference, but for complex curves\n     * longer arrays will provide smoother interpolation.\n     */\n    get curve() {\n        return this._shaper.curve;\n    }\n    set curve(mapping) {\n        this._shaper.curve = mapping;\n    }\n    /**\n     * Specifies what type of oversampling (if any) should be used when\n     * applying the shaping curve. Can either be \"none\", \"2x\" or \"4x\".\n     */\n    get oversample() {\n        return this._shaper.oversample;\n    }\n    set oversample(oversampling) {\n        const isOverSampleType = [\"none\", \"2x\", \"4x\"].some(str => str.includes(oversampling));\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(isOverSampleType, \"oversampling must be either 'none', '2x', or '4x'\");\n        this._shaper.oversample = oversampling;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._shaper.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=WaveShaper.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/WaveShaper.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/Zero.js":
/*!****************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/Zero.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Zero\": () => (/* binding */ Zero)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _SignalOperator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SignalOperator */ \"./node_modules/tone/build/esm/signal/SignalOperator.js\");\n\n\n\n\n/**\n * Tone.Zero outputs 0's at audio-rate. The reason this has to be\n * it's own class is that many browsers optimize out Tone.Signal\n * with a value of 0 and will not process nodes further down the graph.\n * @category Signal\n */\nclass Zero extends _SignalOperator__WEBPACK_IMPORTED_MODULE_3__.SignalOperator {\n    constructor() {\n        super(Object.assign((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(Zero.getDefaults(), arguments)));\n        this.name = \"Zero\";\n        /**\n         * The gain node which connects the constant source to the output\n         */\n        this._gain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({ context: this.context });\n        /**\n         * Only outputs 0\n         */\n        this.output = this._gain;\n        /**\n         * no input node\n         */\n        this.input = undefined;\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.connect)(this.context.getConstant(0), this._gain);\n    }\n    /**\n     * clean up\n     */\n    dispose() {\n        super.dispose();\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.disconnect)(this.context.getConstant(0), this._gain);\n        return this;\n    }\n}\n//# sourceMappingURL=Zero.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/Zero.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/signal/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/signal/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Abs\": () => (/* reexport safe */ _Abs__WEBPACK_IMPORTED_MODULE_1__.Abs),\n/* harmony export */   \"Add\": () => (/* reexport safe */ _Add__WEBPACK_IMPORTED_MODULE_0__.Add),\n/* harmony export */   \"AudioToGain\": () => (/* reexport safe */ _AudioToGain__WEBPACK_IMPORTED_MODULE_2__.AudioToGain),\n/* harmony export */   \"GainToAudio\": () => (/* reexport safe */ _GainToAudio__WEBPACK_IMPORTED_MODULE_3__.GainToAudio),\n/* harmony export */   \"GreaterThan\": () => (/* reexport safe */ _GreaterThan__WEBPACK_IMPORTED_MODULE_4__.GreaterThan),\n/* harmony export */   \"GreaterThanZero\": () => (/* reexport safe */ _GreaterThanZero__WEBPACK_IMPORTED_MODULE_5__.GreaterThanZero),\n/* harmony export */   \"Multiply\": () => (/* reexport safe */ _Multiply__WEBPACK_IMPORTED_MODULE_6__.Multiply),\n/* harmony export */   \"Negate\": () => (/* reexport safe */ _Negate__WEBPACK_IMPORTED_MODULE_7__.Negate),\n/* harmony export */   \"Pow\": () => (/* reexport safe */ _Pow__WEBPACK_IMPORTED_MODULE_8__.Pow),\n/* harmony export */   \"Scale\": () => (/* reexport safe */ _Scale__WEBPACK_IMPORTED_MODULE_10__.Scale),\n/* harmony export */   \"ScaleExp\": () => (/* reexport safe */ _ScaleExp__WEBPACK_IMPORTED_MODULE_11__.ScaleExp),\n/* harmony export */   \"Signal\": () => (/* reexport safe */ _Signal__WEBPACK_IMPORTED_MODULE_9__.Signal),\n/* harmony export */   \"Subtract\": () => (/* reexport safe */ _Subtract__WEBPACK_IMPORTED_MODULE_12__.Subtract),\n/* harmony export */   \"SyncedSignal\": () => (/* reexport safe */ _SyncedSignal__WEBPACK_IMPORTED_MODULE_13__.SyncedSignal),\n/* harmony export */   \"WaveShaper\": () => (/* reexport safe */ _WaveShaper__WEBPACK_IMPORTED_MODULE_14__.WaveShaper),\n/* harmony export */   \"Zero\": () => (/* reexport safe */ _Zero__WEBPACK_IMPORTED_MODULE_15__.Zero),\n/* harmony export */   \"connectSignal\": () => (/* reexport safe */ _Signal__WEBPACK_IMPORTED_MODULE_9__.connectSignal)\n/* harmony export */ });\n/* harmony import */ var _Add__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Add */ \"./node_modules/tone/build/esm/signal/Add.js\");\n/* harmony import */ var _Abs__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Abs */ \"./node_modules/tone/build/esm/signal/Abs.js\");\n/* harmony import */ var _AudioToGain__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _GainToAudio__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./GainToAudio */ \"./node_modules/tone/build/esm/signal/GainToAudio.js\");\n/* harmony import */ var _GreaterThan__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./GreaterThan */ \"./node_modules/tone/build/esm/signal/GreaterThan.js\");\n/* harmony import */ var _GreaterThanZero__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./GreaterThanZero */ \"./node_modules/tone/build/esm/signal/GreaterThanZero.js\");\n/* harmony import */ var _Multiply__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _Negate__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Negate */ \"./node_modules/tone/build/esm/signal/Negate.js\");\n/* harmony import */ var _Pow__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Pow */ \"./node_modules/tone/build/esm/signal/Pow.js\");\n/* harmony import */ var _Signal__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Scale__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _ScaleExp__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./ScaleExp */ \"./node_modules/tone/build/esm/signal/ScaleExp.js\");\n/* harmony import */ var _Subtract__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./Subtract */ \"./node_modules/tone/build/esm/signal/Subtract.js\");\n/* harmony import */ var _SyncedSignal__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./SyncedSignal */ \"./node_modules/tone/build/esm/signal/SyncedSignal.js\");\n/* harmony import */ var _WaveShaper__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _Zero__WEBPACK_IMPORTED_MODULE_15__ = __webpack_require__(/*! ./Zero */ \"./node_modules/tone/build/esm/signal/Zero.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/signal/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/Noise.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/source/Noise.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Noise\": () => (/* binding */ Noise)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _source_Source__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../source/Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n\n\n\n\n\n/**\n * Noise is a noise generator. It uses looped noise buffers to save on performance.\n * Noise supports the noise types: \"pink\", \"white\", and \"brown\". Read more about\n * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).\n *\n * @example\n * // initialize the noise and start\n * const noise = new Tone.Noise(\"pink\").start();\n * // make an autofilter to shape the noise\n * const autoFilter = new Tone.AutoFilter({\n * \tfrequency: \"8n\",\n * \tbaseFrequency: 200,\n * \toctaves: 8\n * }).toDestination().start();\n * // connect the noise\n * noise.connect(autoFilter);\n * // start the autofilter LFO\n * autoFilter.start();\n * @category Source\n */\nclass Noise extends _source_Source__WEBPACK_IMPORTED_MODULE_3__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Noise.getDefaults(), arguments, [\"type\"]));\n        this.name = \"Noise\";\n        /**\n         * Private reference to the source\n         */\n        this._source = null;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Noise.getDefaults(), arguments, [\"type\"]);\n        this._playbackRate = options.playbackRate;\n        this.type = options.type;\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(_source_Source__WEBPACK_IMPORTED_MODULE_3__.Source.getDefaults(), {\n            fadeIn: 0,\n            fadeOut: 0,\n            playbackRate: 1,\n            type: \"white\",\n        });\n    }\n    /**\n     * The type of the noise. Can be \"white\", \"brown\", or \"pink\".\n     * @example\n     * const noise = new Tone.Noise().toDestination().start();\n     * noise.type = \"brown\";\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_2__.assert)(type in _noiseBuffers, \"Noise: invalid type: \" + type);\n        if (this._type !== type) {\n            this._type = type;\n            // if it's playing, stop and restart it\n            if (this.state === \"started\") {\n                const now = this.now();\n                this._stop(now);\n                this._start(now);\n            }\n        }\n    }\n    /**\n     * The playback rate of the noise. Affects\n     * the \"frequency\" of the noise.\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        if (this._source) {\n            this._source.playbackRate.value = rate;\n        }\n    }\n    /**\n     * internal start method\n     */\n    _start(time) {\n        const buffer = _noiseBuffers[this._type];\n        this._source = new _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_4__.ToneBufferSource({\n            url: buffer,\n            context: this.context,\n            fadeIn: this._fadeIn,\n            fadeOut: this._fadeOut,\n            loop: true,\n            onended: () => this.onstop(this),\n            playbackRate: this._playbackRate,\n        }).connect(this.output);\n        this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));\n    }\n    /**\n     * internal stop method\n     */\n    _stop(time) {\n        if (this._source) {\n            this._source.stop(this.toSeconds(time));\n            this._source = null;\n        }\n    }\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(time) {\n        this._fadeIn = time;\n        if (this._source) {\n            this._source.fadeIn = this._fadeIn;\n        }\n    }\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(time) {\n        this._fadeOut = time;\n        if (this._source) {\n            this._source.fadeOut = this._fadeOut;\n        }\n    }\n    _restart(time) {\n        // TODO could be optimized by cancelling the buffer source 'stop'\n        this._stop(time);\n        this._start(time);\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        if (this._source) {\n            this._source.disconnect();\n        }\n        return this;\n    }\n}\n//--------------------\n// THE NOISE BUFFERS\n//--------------------\n// Noise buffer stats\nconst BUFFER_LENGTH = 44100 * 5;\nconst NUM_CHANNELS = 2;\n/**\n * Cache the noise buffers\n */\nconst _noiseCache = {\n    brown: null,\n    pink: null,\n    white: null,\n};\n/**\n * The noise arrays. Generated on initialization.\n * borrowed heavily from https://github.com/zacharydenton/noise.js\n * (c) 2013 Zach Denton (MIT)\n */\nconst _noiseBuffers = {\n    get brown() {\n        if (!_noiseCache.brown) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                let lastOut = 0.0;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    const white = Math.random() * 2 - 1;\n                    channel[i] = (lastOut + (0.02 * white)) / 1.02;\n                    lastOut = channel[i];\n                    channel[i] *= 3.5; // (roughly) compensate for gain\n                }\n            }\n            _noiseCache.brown = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.brown;\n    },\n    get pink() {\n        if (!_noiseCache.pink) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                let b0, b1, b2, b3, b4, b5, b6;\n                b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0.0;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    const white = Math.random() * 2 - 1;\n                    b0 = 0.99886 * b0 + white * 0.0555179;\n                    b1 = 0.99332 * b1 + white * 0.0750759;\n                    b2 = 0.96900 * b2 + white * 0.1538520;\n                    b3 = 0.86650 * b3 + white * 0.3104856;\n                    b4 = 0.55000 * b4 + white * 0.5329522;\n                    b5 = -0.7616 * b5 - white * 0.0168980;\n                    channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;\n                    channel[i] *= 0.11; // (roughly) compensate for gain\n                    b6 = white * 0.115926;\n                }\n            }\n            _noiseCache.pink = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.pink;\n    },\n    get white() {\n        if (!_noiseCache.white) {\n            const buffer = [];\n            for (let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++) {\n                const channel = new Float32Array(BUFFER_LENGTH);\n                buffer[channelNum] = channel;\n                for (let i = 0; i < BUFFER_LENGTH; i++) {\n                    channel[i] = Math.random() * 2 - 1;\n                }\n            }\n            _noiseCache.white = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer().fromArray(buffer);\n        }\n        return _noiseCache.white;\n    },\n};\n//# sourceMappingURL=Noise.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/Noise.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/OneShotSource.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/OneShotSource.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OneShotSource\": () => (/* binding */ OneShotSource)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n/**\n * Base class for fire-and-forget nodes\n */\nclass OneShotSource extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        /**\n         * The callback to invoke after the\n         * source is done playing.\n         */\n        this.onended = _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp;\n        /**\n         * The start time\n         */\n        this._startTime = -1;\n        /**\n         * The stop time\n         */\n        this._stopTime = -1;\n        /**\n         * The id of the timeout\n         */\n        this._timeout = -1;\n        /**\n         * The public output node\n         */\n        this.output = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * The output gain node.\n         */\n        this._gainNode = this.output;\n        /**\n         * Get the playback state at the given time\n         */\n        this.getStateAtTime = function (time) {\n            const computedTime = this.toSeconds(time);\n            if (this._startTime !== -1 &&\n                computedTime >= this._startTime &&\n                (this._stopTime === -1 || computedTime <= this._stopTime)) {\n                return \"started\";\n            }\n            else {\n                return \"stopped\";\n            }\n        };\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n        this._curve = options.curve;\n        this.onended = options.onended;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_1__.ToneAudioNode.getDefaults(), {\n            curve: \"linear\",\n            fadeIn: 0,\n            fadeOut: 0,\n            onended: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n        });\n    }\n    /**\n     * Start the source at the given time\n     * @param  time When to start the source\n     */\n    _startGain(time, gain = 1) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(this._startTime === -1, \"Source cannot be started more than once\");\n        // apply a fade in envelope\n        const fadeInTime = this.toSeconds(this._fadeIn);\n        // record the start time\n        this._startTime = time + fadeInTime;\n        this._startTime = Math.max(this._startTime, this.context.currentTime);\n        // schedule the envelope\n        if (fadeInTime > 0) {\n            this._gainNode.gain.setValueAtTime(0, time);\n            if (this._curve === \"linear\") {\n                this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);\n            }\n            else {\n                this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);\n            }\n        }\n        else {\n            this._gainNode.gain.setValueAtTime(gain, time);\n        }\n        return this;\n    }\n    /**\n     * Stop the source node at the given time.\n     * @param time When to stop the source\n     */\n    stop(time) {\n        this.log(\"stop\", time);\n        this._stopGain(this.toSeconds(time));\n        return this;\n    }\n    /**\n     * Stop the source at the given time\n     * @param  time When to stop the source\n     */\n    _stopGain(time) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(this._startTime !== -1, \"'start' must be called before 'stop'\");\n        // cancel the previous stop\n        this.cancelStop();\n        // the fadeOut time\n        const fadeOutTime = this.toSeconds(this._fadeOut);\n        // schedule the stop callback\n        this._stopTime = this.toSeconds(time) + fadeOutTime;\n        this._stopTime = Math.max(this._stopTime, this.context.currentTime);\n        if (fadeOutTime > 0) {\n            // start the fade out curve at the given time\n            if (this._curve === \"linear\") {\n                this._gainNode.gain.linearRampTo(0, fadeOutTime, time);\n            }\n            else {\n                this._gainNode.gain.targetRampTo(0, fadeOutTime, time);\n            }\n        }\n        else {\n            // stop any ongoing ramps, and set the value to 0\n            this._gainNode.gain.cancelAndHoldAtTime(time);\n            this._gainNode.gain.setValueAtTime(0, time);\n        }\n        this.context.clearTimeout(this._timeout);\n        this._timeout = this.context.setTimeout(() => {\n            // allow additional time for the exponential curve to fully decay\n            const additionalTail = this._curve === \"exponential\" ? fadeOutTime * 2 : 0;\n            this._stopSource(this.now() + additionalTail);\n            this._onended();\n        }, this._stopTime - this.context.currentTime);\n        return this;\n    }\n    /**\n     * Invoke the onended callback\n     */\n    _onended() {\n        if (this.onended !== _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp) {\n            this.onended(this);\n            // overwrite onended to make sure it only is called once\n            this.onended = _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp;\n            // dispose when it's ended to free up for garbage collection only in the online context\n            if (!this.context.isOffline) {\n                const disposeCallback = () => this.dispose();\n                // @ts-ignore\n                if (typeof window.requestIdleCallback !== \"undefined\") {\n                    // @ts-ignore\n                    window.requestIdleCallback(disposeCallback);\n                }\n                else {\n                    setTimeout(disposeCallback, 1000);\n                }\n            }\n        }\n    }\n    /**\n     * Get the playback state at the current time\n     */\n    get state() {\n        return this.getStateAtTime(this.now());\n    }\n    /**\n     * Cancel a scheduled stop event\n     */\n    cancelStop() {\n        this.log(\"cancelStop\");\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(this._startTime !== -1, \"Source is not started\");\n        // cancel the stop envelope\n        this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);\n        this.context.clearTimeout(this._timeout);\n        this._stopTime = -1;\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._gainNode.disconnect();\n        return this;\n    }\n}\n//# sourceMappingURL=OneShotSource.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/OneShotSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/Source.js":
/*!******************************************************!*\
  !*** ./node_modules/tone/build/esm/source/Source.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Source\": () => (/* binding */ Source)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_context_Destination__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../core/context/Destination */ \"./node_modules/tone/build/esm/core/context/Destination.js\");\n/* harmony import */ var _core_clock_Transport__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/clock/Transport */ \"./node_modules/tone/build/esm/core/clock/Transport.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../core/util/StateTimeline */ \"./node_modules/tone/build/esm/core/util/StateTimeline.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * Base class for sources.\n * start/stop of this.context.transport.\n *\n * ```\n * // Multiple state change events can be chained together,\n * // but must be set in the correct order and with ascending times\n * // OK\n * state.start().stop(\"+0.2\");\n * // OK\n * state.start().stop(\"+0.2\").start(\"+0.4\").stop(\"+0.7\")\n * // BAD\n * state.stop(\"+0.2\").start();\n * // BAD\n * state.start(\"+0.3\").stop(\"+0.2\");\n * ```\n */\nclass Source extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode {\n    constructor(options) {\n        super(options);\n        /**\n         * Sources have no inputs\n         */\n        this.input = undefined;\n        /**\n         * Keep track of the scheduled state.\n         */\n        this._state = new _core_util_StateTimeline__WEBPACK_IMPORTED_MODULE_6__.StateTimeline(\"stopped\");\n        /**\n         * The synced `start` callback function from the transport\n         */\n        this._synced = false;\n        /**\n         * Keep track of all of the scheduled event ids\n         */\n        this._scheduled = [];\n        /**\n         * Placeholder functions for syncing/unsyncing to transport\n         */\n        this._syncedStart = _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp;\n        this._syncedStop = _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp;\n        this._state.memory = 100;\n        this._state.increasing = true;\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({\n            context: this.context,\n            mute: options.mute,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, \"volume\");\n        this.onstop = options.onstop;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_3__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            onstop: _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n            volume: 0,\n        });\n    }\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/ahntone_c3.mp3\", () => {\n     * \tplayer.start();\n     * \tconsole.log(player.state);\n     * }).toDestination();\n     */\n    get state() {\n        if (this._synced) {\n            if (this.context.transport.state === \"started\") {\n                return this._state.getValueAtTime(this.context.transport.seconds);\n            }\n            else {\n                return \"stopped\";\n            }\n        }\n        else {\n            return this._state.getValueAtTime(this.now());\n        }\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * // mute the output\n     * osc.mute = true;\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    /**\n     * Ensure that the scheduled time is not before the current time.\n     * Should only be used when scheduled unsynced.\n     */\n    _clampToCurrentTime(time) {\n        if (this._synced) {\n            return time;\n        }\n        else {\n            return Math.max(time, this.context.currentTime);\n        }\n    }\n    /**\n     * Start the source at the specified time. If no time is given,\n     * start the source now.\n     * @param  time When the source should be started.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start(\"+0.5\"); // starts the source 0.5 seconds from now\n     */\n    start(time, offset, duration) {\n        let computedTime = (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__.isUndef)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);\n        computedTime = this._clampToCurrentTime(computedTime);\n        // if it's started, stop it and restart it\n        if (!this._synced && this._state.getValueAtTime(computedTime) === \"started\") {\n            // time should be strictly greater than the previous start time\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assert)((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_9__.GT)(computedTime, this._state.get(computedTime).time), \"Start time must be strictly greater than previous start time\");\n            this._state.cancel(computedTime);\n            this._state.setStateAtTime(\"started\", computedTime);\n            this.log(\"restart\", computedTime);\n            this.restart(computedTime, offset, duration);\n        }\n        else {\n            this.log(\"start\", computedTime);\n            this._state.setStateAtTime(\"started\", computedTime);\n            if (this._synced) {\n                // add the offset time to the event\n                const event = this._state.get(computedTime);\n                if (event) {\n                    event.offset = this.toSeconds((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_4__.defaultArg)(offset, 0));\n                    event.duration = duration ? this.toSeconds(duration) : undefined;\n                }\n                const sched = this.context.transport.schedule(t => {\n                    this._start(t, offset, duration);\n                }, computedTime);\n                this._scheduled.push(sched);\n                // if the transport is already started\n                // and the time is greater than where the transport is\n                if (this.context.transport.state === \"started\" &&\n                    this.context.transport.getSecondsAtTime(this.immediate()) > computedTime) {\n                    this._syncedStart(this.now(), this.context.transport.seconds);\n                }\n            }\n            else {\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_8__.assertContextRunning)(this.context);\n                this._start(computedTime, offset, duration);\n            }\n        }\n        return this;\n    }\n    /**\n     * Stop the source at the specified time. If no time is given,\n     * stop the source now.\n     * @param  time When the source should be stopped.\n     * @example\n     * const source = new Tone.Oscillator().toDestination();\n     * source.start();\n     * source.stop(\"+0.5\"); // stops the source 0.5 seconds from now\n     */\n    stop(time) {\n        let computedTime = (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__.isUndef)(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);\n        computedTime = this._clampToCurrentTime(computedTime);\n        if (this._state.getValueAtTime(computedTime) === \"started\" || (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_7__.isDefined)(this._state.getNextState(\"started\", computedTime))) {\n            this.log(\"stop\", computedTime);\n            if (!this._synced) {\n                this._stop(computedTime);\n            }\n            else {\n                const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);\n                this._scheduled.push(sched);\n            }\n            this._state.cancel(computedTime);\n            this._state.setStateAtTime(\"stopped\", computedTime);\n        }\n        return this;\n    }\n    /**\n     * Restart the source.\n     */\n    restart(time, offset, duration) {\n        time = this.toSeconds(time);\n        if (this._state.getValueAtTime(time) === \"started\") {\n            this._state.cancel(time);\n            this._restart(time, offset, duration);\n        }\n        return this;\n    }\n    /**\n     * Sync the source to the Transport so that all subsequent\n     * calls to `start` and `stop` are synced to the TransportTime\n     * instead of the AudioContext time.\n     *\n     * @example\n     * const osc = new Tone.Oscillator().toDestination();\n     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline\n     * osc.sync().start(0).stop(0.3);\n     * // start the transport.\n     * Tone.Transport.start();\n     * // set it to loop once a second\n     * Tone.Transport.loop = true;\n     * Tone.Transport.loopEnd = 1;\n     */\n    sync() {\n        if (!this._synced) {\n            this._synced = true;\n            this._syncedStart = (time, offset) => {\n                if (offset > 0) {\n                    // get the playback state at that time\n                    const stateEvent = this._state.get(offset);\n                    // listen for start events which may occur in the middle of the sync'ed time\n                    if (stateEvent && stateEvent.state === \"started\" && stateEvent.time !== offset) {\n                        // get the offset\n                        const startOffset = offset - this.toSeconds(stateEvent.time);\n                        let duration;\n                        if (stateEvent.duration) {\n                            duration = this.toSeconds(stateEvent.duration) - startOffset;\n                        }\n                        this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);\n                    }\n                }\n            };\n            this._syncedStop = time => {\n                const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));\n                if (this._state.getValueAtTime(seconds) === \"started\") {\n                    this._stop(time);\n                }\n            };\n            this.context.transport.on(\"start\", this._syncedStart);\n            this.context.transport.on(\"loopStart\", this._syncedStart);\n            this.context.transport.on(\"stop\", this._syncedStop);\n            this.context.transport.on(\"pause\", this._syncedStop);\n            this.context.transport.on(\"loopEnd\", this._syncedStop);\n        }\n        return this;\n    }\n    /**\n     * Unsync the source to the Transport. See Source.sync\n     */\n    unsync() {\n        if (this._synced) {\n            this.context.transport.off(\"stop\", this._syncedStop);\n            this.context.transport.off(\"pause\", this._syncedStop);\n            this.context.transport.off(\"loopEnd\", this._syncedStop);\n            this.context.transport.off(\"start\", this._syncedStart);\n            this.context.transport.off(\"loopStart\", this._syncedStart);\n        }\n        this._synced = false;\n        // clear all of the scheduled ids\n        this._scheduled.forEach(id => this.context.transport.clear(id));\n        this._scheduled = [];\n        this._state.cancel(0);\n        // stop it also\n        this._stop(0);\n        return this;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.onstop = _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp;\n        this.unsync();\n        this._volume.dispose();\n        this._state.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Source.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/Source.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/UserMedia.js":
/*!*********************************************************!*\
  !*** ./node_modules/tone/build/esm/source/UserMedia.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"UserMedia\": () => (/* binding */ UserMedia)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n\n\n\n\n\n\n\n/**\n * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.\n * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)\n * to see which browsers are supported. Access to an external input\n * is limited to secure (HTTPS) connections.\n * @example\n * const meter = new Tone.Meter();\n * const mic = new Tone.UserMedia().connect(meter);\n * mic.open().then(() => {\n * \t// promise resolves when input is available\n * \tconsole.log(\"mic open\");\n * \t// print the incoming mic levels in decibels\n * \tsetInterval(() => console.log(meter.getValue()), 100);\n * }).catch(e => {\n * \t// promise is rejected when the user doesn't have or allow mic access\n * \tconsole.log(\"mic not open\");\n * });\n * @category Source\n */\nclass UserMedia extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(UserMedia.getDefaults(), arguments, [\"volume\"]));\n        this.name = \"UserMedia\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(UserMedia.getDefaults(), arguments, [\"volume\"]);\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_1__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, \"volume\");\n        this.mute = options.mute;\n    }\n    static getDefaults() {\n        return Object.assign(_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.ToneAudioNode.getDefaults(), {\n            mute: false,\n            volume: 0\n        });\n    }\n    /**\n     * Open the media stream. If a string is passed in, it is assumed\n     * to be the label or id of the stream, if a number is passed in,\n     * it is the input number of the stream.\n     * @param  labelOrId The label or id of the audio input media device.\n     *                   With no argument, the default stream is opened.\n     * @return The promise is resolved when the stream is open.\n     */\n    open(labelOrId) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_6__.__awaiter)(this, void 0, void 0, function* () {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)(UserMedia.supported, \"UserMedia is not supported\");\n            // close the previous stream\n            if (this.state === \"started\") {\n                this.close();\n            }\n            const devices = yield UserMedia.enumerateDevices();\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isNumber)(labelOrId)) {\n                this._device = devices[labelOrId];\n            }\n            else {\n                this._device = devices.find((device) => {\n                    return device.label === labelOrId || device.deviceId === labelOrId;\n                });\n                // didn't find a matching device\n                if (!this._device && devices.length > 0) {\n                    this._device = devices[0];\n                }\n                (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_3__.assert)((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(this._device), `No matching device ${labelOrId}`);\n            }\n            // do getUserMedia\n            const constraints = {\n                audio: {\n                    echoCancellation: false,\n                    sampleRate: this.context.sampleRate,\n                    noiseSuppression: false,\n                    mozNoiseSuppression: false,\n                }\n            };\n            if (this._device) {\n                // @ts-ignore\n                constraints.audio.deviceId = this._device.deviceId;\n            }\n            const stream = yield navigator.mediaDevices.getUserMedia(constraints);\n            // start a new source only if the previous one is closed\n            if (!this._stream) {\n                this._stream = stream;\n                // Wrap a MediaStreamSourceNode around the live input stream.\n                const mediaStreamNode = this.context.createMediaStreamSource(stream);\n                // Connect the MediaStreamSourceNode to a gate gain node\n                (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(mediaStreamNode, this.output);\n                this._mediaStream = mediaStreamNode;\n            }\n            return this;\n        });\n    }\n    /**\n     * Close the media stream\n     */\n    close() {\n        if (this._stream && this._mediaStream) {\n            this._stream.getAudioTracks().forEach((track) => {\n                track.stop();\n            });\n            this._stream = undefined;\n            // remove the old media stream\n            this._mediaStream.disconnect();\n            this._mediaStream = undefined;\n        }\n        this._device = undefined;\n        return this;\n    }\n    /**\n     * Returns a promise which resolves with the list of audio input devices available.\n     * @return The promise that is resolved with the devices\n     * @example\n     * Tone.UserMedia.enumerateDevices().then((devices) => {\n     * \t// print the device labels\n     * \tconsole.log(devices.map(device => device.label));\n     * });\n     */\n    static enumerateDevices() {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_6__.__awaiter)(this, void 0, void 0, function* () {\n            const allDevices = yield navigator.mediaDevices.enumerateDevices();\n            return allDevices.filter(device => {\n                return device.kind === \"audioinput\";\n            });\n        });\n    }\n    /**\n     * Returns the playback state of the source, \"started\" when the microphone is open\n     * and \"stopped\" when the mic is closed.\n     */\n    get state() {\n        return this._stream && this._stream.active ? \"started\" : \"stopped\";\n    }\n    /**\n     * Returns an identifier for the represented device that is\n     * persisted across sessions. It is un-guessable by other applications and\n     * unique to the origin of the calling application. It is reset when the\n     * user clears cookies (for Private Browsing, a different identifier is\n     * used that is not persisted across sessions). Returns undefined when the\n     * device is not open.\n     */\n    get deviceId() {\n        if (this._device) {\n            return this._device.deviceId;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Returns a group identifier. Two devices have the\n     * same group identifier if they belong to the same physical device.\n     * Returns null  when the device is not open.\n     */\n    get groupId() {\n        if (this._device) {\n            return this._device.groupId;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Returns a label describing this device (for example \"Built-in Microphone\").\n     * Returns undefined when the device is not open or label is not available\n     * because of permissions.\n     */\n    get label() {\n        if (this._device) {\n            return this._device.label;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Mute the output.\n     * @example\n     * const mic = new Tone.UserMedia();\n     * mic.open().then(() => {\n     * \t// promise resolves when input is available\n     * });\n     * // mute the output\n     * mic.mute = true;\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    dispose() {\n        super.dispose();\n        this.close();\n        this._volume.dispose();\n        this.volume.dispose();\n        return this;\n    }\n    /**\n     * If getUserMedia is supported by the browser.\n     */\n    static get supported() {\n        return (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(navigator.mediaDevices) &&\n            (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(navigator.mediaDevices.getUserMedia);\n    }\n}\n//# sourceMappingURL=UserMedia.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/UserMedia.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/GrainPlayer.js":
/*!******************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/GrainPlayer.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GrainPlayer\": () => (/* binding */ GrainPlayer)\n/* harmony export */ });\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_clock_Clock__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/clock/Clock */ \"./node_modules/tone/build/esm/core/clock/Clock.js\");\n/* harmony import */ var _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _core_type_Conversions__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/type/Conversions */ \"./node_modules/tone/build/esm/core/type/Conversions.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).\n * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the\n * amount of time each small chunk of audio is played for and the overlap is the\n * amount of crossfading transition time between successive grains.\n * @category Source\n */\nclass GrainPlayer extends _Source__WEBPACK_IMPORTED_MODULE_0__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(GrainPlayer.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"GrainPlayer\";\n        /**\n         * Internal loopStart value\n         */\n        this._loopStart = 0;\n        /**\n         * Internal loopStart value\n         */\n        this._loopEnd = 0;\n        /**\n         * All of the currently playing BufferSources\n         */\n        this._activeSources = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(GrainPlayer.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this.buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer({\n            onload: options.onload,\n            onerror: options.onerror,\n            reverse: options.reverse,\n            url: options.url,\n        });\n        this._clock = new _core_clock_Clock__WEBPACK_IMPORTED_MODULE_4__.Clock({\n            context: this.context,\n            callback: this._tick.bind(this),\n            frequency: 1 / options.grainSize\n        });\n        this._playbackRate = options.playbackRate;\n        this._grainSize = options.grainSize;\n        this._overlap = options.overlap;\n        this.detune = options.detune;\n        // setup\n        this.overlap = options.overlap;\n        this.loop = options.loop;\n        this.playbackRate = options.playbackRate;\n        this.grainSize = options.grainSize;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this.reverse = options.reverse;\n        this._clock.on(\"stop\", this._onstop.bind(this));\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_0__.Source.getDefaults(), {\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp,\n            overlap: 0.1,\n            grainSize: 0.2,\n            playbackRate: 1,\n            detune: 0,\n            loop: false,\n            loopStart: 0,\n            loopEnd: 0,\n            reverse: false\n        });\n    }\n    /**\n     * Internal start method\n     */\n    _start(time, offset, duration) {\n        offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(offset, 0);\n        offset = this.toSeconds(offset);\n        time = this.toSeconds(time);\n        const grainSize = 1 / this._clock.frequency.getValueAtTime(time);\n        this._clock.start(time, offset / grainSize);\n        if (duration) {\n            this.stop(time + this.toSeconds(duration));\n        }\n    }\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time, offset, duration) {\n        super.restart(time, offset, duration);\n        return this;\n    }\n    _restart(time, offset, duration) {\n        this._stop(time);\n        this._start(time, offset, duration);\n    }\n    /**\n     * Internal stop method\n     */\n    _stop(time) {\n        this._clock.stop(time);\n    }\n    /**\n     * Invoked when the clock is stopped\n     */\n    _onstop(time) {\n        // stop the players\n        this._activeSources.forEach((source) => {\n            source.fadeOut = 0;\n            source.stop(time);\n        });\n        this.onstop(this);\n    }\n    /**\n     * Invoked on each clock tick. scheduled a new grain at this time.\n     */\n    _tick(time) {\n        // check if it should stop looping\n        const ticks = this._clock.getTicksAtTime(time);\n        const offset = ticks * this._grainSize;\n        this.log(\"offset\", offset);\n        if (!this.loop && offset > this.buffer.duration) {\n            this.stop(time);\n            return;\n        }\n        // at the beginning of the file, the fade in should be 0\n        const fadeIn = offset < this._overlap ? 0 : this._overlap;\n        // create a buffer source\n        const source = new _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__.ToneBufferSource({\n            context: this.context,\n            url: this.buffer,\n            fadeIn: fadeIn,\n            fadeOut: this._overlap,\n            loop: this.loop,\n            loopStart: this._loopStart,\n            loopEnd: this._loopEnd,\n            // compute the playbackRate based on the detune\n            playbackRate: (0,_core_type_Conversions__WEBPACK_IMPORTED_MODULE_6__.intervalToFrequencyRatio)(this.detune / 100)\n        }).connect(this.output);\n        source.start(time, this._grainSize * ticks);\n        source.stop(time + this._grainSize / this.playbackRate);\n        // add it to the active sources\n        this._activeSources.push(source);\n        // remove it when it's done\n        source.onended = () => {\n            const index = this._activeSources.indexOf(source);\n            if (index !== -1) {\n                this._activeSources.splice(index, 1);\n            }\n        };\n    }\n    /**\n     * The playback rate of the sample\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(rate, 0.001);\n        this._playbackRate = rate;\n        this.grainSize = this._grainSize;\n    }\n    /**\n     * The loop start time.\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(time) {\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(this.toSeconds(time), 0, this.buffer.duration);\n        }\n        this._loopStart = this.toSeconds(time);\n    }\n    /**\n     * The loop end time.\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(time) {\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(this.toSeconds(time), 0, this.buffer.duration);\n        }\n        this._loopEnd = this.toSeconds(time);\n    }\n    /**\n     * The direction the buffer should play in\n     */\n    get reverse() {\n        return this.buffer.reverse;\n    }\n    set reverse(rev) {\n        this.buffer.reverse = rev;\n    }\n    /**\n     * The size of each chunk of audio that the\n     * buffer is chopped into and played back at.\n     */\n    get grainSize() {\n        return this._grainSize;\n    }\n    set grainSize(size) {\n        this._grainSize = this.toSeconds(size);\n        this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());\n    }\n    /**\n     * The duration of the cross-fade between successive grains.\n     */\n    get overlap() {\n        return this._overlap;\n    }\n    set overlap(time) {\n        const computedTime = this.toSeconds(time);\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(computedTime, 0);\n        this._overlap = computedTime;\n    }\n    /**\n     * If all the buffer is loaded\n     */\n    get loaded() {\n        return this.buffer.loaded;\n    }\n    dispose() {\n        super.dispose();\n        this.buffer.dispose();\n        this._clock.dispose();\n        this._activeSources.forEach((source) => source.dispose());\n        return this;\n    }\n}\n//# sourceMappingURL=GrainPlayer.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/buffer/GrainPlayer.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/Player.js":
/*!*************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/Player.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Player\": () => (/* binding */ Player)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Decorator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../core/util/Decorator */ \"./node_modules/tone/build/esm/core/util/Decorator.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Player is an audio file player with start, loop, and stop functions.\n * @example\n * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/gong_1.mp3\").toDestination();\n * // play as soon as the buffer is loaded\n * player.autostart = true;\n * @category Source\n */\nclass Player extends _Source__WEBPACK_IMPORTED_MODULE_4__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Player.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"Player\";\n        /**\n         * All of the active buffer source nodes\n         */\n        this._activeSources = new Set();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(Player.getDefaults(), arguments, [\"url\", \"onload\"]);\n        this._buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffer({\n            onload: this._onload.bind(this, options.onload),\n            onerror: options.onerror,\n            reverse: options.reverse,\n            url: options.url,\n        });\n        this.autostart = options.autostart;\n        this._loop = options.loop;\n        this._loopStart = options.loopStart;\n        this._loopEnd = options.loopEnd;\n        this._playbackRate = options.playbackRate;\n        this.fadeIn = options.fadeIn;\n        this.fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_4__.Source.getDefaults(), {\n            autostart: false,\n            fadeIn: 0,\n            fadeOut: 0,\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp,\n            playbackRate: 1,\n            reverse: false,\n        });\n    }\n    /**\n     * Load the audio file as an audio buffer.\n     * Decodes the audio asynchronously and invokes\n     * the callback once the audio buffer loads.\n     * Note: this does not need to be called if a url\n     * was passed in to the constructor. Only use this\n     * if you want to manually load a new url.\n     * @param url The url of the buffer to load. Filetype support depends on the browser.\n     */\n    load(url) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            yield this._buffer.load(url);\n            this._onload();\n            return this;\n        });\n    }\n    /**\n     * Internal callback when the buffer is loaded.\n     */\n    _onload(callback = _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.noOp) {\n        callback();\n        if (this.autostart) {\n            this.start();\n        }\n    }\n    /**\n     * Internal callback when the buffer is done playing.\n     */\n    _onSourceEnd(source) {\n        // invoke the onstop function\n        this.onstop(this);\n        // delete the source from the active sources\n        this._activeSources.delete(source);\n        if (this._activeSources.size === 0 && !this._synced &&\n            this._state.getValueAtTime(this.now()) === \"started\") {\n            // remove the 'implicitEnd' event and replace with an explicit end\n            this._state.cancel(this.now());\n            this._state.setStateAtTime(\"stopped\", this.now());\n        }\n    }\n    /**\n     * Play the buffer at the given startTime. Optionally add an offset\n     * and/or duration which will play the buffer from a position\n     * within the buffer for the given duration.\n     *\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     */\n    start(time, offset, duration) {\n        super.start(time, offset, duration);\n        return this;\n    }\n    /**\n     * Internal start method\n     */\n    _start(startTime, offset, duration) {\n        // if it's a loop the default offset is the loopStart point\n        if (this._loop) {\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.defaultArg)(offset, this._loopStart);\n        }\n        else {\n            // otherwise the default offset is 0\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.defaultArg)(offset, 0);\n        }\n        // compute the values in seconds\n        const computedOffset = this.toSeconds(offset);\n        // compute the duration which is either the passed in duration of the buffer.duration - offset\n        const origDuration = duration;\n        duration = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.defaultArg)(duration, Math.max(this._buffer.duration - computedOffset, 0));\n        let computedDuration = this.toSeconds(duration);\n        // scale it by the playback rate\n        computedDuration = computedDuration / this._playbackRate;\n        // get the start time\n        startTime = this.toSeconds(startTime);\n        // make the source\n        const source = new _ToneBufferSource__WEBPACK_IMPORTED_MODULE_5__.ToneBufferSource({\n            url: this._buffer,\n            context: this.context,\n            fadeIn: this.fadeIn,\n            fadeOut: this.fadeOut,\n            loop: this._loop,\n            loopEnd: this._loopEnd,\n            loopStart: this._loopStart,\n            onended: this._onSourceEnd.bind(this),\n            playbackRate: this._playbackRate,\n        }).connect(this.output);\n        // set the looping properties\n        if (!this._loop && !this._synced) {\n            // cancel the previous stop\n            this._state.cancel(startTime + computedDuration);\n            // if it's not looping, set the state change at the end of the sample\n            this._state.setStateAtTime(\"stopped\", startTime + computedDuration, {\n                implicitEnd: true,\n            });\n        }\n        // add it to the array of active sources\n        this._activeSources.add(source);\n        // start it\n        if (this._loop && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_3__.isUndef)(origDuration)) {\n            source.start(startTime, computedOffset);\n        }\n        else {\n            // subtract the fade out time\n            source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));\n        }\n    }\n    /**\n     * Stop playback.\n     */\n    _stop(time) {\n        const computedTime = this.toSeconds(time);\n        this._activeSources.forEach(source => source.stop(computedTime));\n    }\n    /**\n     * Stop and then restart the player from the beginning (or offset)\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given,\n     * \t\t\t\t\tit will default to the full length of the sample (minus any offset)\n     */\n    restart(time, offset, duration) {\n        super.restart(time, offset, duration);\n        return this;\n    }\n    _restart(time, offset, duration) {\n        this._stop(time);\n        this._start(time, offset, duration);\n    }\n    /**\n     * Seek to a specific time in the player's buffer. If the\n     * source is no longer playing at that time, it will stop.\n     * @param offset The time to seek to.\n     * @param when The time for the seek event to occur.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3\", () => {\n     * \tplayer.start();\n     * \t// seek to the offset in 1 second from now\n     * \tplayer.seek(0.4, \"+1\");\n     * }).toDestination();\n     */\n    seek(offset, when) {\n        const computedTime = this.toSeconds(when);\n        if (this._state.getValueAtTime(computedTime) === \"started\") {\n            const computedOffset = this.toSeconds(offset);\n            // if it's currently playing, stop it\n            this._stop(computedTime);\n            // restart it at the given time\n            this._start(computedTime, computedOffset);\n        }\n        return this;\n    }\n    /**\n     * Set the loop start and end. Will only loop if loop is set to true.\n     * @param loopStart The loop start time\n     * @param loopEnd The loop end time\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3\").toDestination();\n     * // loop between the given points\n     * player.setLoopPoints(0.2, 0.3);\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    setLoopPoints(loopStart, loopEnd) {\n        this.loopStart = loopStart;\n        this.loopEnd = loopEnd;\n        return this;\n    }\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart() {\n        return this._loopStart;\n    }\n    set loopStart(loopStart) {\n        this._loopStart = loopStart;\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertRange)(this.toSeconds(loopStart), 0, this.buffer.duration);\n        }\n        // get the current source\n        this._activeSources.forEach(source => {\n            source.loopStart = loopStart;\n        });\n    }\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd() {\n        return this._loopEnd;\n    }\n    set loopEnd(loopEnd) {\n        this._loopEnd = loopEnd;\n        if (this.buffer.loaded) {\n            (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertRange)(this.toSeconds(loopEnd), 0, this.buffer.duration);\n        }\n        // get the current source\n        this._activeSources.forEach(source => {\n            source.loopEnd = loopEnd;\n        });\n    }\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer() {\n        return this._buffer;\n    }\n    set buffer(buffer) {\n        this._buffer.set(buffer);\n    }\n    /**\n     * If the buffer should loop once it's over.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/drum-samples/breakbeat.mp3\").toDestination();\n     * player.loop = true;\n     * player.autostart = true;\n     */\n    get loop() {\n        return this._loop;\n    }\n    set loop(loop) {\n        // if no change, do nothing\n        if (this._loop === loop) {\n            return;\n        }\n        this._loop = loop;\n        // set the loop of all of the sources\n        this._activeSources.forEach(source => {\n            source.loop = loop;\n        });\n        if (loop) {\n            // remove the next stopEvent\n            const stopEvent = this._state.getNextState(\"stopped\", this.now());\n            if (stopEvent) {\n                this._state.cancel(stopEvent.time);\n            }\n        }\n    }\n    /**\n     * Normal speed is 1. The pitch will change with the playback rate.\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3\").toDestination();\n     * // play at 1/4 speed\n     * player.playbackRate = 0.25;\n     * // play as soon as the buffer is loaded\n     * player.autostart = true;\n     */\n    get playbackRate() {\n        return this._playbackRate;\n    }\n    set playbackRate(rate) {\n        this._playbackRate = rate;\n        const now = this.now();\n        // cancel the stop event since it's at a different time now\n        const stopEvent = this._state.getNextState(\"stopped\", now);\n        if (stopEvent && stopEvent.implicitEnd) {\n            this._state.cancel(stopEvent.time);\n            this._activeSources.forEach(source => source.cancelStop());\n        }\n        // set all the sources\n        this._activeSources.forEach(source => {\n            source.playbackRate.setValueAtTime(rate, now);\n        });\n    }\n    /**\n     * If the buffer should be reversed\n     * @example\n     * const player = new Tone.Player(\"https://tonejs.github.io/audio/berklee/chime_1.mp3\").toDestination();\n     * player.autostart = true;\n     * player.reverse = true;\n     */\n    get reverse() {\n        return this._buffer.reverse;\n    }\n    set reverse(rev) {\n        this._buffer.reverse = rev;\n    }\n    /**\n     * If the buffer is loaded\n     */\n    get loaded() {\n        return this._buffer.loaded;\n    }\n    dispose() {\n        super.dispose();\n        // disconnect all of the players\n        this._activeSources.forEach(source => source.dispose());\n        this._activeSources.clear();\n        this._buffer.dispose();\n        return this;\n    }\n}\n(0,tslib__WEBPACK_IMPORTED_MODULE_8__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_7__.timeRange)(0)\n], Player.prototype, \"fadeIn\", void 0);\n(0,tslib__WEBPACK_IMPORTED_MODULE_8__.__decorate)([\n    (0,_core_util_Decorator__WEBPACK_IMPORTED_MODULE_7__.timeRange)(0)\n], Player.prototype, \"fadeOut\", void 0);\n//# sourceMappingURL=Player.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/buffer/Player.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/Players.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/Players.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Players\": () => (/* binding */ Players)\n/* harmony export */ });\n/* harmony import */ var _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../component/channel/Volume */ \"./node_modules/tone/build/esm/component/channel/Volume.js\");\n/* harmony import */ var _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffers */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffers.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Player__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Player */ \"./node_modules/tone/build/esm/source/buffer/Player.js\");\n\n\n\n\n\n\n\n\n/**\n * Players combines multiple [[Player]] objects.\n * @category Source\n */\nclass Players extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Players.getDefaults(), arguments, [\"urls\", \"onload\"], \"urls\"));\n        this.name = \"Players\";\n        /**\n         * Players has no input.\n         */\n        this.input = undefined;\n        /**\n         * The container of all of the players\n         */\n        this._players = new Map();\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(Players.getDefaults(), arguments, [\"urls\", \"onload\"], \"urls\");\n        /**\n         * The output volume node\n         */\n        this._volume = this.output = new _component_channel_Volume__WEBPACK_IMPORTED_MODULE_0__.Volume({\n            context: this.context,\n            volume: options.volume,\n        });\n        this.volume = this._volume.volume;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.readOnly)(this, \"volume\");\n        this._buffers = new _core_context_ToneAudioBuffers__WEBPACK_IMPORTED_MODULE_1__.ToneAudioBuffers({\n            urls: options.urls,\n            onload: options.onload,\n            baseUrl: options.baseUrl,\n            onerror: options.onerror\n        });\n        // mute initially\n        this.mute = options.mute;\n        this._fadeIn = options.fadeIn;\n        this._fadeOut = options.fadeOut;\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_6__.Source.getDefaults(), {\n            baseUrl: \"\",\n            fadeIn: 0,\n            fadeOut: 0,\n            mute: false,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_5__.noOp,\n            urls: {},\n            volume: 0,\n        });\n    }\n    /**\n     * Mute the output.\n     */\n    get mute() {\n        return this._volume.mute;\n    }\n    set mute(mute) {\n        this._volume.mute = mute;\n    }\n    /**\n     * The fadeIn time of the envelope applied to the source.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(fadeIn) {\n        this._fadeIn = fadeIn;\n        this._players.forEach(player => {\n            player.fadeIn = fadeIn;\n        });\n    }\n    /**\n     * The fadeOut time of the each of the sources.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(fadeOut) {\n        this._fadeOut = fadeOut;\n        this._players.forEach(player => {\n            player.fadeOut = fadeOut;\n        });\n    }\n    /**\n     * The state of the players object. Returns \"started\" if any of the players are playing.\n     */\n    get state() {\n        const playing = Array.from(this._players).some(([_, player]) => player.state === \"started\");\n        return playing ? \"started\" : \"stopped\";\n    }\n    /**\n     * True if the buffers object has a buffer by that name.\n     * @param name  The key or index of the buffer.\n     */\n    has(name) {\n        return this._buffers.has(name);\n    }\n    /**\n     * Get a player by name.\n     * @param  name  The players name as defined in the constructor object or `add` method.\n     */\n    player(name) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(this.has(name), `No Player with the name ${name} exists on this object`);\n        if (!this._players.has(name)) {\n            const player = new _Player__WEBPACK_IMPORTED_MODULE_7__.Player({\n                context: this.context,\n                fadeIn: this._fadeIn,\n                fadeOut: this._fadeOut,\n                url: this._buffers.get(name),\n            }).connect(this.output);\n            this._players.set(name, player);\n        }\n        return this._players.get(name);\n    }\n    /**\n     * If all the buffers are loaded or not\n     */\n    get loaded() {\n        return this._buffers.loaded;\n    }\n    /**\n     * Add a player by name and url to the Players\n     * @param  name A unique name to give the player\n     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.\n     * @param callback  The callback to invoke when the url is loaded.\n     */\n    add(name, url, callback) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_4__.assert)(!this._buffers.has(name), \"A buffer with that name already exists on this object\");\n        this._buffers.add(name, url, callback);\n        return this;\n    }\n    /**\n     * Stop all of the players at the given time\n     * @param time The time to stop all of the players.\n     */\n    stopAll(time) {\n        this._players.forEach(player => player.stop(time));\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._volume.dispose();\n        this.volume.dispose();\n        this._players.forEach(player => player.dispose());\n        this._buffers.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=Players.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/buffer/Players.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneBufferSource\": () => (/* binding */ ToneBufferSource)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioBuffer */ \"./node_modules/tone/build/esm/core/context/ToneAudioBuffer.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _OneShotSource__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../OneShotSource */ \"./node_modules/tone/build/esm/source/OneShotSource.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n\n/**\n * Wrapper around the native BufferSourceNode.\n * @category Source\n */\nclass ToneBufferSource extends _OneShotSource__WEBPACK_IMPORTED_MODULE_7__.OneShotSource {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneBufferSource.getDefaults(), arguments, [\"url\", \"onload\"]));\n        this.name = \"ToneBufferSource\";\n        /**\n         * The oscillator\n         */\n        this._source = this.context.createBufferSource();\n        this._internalChannels = [this._source];\n        /**\n         * indicators if the source has started/stopped\n         */\n        this._sourceStarted = false;\n        this._sourceStopped = false;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(ToneBufferSource.getDefaults(), arguments, [\"url\", \"onload\"]);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(this._source, this._gainNode);\n        this._source.onended = () => this._stopSource();\n        /**\n         * The playbackRate of the buffer\n         */\n        this.playbackRate = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this._source.playbackRate,\n            units: \"positive\",\n            value: options.playbackRate,\n        });\n        // set some values initially\n        this.loop = options.loop;\n        this.loopStart = options.loopStart;\n        this.loopEnd = options.loopEnd;\n        this._buffer = new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer(options.url, options.onload, options.onerror);\n        this._internalChannels.push(this._source);\n    }\n    static getDefaults() {\n        return Object.assign(_OneShotSource__WEBPACK_IMPORTED_MODULE_7__.OneShotSource.getDefaults(), {\n            url: new _core_context_ToneAudioBuffer__WEBPACK_IMPORTED_MODULE_2__.ToneAudioBuffer(),\n            loop: false,\n            loopEnd: 0,\n            loopStart: 0,\n            onload: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            onerror: _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.noOp,\n            playbackRate: 1,\n        });\n    }\n    /**\n     * The fadeIn time of the amplitude envelope.\n     */\n    get fadeIn() {\n        return this._fadeIn;\n    }\n    set fadeIn(t) {\n        this._fadeIn = t;\n    }\n    /**\n     * The fadeOut time of the amplitude envelope.\n     */\n    get fadeOut() {\n        return this._fadeOut;\n    }\n    set fadeOut(t) {\n        this._fadeOut = t;\n    }\n    /**\n     * The curve applied to the fades, either \"linear\" or \"exponential\"\n     */\n    get curve() {\n        return this._curve;\n    }\n    set curve(t) {\n        this._curve = t;\n    }\n    /**\n     * Start the buffer\n     * @param  time When the player should start.\n     * @param  offset The offset from the beginning of the sample to start at.\n     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)\n     * @param  gain  The gain to play the buffer back at.\n     */\n    start(time, offset, duration, gain = 1) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assert)(this.buffer.loaded, \"buffer is either not set or not loaded\");\n        const computedTime = this.toSeconds(time);\n        // apply the gain envelope\n        this._startGain(computedTime, gain);\n        // if it's a loop the default offset is the loopstart point\n        if (this.loop) {\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(offset, this.loopStart);\n        }\n        else {\n            // otherwise the default offset is 0\n            offset = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.defaultArg)(offset, 0);\n        }\n        // make sure the offset is not less than 0\n        let computedOffset = Math.max(this.toSeconds(offset), 0);\n        // start the buffer source\n        if (this.loop) {\n            // modify the offset if it's greater than the loop time\n            const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;\n            const loopStart = this.toSeconds(this.loopStart);\n            const loopDuration = loopEnd - loopStart;\n            // move the offset back\n            if ((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.GTE)(computedOffset, loopEnd)) {\n                computedOffset = ((computedOffset - loopStart) % loopDuration) + loopStart;\n            }\n            // when the offset is very close to the duration, set it to 0\n            if ((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.EQ)(computedOffset, this.buffer.duration)) {\n                computedOffset = 0;\n            }\n        }\n        // this.buffer.loaded would have return false if the AudioBuffer was undefined\n        this._source.buffer = this.buffer.get();\n        this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;\n        if ((0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.LT)(computedOffset, this.buffer.duration)) {\n            this._sourceStarted = true;\n            this._source.start(computedTime, computedOffset);\n        }\n        // if a duration is given, schedule a stop\n        if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_5__.isDefined)(duration)) {\n            let computedDur = this.toSeconds(duration);\n            // make sure it's never negative\n            computedDur = Math.max(computedDur, 0);\n            this.stop(computedTime + computedDur);\n        }\n        return this;\n    }\n    _stopSource(time) {\n        if (!this._sourceStopped && this._sourceStarted) {\n            this._sourceStopped = true;\n            this._source.stop(this.toSeconds(time));\n            this._onended();\n        }\n    }\n    /**\n     * If loop is true, the loop will start at this position.\n     */\n    get loopStart() {\n        return this._source.loopStart;\n    }\n    set loopStart(loopStart) {\n        this._source.loopStart = this.toSeconds(loopStart);\n    }\n    /**\n     * If loop is true, the loop will end at this position.\n     */\n    get loopEnd() {\n        return this._source.loopEnd;\n    }\n    set loopEnd(loopEnd) {\n        this._source.loopEnd = this.toSeconds(loopEnd);\n    }\n    /**\n     * The audio buffer belonging to the player.\n     */\n    get buffer() {\n        return this._buffer;\n    }\n    set buffer(buffer) {\n        this._buffer.set(buffer);\n    }\n    /**\n     * If the buffer should loop once it's over.\n     */\n    get loop() {\n        return this._source.loop;\n    }\n    set loop(loop) {\n        this._source.loop = loop;\n        if (this._sourceStarted) {\n            this.cancelStop();\n        }\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._source.onended = null;\n        this._source.disconnect();\n        this._buffer.dispose();\n        this.playbackRate.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneBufferSource.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/index.js":
/*!*****************************************************!*\
  !*** ./node_modules/tone/build/esm/source/index.js ***!
  \*****************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* reexport safe */ _oscillator_AMOscillator__WEBPACK_IMPORTED_MODULE_3__.AMOscillator),\n/* harmony export */   \"FMOscillator\": () => (/* reexport safe */ _oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_4__.FMOscillator),\n/* harmony export */   \"FatOscillator\": () => (/* reexport safe */ _oscillator_FatOscillator__WEBPACK_IMPORTED_MODULE_6__.FatOscillator),\n/* harmony export */   \"GrainPlayer\": () => (/* reexport safe */ _buffer_GrainPlayer__WEBPACK_IMPORTED_MODULE_14__.GrainPlayer),\n/* harmony export */   \"LFO\": () => (/* reexport safe */ _oscillator_LFO__WEBPACK_IMPORTED_MODULE_10__.LFO),\n/* harmony export */   \"Noise\": () => (/* reexport safe */ _Noise__WEBPACK_IMPORTED_MODULE_0__.Noise),\n/* harmony export */   \"OmniOscillator\": () => (/* reexport safe */ _oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_8__.OmniOscillator),\n/* harmony export */   \"Oscillator\": () => (/* reexport safe */ _oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_2__.Oscillator),\n/* harmony export */   \"PWMOscillator\": () => (/* reexport safe */ _oscillator_PWMOscillator__WEBPACK_IMPORTED_MODULE_7__.PWMOscillator),\n/* harmony export */   \"Player\": () => (/* reexport safe */ _buffer_Player__WEBPACK_IMPORTED_MODULE_12__.Player),\n/* harmony export */   \"Players\": () => (/* reexport safe */ _buffer_Players__WEBPACK_IMPORTED_MODULE_13__.Players),\n/* harmony export */   \"PulseOscillator\": () => (/* reexport safe */ _oscillator_PulseOscillator__WEBPACK_IMPORTED_MODULE_5__.PulseOscillator),\n/* harmony export */   \"ToneBufferSource\": () => (/* reexport safe */ _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_11__.ToneBufferSource),\n/* harmony export */   \"ToneOscillatorNode\": () => (/* reexport safe */ _oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_9__.ToneOscillatorNode),\n/* harmony export */   \"UserMedia\": () => (/* reexport safe */ _UserMedia__WEBPACK_IMPORTED_MODULE_1__.UserMedia)\n/* harmony export */ });\n/* harmony import */ var _Noise__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Noise */ \"./node_modules/tone/build/esm/source/Noise.js\");\n/* harmony import */ var _UserMedia__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./UserMedia */ \"./node_modules/tone/build/esm/source/UserMedia.js\");\n/* harmony import */ var _oscillator_Oscillator__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./oscillator/Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _oscillator_AMOscillator__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./oscillator/AMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/AMOscillator.js\");\n/* harmony import */ var _oscillator_FMOscillator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./oscillator/FMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FMOscillator.js\");\n/* harmony import */ var _oscillator_PulseOscillator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./oscillator/PulseOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js\");\n/* harmony import */ var _oscillator_FatOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./oscillator/FatOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FatOscillator.js\");\n/* harmony import */ var _oscillator_PWMOscillator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./oscillator/PWMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js\");\n/* harmony import */ var _oscillator_OmniOscillator__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./oscillator/OmniOscillator */ \"./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js\");\n/* harmony import */ var _oscillator_ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./oscillator/ToneOscillatorNode */ \"./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js\");\n/* harmony import */ var _oscillator_LFO__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./oscillator/LFO */ \"./node_modules/tone/build/esm/source/oscillator/LFO.js\");\n/* harmony import */ var _buffer_ToneBufferSource__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./buffer/ToneBufferSource */ \"./node_modules/tone/build/esm/source/buffer/ToneBufferSource.js\");\n/* harmony import */ var _buffer_Player__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! ./buffer/Player */ \"./node_modules/tone/build/esm/source/buffer/Player.js\");\n/* harmony import */ var _buffer_Players__WEBPACK_IMPORTED_MODULE_13__ = __webpack_require__(/*! ./buffer/Players */ \"./node_modules/tone/build/esm/source/buffer/Players.js\");\n/* harmony import */ var _buffer_GrainPlayer__WEBPACK_IMPORTED_MODULE_14__ = __webpack_require__(/*! ./buffer/GrainPlayer */ \"./node_modules/tone/build/esm/source/buffer/GrainPlayer.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/index.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/AMOscillator.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/AMOscillator.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AMOscillator\": () => (/* binding */ AMOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n\n\n\n\n\n\n\n\n\n/**\n * An amplitude modulated oscillator node. It is implemented with\n * two oscillators, one which modulators the other's amplitude\n * through a gain node.\n * ```\n *    +-------------+       +----------+\n *    | Carrier Osc +>------> GainNode |\n *    +-------------+       |          +--->Output\n *                      +---> gain     |\n * +---------------+    |   +----------+\n * | Modulator Osc +>---+\n * +---------------+\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst amOsc = new Tone.AMOscillator(30, \"sine\", \"square\").toDestination().start();\n * }, 0.2, 1);\n * @category Source\n */\nclass AMOscillator extends _Source__WEBPACK_IMPORTED_MODULE_5__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]));\n        this.name = \"AMOscillator\";\n        /**\n         * convert the -1,1 output to 0,1\n         */\n        this._modulationScale = new _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_3__.AudioToGain({ context: this.context });\n        /**\n         * the node where the modulation happens\n         */\n        this._modulationNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(AMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]);\n        this._carrier = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: options.type,\n        });\n        this.frequency = this._carrier.frequency,\n            this.detune = this._carrier.detune;\n        this._modulator = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            phase: options.phase,\n            type: options.modulationType,\n        });\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_4__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        // connections\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this._modulator.chain(this._modulationScale, this._modulationNode.gain);\n        this._carrier.chain(this._modulationNode, this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"frequency\", \"detune\", \"harmonicity\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator.getDefaults(), {\n            harmonicity: 1,\n            modulationType: \"square\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._modulator.start(time);\n        this._carrier.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        this._modulator.stop(time);\n        this._carrier.stop(time);\n    }\n    _restart(time) {\n        this._modulator.restart(time);\n        this._carrier.restart(time);\n    }\n    /**\n     * The type of the carrier oscillator\n     */\n    get type() {\n        return this._carrier.type;\n    }\n    set type(type) {\n        this._carrier.type = type;\n    }\n    get baseType() {\n        return this._carrier.baseType;\n    }\n    set baseType(baseType) {\n        this._carrier.baseType = baseType;\n    }\n    get partialCount() {\n        return this._carrier.partialCount;\n    }\n    set partialCount(partialCount) {\n        this._carrier.partialCount = partialCount;\n    }\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType() {\n        return this._modulator.type;\n    }\n    set modulationType(type) {\n        this._modulator.type = type;\n    }\n    get phase() {\n        return this._carrier.phase;\n    }\n    set phase(phase) {\n        this._carrier.phase = phase;\n        this._modulator.phase = phase;\n    }\n    get partials() {\n        return this._carrier.partials;\n    }\n    set partials(partials) {\n        this._carrier.partials = partials;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this.harmonicity.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this._modulationNode.dispose();\n        this._modulationScale.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=AMOscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/AMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/FMOscillator.js":
/*!***********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/FMOscillator.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FMOscillator\": () => (/* binding */ FMOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n\n\n\n\n\n\n\n\n\n/**\n * FMOscillator implements a frequency modulation synthesis\n * ```\n *                                              +-------------+\n * +---------------+        +-------------+     | Carrier Osc |\n * | Modulator Osc +>-------> GainNode    |     |             +--->Output\n * +---------------+        |             +>----> frequency   |\n *                       +--> gain        |     +-------------+\n *                       |  +-------------+\n * +-----------------+   |\n * | modulationIndex +>--+\n * +-----------------+\n * ```\n *\n * @example\n * return Tone.Offline(() => {\n * \tconst fmOsc = new Tone.FMOscillator({\n * \t\tfrequency: 200,\n * \t\ttype: \"square\",\n * \t\tmodulationType: \"triangle\",\n * \t\tharmonicity: 0.2,\n * \t\tmodulationIndex: 3\n * \t}).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass FMOscillator extends _Source__WEBPACK_IMPORTED_MODULE_5__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]));\n        this.name = \"FMOscillator\";\n        /**\n         * the node where the modulation happens\n         */\n        this._modulationNode = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(FMOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"modulationType\"]);\n        this._carrier = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: 0,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: options.type,\n        });\n        this.detune = this._carrier.detune;\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_4__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this._modulator = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            phase: options.phase,\n            type: options.modulationType,\n        });\n        this.harmonicity = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.harmonicity,\n        });\n        this.modulationIndex = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_3__.Multiply({\n            context: this.context,\n            units: \"positive\",\n            value: options.modulationIndex,\n        });\n        // connections\n        this.frequency.connect(this._carrier.frequency);\n        this.frequency.chain(this.harmonicity, this._modulator.frequency);\n        this.frequency.chain(this.modulationIndex, this._modulationNode);\n        this._modulator.connect(this._modulationNode.gain);\n        this._modulationNode.connect(this._carrier.frequency);\n        this._carrier.connect(this.output);\n        this.detune.connect(this._modulator.detune);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"modulationIndex\", \"frequency\", \"detune\", \"harmonicity\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator.getDefaults(), {\n            harmonicity: 1,\n            modulationIndex: 2,\n            modulationType: \"square\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._modulator.start(time);\n        this._carrier.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        this._modulator.stop(time);\n        this._carrier.stop(time);\n    }\n    _restart(time) {\n        this._modulator.restart(time);\n        this._carrier.restart(time);\n        return this;\n    }\n    get type() {\n        return this._carrier.type;\n    }\n    set type(type) {\n        this._carrier.type = type;\n    }\n    get baseType() {\n        return this._carrier.baseType;\n    }\n    set baseType(baseType) {\n        this._carrier.baseType = baseType;\n    }\n    get partialCount() {\n        return this._carrier.partialCount;\n    }\n    set partialCount(partialCount) {\n        this._carrier.partialCount = partialCount;\n    }\n    /**\n     * The type of the modulator oscillator\n     */\n    get modulationType() {\n        return this._modulator.type;\n    }\n    set modulationType(type) {\n        this._modulator.type = type;\n    }\n    get phase() {\n        return this._carrier.phase;\n    }\n    set phase(phase) {\n        this._carrier.phase = phase;\n        this._modulator.phase = phase;\n    }\n    get partials() {\n        return this._carrier.partials;\n    }\n    set partials(partials) {\n        this._carrier.partials = partials;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.harmonicity.dispose();\n        this._carrier.dispose();\n        this._modulator.dispose();\n        this._modulationNode.dispose();\n        this.modulationIndex.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=FMOscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/FMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/FatOscillator.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/FatOscillator.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"FatOscillator\": () => (/* binding */ FatOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n\n\n\n\n\n\n\n\n/**\n * FatOscillator is an array of oscillators with detune spread between the oscillators\n * @example\n * const fatOsc = new Tone.FatOscillator(\"Ab3\", \"sawtooth\", 40).toDestination().start();\n * @category Source\n */\nclass FatOscillator extends _Source__WEBPACK_IMPORTED_MODULE_3__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FatOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"spread\"]));\n        this.name = \"FatOscillator\";\n        /**\n         * The array of oscillators\n         */\n        this._oscillators = [];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(FatOscillator.getDefaults(), arguments, [\"frequency\", \"type\", \"spread\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_2__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        this._spread = options.spread;\n        this._type = options.type;\n        this._phase = options.phase;\n        this._partials = options.partials;\n        this._partialCount = options.partialCount;\n        // set the count initially\n        this.count = options.count;\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_4__.Oscillator.getDefaults(), {\n            count: 3,\n            spread: 20,\n            type: \"sawtooth\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._forEach(osc => osc.start(time));\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._forEach(osc => osc.stop(time));\n    }\n    _restart(time) {\n        this._forEach(osc => osc.restart(time));\n    }\n    /**\n     * Iterate over all of the oscillators\n     */\n    _forEach(iterator) {\n        for (let i = 0; i < this._oscillators.length; i++) {\n            iterator(this._oscillators[i], i);\n        }\n    }\n    /**\n     * The type of the oscillator\n     */\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._type = type;\n        this._forEach(osc => osc.type = type);\n    }\n    /**\n     * The detune spread between the oscillators. If \"count\" is\n     * set to 3 oscillators and the \"spread\" is set to 40,\n     * the three oscillators would be detuned like this: [-20, 0, 20]\n     * for a total detune spread of 40 cents.\n     * @example\n     * const fatOsc = new Tone.FatOscillator().toDestination().start();\n     * fatOsc.spread = 70;\n     */\n    get spread() {\n        return this._spread;\n    }\n    set spread(spread) {\n        this._spread = spread;\n        if (this._oscillators.length > 1) {\n            const start = -spread / 2;\n            const step = spread / (this._oscillators.length - 1);\n            this._forEach((osc, i) => osc.detune.value = start + step * i);\n        }\n    }\n    /**\n     * The number of detuned oscillators. Must be an integer greater than 1.\n     * @example\n     * const fatOsc = new Tone.FatOscillator(\"C#3\", \"sawtooth\").toDestination().start();\n     * // use 4 sawtooth oscillators\n     * fatOsc.count = 4;\n     */\n    get count() {\n        return this._oscillators.length;\n    }\n    set count(count) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_6__.assertRange)(count, 1);\n        if (this._oscillators.length !== count) {\n            // dispose the previous oscillators\n            this._forEach(osc => osc.dispose());\n            this._oscillators = [];\n            for (let i = 0; i < count; i++) {\n                const osc = new _Oscillator__WEBPACK_IMPORTED_MODULE_4__.Oscillator({\n                    context: this.context,\n                    volume: -6 - count * 1.1,\n                    type: this._type,\n                    phase: this._phase + (i / count) * 360,\n                    partialCount: this._partialCount,\n                    onstop: i === 0 ? () => this.onstop(this) : _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.noOp,\n                });\n                if (this.type === \"custom\") {\n                    osc.partials = this._partials;\n                }\n                this.frequency.connect(osc.frequency);\n                this.detune.connect(osc.detune);\n                osc.detune.overridden = false;\n                osc.connect(this.output);\n                this._oscillators[i] = osc;\n            }\n            // set the spread\n            this.spread = this._spread;\n            if (this.state === \"started\") {\n                this._forEach(osc => osc.start());\n            }\n        }\n    }\n    get phase() {\n        return this._phase;\n    }\n    set phase(phase) {\n        this._phase = phase;\n        this._forEach((osc, i) => osc.phase = this._phase + (i / this.count) * 360);\n    }\n    get baseType() {\n        return this._oscillators[0].baseType;\n    }\n    set baseType(baseType) {\n        this._forEach(osc => osc.baseType = baseType);\n        this._type = this._oscillators[0].type;\n    }\n    get partials() {\n        return this._oscillators[0].partials;\n    }\n    set partials(partials) {\n        this._partials = partials;\n        this._partialCount = this._partials.length;\n        if (partials.length) {\n            this._type = \"custom\";\n            this._forEach(osc => osc.partials = partials);\n        }\n    }\n    get partialCount() {\n        return this._oscillators[0].partialCount;\n    }\n    set partialCount(partialCount) {\n        this._partialCount = partialCount;\n        this._forEach(osc => osc.partialCount = partialCount);\n        this._type = this._oscillators[0].type;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this.frequency.dispose();\n        this.detune.dispose();\n        this._forEach(osc => osc.dispose());\n        return this;\n    }\n}\n//# sourceMappingURL=FatOscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/FatOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/LFO.js":
/*!**************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/LFO.js ***!
  \**************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"LFO\": () => (/* binding */ LFO)\n/* harmony export */ });\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../signal/AudioToGain */ \"./node_modules/tone/build/esm/signal/AudioToGain.js\");\n/* harmony import */ var _signal_Scale__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../signal/Scale */ \"./node_modules/tone/build/esm/signal/Scale.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_Zero__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../signal/Zero */ \"./node_modules/tone/build/esm/signal/Zero.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * LFO stands for low frequency oscillator. LFO produces an output signal\n * which can be attached to an AudioParam or Tone.Signal\n * in order to modulate that parameter with an oscillator. The LFO can\n * also be synced to the transport to start/stop and change when the tempo changes.\n * @example\n * return Tone.Offline(() => {\n * \tconst lfo = new Tone.LFO(\"4n\", 400, 4000).start().toDestination();\n * }, 0.5, 1);\n * @category Source\n */\nclass LFO extends _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_2__.ToneAudioNode {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(LFO.getDefaults(), arguments, [\"frequency\", \"min\", \"max\"]));\n        this.name = \"LFO\";\n        /**\n         * The value that the LFO outputs when it's stopped\n         */\n        this._stoppedValue = 0;\n        /**\n         * A private placeholder for the units\n         */\n        this._units = \"number\";\n        /**\n         * If the input value is converted using the [[units]]\n         */\n        this.convert = true;\n        /**\n         * Private methods borrowed from Param\n         */\n        // @ts-ignore\n        this._fromType = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._fromType;\n        // @ts-ignore\n        this._toType = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._toType;\n        // @ts-ignore\n        this._is = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._is;\n        // @ts-ignore\n        this._clampValue = _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param.prototype._clampValue;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_3__.optionsFromArguments)(LFO.getDefaults(), arguments, [\"frequency\", \"min\", \"max\"]);\n        this._oscillator = new _Oscillator__WEBPACK_IMPORTED_MODULE_9__.Oscillator(options);\n        this.frequency = this._oscillator.frequency;\n        this._amplitudeGain = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: options.amplitude,\n            units: \"normalRange\",\n        });\n        this.amplitude = this._amplitudeGain.gain;\n        this._stoppedSignal = new _signal_Signal__WEBPACK_IMPORTED_MODULE_7__.Signal({\n            context: this.context,\n            units: \"audioRange\",\n            value: 0,\n        });\n        this._zeros = new _signal_Zero__WEBPACK_IMPORTED_MODULE_8__.Zero({ context: this.context });\n        this._a2g = new _signal_AudioToGain__WEBPACK_IMPORTED_MODULE_5__.AudioToGain({ context: this.context });\n        this._scaler = this.output = new _signal_Scale__WEBPACK_IMPORTED_MODULE_6__.Scale({\n            context: this.context,\n            max: options.max,\n            min: options.min,\n        });\n        this.units = options.units;\n        this.min = options.min;\n        this.max = options.max;\n        // connect it up\n        this._oscillator.chain(this._amplitudeGain, this._a2g, this._scaler);\n        this._zeros.connect(this._a2g);\n        this._stoppedSignal.connect(this._a2g);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"amplitude\", \"frequency\"]);\n        this.phase = options.phase;\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_9__.Oscillator.getDefaults(), {\n            amplitude: 1,\n            frequency: \"4n\",\n            max: 1,\n            min: 0,\n            type: \"sine\",\n            units: \"number\",\n        });\n    }\n    /**\n     * Start the LFO.\n     * @param time The time the LFO will start\n     */\n    start(time) {\n        time = this.toSeconds(time);\n        this._stoppedSignal.setValueAtTime(0, time);\n        this._oscillator.start(time);\n        return this;\n    }\n    /**\n     * Stop the LFO.\n     * @param  time The time the LFO will stop\n     */\n    stop(time) {\n        time = this.toSeconds(time);\n        this._stoppedSignal.setValueAtTime(this._stoppedValue, time);\n        this._oscillator.stop(time);\n        return this;\n    }\n    /**\n     * Sync the start/stop/pause to the transport\n     * and the frequency to the bpm of the transport\n     * @example\n     * const lfo = new Tone.LFO(\"8n\");\n     * lfo.sync().start(0);\n     * // the rate of the LFO will always be an eighth note, even as the tempo changes\n     */\n    sync() {\n        this._oscillator.sync();\n        this._oscillator.syncFrequency();\n        return this;\n    }\n    /**\n     * unsync the LFO from transport control\n     */\n    unsync() {\n        this._oscillator.unsync();\n        this._oscillator.unsyncFrequency();\n        return this;\n    }\n    /**\n     * After the oscillator waveform is updated, reset the `_stoppedSignal` value to match the updated waveform\n     */\n    _setStoppedValue() {\n        this._stoppedValue = this._oscillator.getInitialValue();\n        this._stoppedSignal.value = this._stoppedValue;\n    }\n    /**\n     * The minimum output of the LFO.\n     */\n    get min() {\n        return this._toType(this._scaler.min);\n    }\n    set min(min) {\n        min = this._fromType(min);\n        this._scaler.min = min;\n    }\n    /**\n     * The maximum output of the LFO.\n     */\n    get max() {\n        return this._toType(this._scaler.max);\n    }\n    set max(max) {\n        max = this._fromType(max);\n        this._scaler.max = max;\n    }\n    /**\n     * The type of the oscillator: See [[Oscillator.type]]\n     */\n    get type() {\n        return this._oscillator.type;\n    }\n    set type(type) {\n        this._oscillator.type = type;\n        this._setStoppedValue();\n    }\n    /**\n     * The oscillator's partials array: See [[Oscillator.partials]]\n     */\n    get partials() {\n        return this._oscillator.partials;\n    }\n    set partials(partials) {\n        this._oscillator.partials = partials;\n        this._setStoppedValue();\n    }\n    /**\n     * The phase of the LFO.\n     */\n    get phase() {\n        return this._oscillator.phase;\n    }\n    set phase(phase) {\n        this._oscillator.phase = phase;\n        this._setStoppedValue();\n    }\n    /**\n     * The output units of the LFO.\n     */\n    get units() {\n        return this._units;\n    }\n    set units(val) {\n        const currentMin = this.min;\n        const currentMax = this.max;\n        // convert the min and the max\n        this._units = val;\n        this.min = currentMin;\n        this.max = currentMax;\n    }\n    /**\n     * Returns the playback state of the source, either \"started\" or \"stopped\".\n     */\n    get state() {\n        return this._oscillator.state;\n    }\n    /**\n     * @param node the destination to connect to\n     * @param outputNum the optional output number\n     * @param inputNum the input number\n     */\n    connect(node, outputNum, inputNum) {\n        if (node instanceof _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param || node instanceof _signal_Signal__WEBPACK_IMPORTED_MODULE_7__.Signal) {\n            this.convert = node.convert;\n            this.units = node.units;\n        }\n        (0,_signal_Signal__WEBPACK_IMPORTED_MODULE_7__.connectSignal)(this, node, outputNum, inputNum);\n        return this;\n    }\n    dispose() {\n        super.dispose();\n        this._oscillator.dispose();\n        this._stoppedSignal.dispose();\n        this._zeros.dispose();\n        this._scaler.dispose();\n        this._a2g.dispose();\n        this._amplitudeGain.dispose();\n        this.amplitude.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=LFO.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/LFO.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js":
/*!*************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"OmniOscillator\": () => (/* binding */ OmniOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_12__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _AMOscillator__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./AMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/AMOscillator.js\");\n/* harmony import */ var _FatOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./FatOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FatOscillator.js\");\n/* harmony import */ var _FMOscillator__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./FMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/FMOscillator.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _PulseOscillator__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./PulseOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js\");\n/* harmony import */ var _PWMOscillator__WEBPACK_IMPORTED_MODULE_11__ = __webpack_require__(/*! ./PWMOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst OmniOscillatorSourceMap = {\n    am: _AMOscillator__WEBPACK_IMPORTED_MODULE_5__.AMOscillator,\n    fat: _FatOscillator__WEBPACK_IMPORTED_MODULE_6__.FatOscillator,\n    fm: _FMOscillator__WEBPACK_IMPORTED_MODULE_7__.FMOscillator,\n    oscillator: _Oscillator__WEBPACK_IMPORTED_MODULE_8__.Oscillator,\n    pulse: _PulseOscillator__WEBPACK_IMPORTED_MODULE_10__.PulseOscillator,\n    pwm: _PWMOscillator__WEBPACK_IMPORTED_MODULE_11__.PWMOscillator,\n};\n/**\n * OmniOscillator aggregates all of the oscillator types into one.\n * @example\n * return Tone.Offline(() => {\n * \tconst omniOsc = new Tone.OmniOscillator(\"C#4\", \"pwm\").toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass OmniOscillator extends _Source__WEBPACK_IMPORTED_MODULE_4__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(OmniOscillator.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"OmniOscillator\";\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(OmniOscillator.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"frequency\", \"detune\"]);\n        // set the options\n        this.set(options);\n    }\n    static getDefaults() {\n        return Object.assign(_Oscillator__WEBPACK_IMPORTED_MODULE_8__.Oscillator.getDefaults(), _FMOscillator__WEBPACK_IMPORTED_MODULE_7__.FMOscillator.getDefaults(), _AMOscillator__WEBPACK_IMPORTED_MODULE_5__.AMOscillator.getDefaults(), _FatOscillator__WEBPACK_IMPORTED_MODULE_6__.FatOscillator.getDefaults(), _PulseOscillator__WEBPACK_IMPORTED_MODULE_10__.PulseOscillator.getDefaults(), _PWMOscillator__WEBPACK_IMPORTED_MODULE_11__.PWMOscillator.getDefaults());\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        this._oscillator.start(time);\n    }\n    /**\n     * start the oscillator\n     */\n    _stop(time) {\n        this._oscillator.stop(time);\n    }\n    _restart(time) {\n        this._oscillator.restart(time);\n        return this;\n    }\n    /**\n     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or\n     * prefix the basic types with \"fm\", \"am\", or \"fat\" to use the FMOscillator, AMOscillator or FatOscillator\n     * types. The oscillator could also be set to \"pwm\" or \"pulse\". All of the parameters of the\n     * oscillator's class are accessible when the oscillator is set to that type, but throws an error\n     * when it's not.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator().toDestination().start();\n     * omniOsc.type = \"pwm\";\n     * // modulationFrequency is parameter which is available\n     * // only when the type is \"pwm\".\n     * omniOsc.modulationFrequency.value = 0.5;\n     */\n    get type() {\n        let prefix = \"\";\n        if ([\"am\", \"fm\", \"fat\"].some(p => this._sourceType === p)) {\n            prefix = this._sourceType;\n        }\n        return prefix + this._oscillator.type;\n    }\n    set type(type) {\n        if (type.substr(0, 2) === \"fm\") {\n            this._createNewOscillator(\"fm\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(2);\n        }\n        else if (type.substr(0, 2) === \"am\") {\n            this._createNewOscillator(\"am\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(2);\n        }\n        else if (type.substr(0, 3) === \"fat\") {\n            this._createNewOscillator(\"fat\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type.substr(3);\n        }\n        else if (type === \"pwm\") {\n            this._createNewOscillator(\"pwm\");\n            this._oscillator = this._oscillator;\n        }\n        else if (type === \"pulse\") {\n            this._createNewOscillator(\"pulse\");\n        }\n        else {\n            this._createNewOscillator(\"oscillator\");\n            this._oscillator = this._oscillator;\n            this._oscillator.type = type;\n        }\n    }\n    /**\n     * The value is an empty array when the type is not \"custom\".\n     * This is not available on \"pwm\" and \"pulse\" oscillator types.\n     * See [[Oscillator.partials]]\n     */\n    get partials() {\n        return this._oscillator.partials;\n    }\n    set partials(partials) {\n        if (!this._getOscType(this._oscillator, \"pulse\") && !this._getOscType(this._oscillator, \"pwm\")) {\n            this._oscillator.partials = partials;\n        }\n    }\n    get partialCount() {\n        return this._oscillator.partialCount;\n    }\n    set partialCount(partialCount) {\n        if (!this._getOscType(this._oscillator, \"pulse\") && !this._getOscType(this._oscillator, \"pwm\")) {\n            this._oscillator.partialCount = partialCount;\n        }\n    }\n    set(props) {\n        // make sure the type is set first\n        if (Reflect.has(props, \"type\") && props.type) {\n            this.type = props.type;\n        }\n        // then set the rest\n        super.set(props);\n        return this;\n    }\n    /**\n     * connect the oscillator to the frequency and detune signals\n     */\n    _createNewOscillator(oscType) {\n        if (oscType !== this._sourceType) {\n            this._sourceType = oscType;\n            const OscConstructor = OmniOscillatorSourceMap[oscType];\n            // short delay to avoid clicks on the change\n            const now = this.now();\n            if (this._oscillator) {\n                const oldOsc = this._oscillator;\n                oldOsc.stop(now);\n                // dispose the old one\n                this.context.setTimeout(() => oldOsc.dispose(), this.blockTime);\n            }\n            this._oscillator = new OscConstructor({\n                context: this.context,\n            });\n            this.frequency.connect(this._oscillator.frequency);\n            this.detune.connect(this._oscillator.detune);\n            this._oscillator.connect(this.output);\n            this._oscillator.onstop = () => this.onstop(this);\n            if (this.state === \"started\") {\n                this._oscillator.start(now);\n            }\n        }\n    }\n    get phase() {\n        return this._oscillator.phase;\n    }\n    set phase(phase) {\n        this._oscillator.phase = phase;\n    }\n    /**\n     * The source type of the oscillator.\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare\");\n     * console.log(omniOsc.sourceType); // 'fm'\n     */\n    get sourceType() {\n        return this._sourceType;\n    }\n    set sourceType(sType) {\n        // the basetype defaults to sine\n        let baseType = \"sine\";\n        if (this._oscillator.type !== \"pwm\" && this._oscillator.type !== \"pulse\") {\n            baseType = this._oscillator.type;\n        }\n        // set the type\n        if (sType === \"fm\") {\n            this.type = \"fm\" + baseType;\n        }\n        else if (sType === \"am\") {\n            this.type = \"am\" + baseType;\n        }\n        else if (sType === \"fat\") {\n            this.type = \"fat\" + baseType;\n        }\n        else if (sType === \"oscillator\") {\n            this.type = baseType;\n        }\n        else if (sType === \"pulse\") {\n            this.type = \"pulse\";\n        }\n        else if (sType === \"pwm\") {\n            this.type = \"pwm\";\n        }\n    }\n    _getOscType(osc, sourceType) {\n        return osc instanceof OmniOscillatorSourceMap[sourceType];\n    }\n    /**\n     * The base type of the oscillator. See [[Oscillator.baseType]]\n     * @example\n     * const omniOsc = new Tone.OmniOscillator(440, \"fmsquare4\");\n     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);\n     */\n    get baseType() {\n        return this._oscillator.baseType;\n    }\n    set baseType(baseType) {\n        if (!this._getOscType(this._oscillator, \"pulse\") &&\n            !this._getOscType(this._oscillator, \"pwm\") &&\n            baseType !== \"pulse\" && baseType !== \"pwm\") {\n            this._oscillator.baseType = baseType;\n        }\n    }\n    /**\n     * The width of the oscillator when sourceType === \"pulse\".\n     * See [[PWMOscillator.width]]\n     */\n    get width() {\n        if (this._getOscType(this._oscillator, \"pulse\")) {\n            return this._oscillator.width;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The number of detuned oscillators when sourceType === \"fat\".\n     * See [[FatOscillator.count]]\n     */\n    get count() {\n        if (this._getOscType(this._oscillator, \"fat\")) {\n            return this._oscillator.count;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set count(count) {\n        if (this._getOscType(this._oscillator, \"fat\") && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isNumber)(count)) {\n            this._oscillator.count = count;\n        }\n    }\n    /**\n     * The detune spread between the oscillators when sourceType === \"fat\".\n     * See [[FatOscillator.count]]\n     */\n    get spread() {\n        if (this._getOscType(this._oscillator, \"fat\")) {\n            return this._oscillator.spread;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set spread(spread) {\n        if (this._getOscType(this._oscillator, \"fat\") && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isNumber)(spread)) {\n            this._oscillator.spread = spread;\n        }\n    }\n    /**\n     * The type of the modulator oscillator. Only if the oscillator is set to \"am\" or \"fm\" types.\n     * See [[AMOscillator]] or [[FMOscillator]]\n     */\n    get modulationType() {\n        if (this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) {\n            return this._oscillator.modulationType;\n        }\n        else {\n            return undefined;\n        }\n    }\n    set modulationType(mType) {\n        if ((this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) && (0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isString)(mType)) {\n            this._oscillator.modulationType = mType;\n        }\n    }\n    /**\n     * The modulation index when the sourceType === \"fm\"\n     * See [[FMOscillator]].\n     */\n    get modulationIndex() {\n        if (this._getOscType(this._oscillator, \"fm\")) {\n            return this._oscillator.modulationIndex;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.\n     * See [[AMOscillator]] or [[FMOscillator]]\n     */\n    get harmonicity() {\n        if (this._getOscType(this._oscillator, \"fm\") || this._getOscType(this._oscillator, \"am\")) {\n            return this._oscillator.harmonicity;\n        }\n        else {\n            return undefined;\n        }\n    }\n    /**\n     * The modulationFrequency Signal of the oscillator when sourceType === \"pwm\"\n     * see [[PWMOscillator]]\n     * @min 0.1\n     * @max 5\n     */\n    get modulationFrequency() {\n        if (this._getOscType(this._oscillator, \"pwm\")) {\n            return this._oscillator.modulationFrequency;\n        }\n        else {\n            return undefined;\n        }\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_12__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_9__.generateWaveform)(this, length);\n        });\n    }\n    dispose() {\n        super.dispose();\n        this.detune.dispose();\n        this.frequency.dispose();\n        this._oscillator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=OmniOscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/OmniOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/Oscillator.js":
/*!*********************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/Oscillator.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Oscillator\": () => (/* binding */ Oscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/TypeCheck */ \"./node_modules/tone/build/esm/core/util/TypeCheck.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./ToneOscillatorNode */ \"./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js\");\n/* harmony import */ var _core_util_Debug__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ../../core/util/Debug */ \"./node_modules/tone/build/esm/core/util/Debug.js\");\n/* harmony import */ var _core_util_Math__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../../core/util/Math */ \"./node_modules/tone/build/esm/core/util/Math.js\");\n\n\n\n\n\n\n\n\n\n\n/**\n * Oscillator supports a number of features including\n * phase rotation, multiple oscillator types (see Oscillator.type),\n * and Transport syncing (see Oscillator.syncFrequency).\n *\n * @example\n * // make and start a 440hz sine tone\n * const osc = new Tone.Oscillator(440, \"sine\").toDestination().start();\n * @category Source\n */\nclass Oscillator extends _Source__WEBPACK_IMPORTED_MODULE_4__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Oscillator.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"Oscillator\";\n        /**\n         * the main oscillator\n         */\n        this._oscillator = null;\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(Oscillator.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        this.frequency = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, \"frequency\");\n        this.detune = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"cents\",\n            value: options.detune,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, \"detune\");\n        this._partials = options.partials;\n        this._partialCount = options.partialCount;\n        this._type = options.type;\n        if (options.partialCount && options.type !== \"custom\") {\n            this._type = this.baseType + options.partialCount.toString();\n        }\n        this.phase = options.phase;\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_4__.Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            partialCount: 0,\n            partials: [],\n            phase: 0,\n            type: \"sine\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        const computedTime = this.toSeconds(time);\n        // new oscillator with previous values\n        const oscillator = new _ToneOscillatorNode__WEBPACK_IMPORTED_MODULE_6__.ToneOscillatorNode({\n            context: this.context,\n            onended: () => this.onstop(this),\n        });\n        this._oscillator = oscillator;\n        if (this._wave) {\n            this._oscillator.setPeriodicWave(this._wave);\n        }\n        else {\n            this._oscillator.type = this._type;\n        }\n        // connect the control signal to the oscillator frequency & detune\n        this._oscillator.connect(this.output);\n        this.frequency.connect(this._oscillator.frequency);\n        this.detune.connect(this._oscillator.detune);\n        // start the oscillator\n        this._oscillator.start(computedTime);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        const computedTime = this.toSeconds(time);\n        if (this._oscillator) {\n            this._oscillator.stop(computedTime);\n        }\n    }\n    /**\n     * Restart the oscillator. Does not stop the oscillator, but instead\n     * just cancels any scheduled 'stop' from being invoked.\n     */\n    _restart(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"restart\", computedTime);\n        if (this._oscillator) {\n            this._oscillator.cancelStop();\n        }\n        this._state.cancel(computedTime);\n        return this;\n    }\n    /**\n     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,\n     * will also affect the oscillators frequency.\n     * @example\n     * const osc = new Tone.Oscillator().toDestination().start();\n     * osc.frequency.value = 440;\n     * // the ratio between the bpm and the frequency will be maintained\n     * osc.syncFrequency();\n     * // double the tempo\n     * Tone.Transport.bpm.value *= 2;\n     * // the frequency of the oscillator is doubled to 880\n     */\n    syncFrequency() {\n        this.context.transport.syncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Unsync the oscillator's frequency from the Transport.\n     * See Oscillator.syncFrequency\n     */\n    unsyncFrequency() {\n        this.context.transport.unsyncSignal(this.frequency);\n        return this;\n    }\n    /**\n     * Get a cached periodic wave. Avoids having to recompute\n     * the oscillator values when they have already been computed\n     * with the same values.\n     */\n    _getCachedPeriodicWave() {\n        if (this._type === \"custom\") {\n            const oscProps = Oscillator._periodicWaveCache.find(description => {\n                return description.phase === this._phase &&\n                    (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.deepEquals)(description.partials, this._partials);\n            });\n            return oscProps;\n        }\n        else {\n            const oscProps = Oscillator._periodicWaveCache.find(description => {\n                return description.type === this._type &&\n                    description.phase === this._phase;\n            });\n            this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;\n            return oscProps;\n        }\n    }\n    get type() {\n        return this._type;\n    }\n    set type(type) {\n        this._type = type;\n        const isBasicType = [\"sine\", \"square\", \"sawtooth\", \"triangle\"].indexOf(type) !== -1;\n        if (this._phase === 0 && isBasicType) {\n            this._wave = undefined;\n            this._partialCount = 0;\n            // just go with the basic approach\n            if (this._oscillator !== null) {\n                // already tested that it's a basic type\n                this._oscillator.type = type;\n            }\n        }\n        else {\n            // first check if the value is cached\n            const cache = this._getCachedPeriodicWave();\n            if ((0,_core_util_TypeCheck__WEBPACK_IMPORTED_MODULE_2__.isDefined)(cache)) {\n                const { partials, wave } = cache;\n                this._wave = wave;\n                this._partials = partials;\n                if (this._oscillator !== null) {\n                    this._oscillator.setPeriodicWave(this._wave);\n                }\n            }\n            else {\n                const [real, imag] = this._getRealImaginary(type, this._phase);\n                const periodicWave = this.context.createPeriodicWave(real, imag);\n                this._wave = periodicWave;\n                if (this._oscillator !== null) {\n                    this._oscillator.setPeriodicWave(this._wave);\n                }\n                // set the cache\n                Oscillator._periodicWaveCache.push({\n                    imag,\n                    partialCount: this._partialCount,\n                    partials: this._partials,\n                    phase: this._phase,\n                    real,\n                    type: this._type,\n                    wave: this._wave,\n                });\n                if (Oscillator._periodicWaveCache.length > 100) {\n                    Oscillator._periodicWaveCache.shift();\n                }\n            }\n        }\n    }\n    get baseType() {\n        return this._type.replace(this.partialCount.toString(), \"\");\n    }\n    set baseType(baseType) {\n        if (this.partialCount && this._type !== \"custom\" && baseType !== \"custom\") {\n            this.type = baseType + this.partialCount;\n        }\n        else {\n            this.type = baseType;\n        }\n    }\n    get partialCount() {\n        return this._partialCount;\n    }\n    set partialCount(p) {\n        (0,_core_util_Debug__WEBPACK_IMPORTED_MODULE_7__.assertRange)(p, 0);\n        let type = this._type;\n        const partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(this._type);\n        if (partial) {\n            type = partial[1];\n        }\n        if (this._type !== \"custom\") {\n            if (p === 0) {\n                this.type = type;\n            }\n            else {\n                this.type = type + p.toString();\n            }\n        }\n        else {\n            // extend or shorten the partials array\n            const fullPartials = new Float32Array(p);\n            // copy over the partials array\n            this._partials.forEach((v, i) => fullPartials[i] = v);\n            this._partials = Array.from(fullPartials);\n            this.type = this._type;\n        }\n    }\n    /**\n     * Returns the real and imaginary components based\n     * on the oscillator type.\n     * @returns [real: Float32Array, imaginary: Float32Array]\n     */\n    _getRealImaginary(type, phase) {\n        const fftSize = 4096;\n        let periodicWaveSize = fftSize / 2;\n        const real = new Float32Array(periodicWaveSize);\n        const imag = new Float32Array(periodicWaveSize);\n        let partialCount = 1;\n        if (type === \"custom\") {\n            partialCount = this._partials.length + 1;\n            this._partialCount = this._partials.length;\n            periodicWaveSize = partialCount;\n            // if the partial count is 0, don't bother doing any computation\n            if (this._partials.length === 0) {\n                return [real, imag];\n            }\n        }\n        else {\n            const partial = /^(sine|triangle|square|sawtooth)(\\d+)$/.exec(type);\n            if (partial) {\n                partialCount = parseInt(partial[2], 10) + 1;\n                this._partialCount = parseInt(partial[2], 10);\n                type = partial[1];\n                partialCount = Math.max(partialCount, 2);\n                periodicWaveSize = partialCount;\n            }\n            else {\n                this._partialCount = 0;\n            }\n            this._partials = [];\n        }\n        for (let n = 1; n < periodicWaveSize; ++n) {\n            const piFactor = 2 / (n * Math.PI);\n            let b;\n            switch (type) {\n                case \"sine\":\n                    b = (n <= partialCount) ? 1 : 0;\n                    this._partials[n - 1] = b;\n                    break;\n                case \"square\":\n                    b = (n & 1) ? 2 * piFactor : 0;\n                    this._partials[n - 1] = b;\n                    break;\n                case \"sawtooth\":\n                    b = piFactor * ((n & 1) ? 1 : -1);\n                    this._partials[n - 1] = b;\n                    break;\n                case \"triangle\":\n                    if (n & 1) {\n                        b = 2 * (piFactor * piFactor) * ((((n - 1) >> 1) & 1) ? -1 : 1);\n                    }\n                    else {\n                        b = 0;\n                    }\n                    this._partials[n - 1] = b;\n                    break;\n                case \"custom\":\n                    b = this._partials[n - 1];\n                    break;\n                default:\n                    throw new TypeError(\"Oscillator: invalid type: \" + type);\n            }\n            if (b !== 0) {\n                real[n] = -b * Math.sin(phase * n);\n                imag[n] = b * Math.cos(phase * n);\n            }\n            else {\n                real[n] = 0;\n                imag[n] = 0;\n            }\n        }\n        return [real, imag];\n    }\n    /**\n     * Compute the inverse FFT for a given phase.\n     */\n    _inverseFFT(real, imag, phase) {\n        let sum = 0;\n        const len = real.length;\n        for (let i = 0; i < len; i++) {\n            sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);\n        }\n        return sum;\n    }\n    /**\n     * Returns the initial value of the oscillator when stopped.\n     * E.g. a \"sine\" oscillator with phase = 90 would return an initial value of -1.\n     */\n    getInitialValue() {\n        const [real, imag] = this._getRealImaginary(this._type, 0);\n        let maxValue = 0;\n        const twoPi = Math.PI * 2;\n        const testPositions = 32;\n        // check for peaks in 16 places\n        for (let i = 0; i < testPositions; i++) {\n            maxValue = Math.max(this._inverseFFT(real, imag, (i / testPositions) * twoPi), maxValue);\n        }\n        return (0,_core_util_Math__WEBPACK_IMPORTED_MODULE_8__.clamp)(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);\n    }\n    get partials() {\n        return this._partials.slice(0, this.partialCount);\n    }\n    set partials(partials) {\n        this._partials = partials;\n        this._partialCount = this._partials.length;\n        if (partials.length) {\n            this.type = \"custom\";\n        }\n    }\n    get phase() {\n        return this._phase * (180 / Math.PI);\n    }\n    set phase(phase) {\n        this._phase = phase * Math.PI / 180;\n        // reset the type\n        this.type = this._type;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_9__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__.generateWaveform)(this, length);\n        });\n    }\n    dispose() {\n        super.dispose();\n        if (this._oscillator !== null) {\n            this._oscillator.dispose();\n        }\n        this._wave = undefined;\n        this.frequency.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n/**\n * Cache the periodic waves to avoid having to redo computations\n */\nOscillator._periodicWaveCache = [];\n//# sourceMappingURL=Oscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/Oscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js":
/*!******************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js ***!
  \******************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"generateWaveform\": () => (/* binding */ generateWaveform)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/OfflineContext */ \"./node_modules/tone/build/esm/core/context/OfflineContext.js\");\n\n\n/**\n * Render a segment of the oscillator to an offline context and return the results as an array\n */\nfunction generateWaveform(instance, length) {\n    return (0,tslib__WEBPACK_IMPORTED_MODULE_1__.__awaiter)(this, void 0, void 0, function* () {\n        const duration = length / instance.context.sampleRate;\n        const context = new _core_context_OfflineContext__WEBPACK_IMPORTED_MODULE_0__.OfflineContext(1, duration, instance.context.sampleRate);\n        const clone = new instance.constructor(Object.assign(instance.get(), {\n            // should do 2 iterations\n            frequency: 2 / duration,\n            // zero out the detune\n            detune: 0,\n            context\n        })).toDestination();\n        clone.start(0);\n        const buffer = yield context.render();\n        return buffer.getChannelData(0);\n    });\n}\n//# sourceMappingURL=OscillatorInterface.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js":
/*!************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PWMOscillator\": () => (/* binding */ PWMOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../signal/Multiply */ \"./node_modules/tone/build/esm/signal/Multiply.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n/* harmony import */ var _PulseOscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./PulseOscillator */ \"./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js\");\n\n\n\n\n\n\n\n\n/**\n * PWMOscillator modulates the width of a Tone.PulseOscillator\n * at the modulationFrequency. This has the effect of continuously\n * changing the timbre of the oscillator by altering the harmonics\n * generated.\n * @example\n * return Tone.Offline(() => {\n * \tconst pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass PWMOscillator extends _Source__WEBPACK_IMPORTED_MODULE_3__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(PWMOscillator.getDefaults(), arguments, [\"frequency\", \"modulationFrequency\"]));\n        this.name = \"PWMOscillator\";\n        this.sourceType = \"pwm\";\n        /**\n         * Scale the oscillator so it doesn't go silent\n         * at the extreme values.\n         */\n        this._scale = new _signal_Multiply__WEBPACK_IMPORTED_MODULE_2__.Multiply({\n            context: this.context,\n            value: 2,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_0__.optionsFromArguments)(PWMOscillator.getDefaults(), arguments, [\"frequency\", \"modulationFrequency\"]);\n        this._pulse = new _PulseOscillator__WEBPACK_IMPORTED_MODULE_6__.PulseOscillator({\n            context: this.context,\n            frequency: options.modulationFrequency,\n        });\n        // change the pulse oscillator type\n        this._pulse.carrierType = \"sine\";\n        this.modulationFrequency = this._pulse.frequency;\n        this._modulator = new _Oscillator__WEBPACK_IMPORTED_MODULE_4__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n        });\n        this.frequency = this._modulator.frequency;\n        this.detune = this._modulator.detune;\n        // connections\n        this._modulator.chain(this._scale, this._pulse.width);\n        this._pulse.connect(this.output);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_1__.readOnly)(this, [\"modulationFrequency\", \"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_3__.Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            modulationFrequency: 0.4,\n            phase: 0,\n            type: \"pwm\",\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._modulator.start(time);\n        this._pulse.start(time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._modulator.stop(time);\n        this._pulse.stop(time);\n    }\n    /**\n     * restart the oscillator\n     */\n    _restart(time) {\n        this._modulator.restart(time);\n        this._pulse.restart(time);\n    }\n    /**\n     * The type of the oscillator. Always returns \"pwm\".\n     */\n    get type() {\n        return \"pwm\";\n    }\n    /**\n     * The baseType of the oscillator. Always returns \"pwm\".\n     */\n    get baseType() {\n        return \"pwm\";\n    }\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials() {\n        return [];\n    }\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount() {\n        return 0;\n    }\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase() {\n        return this._modulator.phase;\n    }\n    set phase(phase) {\n        this._modulator.phase = phase;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_7__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_5__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        this._pulse.dispose();\n        this._scale.dispose();\n        this._modulator.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PWMOscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/PWMOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js":
/*!**************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"PulseOscillator\": () => (/* binding */ PulseOscillator)\n/* harmony export */ });\n/* harmony import */ var tslib__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! tslib */ \"./node_modules/tslib/tslib.es6.js\");\n/* harmony import */ var _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/Gain */ \"./node_modules/tone/build/esm/core/context/Gain.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n/* harmony import */ var _signal_Signal__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../signal/Signal */ \"./node_modules/tone/build/esm/signal/Signal.js\");\n/* harmony import */ var _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../signal/WaveShaper */ \"./node_modules/tone/build/esm/signal/WaveShaper.js\");\n/* harmony import */ var _Source__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../Source */ \"./node_modules/tone/build/esm/source/Source.js\");\n/* harmony import */ var _Oscillator__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Oscillator */ \"./node_modules/tone/build/esm/source/oscillator/Oscillator.js\");\n/* harmony import */ var _OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./OscillatorInterface */ \"./node_modules/tone/build/esm/source/oscillator/OscillatorInterface.js\");\n\n\n\n\n\n\n\n\n\n/**\n * PulseOscillator is an oscillator with control over pulse width,\n * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is\n * a square wave.\n * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).\n * ```\n *    width = -0.25        width = 0.0          width = 0.25\n *\n *   +-----+            +-------+       +    +-------+     +-+\n *   |     |            |       |       |            |     |\n *   |     |            |       |       |            |     |\n * +-+     +-------+    +       +-------+            +-----+\n *\n *\n *    width = -0.5                              width = 0.5\n *\n *     +---+                                 +-------+   +---+\n *     |   |                                         |   |\n *     |   |                                         |   |\n * +---+   +-------+                                 +---+\n *\n *\n *    width = -0.75                             width = 0.75\n *\n *       +-+                                 +-------+ +-----+\n *       | |                                         | |\n *       | |                                         | |\n * +-----+ +-------+                                 +-+\n * ```\n * @example\n * return Tone.Offline(() => {\n * \tconst pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();\n * }, 0.1, 1);\n * @category Source\n */\nclass PulseOscillator extends _Source__WEBPACK_IMPORTED_MODULE_5__.Source {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PulseOscillator.getDefaults(), arguments, [\"frequency\", \"width\"]));\n        this.name = \"PulseOscillator\";\n        /**\n         * gate the width amount\n         */\n        this._widthGate = new _core_context_Gain__WEBPACK_IMPORTED_MODULE_0__.Gain({\n            context: this.context,\n            gain: 0,\n        });\n        /**\n         * Threshold the signal to turn it into a square\n         */\n        this._thresh = new _signal_WaveShaper__WEBPACK_IMPORTED_MODULE_4__.WaveShaper({\n            context: this.context,\n            mapping: val => val <= 0 ? -1 : 1,\n        });\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_1__.optionsFromArguments)(PulseOscillator.getDefaults(), arguments, [\"frequency\", \"width\"]);\n        this.width = new _signal_Signal__WEBPACK_IMPORTED_MODULE_3__.Signal({\n            context: this.context,\n            units: \"audioRange\",\n            value: options.width,\n        });\n        this._triangle = new _Oscillator__WEBPACK_IMPORTED_MODULE_6__.Oscillator({\n            context: this.context,\n            detune: options.detune,\n            frequency: options.frequency,\n            onstop: () => this.onstop(this),\n            phase: options.phase,\n            type: \"triangle\",\n        });\n        this.frequency = this._triangle.frequency;\n        this.detune = this._triangle.detune;\n        // connections\n        this._triangle.chain(this._thresh, this.output);\n        this.width.chain(this._widthGate, this._thresh);\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_2__.readOnly)(this, [\"width\", \"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_Source__WEBPACK_IMPORTED_MODULE_5__.Source.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            phase: 0,\n            type: \"pulse\",\n            width: 0.2,\n        });\n    }\n    /**\n     * start the oscillator\n     */\n    _start(time) {\n        time = this.toSeconds(time);\n        this._triangle.start(time);\n        this._widthGate.gain.setValueAtTime(1, time);\n    }\n    /**\n     * stop the oscillator\n     */\n    _stop(time) {\n        time = this.toSeconds(time);\n        this._triangle.stop(time);\n        // the width is still connected to the output.\n        // that needs to be stopped also\n        this._widthGate.gain.cancelScheduledValues(time);\n        this._widthGate.gain.setValueAtTime(0, time);\n    }\n    _restart(time) {\n        this._triangle.restart(time);\n        this._widthGate.gain.cancelScheduledValues(time);\n        this._widthGate.gain.setValueAtTime(1, time);\n    }\n    /**\n     * The phase of the oscillator in degrees.\n     */\n    get phase() {\n        return this._triangle.phase;\n    }\n    set phase(phase) {\n        this._triangle.phase = phase;\n    }\n    /**\n     * The type of the oscillator. Always returns \"pulse\".\n     */\n    get type() {\n        return \"pulse\";\n    }\n    /**\n     * The baseType of the oscillator. Always returns \"pulse\".\n     */\n    get baseType() {\n        return \"pulse\";\n    }\n    /**\n     * The partials of the waveform. Cannot set partials for this waveform type\n     */\n    get partials() {\n        return [];\n    }\n    /**\n     * No partials for this waveform type.\n     */\n    get partialCount() {\n        return 0;\n    }\n    /**\n     * *Internal use* The carrier oscillator type is fed through the\n     * waveshaper node to create the pulse. Using different carrier oscillators\n     * changes oscillator's behavior.\n     */\n    set carrierType(type) {\n        this._triangle.type = type;\n    }\n    asArray(length = 1024) {\n        return (0,tslib__WEBPACK_IMPORTED_MODULE_8__.__awaiter)(this, void 0, void 0, function* () {\n            return (0,_OscillatorInterface__WEBPACK_IMPORTED_MODULE_7__.generateWaveform)(this, length);\n        });\n    }\n    /**\n     * Clean up method.\n     */\n    dispose() {\n        super.dispose();\n        this._triangle.dispose();\n        this.width.dispose();\n        this._widthGate.dispose();\n        this._thresh.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=PulseOscillator.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/PulseOscillator.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js ***!
  \*****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ToneOscillatorNode\": () => (/* binding */ ToneOscillatorNode)\n/* harmony export */ });\n/* harmony import */ var _core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../core/context/ToneAudioNode */ \"./node_modules/tone/build/esm/core/context/ToneAudioNode.js\");\n/* harmony import */ var _core_context_Param__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../core/context/Param */ \"./node_modules/tone/build/esm/core/context/Param.js\");\n/* harmony import */ var _core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../core/util/Defaults */ \"./node_modules/tone/build/esm/core/util/Defaults.js\");\n/* harmony import */ var _OneShotSource__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../OneShotSource */ \"./node_modules/tone/build/esm/source/OneShotSource.js\");\n/* harmony import */ var _core_util_Interface__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../core/util/Interface */ \"./node_modules/tone/build/esm/core/util/Interface.js\");\n\n\n\n\n\n/**\n * Wrapper around the native fire-and-forget OscillatorNode.\n * Adds the ability to reschedule the stop method.\n * ***[[Oscillator]] is better for most use-cases***\n * @category Source\n */\nclass ToneOscillatorNode extends _OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource {\n    constructor() {\n        super((0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneOscillatorNode.getDefaults(), arguments, [\"frequency\", \"type\"]));\n        this.name = \"ToneOscillatorNode\";\n        /**\n         * The oscillator\n         */\n        this._oscillator = this.context.createOscillator();\n        this._internalChannels = [this._oscillator];\n        const options = (0,_core_util_Defaults__WEBPACK_IMPORTED_MODULE_2__.optionsFromArguments)(ToneOscillatorNode.getDefaults(), arguments, [\"frequency\", \"type\"]);\n        (0,_core_context_ToneAudioNode__WEBPACK_IMPORTED_MODULE_0__.connect)(this._oscillator, this._gainNode);\n        this.type = options.type;\n        this.frequency = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this._oscillator.frequency,\n            units: \"frequency\",\n            value: options.frequency,\n        });\n        this.detune = new _core_context_Param__WEBPACK_IMPORTED_MODULE_1__.Param({\n            context: this.context,\n            param: this._oscillator.detune,\n            units: \"cents\",\n            value: options.detune,\n        });\n        (0,_core_util_Interface__WEBPACK_IMPORTED_MODULE_4__.readOnly)(this, [\"frequency\", \"detune\"]);\n    }\n    static getDefaults() {\n        return Object.assign(_OneShotSource__WEBPACK_IMPORTED_MODULE_3__.OneShotSource.getDefaults(), {\n            detune: 0,\n            frequency: 440,\n            type: \"sine\",\n        });\n    }\n    /**\n     * Start the oscillator node at the given time\n     * @param  time When to start the oscillator\n     */\n    start(time) {\n        const computedTime = this.toSeconds(time);\n        this.log(\"start\", computedTime);\n        this._startGain(computedTime);\n        this._oscillator.start(computedTime);\n        return this;\n    }\n    _stopSource(time) {\n        this._oscillator.stop(time);\n    }\n    /**\n     * Sets an arbitrary custom periodic waveform given a PeriodicWave.\n     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave\n     */\n    setPeriodicWave(periodicWave) {\n        this._oscillator.setPeriodicWave(periodicWave);\n        return this;\n    }\n    /**\n     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'\n     */\n    get type() {\n        return this._oscillator.type;\n    }\n    set type(type) {\n        this._oscillator.type = type;\n    }\n    /**\n     * Clean up.\n     */\n    dispose() {\n        super.dispose();\n        if (this.state === \"started\") {\n            this.stop();\n        }\n        this._oscillator.disconnect();\n        this.frequency.dispose();\n        this.detune.dispose();\n        return this;\n    }\n}\n//# sourceMappingURL=ToneOscillatorNode.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/source/oscillator/ToneOscillatorNode.js?");

/***/ }),

/***/ "./node_modules/tone/build/esm/version.js":
/*!************************************************!*\
  !*** ./node_modules/tone/build/esm/version.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"version\": () => (/* binding */ version)\n/* harmony export */ });\nconst version = \"14.7.77\";\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://Something/./node_modules/tone/build/esm/version.js?");

/***/ }),

/***/ "./node_modules/tslib/tslib.es6.js":
/*!*****************************************!*\
  !*** ./node_modules/tslib/tslib.es6.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"__assign\": () => (/* binding */ __assign),\n/* harmony export */   \"__asyncDelegator\": () => (/* binding */ __asyncDelegator),\n/* harmony export */   \"__asyncGenerator\": () => (/* binding */ __asyncGenerator),\n/* harmony export */   \"__asyncValues\": () => (/* binding */ __asyncValues),\n/* harmony export */   \"__await\": () => (/* binding */ __await),\n/* harmony export */   \"__awaiter\": () => (/* binding */ __awaiter),\n/* harmony export */   \"__classPrivateFieldGet\": () => (/* binding */ __classPrivateFieldGet),\n/* harmony export */   \"__classPrivateFieldSet\": () => (/* binding */ __classPrivateFieldSet),\n/* harmony export */   \"__createBinding\": () => (/* binding */ __createBinding),\n/* harmony export */   \"__decorate\": () => (/* binding */ __decorate),\n/* harmony export */   \"__exportStar\": () => (/* binding */ __exportStar),\n/* harmony export */   \"__extends\": () => (/* binding */ __extends),\n/* harmony export */   \"__generator\": () => (/* binding */ __generator),\n/* harmony export */   \"__importDefault\": () => (/* binding */ __importDefault),\n/* harmony export */   \"__importStar\": () => (/* binding */ __importStar),\n/* harmony export */   \"__makeTemplateObject\": () => (/* binding */ __makeTemplateObject),\n/* harmony export */   \"__metadata\": () => (/* binding */ __metadata),\n/* harmony export */   \"__param\": () => (/* binding */ __param),\n/* harmony export */   \"__read\": () => (/* binding */ __read),\n/* harmony export */   \"__rest\": () => (/* binding */ __rest),\n/* harmony export */   \"__spread\": () => (/* binding */ __spread),\n/* harmony export */   \"__spreadArray\": () => (/* binding */ __spreadArray),\n/* harmony export */   \"__spreadArrays\": () => (/* binding */ __spreadArrays),\n/* harmony export */   \"__values\": () => (/* binding */ __values)\n/* harmony export */ });\n/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nfunction __extends(d, b) {\r\n    if (typeof b !== \"function\" && b !== null)\r\n        throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nvar __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    }\r\n    return __assign.apply(this, arguments);\r\n}\r\n\r\nfunction __rest(s, e) {\r\n    var t = {};\r\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n        t[p] = s[p];\r\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\r\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\r\n                t[p[i]] = s[p[i]];\r\n        }\r\n    return t;\r\n}\r\n\r\nfunction __decorate(decorators, target, key, desc) {\r\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n}\r\n\r\nfunction __param(paramIndex, decorator) {\r\n    return function (target, key) { decorator(target, key, paramIndex); }\r\n}\r\n\r\nfunction __metadata(metadataKey, metadataValue) {\r\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n}\r\n\r\nfunction __awaiter(thisArg, _arguments, P, generator) {\r\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nfunction __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\r\n\r\nvar __createBinding = Object.create ? (function(o, m, k, k2) {\r\n    if (k2 === undefined) k2 = k;\r\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\r\n}) : (function(o, m, k, k2) {\r\n    if (k2 === undefined) k2 = k;\r\n    o[k2] = m[k];\r\n});\r\n\r\nfunction __exportStar(m, o) {\r\n    for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\r\n}\r\n\r\nfunction __values(o) {\r\n    var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\r\n    if (m) return m.call(o);\r\n    if (o && typeof o.length === \"number\") return {\r\n        next: function () {\r\n            if (o && i >= o.length) o = void 0;\r\n            return { value: o && o[i++], done: !o };\r\n        }\r\n    };\r\n    throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\r\n}\r\n\r\nfunction __read(o, n) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n    if (!m) return o;\r\n    var i = m.call(o), r, ar = [], e;\r\n    try {\r\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n    }\r\n    catch (error) { e = { error: error }; }\r\n    finally {\r\n        try {\r\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n        }\r\n        finally { if (e) throw e.error; }\r\n    }\r\n    return ar;\r\n}\r\n\r\n/** @deprecated */\r\nfunction __spread() {\r\n    for (var ar = [], i = 0; i < arguments.length; i++)\r\n        ar = ar.concat(__read(arguments[i]));\r\n    return ar;\r\n}\r\n\r\n/** @deprecated */\r\nfunction __spreadArrays() {\r\n    for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\r\n    for (var r = Array(s), k = 0, i = 0; i < il; i++)\r\n        for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\r\n            r[k] = a[j];\r\n    return r;\r\n}\r\n\r\nfunction __spreadArray(to, from, pack) {\r\n    if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\r\n        if (ar || !(i in from)) {\r\n            if (!ar) ar = Array.prototype.slice.call(from, 0, i);\r\n            ar[i] = from[i];\r\n        }\r\n    }\r\n    return to.concat(ar || Array.prototype.slice.call(from));\r\n}\r\n\r\nfunction __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nfunction __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\nfunction __asyncDelegator(o) {\r\n    var i, p;\r\n    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n    function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n}\r\n\r\nfunction __asyncValues(o) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var m = o[Symbol.asyncIterator], i;\r\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n}\r\n\r\nfunction __makeTemplateObject(cooked, raw) {\r\n    if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n    return cooked;\r\n};\r\n\r\nvar __setModuleDefault = Object.create ? (function(o, v) {\r\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\r\n}) : function(o, v) {\r\n    o[\"default\"] = v;\r\n};\r\n\r\nfunction __importStar(mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\r\n    __setModuleDefault(result, mod);\r\n    return result;\r\n}\r\n\r\nfunction __importDefault(mod) {\r\n    return (mod && mod.__esModule) ? mod : { default: mod };\r\n}\r\n\r\nfunction __classPrivateFieldGet(receiver, state, kind, f) {\r\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\r\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\r\n    return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\r\n}\r\n\r\nfunction __classPrivateFieldSet(receiver, state, value, kind, f) {\r\n    if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\r\n    if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\r\n    if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\r\n    return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\r\n}\r\n\n\n//# sourceURL=webpack://Something/./node_modules/tslib/tslib.es6.js?");

/***/ }),

/***/ "./src/energySystem.js":
/*!*****************************!*\
  !*** ./src/energySystem.js ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"checkIfStorage\": () => (/* binding */ checkIfStorage),\n/* harmony export */   \"decreaseEnergy\": () => (/* binding */ decreaseEnergy),\n/* harmony export */   \"increaseEnergy\": () => (/* binding */ increaseEnergy),\n/* harmony export */   \"initEnergy\": () => (/* binding */ initEnergy),\n/* harmony export */   \"readEnergy\": () => (/* binding */ readEnergy),\n/* harmony export */   \"saveStartTime\": () => (/* binding */ saveStartTime),\n/* harmony export */   \"storageAvailable\": () => (/* binding */ storageAvailable),\n/* harmony export */   \"storeEnergy\": () => (/* binding */ storeEnergy)\n/* harmony export */ });\n/*\r\nCreated by Henry James\r\nhenryjaames@gmail.com\r\n\r\nEnergy system for something story\r\n\r\nUse it if you want leik, sick!\r\n\r\nNeee bother.\r\n\r\nWould love to hear how though!\r\n*/\r\n\r\n// save the start time\r\n// this shouldn't live in here, but I feel\r\n// like it's easier to keep it here\r\nfunction saveStartTime() {\r\n    if (checkIfStorage() === true) {\r\n        if (localStorage.getItem(\"startTime\") === null) {\r\n            localStorage.setItem(\"startTime\", String(Date.now()))\r\n        }\r\n    }\r\n}\r\n\r\nfunction checkIfStorage() {\r\n    if (storageAvailable('localStorage')) {\r\n        // Yippee! We can use localStorage awesomeness\r\n        return (true);\r\n    } else {\r\n        alert(\"A storage feature is not available in your browser, the game will not work properly.\");\r\n        // Too bad, no localStorage for us\r\n    }\r\n}\r\n\r\n// Store the energy levels in local storage\r\nfunction initEnergy() {\r\n    if (checkIfStorage() === true) {\r\n        let energyValue = parseInt(readEnergy());\r\n        if (energyValue > 1000) {\r\n            localStorage.setItem(\"energy\", \"1000\");\r\n        } else if (energyValue < 1000) {\r\n            console.log(\"Energy level below 1000, keeping last known stats\");\r\n        } else {\r\n            localStorage.setItem(\"energy\", \"0\");\r\n        }\r\n    }\r\n}\r\n\r\n// Store the energy levels in local storage\r\nfunction storeEnergy(energyLevel) {\r\n    localStorage.setItem('energy', String(energyLevel));\r\n}\r\n\r\n// to decrease\r\nfunction decreaseEnergy(energyDecrease) {\r\n    var energy = readEnergy();\r\n    if (energy > 0) storeEnergy(energy - energyDecrease);\r\n    return energy;\r\n}\r\n\r\n// to increase\r\nfunction increaseEnergy(energyIncrease) {\r\n    var energy = readEnergy();\r\n    if (energy + energyIncrease < 1000) storeEnergy(energy + energyIncrease);\r\n    if (energy + energyIncrease > 1000) storeEnergy(1000);\r\n    return energy;\r\n}\r\n\r\n// to read\r\nfunction readEnergy() {\r\n    if (checkIfStorage() === true) return (parseInt(localStorage.getItem('energy')));\r\n}\r\n\r\n// taken for the mozzila MDN site\r\nfunction storageAvailable(type) {\r\n    var storage;\r\n    try {\r\n        storage = window[type];\r\n        var x = '__storage_test__';\r\n        storage.setItem(x, x);\r\n        storage.removeItem(x);\r\n        return true;\r\n    } catch (e) {\r\n        return e instanceof DOMException && (\r\n                // everything except Firefox\r\n                e.code === 22 ||\r\n                // Firefox\r\n                e.code === 1014 ||\r\n                // test name field too, because code might not be present\r\n                // everything except Firefox\r\n                e.name === 'QuotaExceededError' ||\r\n                // Firefox\r\n                e.name === 'NS_ERROR_DOM_QUOTA_REACHED') &&\r\n            // acknowledge QuotaExceededError only if there's something already stored\r\n            (storage && storage.length !== 0);\r\n    }\r\n}\n\n//# sourceURL=webpack://Something/./src/energySystem.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! three */ \"./node_modules/three/build/three.module.js\");\n/* harmony import */ var three_examples_jsm_controls_OrbitControls_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! three/examples/jsm/controls/OrbitControls.js */ \"./node_modules/three/examples/jsm/controls/OrbitControls.js\");\n/* harmony import */ var three_examples_jsm_loaders_GLTFLoader_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! three/examples/jsm/loaders/GLTFLoader.js */ \"./node_modules/three/examples/jsm/loaders/GLTFLoader.js\");\n/* harmony import */ var _sound_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./sound.js */ \"./src/sound.js\");\n/* harmony import */ var _energySystem_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./energySystem.js */ \"./src/energySystem.js\");\n/* harmony import */ var _css_normalise_css__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./css/normalise.css */ \"./src/css/normalise.css\");\n/* harmony import */ var _css_main_css__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./css/main.css */ \"./src/css/main.css\");\n/* harmony import */ var _usefulFunctions__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./usefulFunctions */ \"./src/usefulFunctions.js\");\n\n// Option 1: Import the entire three.js core library.\n\n\n\n// import {\n//     SteeringEntity\n// } from './three-steer';\n// import {\n//     isMobile,\n//     getRandomInt,\n//     scale,\n//     isEmpty\n// } from './usefulFunctions.js';\n\n\n\n\n\n//////////////////////////////////////////////////////////////////////////////\nlet entityManager, time, vehicle, target;\n\n// Canvas\nconst canvas = document.getElementById('webgl');\n\n// init energy system\n_energySystem_js__WEBPACK_IMPORTED_MODULE_3__.initEnergy();\n_energySystem_js__WEBPACK_IMPORTED_MODULE_3__.saveStartTime();\n\n// Scene\nconst scene = new three__WEBPACK_IMPORTED_MODULE_7__.Scene();\nscene.fog = new three__WEBPACK_IMPORTED_MODULE_7__.Fog(0x000000, 0.1, 20)\n// scene.background = new THREE.Color(0x000000);\n\n// Instantiate a loader\nconst loader = new three_examples_jsm_loaders_GLTFLoader_js__WEBPACK_IMPORTED_MODULE_1__.GLTFLoader();\n\nlet something;\nlet somethingLoadedFlag = false;\nlet action, mixer, clips, clip;\nlet floatAction, swimAction;\n\n// Load a glTF resource\nloader.load(\n    // resource URL\n    'media/somethinganimation.gltf',\n    // called when the resource is loaded\n    function (gltf) {\n        scene.add(gltf.scene);\n        // let entity = new SteeringEntity(gltf.scene);\n        // scene.add(entity);\n\n        // Create an AnimationMixer, and get the list of AnimationClip instances\n        mixer = new three__WEBPACK_IMPORTED_MODULE_7__.AnimationMixer(gltf.scene);\n        clips = gltf.animations;\n\n        // Play a specific animation\n        clip = three__WEBPACK_IMPORTED_MODULE_7__.AnimationClip.findByName(clips, 'float');\n        action = mixer.clipAction(clip);\n        action.play();\n\n        gltf.scene.name = \"something\"\n        gltf.scene.castShadow = true;\n        gltf.scene.scale.set(0.6, 0.6, 0.6);\n        gltf.scene.translateX((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(-2,2));\n        gltf.scene.translateZ((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(-1,1));\n        gltf.scene.translateY((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(-2,2));\n        gltf.scenes; // Array<THREE.Group>\n        gltf.cameras; // Array<THREE.Camera>\n        gltf.asset; // Object\n\n        // grab the something once its loaded and mark as loaded\n        something = scene.getObjectByName(\"something\")\n        somethingLoadedFlag = true;\n    },\n    // called while loading is progressing\n    function (xhr) {\n        console.log((xhr.loaded / xhr.total * 100) + '% loaded');\n    },\n    // called when loading has errors\n    function (error) {\n        console.log('An error happened');\n    }\n);\n\nconst importTexture = async (url, material) => {\n    const loader = new three__WEBPACK_IMPORTED_MODULE_7__.TextureLoader();\n    const texture = await loader.loadAsync(url);\n    material.map = texture;\n    material.transparent = true;\n    material.needsUpdate = true;\n    return texture;\n}\n\n//usage\nconst mapGeo = new three__WEBPACK_IMPORTED_MODULE_7__.PlaneGeometry(7, 7);\n\nconst matDetails = new three__WEBPACK_IMPORTED_MODULE_7__.MeshBasicMaterial();\nconst meshDetails = new three__WEBPACK_IMPORTED_MODULE_7__.Mesh(mapGeo, matDetails);\nmeshDetails.translateZ(-0.5);\nmeshDetails.castShadow = true;\nscene.add(meshDetails);\n\nconst matOne = new three__WEBPACK_IMPORTED_MODULE_7__.MeshBasicMaterial();\nconst meshOne = new three__WEBPACK_IMPORTED_MODULE_7__.Mesh(mapGeo, matOne);\nmeshOne.translateZ(-0.8);\nmeshOne.castShadow = true;\nscene.add(meshOne);\n\nconst matTwo = new three__WEBPACK_IMPORTED_MODULE_7__.MeshBasicMaterial();\nconst meshTwo = new three__WEBPACK_IMPORTED_MODULE_7__.Mesh(mapGeo, matTwo);\nmeshTwo.translateZ(-2.7);\nmeshTwo.castShadow = true;\nscene.add(meshTwo);\n\nconst matThree = new three__WEBPACK_IMPORTED_MODULE_7__.MeshBasicMaterial();\nconst meshThree = new three__WEBPACK_IMPORTED_MODULE_7__.Mesh(mapGeo, matThree);\nmeshThree.translateZ(-1.7);\nmeshThree.castShadow = true;\nscene.add(meshThree);\n\n//this is asynchronous\nimportTexture('media/details.png', matDetails);\nimportTexture('media/map_1.png', matOne);\nimportTexture('media/map_2.png', matTwo);\nimportTexture('media/map_3.png', matThree);\n\n// Lights\n// white spotlight shining from the side, casting a shadow\n\nconst spotLight = new three__WEBPACK_IMPORTED_MODULE_7__.SpotLight(0xffffff);\nspotLight.position.set(100, 1000, 100);\n\nspotLight.castShadow = true;\n\nspotLight.shadow.mapSize.width = 1024;\nspotLight.shadow.mapSize.height = 1024;\n\nspotLight.shadow.camera.near = 500;\nspotLight.shadow.camera.far = 4000;\nspotLight.shadow.camera.fov = 30;\n\nscene.add(spotLight);\n\n// Sizes\nlet sizes = {\n    width: window.innerWidth,\n    height: window.innerHeight\n}\n\n// Camera\nconst camera = new three__WEBPACK_IMPORTED_MODULE_7__.PerspectiveCamera(75, sizes.width / sizes.height, 0.1, 100);\ncamera.position.x = 0;\ncamera.position.y = 0;\ncamera.position.z = 2;\nscene.add(camera);\n\nconst controls = new three_examples_jsm_controls_OrbitControls_js__WEBPACK_IMPORTED_MODULE_0__.OrbitControls(camera, canvas)\ncontrols.enableDamping = true;\ncontrols.dampingFactor = 0.08;\ncontrols.enableZoom = true;\ncontrols.maxDistance = 2.5;\ncontrols.minDistance = 1;\n\n// set up the controls, which buttons and touches do what\ncontrols.mouseButtons.LEFT = three__WEBPACK_IMPORTED_MODULE_7__.MOUSE.PAN;\ncontrols.touches.ONE = three__WEBPACK_IMPORTED_MODULE_7__.TOUCH.PAN;\n\n// Renderer\nconst renderer = new three__WEBPACK_IMPORTED_MODULE_7__.WebGLRenderer({\n    canvas: canvas,\n    alpha: true,\n    antialias: true\n});\nrenderer.setClearColor(0x000000, 0); // the default\nrenderer.setSize(sizes.width, sizes.height);\nrenderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));\n\n// this bit sets up boundaries for the pan, effectively \n// creating the edges of the 'map'\nvar minPan = new three__WEBPACK_IMPORTED_MODULE_7__.Vector3(-4, -4, -4);\nvar maxPan = new three__WEBPACK_IMPORTED_MODULE_7__.Vector3(4, 4, 4);\nvar _v = new three__WEBPACK_IMPORTED_MODULE_7__.Vector3();\ncontrols.addEventListener(\"change\", function () {\n    _v.copy(controls.target);\n    controls.target.clamp(minPan, maxPan);\n    _v.sub(controls.target);\n    camera.position.sub(_v);\n})\n\n\n// keep the same size even if window is resized\nwindow.addEventListener('resize', () => {\n    // Update sizes\n    sizes.width = window.innerWidth;\n    sizes.height = window.innerHeight;\n\n    // Update camera\n    camera.aspect = sizes.width / sizes.height;\n    camera.updateProjectionMatrix();\n\n    // Update renderer\n    renderer.setSize(sizes.width, sizes.height);\n    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));\n})\n\nlet mousedownTime;\nlet mouseDownFlag = false;\nlet playPromise;\n\n// only play video when user interacts with piece to give movement\nconst mainVideo = document.getElementById('mainVideo');\nwindow.addEventListener('pointerdown', () => {\n    mousedownTime = new Date().getTime();\n    mouseDownFlag = true;\n    playPromise = mainVideo.play();\n})\nwindow.addEventListener('pointerup', () => {\n    // stop the incrementing saturation\n    mouseDownFlag = false;\n    // make sure there's something playing to pause\n    if (playPromise !== undefined) {\n        mainVideo.pause();\n    }\n})\n\nconst clock = new three__WEBPACK_IMPORTED_MODULE_7__.Clock();\nlet saveCount = 0;\nlet liveEnergyCounter = 0;\nlet currentEnergy;\nlet delta;\nlet teleportCount = 0;\nlet energy;\n\nconst tick = () => {\n    energy = _energySystem_js__WEBPACK_IMPORTED_MODULE_3__.readEnergy();\n    // every now and then during the session, store the time \n    // into a local storage var called lastseen\n    if (saveCount % 300 === 0) {\n        // save the time in local storage \n        localStorage.setItem('lastSeen', String(Date.now()));\n        saveCount = 0;\n    }\n    saveCount++;\n\n    // every now and then the something teleports\n    if (teleportCount % parseInt(300) === 0) {\n        if (somethingLoadedFlag === true) {\n            something.position.x = ((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(-2,2));\n            something.position.y = ((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(-2,2));\n            something.position.z = ((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(-1,1));\n            \n            // if the something is happy play happy noises\n            if (energy > 700) {\n                _sound_js__WEBPACK_IMPORTED_MODULE_2__.player.buffer = _sound_js__WEBPACK_IMPORTED_MODULE_2__.vocalSamples.get(_sound_js__WEBPACK_IMPORTED_MODULE_2__.happySampleNames[(0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_6__.getRandomInt)(0, _sound_js__WEBPACK_IMPORTED_MODULE_2__.happySampleNames.length)]);\n                _sound_js__WEBPACK_IMPORTED_MODULE_2__.player.start();\n            }\n        }\n        teleportCount = 0;\n    }\n    teleportCount++;\n\n    // gradually decrease the energy if its more than 0\n    if (liveEnergyCounter % 1000000 === 0) {\n        // decrease energy\n        currentEnergy = _energySystem_js__WEBPACK_IMPORTED_MODULE_3__.decreaseEnergy(1);\n        liveEnergyCounter = 0;\n\n        canvas.style.filter = \"saturate(\" + currentEnergy * 0.001 + \") blur(\" + (1000 - currentEnergy) * 0.001 + \"px)\";\n    }\n    if (mouseDownFlag === true) {\n        // figure out the time now the mouse is up\n        const mouseupTime = new Date().getTime(),\n            timeDifference = (mouseupTime - mousedownTime) * 0.005;\n        _energySystem_js__WEBPACK_IMPORTED_MODULE_3__.increaseEnergy(timeDifference);\n    }\n\n    if (somethingLoadedFlag === true) {\n        something.rotation.x += 0.001;\n        something.rotation.z += 0.001;\n        meshDetails.rotation.z += 0.0001;\n        meshOne.rotation.z -= 0.0001;\n    }\n\n    delta = clock.getDelta()\n    if (mixer) {\n        mixer.update(delta);\n    }\n\n\n    // Update Orbital Controls\n    controls.update()\n\n    // Render\n    renderer.render(scene, camera);\n\n    // Call tick again on the next frame\n    window.requestAnimationFrame(tick);\n}\ntick();\n\n\n//# sourceURL=webpack://Something/./src/index.js?");

/***/ }),

/***/ "./src/sound.js":
/*!**********************!*\
  !*** ./src/sound.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"chorus\": () => (/* binding */ chorus),\n/* harmony export */   \"happySampleNames\": () => (/* binding */ happySampleNames),\n/* harmony export */   \"loop\": () => (/* binding */ loop),\n/* harmony export */   \"player\": () => (/* binding */ player),\n/* harmony export */   \"synth\": () => (/* binding */ synth),\n/* harmony export */   \"vocalSamples\": () => (/* binding */ vocalSamples)\n/* harmony export */ });\n/* harmony import */ var tone__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! tone */ \"./node_modules/tone/build/esm/index.js\");\n/* harmony import */ var _usefulFunctions__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./usefulFunctions */ \"./src/usefulFunctions.js\");\n/* harmony import */ var _energySystem__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./energySystem */ \"./src/energySystem.js\");\n\r\n// File to house all the tone js code\r\n\r\n// import tone\r\n\r\n\r\n\r\n\r\n//attach a click listener to a play button \r\nlet toneStartFlag = false;\r\n\r\nlet notes = [\"D#4\", \"E#4\", \"G#4\", \"A#4\", \"C#4\", \"D#5\", \"E#5\", \"G#5\", \"A#5\", \"C#5\", \"G#6\", \"A#6\", \"C#6\"];\r\nconst happySampleNames = [\"happy1\", \"happy2\"];\r\nlet firstTimeDown = true;\r\nlet synth, loop, player, vocalSamples, chorus;\r\n\r\nwindow.addEventListener('pointerdown', () => {\r\n    if (firstTimeDown === true) {\r\n        const show = document.getElementsByClassName(\"show\");\r\n        const hide = document.getElementsByClassName(\"hide\");\r\n        // once object loaded change the landing text\r\n        for (var i = 0; i < show.length; i++) {\r\n            show[i].style.display = \"none\";\r\n        }\r\n        for (var i = 0; i < hide.length; i++) {\r\n            hide[i].style.display = \"block\";\r\n        }\r\n    }\r\n    // if audio isn't setup then call the async function\r\n    if (toneStartFlag === false) setup();\r\n    // speed up if we move\r\n    if (toneStartFlag === true) {\r\n        tone__WEBPACK_IMPORTED_MODULE_0__.Transport.start();\r\n        tone__WEBPACK_IMPORTED_MODULE_0__.Transport.bpm.rampTo((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_1__.getRandomInt)(180, 220), 0.1);\r\n\r\n    }\r\n})\r\nwindow.addEventListener('pointerup', () => {\r\n    if (toneStartFlag === true) tone__WEBPACK_IMPORTED_MODULE_0__.Transport.pause();\r\n})\r\n\r\nasync function setup() {\r\n    await tone__WEBPACK_IMPORTED_MODULE_0__.start()\r\n    console.log('audio is ready')\r\n    toneStartFlag = true;\r\n\r\n    // create chorus \r\n    chorus = new tone__WEBPACK_IMPORTED_MODULE_0__.Chorus({\r\n        \"delayTime\": 4,\r\n        \"depth\": 1,\r\n        \"feedback\": 0.3,\r\n        \"spread\": 180,\r\n        \"wet\": 0.6\r\n    }).toDestination().start();\r\n\r\n    vocalSamples = new tone__WEBPACK_IMPORTED_MODULE_0__.ToneAudioBuffers({\r\n        happy1: \"/media/voiceHappy/happy_1.mp3\",\r\n        happy2: \"/media/voiceHappy/happy_2.mp3\",\r\n    }, () => {\r\n        player = new tone__WEBPACK_IMPORTED_MODULE_0__.Player().connect(chorus);\r\n        // play one of the samples when they all load\r\n        player.buffer = vocalSamples.get(happySampleNames[(0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_1__.getRandomInt)(0, happySampleNames.length)]);\r\n        player.start();\r\n    });\r\n\r\n    // create the synth\r\n    synth = new tone__WEBPACK_IMPORTED_MODULE_0__.PolySynth().connect(chorus);\r\n    // set the attributes across all the voices using 'set'\r\n    synth.set({\r\n        detune: -1200,\r\n        volume: -12\r\n    });\r\n\r\n    loop = new tone__WEBPACK_IMPORTED_MODULE_0__.Loop((time) => {\r\n        // triggered every eighth note.\r\n        //synth.triggerAttackRelease(notes[getRandomInt(0, notes.length)], (getRandomInt(1,6)*0.1));\r\n        pattern();\r\n    }, \"8n\", );\r\n    loop.humanize = true;\r\n    loop.start(0);\r\n\r\n    tone__WEBPACK_IMPORTED_MODULE_0__.Transport.start();\r\n}\r\n\r\n// gets called each loop\r\nfunction pattern() {\r\n    chorus.wet.value = Math.abs((1000 - (0,_energySystem__WEBPACK_IMPORTED_MODULE_2__.readEnergy)()) * 0.001);\r\n    synth.triggerAttackRelease(notes[(0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_1__.getRandomInt)(0, notes.length)], ((0,_usefulFunctions__WEBPACK_IMPORTED_MODULE_1__.getRandomInt)(1, 150) * 0.01));\r\n}\n\n//# sourceURL=webpack://Something/./src/sound.js?");

/***/ }),

/***/ "./src/usefulFunctions.js":
/*!********************************!*\
  !*** ./src/usefulFunctions.js ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"getRandomInt\": () => (/* binding */ getRandomInt),\n/* harmony export */   \"isEmpty\": () => (/* binding */ isEmpty),\n/* harmony export */   \"isMobile\": () => (/* binding */ isMobile),\n/* harmony export */   \"scale\": () => (/* binding */ scale)\n/* harmony export */ });\n// some useful functions and variables\r\n\r\n//initiate as false\r\n//https://stackoverflow.com/questions/3514784/what-is-the-best-way-to-detect-a-mobile-device\r\nvar isMobile = false;\r\n// device detection\r\nif (/(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|ipad|iris|kindle|Android|Silk|lge |maemo|midp|mmp|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows (ce|phone)|xda|xiino/i.test(navigator.userAgent) ||\r\n  /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(navigator.userAgent.substr(0, 4))) {\r\n  isMobile = true;\r\n}\r\n//////////////////////////////////////////////////////////////////////////////\r\nfunction getRandomInt(min, max) {\r\n  min = Math.ceil(min);\r\n  max = Math.floor(max);\r\n  //The maximum is exclusive and the minimum is inclusive\r\n  return Math.floor(Math.random() * (max - min)) + min;\r\n}\r\n//////////////////////////////////////////////////////////////////////////////\r\nfunction scale(number, inMin, inMax, outMin, outMax) {\r\n  return (number - inMin) * (outMax - outMin) / (inMax - inMin) + outMin;\r\n}\r\n//////////////////////////////////////////////////////////////////////////////\r\nfunction isEmpty(obj) {\r\n  for (var key in obj) {\r\n    if (obj.hasOwnProperty(key))\r\n      return false;\r\n  }\r\n  return true;\r\n}\r\n//////////////////////////////////////////////////////////////////////////////\r\nlet pageLoadedFlag = false;\r\nwindow.onload = function () {\r\n    pageLoadedFlag = true;\r\n}\r\n//////////////////////////////////////////////////////////////////////////////\r\n\n\n//# sourceURL=webpack://Something/./src/usefulFunctions.js?");

/***/ }),

/***/ "./node_modules/three/build/three.module.js":
/*!**************************************************!*\
  !*** ./node_modules/three/build/three.module.js ***!
  \**************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ACESFilmicToneMapping\": () => (/* binding */ ACESFilmicToneMapping),\n/* harmony export */   \"AddEquation\": () => (/* binding */ AddEquation),\n/* harmony export */   \"AddOperation\": () => (/* binding */ AddOperation),\n/* harmony export */   \"AdditiveAnimationBlendMode\": () => (/* binding */ AdditiveAnimationBlendMode),\n/* harmony export */   \"AdditiveBlending\": () => (/* binding */ AdditiveBlending),\n/* harmony export */   \"AlphaFormat\": () => (/* binding */ AlphaFormat),\n/* harmony export */   \"AlwaysDepth\": () => (/* binding */ AlwaysDepth),\n/* harmony export */   \"AlwaysStencilFunc\": () => (/* binding */ AlwaysStencilFunc),\n/* harmony export */   \"AmbientLight\": () => (/* binding */ AmbientLight),\n/* harmony export */   \"AmbientLightProbe\": () => (/* binding */ AmbientLightProbe),\n/* harmony export */   \"AnimationClip\": () => (/* binding */ AnimationClip),\n/* harmony export */   \"AnimationLoader\": () => (/* binding */ AnimationLoader),\n/* harmony export */   \"AnimationMixer\": () => (/* binding */ AnimationMixer),\n/* harmony export */   \"AnimationObjectGroup\": () => (/* binding */ AnimationObjectGroup),\n/* harmony export */   \"AnimationUtils\": () => (/* binding */ AnimationUtils),\n/* harmony export */   \"ArcCurve\": () => (/* binding */ ArcCurve),\n/* harmony export */   \"ArrayCamera\": () => (/* binding */ ArrayCamera),\n/* harmony export */   \"ArrowHelper\": () => (/* binding */ ArrowHelper),\n/* harmony export */   \"Audio\": () => (/* binding */ Audio),\n/* harmony export */   \"AudioAnalyser\": () => (/* binding */ AudioAnalyser),\n/* harmony export */   \"AudioContext\": () => (/* binding */ AudioContext),\n/* harmony export */   \"AudioListener\": () => (/* binding */ AudioListener),\n/* harmony export */   \"AudioLoader\": () => (/* binding */ AudioLoader),\n/* harmony export */   \"AxesHelper\": () => (/* binding */ AxesHelper),\n/* harmony export */   \"AxisHelper\": () => (/* binding */ AxisHelper),\n/* harmony export */   \"BackSide\": () => (/* binding */ BackSide),\n/* harmony export */   \"BasicDepthPacking\": () => (/* binding */ BasicDepthPacking),\n/* harmony export */   \"BasicShadowMap\": () => (/* binding */ BasicShadowMap),\n/* harmony export */   \"BinaryTextureLoader\": () => (/* binding */ BinaryTextureLoader),\n/* harmony export */   \"Bone\": () => (/* binding */ Bone),\n/* harmony export */   \"BooleanKeyframeTrack\": () => (/* binding */ BooleanKeyframeTrack),\n/* harmony export */   \"BoundingBoxHelper\": () => (/* binding */ BoundingBoxHelper),\n/* harmony export */   \"Box2\": () => (/* binding */ Box2),\n/* harmony export */   \"Box3\": () => (/* binding */ Box3),\n/* harmony export */   \"Box3Helper\": () => (/* binding */ Box3Helper),\n/* harmony export */   \"BoxBufferGeometry\": () => (/* binding */ BoxGeometry),\n/* harmony export */   \"BoxGeometry\": () => (/* binding */ BoxGeometry),\n/* harmony export */   \"BoxHelper\": () => (/* binding */ BoxHelper),\n/* harmony export */   \"BufferAttribute\": () => (/* binding */ BufferAttribute),\n/* harmony export */   \"BufferGeometry\": () => (/* binding */ BufferGeometry),\n/* harmony export */   \"BufferGeometryLoader\": () => (/* binding */ BufferGeometryLoader),\n/* harmony export */   \"ByteType\": () => (/* binding */ ByteType),\n/* harmony export */   \"Cache\": () => (/* binding */ Cache),\n/* harmony export */   \"Camera\": () => (/* binding */ Camera),\n/* harmony export */   \"CameraHelper\": () => (/* binding */ CameraHelper),\n/* harmony export */   \"CanvasRenderer\": () => (/* binding */ CanvasRenderer),\n/* harmony export */   \"CanvasTexture\": () => (/* binding */ CanvasTexture),\n/* harmony export */   \"CatmullRomCurve3\": () => (/* binding */ CatmullRomCurve3),\n/* harmony export */   \"CineonToneMapping\": () => (/* binding */ CineonToneMapping),\n/* harmony export */   \"CircleBufferGeometry\": () => (/* binding */ CircleGeometry),\n/* harmony export */   \"CircleGeometry\": () => (/* binding */ CircleGeometry),\n/* harmony export */   \"ClampToEdgeWrapping\": () => (/* binding */ ClampToEdgeWrapping),\n/* harmony export */   \"Clock\": () => (/* binding */ Clock),\n/* harmony export */   \"Color\": () => (/* binding */ Color),\n/* harmony export */   \"ColorKeyframeTrack\": () => (/* binding */ ColorKeyframeTrack),\n/* harmony export */   \"CompressedTexture\": () => (/* binding */ CompressedTexture),\n/* harmony export */   \"CompressedTextureLoader\": () => (/* binding */ CompressedTextureLoader),\n/* harmony export */   \"ConeBufferGeometry\": () => (/* binding */ ConeGeometry),\n/* harmony export */   \"ConeGeometry\": () => (/* binding */ ConeGeometry),\n/* harmony export */   \"CubeCamera\": () => (/* binding */ CubeCamera),\n/* harmony export */   \"CubeReflectionMapping\": () => (/* binding */ CubeReflectionMapping),\n/* harmony export */   \"CubeRefractionMapping\": () => (/* binding */ CubeRefractionMapping),\n/* harmony export */   \"CubeTexture\": () => (/* binding */ CubeTexture),\n/* harmony export */   \"CubeTextureLoader\": () => (/* binding */ CubeTextureLoader),\n/* harmony export */   \"CubeUVReflectionMapping\": () => (/* binding */ CubeUVReflectionMapping),\n/* harmony export */   \"CubeUVRefractionMapping\": () => (/* binding */ CubeUVRefractionMapping),\n/* harmony export */   \"CubicBezierCurve\": () => (/* binding */ CubicBezierCurve),\n/* harmony export */   \"CubicBezierCurve3\": () => (/* binding */ CubicBezierCurve3),\n/* harmony export */   \"CubicInterpolant\": () => (/* binding */ CubicInterpolant),\n/* harmony export */   \"CullFaceBack\": () => (/* binding */ CullFaceBack),\n/* harmony export */   \"CullFaceFront\": () => (/* binding */ CullFaceFront),\n/* harmony export */   \"CullFaceFrontBack\": () => (/* binding */ CullFaceFrontBack),\n/* harmony export */   \"CullFaceNone\": () => (/* binding */ CullFaceNone),\n/* harmony export */   \"Curve\": () => (/* binding */ Curve),\n/* harmony export */   \"CurvePath\": () => (/* binding */ CurvePath),\n/* harmony export */   \"CustomBlending\": () => (/* binding */ CustomBlending),\n/* harmony export */   \"CustomToneMapping\": () => (/* binding */ CustomToneMapping),\n/* harmony export */   \"CylinderBufferGeometry\": () => (/* binding */ CylinderGeometry),\n/* harmony export */   \"CylinderGeometry\": () => (/* binding */ CylinderGeometry),\n/* harmony export */   \"Cylindrical\": () => (/* binding */ Cylindrical),\n/* harmony export */   \"Data3DTexture\": () => (/* binding */ Data3DTexture),\n/* harmony export */   \"DataArrayTexture\": () => (/* binding */ DataArrayTexture),\n/* harmony export */   \"DataTexture\": () => (/* binding */ DataTexture),\n/* harmony export */   \"DataTexture2DArray\": () => (/* binding */ DataTexture2DArray),\n/* harmony export */   \"DataTexture3D\": () => (/* binding */ DataTexture3D),\n/* harmony export */   \"DataTextureLoader\": () => (/* binding */ DataTextureLoader),\n/* harmony export */   \"DataUtils\": () => (/* binding */ DataUtils),\n/* harmony export */   \"DecrementStencilOp\": () => (/* binding */ DecrementStencilOp),\n/* harmony export */   \"DecrementWrapStencilOp\": () => (/* binding */ DecrementWrapStencilOp),\n/* harmony export */   \"DefaultLoadingManager\": () => (/* binding */ DefaultLoadingManager),\n/* harmony export */   \"DepthFormat\": () => (/* binding */ DepthFormat),\n/* harmony export */   \"DepthStencilFormat\": () => (/* binding */ DepthStencilFormat),\n/* harmony export */   \"DepthTexture\": () => (/* binding */ DepthTexture),\n/* harmony export */   \"DirectionalLight\": () => (/* binding */ DirectionalLight),\n/* harmony export */   \"DirectionalLightHelper\": () => (/* binding */ DirectionalLightHelper),\n/* harmony export */   \"DiscreteInterpolant\": () => (/* binding */ DiscreteInterpolant),\n/* harmony export */   \"DodecahedronBufferGeometry\": () => (/* binding */ DodecahedronGeometry),\n/* harmony export */   \"DodecahedronGeometry\": () => (/* binding */ DodecahedronGeometry),\n/* harmony export */   \"DoubleSide\": () => (/* binding */ DoubleSide),\n/* harmony export */   \"DstAlphaFactor\": () => (/* binding */ DstAlphaFactor),\n/* harmony export */   \"DstColorFactor\": () => (/* binding */ DstColorFactor),\n/* harmony export */   \"DynamicBufferAttribute\": () => (/* binding */ DynamicBufferAttribute),\n/* harmony export */   \"DynamicCopyUsage\": () => (/* binding */ DynamicCopyUsage),\n/* harmony export */   \"DynamicDrawUsage\": () => (/* binding */ DynamicDrawUsage),\n/* harmony export */   \"DynamicReadUsage\": () => (/* binding */ DynamicReadUsage),\n/* harmony export */   \"EdgesGeometry\": () => (/* binding */ EdgesGeometry),\n/* harmony export */   \"EdgesHelper\": () => (/* binding */ EdgesHelper),\n/* harmony export */   \"EllipseCurve\": () => (/* binding */ EllipseCurve),\n/* harmony export */   \"EqualDepth\": () => (/* binding */ EqualDepth),\n/* harmony export */   \"EqualStencilFunc\": () => (/* binding */ EqualStencilFunc),\n/* harmony export */   \"EquirectangularReflectionMapping\": () => (/* binding */ EquirectangularReflectionMapping),\n/* harmony export */   \"EquirectangularRefractionMapping\": () => (/* binding */ EquirectangularRefractionMapping),\n/* harmony export */   \"Euler\": () => (/* binding */ Euler),\n/* harmony export */   \"EventDispatcher\": () => (/* binding */ EventDispatcher),\n/* harmony export */   \"ExtrudeBufferGeometry\": () => (/* binding */ ExtrudeGeometry),\n/* harmony export */   \"ExtrudeGeometry\": () => (/* binding */ ExtrudeGeometry),\n/* harmony export */   \"FaceColors\": () => (/* binding */ FaceColors),\n/* harmony export */   \"FileLoader\": () => (/* binding */ FileLoader),\n/* harmony export */   \"FlatShading\": () => (/* binding */ FlatShading),\n/* harmony export */   \"Float16BufferAttribute\": () => (/* binding */ Float16BufferAttribute),\n/* harmony export */   \"Float32Attribute\": () => (/* binding */ Float32Attribute),\n/* harmony export */   \"Float32BufferAttribute\": () => (/* binding */ Float32BufferAttribute),\n/* harmony export */   \"Float64Attribute\": () => (/* binding */ Float64Attribute),\n/* harmony export */   \"Float64BufferAttribute\": () => (/* binding */ Float64BufferAttribute),\n/* harmony export */   \"FloatType\": () => (/* binding */ FloatType),\n/* harmony export */   \"Fog\": () => (/* binding */ Fog),\n/* harmony export */   \"FogExp2\": () => (/* binding */ FogExp2),\n/* harmony export */   \"Font\": () => (/* binding */ Font),\n/* harmony export */   \"FontLoader\": () => (/* binding */ FontLoader),\n/* harmony export */   \"FramebufferTexture\": () => (/* binding */ FramebufferTexture),\n/* harmony export */   \"FrontSide\": () => (/* binding */ FrontSide),\n/* harmony export */   \"Frustum\": () => (/* binding */ Frustum),\n/* harmony export */   \"GLBufferAttribute\": () => (/* binding */ GLBufferAttribute),\n/* harmony export */   \"GLSL1\": () => (/* binding */ GLSL1),\n/* harmony export */   \"GLSL3\": () => (/* binding */ GLSL3),\n/* harmony export */   \"GreaterDepth\": () => (/* binding */ GreaterDepth),\n/* harmony export */   \"GreaterEqualDepth\": () => (/* binding */ GreaterEqualDepth),\n/* harmony export */   \"GreaterEqualStencilFunc\": () => (/* binding */ GreaterEqualStencilFunc),\n/* harmony export */   \"GreaterStencilFunc\": () => (/* binding */ GreaterStencilFunc),\n/* harmony export */   \"GridHelper\": () => (/* binding */ GridHelper),\n/* harmony export */   \"Group\": () => (/* binding */ Group),\n/* harmony export */   \"HalfFloatType\": () => (/* binding */ HalfFloatType),\n/* harmony export */   \"HemisphereLight\": () => (/* binding */ HemisphereLight),\n/* harmony export */   \"HemisphereLightHelper\": () => (/* binding */ HemisphereLightHelper),\n/* harmony export */   \"HemisphereLightProbe\": () => (/* binding */ HemisphereLightProbe),\n/* harmony export */   \"IcosahedronBufferGeometry\": () => (/* binding */ IcosahedronGeometry),\n/* harmony export */   \"IcosahedronGeometry\": () => (/* binding */ IcosahedronGeometry),\n/* harmony export */   \"ImageBitmapLoader\": () => (/* binding */ ImageBitmapLoader),\n/* harmony export */   \"ImageLoader\": () => (/* binding */ ImageLoader),\n/* harmony export */   \"ImageUtils\": () => (/* binding */ ImageUtils),\n/* harmony export */   \"ImmediateRenderObject\": () => (/* binding */ ImmediateRenderObject),\n/* harmony export */   \"IncrementStencilOp\": () => (/* binding */ IncrementStencilOp),\n/* harmony export */   \"IncrementWrapStencilOp\": () => (/* binding */ IncrementWrapStencilOp),\n/* harmony export */   \"InstancedBufferAttribute\": () => (/* binding */ InstancedBufferAttribute),\n/* harmony export */   \"InstancedBufferGeometry\": () => (/* binding */ InstancedBufferGeometry),\n/* harmony export */   \"InstancedInterleavedBuffer\": () => (/* binding */ InstancedInterleavedBuffer),\n/* harmony export */   \"InstancedMesh\": () => (/* binding */ InstancedMesh),\n/* harmony export */   \"Int16Attribute\": () => (/* binding */ Int16Attribute),\n/* harmony export */   \"Int16BufferAttribute\": () => (/* binding */ Int16BufferAttribute),\n/* harmony export */   \"Int32Attribute\": () => (/* binding */ Int32Attribute),\n/* harmony export */   \"Int32BufferAttribute\": () => (/* binding */ Int32BufferAttribute),\n/* harmony export */   \"Int8Attribute\": () => (/* binding */ Int8Attribute),\n/* harmony export */   \"Int8BufferAttribute\": () => (/* binding */ Int8BufferAttribute),\n/* harmony export */   \"IntType\": () => (/* binding */ IntType),\n/* harmony export */   \"InterleavedBuffer\": () => (/* binding */ InterleavedBuffer),\n/* harmony export */   \"InterleavedBufferAttribute\": () => (/* binding */ InterleavedBufferAttribute),\n/* harmony export */   \"Interpolant\": () => (/* binding */ Interpolant),\n/* harmony export */   \"InterpolateDiscrete\": () => (/* binding */ InterpolateDiscrete),\n/* harmony export */   \"InterpolateLinear\": () => (/* binding */ InterpolateLinear),\n/* harmony export */   \"InterpolateSmooth\": () => (/* binding */ InterpolateSmooth),\n/* harmony export */   \"InvertStencilOp\": () => (/* binding */ InvertStencilOp),\n/* harmony export */   \"JSONLoader\": () => (/* binding */ JSONLoader),\n/* harmony export */   \"KeepStencilOp\": () => (/* binding */ KeepStencilOp),\n/* harmony export */   \"KeyframeTrack\": () => (/* binding */ KeyframeTrack),\n/* harmony export */   \"LOD\": () => (/* binding */ LOD),\n/* harmony export */   \"LatheBufferGeometry\": () => (/* binding */ LatheGeometry),\n/* harmony export */   \"LatheGeometry\": () => (/* binding */ LatheGeometry),\n/* harmony export */   \"Layers\": () => (/* binding */ Layers),\n/* harmony export */   \"LensFlare\": () => (/* binding */ LensFlare),\n/* harmony export */   \"LessDepth\": () => (/* binding */ LessDepth),\n/* harmony export */   \"LessEqualDepth\": () => (/* binding */ LessEqualDepth),\n/* harmony export */   \"LessEqualStencilFunc\": () => (/* binding */ LessEqualStencilFunc),\n/* harmony export */   \"LessStencilFunc\": () => (/* binding */ LessStencilFunc),\n/* harmony export */   \"Light\": () => (/* binding */ Light),\n/* harmony export */   \"LightProbe\": () => (/* binding */ LightProbe),\n/* harmony export */   \"Line\": () => (/* binding */ Line),\n/* harmony export */   \"Line3\": () => (/* binding */ Line3),\n/* harmony export */   \"LineBasicMaterial\": () => (/* binding */ LineBasicMaterial),\n/* harmony export */   \"LineCurve\": () => (/* binding */ LineCurve),\n/* harmony export */   \"LineCurve3\": () => (/* binding */ LineCurve3),\n/* harmony export */   \"LineDashedMaterial\": () => (/* binding */ LineDashedMaterial),\n/* harmony export */   \"LineLoop\": () => (/* binding */ LineLoop),\n/* harmony export */   \"LinePieces\": () => (/* binding */ LinePieces),\n/* harmony export */   \"LineSegments\": () => (/* binding */ LineSegments),\n/* harmony export */   \"LineStrip\": () => (/* binding */ LineStrip),\n/* harmony export */   \"LinearEncoding\": () => (/* binding */ LinearEncoding),\n/* harmony export */   \"LinearFilter\": () => (/* binding */ LinearFilter),\n/* harmony export */   \"LinearInterpolant\": () => (/* binding */ LinearInterpolant),\n/* harmony export */   \"LinearMipMapLinearFilter\": () => (/* binding */ LinearMipMapLinearFilter),\n/* harmony export */   \"LinearMipMapNearestFilter\": () => (/* binding */ LinearMipMapNearestFilter),\n/* harmony export */   \"LinearMipmapLinearFilter\": () => (/* binding */ LinearMipmapLinearFilter),\n/* harmony export */   \"LinearMipmapNearestFilter\": () => (/* binding */ LinearMipmapNearestFilter),\n/* harmony export */   \"LinearToneMapping\": () => (/* binding */ LinearToneMapping),\n/* harmony export */   \"Loader\": () => (/* binding */ Loader),\n/* harmony export */   \"LoaderUtils\": () => (/* binding */ LoaderUtils),\n/* harmony export */   \"LoadingManager\": () => (/* binding */ LoadingManager),\n/* harmony export */   \"LoopOnce\": () => (/* binding */ LoopOnce),\n/* harmony export */   \"LoopPingPong\": () => (/* binding */ LoopPingPong),\n/* harmony export */   \"LoopRepeat\": () => (/* binding */ LoopRepeat),\n/* harmony export */   \"LuminanceAlphaFormat\": () => (/* binding */ LuminanceAlphaFormat),\n/* harmony export */   \"LuminanceFormat\": () => (/* binding */ LuminanceFormat),\n/* harmony export */   \"MOUSE\": () => (/* binding */ MOUSE),\n/* harmony export */   \"Material\": () => (/* binding */ Material),\n/* harmony export */   \"MaterialLoader\": () => (/* binding */ MaterialLoader),\n/* harmony export */   \"Math\": () => (/* binding */ MathUtils),\n/* harmony export */   \"MathUtils\": () => (/* binding */ MathUtils),\n/* harmony export */   \"Matrix3\": () => (/* binding */ Matrix3),\n/* harmony export */   \"Matrix4\": () => (/* binding */ Matrix4),\n/* harmony export */   \"MaxEquation\": () => (/* binding */ MaxEquation),\n/* harmony export */   \"Mesh\": () => (/* binding */ Mesh),\n/* harmony export */   \"MeshBasicMaterial\": () => (/* binding */ MeshBasicMaterial),\n/* harmony export */   \"MeshDepthMaterial\": () => (/* binding */ MeshDepthMaterial),\n/* harmony export */   \"MeshDistanceMaterial\": () => (/* binding */ MeshDistanceMaterial),\n/* harmony export */   \"MeshFaceMaterial\": () => (/* binding */ MeshFaceMaterial),\n/* harmony export */   \"MeshLambertMaterial\": () => (/* binding */ MeshLambertMaterial),\n/* harmony export */   \"MeshMatcapMaterial\": () => (/* binding */ MeshMatcapMaterial),\n/* harmony export */   \"MeshNormalMaterial\": () => (/* binding */ MeshNormalMaterial),\n/* harmony export */   \"MeshPhongMaterial\": () => (/* binding */ MeshPhongMaterial),\n/* harmony export */   \"MeshPhysicalMaterial\": () => (/* binding */ MeshPhysicalMaterial),\n/* harmony export */   \"MeshStandardMaterial\": () => (/* binding */ MeshStandardMaterial),\n/* harmony export */   \"MeshToonMaterial\": () => (/* binding */ MeshToonMaterial),\n/* harmony export */   \"MinEquation\": () => (/* binding */ MinEquation),\n/* harmony export */   \"MirroredRepeatWrapping\": () => (/* binding */ MirroredRepeatWrapping),\n/* harmony export */   \"MixOperation\": () => (/* binding */ MixOperation),\n/* harmony export */   \"MultiMaterial\": () => (/* binding */ MultiMaterial),\n/* harmony export */   \"MultiplyBlending\": () => (/* binding */ MultiplyBlending),\n/* harmony export */   \"MultiplyOperation\": () => (/* binding */ MultiplyOperation),\n/* harmony export */   \"NearestFilter\": () => (/* binding */ NearestFilter),\n/* harmony export */   \"NearestMipMapLinearFilter\": () => (/* binding */ NearestMipMapLinearFilter),\n/* harmony export */   \"NearestMipMapNearestFilter\": () => (/* binding */ NearestMipMapNearestFilter),\n/* harmony export */   \"NearestMipmapLinearFilter\": () => (/* binding */ NearestMipmapLinearFilter),\n/* harmony export */   \"NearestMipmapNearestFilter\": () => (/* binding */ NearestMipmapNearestFilter),\n/* harmony export */   \"NeverDepth\": () => (/* binding */ NeverDepth),\n/* harmony export */   \"NeverStencilFunc\": () => (/* binding */ NeverStencilFunc),\n/* harmony export */   \"NoBlending\": () => (/* binding */ NoBlending),\n/* harmony export */   \"NoColors\": () => (/* binding */ NoColors),\n/* harmony export */   \"NoToneMapping\": () => (/* binding */ NoToneMapping),\n/* harmony export */   \"NormalAnimationBlendMode\": () => (/* binding */ NormalAnimationBlendMode),\n/* harmony export */   \"NormalBlending\": () => (/* binding */ NormalBlending),\n/* harmony export */   \"NotEqualDepth\": () => (/* binding */ NotEqualDepth),\n/* harmony export */   \"NotEqualStencilFunc\": () => (/* binding */ NotEqualStencilFunc),\n/* harmony export */   \"NumberKeyframeTrack\": () => (/* binding */ NumberKeyframeTrack),\n/* harmony export */   \"Object3D\": () => (/* binding */ Object3D),\n/* harmony export */   \"ObjectLoader\": () => (/* binding */ ObjectLoader),\n/* harmony export */   \"ObjectSpaceNormalMap\": () => (/* binding */ ObjectSpaceNormalMap),\n/* harmony export */   \"OctahedronBufferGeometry\": () => (/* binding */ OctahedronGeometry),\n/* harmony export */   \"OctahedronGeometry\": () => (/* binding */ OctahedronGeometry),\n/* harmony export */   \"OneFactor\": () => (/* binding */ OneFactor),\n/* harmony export */   \"OneMinusDstAlphaFactor\": () => (/* binding */ OneMinusDstAlphaFactor),\n/* harmony export */   \"OneMinusDstColorFactor\": () => (/* binding */ OneMinusDstColorFactor),\n/* harmony export */   \"OneMinusSrcAlphaFactor\": () => (/* binding */ OneMinusSrcAlphaFactor),\n/* harmony export */   \"OneMinusSrcColorFactor\": () => (/* binding */ OneMinusSrcColorFactor),\n/* harmony export */   \"OrthographicCamera\": () => (/* binding */ OrthographicCamera),\n/* harmony export */   \"PCFShadowMap\": () => (/* binding */ PCFShadowMap),\n/* harmony export */   \"PCFSoftShadowMap\": () => (/* binding */ PCFSoftShadowMap),\n/* harmony export */   \"PMREMGenerator\": () => (/* binding */ PMREMGenerator),\n/* harmony export */   \"ParametricGeometry\": () => (/* binding */ ParametricGeometry),\n/* harmony export */   \"Particle\": () => (/* binding */ Particle),\n/* harmony export */   \"ParticleBasicMaterial\": () => (/* binding */ ParticleBasicMaterial),\n/* harmony export */   \"ParticleSystem\": () => (/* binding */ ParticleSystem),\n/* harmony export */   \"ParticleSystemMaterial\": () => (/* binding */ ParticleSystemMaterial),\n/* harmony export */   \"Path\": () => (/* binding */ Path),\n/* harmony export */   \"PerspectiveCamera\": () => (/* binding */ PerspectiveCamera),\n/* harmony export */   \"Plane\": () => (/* binding */ Plane),\n/* harmony export */   \"PlaneBufferGeometry\": () => (/* binding */ PlaneGeometry),\n/* harmony export */   \"PlaneGeometry\": () => (/* binding */ PlaneGeometry),\n/* harmony export */   \"PlaneHelper\": () => (/* binding */ PlaneHelper),\n/* harmony export */   \"PointCloud\": () => (/* binding */ PointCloud),\n/* harmony export */   \"PointCloudMaterial\": () => (/* binding */ PointCloudMaterial),\n/* harmony export */   \"PointLight\": () => (/* binding */ PointLight),\n/* harmony export */   \"PointLightHelper\": () => (/* binding */ PointLightHelper),\n/* harmony export */   \"Points\": () => (/* binding */ Points),\n/* harmony export */   \"PointsMaterial\": () => (/* binding */ PointsMaterial),\n/* harmony export */   \"PolarGridHelper\": () => (/* binding */ PolarGridHelper),\n/* harmony export */   \"PolyhedronBufferGeometry\": () => (/* binding */ PolyhedronGeometry),\n/* harmony export */   \"PolyhedronGeometry\": () => (/* binding */ PolyhedronGeometry),\n/* harmony export */   \"PositionalAudio\": () => (/* binding */ PositionalAudio),\n/* harmony export */   \"PropertyBinding\": () => (/* binding */ PropertyBinding),\n/* harmony export */   \"PropertyMixer\": () => (/* binding */ PropertyMixer),\n/* harmony export */   \"QuadraticBezierCurve\": () => (/* binding */ QuadraticBezierCurve),\n/* harmony export */   \"QuadraticBezierCurve3\": () => (/* binding */ QuadraticBezierCurve3),\n/* harmony export */   \"Quaternion\": () => (/* binding */ Quaternion),\n/* harmony export */   \"QuaternionKeyframeTrack\": () => (/* binding */ QuaternionKeyframeTrack),\n/* harmony export */   \"QuaternionLinearInterpolant\": () => (/* binding */ QuaternionLinearInterpolant),\n/* harmony export */   \"REVISION\": () => (/* binding */ REVISION),\n/* harmony export */   \"RGBADepthPacking\": () => (/* binding */ RGBADepthPacking),\n/* harmony export */   \"RGBAFormat\": () => (/* binding */ RGBAFormat),\n/* harmony export */   \"RGBAIntegerFormat\": () => (/* binding */ RGBAIntegerFormat),\n/* harmony export */   \"RGBA_ASTC_10x10_Format\": () => (/* binding */ RGBA_ASTC_10x10_Format),\n/* harmony export */   \"RGBA_ASTC_10x5_Format\": () => (/* binding */ RGBA_ASTC_10x5_Format),\n/* harmony export */   \"RGBA_ASTC_10x6_Format\": () => (/* binding */ RGBA_ASTC_10x6_Format),\n/* harmony export */   \"RGBA_ASTC_10x8_Format\": () => (/* binding */ RGBA_ASTC_10x8_Format),\n/* harmony export */   \"RGBA_ASTC_12x10_Format\": () => (/* binding */ RGBA_ASTC_12x10_Format),\n/* harmony export */   \"RGBA_ASTC_12x12_Format\": () => (/* binding */ RGBA_ASTC_12x12_Format),\n/* harmony export */   \"RGBA_ASTC_4x4_Format\": () => (/* binding */ RGBA_ASTC_4x4_Format),\n/* harmony export */   \"RGBA_ASTC_5x4_Format\": () => (/* binding */ RGBA_ASTC_5x4_Format),\n/* harmony export */   \"RGBA_ASTC_5x5_Format\": () => (/* binding */ RGBA_ASTC_5x5_Format),\n/* harmony export */   \"RGBA_ASTC_6x5_Format\": () => (/* binding */ RGBA_ASTC_6x5_Format),\n/* harmony export */   \"RGBA_ASTC_6x6_Format\": () => (/* binding */ RGBA_ASTC_6x6_Format),\n/* harmony export */   \"RGBA_ASTC_8x5_Format\": () => (/* binding */ RGBA_ASTC_8x5_Format),\n/* harmony export */   \"RGBA_ASTC_8x6_Format\": () => (/* binding */ RGBA_ASTC_8x6_Format),\n/* harmony export */   \"RGBA_ASTC_8x8_Format\": () => (/* binding */ RGBA_ASTC_8x8_Format),\n/* harmony export */   \"RGBA_BPTC_Format\": () => (/* binding */ RGBA_BPTC_Format),\n/* harmony export */   \"RGBA_ETC2_EAC_Format\": () => (/* binding */ RGBA_ETC2_EAC_Format),\n/* harmony export */   \"RGBA_PVRTC_2BPPV1_Format\": () => (/* binding */ RGBA_PVRTC_2BPPV1_Format),\n/* harmony export */   \"RGBA_PVRTC_4BPPV1_Format\": () => (/* binding */ RGBA_PVRTC_4BPPV1_Format),\n/* harmony export */   \"RGBA_S3TC_DXT1_Format\": () => (/* binding */ RGBA_S3TC_DXT1_Format),\n/* harmony export */   \"RGBA_S3TC_DXT3_Format\": () => (/* binding */ RGBA_S3TC_DXT3_Format),\n/* harmony export */   \"RGBA_S3TC_DXT5_Format\": () => (/* binding */ RGBA_S3TC_DXT5_Format),\n/* harmony export */   \"RGBFormat\": () => (/* binding */ RGBFormat),\n/* harmony export */   \"RGB_ETC1_Format\": () => (/* binding */ RGB_ETC1_Format),\n/* harmony export */   \"RGB_ETC2_Format\": () => (/* binding */ RGB_ETC2_Format),\n/* harmony export */   \"RGB_PVRTC_2BPPV1_Format\": () => (/* binding */ RGB_PVRTC_2BPPV1_Format),\n/* harmony export */   \"RGB_PVRTC_4BPPV1_Format\": () => (/* binding */ RGB_PVRTC_4BPPV1_Format),\n/* harmony export */   \"RGB_S3TC_DXT1_Format\": () => (/* binding */ RGB_S3TC_DXT1_Format),\n/* harmony export */   \"RGFormat\": () => (/* binding */ RGFormat),\n/* harmony export */   \"RGIntegerFormat\": () => (/* binding */ RGIntegerFormat),\n/* harmony export */   \"RawShaderMaterial\": () => (/* binding */ RawShaderMaterial),\n/* harmony export */   \"Ray\": () => (/* binding */ Ray),\n/* harmony export */   \"Raycaster\": () => (/* binding */ Raycaster),\n/* harmony export */   \"RectAreaLight\": () => (/* binding */ RectAreaLight),\n/* harmony export */   \"RedFormat\": () => (/* binding */ RedFormat),\n/* harmony export */   \"RedIntegerFormat\": () => (/* binding */ RedIntegerFormat),\n/* harmony export */   \"ReinhardToneMapping\": () => (/* binding */ ReinhardToneMapping),\n/* harmony export */   \"RepeatWrapping\": () => (/* binding */ RepeatWrapping),\n/* harmony export */   \"ReplaceStencilOp\": () => (/* binding */ ReplaceStencilOp),\n/* harmony export */   \"ReverseSubtractEquation\": () => (/* binding */ ReverseSubtractEquation),\n/* harmony export */   \"RingBufferGeometry\": () => (/* binding */ RingGeometry),\n/* harmony export */   \"RingGeometry\": () => (/* binding */ RingGeometry),\n/* harmony export */   \"Scene\": () => (/* binding */ Scene),\n/* harmony export */   \"SceneUtils\": () => (/* binding */ SceneUtils),\n/* harmony export */   \"ShaderChunk\": () => (/* binding */ ShaderChunk),\n/* harmony export */   \"ShaderLib\": () => (/* binding */ ShaderLib),\n/* harmony export */   \"ShaderMaterial\": () => (/* binding */ ShaderMaterial),\n/* harmony export */   \"ShadowMaterial\": () => (/* binding */ ShadowMaterial),\n/* harmony export */   \"Shape\": () => (/* binding */ Shape),\n/* harmony export */   \"ShapeBufferGeometry\": () => (/* binding */ ShapeGeometry),\n/* harmony export */   \"ShapeGeometry\": () => (/* binding */ ShapeGeometry),\n/* harmony export */   \"ShapePath\": () => (/* binding */ ShapePath),\n/* harmony export */   \"ShapeUtils\": () => (/* binding */ ShapeUtils),\n/* harmony export */   \"ShortType\": () => (/* binding */ ShortType),\n/* harmony export */   \"Skeleton\": () => (/* binding */ Skeleton),\n/* harmony export */   \"SkeletonHelper\": () => (/* binding */ SkeletonHelper),\n/* harmony export */   \"SkinnedMesh\": () => (/* binding */ SkinnedMesh),\n/* harmony export */   \"SmoothShading\": () => (/* binding */ SmoothShading),\n/* harmony export */   \"Sphere\": () => (/* binding */ Sphere),\n/* harmony export */   \"SphereBufferGeometry\": () => (/* binding */ SphereGeometry),\n/* harmony export */   \"SphereGeometry\": () => (/* binding */ SphereGeometry),\n/* harmony export */   \"Spherical\": () => (/* binding */ Spherical),\n/* harmony export */   \"SphericalHarmonics3\": () => (/* binding */ SphericalHarmonics3),\n/* harmony export */   \"SplineCurve\": () => (/* binding */ SplineCurve),\n/* harmony export */   \"SpotLight\": () => (/* binding */ SpotLight),\n/* harmony export */   \"SpotLightHelper\": () => (/* binding */ SpotLightHelper),\n/* harmony export */   \"Sprite\": () => (/* binding */ Sprite),\n/* harmony export */   \"SpriteMaterial\": () => (/* binding */ SpriteMaterial),\n/* harmony export */   \"SrcAlphaFactor\": () => (/* binding */ SrcAlphaFactor),\n/* harmony export */   \"SrcAlphaSaturateFactor\": () => (/* binding */ SrcAlphaSaturateFactor),\n/* harmony export */   \"SrcColorFactor\": () => (/* binding */ SrcColorFactor),\n/* harmony export */   \"StaticCopyUsage\": () => (/* binding */ StaticCopyUsage),\n/* harmony export */   \"StaticDrawUsage\": () => (/* binding */ StaticDrawUsage),\n/* harmony export */   \"StaticReadUsage\": () => (/* binding */ StaticReadUsage),\n/* harmony export */   \"StereoCamera\": () => (/* binding */ StereoCamera),\n/* harmony export */   \"StreamCopyUsage\": () => (/* binding */ StreamCopyUsage),\n/* harmony export */   \"StreamDrawUsage\": () => (/* binding */ StreamDrawUsage),\n/* harmony export */   \"StreamReadUsage\": () => (/* binding */ StreamReadUsage),\n/* harmony export */   \"StringKeyframeTrack\": () => (/* binding */ StringKeyframeTrack),\n/* harmony export */   \"SubtractEquation\": () => (/* binding */ SubtractEquation),\n/* harmony export */   \"SubtractiveBlending\": () => (/* binding */ SubtractiveBlending),\n/* harmony export */   \"TOUCH\": () => (/* binding */ TOUCH),\n/* harmony export */   \"TangentSpaceNormalMap\": () => (/* binding */ TangentSpaceNormalMap),\n/* harmony export */   \"TetrahedronBufferGeometry\": () => (/* binding */ TetrahedronGeometry),\n/* harmony export */   \"TetrahedronGeometry\": () => (/* binding */ TetrahedronGeometry),\n/* harmony export */   \"TextGeometry\": () => (/* binding */ TextGeometry),\n/* harmony export */   \"Texture\": () => (/* binding */ Texture),\n/* harmony export */   \"TextureLoader\": () => (/* binding */ TextureLoader),\n/* harmony export */   \"TorusBufferGeometry\": () => (/* binding */ TorusGeometry),\n/* harmony export */   \"TorusGeometry\": () => (/* binding */ TorusGeometry),\n/* harmony export */   \"TorusKnotBufferGeometry\": () => (/* binding */ TorusKnotGeometry),\n/* harmony export */   \"TorusKnotGeometry\": () => (/* binding */ TorusKnotGeometry),\n/* harmony export */   \"Triangle\": () => (/* binding */ Triangle),\n/* harmony export */   \"TriangleFanDrawMode\": () => (/* binding */ TriangleFanDrawMode),\n/* harmony export */   \"TriangleStripDrawMode\": () => (/* binding */ TriangleStripDrawMode),\n/* harmony export */   \"TrianglesDrawMode\": () => (/* binding */ TrianglesDrawMode),\n/* harmony export */   \"TubeBufferGeometry\": () => (/* binding */ TubeGeometry),\n/* harmony export */   \"TubeGeometry\": () => (/* binding */ TubeGeometry),\n/* harmony export */   \"UVMapping\": () => (/* binding */ UVMapping),\n/* harmony export */   \"Uint16Attribute\": () => (/* binding */ Uint16Attribute),\n/* harmony export */   \"Uint16BufferAttribute\": () => (/* binding */ Uint16BufferAttribute),\n/* harmony export */   \"Uint32Attribute\": () => (/* binding */ Uint32Attribute),\n/* harmony export */   \"Uint32BufferAttribute\": () => (/* binding */ Uint32BufferAttribute),\n/* harmony export */   \"Uint8Attribute\": () => (/* binding */ Uint8Attribute),\n/* harmony export */   \"Uint8BufferAttribute\": () => (/* binding */ Uint8BufferAttribute),\n/* harmony export */   \"Uint8ClampedAttribute\": () => (/* binding */ Uint8ClampedAttribute),\n/* harmony export */   \"Uint8ClampedBufferAttribute\": () => (/* binding */ Uint8ClampedBufferAttribute),\n/* harmony export */   \"Uniform\": () => (/* binding */ Uniform),\n/* harmony export */   \"UniformsLib\": () => (/* binding */ UniformsLib),\n/* harmony export */   \"UniformsUtils\": () => (/* binding */ UniformsUtils),\n/* harmony export */   \"UnsignedByteType\": () => (/* binding */ UnsignedByteType),\n/* harmony export */   \"UnsignedInt248Type\": () => (/* binding */ UnsignedInt248Type),\n/* harmony export */   \"UnsignedIntType\": () => (/* binding */ UnsignedIntType),\n/* harmony export */   \"UnsignedShort4444Type\": () => (/* binding */ UnsignedShort4444Type),\n/* harmony export */   \"UnsignedShort5551Type\": () => (/* binding */ UnsignedShort5551Type),\n/* harmony export */   \"UnsignedShortType\": () => (/* binding */ UnsignedShortType),\n/* harmony export */   \"VSMShadowMap\": () => (/* binding */ VSMShadowMap),\n/* harmony export */   \"Vector2\": () => (/* binding */ Vector2),\n/* harmony export */   \"Vector3\": () => (/* binding */ Vector3),\n/* harmony export */   \"Vector4\": () => (/* binding */ Vector4),\n/* harmony export */   \"VectorKeyframeTrack\": () => (/* binding */ VectorKeyframeTrack),\n/* harmony export */   \"Vertex\": () => (/* binding */ Vertex),\n/* harmony export */   \"VertexColors\": () => (/* binding */ VertexColors),\n/* harmony export */   \"VideoTexture\": () => (/* binding */ VideoTexture),\n/* harmony export */   \"WebGL1Renderer\": () => (/* binding */ WebGL1Renderer),\n/* harmony export */   \"WebGL3DRenderTarget\": () => (/* binding */ WebGL3DRenderTarget),\n/* harmony export */   \"WebGLArrayRenderTarget\": () => (/* binding */ WebGLArrayRenderTarget),\n/* harmony export */   \"WebGLCubeRenderTarget\": () => (/* binding */ WebGLCubeRenderTarget),\n/* harmony export */   \"WebGLMultipleRenderTargets\": () => (/* binding */ WebGLMultipleRenderTargets),\n/* harmony export */   \"WebGLMultisampleRenderTarget\": () => (/* binding */ WebGLMultisampleRenderTarget),\n/* harmony export */   \"WebGLRenderTarget\": () => (/* binding */ WebGLRenderTarget),\n/* harmony export */   \"WebGLRenderTargetCube\": () => (/* binding */ WebGLRenderTargetCube),\n/* harmony export */   \"WebGLRenderer\": () => (/* binding */ WebGLRenderer),\n/* harmony export */   \"WebGLUtils\": () => (/* binding */ WebGLUtils),\n/* harmony export */   \"WireframeGeometry\": () => (/* binding */ WireframeGeometry),\n/* harmony export */   \"WireframeHelper\": () => (/* binding */ WireframeHelper),\n/* harmony export */   \"WrapAroundEnding\": () => (/* binding */ WrapAroundEnding),\n/* harmony export */   \"XHRLoader\": () => (/* binding */ XHRLoader),\n/* harmony export */   \"ZeroCurvatureEnding\": () => (/* binding */ ZeroCurvatureEnding),\n/* harmony export */   \"ZeroFactor\": () => (/* binding */ ZeroFactor),\n/* harmony export */   \"ZeroSlopeEnding\": () => (/* binding */ ZeroSlopeEnding),\n/* harmony export */   \"ZeroStencilOp\": () => (/* binding */ ZeroStencilOp),\n/* harmony export */   \"_SRGBAFormat\": () => (/* binding */ _SRGBAFormat),\n/* harmony export */   \"sRGBEncoding\": () => (/* binding */ sRGBEncoding)\n/* harmony export */ });\n/**\n * @license\n * Copyright 2010-2022 Three.js Authors\n * SPDX-License-Identifier: MIT\n */\nconst REVISION = '138';\nconst MOUSE = { LEFT: 0, MIDDLE: 1, RIGHT: 2, ROTATE: 0, DOLLY: 1, PAN: 2 };\nconst TOUCH = { ROTATE: 0, PAN: 1, DOLLY_PAN: 2, DOLLY_ROTATE: 3 };\nconst CullFaceNone = 0;\nconst CullFaceBack = 1;\nconst CullFaceFront = 2;\nconst CullFaceFrontBack = 3;\nconst BasicShadowMap = 0;\nconst PCFShadowMap = 1;\nconst PCFSoftShadowMap = 2;\nconst VSMShadowMap = 3;\nconst FrontSide = 0;\nconst BackSide = 1;\nconst DoubleSide = 2;\nconst FlatShading = 1;\nconst SmoothShading = 2;\nconst NoBlending = 0;\nconst NormalBlending = 1;\nconst AdditiveBlending = 2;\nconst SubtractiveBlending = 3;\nconst MultiplyBlending = 4;\nconst CustomBlending = 5;\nconst AddEquation = 100;\nconst SubtractEquation = 101;\nconst ReverseSubtractEquation = 102;\nconst MinEquation = 103;\nconst MaxEquation = 104;\nconst ZeroFactor = 200;\nconst OneFactor = 201;\nconst SrcColorFactor = 202;\nconst OneMinusSrcColorFactor = 203;\nconst SrcAlphaFactor = 204;\nconst OneMinusSrcAlphaFactor = 205;\nconst DstAlphaFactor = 206;\nconst OneMinusDstAlphaFactor = 207;\nconst DstColorFactor = 208;\nconst OneMinusDstColorFactor = 209;\nconst SrcAlphaSaturateFactor = 210;\nconst NeverDepth = 0;\nconst AlwaysDepth = 1;\nconst LessDepth = 2;\nconst LessEqualDepth = 3;\nconst EqualDepth = 4;\nconst GreaterEqualDepth = 5;\nconst GreaterDepth = 6;\nconst NotEqualDepth = 7;\nconst MultiplyOperation = 0;\nconst MixOperation = 1;\nconst AddOperation = 2;\nconst NoToneMapping = 0;\nconst LinearToneMapping = 1;\nconst ReinhardToneMapping = 2;\nconst CineonToneMapping = 3;\nconst ACESFilmicToneMapping = 4;\nconst CustomToneMapping = 5;\n\nconst UVMapping = 300;\nconst CubeReflectionMapping = 301;\nconst CubeRefractionMapping = 302;\nconst EquirectangularReflectionMapping = 303;\nconst EquirectangularRefractionMapping = 304;\nconst CubeUVReflectionMapping = 306;\nconst CubeUVRefractionMapping = 307;\nconst RepeatWrapping = 1000;\nconst ClampToEdgeWrapping = 1001;\nconst MirroredRepeatWrapping = 1002;\nconst NearestFilter = 1003;\nconst NearestMipmapNearestFilter = 1004;\nconst NearestMipMapNearestFilter = 1004;\nconst NearestMipmapLinearFilter = 1005;\nconst NearestMipMapLinearFilter = 1005;\nconst LinearFilter = 1006;\nconst LinearMipmapNearestFilter = 1007;\nconst LinearMipMapNearestFilter = 1007;\nconst LinearMipmapLinearFilter = 1008;\nconst LinearMipMapLinearFilter = 1008;\nconst UnsignedByteType = 1009;\nconst ByteType = 1010;\nconst ShortType = 1011;\nconst UnsignedShortType = 1012;\nconst IntType = 1013;\nconst UnsignedIntType = 1014;\nconst FloatType = 1015;\nconst HalfFloatType = 1016;\nconst UnsignedShort4444Type = 1017;\nconst UnsignedShort5551Type = 1018;\nconst UnsignedInt248Type = 1020;\nconst AlphaFormat = 1021;\nconst RGBFormat = 1022;\nconst RGBAFormat = 1023;\nconst LuminanceFormat = 1024;\nconst LuminanceAlphaFormat = 1025;\nconst DepthFormat = 1026;\nconst DepthStencilFormat = 1027;\nconst RedFormat = 1028;\nconst RedIntegerFormat = 1029;\nconst RGFormat = 1030;\nconst RGIntegerFormat = 1031;\nconst RGBAIntegerFormat = 1033;\n\nconst RGB_S3TC_DXT1_Format = 33776;\nconst RGBA_S3TC_DXT1_Format = 33777;\nconst RGBA_S3TC_DXT3_Format = 33778;\nconst RGBA_S3TC_DXT5_Format = 33779;\nconst RGB_PVRTC_4BPPV1_Format = 35840;\nconst RGB_PVRTC_2BPPV1_Format = 35841;\nconst RGBA_PVRTC_4BPPV1_Format = 35842;\nconst RGBA_PVRTC_2BPPV1_Format = 35843;\nconst RGB_ETC1_Format = 36196;\nconst RGB_ETC2_Format = 37492;\nconst RGBA_ETC2_EAC_Format = 37496;\nconst RGBA_ASTC_4x4_Format = 37808;\nconst RGBA_ASTC_5x4_Format = 37809;\nconst RGBA_ASTC_5x5_Format = 37810;\nconst RGBA_ASTC_6x5_Format = 37811;\nconst RGBA_ASTC_6x6_Format = 37812;\nconst RGBA_ASTC_8x5_Format = 37813;\nconst RGBA_ASTC_8x6_Format = 37814;\nconst RGBA_ASTC_8x8_Format = 37815;\nconst RGBA_ASTC_10x5_Format = 37816;\nconst RGBA_ASTC_10x6_Format = 37817;\nconst RGBA_ASTC_10x8_Format = 37818;\nconst RGBA_ASTC_10x10_Format = 37819;\nconst RGBA_ASTC_12x10_Format = 37820;\nconst RGBA_ASTC_12x12_Format = 37821;\nconst RGBA_BPTC_Format = 36492;\nconst LoopOnce = 2200;\nconst LoopRepeat = 2201;\nconst LoopPingPong = 2202;\nconst InterpolateDiscrete = 2300;\nconst InterpolateLinear = 2301;\nconst InterpolateSmooth = 2302;\nconst ZeroCurvatureEnding = 2400;\nconst ZeroSlopeEnding = 2401;\nconst WrapAroundEnding = 2402;\nconst NormalAnimationBlendMode = 2500;\nconst AdditiveAnimationBlendMode = 2501;\nconst TrianglesDrawMode = 0;\nconst TriangleStripDrawMode = 1;\nconst TriangleFanDrawMode = 2;\nconst LinearEncoding = 3000;\nconst sRGBEncoding = 3001;\nconst BasicDepthPacking = 3200;\nconst RGBADepthPacking = 3201;\nconst TangentSpaceNormalMap = 0;\nconst ObjectSpaceNormalMap = 1;\n\nconst ZeroStencilOp = 0;\nconst KeepStencilOp = 7680;\nconst ReplaceStencilOp = 7681;\nconst IncrementStencilOp = 7682;\nconst DecrementStencilOp = 7683;\nconst IncrementWrapStencilOp = 34055;\nconst DecrementWrapStencilOp = 34056;\nconst InvertStencilOp = 5386;\n\nconst NeverStencilFunc = 512;\nconst LessStencilFunc = 513;\nconst EqualStencilFunc = 514;\nconst LessEqualStencilFunc = 515;\nconst GreaterStencilFunc = 516;\nconst NotEqualStencilFunc = 517;\nconst GreaterEqualStencilFunc = 518;\nconst AlwaysStencilFunc = 519;\n\nconst StaticDrawUsage = 35044;\nconst DynamicDrawUsage = 35048;\nconst StreamDrawUsage = 35040;\nconst StaticReadUsage = 35045;\nconst DynamicReadUsage = 35049;\nconst StreamReadUsage = 35041;\nconst StaticCopyUsage = 35046;\nconst DynamicCopyUsage = 35050;\nconst StreamCopyUsage = 35042;\n\nconst GLSL1 = '100';\nconst GLSL3 = '300 es';\n\nconst _SRGBAFormat = 1035; // fallback for WebGL 1\n\n/**\n * https://github.com/mrdoob/eventdispatcher.js/\n */\n\nclass EventDispatcher {\n\n\taddEventListener( type, listener ) {\n\n\t\tif ( this._listeners === undefined ) this._listeners = {};\n\n\t\tconst listeners = this._listeners;\n\n\t\tif ( listeners[ type ] === undefined ) {\n\n\t\t\tlisteners[ type ] = [];\n\n\t\t}\n\n\t\tif ( listeners[ type ].indexOf( listener ) === - 1 ) {\n\n\t\t\tlisteners[ type ].push( listener );\n\n\t\t}\n\n\t}\n\n\thasEventListener( type, listener ) {\n\n\t\tif ( this._listeners === undefined ) return false;\n\n\t\tconst listeners = this._listeners;\n\n\t\treturn listeners[ type ] !== undefined && listeners[ type ].indexOf( listener ) !== - 1;\n\n\t}\n\n\tremoveEventListener( type, listener ) {\n\n\t\tif ( this._listeners === undefined ) return;\n\n\t\tconst listeners = this._listeners;\n\t\tconst listenerArray = listeners[ type ];\n\n\t\tif ( listenerArray !== undefined ) {\n\n\t\t\tconst index = listenerArray.indexOf( listener );\n\n\t\t\tif ( index !== - 1 ) {\n\n\t\t\t\tlistenerArray.splice( index, 1 );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tdispatchEvent( event ) {\n\n\t\tif ( this._listeners === undefined ) return;\n\n\t\tconst listeners = this._listeners;\n\t\tconst listenerArray = listeners[ event.type ];\n\n\t\tif ( listenerArray !== undefined ) {\n\n\t\t\tevent.target = this;\n\n\t\t\t// Make a copy, in case listeners are removed while iterating.\n\t\t\tconst array = listenerArray.slice( 0 );\n\n\t\t\tfor ( let i = 0, l = array.length; i < l; i ++ ) {\n\n\t\t\t\tarray[ i ].call( this, event );\n\n\t\t\t}\n\n\t\t\tevent.target = null;\n\n\t\t}\n\n\t}\n\n}\n\nconst _lut = [];\n\nfor ( let i = 0; i < 256; i ++ ) {\n\n\t_lut[ i ] = ( i < 16 ? '0' : '' ) + ( i ).toString( 16 );\n\n}\n\nlet _seed = 1234567;\n\n\nconst DEG2RAD = Math.PI / 180;\nconst RAD2DEG = 180 / Math.PI;\n\n// http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/21963136#21963136\nfunction generateUUID() {\n\n\tconst d0 = Math.random() * 0xffffffff | 0;\n\tconst d1 = Math.random() * 0xffffffff | 0;\n\tconst d2 = Math.random() * 0xffffffff | 0;\n\tconst d3 = Math.random() * 0xffffffff | 0;\n\tconst uuid = _lut[ d0 & 0xff ] + _lut[ d0 >> 8 & 0xff ] + _lut[ d0 >> 16 & 0xff ] + _lut[ d0 >> 24 & 0xff ] + '-' +\n\t\t\t_lut[ d1 & 0xff ] + _lut[ d1 >> 8 & 0xff ] + '-' + _lut[ d1 >> 16 & 0x0f | 0x40 ] + _lut[ d1 >> 24 & 0xff ] + '-' +\n\t\t\t_lut[ d2 & 0x3f | 0x80 ] + _lut[ d2 >> 8 & 0xff ] + '-' + _lut[ d2 >> 16 & 0xff ] + _lut[ d2 >> 24 & 0xff ] +\n\t\t\t_lut[ d3 & 0xff ] + _lut[ d3 >> 8 & 0xff ] + _lut[ d3 >> 16 & 0xff ] + _lut[ d3 >> 24 & 0xff ];\n\n\t// .toUpperCase() here flattens concatenated strings to save heap memory space.\n\treturn uuid.toUpperCase();\n\n}\n\nfunction clamp( value, min, max ) {\n\n\treturn Math.max( min, Math.min( max, value ) );\n\n}\n\n// compute euclidian modulo of m % n\n// https://en.wikipedia.org/wiki/Modulo_operation\nfunction euclideanModulo( n, m ) {\n\n\treturn ( ( n % m ) + m ) % m;\n\n}\n\n// Linear mapping from range <a1, a2> to range <b1, b2>\nfunction mapLinear( x, a1, a2, b1, b2 ) {\n\n\treturn b1 + ( x - a1 ) * ( b2 - b1 ) / ( a2 - a1 );\n\n}\n\n// https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/inverse-lerp-a-super-useful-yet-often-overlooked-function-r5230/\nfunction inverseLerp( x, y, value ) {\n\n\tif ( x !== y ) {\n\n\t\treturn ( value - x ) / ( y - x );\n\n\t} else {\n\n\t\treturn 0;\n\n\t}\n\n}\n\n// https://en.wikipedia.org/wiki/Linear_interpolation\nfunction lerp( x, y, t ) {\n\n\treturn ( 1 - t ) * x + t * y;\n\n}\n\n// http://www.rorydriscoll.com/2016/03/07/frame-rate-independent-damping-using-lerp/\nfunction damp( x, y, lambda, dt ) {\n\n\treturn lerp( x, y, 1 - Math.exp( - lambda * dt ) );\n\n}\n\n// https://www.desmos.com/calculator/vcsjnyz7x4\nfunction pingpong( x, length = 1 ) {\n\n\treturn length - Math.abs( euclideanModulo( x, length * 2 ) - length );\n\n}\n\n// http://en.wikipedia.org/wiki/Smoothstep\nfunction smoothstep( x, min, max ) {\n\n\tif ( x <= min ) return 0;\n\tif ( x >= max ) return 1;\n\n\tx = ( x - min ) / ( max - min );\n\n\treturn x * x * ( 3 - 2 * x );\n\n}\n\nfunction smootherstep( x, min, max ) {\n\n\tif ( x <= min ) return 0;\n\tif ( x >= max ) return 1;\n\n\tx = ( x - min ) / ( max - min );\n\n\treturn x * x * x * ( x * ( x * 6 - 15 ) + 10 );\n\n}\n\n// Random integer from <low, high> interval\nfunction randInt( low, high ) {\n\n\treturn low + Math.floor( Math.random() * ( high - low + 1 ) );\n\n}\n\n// Random float from <low, high> interval\nfunction randFloat( low, high ) {\n\n\treturn low + Math.random() * ( high - low );\n\n}\n\n// Random float from <-range/2, range/2> interval\nfunction randFloatSpread( range ) {\n\n\treturn range * ( 0.5 - Math.random() );\n\n}\n\n// Deterministic pseudo-random float in the interval [ 0, 1 ]\nfunction seededRandom( s ) {\n\n\tif ( s !== undefined ) _seed = s % 2147483647;\n\n\t// Park-Miller algorithm\n\n\t_seed = _seed * 16807 % 2147483647;\n\n\treturn ( _seed - 1 ) / 2147483646;\n\n}\n\nfunction degToRad( degrees ) {\n\n\treturn degrees * DEG2RAD;\n\n}\n\nfunction radToDeg( radians ) {\n\n\treturn radians * RAD2DEG;\n\n}\n\nfunction isPowerOfTwo( value ) {\n\n\treturn ( value & ( value - 1 ) ) === 0 && value !== 0;\n\n}\n\nfunction ceilPowerOfTwo( value ) {\n\n\treturn Math.pow( 2, Math.ceil( Math.log( value ) / Math.LN2 ) );\n\n}\n\nfunction floorPowerOfTwo( value ) {\n\n\treturn Math.pow( 2, Math.floor( Math.log( value ) / Math.LN2 ) );\n\n}\n\nfunction setQuaternionFromProperEuler( q, a, b, c, order ) {\n\n\t// Intrinsic Proper Euler Angles - see https://en.wikipedia.org/wiki/Euler_angles\n\n\t// rotations are applied to the axes in the order specified by 'order'\n\t// rotation by angle 'a' is applied first, then by angle 'b', then by angle 'c'\n\t// angles are in radians\n\n\tconst cos = Math.cos;\n\tconst sin = Math.sin;\n\n\tconst c2 = cos( b / 2 );\n\tconst s2 = sin( b / 2 );\n\n\tconst c13 = cos( ( a + c ) / 2 );\n\tconst s13 = sin( ( a + c ) / 2 );\n\n\tconst c1_3 = cos( ( a - c ) / 2 );\n\tconst s1_3 = sin( ( a - c ) / 2 );\n\n\tconst c3_1 = cos( ( c - a ) / 2 );\n\tconst s3_1 = sin( ( c - a ) / 2 );\n\n\tswitch ( order ) {\n\n\t\tcase 'XYX':\n\t\t\tq.set( c2 * s13, s2 * c1_3, s2 * s1_3, c2 * c13 );\n\t\t\tbreak;\n\n\t\tcase 'YZY':\n\t\t\tq.set( s2 * s1_3, c2 * s13, s2 * c1_3, c2 * c13 );\n\t\t\tbreak;\n\n\t\tcase 'ZXZ':\n\t\t\tq.set( s2 * c1_3, s2 * s1_3, c2 * s13, c2 * c13 );\n\t\t\tbreak;\n\n\t\tcase 'XZX':\n\t\t\tq.set( c2 * s13, s2 * s3_1, s2 * c3_1, c2 * c13 );\n\t\t\tbreak;\n\n\t\tcase 'YXY':\n\t\t\tq.set( s2 * c3_1, c2 * s13, s2 * s3_1, c2 * c13 );\n\t\t\tbreak;\n\n\t\tcase 'ZYZ':\n\t\t\tq.set( s2 * s3_1, s2 * c3_1, c2 * s13, c2 * c13 );\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tconsole.warn( 'THREE.MathUtils: .setQuaternionFromProperEuler() encountered an unknown order: ' + order );\n\n\t}\n\n}\n\nvar MathUtils = /*#__PURE__*/Object.freeze({\n\t__proto__: null,\n\tDEG2RAD: DEG2RAD,\n\tRAD2DEG: RAD2DEG,\n\tgenerateUUID: generateUUID,\n\tclamp: clamp,\n\teuclideanModulo: euclideanModulo,\n\tmapLinear: mapLinear,\n\tinverseLerp: inverseLerp,\n\tlerp: lerp,\n\tdamp: damp,\n\tpingpong: pingpong,\n\tsmoothstep: smoothstep,\n\tsmootherstep: smootherstep,\n\trandInt: randInt,\n\trandFloat: randFloat,\n\trandFloatSpread: randFloatSpread,\n\tseededRandom: seededRandom,\n\tdegToRad: degToRad,\n\tradToDeg: radToDeg,\n\tisPowerOfTwo: isPowerOfTwo,\n\tceilPowerOfTwo: ceilPowerOfTwo,\n\tfloorPowerOfTwo: floorPowerOfTwo,\n\tsetQuaternionFromProperEuler: setQuaternionFromProperEuler\n});\n\nclass Vector2 {\n\n\tconstructor( x = 0, y = 0 ) {\n\n\t\tthis.x = x;\n\t\tthis.y = y;\n\n\t}\n\n\tget width() {\n\n\t\treturn this.x;\n\n\t}\n\n\tset width( value ) {\n\n\t\tthis.x = value;\n\n\t}\n\n\tget height() {\n\n\t\treturn this.y;\n\n\t}\n\n\tset height( value ) {\n\n\t\tthis.y = value;\n\n\t}\n\n\tset( x, y ) {\n\n\t\tthis.x = x;\n\t\tthis.y = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetScalar( scalar ) {\n\n\t\tthis.x = scalar;\n\t\tthis.y = scalar;\n\n\t\treturn this;\n\n\t}\n\n\tsetX( x ) {\n\n\t\tthis.x = x;\n\n\t\treturn this;\n\n\t}\n\n\tsetY( y ) {\n\n\t\tthis.y = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetComponent( index, value ) {\n\n\t\tswitch ( index ) {\n\n\t\t\tcase 0: this.x = value; break;\n\t\t\tcase 1: this.y = value; break;\n\t\t\tdefault: throw new Error( 'index is out of range: ' + index );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetComponent( index ) {\n\n\t\tswitch ( index ) {\n\n\t\t\tcase 0: return this.x;\n\t\t\tcase 1: return this.y;\n\t\t\tdefault: throw new Error( 'index is out of range: ' + index );\n\n\t\t}\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this.x, this.y );\n\n\t}\n\n\tcopy( v ) {\n\n\t\tthis.x = v.x;\n\t\tthis.y = v.y;\n\n\t\treturn this;\n\n\t}\n\n\tadd( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector2: .add() now only accepts one argument. Use .addVectors( a, b ) instead.' );\n\t\t\treturn this.addVectors( v, w );\n\n\t\t}\n\n\t\tthis.x += v.x;\n\t\tthis.y += v.y;\n\n\t\treturn this;\n\n\t}\n\n\taddScalar( s ) {\n\n\t\tthis.x += s;\n\t\tthis.y += s;\n\n\t\treturn this;\n\n\t}\n\n\taddVectors( a, b ) {\n\n\t\tthis.x = a.x + b.x;\n\t\tthis.y = a.y + b.y;\n\n\t\treturn this;\n\n\t}\n\n\taddScaledVector( v, s ) {\n\n\t\tthis.x += v.x * s;\n\t\tthis.y += v.y * s;\n\n\t\treturn this;\n\n\t}\n\n\tsub( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector2: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.' );\n\t\t\treturn this.subVectors( v, w );\n\n\t\t}\n\n\t\tthis.x -= v.x;\n\t\tthis.y -= v.y;\n\n\t\treturn this;\n\n\t}\n\n\tsubScalar( s ) {\n\n\t\tthis.x -= s;\n\t\tthis.y -= s;\n\n\t\treturn this;\n\n\t}\n\n\tsubVectors( a, b ) {\n\n\t\tthis.x = a.x - b.x;\n\t\tthis.y = a.y - b.y;\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( v ) {\n\n\t\tthis.x *= v.x;\n\t\tthis.y *= v.y;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyScalar( scalar ) {\n\n\t\tthis.x *= scalar;\n\t\tthis.y *= scalar;\n\n\t\treturn this;\n\n\t}\n\n\tdivide( v ) {\n\n\t\tthis.x /= v.x;\n\t\tthis.y /= v.y;\n\n\t\treturn this;\n\n\t}\n\n\tdivideScalar( scalar ) {\n\n\t\treturn this.multiplyScalar( 1 / scalar );\n\n\t}\n\n\tapplyMatrix3( m ) {\n\n\t\tconst x = this.x, y = this.y;\n\t\tconst e = m.elements;\n\n\t\tthis.x = e[ 0 ] * x + e[ 3 ] * y + e[ 6 ];\n\t\tthis.y = e[ 1 ] * x + e[ 4 ] * y + e[ 7 ];\n\n\t\treturn this;\n\n\t}\n\n\tmin( v ) {\n\n\t\tthis.x = Math.min( this.x, v.x );\n\t\tthis.y = Math.min( this.y, v.y );\n\n\t\treturn this;\n\n\t}\n\n\tmax( v ) {\n\n\t\tthis.x = Math.max( this.x, v.x );\n\t\tthis.y = Math.max( this.y, v.y );\n\n\t\treturn this;\n\n\t}\n\n\tclamp( min, max ) {\n\n\t\t// assumes min < max, componentwise\n\n\t\tthis.x = Math.max( min.x, Math.min( max.x, this.x ) );\n\t\tthis.y = Math.max( min.y, Math.min( max.y, this.y ) );\n\n\t\treturn this;\n\n\t}\n\n\tclampScalar( minVal, maxVal ) {\n\n\t\tthis.x = Math.max( minVal, Math.min( maxVal, this.x ) );\n\t\tthis.y = Math.max( minVal, Math.min( maxVal, this.y ) );\n\n\t\treturn this;\n\n\t}\n\n\tclampLength( min, max ) {\n\n\t\tconst length = this.length();\n\n\t\treturn this.divideScalar( length || 1 ).multiplyScalar( Math.max( min, Math.min( max, length ) ) );\n\n\t}\n\n\tfloor() {\n\n\t\tthis.x = Math.floor( this.x );\n\t\tthis.y = Math.floor( this.y );\n\n\t\treturn this;\n\n\t}\n\n\tceil() {\n\n\t\tthis.x = Math.ceil( this.x );\n\t\tthis.y = Math.ceil( this.y );\n\n\t\treturn this;\n\n\t}\n\n\tround() {\n\n\t\tthis.x = Math.round( this.x );\n\t\tthis.y = Math.round( this.y );\n\n\t\treturn this;\n\n\t}\n\n\troundToZero() {\n\n\t\tthis.x = ( this.x < 0 ) ? Math.ceil( this.x ) : Math.floor( this.x );\n\t\tthis.y = ( this.y < 0 ) ? Math.ceil( this.y ) : Math.floor( this.y );\n\n\t\treturn this;\n\n\t}\n\n\tnegate() {\n\n\t\tthis.x = - this.x;\n\t\tthis.y = - this.y;\n\n\t\treturn this;\n\n\t}\n\n\tdot( v ) {\n\n\t\treturn this.x * v.x + this.y * v.y;\n\n\t}\n\n\tcross( v ) {\n\n\t\treturn this.x * v.y - this.y * v.x;\n\n\t}\n\n\tlengthSq() {\n\n\t\treturn this.x * this.x + this.y * this.y;\n\n\t}\n\n\tlength() {\n\n\t\treturn Math.sqrt( this.x * this.x + this.y * this.y );\n\n\t}\n\n\tmanhattanLength() {\n\n\t\treturn Math.abs( this.x ) + Math.abs( this.y );\n\n\t}\n\n\tnormalize() {\n\n\t\treturn this.divideScalar( this.length() || 1 );\n\n\t}\n\n\tangle() {\n\n\t\t// computes the angle in radians with respect to the positive x-axis\n\n\t\tconst angle = Math.atan2( - this.y, - this.x ) + Math.PI;\n\n\t\treturn angle;\n\n\t}\n\n\tdistanceTo( v ) {\n\n\t\treturn Math.sqrt( this.distanceToSquared( v ) );\n\n\t}\n\n\tdistanceToSquared( v ) {\n\n\t\tconst dx = this.x - v.x, dy = this.y - v.y;\n\t\treturn dx * dx + dy * dy;\n\n\t}\n\n\tmanhattanDistanceTo( v ) {\n\n\t\treturn Math.abs( this.x - v.x ) + Math.abs( this.y - v.y );\n\n\t}\n\n\tsetLength( length ) {\n\n\t\treturn this.normalize().multiplyScalar( length );\n\n\t}\n\n\tlerp( v, alpha ) {\n\n\t\tthis.x += ( v.x - this.x ) * alpha;\n\t\tthis.y += ( v.y - this.y ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tlerpVectors( v1, v2, alpha ) {\n\n\t\tthis.x = v1.x + ( v2.x - v1.x ) * alpha;\n\t\tthis.y = v1.y + ( v2.y - v1.y ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tequals( v ) {\n\n\t\treturn ( ( v.x === this.x ) && ( v.y === this.y ) );\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tthis.x = array[ offset ];\n\t\tthis.y = array[ offset + 1 ];\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tarray[ offset ] = this.x;\n\t\tarray[ offset + 1 ] = this.y;\n\n\t\treturn array;\n\n\t}\n\n\tfromBufferAttribute( attribute, index, offset ) {\n\n\t\tif ( offset !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector2: offset has been removed from .fromBufferAttribute().' );\n\n\t\t}\n\n\t\tthis.x = attribute.getX( index );\n\t\tthis.y = attribute.getY( index );\n\n\t\treturn this;\n\n\t}\n\n\trotateAround( center, angle ) {\n\n\t\tconst c = Math.cos( angle ), s = Math.sin( angle );\n\n\t\tconst x = this.x - center.x;\n\t\tconst y = this.y - center.y;\n\n\t\tthis.x = x * c - y * s + center.x;\n\t\tthis.y = x * s + y * c + center.y;\n\n\t\treturn this;\n\n\t}\n\n\trandom() {\n\n\t\tthis.x = Math.random();\n\t\tthis.y = Math.random();\n\n\t\treturn this;\n\n\t}\n\n\t*[ Symbol.iterator ]() {\n\n\t\tyield this.x;\n\t\tyield this.y;\n\n\t}\n\n}\n\nVector2.prototype.isVector2 = true;\n\nclass Matrix3 {\n\n\tconstructor() {\n\n\t\tthis.elements = [\n\n\t\t\t1, 0, 0,\n\t\t\t0, 1, 0,\n\t\t\t0, 0, 1\n\n\t\t];\n\n\t\tif ( arguments.length > 0 ) {\n\n\t\t\tconsole.error( 'THREE.Matrix3: the constructor no longer reads arguments. use .set() instead.' );\n\n\t\t}\n\n\t}\n\n\tset( n11, n12, n13, n21, n22, n23, n31, n32, n33 ) {\n\n\t\tconst te = this.elements;\n\n\t\tte[ 0 ] = n11; te[ 1 ] = n21; te[ 2 ] = n31;\n\t\tte[ 3 ] = n12; te[ 4 ] = n22; te[ 5 ] = n32;\n\t\tte[ 6 ] = n13; te[ 7 ] = n23; te[ 8 ] = n33;\n\n\t\treturn this;\n\n\t}\n\n\tidentity() {\n\n\t\tthis.set(\n\n\t\t\t1, 0, 0,\n\t\t\t0, 1, 0,\n\t\t\t0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tcopy( m ) {\n\n\t\tconst te = this.elements;\n\t\tconst me = m.elements;\n\n\t\tte[ 0 ] = me[ 0 ]; te[ 1 ] = me[ 1 ]; te[ 2 ] = me[ 2 ];\n\t\tte[ 3 ] = me[ 3 ]; te[ 4 ] = me[ 4 ]; te[ 5 ] = me[ 5 ];\n\t\tte[ 6 ] = me[ 6 ]; te[ 7 ] = me[ 7 ]; te[ 8 ] = me[ 8 ];\n\n\t\treturn this;\n\n\t}\n\n\textractBasis( xAxis, yAxis, zAxis ) {\n\n\t\txAxis.setFromMatrix3Column( this, 0 );\n\t\tyAxis.setFromMatrix3Column( this, 1 );\n\t\tzAxis.setFromMatrix3Column( this, 2 );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromMatrix4( m ) {\n\n\t\tconst me = m.elements;\n\n\t\tthis.set(\n\n\t\t\tme[ 0 ], me[ 4 ], me[ 8 ],\n\t\t\tme[ 1 ], me[ 5 ], me[ 9 ],\n\t\t\tme[ 2 ], me[ 6 ], me[ 10 ]\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( m ) {\n\n\t\treturn this.multiplyMatrices( this, m );\n\n\t}\n\n\tpremultiply( m ) {\n\n\t\treturn this.multiplyMatrices( m, this );\n\n\t}\n\n\tmultiplyMatrices( a, b ) {\n\n\t\tconst ae = a.elements;\n\t\tconst be = b.elements;\n\t\tconst te = this.elements;\n\n\t\tconst a11 = ae[ 0 ], a12 = ae[ 3 ], a13 = ae[ 6 ];\n\t\tconst a21 = ae[ 1 ], a22 = ae[ 4 ], a23 = ae[ 7 ];\n\t\tconst a31 = ae[ 2 ], a32 = ae[ 5 ], a33 = ae[ 8 ];\n\n\t\tconst b11 = be[ 0 ], b12 = be[ 3 ], b13 = be[ 6 ];\n\t\tconst b21 = be[ 1 ], b22 = be[ 4 ], b23 = be[ 7 ];\n\t\tconst b31 = be[ 2 ], b32 = be[ 5 ], b33 = be[ 8 ];\n\n\t\tte[ 0 ] = a11 * b11 + a12 * b21 + a13 * b31;\n\t\tte[ 3 ] = a11 * b12 + a12 * b22 + a13 * b32;\n\t\tte[ 6 ] = a11 * b13 + a12 * b23 + a13 * b33;\n\n\t\tte[ 1 ] = a21 * b11 + a22 * b21 + a23 * b31;\n\t\tte[ 4 ] = a21 * b12 + a22 * b22 + a23 * b32;\n\t\tte[ 7 ] = a21 * b13 + a22 * b23 + a23 * b33;\n\n\t\tte[ 2 ] = a31 * b11 + a32 * b21 + a33 * b31;\n\t\tte[ 5 ] = a31 * b12 + a32 * b22 + a33 * b32;\n\t\tte[ 8 ] = a31 * b13 + a32 * b23 + a33 * b33;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyScalar( s ) {\n\n\t\tconst te = this.elements;\n\n\t\tte[ 0 ] *= s; te[ 3 ] *= s; te[ 6 ] *= s;\n\t\tte[ 1 ] *= s; te[ 4 ] *= s; te[ 7 ] *= s;\n\t\tte[ 2 ] *= s; te[ 5 ] *= s; te[ 8 ] *= s;\n\n\t\treturn this;\n\n\t}\n\n\tdeterminant() {\n\n\t\tconst te = this.elements;\n\n\t\tconst a = te[ 0 ], b = te[ 1 ], c = te[ 2 ],\n\t\t\td = te[ 3 ], e = te[ 4 ], f = te[ 5 ],\n\t\t\tg = te[ 6 ], h = te[ 7 ], i = te[ 8 ];\n\n\t\treturn a * e * i - a * f * h - b * d * i + b * f * g + c * d * h - c * e * g;\n\n\t}\n\n\tinvert() {\n\n\t\tconst te = this.elements,\n\n\t\t\tn11 = te[ 0 ], n21 = te[ 1 ], n31 = te[ 2 ],\n\t\t\tn12 = te[ 3 ], n22 = te[ 4 ], n32 = te[ 5 ],\n\t\t\tn13 = te[ 6 ], n23 = te[ 7 ], n33 = te[ 8 ],\n\n\t\t\tt11 = n33 * n22 - n32 * n23,\n\t\t\tt12 = n32 * n13 - n33 * n12,\n\t\t\tt13 = n23 * n12 - n22 * n13,\n\n\t\t\tdet = n11 * t11 + n21 * t12 + n31 * t13;\n\n\t\tif ( det === 0 ) return this.set( 0, 0, 0, 0, 0, 0, 0, 0, 0 );\n\n\t\tconst detInv = 1 / det;\n\n\t\tte[ 0 ] = t11 * detInv;\n\t\tte[ 1 ] = ( n31 * n23 - n33 * n21 ) * detInv;\n\t\tte[ 2 ] = ( n32 * n21 - n31 * n22 ) * detInv;\n\n\t\tte[ 3 ] = t12 * detInv;\n\t\tte[ 4 ] = ( n33 * n11 - n31 * n13 ) * detInv;\n\t\tte[ 5 ] = ( n31 * n12 - n32 * n11 ) * detInv;\n\n\t\tte[ 6 ] = t13 * detInv;\n\t\tte[ 7 ] = ( n21 * n13 - n23 * n11 ) * detInv;\n\t\tte[ 8 ] = ( n22 * n11 - n21 * n12 ) * detInv;\n\n\t\treturn this;\n\n\t}\n\n\ttranspose() {\n\n\t\tlet tmp;\n\t\tconst m = this.elements;\n\n\t\ttmp = m[ 1 ]; m[ 1 ] = m[ 3 ]; m[ 3 ] = tmp;\n\t\ttmp = m[ 2 ]; m[ 2 ] = m[ 6 ]; m[ 6 ] = tmp;\n\t\ttmp = m[ 5 ]; m[ 5 ] = m[ 7 ]; m[ 7 ] = tmp;\n\n\t\treturn this;\n\n\t}\n\n\tgetNormalMatrix( matrix4 ) {\n\n\t\treturn this.setFromMatrix4( matrix4 ).invert().transpose();\n\n\t}\n\n\ttransposeIntoArray( r ) {\n\n\t\tconst m = this.elements;\n\n\t\tr[ 0 ] = m[ 0 ];\n\t\tr[ 1 ] = m[ 3 ];\n\t\tr[ 2 ] = m[ 6 ];\n\t\tr[ 3 ] = m[ 1 ];\n\t\tr[ 4 ] = m[ 4 ];\n\t\tr[ 5 ] = m[ 7 ];\n\t\tr[ 6 ] = m[ 2 ];\n\t\tr[ 7 ] = m[ 5 ];\n\t\tr[ 8 ] = m[ 8 ];\n\n\t\treturn this;\n\n\t}\n\n\tsetUvTransform( tx, ty, sx, sy, rotation, cx, cy ) {\n\n\t\tconst c = Math.cos( rotation );\n\t\tconst s = Math.sin( rotation );\n\n\t\tthis.set(\n\t\t\tsx * c, sx * s, - sx * ( c * cx + s * cy ) + cx + tx,\n\t\t\t- sy * s, sy * c, - sy * ( - s * cx + c * cy ) + cy + ty,\n\t\t\t0, 0, 1\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tscale( sx, sy ) {\n\n\t\tconst te = this.elements;\n\n\t\tte[ 0 ] *= sx; te[ 3 ] *= sx; te[ 6 ] *= sx;\n\t\tte[ 1 ] *= sy; te[ 4 ] *= sy; te[ 7 ] *= sy;\n\n\t\treturn this;\n\n\t}\n\n\trotate( theta ) {\n\n\t\tconst c = Math.cos( theta );\n\t\tconst s = Math.sin( theta );\n\n\t\tconst te = this.elements;\n\n\t\tconst a11 = te[ 0 ], a12 = te[ 3 ], a13 = te[ 6 ];\n\t\tconst a21 = te[ 1 ], a22 = te[ 4 ], a23 = te[ 7 ];\n\n\t\tte[ 0 ] = c * a11 + s * a21;\n\t\tte[ 3 ] = c * a12 + s * a22;\n\t\tte[ 6 ] = c * a13 + s * a23;\n\n\t\tte[ 1 ] = - s * a11 + c * a21;\n\t\tte[ 4 ] = - s * a12 + c * a22;\n\t\tte[ 7 ] = - s * a13 + c * a23;\n\n\t\treturn this;\n\n\t}\n\n\ttranslate( tx, ty ) {\n\n\t\tconst te = this.elements;\n\n\t\tte[ 0 ] += tx * te[ 2 ]; te[ 3 ] += tx * te[ 5 ]; te[ 6 ] += tx * te[ 8 ];\n\t\tte[ 1 ] += ty * te[ 2 ]; te[ 4 ] += ty * te[ 5 ]; te[ 7 ] += ty * te[ 8 ];\n\n\t\treturn this;\n\n\t}\n\n\tequals( matrix ) {\n\n\t\tconst te = this.elements;\n\t\tconst me = matrix.elements;\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tif ( te[ i ] !== me[ i ] ) return false;\n\n\t\t}\n\n\t\treturn true;\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.elements[ i ] = array[ i + offset ];\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tconst te = this.elements;\n\n\t\tarray[ offset ] = te[ 0 ];\n\t\tarray[ offset + 1 ] = te[ 1 ];\n\t\tarray[ offset + 2 ] = te[ 2 ];\n\n\t\tarray[ offset + 3 ] = te[ 3 ];\n\t\tarray[ offset + 4 ] = te[ 4 ];\n\t\tarray[ offset + 5 ] = te[ 5 ];\n\n\t\tarray[ offset + 6 ] = te[ 6 ];\n\t\tarray[ offset + 7 ] = te[ 7 ];\n\t\tarray[ offset + 8 ] = te[ 8 ];\n\n\t\treturn array;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().fromArray( this.elements );\n\n\t}\n\n}\n\nMatrix3.prototype.isMatrix3 = true;\n\nfunction arrayNeedsUint32( array ) {\n\n\t// assumes larger values usually on last\n\n\tfor ( let i = array.length - 1; i >= 0; -- i ) {\n\n\t\tif ( array[ i ] > 65535 ) return true;\n\n\t}\n\n\treturn false;\n\n}\n\nconst TYPED_ARRAYS = {\n\tInt8Array: Int8Array,\n\tUint8Array: Uint8Array,\n\tUint8ClampedArray: Uint8ClampedArray,\n\tInt16Array: Int16Array,\n\tUint16Array: Uint16Array,\n\tInt32Array: Int32Array,\n\tUint32Array: Uint32Array,\n\tFloat32Array: Float32Array,\n\tFloat64Array: Float64Array\n};\n\nfunction getTypedArray( type, buffer ) {\n\n\treturn new TYPED_ARRAYS[ type ]( buffer );\n\n}\n\nfunction createElementNS( name ) {\n\n\treturn document.createElementNS( 'http://www.w3.org/1999/xhtml', name );\n\n}\n\nconst _colorKeywords = { 'aliceblue': 0xF0F8FF, 'antiquewhite': 0xFAEBD7, 'aqua': 0x00FFFF, 'aquamarine': 0x7FFFD4, 'azure': 0xF0FFFF,\n\t'beige': 0xF5F5DC, 'bisque': 0xFFE4C4, 'black': 0x000000, 'blanchedalmond': 0xFFEBCD, 'blue': 0x0000FF, 'blueviolet': 0x8A2BE2,\n\t'brown': 0xA52A2A, 'burlywood': 0xDEB887, 'cadetblue': 0x5F9EA0, 'chartreuse': 0x7FFF00, 'chocolate': 0xD2691E, 'coral': 0xFF7F50,\n\t'cornflowerblue': 0x6495ED, 'cornsilk': 0xFFF8DC, 'crimson': 0xDC143C, 'cyan': 0x00FFFF, 'darkblue': 0x00008B, 'darkcyan': 0x008B8B,\n\t'darkgoldenrod': 0xB8860B, 'darkgray': 0xA9A9A9, 'darkgreen': 0x006400, 'darkgrey': 0xA9A9A9, 'darkkhaki': 0xBDB76B, 'darkmagenta': 0x8B008B,\n\t'darkolivegreen': 0x556B2F, 'darkorange': 0xFF8C00, 'darkorchid': 0x9932CC, 'darkred': 0x8B0000, 'darksalmon': 0xE9967A, 'darkseagreen': 0x8FBC8F,\n\t'darkslateblue': 0x483D8B, 'darkslategray': 0x2F4F4F, 'darkslategrey': 0x2F4F4F, 'darkturquoise': 0x00CED1, 'darkviolet': 0x9400D3,\n\t'deeppink': 0xFF1493, 'deepskyblue': 0x00BFFF, 'dimgray': 0x696969, 'dimgrey': 0x696969, 'dodgerblue': 0x1E90FF, 'firebrick': 0xB22222,\n\t'floralwhite': 0xFFFAF0, 'forestgreen': 0x228B22, 'fuchsia': 0xFF00FF, 'gainsboro': 0xDCDCDC, 'ghostwhite': 0xF8F8FF, 'gold': 0xFFD700,\n\t'goldenrod': 0xDAA520, 'gray': 0x808080, 'green': 0x008000, 'greenyellow': 0xADFF2F, 'grey': 0x808080, 'honeydew': 0xF0FFF0, 'hotpink': 0xFF69B4,\n\t'indianred': 0xCD5C5C, 'indigo': 0x4B0082, 'ivory': 0xFFFFF0, 'khaki': 0xF0E68C, 'lavender': 0xE6E6FA, 'lavenderblush': 0xFFF0F5, 'lawngreen': 0x7CFC00,\n\t'lemonchiffon': 0xFFFACD, 'lightblue': 0xADD8E6, 'lightcoral': 0xF08080, 'lightcyan': 0xE0FFFF, 'lightgoldenrodyellow': 0xFAFAD2, 'lightgray': 0xD3D3D3,\n\t'lightgreen': 0x90EE90, 'lightgrey': 0xD3D3D3, 'lightpink': 0xFFB6C1, 'lightsalmon': 0xFFA07A, 'lightseagreen': 0x20B2AA, 'lightskyblue': 0x87CEFA,\n\t'lightslategray': 0x778899, 'lightslategrey': 0x778899, 'lightsteelblue': 0xB0C4DE, 'lightyellow': 0xFFFFE0, 'lime': 0x00FF00, 'limegreen': 0x32CD32,\n\t'linen': 0xFAF0E6, 'magenta': 0xFF00FF, 'maroon': 0x800000, 'mediumaquamarine': 0x66CDAA, 'mediumblue': 0x0000CD, 'mediumorchid': 0xBA55D3,\n\t'mediumpurple': 0x9370DB, 'mediumseagreen': 0x3CB371, 'mediumslateblue': 0x7B68EE, 'mediumspringgreen': 0x00FA9A, 'mediumturquoise': 0x48D1CC,\n\t'mediumvioletred': 0xC71585, 'midnightblue': 0x191970, 'mintcream': 0xF5FFFA, 'mistyrose': 0xFFE4E1, 'moccasin': 0xFFE4B5, 'navajowhite': 0xFFDEAD,\n\t'navy': 0x000080, 'oldlace': 0xFDF5E6, 'olive': 0x808000, 'olivedrab': 0x6B8E23, 'orange': 0xFFA500, 'orangered': 0xFF4500, 'orchid': 0xDA70D6,\n\t'palegoldenrod': 0xEEE8AA, 'palegreen': 0x98FB98, 'paleturquoise': 0xAFEEEE, 'palevioletred': 0xDB7093, 'papayawhip': 0xFFEFD5, 'peachpuff': 0xFFDAB9,\n\t'peru': 0xCD853F, 'pink': 0xFFC0CB, 'plum': 0xDDA0DD, 'powderblue': 0xB0E0E6, 'purple': 0x800080, 'rebeccapurple': 0x663399, 'red': 0xFF0000, 'rosybrown': 0xBC8F8F,\n\t'royalblue': 0x4169E1, 'saddlebrown': 0x8B4513, 'salmon': 0xFA8072, 'sandybrown': 0xF4A460, 'seagreen': 0x2E8B57, 'seashell': 0xFFF5EE,\n\t'sienna': 0xA0522D, 'silver': 0xC0C0C0, 'skyblue': 0x87CEEB, 'slateblue': 0x6A5ACD, 'slategray': 0x708090, 'slategrey': 0x708090, 'snow': 0xFFFAFA,\n\t'springgreen': 0x00FF7F, 'steelblue': 0x4682B4, 'tan': 0xD2B48C, 'teal': 0x008080, 'thistle': 0xD8BFD8, 'tomato': 0xFF6347, 'turquoise': 0x40E0D0,\n\t'violet': 0xEE82EE, 'wheat': 0xF5DEB3, 'white': 0xFFFFFF, 'whitesmoke': 0xF5F5F5, 'yellow': 0xFFFF00, 'yellowgreen': 0x9ACD32 };\n\nconst _hslA = { h: 0, s: 0, l: 0 };\nconst _hslB = { h: 0, s: 0, l: 0 };\n\nfunction hue2rgb( p, q, t ) {\n\n\tif ( t < 0 ) t += 1;\n\tif ( t > 1 ) t -= 1;\n\tif ( t < 1 / 6 ) return p + ( q - p ) * 6 * t;\n\tif ( t < 1 / 2 ) return q;\n\tif ( t < 2 / 3 ) return p + ( q - p ) * 6 * ( 2 / 3 - t );\n\treturn p;\n\n}\n\nfunction SRGBToLinear( c ) {\n\n\treturn ( c < 0.04045 ) ? c * 0.0773993808 : Math.pow( c * 0.9478672986 + 0.0521327014, 2.4 );\n\n}\n\nfunction LinearToSRGB( c ) {\n\n\treturn ( c < 0.0031308 ) ? c * 12.92 : 1.055 * ( Math.pow( c, 0.41666 ) ) - 0.055;\n\n}\n\nclass Color {\n\n\tconstructor( r, g, b ) {\n\n\t\tif ( g === undefined && b === undefined ) {\n\n\t\t\t// r is THREE.Color, hex or string\n\t\t\treturn this.set( r );\n\n\t\t}\n\n\t\treturn this.setRGB( r, g, b );\n\n\t}\n\n\tset( value ) {\n\n\t\tif ( value && value.isColor ) {\n\n\t\t\tthis.copy( value );\n\n\t\t} else if ( typeof value === 'number' ) {\n\n\t\t\tthis.setHex( value );\n\n\t\t} else if ( typeof value === 'string' ) {\n\n\t\t\tthis.setStyle( value );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetScalar( scalar ) {\n\n\t\tthis.r = scalar;\n\t\tthis.g = scalar;\n\t\tthis.b = scalar;\n\n\t\treturn this;\n\n\t}\n\n\tsetHex( hex ) {\n\n\t\thex = Math.floor( hex );\n\n\t\tthis.r = ( hex >> 16 & 255 ) / 255;\n\t\tthis.g = ( hex >> 8 & 255 ) / 255;\n\t\tthis.b = ( hex & 255 ) / 255;\n\n\t\treturn this;\n\n\t}\n\n\tsetRGB( r, g, b ) {\n\n\t\tthis.r = r;\n\t\tthis.g = g;\n\t\tthis.b = b;\n\n\t\treturn this;\n\n\t}\n\n\tsetHSL( h, s, l ) {\n\n\t\t// h,s,l ranges are in 0.0 - 1.0\n\t\th = euclideanModulo( h, 1 );\n\t\ts = clamp( s, 0, 1 );\n\t\tl = clamp( l, 0, 1 );\n\n\t\tif ( s === 0 ) {\n\n\t\t\tthis.r = this.g = this.b = l;\n\n\t\t} else {\n\n\t\t\tconst p = l <= 0.5 ? l * ( 1 + s ) : l + s - ( l * s );\n\t\t\tconst q = ( 2 * l ) - p;\n\n\t\t\tthis.r = hue2rgb( q, p, h + 1 / 3 );\n\t\t\tthis.g = hue2rgb( q, p, h );\n\t\t\tthis.b = hue2rgb( q, p, h - 1 / 3 );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetStyle( style ) {\n\n\t\tfunction handleAlpha( string ) {\n\n\t\t\tif ( string === undefined ) return;\n\n\t\t\tif ( parseFloat( string ) < 1 ) {\n\n\t\t\t\tconsole.warn( 'THREE.Color: Alpha component of ' + style + ' will be ignored.' );\n\n\t\t\t}\n\n\t\t}\n\n\n\t\tlet m;\n\n\t\tif ( m = /^((?:rgb|hsl)a?)\\(([^\\)]*)\\)/.exec( style ) ) {\n\n\t\t\t// rgb / hsl\n\n\t\t\tlet color;\n\t\t\tconst name = m[ 1 ];\n\t\t\tconst components = m[ 2 ];\n\n\t\t\tswitch ( name ) {\n\n\t\t\t\tcase 'rgb':\n\t\t\t\tcase 'rgba':\n\n\t\t\t\t\tif ( color = /^\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n\n\t\t\t\t\t\t// rgb(255,0,0) rgba(255,0,0,0.5)\n\t\t\t\t\t\tthis.r = Math.min( 255, parseInt( color[ 1 ], 10 ) ) / 255;\n\t\t\t\t\t\tthis.g = Math.min( 255, parseInt( color[ 2 ], 10 ) ) / 255;\n\t\t\t\t\t\tthis.b = Math.min( 255, parseInt( color[ 3 ], 10 ) ) / 255;\n\n\t\t\t\t\t\thandleAlpha( color[ 4 ] );\n\n\t\t\t\t\t\treturn this;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( color = /^\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n\n\t\t\t\t\t\t// rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\n\t\t\t\t\t\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) / 100;\n\t\t\t\t\t\tthis.g = Math.min( 100, parseInt( color[ 2 ], 10 ) ) / 100;\n\t\t\t\t\t\tthis.b = Math.min( 100, parseInt( color[ 3 ], 10 ) ) / 100;\n\n\t\t\t\t\t\thandleAlpha( color[ 4 ] );\n\n\t\t\t\t\t\treturn this;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'hsl':\n\t\t\t\tcase 'hsla':\n\n\t\t\t\t\tif ( color = /^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n\n\t\t\t\t\t\t// hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n\t\t\t\t\t\tconst h = parseFloat( color[ 1 ] ) / 360;\n\t\t\t\t\t\tconst s = parseInt( color[ 2 ], 10 ) / 100;\n\t\t\t\t\t\tconst l = parseInt( color[ 3 ], 10 ) / 100;\n\n\t\t\t\t\t\thandleAlpha( color[ 4 ] );\n\n\t\t\t\t\t\treturn this.setHSL( h, s, l );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t} else if ( m = /^\\#([A-Fa-f\\d]+)$/.exec( style ) ) {\n\n\t\t\t// hex color\n\n\t\t\tconst hex = m[ 1 ];\n\t\t\tconst size = hex.length;\n\n\t\t\tif ( size === 3 ) {\n\n\t\t\t\t// #ff0\n\t\t\t\tthis.r = parseInt( hex.charAt( 0 ) + hex.charAt( 0 ), 16 ) / 255;\n\t\t\t\tthis.g = parseInt( hex.charAt( 1 ) + hex.charAt( 1 ), 16 ) / 255;\n\t\t\t\tthis.b = parseInt( hex.charAt( 2 ) + hex.charAt( 2 ), 16 ) / 255;\n\n\t\t\t\treturn this;\n\n\t\t\t} else if ( size === 6 ) {\n\n\t\t\t\t// #ff0000\n\t\t\t\tthis.r = parseInt( hex.charAt( 0 ) + hex.charAt( 1 ), 16 ) / 255;\n\t\t\t\tthis.g = parseInt( hex.charAt( 2 ) + hex.charAt( 3 ), 16 ) / 255;\n\t\t\t\tthis.b = parseInt( hex.charAt( 4 ) + hex.charAt( 5 ), 16 ) / 255;\n\n\t\t\t\treturn this;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( style && style.length > 0 ) {\n\n\t\t\treturn this.setColorName( style );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetColorName( style ) {\n\n\t\t// color keywords\n\t\tconst hex = _colorKeywords[ style.toLowerCase() ];\n\n\t\tif ( hex !== undefined ) {\n\n\t\t\t// red\n\t\t\tthis.setHex( hex );\n\n\t\t} else {\n\n\t\t\t// unknown color\n\t\t\tconsole.warn( 'THREE.Color: Unknown color ' + style );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this.r, this.g, this.b );\n\n\t}\n\n\tcopy( color ) {\n\n\t\tthis.r = color.r;\n\t\tthis.g = color.g;\n\t\tthis.b = color.b;\n\n\t\treturn this;\n\n\t}\n\n\tcopySRGBToLinear( color ) {\n\n\t\tthis.r = SRGBToLinear( color.r );\n\t\tthis.g = SRGBToLinear( color.g );\n\t\tthis.b = SRGBToLinear( color.b );\n\n\t\treturn this;\n\n\t}\n\n\tcopyLinearToSRGB( color ) {\n\n\t\tthis.r = LinearToSRGB( color.r );\n\t\tthis.g = LinearToSRGB( color.g );\n\t\tthis.b = LinearToSRGB( color.b );\n\n\t\treturn this;\n\n\t}\n\n\tconvertSRGBToLinear() {\n\n\t\tthis.copySRGBToLinear( this );\n\n\t\treturn this;\n\n\t}\n\n\tconvertLinearToSRGB() {\n\n\t\tthis.copyLinearToSRGB( this );\n\n\t\treturn this;\n\n\t}\n\n\tgetHex() {\n\n\t\treturn ( this.r * 255 ) << 16 ^ ( this.g * 255 ) << 8 ^ ( this.b * 255 ) << 0;\n\n\t}\n\n\tgetHexString() {\n\n\t\treturn ( '000000' + this.getHex().toString( 16 ) ).slice( - 6 );\n\n\t}\n\n\tgetHSL( target ) {\n\n\t\t// h,s,l ranges are in 0.0 - 1.0\n\n\t\tconst r = this.r, g = this.g, b = this.b;\n\n\t\tconst max = Math.max( r, g, b );\n\t\tconst min = Math.min( r, g, b );\n\n\t\tlet hue, saturation;\n\t\tconst lightness = ( min + max ) / 2.0;\n\n\t\tif ( min === max ) {\n\n\t\t\thue = 0;\n\t\t\tsaturation = 0;\n\n\t\t} else {\n\n\t\t\tconst delta = max - min;\n\n\t\t\tsaturation = lightness <= 0.5 ? delta / ( max + min ) : delta / ( 2 - max - min );\n\n\t\t\tswitch ( max ) {\n\n\t\t\t\tcase r: hue = ( g - b ) / delta + ( g < b ? 6 : 0 ); break;\n\t\t\t\tcase g: hue = ( b - r ) / delta + 2; break;\n\t\t\t\tcase b: hue = ( r - g ) / delta + 4; break;\n\n\t\t\t}\n\n\t\t\thue /= 6;\n\n\t\t}\n\n\t\ttarget.h = hue;\n\t\ttarget.s = saturation;\n\t\ttarget.l = lightness;\n\n\t\treturn target;\n\n\t}\n\n\tgetStyle() {\n\n\t\treturn 'rgb(' + ( ( this.r * 255 ) | 0 ) + ',' + ( ( this.g * 255 ) | 0 ) + ',' + ( ( this.b * 255 ) | 0 ) + ')';\n\n\t}\n\n\toffsetHSL( h, s, l ) {\n\n\t\tthis.getHSL( _hslA );\n\n\t\t_hslA.h += h; _hslA.s += s; _hslA.l += l;\n\n\t\tthis.setHSL( _hslA.h, _hslA.s, _hslA.l );\n\n\t\treturn this;\n\n\t}\n\n\tadd( color ) {\n\n\t\tthis.r += color.r;\n\t\tthis.g += color.g;\n\t\tthis.b += color.b;\n\n\t\treturn this;\n\n\t}\n\n\taddColors( color1, color2 ) {\n\n\t\tthis.r = color1.r + color2.r;\n\t\tthis.g = color1.g + color2.g;\n\t\tthis.b = color1.b + color2.b;\n\n\t\treturn this;\n\n\t}\n\n\taddScalar( s ) {\n\n\t\tthis.r += s;\n\t\tthis.g += s;\n\t\tthis.b += s;\n\n\t\treturn this;\n\n\t}\n\n\tsub( color ) {\n\n\t\tthis.r = Math.max( 0, this.r - color.r );\n\t\tthis.g = Math.max( 0, this.g - color.g );\n\t\tthis.b = Math.max( 0, this.b - color.b );\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( color ) {\n\n\t\tthis.r *= color.r;\n\t\tthis.g *= color.g;\n\t\tthis.b *= color.b;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyScalar( s ) {\n\n\t\tthis.r *= s;\n\t\tthis.g *= s;\n\t\tthis.b *= s;\n\n\t\treturn this;\n\n\t}\n\n\tlerp( color, alpha ) {\n\n\t\tthis.r += ( color.r - this.r ) * alpha;\n\t\tthis.g += ( color.g - this.g ) * alpha;\n\t\tthis.b += ( color.b - this.b ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tlerpColors( color1, color2, alpha ) {\n\n\t\tthis.r = color1.r + ( color2.r - color1.r ) * alpha;\n\t\tthis.g = color1.g + ( color2.g - color1.g ) * alpha;\n\t\tthis.b = color1.b + ( color2.b - color1.b ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tlerpHSL( color, alpha ) {\n\n\t\tthis.getHSL( _hslA );\n\t\tcolor.getHSL( _hslB );\n\n\t\tconst h = lerp( _hslA.h, _hslB.h, alpha );\n\t\tconst s = lerp( _hslA.s, _hslB.s, alpha );\n\t\tconst l = lerp( _hslA.l, _hslB.l, alpha );\n\n\t\tthis.setHSL( h, s, l );\n\n\t\treturn this;\n\n\t}\n\n\tequals( c ) {\n\n\t\treturn ( c.r === this.r ) && ( c.g === this.g ) && ( c.b === this.b );\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tthis.r = array[ offset ];\n\t\tthis.g = array[ offset + 1 ];\n\t\tthis.b = array[ offset + 2 ];\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tarray[ offset ] = this.r;\n\t\tarray[ offset + 1 ] = this.g;\n\t\tarray[ offset + 2 ] = this.b;\n\n\t\treturn array;\n\n\t}\n\n\tfromBufferAttribute( attribute, index ) {\n\n\t\tthis.r = attribute.getX( index );\n\t\tthis.g = attribute.getY( index );\n\t\tthis.b = attribute.getZ( index );\n\n\t\tif ( attribute.normalized === true ) {\n\n\t\t\t// assuming Uint8Array\n\n\t\t\tthis.r /= 255;\n\t\t\tthis.g /= 255;\n\t\t\tthis.b /= 255;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\treturn this.getHex();\n\n\t}\n\n}\n\nColor.NAMES = _colorKeywords;\n\nColor.prototype.isColor = true;\nColor.prototype.r = 1;\nColor.prototype.g = 1;\nColor.prototype.b = 1;\n\nlet _canvas;\n\nclass ImageUtils {\n\n\tstatic getDataURL( image ) {\n\n\t\tif ( /^data:/i.test( image.src ) ) {\n\n\t\t\treturn image.src;\n\n\t\t}\n\n\t\tif ( typeof HTMLCanvasElement == 'undefined' ) {\n\n\t\t\treturn image.src;\n\n\t\t}\n\n\t\tlet canvas;\n\n\t\tif ( image instanceof HTMLCanvasElement ) {\n\n\t\t\tcanvas = image;\n\n\t\t} else {\n\n\t\t\tif ( _canvas === undefined ) _canvas = createElementNS( 'canvas' );\n\n\t\t\t_canvas.width = image.width;\n\t\t\t_canvas.height = image.height;\n\n\t\t\tconst context = _canvas.getContext( '2d' );\n\n\t\t\tif ( image instanceof ImageData ) {\n\n\t\t\t\tcontext.putImageData( image, 0, 0 );\n\n\t\t\t} else {\n\n\t\t\t\tcontext.drawImage( image, 0, 0, image.width, image.height );\n\n\t\t\t}\n\n\t\t\tcanvas = _canvas;\n\n\t\t}\n\n\t\tif ( canvas.width > 2048 || canvas.height > 2048 ) {\n\n\t\t\tconsole.warn( 'THREE.ImageUtils.getDataURL: Image converted to jpg for performance reasons', image );\n\n\t\t\treturn canvas.toDataURL( 'image/jpeg', 0.6 );\n\n\t\t} else {\n\n\t\t\treturn canvas.toDataURL( 'image/png' );\n\n\t\t}\n\n\t}\n\n\tstatic sRGBToLinear( image ) {\n\n\t\tif ( ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) ||\n\t\t\t( typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement ) ||\n\t\t\t( typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap ) ) {\n\n\t\t\tconst canvas = createElementNS( 'canvas' );\n\n\t\t\tcanvas.width = image.width;\n\t\t\tcanvas.height = image.height;\n\n\t\t\tconst context = canvas.getContext( '2d' );\n\t\t\tcontext.drawImage( image, 0, 0, image.width, image.height );\n\n\t\t\tconst imageData = context.getImageData( 0, 0, image.width, image.height );\n\t\t\tconst data = imageData.data;\n\n\t\t\tfor ( let i = 0; i < data.length; i ++ ) {\n\n\t\t\t\tdata[ i ] = SRGBToLinear( data[ i ] / 255 ) * 255;\n\n\t\t\t}\n\n\t\t\tcontext.putImageData( imageData, 0, 0 );\n\n\t\t\treturn canvas;\n\n\t\t} else if ( image.data ) {\n\n\t\t\tconst data = image.data.slice( 0 );\n\n\t\t\tfor ( let i = 0; i < data.length; i ++ ) {\n\n\t\t\t\tif ( data instanceof Uint8Array || data instanceof Uint8ClampedArray ) {\n\n\t\t\t\t\tdata[ i ] = Math.floor( SRGBToLinear( data[ i ] / 255 ) * 255 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// assuming float\n\n\t\t\t\t\tdata[ i ] = SRGBToLinear( data[ i ] );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\tdata: data,\n\t\t\t\twidth: image.width,\n\t\t\t\theight: image.height\n\t\t\t};\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.ImageUtils.sRGBToLinear(): Unsupported image type. No color space conversion applied.' );\n\t\t\treturn image;\n\n\t\t}\n\n\t}\n\n}\n\nclass Source {\n\n\tconstructor( data = null ) {\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.data = data;\n\n\t\tthis.version = 0;\n\n\t}\n\n\tset needsUpdate( value ) {\n\n\t\tif ( value === true ) this.version ++;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst isRootObject = ( meta === undefined || typeof meta === 'string' );\n\n\t\tif ( ! isRootObject && meta.images[ this.uuid ] !== undefined ) {\n\n\t\t\treturn meta.images[ this.uuid ];\n\n\t\t}\n\n\t\tconst output = {\n\t\t\tuuid: this.uuid,\n\t\t\turl: ''\n\t\t};\n\n\t\tconst data = this.data;\n\n\t\tif ( data !== null ) {\n\n\t\t\tlet url;\n\n\t\t\tif ( Array.isArray( data ) ) {\n\n\t\t\t\t// cube texture\n\n\t\t\t\turl = [];\n\n\t\t\t\tfor ( let i = 0, l = data.length; i < l; i ++ ) {\n\n\t\t\t\t\tif ( data[ i ].isDataTexture ) {\n\n\t\t\t\t\t\turl.push( serializeImage( data[ i ].image ) );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\turl.push( serializeImage( data[ i ] ) );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\t// texture\n\n\t\t\t\turl = serializeImage( data );\n\n\t\t\t}\n\n\t\t\toutput.url = url;\n\n\t\t}\n\n\t\tif ( ! isRootObject ) {\n\n\t\t\tmeta.images[ this.uuid ] = output;\n\n\t\t}\n\n\t\treturn output;\n\n\t}\n\n}\n\nfunction serializeImage( image ) {\n\n\tif ( ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) ||\n\t\t( typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement ) ||\n\t\t( typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap ) ) {\n\n\t\t// default images\n\n\t\treturn ImageUtils.getDataURL( image );\n\n\t} else {\n\n\t\tif ( image.data ) {\n\n\t\t\t// images of DataTexture\n\n\t\t\treturn {\n\t\t\t\tdata: Array.prototype.slice.call( image.data ),\n\t\t\t\twidth: image.width,\n\t\t\t\theight: image.height,\n\t\t\t\ttype: image.data.constructor.name\n\t\t\t};\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.Texture: Unable to serialize Texture.' );\n\t\t\treturn {};\n\n\t\t}\n\n\t}\n\n}\n\nSource.prototype.isSource = true;\n\nlet textureId = 0;\n\nclass Texture extends EventDispatcher {\n\n\tconstructor( image = Texture.DEFAULT_IMAGE, mapping = Texture.DEFAULT_MAPPING, wrapS = ClampToEdgeWrapping, wrapT = ClampToEdgeWrapping, magFilter = LinearFilter, minFilter = LinearMipmapLinearFilter, format = RGBAFormat, type = UnsignedByteType, anisotropy = 1, encoding = LinearEncoding ) {\n\n\t\tsuper();\n\n\t\tObject.defineProperty( this, 'id', { value: textureId ++ } );\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.name = '';\n\n\t\tthis.source = new Source( image );\n\t\tthis.mipmaps = [];\n\n\t\tthis.mapping = mapping;\n\n\t\tthis.wrapS = wrapS;\n\t\tthis.wrapT = wrapT;\n\n\t\tthis.magFilter = magFilter;\n\t\tthis.minFilter = minFilter;\n\n\t\tthis.anisotropy = anisotropy;\n\n\t\tthis.format = format;\n\t\tthis.internalFormat = null;\n\t\tthis.type = type;\n\n\t\tthis.offset = new Vector2( 0, 0 );\n\t\tthis.repeat = new Vector2( 1, 1 );\n\t\tthis.center = new Vector2( 0, 0 );\n\t\tthis.rotation = 0;\n\n\t\tthis.matrixAutoUpdate = true;\n\t\tthis.matrix = new Matrix3();\n\n\t\tthis.generateMipmaps = true;\n\t\tthis.premultiplyAlpha = false;\n\t\tthis.flipY = true;\n\t\tthis.unpackAlignment = 4;\t// valid values: 1, 2, 4, 8 (see http://www.khronos.org/opengles/sdk/docs/man/xhtml/glPixelStorei.xml)\n\n\t\t// Values of encoding !== THREE.LinearEncoding only supported on map, envMap and emissiveMap.\n\t\t//\n\t\t// Also changing the encoding after already used by a Material will not automatically make the Material\n\t\t// update. You need to explicitly call Material.needsUpdate to trigger it to recompile.\n\t\tthis.encoding = encoding;\n\n\t\tthis.userData = {};\n\n\t\tthis.version = 0;\n\t\tthis.onUpdate = null;\n\n\t\tthis.isRenderTargetTexture = false; // indicates whether a texture belongs to a render target or not\n\t\tthis.needsPMREMUpdate = false; // indicates whether this texture should be processed by PMREMGenerator or not (only relevant for render target textures)\n\n\t}\n\n\tget image() {\n\n\t\treturn this.source.data;\n\n\t}\n\n\tset image( value ) {\n\n\t\tthis.source.data = value;\n\n\t}\n\n\tupdateMatrix() {\n\n\t\tthis.matrix.setUvTransform( this.offset.x, this.offset.y, this.repeat.x, this.repeat.y, this.rotation, this.center.x, this.center.y );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.name = source.name;\n\n\t\tthis.source = source.source;\n\t\tthis.mipmaps = source.mipmaps.slice( 0 );\n\n\t\tthis.mapping = source.mapping;\n\n\t\tthis.wrapS = source.wrapS;\n\t\tthis.wrapT = source.wrapT;\n\n\t\tthis.magFilter = source.magFilter;\n\t\tthis.minFilter = source.minFilter;\n\n\t\tthis.anisotropy = source.anisotropy;\n\n\t\tthis.format = source.format;\n\t\tthis.internalFormat = source.internalFormat;\n\t\tthis.type = source.type;\n\n\t\tthis.offset.copy( source.offset );\n\t\tthis.repeat.copy( source.repeat );\n\t\tthis.center.copy( source.center );\n\t\tthis.rotation = source.rotation;\n\n\t\tthis.matrixAutoUpdate = source.matrixAutoUpdate;\n\t\tthis.matrix.copy( source.matrix );\n\n\t\tthis.generateMipmaps = source.generateMipmaps;\n\t\tthis.premultiplyAlpha = source.premultiplyAlpha;\n\t\tthis.flipY = source.flipY;\n\t\tthis.unpackAlignment = source.unpackAlignment;\n\t\tthis.encoding = source.encoding;\n\n\t\tthis.userData = JSON.parse( JSON.stringify( source.userData ) );\n\n\t\tthis.needsUpdate = true;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst isRootObject = ( meta === undefined || typeof meta === 'string' );\n\n\t\tif ( ! isRootObject && meta.textures[ this.uuid ] !== undefined ) {\n\n\t\t\treturn meta.textures[ this.uuid ];\n\n\t\t}\n\n\t\tconst output = {\n\n\t\t\tmetadata: {\n\t\t\t\tversion: 4.5,\n\t\t\t\ttype: 'Texture',\n\t\t\t\tgenerator: 'Texture.toJSON'\n\t\t\t},\n\n\t\t\tuuid: this.uuid,\n\t\t\tname: this.name,\n\n\t\t\timage: this.source.toJSON( meta ).uuid,\n\n\t\t\tmapping: this.mapping,\n\n\t\t\trepeat: [ this.repeat.x, this.repeat.y ],\n\t\t\toffset: [ this.offset.x, this.offset.y ],\n\t\t\tcenter: [ this.center.x, this.center.y ],\n\t\t\trotation: this.rotation,\n\n\t\t\twrap: [ this.wrapS, this.wrapT ],\n\n\t\t\tformat: this.format,\n\t\t\ttype: this.type,\n\t\t\tencoding: this.encoding,\n\n\t\t\tminFilter: this.minFilter,\n\t\t\tmagFilter: this.magFilter,\n\t\t\tanisotropy: this.anisotropy,\n\n\t\t\tflipY: this.flipY,\n\n\t\t\tpremultiplyAlpha: this.premultiplyAlpha,\n\t\t\tunpackAlignment: this.unpackAlignment\n\n\t\t};\n\n\t\tif ( JSON.stringify( this.userData ) !== '{}' ) output.userData = this.userData;\n\n\t\tif ( ! isRootObject ) {\n\n\t\t\tmeta.textures[ this.uuid ] = output;\n\n\t\t}\n\n\t\treturn output;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.dispatchEvent( { type: 'dispose' } );\n\n\t}\n\n\ttransformUv( uv ) {\n\n\t\tif ( this.mapping !== UVMapping ) return uv;\n\n\t\tuv.applyMatrix3( this.matrix );\n\n\t\tif ( uv.x < 0 || uv.x > 1 ) {\n\n\t\t\tswitch ( this.wrapS ) {\n\n\t\t\t\tcase RepeatWrapping:\n\n\t\t\t\t\tuv.x = uv.x - Math.floor( uv.x );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ClampToEdgeWrapping:\n\n\t\t\t\t\tuv.x = uv.x < 0 ? 0 : 1;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase MirroredRepeatWrapping:\n\n\t\t\t\t\tif ( Math.abs( Math.floor( uv.x ) % 2 ) === 1 ) {\n\n\t\t\t\t\t\tuv.x = Math.ceil( uv.x ) - uv.x;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tuv.x = uv.x - Math.floor( uv.x );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( uv.y < 0 || uv.y > 1 ) {\n\n\t\t\tswitch ( this.wrapT ) {\n\n\t\t\t\tcase RepeatWrapping:\n\n\t\t\t\t\tuv.y = uv.y - Math.floor( uv.y );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ClampToEdgeWrapping:\n\n\t\t\t\t\tuv.y = uv.y < 0 ? 0 : 1;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase MirroredRepeatWrapping:\n\n\t\t\t\t\tif ( Math.abs( Math.floor( uv.y ) % 2 ) === 1 ) {\n\n\t\t\t\t\t\tuv.y = Math.ceil( uv.y ) - uv.y;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tuv.y = uv.y - Math.floor( uv.y );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( this.flipY ) {\n\n\t\t\tuv.y = 1 - uv.y;\n\n\t\t}\n\n\t\treturn uv;\n\n\t}\n\n\tset needsUpdate( value ) {\n\n\t\tif ( value === true ) {\n\n\t\t\tthis.version ++;\n\t\t\tthis.source.needsUpdate = true;\n\n\t\t}\n\n\t}\n\n}\n\nTexture.DEFAULT_IMAGE = null;\nTexture.DEFAULT_MAPPING = UVMapping;\n\nTexture.prototype.isTexture = true;\n\nclass Vector4 {\n\n\tconstructor( x = 0, y = 0, z = 0, w = 1 ) {\n\n\t\tthis.x = x;\n\t\tthis.y = y;\n\t\tthis.z = z;\n\t\tthis.w = w;\n\n\t}\n\n\tget width() {\n\n\t\treturn this.z;\n\n\t}\n\n\tset width( value ) {\n\n\t\tthis.z = value;\n\n\t}\n\n\tget height() {\n\n\t\treturn this.w;\n\n\t}\n\n\tset height( value ) {\n\n\t\tthis.w = value;\n\n\t}\n\n\tset( x, y, z, w ) {\n\n\t\tthis.x = x;\n\t\tthis.y = y;\n\t\tthis.z = z;\n\t\tthis.w = w;\n\n\t\treturn this;\n\n\t}\n\n\tsetScalar( scalar ) {\n\n\t\tthis.x = scalar;\n\t\tthis.y = scalar;\n\t\tthis.z = scalar;\n\t\tthis.w = scalar;\n\n\t\treturn this;\n\n\t}\n\n\tsetX( x ) {\n\n\t\tthis.x = x;\n\n\t\treturn this;\n\n\t}\n\n\tsetY( y ) {\n\n\t\tthis.y = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetZ( z ) {\n\n\t\tthis.z = z;\n\n\t\treturn this;\n\n\t}\n\n\tsetW( w ) {\n\n\t\tthis.w = w;\n\n\t\treturn this;\n\n\t}\n\n\tsetComponent( index, value ) {\n\n\t\tswitch ( index ) {\n\n\t\t\tcase 0: this.x = value; break;\n\t\t\tcase 1: this.y = value; break;\n\t\t\tcase 2: this.z = value; break;\n\t\t\tcase 3: this.w = value; break;\n\t\t\tdefault: throw new Error( 'index is out of range: ' + index );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetComponent( index ) {\n\n\t\tswitch ( index ) {\n\n\t\t\tcase 0: return this.x;\n\t\t\tcase 1: return this.y;\n\t\t\tcase 2: return this.z;\n\t\t\tcase 3: return this.w;\n\t\t\tdefault: throw new Error( 'index is out of range: ' + index );\n\n\t\t}\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this.x, this.y, this.z, this.w );\n\n\t}\n\n\tcopy( v ) {\n\n\t\tthis.x = v.x;\n\t\tthis.y = v.y;\n\t\tthis.z = v.z;\n\t\tthis.w = ( v.w !== undefined ) ? v.w : 1;\n\n\t\treturn this;\n\n\t}\n\n\tadd( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector4: .add() now only accepts one argument. Use .addVectors( a, b ) instead.' );\n\t\t\treturn this.addVectors( v, w );\n\n\t\t}\n\n\t\tthis.x += v.x;\n\t\tthis.y += v.y;\n\t\tthis.z += v.z;\n\t\tthis.w += v.w;\n\n\t\treturn this;\n\n\t}\n\n\taddScalar( s ) {\n\n\t\tthis.x += s;\n\t\tthis.y += s;\n\t\tthis.z += s;\n\t\tthis.w += s;\n\n\t\treturn this;\n\n\t}\n\n\taddVectors( a, b ) {\n\n\t\tthis.x = a.x + b.x;\n\t\tthis.y = a.y + b.y;\n\t\tthis.z = a.z + b.z;\n\t\tthis.w = a.w + b.w;\n\n\t\treturn this;\n\n\t}\n\n\taddScaledVector( v, s ) {\n\n\t\tthis.x += v.x * s;\n\t\tthis.y += v.y * s;\n\t\tthis.z += v.z * s;\n\t\tthis.w += v.w * s;\n\n\t\treturn this;\n\n\t}\n\n\tsub( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector4: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.' );\n\t\t\treturn this.subVectors( v, w );\n\n\t\t}\n\n\t\tthis.x -= v.x;\n\t\tthis.y -= v.y;\n\t\tthis.z -= v.z;\n\t\tthis.w -= v.w;\n\n\t\treturn this;\n\n\t}\n\n\tsubScalar( s ) {\n\n\t\tthis.x -= s;\n\t\tthis.y -= s;\n\t\tthis.z -= s;\n\t\tthis.w -= s;\n\n\t\treturn this;\n\n\t}\n\n\tsubVectors( a, b ) {\n\n\t\tthis.x = a.x - b.x;\n\t\tthis.y = a.y - b.y;\n\t\tthis.z = a.z - b.z;\n\t\tthis.w = a.w - b.w;\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( v ) {\n\n\t\tthis.x *= v.x;\n\t\tthis.y *= v.y;\n\t\tthis.z *= v.z;\n\t\tthis.w *= v.w;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyScalar( scalar ) {\n\n\t\tthis.x *= scalar;\n\t\tthis.y *= scalar;\n\t\tthis.z *= scalar;\n\t\tthis.w *= scalar;\n\n\t\treturn this;\n\n\t}\n\n\tapplyMatrix4( m ) {\n\n\t\tconst x = this.x, y = this.y, z = this.z, w = this.w;\n\t\tconst e = m.elements;\n\n\t\tthis.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ] * z + e[ 12 ] * w;\n\t\tthis.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ] * z + e[ 13 ] * w;\n\t\tthis.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] * w;\n\t\tthis.w = e[ 3 ] * x + e[ 7 ] * y + e[ 11 ] * z + e[ 15 ] * w;\n\n\t\treturn this;\n\n\t}\n\n\tdivideScalar( scalar ) {\n\n\t\treturn this.multiplyScalar( 1 / scalar );\n\n\t}\n\n\tsetAxisAngleFromQuaternion( q ) {\n\n\t\t// http://www.euclideanspace.com/maths/geometry/rotations/conversions/quaternionToAngle/index.htm\n\n\t\t// q is assumed to be normalized\n\n\t\tthis.w = 2 * Math.acos( q.w );\n\n\t\tconst s = Math.sqrt( 1 - q.w * q.w );\n\n\t\tif ( s < 0.0001 ) {\n\n\t\t\tthis.x = 1;\n\t\t\tthis.y = 0;\n\t\t\tthis.z = 0;\n\n\t\t} else {\n\n\t\t\tthis.x = q.x / s;\n\t\t\tthis.y = q.y / s;\n\t\t\tthis.z = q.z / s;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetAxisAngleFromRotationMatrix( m ) {\n\n\t\t// http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToAngle/index.htm\n\n\t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n\t\tlet angle, x, y, z; // variables for result\n\t\tconst epsilon = 0.01,\t\t// margin to allow for rounding errors\n\t\t\tepsilon2 = 0.1,\t\t// margin to distinguish between 0 and 180 degrees\n\n\t\t\tte = m.elements,\n\n\t\t\tm11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ],\n\t\t\tm21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ],\n\t\t\tm31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ];\n\n\t\tif ( ( Math.abs( m12 - m21 ) < epsilon ) &&\n\t\t     ( Math.abs( m13 - m31 ) < epsilon ) &&\n\t\t     ( Math.abs( m23 - m32 ) < epsilon ) ) {\n\n\t\t\t// singularity found\n\t\t\t// first check for identity matrix which must have +1 for all terms\n\t\t\t// in leading diagonal and zero in other terms\n\n\t\t\tif ( ( Math.abs( m12 + m21 ) < epsilon2 ) &&\n\t\t\t     ( Math.abs( m13 + m31 ) < epsilon2 ) &&\n\t\t\t     ( Math.abs( m23 + m32 ) < epsilon2 ) &&\n\t\t\t     ( Math.abs( m11 + m22 + m33 - 3 ) < epsilon2 ) ) {\n\n\t\t\t\t// this singularity is identity matrix so angle = 0\n\n\t\t\t\tthis.set( 1, 0, 0, 0 );\n\n\t\t\t\treturn this; // zero angle, arbitrary axis\n\n\t\t\t}\n\n\t\t\t// otherwise this singularity is angle = 180\n\n\t\t\tangle = Math.PI;\n\n\t\t\tconst xx = ( m11 + 1 ) / 2;\n\t\t\tconst yy = ( m22 + 1 ) / 2;\n\t\t\tconst zz = ( m33 + 1 ) / 2;\n\t\t\tconst xy = ( m12 + m21 ) / 4;\n\t\t\tconst xz = ( m13 + m31 ) / 4;\n\t\t\tconst yz = ( m23 + m32 ) / 4;\n\n\t\t\tif ( ( xx > yy ) && ( xx > zz ) ) {\n\n\t\t\t\t// m11 is the largest diagonal term\n\n\t\t\t\tif ( xx < epsilon ) {\n\n\t\t\t\t\tx = 0;\n\t\t\t\t\ty = 0.707106781;\n\t\t\t\t\tz = 0.707106781;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tx = Math.sqrt( xx );\n\t\t\t\t\ty = xy / x;\n\t\t\t\t\tz = xz / x;\n\n\t\t\t\t}\n\n\t\t\t} else if ( yy > zz ) {\n\n\t\t\t\t// m22 is the largest diagonal term\n\n\t\t\t\tif ( yy < epsilon ) {\n\n\t\t\t\t\tx = 0.707106781;\n\t\t\t\t\ty = 0;\n\t\t\t\t\tz = 0.707106781;\n\n\t\t\t\t} else {\n\n\t\t\t\t\ty = Math.sqrt( yy );\n\t\t\t\t\tx = xy / y;\n\t\t\t\t\tz = yz / y;\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\t// m33 is the largest diagonal term so base result on this\n\n\t\t\t\tif ( zz < epsilon ) {\n\n\t\t\t\t\tx = 0.707106781;\n\t\t\t\t\ty = 0.707106781;\n\t\t\t\t\tz = 0;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tz = Math.sqrt( zz );\n\t\t\t\t\tx = xz / z;\n\t\t\t\t\ty = yz / z;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis.set( x, y, z, angle );\n\n\t\t\treturn this; // return 180 deg rotation\n\n\t\t}\n\n\t\t// as we have reached here there are no singularities so we can handle normally\n\n\t\tlet s = Math.sqrt( ( m32 - m23 ) * ( m32 - m23 ) +\n\t\t\t( m13 - m31 ) * ( m13 - m31 ) +\n\t\t\t( m21 - m12 ) * ( m21 - m12 ) ); // used to normalize\n\n\t\tif ( Math.abs( s ) < 0.001 ) s = 1;\n\n\t\t// prevent divide by zero, should not happen if matrix is orthogonal and should be\n\t\t// caught by singularity test above, but I've left it in just in case\n\n\t\tthis.x = ( m32 - m23 ) / s;\n\t\tthis.y = ( m13 - m31 ) / s;\n\t\tthis.z = ( m21 - m12 ) / s;\n\t\tthis.w = Math.acos( ( m11 + m22 + m33 - 1 ) / 2 );\n\n\t\treturn this;\n\n\t}\n\n\tmin( v ) {\n\n\t\tthis.x = Math.min( this.x, v.x );\n\t\tthis.y = Math.min( this.y, v.y );\n\t\tthis.z = Math.min( this.z, v.z );\n\t\tthis.w = Math.min( this.w, v.w );\n\n\t\treturn this;\n\n\t}\n\n\tmax( v ) {\n\n\t\tthis.x = Math.max( this.x, v.x );\n\t\tthis.y = Math.max( this.y, v.y );\n\t\tthis.z = Math.max( this.z, v.z );\n\t\tthis.w = Math.max( this.w, v.w );\n\n\t\treturn this;\n\n\t}\n\n\tclamp( min, max ) {\n\n\t\t// assumes min < max, componentwise\n\n\t\tthis.x = Math.max( min.x, Math.min( max.x, this.x ) );\n\t\tthis.y = Math.max( min.y, Math.min( max.y, this.y ) );\n\t\tthis.z = Math.max( min.z, Math.min( max.z, this.z ) );\n\t\tthis.w = Math.max( min.w, Math.min( max.w, this.w ) );\n\n\t\treturn this;\n\n\t}\n\n\tclampScalar( minVal, maxVal ) {\n\n\t\tthis.x = Math.max( minVal, Math.min( maxVal, this.x ) );\n\t\tthis.y = Math.max( minVal, Math.min( maxVal, this.y ) );\n\t\tthis.z = Math.max( minVal, Math.min( maxVal, this.z ) );\n\t\tthis.w = Math.max( minVal, Math.min( maxVal, this.w ) );\n\n\t\treturn this;\n\n\t}\n\n\tclampLength( min, max ) {\n\n\t\tconst length = this.length();\n\n\t\treturn this.divideScalar( length || 1 ).multiplyScalar( Math.max( min, Math.min( max, length ) ) );\n\n\t}\n\n\tfloor() {\n\n\t\tthis.x = Math.floor( this.x );\n\t\tthis.y = Math.floor( this.y );\n\t\tthis.z = Math.floor( this.z );\n\t\tthis.w = Math.floor( this.w );\n\n\t\treturn this;\n\n\t}\n\n\tceil() {\n\n\t\tthis.x = Math.ceil( this.x );\n\t\tthis.y = Math.ceil( this.y );\n\t\tthis.z = Math.ceil( this.z );\n\t\tthis.w = Math.ceil( this.w );\n\n\t\treturn this;\n\n\t}\n\n\tround() {\n\n\t\tthis.x = Math.round( this.x );\n\t\tthis.y = Math.round( this.y );\n\t\tthis.z = Math.round( this.z );\n\t\tthis.w = Math.round( this.w );\n\n\t\treturn this;\n\n\t}\n\n\troundToZero() {\n\n\t\tthis.x = ( this.x < 0 ) ? Math.ceil( this.x ) : Math.floor( this.x );\n\t\tthis.y = ( this.y < 0 ) ? Math.ceil( this.y ) : Math.floor( this.y );\n\t\tthis.z = ( this.z < 0 ) ? Math.ceil( this.z ) : Math.floor( this.z );\n\t\tthis.w = ( this.w < 0 ) ? Math.ceil( this.w ) : Math.floor( this.w );\n\n\t\treturn this;\n\n\t}\n\n\tnegate() {\n\n\t\tthis.x = - this.x;\n\t\tthis.y = - this.y;\n\t\tthis.z = - this.z;\n\t\tthis.w = - this.w;\n\n\t\treturn this;\n\n\t}\n\n\tdot( v ) {\n\n\t\treturn this.x * v.x + this.y * v.y + this.z * v.z + this.w * v.w;\n\n\t}\n\n\tlengthSq() {\n\n\t\treturn this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w;\n\n\t}\n\n\tlength() {\n\n\t\treturn Math.sqrt( this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w );\n\n\t}\n\n\tmanhattanLength() {\n\n\t\treturn Math.abs( this.x ) + Math.abs( this.y ) + Math.abs( this.z ) + Math.abs( this.w );\n\n\t}\n\n\tnormalize() {\n\n\t\treturn this.divideScalar( this.length() || 1 );\n\n\t}\n\n\tsetLength( length ) {\n\n\t\treturn this.normalize().multiplyScalar( length );\n\n\t}\n\n\tlerp( v, alpha ) {\n\n\t\tthis.x += ( v.x - this.x ) * alpha;\n\t\tthis.y += ( v.y - this.y ) * alpha;\n\t\tthis.z += ( v.z - this.z ) * alpha;\n\t\tthis.w += ( v.w - this.w ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tlerpVectors( v1, v2, alpha ) {\n\n\t\tthis.x = v1.x + ( v2.x - v1.x ) * alpha;\n\t\tthis.y = v1.y + ( v2.y - v1.y ) * alpha;\n\t\tthis.z = v1.z + ( v2.z - v1.z ) * alpha;\n\t\tthis.w = v1.w + ( v2.w - v1.w ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tequals( v ) {\n\n\t\treturn ( ( v.x === this.x ) && ( v.y === this.y ) && ( v.z === this.z ) && ( v.w === this.w ) );\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tthis.x = array[ offset ];\n\t\tthis.y = array[ offset + 1 ];\n\t\tthis.z = array[ offset + 2 ];\n\t\tthis.w = array[ offset + 3 ];\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tarray[ offset ] = this.x;\n\t\tarray[ offset + 1 ] = this.y;\n\t\tarray[ offset + 2 ] = this.z;\n\t\tarray[ offset + 3 ] = this.w;\n\n\t\treturn array;\n\n\t}\n\n\tfromBufferAttribute( attribute, index, offset ) {\n\n\t\tif ( offset !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector4: offset has been removed from .fromBufferAttribute().' );\n\n\t\t}\n\n\t\tthis.x = attribute.getX( index );\n\t\tthis.y = attribute.getY( index );\n\t\tthis.z = attribute.getZ( index );\n\t\tthis.w = attribute.getW( index );\n\n\t\treturn this;\n\n\t}\n\n\trandom() {\n\n\t\tthis.x = Math.random();\n\t\tthis.y = Math.random();\n\t\tthis.z = Math.random();\n\t\tthis.w = Math.random();\n\n\t\treturn this;\n\n\t}\n\n\t*[ Symbol.iterator ]() {\n\n\t\tyield this.x;\n\t\tyield this.y;\n\t\tyield this.z;\n\t\tyield this.w;\n\n\t}\n\n}\n\nVector4.prototype.isVector4 = true;\n\n/*\n In options, we can specify:\n * Texture parameters for an auto-generated target texture\n * depthBuffer/stencilBuffer: Booleans to indicate if we should generate these buffers\n*/\nclass WebGLRenderTarget extends EventDispatcher {\n\n\tconstructor( width, height, options = {} ) {\n\n\t\tsuper();\n\n\t\tthis.width = width;\n\t\tthis.height = height;\n\t\tthis.depth = 1;\n\n\t\tthis.scissor = new Vector4( 0, 0, width, height );\n\t\tthis.scissorTest = false;\n\n\t\tthis.viewport = new Vector4( 0, 0, width, height );\n\n\t\tconst image = { width: width, height: height, depth: 1 };\n\n\t\tthis.texture = new Texture( image, options.mapping, options.wrapS, options.wrapT, options.magFilter, options.minFilter, options.format, options.type, options.anisotropy, options.encoding );\n\t\tthis.texture.isRenderTargetTexture = true;\n\n\t\tthis.texture.generateMipmaps = options.generateMipmaps !== undefined ? options.generateMipmaps : false;\n\t\tthis.texture.internalFormat = options.internalFormat !== undefined ? options.internalFormat : null;\n\t\tthis.texture.minFilter = options.minFilter !== undefined ? options.minFilter : LinearFilter;\n\n\t\tthis.depthBuffer = options.depthBuffer !== undefined ? options.depthBuffer : true;\n\t\tthis.stencilBuffer = options.stencilBuffer !== undefined ? options.stencilBuffer : false;\n\n\t\tthis.depthTexture = options.depthTexture !== undefined ? options.depthTexture : null;\n\n\t\tthis.samples = options.samples !== undefined ? options.samples : 0;\n\n\t}\n\n\tsetSize( width, height, depth = 1 ) {\n\n\t\tif ( this.width !== width || this.height !== height || this.depth !== depth ) {\n\n\t\t\tthis.width = width;\n\t\t\tthis.height = height;\n\t\t\tthis.depth = depth;\n\n\t\t\tthis.texture.image.width = width;\n\t\t\tthis.texture.image.height = height;\n\t\t\tthis.texture.image.depth = depth;\n\n\t\t\tthis.dispose();\n\n\t\t}\n\n\t\tthis.viewport.set( 0, 0, width, height );\n\t\tthis.scissor.set( 0, 0, width, height );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.width = source.width;\n\t\tthis.height = source.height;\n\t\tthis.depth = source.depth;\n\n\t\tthis.viewport.copy( source.viewport );\n\n\t\tthis.texture = source.texture.clone();\n\n\t\t// ensure image object is not shared, see #20328\n\n\t\tthis.texture.image = Object.assign( {}, source.texture.image );\n\n\t\tthis.depthBuffer = source.depthBuffer;\n\t\tthis.stencilBuffer = source.stencilBuffer;\n\n\t\tif ( source.depthTexture !== null ) this.depthTexture = source.depthTexture.clone();\n\n\t\tthis.samples = source.samples;\n\n\t\treturn this;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.dispatchEvent( { type: 'dispose' } );\n\n\t}\n\n}\n\nWebGLRenderTarget.prototype.isWebGLRenderTarget = true;\n\nclass DataArrayTexture extends Texture {\n\n\tconstructor( data = null, width = 1, height = 1, depth = 1 ) {\n\n\t\tsuper( null );\n\n\t\tthis.image = { data, width, height, depth };\n\n\t\tthis.magFilter = NearestFilter;\n\t\tthis.minFilter = NearestFilter;\n\n\t\tthis.wrapR = ClampToEdgeWrapping;\n\n\t\tthis.generateMipmaps = false;\n\t\tthis.flipY = false;\n\t\tthis.unpackAlignment = 1;\n\n\t}\n\n}\n\nDataArrayTexture.prototype.isDataArrayTexture = true;\n\nclass WebGLArrayRenderTarget extends WebGLRenderTarget {\n\n\tconstructor( width, height, depth ) {\n\n\t\tsuper( width, height );\n\n\t\tthis.depth = depth;\n\n\t\tthis.texture = new DataArrayTexture( null, width, height, depth );\n\n\t\tthis.texture.isRenderTargetTexture = true;\n\n\t}\n\n}\n\nWebGLArrayRenderTarget.prototype.isWebGLArrayRenderTarget = true;\n\nclass Data3DTexture extends Texture {\n\n\tconstructor( data = null, width = 1, height = 1, depth = 1 ) {\n\n\t\t// We're going to add .setXXX() methods for setting properties later.\n\t\t// Users can still set in DataTexture3D directly.\n\t\t//\n\t\t//\tconst texture = new THREE.DataTexture3D( data, width, height, depth );\n\t\t// \ttexture.anisotropy = 16;\n\t\t//\n\t\t// See #14839\n\n\t\tsuper( null );\n\n\t\tthis.image = { data, width, height, depth };\n\n\t\tthis.magFilter = NearestFilter;\n\t\tthis.minFilter = NearestFilter;\n\n\t\tthis.wrapR = ClampToEdgeWrapping;\n\n\t\tthis.generateMipmaps = false;\n\t\tthis.flipY = false;\n\t\tthis.unpackAlignment = 1;\n\n\t}\n\n}\n\nData3DTexture.prototype.isData3DTexture = true;\n\nclass WebGL3DRenderTarget extends WebGLRenderTarget {\n\n\tconstructor( width, height, depth ) {\n\n\t\tsuper( width, height );\n\n\t\tthis.depth = depth;\n\n\t\tthis.texture = new Data3DTexture( null, width, height, depth );\n\n\t\tthis.texture.isRenderTargetTexture = true;\n\n\t}\n\n}\n\nWebGL3DRenderTarget.prototype.isWebGL3DRenderTarget = true;\n\nclass WebGLMultipleRenderTargets extends WebGLRenderTarget {\n\n\tconstructor( width, height, count, options = {} ) {\n\n\t\tsuper( width, height, options );\n\n\t\tconst texture = this.texture;\n\n\t\tthis.texture = [];\n\n\t\tfor ( let i = 0; i < count; i ++ ) {\n\n\t\t\tthis.texture[ i ] = texture.clone();\n\t\t\tthis.texture[ i ].isRenderTargetTexture = true;\n\n\t\t}\n\n\t}\n\n\tsetSize( width, height, depth = 1 ) {\n\n\t\tif ( this.width !== width || this.height !== height || this.depth !== depth ) {\n\n\t\t\tthis.width = width;\n\t\t\tthis.height = height;\n\t\t\tthis.depth = depth;\n\n\t\t\tfor ( let i = 0, il = this.texture.length; i < il; i ++ ) {\n\n\t\t\t\tthis.texture[ i ].image.width = width;\n\t\t\t\tthis.texture[ i ].image.height = height;\n\t\t\t\tthis.texture[ i ].image.depth = depth;\n\n\t\t\t}\n\n\t\t\tthis.dispose();\n\n\t\t}\n\n\t\tthis.viewport.set( 0, 0, width, height );\n\t\tthis.scissor.set( 0, 0, width, height );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.dispose();\n\n\t\tthis.width = source.width;\n\t\tthis.height = source.height;\n\t\tthis.depth = source.depth;\n\n\t\tthis.viewport.set( 0, 0, this.width, this.height );\n\t\tthis.scissor.set( 0, 0, this.width, this.height );\n\n\t\tthis.depthBuffer = source.depthBuffer;\n\t\tthis.stencilBuffer = source.stencilBuffer;\n\t\tthis.depthTexture = source.depthTexture;\n\n\t\tthis.texture.length = 0;\n\n\t\tfor ( let i = 0, il = source.texture.length; i < il; i ++ ) {\n\n\t\t\tthis.texture[ i ] = source.texture[ i ].clone();\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\nWebGLMultipleRenderTargets.prototype.isWebGLMultipleRenderTargets = true;\n\nclass Quaternion {\n\n\tconstructor( x = 0, y = 0, z = 0, w = 1 ) {\n\n\t\tthis._x = x;\n\t\tthis._y = y;\n\t\tthis._z = z;\n\t\tthis._w = w;\n\n\t}\n\n\tstatic slerp( qa, qb, qm, t ) {\n\n\t\tconsole.warn( 'THREE.Quaternion: Static .slerp() has been deprecated. Use qm.slerpQuaternions( qa, qb, t ) instead.' );\n\t\treturn qm.slerpQuaternions( qa, qb, t );\n\n\t}\n\n\tstatic slerpFlat( dst, dstOffset, src0, srcOffset0, src1, srcOffset1, t ) {\n\n\t\t// fuzz-free, array-based Quaternion SLERP operation\n\n\t\tlet x0 = src0[ srcOffset0 + 0 ],\n\t\t\ty0 = src0[ srcOffset0 + 1 ],\n\t\t\tz0 = src0[ srcOffset0 + 2 ],\n\t\t\tw0 = src0[ srcOffset0 + 3 ];\n\n\t\tconst x1 = src1[ srcOffset1 + 0 ],\n\t\t\ty1 = src1[ srcOffset1 + 1 ],\n\t\t\tz1 = src1[ srcOffset1 + 2 ],\n\t\t\tw1 = src1[ srcOffset1 + 3 ];\n\n\t\tif ( t === 0 ) {\n\n\t\t\tdst[ dstOffset + 0 ] = x0;\n\t\t\tdst[ dstOffset + 1 ] = y0;\n\t\t\tdst[ dstOffset + 2 ] = z0;\n\t\t\tdst[ dstOffset + 3 ] = w0;\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( t === 1 ) {\n\n\t\t\tdst[ dstOffset + 0 ] = x1;\n\t\t\tdst[ dstOffset + 1 ] = y1;\n\t\t\tdst[ dstOffset + 2 ] = z1;\n\t\t\tdst[ dstOffset + 3 ] = w1;\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( w0 !== w1 || x0 !== x1 || y0 !== y1 || z0 !== z1 ) {\n\n\t\t\tlet s = 1 - t;\n\t\t\tconst cos = x0 * x1 + y0 * y1 + z0 * z1 + w0 * w1,\n\t\t\t\tdir = ( cos >= 0 ? 1 : - 1 ),\n\t\t\t\tsqrSin = 1 - cos * cos;\n\n\t\t\t// Skip the Slerp for tiny steps to avoid numeric problems:\n\t\t\tif ( sqrSin > Number.EPSILON ) {\n\n\t\t\t\tconst sin = Math.sqrt( sqrSin ),\n\t\t\t\t\tlen = Math.atan2( sin, cos * dir );\n\n\t\t\t\ts = Math.sin( s * len ) / sin;\n\t\t\t\tt = Math.sin( t * len ) / sin;\n\n\t\t\t}\n\n\t\t\tconst tDir = t * dir;\n\n\t\t\tx0 = x0 * s + x1 * tDir;\n\t\t\ty0 = y0 * s + y1 * tDir;\n\t\t\tz0 = z0 * s + z1 * tDir;\n\t\t\tw0 = w0 * s + w1 * tDir;\n\n\t\t\t// Normalize in case we just did a lerp:\n\t\t\tif ( s === 1 - t ) {\n\n\t\t\t\tconst f = 1 / Math.sqrt( x0 * x0 + y0 * y0 + z0 * z0 + w0 * w0 );\n\n\t\t\t\tx0 *= f;\n\t\t\t\ty0 *= f;\n\t\t\t\tz0 *= f;\n\t\t\t\tw0 *= f;\n\n\t\t\t}\n\n\t\t}\n\n\t\tdst[ dstOffset ] = x0;\n\t\tdst[ dstOffset + 1 ] = y0;\n\t\tdst[ dstOffset + 2 ] = z0;\n\t\tdst[ dstOffset + 3 ] = w0;\n\n\t}\n\n\tstatic multiplyQuaternionsFlat( dst, dstOffset, src0, srcOffset0, src1, srcOffset1 ) {\n\n\t\tconst x0 = src0[ srcOffset0 ];\n\t\tconst y0 = src0[ srcOffset0 + 1 ];\n\t\tconst z0 = src0[ srcOffset0 + 2 ];\n\t\tconst w0 = src0[ srcOffset0 + 3 ];\n\n\t\tconst x1 = src1[ srcOffset1 ];\n\t\tconst y1 = src1[ srcOffset1 + 1 ];\n\t\tconst z1 = src1[ srcOffset1 + 2 ];\n\t\tconst w1 = src1[ srcOffset1 + 3 ];\n\n\t\tdst[ dstOffset ] = x0 * w1 + w0 * x1 + y0 * z1 - z0 * y1;\n\t\tdst[ dstOffset + 1 ] = y0 * w1 + w0 * y1 + z0 * x1 - x0 * z1;\n\t\tdst[ dstOffset + 2 ] = z0 * w1 + w0 * z1 + x0 * y1 - y0 * x1;\n\t\tdst[ dstOffset + 3 ] = w0 * w1 - x0 * x1 - y0 * y1 - z0 * z1;\n\n\t\treturn dst;\n\n\t}\n\n\tget x() {\n\n\t\treturn this._x;\n\n\t}\n\n\tset x( value ) {\n\n\t\tthis._x = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tget y() {\n\n\t\treturn this._y;\n\n\t}\n\n\tset y( value ) {\n\n\t\tthis._y = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tget z() {\n\n\t\treturn this._z;\n\n\t}\n\n\tset z( value ) {\n\n\t\tthis._z = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tget w() {\n\n\t\treturn this._w;\n\n\t}\n\n\tset w( value ) {\n\n\t\tthis._w = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tset( x, y, z, w ) {\n\n\t\tthis._x = x;\n\t\tthis._y = y;\n\t\tthis._z = z;\n\t\tthis._w = w;\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this._x, this._y, this._z, this._w );\n\n\t}\n\n\tcopy( quaternion ) {\n\n\t\tthis._x = quaternion.x;\n\t\tthis._y = quaternion.y;\n\t\tthis._z = quaternion.z;\n\t\tthis._w = quaternion.w;\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tsetFromEuler( euler, update ) {\n\n\t\tif ( ! ( euler && euler.isEuler ) ) {\n\n\t\t\tthrow new Error( 'THREE.Quaternion: .setFromEuler() now expects an Euler rotation rather than a Vector3 and order.' );\n\n\t\t}\n\n\t\tconst x = euler._x, y = euler._y, z = euler._z, order = euler._order;\n\n\t\t// http://www.mathworks.com/matlabcentral/fileexchange/\n\t\t// \t20696-function-to-convert-between-dcm-euler-angles-quaternions-and-euler-vectors/\n\t\t//\tcontent/SpinCalc.m\n\n\t\tconst cos = Math.cos;\n\t\tconst sin = Math.sin;\n\n\t\tconst c1 = cos( x / 2 );\n\t\tconst c2 = cos( y / 2 );\n\t\tconst c3 = cos( z / 2 );\n\n\t\tconst s1 = sin( x / 2 );\n\t\tconst s2 = sin( y / 2 );\n\t\tconst s3 = sin( z / 2 );\n\n\t\tswitch ( order ) {\n\n\t\t\tcase 'XYZ':\n\t\t\t\tthis._x = s1 * c2 * c3 + c1 * s2 * s3;\n\t\t\t\tthis._y = c1 * s2 * c3 - s1 * c2 * s3;\n\t\t\t\tthis._z = c1 * c2 * s3 + s1 * s2 * c3;\n\t\t\t\tthis._w = c1 * c2 * c3 - s1 * s2 * s3;\n\t\t\t\tbreak;\n\n\t\t\tcase 'YXZ':\n\t\t\t\tthis._x = s1 * c2 * c3 + c1 * s2 * s3;\n\t\t\t\tthis._y = c1 * s2 * c3 - s1 * c2 * s3;\n\t\t\t\tthis._z = c1 * c2 * s3 - s1 * s2 * c3;\n\t\t\t\tthis._w = c1 * c2 * c3 + s1 * s2 * s3;\n\t\t\t\tbreak;\n\n\t\t\tcase 'ZXY':\n\t\t\t\tthis._x = s1 * c2 * c3 - c1 * s2 * s3;\n\t\t\t\tthis._y = c1 * s2 * c3 + s1 * c2 * s3;\n\t\t\t\tthis._z = c1 * c2 * s3 + s1 * s2 * c3;\n\t\t\t\tthis._w = c1 * c2 * c3 - s1 * s2 * s3;\n\t\t\t\tbreak;\n\n\t\t\tcase 'ZYX':\n\t\t\t\tthis._x = s1 * c2 * c3 - c1 * s2 * s3;\n\t\t\t\tthis._y = c1 * s2 * c3 + s1 * c2 * s3;\n\t\t\t\tthis._z = c1 * c2 * s3 - s1 * s2 * c3;\n\t\t\t\tthis._w = c1 * c2 * c3 + s1 * s2 * s3;\n\t\t\t\tbreak;\n\n\t\t\tcase 'YZX':\n\t\t\t\tthis._x = s1 * c2 * c3 + c1 * s2 * s3;\n\t\t\t\tthis._y = c1 * s2 * c3 + s1 * c2 * s3;\n\t\t\t\tthis._z = c1 * c2 * s3 - s1 * s2 * c3;\n\t\t\t\tthis._w = c1 * c2 * c3 - s1 * s2 * s3;\n\t\t\t\tbreak;\n\n\t\t\tcase 'XZY':\n\t\t\t\tthis._x = s1 * c2 * c3 - c1 * s2 * s3;\n\t\t\t\tthis._y = c1 * s2 * c3 - s1 * c2 * s3;\n\t\t\t\tthis._z = c1 * c2 * s3 + s1 * s2 * c3;\n\t\t\t\tthis._w = c1 * c2 * c3 + s1 * s2 * s3;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tconsole.warn( 'THREE.Quaternion: .setFromEuler() encountered an unknown order: ' + order );\n\n\t\t}\n\n\t\tif ( update !== false ) this._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tsetFromAxisAngle( axis, angle ) {\n\n\t\t// http://www.euclideanspace.com/maths/geometry/rotations/conversions/angleToQuaternion/index.htm\n\n\t\t// assumes axis is normalized\n\n\t\tconst halfAngle = angle / 2, s = Math.sin( halfAngle );\n\n\t\tthis._x = axis.x * s;\n\t\tthis._y = axis.y * s;\n\t\tthis._z = axis.z * s;\n\t\tthis._w = Math.cos( halfAngle );\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tsetFromRotationMatrix( m ) {\n\n\t\t// http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm\n\n\t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n\t\tconst te = m.elements,\n\n\t\t\tm11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ],\n\t\t\tm21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ],\n\t\t\tm31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ],\n\n\t\t\ttrace = m11 + m22 + m33;\n\n\t\tif ( trace > 0 ) {\n\n\t\t\tconst s = 0.5 / Math.sqrt( trace + 1.0 );\n\n\t\t\tthis._w = 0.25 / s;\n\t\t\tthis._x = ( m32 - m23 ) * s;\n\t\t\tthis._y = ( m13 - m31 ) * s;\n\t\t\tthis._z = ( m21 - m12 ) * s;\n\n\t\t} else if ( m11 > m22 && m11 > m33 ) {\n\n\t\t\tconst s = 2.0 * Math.sqrt( 1.0 + m11 - m22 - m33 );\n\n\t\t\tthis._w = ( m32 - m23 ) / s;\n\t\t\tthis._x = 0.25 * s;\n\t\t\tthis._y = ( m12 + m21 ) / s;\n\t\t\tthis._z = ( m13 + m31 ) / s;\n\n\t\t} else if ( m22 > m33 ) {\n\n\t\t\tconst s = 2.0 * Math.sqrt( 1.0 + m22 - m11 - m33 );\n\n\t\t\tthis._w = ( m13 - m31 ) / s;\n\t\t\tthis._x = ( m12 + m21 ) / s;\n\t\t\tthis._y = 0.25 * s;\n\t\t\tthis._z = ( m23 + m32 ) / s;\n\n\t\t} else {\n\n\t\t\tconst s = 2.0 * Math.sqrt( 1.0 + m33 - m11 - m22 );\n\n\t\t\tthis._w = ( m21 - m12 ) / s;\n\t\t\tthis._x = ( m13 + m31 ) / s;\n\t\t\tthis._y = ( m23 + m32 ) / s;\n\t\t\tthis._z = 0.25 * s;\n\n\t\t}\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tsetFromUnitVectors( vFrom, vTo ) {\n\n\t\t// assumes direction vectors vFrom and vTo are normalized\n\n\t\tlet r = vFrom.dot( vTo ) + 1;\n\n\t\tif ( r < Number.EPSILON ) {\n\n\t\t\t// vFrom and vTo point in opposite directions\n\n\t\t\tr = 0;\n\n\t\t\tif ( Math.abs( vFrom.x ) > Math.abs( vFrom.z ) ) {\n\n\t\t\t\tthis._x = - vFrom.y;\n\t\t\t\tthis._y = vFrom.x;\n\t\t\t\tthis._z = 0;\n\t\t\t\tthis._w = r;\n\n\t\t\t} else {\n\n\t\t\t\tthis._x = 0;\n\t\t\t\tthis._y = - vFrom.z;\n\t\t\t\tthis._z = vFrom.y;\n\t\t\t\tthis._w = r;\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\t// crossVectors( vFrom, vTo ); // inlined to avoid cyclic dependency on Vector3\n\n\t\t\tthis._x = vFrom.y * vTo.z - vFrom.z * vTo.y;\n\t\t\tthis._y = vFrom.z * vTo.x - vFrom.x * vTo.z;\n\t\t\tthis._z = vFrom.x * vTo.y - vFrom.y * vTo.x;\n\t\t\tthis._w = r;\n\n\t\t}\n\n\t\treturn this.normalize();\n\n\t}\n\n\tangleTo( q ) {\n\n\t\treturn 2 * Math.acos( Math.abs( clamp( this.dot( q ), - 1, 1 ) ) );\n\n\t}\n\n\trotateTowards( q, step ) {\n\n\t\tconst angle = this.angleTo( q );\n\n\t\tif ( angle === 0 ) return this;\n\n\t\tconst t = Math.min( 1, step / angle );\n\n\t\tthis.slerp( q, t );\n\n\t\treturn this;\n\n\t}\n\n\tidentity() {\n\n\t\treturn this.set( 0, 0, 0, 1 );\n\n\t}\n\n\tinvert() {\n\n\t\t// quaternion is assumed to have unit length\n\n\t\treturn this.conjugate();\n\n\t}\n\n\tconjugate() {\n\n\t\tthis._x *= - 1;\n\t\tthis._y *= - 1;\n\t\tthis._z *= - 1;\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tdot( v ) {\n\n\t\treturn this._x * v._x + this._y * v._y + this._z * v._z + this._w * v._w;\n\n\t}\n\n\tlengthSq() {\n\n\t\treturn this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w;\n\n\t}\n\n\tlength() {\n\n\t\treturn Math.sqrt( this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w );\n\n\t}\n\n\tnormalize() {\n\n\t\tlet l = this.length();\n\n\t\tif ( l === 0 ) {\n\n\t\t\tthis._x = 0;\n\t\t\tthis._y = 0;\n\t\t\tthis._z = 0;\n\t\t\tthis._w = 1;\n\n\t\t} else {\n\n\t\t\tl = 1 / l;\n\n\t\t\tthis._x = this._x * l;\n\t\t\tthis._y = this._y * l;\n\t\t\tthis._z = this._z * l;\n\t\t\tthis._w = this._w * l;\n\n\t\t}\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( q, p ) {\n\n\t\tif ( p !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Quaternion: .multiply() now only accepts one argument. Use .multiplyQuaternions( a, b ) instead.' );\n\t\t\treturn this.multiplyQuaternions( q, p );\n\n\t\t}\n\n\t\treturn this.multiplyQuaternions( this, q );\n\n\t}\n\n\tpremultiply( q ) {\n\n\t\treturn this.multiplyQuaternions( q, this );\n\n\t}\n\n\tmultiplyQuaternions( a, b ) {\n\n\t\t// from http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/code/index.htm\n\n\t\tconst qax = a._x, qay = a._y, qaz = a._z, qaw = a._w;\n\t\tconst qbx = b._x, qby = b._y, qbz = b._z, qbw = b._w;\n\n\t\tthis._x = qax * qbw + qaw * qbx + qay * qbz - qaz * qby;\n\t\tthis._y = qay * qbw + qaw * qby + qaz * qbx - qax * qbz;\n\t\tthis._z = qaz * qbw + qaw * qbz + qax * qby - qay * qbx;\n\t\tthis._w = qaw * qbw - qax * qbx - qay * qby - qaz * qbz;\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tslerp( qb, t ) {\n\n\t\tif ( t === 0 ) return this;\n\t\tif ( t === 1 ) return this.copy( qb );\n\n\t\tconst x = this._x, y = this._y, z = this._z, w = this._w;\n\n\t\t// http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/slerp/\n\n\t\tlet cosHalfTheta = w * qb._w + x * qb._x + y * qb._y + z * qb._z;\n\n\t\tif ( cosHalfTheta < 0 ) {\n\n\t\t\tthis._w = - qb._w;\n\t\t\tthis._x = - qb._x;\n\t\t\tthis._y = - qb._y;\n\t\t\tthis._z = - qb._z;\n\n\t\t\tcosHalfTheta = - cosHalfTheta;\n\n\t\t} else {\n\n\t\t\tthis.copy( qb );\n\n\t\t}\n\n\t\tif ( cosHalfTheta >= 1.0 ) {\n\n\t\t\tthis._w = w;\n\t\t\tthis._x = x;\n\t\t\tthis._y = y;\n\t\t\tthis._z = z;\n\n\t\t\treturn this;\n\n\t\t}\n\n\t\tconst sqrSinHalfTheta = 1.0 - cosHalfTheta * cosHalfTheta;\n\n\t\tif ( sqrSinHalfTheta <= Number.EPSILON ) {\n\n\t\t\tconst s = 1 - t;\n\t\t\tthis._w = s * w + t * this._w;\n\t\t\tthis._x = s * x + t * this._x;\n\t\t\tthis._y = s * y + t * this._y;\n\t\t\tthis._z = s * z + t * this._z;\n\n\t\t\tthis.normalize();\n\t\t\tthis._onChangeCallback();\n\n\t\t\treturn this;\n\n\t\t}\n\n\t\tconst sinHalfTheta = Math.sqrt( sqrSinHalfTheta );\n\t\tconst halfTheta = Math.atan2( sinHalfTheta, cosHalfTheta );\n\t\tconst ratioA = Math.sin( ( 1 - t ) * halfTheta ) / sinHalfTheta,\n\t\t\tratioB = Math.sin( t * halfTheta ) / sinHalfTheta;\n\n\t\tthis._w = ( w * ratioA + this._w * ratioB );\n\t\tthis._x = ( x * ratioA + this._x * ratioB );\n\t\tthis._y = ( y * ratioA + this._y * ratioB );\n\t\tthis._z = ( z * ratioA + this._z * ratioB );\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tslerpQuaternions( qa, qb, t ) {\n\n\t\treturn this.copy( qa ).slerp( qb, t );\n\n\t}\n\n\trandom() {\n\n\t\t// Derived from http://planning.cs.uiuc.edu/node198.html\n\t\t// Note, this source uses w, x, y, z ordering,\n\t\t// so we swap the order below.\n\n\t\tconst u1 = Math.random();\n\t\tconst sqrt1u1 = Math.sqrt( 1 - u1 );\n\t\tconst sqrtu1 = Math.sqrt( u1 );\n\n\t\tconst u2 = 2 * Math.PI * Math.random();\n\n\t\tconst u3 = 2 * Math.PI * Math.random();\n\n\t\treturn this.set(\n\t\t\tsqrt1u1 * Math.cos( u2 ),\n\t\t\tsqrtu1 * Math.sin( u3 ),\n\t\t\tsqrtu1 * Math.cos( u3 ),\n\t\t\tsqrt1u1 * Math.sin( u2 ),\n\t\t);\n\n\t}\n\n\tequals( quaternion ) {\n\n\t\treturn ( quaternion._x === this._x ) && ( quaternion._y === this._y ) && ( quaternion._z === this._z ) && ( quaternion._w === this._w );\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tthis._x = array[ offset ];\n\t\tthis._y = array[ offset + 1 ];\n\t\tthis._z = array[ offset + 2 ];\n\t\tthis._w = array[ offset + 3 ];\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tarray[ offset ] = this._x;\n\t\tarray[ offset + 1 ] = this._y;\n\t\tarray[ offset + 2 ] = this._z;\n\t\tarray[ offset + 3 ] = this._w;\n\n\t\treturn array;\n\n\t}\n\n\tfromBufferAttribute( attribute, index ) {\n\n\t\tthis._x = attribute.getX( index );\n\t\tthis._y = attribute.getY( index );\n\t\tthis._z = attribute.getZ( index );\n\t\tthis._w = attribute.getW( index );\n\n\t\treturn this;\n\n\t}\n\n\t_onChange( callback ) {\n\n\t\tthis._onChangeCallback = callback;\n\n\t\treturn this;\n\n\t}\n\n\t_onChangeCallback() {}\n\n}\n\nQuaternion.prototype.isQuaternion = true;\n\nclass Vector3 {\n\n\tconstructor( x = 0, y = 0, z = 0 ) {\n\n\t\tthis.x = x;\n\t\tthis.y = y;\n\t\tthis.z = z;\n\n\t}\n\n\tset( x, y, z ) {\n\n\t\tif ( z === undefined ) z = this.z; // sprite.scale.set(x,y)\n\n\t\tthis.x = x;\n\t\tthis.y = y;\n\t\tthis.z = z;\n\n\t\treturn this;\n\n\t}\n\n\tsetScalar( scalar ) {\n\n\t\tthis.x = scalar;\n\t\tthis.y = scalar;\n\t\tthis.z = scalar;\n\n\t\treturn this;\n\n\t}\n\n\tsetX( x ) {\n\n\t\tthis.x = x;\n\n\t\treturn this;\n\n\t}\n\n\tsetY( y ) {\n\n\t\tthis.y = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetZ( z ) {\n\n\t\tthis.z = z;\n\n\t\treturn this;\n\n\t}\n\n\tsetComponent( index, value ) {\n\n\t\tswitch ( index ) {\n\n\t\t\tcase 0: this.x = value; break;\n\t\t\tcase 1: this.y = value; break;\n\t\t\tcase 2: this.z = value; break;\n\t\t\tdefault: throw new Error( 'index is out of range: ' + index );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetComponent( index ) {\n\n\t\tswitch ( index ) {\n\n\t\t\tcase 0: return this.x;\n\t\t\tcase 1: return this.y;\n\t\t\tcase 2: return this.z;\n\t\t\tdefault: throw new Error( 'index is out of range: ' + index );\n\n\t\t}\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this.x, this.y, this.z );\n\n\t}\n\n\tcopy( v ) {\n\n\t\tthis.x = v.x;\n\t\tthis.y = v.y;\n\t\tthis.z = v.z;\n\n\t\treturn this;\n\n\t}\n\n\tadd( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector3: .add() now only accepts one argument. Use .addVectors( a, b ) instead.' );\n\t\t\treturn this.addVectors( v, w );\n\n\t\t}\n\n\t\tthis.x += v.x;\n\t\tthis.y += v.y;\n\t\tthis.z += v.z;\n\n\t\treturn this;\n\n\t}\n\n\taddScalar( s ) {\n\n\t\tthis.x += s;\n\t\tthis.y += s;\n\t\tthis.z += s;\n\n\t\treturn this;\n\n\t}\n\n\taddVectors( a, b ) {\n\n\t\tthis.x = a.x + b.x;\n\t\tthis.y = a.y + b.y;\n\t\tthis.z = a.z + b.z;\n\n\t\treturn this;\n\n\t}\n\n\taddScaledVector( v, s ) {\n\n\t\tthis.x += v.x * s;\n\t\tthis.y += v.y * s;\n\t\tthis.z += v.z * s;\n\n\t\treturn this;\n\n\t}\n\n\tsub( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector3: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.' );\n\t\t\treturn this.subVectors( v, w );\n\n\t\t}\n\n\t\tthis.x -= v.x;\n\t\tthis.y -= v.y;\n\t\tthis.z -= v.z;\n\n\t\treturn this;\n\n\t}\n\n\tsubScalar( s ) {\n\n\t\tthis.x -= s;\n\t\tthis.y -= s;\n\t\tthis.z -= s;\n\n\t\treturn this;\n\n\t}\n\n\tsubVectors( a, b ) {\n\n\t\tthis.x = a.x - b.x;\n\t\tthis.y = a.y - b.y;\n\t\tthis.z = a.z - b.z;\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector3: .multiply() now only accepts one argument. Use .multiplyVectors( a, b ) instead.' );\n\t\t\treturn this.multiplyVectors( v, w );\n\n\t\t}\n\n\t\tthis.x *= v.x;\n\t\tthis.y *= v.y;\n\t\tthis.z *= v.z;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyScalar( scalar ) {\n\n\t\tthis.x *= scalar;\n\t\tthis.y *= scalar;\n\t\tthis.z *= scalar;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyVectors( a, b ) {\n\n\t\tthis.x = a.x * b.x;\n\t\tthis.y = a.y * b.y;\n\t\tthis.z = a.z * b.z;\n\n\t\treturn this;\n\n\t}\n\n\tapplyEuler( euler ) {\n\n\t\tif ( ! ( euler && euler.isEuler ) ) {\n\n\t\t\tconsole.error( 'THREE.Vector3: .applyEuler() now expects an Euler rotation rather than a Vector3 and order.' );\n\n\t\t}\n\n\t\treturn this.applyQuaternion( _quaternion$4.setFromEuler( euler ) );\n\n\t}\n\n\tapplyAxisAngle( axis, angle ) {\n\n\t\treturn this.applyQuaternion( _quaternion$4.setFromAxisAngle( axis, angle ) );\n\n\t}\n\n\tapplyMatrix3( m ) {\n\n\t\tconst x = this.x, y = this.y, z = this.z;\n\t\tconst e = m.elements;\n\n\t\tthis.x = e[ 0 ] * x + e[ 3 ] * y + e[ 6 ] * z;\n\t\tthis.y = e[ 1 ] * x + e[ 4 ] * y + e[ 7 ] * z;\n\t\tthis.z = e[ 2 ] * x + e[ 5 ] * y + e[ 8 ] * z;\n\n\t\treturn this;\n\n\t}\n\n\tapplyNormalMatrix( m ) {\n\n\t\treturn this.applyMatrix3( m ).normalize();\n\n\t}\n\n\tapplyMatrix4( m ) {\n\n\t\tconst x = this.x, y = this.y, z = this.z;\n\t\tconst e = m.elements;\n\n\t\tconst w = 1 / ( e[ 3 ] * x + e[ 7 ] * y + e[ 11 ] * z + e[ 15 ] );\n\n\t\tthis.x = ( e[ 0 ] * x + e[ 4 ] * y + e[ 8 ] * z + e[ 12 ] ) * w;\n\t\tthis.y = ( e[ 1 ] * x + e[ 5 ] * y + e[ 9 ] * z + e[ 13 ] ) * w;\n\t\tthis.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * w;\n\n\t\treturn this;\n\n\t}\n\n\tapplyQuaternion( q ) {\n\n\t\tconst x = this.x, y = this.y, z = this.z;\n\t\tconst qx = q.x, qy = q.y, qz = q.z, qw = q.w;\n\n\t\t// calculate quat * vector\n\n\t\tconst ix = qw * x + qy * z - qz * y;\n\t\tconst iy = qw * y + qz * x - qx * z;\n\t\tconst iz = qw * z + qx * y - qy * x;\n\t\tconst iw = - qx * x - qy * y - qz * z;\n\n\t\t// calculate result * inverse quat\n\n\t\tthis.x = ix * qw + iw * - qx + iy * - qz - iz * - qy;\n\t\tthis.y = iy * qw + iw * - qy + iz * - qx - ix * - qz;\n\t\tthis.z = iz * qw + iw * - qz + ix * - qy - iy * - qx;\n\n\t\treturn this;\n\n\t}\n\n\tproject( camera ) {\n\n\t\treturn this.applyMatrix4( camera.matrixWorldInverse ).applyMatrix4( camera.projectionMatrix );\n\n\t}\n\n\tunproject( camera ) {\n\n\t\treturn this.applyMatrix4( camera.projectionMatrixInverse ).applyMatrix4( camera.matrixWorld );\n\n\t}\n\n\ttransformDirection( m ) {\n\n\t\t// input: THREE.Matrix4 affine matrix\n\t\t// vector interpreted as a direction\n\n\t\tconst x = this.x, y = this.y, z = this.z;\n\t\tconst e = m.elements;\n\n\t\tthis.x = e[ 0 ] * x + e[ 4 ] * y + e[ 8 ] * z;\n\t\tthis.y = e[ 1 ] * x + e[ 5 ] * y + e[ 9 ] * z;\n\t\tthis.z = e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z;\n\n\t\treturn this.normalize();\n\n\t}\n\n\tdivide( v ) {\n\n\t\tthis.x /= v.x;\n\t\tthis.y /= v.y;\n\t\tthis.z /= v.z;\n\n\t\treturn this;\n\n\t}\n\n\tdivideScalar( scalar ) {\n\n\t\treturn this.multiplyScalar( 1 / scalar );\n\n\t}\n\n\tmin( v ) {\n\n\t\tthis.x = Math.min( this.x, v.x );\n\t\tthis.y = Math.min( this.y, v.y );\n\t\tthis.z = Math.min( this.z, v.z );\n\n\t\treturn this;\n\n\t}\n\n\tmax( v ) {\n\n\t\tthis.x = Math.max( this.x, v.x );\n\t\tthis.y = Math.max( this.y, v.y );\n\t\tthis.z = Math.max( this.z, v.z );\n\n\t\treturn this;\n\n\t}\n\n\tclamp( min, max ) {\n\n\t\t// assumes min < max, componentwise\n\n\t\tthis.x = Math.max( min.x, Math.min( max.x, this.x ) );\n\t\tthis.y = Math.max( min.y, Math.min( max.y, this.y ) );\n\t\tthis.z = Math.max( min.z, Math.min( max.z, this.z ) );\n\n\t\treturn this;\n\n\t}\n\n\tclampScalar( minVal, maxVal ) {\n\n\t\tthis.x = Math.max( minVal, Math.min( maxVal, this.x ) );\n\t\tthis.y = Math.max( minVal, Math.min( maxVal, this.y ) );\n\t\tthis.z = Math.max( minVal, Math.min( maxVal, this.z ) );\n\n\t\treturn this;\n\n\t}\n\n\tclampLength( min, max ) {\n\n\t\tconst length = this.length();\n\n\t\treturn this.divideScalar( length || 1 ).multiplyScalar( Math.max( min, Math.min( max, length ) ) );\n\n\t}\n\n\tfloor() {\n\n\t\tthis.x = Math.floor( this.x );\n\t\tthis.y = Math.floor( this.y );\n\t\tthis.z = Math.floor( this.z );\n\n\t\treturn this;\n\n\t}\n\n\tceil() {\n\n\t\tthis.x = Math.ceil( this.x );\n\t\tthis.y = Math.ceil( this.y );\n\t\tthis.z = Math.ceil( this.z );\n\n\t\treturn this;\n\n\t}\n\n\tround() {\n\n\t\tthis.x = Math.round( this.x );\n\t\tthis.y = Math.round( this.y );\n\t\tthis.z = Math.round( this.z );\n\n\t\treturn this;\n\n\t}\n\n\troundToZero() {\n\n\t\tthis.x = ( this.x < 0 ) ? Math.ceil( this.x ) : Math.floor( this.x );\n\t\tthis.y = ( this.y < 0 ) ? Math.ceil( this.y ) : Math.floor( this.y );\n\t\tthis.z = ( this.z < 0 ) ? Math.ceil( this.z ) : Math.floor( this.z );\n\n\t\treturn this;\n\n\t}\n\n\tnegate() {\n\n\t\tthis.x = - this.x;\n\t\tthis.y = - this.y;\n\t\tthis.z = - this.z;\n\n\t\treturn this;\n\n\t}\n\n\tdot( v ) {\n\n\t\treturn this.x * v.x + this.y * v.y + this.z * v.z;\n\n\t}\n\n\t// TODO lengthSquared?\n\n\tlengthSq() {\n\n\t\treturn this.x * this.x + this.y * this.y + this.z * this.z;\n\n\t}\n\n\tlength() {\n\n\t\treturn Math.sqrt( this.x * this.x + this.y * this.y + this.z * this.z );\n\n\t}\n\n\tmanhattanLength() {\n\n\t\treturn Math.abs( this.x ) + Math.abs( this.y ) + Math.abs( this.z );\n\n\t}\n\n\tnormalize() {\n\n\t\treturn this.divideScalar( this.length() || 1 );\n\n\t}\n\n\tsetLength( length ) {\n\n\t\treturn this.normalize().multiplyScalar( length );\n\n\t}\n\n\tlerp( v, alpha ) {\n\n\t\tthis.x += ( v.x - this.x ) * alpha;\n\t\tthis.y += ( v.y - this.y ) * alpha;\n\t\tthis.z += ( v.z - this.z ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tlerpVectors( v1, v2, alpha ) {\n\n\t\tthis.x = v1.x + ( v2.x - v1.x ) * alpha;\n\t\tthis.y = v1.y + ( v2.y - v1.y ) * alpha;\n\t\tthis.z = v1.z + ( v2.z - v1.z ) * alpha;\n\n\t\treturn this;\n\n\t}\n\n\tcross( v, w ) {\n\n\t\tif ( w !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector3: .cross() now only accepts one argument. Use .crossVectors( a, b ) instead.' );\n\t\t\treturn this.crossVectors( v, w );\n\n\t\t}\n\n\t\treturn this.crossVectors( this, v );\n\n\t}\n\n\tcrossVectors( a, b ) {\n\n\t\tconst ax = a.x, ay = a.y, az = a.z;\n\t\tconst bx = b.x, by = b.y, bz = b.z;\n\n\t\tthis.x = ay * bz - az * by;\n\t\tthis.y = az * bx - ax * bz;\n\t\tthis.z = ax * by - ay * bx;\n\n\t\treturn this;\n\n\t}\n\n\tprojectOnVector( v ) {\n\n\t\tconst denominator = v.lengthSq();\n\n\t\tif ( denominator === 0 ) return this.set( 0, 0, 0 );\n\n\t\tconst scalar = v.dot( this ) / denominator;\n\n\t\treturn this.copy( v ).multiplyScalar( scalar );\n\n\t}\n\n\tprojectOnPlane( planeNormal ) {\n\n\t\t_vector$c.copy( this ).projectOnVector( planeNormal );\n\n\t\treturn this.sub( _vector$c );\n\n\t}\n\n\treflect( normal ) {\n\n\t\t// reflect incident vector off plane orthogonal to normal\n\t\t// normal is assumed to have unit length\n\n\t\treturn this.sub( _vector$c.copy( normal ).multiplyScalar( 2 * this.dot( normal ) ) );\n\n\t}\n\n\tangleTo( v ) {\n\n\t\tconst denominator = Math.sqrt( this.lengthSq() * v.lengthSq() );\n\n\t\tif ( denominator === 0 ) return Math.PI / 2;\n\n\t\tconst theta = this.dot( v ) / denominator;\n\n\t\t// clamp, to handle numerical problems\n\n\t\treturn Math.acos( clamp( theta, - 1, 1 ) );\n\n\t}\n\n\tdistanceTo( v ) {\n\n\t\treturn Math.sqrt( this.distanceToSquared( v ) );\n\n\t}\n\n\tdistanceToSquared( v ) {\n\n\t\tconst dx = this.x - v.x, dy = this.y - v.y, dz = this.z - v.z;\n\n\t\treturn dx * dx + dy * dy + dz * dz;\n\n\t}\n\n\tmanhattanDistanceTo( v ) {\n\n\t\treturn Math.abs( this.x - v.x ) + Math.abs( this.y - v.y ) + Math.abs( this.z - v.z );\n\n\t}\n\n\tsetFromSpherical( s ) {\n\n\t\treturn this.setFromSphericalCoords( s.radius, s.phi, s.theta );\n\n\t}\n\n\tsetFromSphericalCoords( radius, phi, theta ) {\n\n\t\tconst sinPhiRadius = Math.sin( phi ) * radius;\n\n\t\tthis.x = sinPhiRadius * Math.sin( theta );\n\t\tthis.y = Math.cos( phi ) * radius;\n\t\tthis.z = sinPhiRadius * Math.cos( theta );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromCylindrical( c ) {\n\n\t\treturn this.setFromCylindricalCoords( c.radius, c.theta, c.y );\n\n\t}\n\n\tsetFromCylindricalCoords( radius, theta, y ) {\n\n\t\tthis.x = radius * Math.sin( theta );\n\t\tthis.y = y;\n\t\tthis.z = radius * Math.cos( theta );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromMatrixPosition( m ) {\n\n\t\tconst e = m.elements;\n\n\t\tthis.x = e[ 12 ];\n\t\tthis.y = e[ 13 ];\n\t\tthis.z = e[ 14 ];\n\n\t\treturn this;\n\n\t}\n\n\tsetFromMatrixScale( m ) {\n\n\t\tconst sx = this.setFromMatrixColumn( m, 0 ).length();\n\t\tconst sy = this.setFromMatrixColumn( m, 1 ).length();\n\t\tconst sz = this.setFromMatrixColumn( m, 2 ).length();\n\n\t\tthis.x = sx;\n\t\tthis.y = sy;\n\t\tthis.z = sz;\n\n\t\treturn this;\n\n\t}\n\n\tsetFromMatrixColumn( m, index ) {\n\n\t\treturn this.fromArray( m.elements, index * 4 );\n\n\t}\n\n\tsetFromMatrix3Column( m, index ) {\n\n\t\treturn this.fromArray( m.elements, index * 3 );\n\n\t}\n\n\tsetFromEuler( e ) {\n\n\t\tthis.x = e._x;\n\t\tthis.y = e._y;\n\t\tthis.z = e._z;\n\n\t\treturn this;\n\n\t}\n\n\tequals( v ) {\n\n\t\treturn ( ( v.x === this.x ) && ( v.y === this.y ) && ( v.z === this.z ) );\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tthis.x = array[ offset ];\n\t\tthis.y = array[ offset + 1 ];\n\t\tthis.z = array[ offset + 2 ];\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tarray[ offset ] = this.x;\n\t\tarray[ offset + 1 ] = this.y;\n\t\tarray[ offset + 2 ] = this.z;\n\n\t\treturn array;\n\n\t}\n\n\tfromBufferAttribute( attribute, index, offset ) {\n\n\t\tif ( offset !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Vector3: offset has been removed from .fromBufferAttribute().' );\n\n\t\t}\n\n\t\tthis.x = attribute.getX( index );\n\t\tthis.y = attribute.getY( index );\n\t\tthis.z = attribute.getZ( index );\n\n\t\treturn this;\n\n\t}\n\n\trandom() {\n\n\t\tthis.x = Math.random();\n\t\tthis.y = Math.random();\n\t\tthis.z = Math.random();\n\n\t\treturn this;\n\n\t}\n\n\trandomDirection() {\n\n\t\t// Derived from https://mathworld.wolfram.com/SpherePointPicking.html\n\n\t\tconst u = ( Math.random() - 0.5 ) * 2;\n\t\tconst t = Math.random() * Math.PI * 2;\n\t\tconst f = Math.sqrt( 1 - u ** 2 );\n\n\t\tthis.x = f * Math.cos( t );\n\t\tthis.y = f * Math.sin( t );\n\t\tthis.z = u;\n\n\t\treturn this;\n\n\t}\n\n\t*[ Symbol.iterator ]() {\n\n\t\tyield this.x;\n\t\tyield this.y;\n\t\tyield this.z;\n\n\t}\n\n}\n\nVector3.prototype.isVector3 = true;\n\nconst _vector$c = /*@__PURE__*/ new Vector3();\nconst _quaternion$4 = /*@__PURE__*/ new Quaternion();\n\nclass Box3 {\n\n\tconstructor( min = new Vector3( + Infinity, + Infinity, + Infinity ), max = new Vector3( - Infinity, - Infinity, - Infinity ) ) {\n\n\t\tthis.min = min;\n\t\tthis.max = max;\n\n\t}\n\n\tset( min, max ) {\n\n\t\tthis.min.copy( min );\n\t\tthis.max.copy( max );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromArray( array ) {\n\n\t\tlet minX = + Infinity;\n\t\tlet minY = + Infinity;\n\t\tlet minZ = + Infinity;\n\n\t\tlet maxX = - Infinity;\n\t\tlet maxY = - Infinity;\n\t\tlet maxZ = - Infinity;\n\n\t\tfor ( let i = 0, l = array.length; i < l; i += 3 ) {\n\n\t\t\tconst x = array[ i ];\n\t\t\tconst y = array[ i + 1 ];\n\t\t\tconst z = array[ i + 2 ];\n\n\t\t\tif ( x < minX ) minX = x;\n\t\t\tif ( y < minY ) minY = y;\n\t\t\tif ( z < minZ ) minZ = z;\n\n\t\t\tif ( x > maxX ) maxX = x;\n\t\t\tif ( y > maxY ) maxY = y;\n\t\t\tif ( z > maxZ ) maxZ = z;\n\n\t\t}\n\n\t\tthis.min.set( minX, minY, minZ );\n\t\tthis.max.set( maxX, maxY, maxZ );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromBufferAttribute( attribute ) {\n\n\t\tlet minX = + Infinity;\n\t\tlet minY = + Infinity;\n\t\tlet minZ = + Infinity;\n\n\t\tlet maxX = - Infinity;\n\t\tlet maxY = - Infinity;\n\t\tlet maxZ = - Infinity;\n\n\t\tfor ( let i = 0, l = attribute.count; i < l; i ++ ) {\n\n\t\t\tconst x = attribute.getX( i );\n\t\t\tconst y = attribute.getY( i );\n\t\t\tconst z = attribute.getZ( i );\n\n\t\t\tif ( x < minX ) minX = x;\n\t\t\tif ( y < minY ) minY = y;\n\t\t\tif ( z < minZ ) minZ = z;\n\n\t\t\tif ( x > maxX ) maxX = x;\n\t\t\tif ( y > maxY ) maxY = y;\n\t\t\tif ( z > maxZ ) maxZ = z;\n\n\t\t}\n\n\t\tthis.min.set( minX, minY, minZ );\n\t\tthis.max.set( maxX, maxY, maxZ );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromPoints( points ) {\n\n\t\tthis.makeEmpty();\n\n\t\tfor ( let i = 0, il = points.length; i < il; i ++ ) {\n\n\t\t\tthis.expandByPoint( points[ i ] );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetFromCenterAndSize( center, size ) {\n\n\t\tconst halfSize = _vector$b.copy( size ).multiplyScalar( 0.5 );\n\n\t\tthis.min.copy( center ).sub( halfSize );\n\t\tthis.max.copy( center ).add( halfSize );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromObject( object, precise = false ) {\n\n\t\tthis.makeEmpty();\n\n\t\treturn this.expandByObject( object, precise );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( box ) {\n\n\t\tthis.min.copy( box.min );\n\t\tthis.max.copy( box.max );\n\n\t\treturn this;\n\n\t}\n\n\tmakeEmpty() {\n\n\t\tthis.min.x = this.min.y = this.min.z = + Infinity;\n\t\tthis.max.x = this.max.y = this.max.z = - Infinity;\n\n\t\treturn this;\n\n\t}\n\n\tisEmpty() {\n\n\t\t// this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes\n\n\t\treturn ( this.max.x < this.min.x ) || ( this.max.y < this.min.y ) || ( this.max.z < this.min.z );\n\n\t}\n\n\tgetCenter( target ) {\n\n\t\treturn this.isEmpty() ? target.set( 0, 0, 0 ) : target.addVectors( this.min, this.max ).multiplyScalar( 0.5 );\n\n\t}\n\n\tgetSize( target ) {\n\n\t\treturn this.isEmpty() ? target.set( 0, 0, 0 ) : target.subVectors( this.max, this.min );\n\n\t}\n\n\texpandByPoint( point ) {\n\n\t\tthis.min.min( point );\n\t\tthis.max.max( point );\n\n\t\treturn this;\n\n\t}\n\n\texpandByVector( vector ) {\n\n\t\tthis.min.sub( vector );\n\t\tthis.max.add( vector );\n\n\t\treturn this;\n\n\t}\n\n\texpandByScalar( scalar ) {\n\n\t\tthis.min.addScalar( - scalar );\n\t\tthis.max.addScalar( scalar );\n\n\t\treturn this;\n\n\t}\n\n\texpandByObject( object, precise = false ) {\n\n\t\t// Computes the world-axis-aligned bounding box of an object (including its children),\n\t\t// accounting for both the object's, and children's, world transforms\n\n\t\tobject.updateWorldMatrix( false, false );\n\n\t\tconst geometry = object.geometry;\n\n\t\tif ( geometry !== undefined ) {\n\n\t\t\tif ( precise && geometry.attributes != undefined && geometry.attributes.position !== undefined ) {\n\n\t\t\t\tconst position = geometry.attributes.position;\n\t\t\t\tfor ( let i = 0, l = position.count; i < l; i ++ ) {\n\n\t\t\t\t\t_vector$b.fromBufferAttribute( position, i ).applyMatrix4( object.matrixWorld );\n\t\t\t\t\tthis.expandByPoint( _vector$b );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tif ( geometry.boundingBox === null ) {\n\n\t\t\t\t\tgeometry.computeBoundingBox();\n\n\t\t\t\t}\n\n\t\t\t\t_box$3.copy( geometry.boundingBox );\n\t\t\t\t_box$3.applyMatrix4( object.matrixWorld );\n\n\t\t\t\tthis.union( _box$3 );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst children = object.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\tthis.expandByObject( children[ i ], precise );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tcontainsPoint( point ) {\n\n\t\treturn point.x < this.min.x || point.x > this.max.x ||\n\t\t\tpoint.y < this.min.y || point.y > this.max.y ||\n\t\t\tpoint.z < this.min.z || point.z > this.max.z ? false : true;\n\n\t}\n\n\tcontainsBox( box ) {\n\n\t\treturn this.min.x <= box.min.x && box.max.x <= this.max.x &&\n\t\t\tthis.min.y <= box.min.y && box.max.y <= this.max.y &&\n\t\t\tthis.min.z <= box.min.z && box.max.z <= this.max.z;\n\n\t}\n\n\tgetParameter( point, target ) {\n\n\t\t// This can potentially have a divide by zero if the box\n\t\t// has a size dimension of 0.\n\n\t\treturn target.set(\n\t\t\t( point.x - this.min.x ) / ( this.max.x - this.min.x ),\n\t\t\t( point.y - this.min.y ) / ( this.max.y - this.min.y ),\n\t\t\t( point.z - this.min.z ) / ( this.max.z - this.min.z )\n\t\t);\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\t// using 6 splitting planes to rule out intersections.\n\t\treturn box.max.x < this.min.x || box.min.x > this.max.x ||\n\t\t\tbox.max.y < this.min.y || box.min.y > this.max.y ||\n\t\t\tbox.max.z < this.min.z || box.min.z > this.max.z ? false : true;\n\n\t}\n\n\tintersectsSphere( sphere ) {\n\n\t\t// Find the point on the AABB closest to the sphere center.\n\t\tthis.clampPoint( sphere.center, _vector$b );\n\n\t\t// If that point is inside the sphere, the AABB and sphere intersect.\n\t\treturn _vector$b.distanceToSquared( sphere.center ) <= ( sphere.radius * sphere.radius );\n\n\t}\n\n\tintersectsPlane( plane ) {\n\n\t\t// We compute the minimum and maximum dot product values. If those values\n\t\t// are on the same side (back or front) of the plane, then there is no intersection.\n\n\t\tlet min, max;\n\n\t\tif ( plane.normal.x > 0 ) {\n\n\t\t\tmin = plane.normal.x * this.min.x;\n\t\t\tmax = plane.normal.x * this.max.x;\n\n\t\t} else {\n\n\t\t\tmin = plane.normal.x * this.max.x;\n\t\t\tmax = plane.normal.x * this.min.x;\n\n\t\t}\n\n\t\tif ( plane.normal.y > 0 ) {\n\n\t\t\tmin += plane.normal.y * this.min.y;\n\t\t\tmax += plane.normal.y * this.max.y;\n\n\t\t} else {\n\n\t\t\tmin += plane.normal.y * this.max.y;\n\t\t\tmax += plane.normal.y * this.min.y;\n\n\t\t}\n\n\t\tif ( plane.normal.z > 0 ) {\n\n\t\t\tmin += plane.normal.z * this.min.z;\n\t\t\tmax += plane.normal.z * this.max.z;\n\n\t\t} else {\n\n\t\t\tmin += plane.normal.z * this.max.z;\n\t\t\tmax += plane.normal.z * this.min.z;\n\n\t\t}\n\n\t\treturn ( min <= - plane.constant && max >= - plane.constant );\n\n\t}\n\n\tintersectsTriangle( triangle ) {\n\n\t\tif ( this.isEmpty() ) {\n\n\t\t\treturn false;\n\n\t\t}\n\n\t\t// compute box center and extents\n\t\tthis.getCenter( _center );\n\t\t_extents.subVectors( this.max, _center );\n\n\t\t// translate triangle to aabb origin\n\t\t_v0$2.subVectors( triangle.a, _center );\n\t\t_v1$7.subVectors( triangle.b, _center );\n\t\t_v2$3.subVectors( triangle.c, _center );\n\n\t\t// compute edge vectors for triangle\n\t\t_f0.subVectors( _v1$7, _v0$2 );\n\t\t_f1.subVectors( _v2$3, _v1$7 );\n\t\t_f2.subVectors( _v0$2, _v2$3 );\n\n\t\t// test against axes that are given by cross product combinations of the edges of the triangle and the edges of the aabb\n\t\t// make an axis testing of each of the 3 sides of the aabb against each of the 3 sides of the triangle = 9 axis of separation\n\t\t// axis_ij = u_i x f_j (u0, u1, u2 = face normals of aabb = x,y,z axes vectors since aabb is axis aligned)\n\t\tlet axes = [\n\t\t\t0, - _f0.z, _f0.y, 0, - _f1.z, _f1.y, 0, - _f2.z, _f2.y,\n\t\t\t_f0.z, 0, - _f0.x, _f1.z, 0, - _f1.x, _f2.z, 0, - _f2.x,\n\t\t\t- _f0.y, _f0.x, 0, - _f1.y, _f1.x, 0, - _f2.y, _f2.x, 0\n\t\t];\n\t\tif ( ! satForAxes( axes, _v0$2, _v1$7, _v2$3, _extents ) ) {\n\n\t\t\treturn false;\n\n\t\t}\n\n\t\t// test 3 face normals from the aabb\n\t\taxes = [ 1, 0, 0, 0, 1, 0, 0, 0, 1 ];\n\t\tif ( ! satForAxes( axes, _v0$2, _v1$7, _v2$3, _extents ) ) {\n\n\t\t\treturn false;\n\n\t\t}\n\n\t\t// finally testing the face normal of the triangle\n\t\t// use already existing triangle edge vectors here\n\t\t_triangleNormal.crossVectors( _f0, _f1 );\n\t\taxes = [ _triangleNormal.x, _triangleNormal.y, _triangleNormal.z ];\n\n\t\treturn satForAxes( axes, _v0$2, _v1$7, _v2$3, _extents );\n\n\t}\n\n\tclampPoint( point, target ) {\n\n\t\treturn target.copy( point ).clamp( this.min, this.max );\n\n\t}\n\n\tdistanceToPoint( point ) {\n\n\t\tconst clampedPoint = _vector$b.copy( point ).clamp( this.min, this.max );\n\n\t\treturn clampedPoint.sub( point ).length();\n\n\t}\n\n\tgetBoundingSphere( target ) {\n\n\t\tthis.getCenter( target.center );\n\n\t\ttarget.radius = this.getSize( _vector$b ).length() * 0.5;\n\n\t\treturn target;\n\n\t}\n\n\tintersect( box ) {\n\n\t\tthis.min.max( box.min );\n\t\tthis.max.min( box.max );\n\n\t\t// ensure that if there is no overlap, the result is fully empty, not slightly empty with non-inf/+inf values that will cause subsequence intersects to erroneously return valid values.\n\t\tif ( this.isEmpty() ) this.makeEmpty();\n\n\t\treturn this;\n\n\t}\n\n\tunion( box ) {\n\n\t\tthis.min.min( box.min );\n\t\tthis.max.max( box.max );\n\n\t\treturn this;\n\n\t}\n\n\tapplyMatrix4( matrix ) {\n\n\t\t// transform of empty box is an empty box.\n\t\tif ( this.isEmpty() ) return this;\n\n\t\t// NOTE: I am using a binary pattern to specify all 2^3 combinations below\n\t\t_points[ 0 ].set( this.min.x, this.min.y, this.min.z ).applyMatrix4( matrix ); // 000\n\t\t_points[ 1 ].set( this.min.x, this.min.y, this.max.z ).applyMatrix4( matrix ); // 001\n\t\t_points[ 2 ].set( this.min.x, this.max.y, this.min.z ).applyMatrix4( matrix ); // 010\n\t\t_points[ 3 ].set( this.min.x, this.max.y, this.max.z ).applyMatrix4( matrix ); // 011\n\t\t_points[ 4 ].set( this.max.x, this.min.y, this.min.z ).applyMatrix4( matrix ); // 100\n\t\t_points[ 5 ].set( this.max.x, this.min.y, this.max.z ).applyMatrix4( matrix ); // 101\n\t\t_points[ 6 ].set( this.max.x, this.max.y, this.min.z ).applyMatrix4( matrix ); // 110\n\t\t_points[ 7 ].set( this.max.x, this.max.y, this.max.z ).applyMatrix4( matrix ); // 111\n\n\t\tthis.setFromPoints( _points );\n\n\t\treturn this;\n\n\t}\n\n\ttranslate( offset ) {\n\n\t\tthis.min.add( offset );\n\t\tthis.max.add( offset );\n\n\t\treturn this;\n\n\t}\n\n\tequals( box ) {\n\n\t\treturn box.min.equals( this.min ) && box.max.equals( this.max );\n\n\t}\n\n}\n\nBox3.prototype.isBox3 = true;\n\nconst _points = [\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3(),\n\t/*@__PURE__*/ new Vector3()\n];\n\nconst _vector$b = /*@__PURE__*/ new Vector3();\n\nconst _box$3 = /*@__PURE__*/ new Box3();\n\n// triangle centered vertices\n\nconst _v0$2 = /*@__PURE__*/ new Vector3();\nconst _v1$7 = /*@__PURE__*/ new Vector3();\nconst _v2$3 = /*@__PURE__*/ new Vector3();\n\n// triangle edge vectors\n\nconst _f0 = /*@__PURE__*/ new Vector3();\nconst _f1 = /*@__PURE__*/ new Vector3();\nconst _f2 = /*@__PURE__*/ new Vector3();\n\nconst _center = /*@__PURE__*/ new Vector3();\nconst _extents = /*@__PURE__*/ new Vector3();\nconst _triangleNormal = /*@__PURE__*/ new Vector3();\nconst _testAxis = /*@__PURE__*/ new Vector3();\n\nfunction satForAxes( axes, v0, v1, v2, extents ) {\n\n\tfor ( let i = 0, j = axes.length - 3; i <= j; i += 3 ) {\n\n\t\t_testAxis.fromArray( axes, i );\n\t\t// project the aabb onto the seperating axis\n\t\tconst r = extents.x * Math.abs( _testAxis.x ) + extents.y * Math.abs( _testAxis.y ) + extents.z * Math.abs( _testAxis.z );\n\t\t// project all 3 vertices of the triangle onto the seperating axis\n\t\tconst p0 = v0.dot( _testAxis );\n\t\tconst p1 = v1.dot( _testAxis );\n\t\tconst p2 = v2.dot( _testAxis );\n\t\t// actual test, basically see if either of the most extreme of the triangle points intersects r\n\t\tif ( Math.max( - Math.max( p0, p1, p2 ), Math.min( p0, p1, p2 ) ) > r ) {\n\n\t\t\t// points of the projected triangle are outside the projected half-length of the aabb\n\t\t\t// the axis is seperating and we can exit\n\t\t\treturn false;\n\n\t\t}\n\n\t}\n\n\treturn true;\n\n}\n\nconst _box$2 = /*@__PURE__*/ new Box3();\nconst _v1$6 = /*@__PURE__*/ new Vector3();\nconst _toFarthestPoint = /*@__PURE__*/ new Vector3();\nconst _toPoint = /*@__PURE__*/ new Vector3();\n\nclass Sphere {\n\n\tconstructor( center = new Vector3(), radius = - 1 ) {\n\n\t\tthis.center = center;\n\t\tthis.radius = radius;\n\n\t}\n\n\tset( center, radius ) {\n\n\t\tthis.center.copy( center );\n\t\tthis.radius = radius;\n\n\t\treturn this;\n\n\t}\n\n\tsetFromPoints( points, optionalCenter ) {\n\n\t\tconst center = this.center;\n\n\t\tif ( optionalCenter !== undefined ) {\n\n\t\t\tcenter.copy( optionalCenter );\n\n\t\t} else {\n\n\t\t\t_box$2.setFromPoints( points ).getCenter( center );\n\n\t\t}\n\n\t\tlet maxRadiusSq = 0;\n\n\t\tfor ( let i = 0, il = points.length; i < il; i ++ ) {\n\n\t\t\tmaxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( points[ i ] ) );\n\n\t\t}\n\n\t\tthis.radius = Math.sqrt( maxRadiusSq );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( sphere ) {\n\n\t\tthis.center.copy( sphere.center );\n\t\tthis.radius = sphere.radius;\n\n\t\treturn this;\n\n\t}\n\n\tisEmpty() {\n\n\t\treturn ( this.radius < 0 );\n\n\t}\n\n\tmakeEmpty() {\n\n\t\tthis.center.set( 0, 0, 0 );\n\t\tthis.radius = - 1;\n\n\t\treturn this;\n\n\t}\n\n\tcontainsPoint( point ) {\n\n\t\treturn ( point.distanceToSquared( this.center ) <= ( this.radius * this.radius ) );\n\n\t}\n\n\tdistanceToPoint( point ) {\n\n\t\treturn ( point.distanceTo( this.center ) - this.radius );\n\n\t}\n\n\tintersectsSphere( sphere ) {\n\n\t\tconst radiusSum = this.radius + sphere.radius;\n\n\t\treturn sphere.center.distanceToSquared( this.center ) <= ( radiusSum * radiusSum );\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\treturn box.intersectsSphere( this );\n\n\t}\n\n\tintersectsPlane( plane ) {\n\n\t\treturn Math.abs( plane.distanceToPoint( this.center ) ) <= this.radius;\n\n\t}\n\n\tclampPoint( point, target ) {\n\n\t\tconst deltaLengthSq = this.center.distanceToSquared( point );\n\n\t\ttarget.copy( point );\n\n\t\tif ( deltaLengthSq > ( this.radius * this.radius ) ) {\n\n\t\t\ttarget.sub( this.center ).normalize();\n\t\t\ttarget.multiplyScalar( this.radius ).add( this.center );\n\n\t\t}\n\n\t\treturn target;\n\n\t}\n\n\tgetBoundingBox( target ) {\n\n\t\tif ( this.isEmpty() ) {\n\n\t\t\t// Empty sphere produces empty bounding box\n\t\t\ttarget.makeEmpty();\n\t\t\treturn target;\n\n\t\t}\n\n\t\ttarget.set( this.center, this.center );\n\t\ttarget.expandByScalar( this.radius );\n\n\t\treturn target;\n\n\t}\n\n\tapplyMatrix4( matrix ) {\n\n\t\tthis.center.applyMatrix4( matrix );\n\t\tthis.radius = this.radius * matrix.getMaxScaleOnAxis();\n\n\t\treturn this;\n\n\t}\n\n\ttranslate( offset ) {\n\n\t\tthis.center.add( offset );\n\n\t\treturn this;\n\n\t}\n\n\texpandByPoint( point ) {\n\n\t\t// from https://github.com/juj/MathGeoLib/blob/2940b99b99cfe575dd45103ef20f4019dee15b54/src/Geometry/Sphere.cpp#L649-L671\n\n\t\t_toPoint.subVectors( point, this.center );\n\n\t\tconst lengthSq = _toPoint.lengthSq();\n\n\t\tif ( lengthSq > ( this.radius * this.radius ) ) {\n\n\t\t\tconst length = Math.sqrt( lengthSq );\n\t\t\tconst missingRadiusHalf = ( length - this.radius ) * 0.5;\n\n\t\t\t// Nudge this sphere towards the target point. Add half the missing distance to radius,\n\t\t\t// and the other half to position. This gives a tighter enclosure, instead of if\n\t\t\t// the whole missing distance were just added to radius.\n\n\t\t\tthis.center.add( _toPoint.multiplyScalar( missingRadiusHalf / length ) );\n\t\t\tthis.radius += missingRadiusHalf;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tunion( sphere ) {\n\n\t\t// from https://github.com/juj/MathGeoLib/blob/2940b99b99cfe575dd45103ef20f4019dee15b54/src/Geometry/Sphere.cpp#L759-L769\n\n\t\t// To enclose another sphere into this sphere, we only need to enclose two points:\n\t\t// 1) Enclose the farthest point on the other sphere into this sphere.\n\t\t// 2) Enclose the opposite point of the farthest point into this sphere.\n\n\t\t if ( this.center.equals( sphere.center ) === true ) {\n\n\t\t\t _toFarthestPoint.set( 0, 0, 1 ).multiplyScalar( sphere.radius );\n\n\n\t\t} else {\n\n\t\t\t_toFarthestPoint.subVectors( sphere.center, this.center ).normalize().multiplyScalar( sphere.radius );\n\n\t\t}\n\n\t\tthis.expandByPoint( _v1$6.copy( sphere.center ).add( _toFarthestPoint ) );\n\t\tthis.expandByPoint( _v1$6.copy( sphere.center ).sub( _toFarthestPoint ) );\n\n\t\treturn this;\n\n\t}\n\n\tequals( sphere ) {\n\n\t\treturn sphere.center.equals( this.center ) && ( sphere.radius === this.radius );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nconst _vector$a = /*@__PURE__*/ new Vector3();\nconst _segCenter = /*@__PURE__*/ new Vector3();\nconst _segDir = /*@__PURE__*/ new Vector3();\nconst _diff = /*@__PURE__*/ new Vector3();\n\nconst _edge1 = /*@__PURE__*/ new Vector3();\nconst _edge2 = /*@__PURE__*/ new Vector3();\nconst _normal$1 = /*@__PURE__*/ new Vector3();\n\nclass Ray {\n\n\tconstructor( origin = new Vector3(), direction = new Vector3( 0, 0, - 1 ) ) {\n\n\t\tthis.origin = origin;\n\t\tthis.direction = direction;\n\n\t}\n\n\tset( origin, direction ) {\n\n\t\tthis.origin.copy( origin );\n\t\tthis.direction.copy( direction );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( ray ) {\n\n\t\tthis.origin.copy( ray.origin );\n\t\tthis.direction.copy( ray.direction );\n\n\t\treturn this;\n\n\t}\n\n\tat( t, target ) {\n\n\t\treturn target.copy( this.direction ).multiplyScalar( t ).add( this.origin );\n\n\t}\n\n\tlookAt( v ) {\n\n\t\tthis.direction.copy( v ).sub( this.origin ).normalize();\n\n\t\treturn this;\n\n\t}\n\n\trecast( t ) {\n\n\t\tthis.origin.copy( this.at( t, _vector$a ) );\n\n\t\treturn this;\n\n\t}\n\n\tclosestPointToPoint( point, target ) {\n\n\t\ttarget.subVectors( point, this.origin );\n\n\t\tconst directionDistance = target.dot( this.direction );\n\n\t\tif ( directionDistance < 0 ) {\n\n\t\t\treturn target.copy( this.origin );\n\n\t\t}\n\n\t\treturn target.copy( this.direction ).multiplyScalar( directionDistance ).add( this.origin );\n\n\t}\n\n\tdistanceToPoint( point ) {\n\n\t\treturn Math.sqrt( this.distanceSqToPoint( point ) );\n\n\t}\n\n\tdistanceSqToPoint( point ) {\n\n\t\tconst directionDistance = _vector$a.subVectors( point, this.origin ).dot( this.direction );\n\n\t\t// point behind the ray\n\n\t\tif ( directionDistance < 0 ) {\n\n\t\t\treturn this.origin.distanceToSquared( point );\n\n\t\t}\n\n\t\t_vector$a.copy( this.direction ).multiplyScalar( directionDistance ).add( this.origin );\n\n\t\treturn _vector$a.distanceToSquared( point );\n\n\t}\n\n\tdistanceSqToSegment( v0, v1, optionalPointOnRay, optionalPointOnSegment ) {\n\n\t\t// from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteDistRaySegment.h\n\t\t// It returns the min distance between the ray and the segment\n\t\t// defined by v0 and v1\n\t\t// It can also set two optional targets :\n\t\t// - The closest point on the ray\n\t\t// - The closest point on the segment\n\n\t\t_segCenter.copy( v0 ).add( v1 ).multiplyScalar( 0.5 );\n\t\t_segDir.copy( v1 ).sub( v0 ).normalize();\n\t\t_diff.copy( this.origin ).sub( _segCenter );\n\n\t\tconst segExtent = v0.distanceTo( v1 ) * 0.5;\n\t\tconst a01 = - this.direction.dot( _segDir );\n\t\tconst b0 = _diff.dot( this.direction );\n\t\tconst b1 = - _diff.dot( _segDir );\n\t\tconst c = _diff.lengthSq();\n\t\tconst det = Math.abs( 1 - a01 * a01 );\n\t\tlet s0, s1, sqrDist, extDet;\n\n\t\tif ( det > 0 ) {\n\n\t\t\t// The ray and segment are not parallel.\n\n\t\t\ts0 = a01 * b1 - b0;\n\t\t\ts1 = a01 * b0 - b1;\n\t\t\textDet = segExtent * det;\n\n\t\t\tif ( s0 >= 0 ) {\n\n\t\t\t\tif ( s1 >= - extDet ) {\n\n\t\t\t\t\tif ( s1 <= extDet ) {\n\n\t\t\t\t\t\t// region 0\n\t\t\t\t\t\t// Minimum at interior points of ray and segment.\n\n\t\t\t\t\t\tconst invDet = 1 / det;\n\t\t\t\t\t\ts0 *= invDet;\n\t\t\t\t\t\ts1 *= invDet;\n\t\t\t\t\t\tsqrDist = s0 * ( s0 + a01 * s1 + 2 * b0 ) + s1 * ( a01 * s0 + s1 + 2 * b1 ) + c;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t// region 1\n\n\t\t\t\t\t\ts1 = segExtent;\n\t\t\t\t\t\ts0 = Math.max( 0, - ( a01 * s1 + b0 ) );\n\t\t\t\t\t\tsqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// region 5\n\n\t\t\t\t\ts1 = - segExtent;\n\t\t\t\t\ts0 = Math.max( 0, - ( a01 * s1 + b0 ) );\n\t\t\t\t\tsqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tif ( s1 <= - extDet ) {\n\n\t\t\t\t\t// region 4\n\n\t\t\t\t\ts0 = Math.max( 0, - ( - a01 * segExtent + b0 ) );\n\t\t\t\t\ts1 = ( s0 > 0 ) ? - segExtent : Math.min( Math.max( - segExtent, - b1 ), segExtent );\n\t\t\t\t\tsqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;\n\n\t\t\t\t} else if ( s1 <= extDet ) {\n\n\t\t\t\t\t// region 3\n\n\t\t\t\t\ts0 = 0;\n\t\t\t\t\ts1 = Math.min( Math.max( - segExtent, - b1 ), segExtent );\n\t\t\t\t\tsqrDist = s1 * ( s1 + 2 * b1 ) + c;\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// region 2\n\n\t\t\t\t\ts0 = Math.max( 0, - ( a01 * segExtent + b0 ) );\n\t\t\t\t\ts1 = ( s0 > 0 ) ? segExtent : Math.min( Math.max( - segExtent, - b1 ), segExtent );\n\t\t\t\t\tsqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\t// Ray and segment are parallel.\n\n\t\t\ts1 = ( a01 > 0 ) ? - segExtent : segExtent;\n\t\t\ts0 = Math.max( 0, - ( a01 * s1 + b0 ) );\n\t\t\tsqrDist = - s0 * s0 + s1 * ( s1 + 2 * b1 ) + c;\n\n\t\t}\n\n\t\tif ( optionalPointOnRay ) {\n\n\t\t\toptionalPointOnRay.copy( this.direction ).multiplyScalar( s0 ).add( this.origin );\n\n\t\t}\n\n\t\tif ( optionalPointOnSegment ) {\n\n\t\t\toptionalPointOnSegment.copy( _segDir ).multiplyScalar( s1 ).add( _segCenter );\n\n\t\t}\n\n\t\treturn sqrDist;\n\n\t}\n\n\tintersectSphere( sphere, target ) {\n\n\t\t_vector$a.subVectors( sphere.center, this.origin );\n\t\tconst tca = _vector$a.dot( this.direction );\n\t\tconst d2 = _vector$a.dot( _vector$a ) - tca * tca;\n\t\tconst radius2 = sphere.radius * sphere.radius;\n\n\t\tif ( d2 > radius2 ) return null;\n\n\t\tconst thc = Math.sqrt( radius2 - d2 );\n\n\t\t// t0 = first intersect point - entrance on front of sphere\n\t\tconst t0 = tca - thc;\n\n\t\t// t1 = second intersect point - exit point on back of sphere\n\t\tconst t1 = tca + thc;\n\n\t\t// test to see if both t0 and t1 are behind the ray - if so, return null\n\t\tif ( t0 < 0 && t1 < 0 ) return null;\n\n\t\t// test to see if t0 is behind the ray:\n\t\t// if it is, the ray is inside the sphere, so return the second exit point scaled by t1,\n\t\t// in order to always return an intersect point that is in front of the ray.\n\t\tif ( t0 < 0 ) return this.at( t1, target );\n\n\t\t// else t0 is in front of the ray, so return the first collision point scaled by t0\n\t\treturn this.at( t0, target );\n\n\t}\n\n\tintersectsSphere( sphere ) {\n\n\t\treturn this.distanceSqToPoint( sphere.center ) <= ( sphere.radius * sphere.radius );\n\n\t}\n\n\tdistanceToPlane( plane ) {\n\n\t\tconst denominator = plane.normal.dot( this.direction );\n\n\t\tif ( denominator === 0 ) {\n\n\t\t\t// line is coplanar, return origin\n\t\t\tif ( plane.distanceToPoint( this.origin ) === 0 ) {\n\n\t\t\t\treturn 0;\n\n\t\t\t}\n\n\t\t\t// Null is preferable to undefined since undefined means.... it is undefined\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst t = - ( this.origin.dot( plane.normal ) + plane.constant ) / denominator;\n\n\t\t// Return if the ray never intersects the plane\n\n\t\treturn t >= 0 ? t : null;\n\n\t}\n\n\tintersectPlane( plane, target ) {\n\n\t\tconst t = this.distanceToPlane( plane );\n\n\t\tif ( t === null ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\treturn this.at( t, target );\n\n\t}\n\n\tintersectsPlane( plane ) {\n\n\t\t// check if the ray lies on the plane first\n\n\t\tconst distToPoint = plane.distanceToPoint( this.origin );\n\n\t\tif ( distToPoint === 0 ) {\n\n\t\t\treturn true;\n\n\t\t}\n\n\t\tconst denominator = plane.normal.dot( this.direction );\n\n\t\tif ( denominator * distToPoint < 0 ) {\n\n\t\t\treturn true;\n\n\t\t}\n\n\t\t// ray origin is behind the plane (and is pointing behind it)\n\n\t\treturn false;\n\n\t}\n\n\tintersectBox( box, target ) {\n\n\t\tlet tmin, tmax, tymin, tymax, tzmin, tzmax;\n\n\t\tconst invdirx = 1 / this.direction.x,\n\t\t\tinvdiry = 1 / this.direction.y,\n\t\t\tinvdirz = 1 / this.direction.z;\n\n\t\tconst origin = this.origin;\n\n\t\tif ( invdirx >= 0 ) {\n\n\t\t\ttmin = ( box.min.x - origin.x ) * invdirx;\n\t\t\ttmax = ( box.max.x - origin.x ) * invdirx;\n\n\t\t} else {\n\n\t\t\ttmin = ( box.max.x - origin.x ) * invdirx;\n\t\t\ttmax = ( box.min.x - origin.x ) * invdirx;\n\n\t\t}\n\n\t\tif ( invdiry >= 0 ) {\n\n\t\t\ttymin = ( box.min.y - origin.y ) * invdiry;\n\t\t\ttymax = ( box.max.y - origin.y ) * invdiry;\n\n\t\t} else {\n\n\t\t\ttymin = ( box.max.y - origin.y ) * invdiry;\n\t\t\ttymax = ( box.min.y - origin.y ) * invdiry;\n\n\t\t}\n\n\t\tif ( ( tmin > tymax ) || ( tymin > tmax ) ) return null;\n\n\t\t// These lines also handle the case where tmin or tmax is NaN\n\t\t// (result of 0 * Infinity). x !== x returns true if x is NaN\n\n\t\tif ( tymin > tmin || tmin !== tmin ) tmin = tymin;\n\n\t\tif ( tymax < tmax || tmax !== tmax ) tmax = tymax;\n\n\t\tif ( invdirz >= 0 ) {\n\n\t\t\ttzmin = ( box.min.z - origin.z ) * invdirz;\n\t\t\ttzmax = ( box.max.z - origin.z ) * invdirz;\n\n\t\t} else {\n\n\t\t\ttzmin = ( box.max.z - origin.z ) * invdirz;\n\t\t\ttzmax = ( box.min.z - origin.z ) * invdirz;\n\n\t\t}\n\n\t\tif ( ( tmin > tzmax ) || ( tzmin > tmax ) ) return null;\n\n\t\tif ( tzmin > tmin || tmin !== tmin ) tmin = tzmin;\n\n\t\tif ( tzmax < tmax || tmax !== tmax ) tmax = tzmax;\n\n\t\t//return point closest to the ray (positive side)\n\n\t\tif ( tmax < 0 ) return null;\n\n\t\treturn this.at( tmin >= 0 ? tmin : tmax, target );\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\treturn this.intersectBox( box, _vector$a ) !== null;\n\n\t}\n\n\tintersectTriangle( a, b, c, backfaceCulling, target ) {\n\n\t\t// Compute the offset origin, edges, and normal.\n\n\t\t// from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteIntrRay3Triangle3.h\n\n\t\t_edge1.subVectors( b, a );\n\t\t_edge2.subVectors( c, a );\n\t\t_normal$1.crossVectors( _edge1, _edge2 );\n\n\t\t// Solve Q + t*D = b1*E1 + b2*E2 (Q = kDiff, D = ray direction,\n\t\t// E1 = kEdge1, E2 = kEdge2, N = Cross(E1,E2)) by\n\t\t//   |Dot(D,N)|*b1 = sign(Dot(D,N))*Dot(D,Cross(Q,E2))\n\t\t//   |Dot(D,N)|*b2 = sign(Dot(D,N))*Dot(D,Cross(E1,Q))\n\t\t//   |Dot(D,N)|*t = -sign(Dot(D,N))*Dot(Q,N)\n\t\tlet DdN = this.direction.dot( _normal$1 );\n\t\tlet sign;\n\n\t\tif ( DdN > 0 ) {\n\n\t\t\tif ( backfaceCulling ) return null;\n\t\t\tsign = 1;\n\n\t\t} else if ( DdN < 0 ) {\n\n\t\t\tsign = - 1;\n\t\t\tDdN = - DdN;\n\n\t\t} else {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\t_diff.subVectors( this.origin, a );\n\t\tconst DdQxE2 = sign * this.direction.dot( _edge2.crossVectors( _diff, _edge2 ) );\n\n\t\t// b1 < 0, no intersection\n\t\tif ( DdQxE2 < 0 ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst DdE1xQ = sign * this.direction.dot( _edge1.cross( _diff ) );\n\n\t\t// b2 < 0, no intersection\n\t\tif ( DdE1xQ < 0 ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\t// b1+b2 > 1, no intersection\n\t\tif ( DdQxE2 + DdE1xQ > DdN ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\t// Line intersects triangle, check if ray does.\n\t\tconst QdN = - sign * _diff.dot( _normal$1 );\n\n\t\t// t < 0, no intersection\n\t\tif ( QdN < 0 ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\t// Ray intersects triangle.\n\t\treturn this.at( QdN / DdN, target );\n\n\t}\n\n\tapplyMatrix4( matrix4 ) {\n\n\t\tthis.origin.applyMatrix4( matrix4 );\n\t\tthis.direction.transformDirection( matrix4 );\n\n\t\treturn this;\n\n\t}\n\n\tequals( ray ) {\n\n\t\treturn ray.origin.equals( this.origin ) && ray.direction.equals( this.direction );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nclass Matrix4 {\n\n\tconstructor() {\n\n\t\tthis.elements = [\n\n\t\t\t1, 0, 0, 0,\n\t\t\t0, 1, 0, 0,\n\t\t\t0, 0, 1, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t];\n\n\t\tif ( arguments.length > 0 ) {\n\n\t\t\tconsole.error( 'THREE.Matrix4: the constructor no longer reads arguments. use .set() instead.' );\n\n\t\t}\n\n\t}\n\n\tset( n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44 ) {\n\n\t\tconst te = this.elements;\n\n\t\tte[ 0 ] = n11; te[ 4 ] = n12; te[ 8 ] = n13; te[ 12 ] = n14;\n\t\tte[ 1 ] = n21; te[ 5 ] = n22; te[ 9 ] = n23; te[ 13 ] = n24;\n\t\tte[ 2 ] = n31; te[ 6 ] = n32; te[ 10 ] = n33; te[ 14 ] = n34;\n\t\tte[ 3 ] = n41; te[ 7 ] = n42; te[ 11 ] = n43; te[ 15 ] = n44;\n\n\t\treturn this;\n\n\t}\n\n\tidentity() {\n\n\t\tthis.set(\n\n\t\t\t1, 0, 0, 0,\n\t\t\t0, 1, 0, 0,\n\t\t\t0, 0, 1, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new Matrix4().fromArray( this.elements );\n\n\t}\n\n\tcopy( m ) {\n\n\t\tconst te = this.elements;\n\t\tconst me = m.elements;\n\n\t\tte[ 0 ] = me[ 0 ]; te[ 1 ] = me[ 1 ]; te[ 2 ] = me[ 2 ]; te[ 3 ] = me[ 3 ];\n\t\tte[ 4 ] = me[ 4 ]; te[ 5 ] = me[ 5 ]; te[ 6 ] = me[ 6 ]; te[ 7 ] = me[ 7 ];\n\t\tte[ 8 ] = me[ 8 ]; te[ 9 ] = me[ 9 ]; te[ 10 ] = me[ 10 ]; te[ 11 ] = me[ 11 ];\n\t\tte[ 12 ] = me[ 12 ]; te[ 13 ] = me[ 13 ]; te[ 14 ] = me[ 14 ]; te[ 15 ] = me[ 15 ];\n\n\t\treturn this;\n\n\t}\n\n\tcopyPosition( m ) {\n\n\t\tconst te = this.elements, me = m.elements;\n\n\t\tte[ 12 ] = me[ 12 ];\n\t\tte[ 13 ] = me[ 13 ];\n\t\tte[ 14 ] = me[ 14 ];\n\n\t\treturn this;\n\n\t}\n\n\tsetFromMatrix3( m ) {\n\n\t\tconst me = m.elements;\n\n\t\tthis.set(\n\n\t\t\tme[ 0 ], me[ 3 ], me[ 6 ], 0,\n\t\t\tme[ 1 ], me[ 4 ], me[ 7 ], 0,\n\t\t\tme[ 2 ], me[ 5 ], me[ 8 ], 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\textractBasis( xAxis, yAxis, zAxis ) {\n\n\t\txAxis.setFromMatrixColumn( this, 0 );\n\t\tyAxis.setFromMatrixColumn( this, 1 );\n\t\tzAxis.setFromMatrixColumn( this, 2 );\n\n\t\treturn this;\n\n\t}\n\n\tmakeBasis( xAxis, yAxis, zAxis ) {\n\n\t\tthis.set(\n\t\t\txAxis.x, yAxis.x, zAxis.x, 0,\n\t\t\txAxis.y, yAxis.y, zAxis.y, 0,\n\t\t\txAxis.z, yAxis.z, zAxis.z, 0,\n\t\t\t0, 0, 0, 1\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\textractRotation( m ) {\n\n\t\t// this method does not support reflection matrices\n\n\t\tconst te = this.elements;\n\t\tconst me = m.elements;\n\n\t\tconst scaleX = 1 / _v1$5.setFromMatrixColumn( m, 0 ).length();\n\t\tconst scaleY = 1 / _v1$5.setFromMatrixColumn( m, 1 ).length();\n\t\tconst scaleZ = 1 / _v1$5.setFromMatrixColumn( m, 2 ).length();\n\n\t\tte[ 0 ] = me[ 0 ] * scaleX;\n\t\tte[ 1 ] = me[ 1 ] * scaleX;\n\t\tte[ 2 ] = me[ 2 ] * scaleX;\n\t\tte[ 3 ] = 0;\n\n\t\tte[ 4 ] = me[ 4 ] * scaleY;\n\t\tte[ 5 ] = me[ 5 ] * scaleY;\n\t\tte[ 6 ] = me[ 6 ] * scaleY;\n\t\tte[ 7 ] = 0;\n\n\t\tte[ 8 ] = me[ 8 ] * scaleZ;\n\t\tte[ 9 ] = me[ 9 ] * scaleZ;\n\t\tte[ 10 ] = me[ 10 ] * scaleZ;\n\t\tte[ 11 ] = 0;\n\n\t\tte[ 12 ] = 0;\n\t\tte[ 13 ] = 0;\n\t\tte[ 14 ] = 0;\n\t\tte[ 15 ] = 1;\n\n\t\treturn this;\n\n\t}\n\n\tmakeRotationFromEuler( euler ) {\n\n\t\tif ( ! ( euler && euler.isEuler ) ) {\n\n\t\t\tconsole.error( 'THREE.Matrix4: .makeRotationFromEuler() now expects a Euler rotation rather than a Vector3 and order.' );\n\n\t\t}\n\n\t\tconst te = this.elements;\n\n\t\tconst x = euler.x, y = euler.y, z = euler.z;\n\t\tconst a = Math.cos( x ), b = Math.sin( x );\n\t\tconst c = Math.cos( y ), d = Math.sin( y );\n\t\tconst e = Math.cos( z ), f = Math.sin( z );\n\n\t\tif ( euler.order === 'XYZ' ) {\n\n\t\t\tconst ae = a * e, af = a * f, be = b * e, bf = b * f;\n\n\t\t\tte[ 0 ] = c * e;\n\t\t\tte[ 4 ] = - c * f;\n\t\t\tte[ 8 ] = d;\n\n\t\t\tte[ 1 ] = af + be * d;\n\t\t\tte[ 5 ] = ae - bf * d;\n\t\t\tte[ 9 ] = - b * c;\n\n\t\t\tte[ 2 ] = bf - ae * d;\n\t\t\tte[ 6 ] = be + af * d;\n\t\t\tte[ 10 ] = a * c;\n\n\t\t} else if ( euler.order === 'YXZ' ) {\n\n\t\t\tconst ce = c * e, cf = c * f, de = d * e, df = d * f;\n\n\t\t\tte[ 0 ] = ce + df * b;\n\t\t\tte[ 4 ] = de * b - cf;\n\t\t\tte[ 8 ] = a * d;\n\n\t\t\tte[ 1 ] = a * f;\n\t\t\tte[ 5 ] = a * e;\n\t\t\tte[ 9 ] = - b;\n\n\t\t\tte[ 2 ] = cf * b - de;\n\t\t\tte[ 6 ] = df + ce * b;\n\t\t\tte[ 10 ] = a * c;\n\n\t\t} else if ( euler.order === 'ZXY' ) {\n\n\t\t\tconst ce = c * e, cf = c * f, de = d * e, df = d * f;\n\n\t\t\tte[ 0 ] = ce - df * b;\n\t\t\tte[ 4 ] = - a * f;\n\t\t\tte[ 8 ] = de + cf * b;\n\n\t\t\tte[ 1 ] = cf + de * b;\n\t\t\tte[ 5 ] = a * e;\n\t\t\tte[ 9 ] = df - ce * b;\n\n\t\t\tte[ 2 ] = - a * d;\n\t\t\tte[ 6 ] = b;\n\t\t\tte[ 10 ] = a * c;\n\n\t\t} else if ( euler.order === 'ZYX' ) {\n\n\t\t\tconst ae = a * e, af = a * f, be = b * e, bf = b * f;\n\n\t\t\tte[ 0 ] = c * e;\n\t\t\tte[ 4 ] = be * d - af;\n\t\t\tte[ 8 ] = ae * d + bf;\n\n\t\t\tte[ 1 ] = c * f;\n\t\t\tte[ 5 ] = bf * d + ae;\n\t\t\tte[ 9 ] = af * d - be;\n\n\t\t\tte[ 2 ] = - d;\n\t\t\tte[ 6 ] = b * c;\n\t\t\tte[ 10 ] = a * c;\n\n\t\t} else if ( euler.order === 'YZX' ) {\n\n\t\t\tconst ac = a * c, ad = a * d, bc = b * c, bd = b * d;\n\n\t\t\tte[ 0 ] = c * e;\n\t\t\tte[ 4 ] = bd - ac * f;\n\t\t\tte[ 8 ] = bc * f + ad;\n\n\t\t\tte[ 1 ] = f;\n\t\t\tte[ 5 ] = a * e;\n\t\t\tte[ 9 ] = - b * e;\n\n\t\t\tte[ 2 ] = - d * e;\n\t\t\tte[ 6 ] = ad * f + bc;\n\t\t\tte[ 10 ] = ac - bd * f;\n\n\t\t} else if ( euler.order === 'XZY' ) {\n\n\t\t\tconst ac = a * c, ad = a * d, bc = b * c, bd = b * d;\n\n\t\t\tte[ 0 ] = c * e;\n\t\t\tte[ 4 ] = - f;\n\t\t\tte[ 8 ] = d * e;\n\n\t\t\tte[ 1 ] = ac * f + bd;\n\t\t\tte[ 5 ] = a * e;\n\t\t\tte[ 9 ] = ad * f - bc;\n\n\t\t\tte[ 2 ] = bc * f - ad;\n\t\t\tte[ 6 ] = b * e;\n\t\t\tte[ 10 ] = bd * f + ac;\n\n\t\t}\n\n\t\t// bottom row\n\t\tte[ 3 ] = 0;\n\t\tte[ 7 ] = 0;\n\t\tte[ 11 ] = 0;\n\n\t\t// last column\n\t\tte[ 12 ] = 0;\n\t\tte[ 13 ] = 0;\n\t\tte[ 14 ] = 0;\n\t\tte[ 15 ] = 1;\n\n\t\treturn this;\n\n\t}\n\n\tmakeRotationFromQuaternion( q ) {\n\n\t\treturn this.compose( _zero, q, _one );\n\n\t}\n\n\tlookAt( eye, target, up ) {\n\n\t\tconst te = this.elements;\n\n\t\t_z.subVectors( eye, target );\n\n\t\tif ( _z.lengthSq() === 0 ) {\n\n\t\t\t// eye and target are in the same position\n\n\t\t\t_z.z = 1;\n\n\t\t}\n\n\t\t_z.normalize();\n\t\t_x.crossVectors( up, _z );\n\n\t\tif ( _x.lengthSq() === 0 ) {\n\n\t\t\t// up and z are parallel\n\n\t\t\tif ( Math.abs( up.z ) === 1 ) {\n\n\t\t\t\t_z.x += 0.0001;\n\n\t\t\t} else {\n\n\t\t\t\t_z.z += 0.0001;\n\n\t\t\t}\n\n\t\t\t_z.normalize();\n\t\t\t_x.crossVectors( up, _z );\n\n\t\t}\n\n\t\t_x.normalize();\n\t\t_y.crossVectors( _z, _x );\n\n\t\tte[ 0 ] = _x.x; te[ 4 ] = _y.x; te[ 8 ] = _z.x;\n\t\tte[ 1 ] = _x.y; te[ 5 ] = _y.y; te[ 9 ] = _z.y;\n\t\tte[ 2 ] = _x.z; te[ 6 ] = _y.z; te[ 10 ] = _z.z;\n\n\t\treturn this;\n\n\t}\n\n\tmultiply( m, n ) {\n\n\t\tif ( n !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Matrix4: .multiply() now only accepts one argument. Use .multiplyMatrices( a, b ) instead.' );\n\t\t\treturn this.multiplyMatrices( m, n );\n\n\t\t}\n\n\t\treturn this.multiplyMatrices( this, m );\n\n\t}\n\n\tpremultiply( m ) {\n\n\t\treturn this.multiplyMatrices( m, this );\n\n\t}\n\n\tmultiplyMatrices( a, b ) {\n\n\t\tconst ae = a.elements;\n\t\tconst be = b.elements;\n\t\tconst te = this.elements;\n\n\t\tconst a11 = ae[ 0 ], a12 = ae[ 4 ], a13 = ae[ 8 ], a14 = ae[ 12 ];\n\t\tconst a21 = ae[ 1 ], a22 = ae[ 5 ], a23 = ae[ 9 ], a24 = ae[ 13 ];\n\t\tconst a31 = ae[ 2 ], a32 = ae[ 6 ], a33 = ae[ 10 ], a34 = ae[ 14 ];\n\t\tconst a41 = ae[ 3 ], a42 = ae[ 7 ], a43 = ae[ 11 ], a44 = ae[ 15 ];\n\n\t\tconst b11 = be[ 0 ], b12 = be[ 4 ], b13 = be[ 8 ], b14 = be[ 12 ];\n\t\tconst b21 = be[ 1 ], b22 = be[ 5 ], b23 = be[ 9 ], b24 = be[ 13 ];\n\t\tconst b31 = be[ 2 ], b32 = be[ 6 ], b33 = be[ 10 ], b34 = be[ 14 ];\n\t\tconst b41 = be[ 3 ], b42 = be[ 7 ], b43 = be[ 11 ], b44 = be[ 15 ];\n\n\t\tte[ 0 ] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;\n\t\tte[ 4 ] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;\n\t\tte[ 8 ] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;\n\t\tte[ 12 ] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;\n\n\t\tte[ 1 ] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;\n\t\tte[ 5 ] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;\n\t\tte[ 9 ] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;\n\t\tte[ 13 ] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;\n\n\t\tte[ 2 ] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;\n\t\tte[ 6 ] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;\n\t\tte[ 10 ] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;\n\t\tte[ 14 ] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;\n\n\t\tte[ 3 ] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;\n\t\tte[ 7 ] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;\n\t\tte[ 11 ] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;\n\t\tte[ 15 ] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;\n\n\t\treturn this;\n\n\t}\n\n\tmultiplyScalar( s ) {\n\n\t\tconst te = this.elements;\n\n\t\tte[ 0 ] *= s; te[ 4 ] *= s; te[ 8 ] *= s; te[ 12 ] *= s;\n\t\tte[ 1 ] *= s; te[ 5 ] *= s; te[ 9 ] *= s; te[ 13 ] *= s;\n\t\tte[ 2 ] *= s; te[ 6 ] *= s; te[ 10 ] *= s; te[ 14 ] *= s;\n\t\tte[ 3 ] *= s; te[ 7 ] *= s; te[ 11 ] *= s; te[ 15 ] *= s;\n\n\t\treturn this;\n\n\t}\n\n\tdeterminant() {\n\n\t\tconst te = this.elements;\n\n\t\tconst n11 = te[ 0 ], n12 = te[ 4 ], n13 = te[ 8 ], n14 = te[ 12 ];\n\t\tconst n21 = te[ 1 ], n22 = te[ 5 ], n23 = te[ 9 ], n24 = te[ 13 ];\n\t\tconst n31 = te[ 2 ], n32 = te[ 6 ], n33 = te[ 10 ], n34 = te[ 14 ];\n\t\tconst n41 = te[ 3 ], n42 = te[ 7 ], n43 = te[ 11 ], n44 = te[ 15 ];\n\n\t\t//TODO: make this more efficient\n\t\t//( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )\n\n\t\treturn (\n\t\t\tn41 * (\n\t\t\t\t+ n14 * n23 * n32\n\t\t\t\t - n13 * n24 * n32\n\t\t\t\t - n14 * n22 * n33\n\t\t\t\t + n12 * n24 * n33\n\t\t\t\t + n13 * n22 * n34\n\t\t\t\t - n12 * n23 * n34\n\t\t\t) +\n\t\t\tn42 * (\n\t\t\t\t+ n11 * n23 * n34\n\t\t\t\t - n11 * n24 * n33\n\t\t\t\t + n14 * n21 * n33\n\t\t\t\t - n13 * n21 * n34\n\t\t\t\t + n13 * n24 * n31\n\t\t\t\t - n14 * n23 * n31\n\t\t\t) +\n\t\t\tn43 * (\n\t\t\t\t+ n11 * n24 * n32\n\t\t\t\t - n11 * n22 * n34\n\t\t\t\t - n14 * n21 * n32\n\t\t\t\t + n12 * n21 * n34\n\t\t\t\t + n14 * n22 * n31\n\t\t\t\t - n12 * n24 * n31\n\t\t\t) +\n\t\t\tn44 * (\n\t\t\t\t- n13 * n22 * n31\n\t\t\t\t - n11 * n23 * n32\n\t\t\t\t + n11 * n22 * n33\n\t\t\t\t + n13 * n21 * n32\n\t\t\t\t - n12 * n21 * n33\n\t\t\t\t + n12 * n23 * n31\n\t\t\t)\n\n\t\t);\n\n\t}\n\n\ttranspose() {\n\n\t\tconst te = this.elements;\n\t\tlet tmp;\n\n\t\ttmp = te[ 1 ]; te[ 1 ] = te[ 4 ]; te[ 4 ] = tmp;\n\t\ttmp = te[ 2 ]; te[ 2 ] = te[ 8 ]; te[ 8 ] = tmp;\n\t\ttmp = te[ 6 ]; te[ 6 ] = te[ 9 ]; te[ 9 ] = tmp;\n\n\t\ttmp = te[ 3 ]; te[ 3 ] = te[ 12 ]; te[ 12 ] = tmp;\n\t\ttmp = te[ 7 ]; te[ 7 ] = te[ 13 ]; te[ 13 ] = tmp;\n\t\ttmp = te[ 11 ]; te[ 11 ] = te[ 14 ]; te[ 14 ] = tmp;\n\n\t\treturn this;\n\n\t}\n\n\tsetPosition( x, y, z ) {\n\n\t\tconst te = this.elements;\n\n\t\tif ( x.isVector3 ) {\n\n\t\t\tte[ 12 ] = x.x;\n\t\t\tte[ 13 ] = x.y;\n\t\t\tte[ 14 ] = x.z;\n\n\t\t} else {\n\n\t\t\tte[ 12 ] = x;\n\t\t\tte[ 13 ] = y;\n\t\t\tte[ 14 ] = z;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tinvert() {\n\n\t\t// based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm\n\t\tconst te = this.elements,\n\n\t\t\tn11 = te[ 0 ], n21 = te[ 1 ], n31 = te[ 2 ], n41 = te[ 3 ],\n\t\t\tn12 = te[ 4 ], n22 = te[ 5 ], n32 = te[ 6 ], n42 = te[ 7 ],\n\t\t\tn13 = te[ 8 ], n23 = te[ 9 ], n33 = te[ 10 ], n43 = te[ 11 ],\n\t\t\tn14 = te[ 12 ], n24 = te[ 13 ], n34 = te[ 14 ], n44 = te[ 15 ],\n\n\t\t\tt11 = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44,\n\t\t\tt12 = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44,\n\t\t\tt13 = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44,\n\t\t\tt14 = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;\n\n\t\tconst det = n11 * t11 + n21 * t12 + n31 * t13 + n41 * t14;\n\n\t\tif ( det === 0 ) return this.set( 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 );\n\n\t\tconst detInv = 1 / det;\n\n\t\tte[ 0 ] = t11 * detInv;\n\t\tte[ 1 ] = ( n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44 ) * detInv;\n\t\tte[ 2 ] = ( n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44 ) * detInv;\n\t\tte[ 3 ] = ( n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43 ) * detInv;\n\n\t\tte[ 4 ] = t12 * detInv;\n\t\tte[ 5 ] = ( n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44 ) * detInv;\n\t\tte[ 6 ] = ( n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44 ) * detInv;\n\t\tte[ 7 ] = ( n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43 ) * detInv;\n\n\t\tte[ 8 ] = t13 * detInv;\n\t\tte[ 9 ] = ( n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44 ) * detInv;\n\t\tte[ 10 ] = ( n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44 ) * detInv;\n\t\tte[ 11 ] = ( n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43 ) * detInv;\n\n\t\tte[ 12 ] = t14 * detInv;\n\t\tte[ 13 ] = ( n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34 ) * detInv;\n\t\tte[ 14 ] = ( n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34 ) * detInv;\n\t\tte[ 15 ] = ( n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33 ) * detInv;\n\n\t\treturn this;\n\n\t}\n\n\tscale( v ) {\n\n\t\tconst te = this.elements;\n\t\tconst x = v.x, y = v.y, z = v.z;\n\n\t\tte[ 0 ] *= x; te[ 4 ] *= y; te[ 8 ] *= z;\n\t\tte[ 1 ] *= x; te[ 5 ] *= y; te[ 9 ] *= z;\n\t\tte[ 2 ] *= x; te[ 6 ] *= y; te[ 10 ] *= z;\n\t\tte[ 3 ] *= x; te[ 7 ] *= y; te[ 11 ] *= z;\n\n\t\treturn this;\n\n\t}\n\n\tgetMaxScaleOnAxis() {\n\n\t\tconst te = this.elements;\n\n\t\tconst scaleXSq = te[ 0 ] * te[ 0 ] + te[ 1 ] * te[ 1 ] + te[ 2 ] * te[ 2 ];\n\t\tconst scaleYSq = te[ 4 ] * te[ 4 ] + te[ 5 ] * te[ 5 ] + te[ 6 ] * te[ 6 ];\n\t\tconst scaleZSq = te[ 8 ] * te[ 8 ] + te[ 9 ] * te[ 9 ] + te[ 10 ] * te[ 10 ];\n\n\t\treturn Math.sqrt( Math.max( scaleXSq, scaleYSq, scaleZSq ) );\n\n\t}\n\n\tmakeTranslation( x, y, z ) {\n\n\t\tthis.set(\n\n\t\t\t1, 0, 0, x,\n\t\t\t0, 1, 0, y,\n\t\t\t0, 0, 1, z,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmakeRotationX( theta ) {\n\n\t\tconst c = Math.cos( theta ), s = Math.sin( theta );\n\n\t\tthis.set(\n\n\t\t\t1, 0, 0, 0,\n\t\t\t0, c, - s, 0,\n\t\t\t0, s, c, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmakeRotationY( theta ) {\n\n\t\tconst c = Math.cos( theta ), s = Math.sin( theta );\n\n\t\tthis.set(\n\n\t\t\t c, 0, s, 0,\n\t\t\t 0, 1, 0, 0,\n\t\t\t- s, 0, c, 0,\n\t\t\t 0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmakeRotationZ( theta ) {\n\n\t\tconst c = Math.cos( theta ), s = Math.sin( theta );\n\n\t\tthis.set(\n\n\t\t\tc, - s, 0, 0,\n\t\t\ts, c, 0, 0,\n\t\t\t0, 0, 1, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmakeRotationAxis( axis, angle ) {\n\n\t\t// Based on http://www.gamedev.net/reference/articles/article1199.asp\n\n\t\tconst c = Math.cos( angle );\n\t\tconst s = Math.sin( angle );\n\t\tconst t = 1 - c;\n\t\tconst x = axis.x, y = axis.y, z = axis.z;\n\t\tconst tx = t * x, ty = t * y;\n\n\t\tthis.set(\n\n\t\t\ttx * x + c, tx * y - s * z, tx * z + s * y, 0,\n\t\t\ttx * y + s * z, ty * y + c, ty * z - s * x, 0,\n\t\t\ttx * z - s * y, ty * z + s * x, t * z * z + c, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmakeScale( x, y, z ) {\n\n\t\tthis.set(\n\n\t\t\tx, 0, 0, 0,\n\t\t\t0, y, 0, 0,\n\t\t\t0, 0, z, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tmakeShear( xy, xz, yx, yz, zx, zy ) {\n\n\t\tthis.set(\n\n\t\t\t1, yx, zx, 0,\n\t\t\txy, 1, zy, 0,\n\t\t\txz, yz, 1, 0,\n\t\t\t0, 0, 0, 1\n\n\t\t);\n\n\t\treturn this;\n\n\t}\n\n\tcompose( position, quaternion, scale ) {\n\n\t\tconst te = this.elements;\n\n\t\tconst x = quaternion._x, y = quaternion._y, z = quaternion._z, w = quaternion._w;\n\t\tconst x2 = x + x,\ty2 = y + y, z2 = z + z;\n\t\tconst xx = x * x2, xy = x * y2, xz = x * z2;\n\t\tconst yy = y * y2, yz = y * z2, zz = z * z2;\n\t\tconst wx = w * x2, wy = w * y2, wz = w * z2;\n\n\t\tconst sx = scale.x, sy = scale.y, sz = scale.z;\n\n\t\tte[ 0 ] = ( 1 - ( yy + zz ) ) * sx;\n\t\tte[ 1 ] = ( xy + wz ) * sx;\n\t\tte[ 2 ] = ( xz - wy ) * sx;\n\t\tte[ 3 ] = 0;\n\n\t\tte[ 4 ] = ( xy - wz ) * sy;\n\t\tte[ 5 ] = ( 1 - ( xx + zz ) ) * sy;\n\t\tte[ 6 ] = ( yz + wx ) * sy;\n\t\tte[ 7 ] = 0;\n\n\t\tte[ 8 ] = ( xz + wy ) * sz;\n\t\tte[ 9 ] = ( yz - wx ) * sz;\n\t\tte[ 10 ] = ( 1 - ( xx + yy ) ) * sz;\n\t\tte[ 11 ] = 0;\n\n\t\tte[ 12 ] = position.x;\n\t\tte[ 13 ] = position.y;\n\t\tte[ 14 ] = position.z;\n\t\tte[ 15 ] = 1;\n\n\t\treturn this;\n\n\t}\n\n\tdecompose( position, quaternion, scale ) {\n\n\t\tconst te = this.elements;\n\n\t\tlet sx = _v1$5.set( te[ 0 ], te[ 1 ], te[ 2 ] ).length();\n\t\tconst sy = _v1$5.set( te[ 4 ], te[ 5 ], te[ 6 ] ).length();\n\t\tconst sz = _v1$5.set( te[ 8 ], te[ 9 ], te[ 10 ] ).length();\n\n\t\t// if determine is negative, we need to invert one scale\n\t\tconst det = this.determinant();\n\t\tif ( det < 0 ) sx = - sx;\n\n\t\tposition.x = te[ 12 ];\n\t\tposition.y = te[ 13 ];\n\t\tposition.z = te[ 14 ];\n\n\t\t// scale the rotation part\n\t\t_m1$2.copy( this );\n\n\t\tconst invSX = 1 / sx;\n\t\tconst invSY = 1 / sy;\n\t\tconst invSZ = 1 / sz;\n\n\t\t_m1$2.elements[ 0 ] *= invSX;\n\t\t_m1$2.elements[ 1 ] *= invSX;\n\t\t_m1$2.elements[ 2 ] *= invSX;\n\n\t\t_m1$2.elements[ 4 ] *= invSY;\n\t\t_m1$2.elements[ 5 ] *= invSY;\n\t\t_m1$2.elements[ 6 ] *= invSY;\n\n\t\t_m1$2.elements[ 8 ] *= invSZ;\n\t\t_m1$2.elements[ 9 ] *= invSZ;\n\t\t_m1$2.elements[ 10 ] *= invSZ;\n\n\t\tquaternion.setFromRotationMatrix( _m1$2 );\n\n\t\tscale.x = sx;\n\t\tscale.y = sy;\n\t\tscale.z = sz;\n\n\t\treturn this;\n\n\t}\n\n\tmakePerspective( left, right, top, bottom, near, far ) {\n\n\t\tif ( far === undefined ) {\n\n\t\t\tconsole.warn( 'THREE.Matrix4: .makePerspective() has been redefined and has a new signature. Please check the docs.' );\n\n\t\t}\n\n\t\tconst te = this.elements;\n\t\tconst x = 2 * near / ( right - left );\n\t\tconst y = 2 * near / ( top - bottom );\n\n\t\tconst a = ( right + left ) / ( right - left );\n\t\tconst b = ( top + bottom ) / ( top - bottom );\n\t\tconst c = - ( far + near ) / ( far - near );\n\t\tconst d = - 2 * far * near / ( far - near );\n\n\t\tte[ 0 ] = x;\tte[ 4 ] = 0;\tte[ 8 ] = a;\tte[ 12 ] = 0;\n\t\tte[ 1 ] = 0;\tte[ 5 ] = y;\tte[ 9 ] = b;\tte[ 13 ] = 0;\n\t\tte[ 2 ] = 0;\tte[ 6 ] = 0;\tte[ 10 ] = c;\tte[ 14 ] = d;\n\t\tte[ 3 ] = 0;\tte[ 7 ] = 0;\tte[ 11 ] = - 1;\tte[ 15 ] = 0;\n\n\t\treturn this;\n\n\t}\n\n\tmakeOrthographic( left, right, top, bottom, near, far ) {\n\n\t\tconst te = this.elements;\n\t\tconst w = 1.0 / ( right - left );\n\t\tconst h = 1.0 / ( top - bottom );\n\t\tconst p = 1.0 / ( far - near );\n\n\t\tconst x = ( right + left ) * w;\n\t\tconst y = ( top + bottom ) * h;\n\t\tconst z = ( far + near ) * p;\n\n\t\tte[ 0 ] = 2 * w;\tte[ 4 ] = 0;\tte[ 8 ] = 0;\tte[ 12 ] = - x;\n\t\tte[ 1 ] = 0;\tte[ 5 ] = 2 * h;\tte[ 9 ] = 0;\tte[ 13 ] = - y;\n\t\tte[ 2 ] = 0;\tte[ 6 ] = 0;\tte[ 10 ] = - 2 * p;\tte[ 14 ] = - z;\n\t\tte[ 3 ] = 0;\tte[ 7 ] = 0;\tte[ 11 ] = 0;\tte[ 15 ] = 1;\n\n\t\treturn this;\n\n\t}\n\n\tequals( matrix ) {\n\n\t\tconst te = this.elements;\n\t\tconst me = matrix.elements;\n\n\t\tfor ( let i = 0; i < 16; i ++ ) {\n\n\t\t\tif ( te[ i ] !== me[ i ] ) return false;\n\n\t\t}\n\n\t\treturn true;\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tfor ( let i = 0; i < 16; i ++ ) {\n\n\t\t\tthis.elements[ i ] = array[ i + offset ];\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tconst te = this.elements;\n\n\t\tarray[ offset ] = te[ 0 ];\n\t\tarray[ offset + 1 ] = te[ 1 ];\n\t\tarray[ offset + 2 ] = te[ 2 ];\n\t\tarray[ offset + 3 ] = te[ 3 ];\n\n\t\tarray[ offset + 4 ] = te[ 4 ];\n\t\tarray[ offset + 5 ] = te[ 5 ];\n\t\tarray[ offset + 6 ] = te[ 6 ];\n\t\tarray[ offset + 7 ] = te[ 7 ];\n\n\t\tarray[ offset + 8 ] = te[ 8 ];\n\t\tarray[ offset + 9 ] = te[ 9 ];\n\t\tarray[ offset + 10 ] = te[ 10 ];\n\t\tarray[ offset + 11 ] = te[ 11 ];\n\n\t\tarray[ offset + 12 ] = te[ 12 ];\n\t\tarray[ offset + 13 ] = te[ 13 ];\n\t\tarray[ offset + 14 ] = te[ 14 ];\n\t\tarray[ offset + 15 ] = te[ 15 ];\n\n\t\treturn array;\n\n\t}\n\n}\n\nMatrix4.prototype.isMatrix4 = true;\n\nconst _v1$5 = /*@__PURE__*/ new Vector3();\nconst _m1$2 = /*@__PURE__*/ new Matrix4();\nconst _zero = /*@__PURE__*/ new Vector3( 0, 0, 0 );\nconst _one = /*@__PURE__*/ new Vector3( 1, 1, 1 );\nconst _x = /*@__PURE__*/ new Vector3();\nconst _y = /*@__PURE__*/ new Vector3();\nconst _z = /*@__PURE__*/ new Vector3();\n\nconst _matrix$1 = /*@__PURE__*/ new Matrix4();\nconst _quaternion$3 = /*@__PURE__*/ new Quaternion();\n\nclass Euler {\n\n\tconstructor( x = 0, y = 0, z = 0, order = Euler.DefaultOrder ) {\n\n\t\tthis._x = x;\n\t\tthis._y = y;\n\t\tthis._z = z;\n\t\tthis._order = order;\n\n\t}\n\n\tget x() {\n\n\t\treturn this._x;\n\n\t}\n\n\tset x( value ) {\n\n\t\tthis._x = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tget y() {\n\n\t\treturn this._y;\n\n\t}\n\n\tset y( value ) {\n\n\t\tthis._y = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tget z() {\n\n\t\treturn this._z;\n\n\t}\n\n\tset z( value ) {\n\n\t\tthis._z = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tget order() {\n\n\t\treturn this._order;\n\n\t}\n\n\tset order( value ) {\n\n\t\tthis._order = value;\n\t\tthis._onChangeCallback();\n\n\t}\n\n\tset( x, y, z, order = this._order ) {\n\n\t\tthis._x = x;\n\t\tthis._y = y;\n\t\tthis._z = z;\n\t\tthis._order = order;\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this._x, this._y, this._z, this._order );\n\n\t}\n\n\tcopy( euler ) {\n\n\t\tthis._x = euler._x;\n\t\tthis._y = euler._y;\n\t\tthis._z = euler._z;\n\t\tthis._order = euler._order;\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tsetFromRotationMatrix( m, order = this._order, update = true ) {\n\n\t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n\t\tconst te = m.elements;\n\t\tconst m11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ];\n\t\tconst m21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ];\n\t\tconst m31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ];\n\n\t\tswitch ( order ) {\n\n\t\t\tcase 'XYZ':\n\n\t\t\t\tthis._y = Math.asin( clamp( m13, - 1, 1 ) );\n\n\t\t\t\tif ( Math.abs( m13 ) < 0.9999999 ) {\n\n\t\t\t\t\tthis._x = Math.atan2( - m23, m33 );\n\t\t\t\t\tthis._z = Math.atan2( - m12, m11 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis._x = Math.atan2( m32, m22 );\n\t\t\t\t\tthis._z = 0;\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'YXZ':\n\n\t\t\t\tthis._x = Math.asin( - clamp( m23, - 1, 1 ) );\n\n\t\t\t\tif ( Math.abs( m23 ) < 0.9999999 ) {\n\n\t\t\t\t\tthis._y = Math.atan2( m13, m33 );\n\t\t\t\t\tthis._z = Math.atan2( m21, m22 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis._y = Math.atan2( - m31, m11 );\n\t\t\t\t\tthis._z = 0;\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'ZXY':\n\n\t\t\t\tthis._x = Math.asin( clamp( m32, - 1, 1 ) );\n\n\t\t\t\tif ( Math.abs( m32 ) < 0.9999999 ) {\n\n\t\t\t\t\tthis._y = Math.atan2( - m31, m33 );\n\t\t\t\t\tthis._z = Math.atan2( - m12, m22 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis._y = 0;\n\t\t\t\t\tthis._z = Math.atan2( m21, m11 );\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'ZYX':\n\n\t\t\t\tthis._y = Math.asin( - clamp( m31, - 1, 1 ) );\n\n\t\t\t\tif ( Math.abs( m31 ) < 0.9999999 ) {\n\n\t\t\t\t\tthis._x = Math.atan2( m32, m33 );\n\t\t\t\t\tthis._z = Math.atan2( m21, m11 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis._x = 0;\n\t\t\t\t\tthis._z = Math.atan2( - m12, m22 );\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'YZX':\n\n\t\t\t\tthis._z = Math.asin( clamp( m21, - 1, 1 ) );\n\n\t\t\t\tif ( Math.abs( m21 ) < 0.9999999 ) {\n\n\t\t\t\t\tthis._x = Math.atan2( - m23, m22 );\n\t\t\t\t\tthis._y = Math.atan2( - m31, m11 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis._x = 0;\n\t\t\t\t\tthis._y = Math.atan2( m13, m33 );\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'XZY':\n\n\t\t\t\tthis._z = Math.asin( - clamp( m12, - 1, 1 ) );\n\n\t\t\t\tif ( Math.abs( m12 ) < 0.9999999 ) {\n\n\t\t\t\t\tthis._x = Math.atan2( m32, m22 );\n\t\t\t\t\tthis._y = Math.atan2( m13, m11 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis._x = Math.atan2( - m23, m33 );\n\t\t\t\t\tthis._y = 0;\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\n\t\t\t\tconsole.warn( 'THREE.Euler: .setFromRotationMatrix() encountered an unknown order: ' + order );\n\n\t\t}\n\n\t\tthis._order = order;\n\n\t\tif ( update === true ) this._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\tsetFromQuaternion( q, order, update ) {\n\n\t\t_matrix$1.makeRotationFromQuaternion( q );\n\n\t\treturn this.setFromRotationMatrix( _matrix$1, order, update );\n\n\t}\n\n\tsetFromVector3( v, order = this._order ) {\n\n\t\treturn this.set( v.x, v.y, v.z, order );\n\n\t}\n\n\treorder( newOrder ) {\n\n\t\t// WARNING: this discards revolution information -bhouston\n\n\t\t_quaternion$3.setFromEuler( this );\n\n\t\treturn this.setFromQuaternion( _quaternion$3, newOrder );\n\n\t}\n\n\tequals( euler ) {\n\n\t\treturn ( euler._x === this._x ) && ( euler._y === this._y ) && ( euler._z === this._z ) && ( euler._order === this._order );\n\n\t}\n\n\tfromArray( array ) {\n\n\t\tthis._x = array[ 0 ];\n\t\tthis._y = array[ 1 ];\n\t\tthis._z = array[ 2 ];\n\t\tif ( array[ 3 ] !== undefined ) this._order = array[ 3 ];\n\n\t\tthis._onChangeCallback();\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tarray[ offset ] = this._x;\n\t\tarray[ offset + 1 ] = this._y;\n\t\tarray[ offset + 2 ] = this._z;\n\t\tarray[ offset + 3 ] = this._order;\n\n\t\treturn array;\n\n\t}\n\n\t_onChange( callback ) {\n\n\t\tthis._onChangeCallback = callback;\n\n\t\treturn this;\n\n\t}\n\n\t_onChangeCallback() {}\n\n}\n\nEuler.prototype.isEuler = true;\n\nEuler.DefaultOrder = 'XYZ';\nEuler.RotationOrders = [ 'XYZ', 'YZX', 'ZXY', 'XZY', 'YXZ', 'ZYX' ];\n\nclass Layers {\n\n\tconstructor() {\n\n\t\tthis.mask = 1 | 0;\n\n\t}\n\n\tset( channel ) {\n\n\t\tthis.mask = ( 1 << channel | 0 ) >>> 0;\n\n\t}\n\n\tenable( channel ) {\n\n\t\tthis.mask |= 1 << channel | 0;\n\n\t}\n\n\tenableAll() {\n\n\t\tthis.mask = 0xffffffff | 0;\n\n\t}\n\n\ttoggle( channel ) {\n\n\t\tthis.mask ^= 1 << channel | 0;\n\n\t}\n\n\tdisable( channel ) {\n\n\t\tthis.mask &= ~ ( 1 << channel | 0 );\n\n\t}\n\n\tdisableAll() {\n\n\t\tthis.mask = 0;\n\n\t}\n\n\ttest( layers ) {\n\n\t\treturn ( this.mask & layers.mask ) !== 0;\n\n\t}\n\n\tisEnabled( channel ) {\n\n\t\treturn ( this.mask & ( 1 << channel | 0 ) ) !== 0;\n\n\t}\n\n}\n\nlet _object3DId = 0;\n\nconst _v1$4 = /*@__PURE__*/ new Vector3();\nconst _q1 = /*@__PURE__*/ new Quaternion();\nconst _m1$1 = /*@__PURE__*/ new Matrix4();\nconst _target = /*@__PURE__*/ new Vector3();\n\nconst _position$3 = /*@__PURE__*/ new Vector3();\nconst _scale$2 = /*@__PURE__*/ new Vector3();\nconst _quaternion$2 = /*@__PURE__*/ new Quaternion();\n\nconst _xAxis = /*@__PURE__*/ new Vector3( 1, 0, 0 );\nconst _yAxis = /*@__PURE__*/ new Vector3( 0, 1, 0 );\nconst _zAxis = /*@__PURE__*/ new Vector3( 0, 0, 1 );\n\nconst _addedEvent = { type: 'added' };\nconst _removedEvent = { type: 'removed' };\n\nclass Object3D extends EventDispatcher {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tObject.defineProperty( this, 'id', { value: _object3DId ++ } );\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.name = '';\n\t\tthis.type = 'Object3D';\n\n\t\tthis.parent = null;\n\t\tthis.children = [];\n\n\t\tthis.up = Object3D.DefaultUp.clone();\n\n\t\tconst position = new Vector3();\n\t\tconst rotation = new Euler();\n\t\tconst quaternion = new Quaternion();\n\t\tconst scale = new Vector3( 1, 1, 1 );\n\n\t\tfunction onRotationChange() {\n\n\t\t\tquaternion.setFromEuler( rotation, false );\n\n\t\t}\n\n\t\tfunction onQuaternionChange() {\n\n\t\t\trotation.setFromQuaternion( quaternion, undefined, false );\n\n\t\t}\n\n\t\trotation._onChange( onRotationChange );\n\t\tquaternion._onChange( onQuaternionChange );\n\n\t\tObject.defineProperties( this, {\n\t\t\tposition: {\n\t\t\t\tconfigurable: true,\n\t\t\t\tenumerable: true,\n\t\t\t\tvalue: position\n\t\t\t},\n\t\t\trotation: {\n\t\t\t\tconfigurable: true,\n\t\t\t\tenumerable: true,\n\t\t\t\tvalue: rotation\n\t\t\t},\n\t\t\tquaternion: {\n\t\t\t\tconfigurable: true,\n\t\t\t\tenumerable: true,\n\t\t\t\tvalue: quaternion\n\t\t\t},\n\t\t\tscale: {\n\t\t\t\tconfigurable: true,\n\t\t\t\tenumerable: true,\n\t\t\t\tvalue: scale\n\t\t\t},\n\t\t\tmodelViewMatrix: {\n\t\t\t\tvalue: new Matrix4()\n\t\t\t},\n\t\t\tnormalMatrix: {\n\t\t\t\tvalue: new Matrix3()\n\t\t\t}\n\t\t} );\n\n\t\tthis.matrix = new Matrix4();\n\t\tthis.matrixWorld = new Matrix4();\n\n\t\tthis.matrixAutoUpdate = Object3D.DefaultMatrixAutoUpdate;\n\t\tthis.matrixWorldNeedsUpdate = false;\n\n\t\tthis.layers = new Layers();\n\t\tthis.visible = true;\n\n\t\tthis.castShadow = false;\n\t\tthis.receiveShadow = false;\n\n\t\tthis.frustumCulled = true;\n\t\tthis.renderOrder = 0;\n\n\t\tthis.animations = [];\n\n\t\tthis.userData = {};\n\n\t}\n\n\tonBeforeRender( /* renderer, scene, camera, geometry, material, group */ ) {}\n\n\tonAfterRender( /* renderer, scene, camera, geometry, material, group */ ) {}\n\n\tapplyMatrix4( matrix ) {\n\n\t\tif ( this.matrixAutoUpdate ) this.updateMatrix();\n\n\t\tthis.matrix.premultiply( matrix );\n\n\t\tthis.matrix.decompose( this.position, this.quaternion, this.scale );\n\n\t}\n\n\tapplyQuaternion( q ) {\n\n\t\tthis.quaternion.premultiply( q );\n\n\t\treturn this;\n\n\t}\n\n\tsetRotationFromAxisAngle( axis, angle ) {\n\n\t\t// assumes axis is normalized\n\n\t\tthis.quaternion.setFromAxisAngle( axis, angle );\n\n\t}\n\n\tsetRotationFromEuler( euler ) {\n\n\t\tthis.quaternion.setFromEuler( euler, true );\n\n\t}\n\n\tsetRotationFromMatrix( m ) {\n\n\t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n\t\tthis.quaternion.setFromRotationMatrix( m );\n\n\t}\n\n\tsetRotationFromQuaternion( q ) {\n\n\t\t// assumes q is normalized\n\n\t\tthis.quaternion.copy( q );\n\n\t}\n\n\trotateOnAxis( axis, angle ) {\n\n\t\t// rotate object on axis in object space\n\t\t// axis is assumed to be normalized\n\n\t\t_q1.setFromAxisAngle( axis, angle );\n\n\t\tthis.quaternion.multiply( _q1 );\n\n\t\treturn this;\n\n\t}\n\n\trotateOnWorldAxis( axis, angle ) {\n\n\t\t// rotate object on axis in world space\n\t\t// axis is assumed to be normalized\n\t\t// method assumes no rotated parent\n\n\t\t_q1.setFromAxisAngle( axis, angle );\n\n\t\tthis.quaternion.premultiply( _q1 );\n\n\t\treturn this;\n\n\t}\n\n\trotateX( angle ) {\n\n\t\treturn this.rotateOnAxis( _xAxis, angle );\n\n\t}\n\n\trotateY( angle ) {\n\n\t\treturn this.rotateOnAxis( _yAxis, angle );\n\n\t}\n\n\trotateZ( angle ) {\n\n\t\treturn this.rotateOnAxis( _zAxis, angle );\n\n\t}\n\n\ttranslateOnAxis( axis, distance ) {\n\n\t\t// translate object by distance along axis in object space\n\t\t// axis is assumed to be normalized\n\n\t\t_v1$4.copy( axis ).applyQuaternion( this.quaternion );\n\n\t\tthis.position.add( _v1$4.multiplyScalar( distance ) );\n\n\t\treturn this;\n\n\t}\n\n\ttranslateX( distance ) {\n\n\t\treturn this.translateOnAxis( _xAxis, distance );\n\n\t}\n\n\ttranslateY( distance ) {\n\n\t\treturn this.translateOnAxis( _yAxis, distance );\n\n\t}\n\n\ttranslateZ( distance ) {\n\n\t\treturn this.translateOnAxis( _zAxis, distance );\n\n\t}\n\n\tlocalToWorld( vector ) {\n\n\t\treturn vector.applyMatrix4( this.matrixWorld );\n\n\t}\n\n\tworldToLocal( vector ) {\n\n\t\treturn vector.applyMatrix4( _m1$1.copy( this.matrixWorld ).invert() );\n\n\t}\n\n\tlookAt( x, y, z ) {\n\n\t\t// This method does not support objects having non-uniformly-scaled parent(s)\n\n\t\tif ( x.isVector3 ) {\n\n\t\t\t_target.copy( x );\n\n\t\t} else {\n\n\t\t\t_target.set( x, y, z );\n\n\t\t}\n\n\t\tconst parent = this.parent;\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\t_position$3.setFromMatrixPosition( this.matrixWorld );\n\n\t\tif ( this.isCamera || this.isLight ) {\n\n\t\t\t_m1$1.lookAt( _position$3, _target, this.up );\n\n\t\t} else {\n\n\t\t\t_m1$1.lookAt( _target, _position$3, this.up );\n\n\t\t}\n\n\t\tthis.quaternion.setFromRotationMatrix( _m1$1 );\n\n\t\tif ( parent ) {\n\n\t\t\t_m1$1.extractRotation( parent.matrixWorld );\n\t\t\t_q1.setFromRotationMatrix( _m1$1 );\n\t\t\tthis.quaternion.premultiply( _q1.invert() );\n\n\t\t}\n\n\t}\n\n\tadd( object ) {\n\n\t\tif ( arguments.length > 1 ) {\n\n\t\t\tfor ( let i = 0; i < arguments.length; i ++ ) {\n\n\t\t\t\tthis.add( arguments[ i ] );\n\n\t\t\t}\n\n\t\t\treturn this;\n\n\t\t}\n\n\t\tif ( object === this ) {\n\n\t\t\tconsole.error( 'THREE.Object3D.add: object can\\'t be added as a child of itself.', object );\n\t\t\treturn this;\n\n\t\t}\n\n\t\tif ( object && object.isObject3D ) {\n\n\t\t\tif ( object.parent !== null ) {\n\n\t\t\t\tobject.parent.remove( object );\n\n\t\t\t}\n\n\t\t\tobject.parent = this;\n\t\t\tthis.children.push( object );\n\n\t\t\tobject.dispatchEvent( _addedEvent );\n\n\t\t} else {\n\n\t\t\tconsole.error( 'THREE.Object3D.add: object not an instance of THREE.Object3D.', object );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tremove( object ) {\n\n\t\tif ( arguments.length > 1 ) {\n\n\t\t\tfor ( let i = 0; i < arguments.length; i ++ ) {\n\n\t\t\t\tthis.remove( arguments[ i ] );\n\n\t\t\t}\n\n\t\t\treturn this;\n\n\t\t}\n\n\t\tconst index = this.children.indexOf( object );\n\n\t\tif ( index !== - 1 ) {\n\n\t\t\tobject.parent = null;\n\t\t\tthis.children.splice( index, 1 );\n\n\t\t\tobject.dispatchEvent( _removedEvent );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tremoveFromParent() {\n\n\t\tconst parent = this.parent;\n\n\t\tif ( parent !== null ) {\n\n\t\t\tparent.remove( this );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tclear() {\n\n\t\tfor ( let i = 0; i < this.children.length; i ++ ) {\n\n\t\t\tconst object = this.children[ i ];\n\n\t\t\tobject.parent = null;\n\n\t\t\tobject.dispatchEvent( _removedEvent );\n\n\t\t}\n\n\t\tthis.children.length = 0;\n\n\t\treturn this;\n\n\n\t}\n\n\tattach( object ) {\n\n\t\t// adds object as a child of this, while maintaining the object's world transform\n\n\t\t// Note: This method does not support scene graphs having non-uniformly-scaled nodes(s)\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\t_m1$1.copy( this.matrixWorld ).invert();\n\n\t\tif ( object.parent !== null ) {\n\n\t\t\tobject.parent.updateWorldMatrix( true, false );\n\n\t\t\t_m1$1.multiply( object.parent.matrixWorld );\n\n\t\t}\n\n\t\tobject.applyMatrix4( _m1$1 );\n\n\t\tthis.add( object );\n\n\t\tobject.updateWorldMatrix( false, true );\n\n\t\treturn this;\n\n\t}\n\n\tgetObjectById( id ) {\n\n\t\treturn this.getObjectByProperty( 'id', id );\n\n\t}\n\n\tgetObjectByName( name ) {\n\n\t\treturn this.getObjectByProperty( 'name', name );\n\n\t}\n\n\tgetObjectByProperty( name, value ) {\n\n\t\tif ( this[ name ] === value ) return this;\n\n\t\tfor ( let i = 0, l = this.children.length; i < l; i ++ ) {\n\n\t\t\tconst child = this.children[ i ];\n\t\t\tconst object = child.getObjectByProperty( name, value );\n\n\t\t\tif ( object !== undefined ) {\n\n\t\t\t\treturn object;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn undefined;\n\n\t}\n\n\tgetWorldPosition( target ) {\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\treturn target.setFromMatrixPosition( this.matrixWorld );\n\n\t}\n\n\tgetWorldQuaternion( target ) {\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\tthis.matrixWorld.decompose( _position$3, target, _scale$2 );\n\n\t\treturn target;\n\n\t}\n\n\tgetWorldScale( target ) {\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\tthis.matrixWorld.decompose( _position$3, _quaternion$2, target );\n\n\t\treturn target;\n\n\t}\n\n\tgetWorldDirection( target ) {\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\tconst e = this.matrixWorld.elements;\n\n\t\treturn target.set( e[ 8 ], e[ 9 ], e[ 10 ] ).normalize();\n\n\t}\n\n\traycast( /* raycaster, intersects */ ) {}\n\n\ttraverse( callback ) {\n\n\t\tcallback( this );\n\n\t\tconst children = this.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\tchildren[ i ].traverse( callback );\n\n\t\t}\n\n\t}\n\n\ttraverseVisible( callback ) {\n\n\t\tif ( this.visible === false ) return;\n\n\t\tcallback( this );\n\n\t\tconst children = this.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\tchildren[ i ].traverseVisible( callback );\n\n\t\t}\n\n\t}\n\n\ttraverseAncestors( callback ) {\n\n\t\tconst parent = this.parent;\n\n\t\tif ( parent !== null ) {\n\n\t\t\tcallback( parent );\n\n\t\t\tparent.traverseAncestors( callback );\n\n\t\t}\n\n\t}\n\n\tupdateMatrix() {\n\n\t\tthis.matrix.compose( this.position, this.quaternion, this.scale );\n\n\t\tthis.matrixWorldNeedsUpdate = true;\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tif ( this.matrixAutoUpdate ) this.updateMatrix();\n\n\t\tif ( this.matrixWorldNeedsUpdate || force ) {\n\n\t\t\tif ( this.parent === null ) {\n\n\t\t\t\tthis.matrixWorld.copy( this.matrix );\n\n\t\t\t} else {\n\n\t\t\t\tthis.matrixWorld.multiplyMatrices( this.parent.matrixWorld, this.matrix );\n\n\t\t\t}\n\n\t\t\tthis.matrixWorldNeedsUpdate = false;\n\n\t\t\tforce = true;\n\n\t\t}\n\n\t\t// update children\n\n\t\tconst children = this.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\tchildren[ i ].updateMatrixWorld( force );\n\n\t\t}\n\n\t}\n\n\tupdateWorldMatrix( updateParents, updateChildren ) {\n\n\t\tconst parent = this.parent;\n\n\t\tif ( updateParents === true && parent !== null ) {\n\n\t\t\tparent.updateWorldMatrix( true, false );\n\n\t\t}\n\n\t\tif ( this.matrixAutoUpdate ) this.updateMatrix();\n\n\t\tif ( this.parent === null ) {\n\n\t\t\tthis.matrixWorld.copy( this.matrix );\n\n\t\t} else {\n\n\t\t\tthis.matrixWorld.multiplyMatrices( this.parent.matrixWorld, this.matrix );\n\n\t\t}\n\n\t\t// update children\n\n\t\tif ( updateChildren === true ) {\n\n\t\t\tconst children = this.children;\n\n\t\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\t\tchildren[ i ].updateWorldMatrix( false, true );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\t// meta is a string when called from JSON.stringify\n\t\tconst isRootObject = ( meta === undefined || typeof meta === 'string' );\n\n\t\tconst output = {};\n\n\t\t// meta is a hash used to collect geometries, materials.\n\t\t// not providing it implies that this is the root object\n\t\t// being serialized.\n\t\tif ( isRootObject ) {\n\n\t\t\t// initialize meta obj\n\t\t\tmeta = {\n\t\t\t\tgeometries: {},\n\t\t\t\tmaterials: {},\n\t\t\t\ttextures: {},\n\t\t\t\timages: {},\n\t\t\t\tshapes: {},\n\t\t\t\tskeletons: {},\n\t\t\t\tanimations: {},\n\t\t\t\tnodes: {}\n\t\t\t};\n\n\t\t\toutput.metadata = {\n\t\t\t\tversion: 4.5,\n\t\t\t\ttype: 'Object',\n\t\t\t\tgenerator: 'Object3D.toJSON'\n\t\t\t};\n\n\t\t}\n\n\t\t// standard Object3D serialization\n\n\t\tconst object = {};\n\n\t\tobject.uuid = this.uuid;\n\t\tobject.type = this.type;\n\n\t\tif ( this.name !== '' ) object.name = this.name;\n\t\tif ( this.castShadow === true ) object.castShadow = true;\n\t\tif ( this.receiveShadow === true ) object.receiveShadow = true;\n\t\tif ( this.visible === false ) object.visible = false;\n\t\tif ( this.frustumCulled === false ) object.frustumCulled = false;\n\t\tif ( this.renderOrder !== 0 ) object.renderOrder = this.renderOrder;\n\t\tif ( JSON.stringify( this.userData ) !== '{}' ) object.userData = this.userData;\n\n\t\tobject.layers = this.layers.mask;\n\t\tobject.matrix = this.matrix.toArray();\n\n\t\tif ( this.matrixAutoUpdate === false ) object.matrixAutoUpdate = false;\n\n\t\t// object specific properties\n\n\t\tif ( this.isInstancedMesh ) {\n\n\t\t\tobject.type = 'InstancedMesh';\n\t\t\tobject.count = this.count;\n\t\t\tobject.instanceMatrix = this.instanceMatrix.toJSON();\n\t\t\tif ( this.instanceColor !== null ) object.instanceColor = this.instanceColor.toJSON();\n\n\t\t}\n\n\t\t//\n\n\t\tfunction serialize( library, element ) {\n\n\t\t\tif ( library[ element.uuid ] === undefined ) {\n\n\t\t\t\tlibrary[ element.uuid ] = element.toJSON( meta );\n\n\t\t\t}\n\n\t\t\treturn element.uuid;\n\n\t\t}\n\n\t\tif ( this.isScene ) {\n\n\t\t\tif ( this.background ) {\n\n\t\t\t\tif ( this.background.isColor ) {\n\n\t\t\t\t\tobject.background = this.background.toJSON();\n\n\t\t\t\t} else if ( this.background.isTexture ) {\n\n\t\t\t\t\tobject.background = this.background.toJSON( meta ).uuid;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( this.environment && this.environment.isTexture ) {\n\n\t\t\t\tobject.environment = this.environment.toJSON( meta ).uuid;\n\n\t\t\t}\n\n\t\t} else if ( this.isMesh || this.isLine || this.isPoints ) {\n\n\t\t\tobject.geometry = serialize( meta.geometries, this.geometry );\n\n\t\t\tconst parameters = this.geometry.parameters;\n\n\t\t\tif ( parameters !== undefined && parameters.shapes !== undefined ) {\n\n\t\t\t\tconst shapes = parameters.shapes;\n\n\t\t\t\tif ( Array.isArray( shapes ) ) {\n\n\t\t\t\t\tfor ( let i = 0, l = shapes.length; i < l; i ++ ) {\n\n\t\t\t\t\t\tconst shape = shapes[ i ];\n\n\t\t\t\t\t\tserialize( meta.shapes, shape );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tserialize( meta.shapes, shapes );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( this.isSkinnedMesh ) {\n\n\t\t\tobject.bindMode = this.bindMode;\n\t\t\tobject.bindMatrix = this.bindMatrix.toArray();\n\n\t\t\tif ( this.skeleton !== undefined ) {\n\n\t\t\t\tserialize( meta.skeletons, this.skeleton );\n\n\t\t\t\tobject.skeleton = this.skeleton.uuid;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( this.material !== undefined ) {\n\n\t\t\tif ( Array.isArray( this.material ) ) {\n\n\t\t\t\tconst uuids = [];\n\n\t\t\t\tfor ( let i = 0, l = this.material.length; i < l; i ++ ) {\n\n\t\t\t\t\tuuids.push( serialize( meta.materials, this.material[ i ] ) );\n\n\t\t\t\t}\n\n\t\t\t\tobject.material = uuids;\n\n\t\t\t} else {\n\n\t\t\t\tobject.material = serialize( meta.materials, this.material );\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\n\t\tif ( this.children.length > 0 ) {\n\n\t\t\tobject.children = [];\n\n\t\t\tfor ( let i = 0; i < this.children.length; i ++ ) {\n\n\t\t\t\tobject.children.push( this.children[ i ].toJSON( meta ).object );\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\n\t\tif ( this.animations.length > 0 ) {\n\n\t\t\tobject.animations = [];\n\n\t\t\tfor ( let i = 0; i < this.animations.length; i ++ ) {\n\n\t\t\t\tconst animation = this.animations[ i ];\n\n\t\t\t\tobject.animations.push( serialize( meta.animations, animation ) );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( isRootObject ) {\n\n\t\t\tconst geometries = extractFromCache( meta.geometries );\n\t\t\tconst materials = extractFromCache( meta.materials );\n\t\t\tconst textures = extractFromCache( meta.textures );\n\t\t\tconst images = extractFromCache( meta.images );\n\t\t\tconst shapes = extractFromCache( meta.shapes );\n\t\t\tconst skeletons = extractFromCache( meta.skeletons );\n\t\t\tconst animations = extractFromCache( meta.animations );\n\t\t\tconst nodes = extractFromCache( meta.nodes );\n\n\t\t\tif ( geometries.length > 0 ) output.geometries = geometries;\n\t\t\tif ( materials.length > 0 ) output.materials = materials;\n\t\t\tif ( textures.length > 0 ) output.textures = textures;\n\t\t\tif ( images.length > 0 ) output.images = images;\n\t\t\tif ( shapes.length > 0 ) output.shapes = shapes;\n\t\t\tif ( skeletons.length > 0 ) output.skeletons = skeletons;\n\t\t\tif ( animations.length > 0 ) output.animations = animations;\n\t\t\tif ( nodes.length > 0 ) output.nodes = nodes;\n\n\t\t}\n\n\t\toutput.object = object;\n\n\t\treturn output;\n\n\t\t// extract data from the cache hash\n\t\t// remove metadata on each item\n\t\t// and return as array\n\t\tfunction extractFromCache( cache ) {\n\n\t\t\tconst values = [];\n\t\t\tfor ( const key in cache ) {\n\n\t\t\t\tconst data = cache[ key ];\n\t\t\t\tdelete data.metadata;\n\t\t\t\tvalues.push( data );\n\n\t\t\t}\n\n\t\t\treturn values;\n\n\t\t}\n\n\t}\n\n\tclone( recursive ) {\n\n\t\treturn new this.constructor().copy( this, recursive );\n\n\t}\n\n\tcopy( source, recursive = true ) {\n\n\t\tthis.name = source.name;\n\n\t\tthis.up.copy( source.up );\n\n\t\tthis.position.copy( source.position );\n\t\tthis.rotation.order = source.rotation.order;\n\t\tthis.quaternion.copy( source.quaternion );\n\t\tthis.scale.copy( source.scale );\n\n\t\tthis.matrix.copy( source.matrix );\n\t\tthis.matrixWorld.copy( source.matrixWorld );\n\n\t\tthis.matrixAutoUpdate = source.matrixAutoUpdate;\n\t\tthis.matrixWorldNeedsUpdate = source.matrixWorldNeedsUpdate;\n\n\t\tthis.layers.mask = source.layers.mask;\n\t\tthis.visible = source.visible;\n\n\t\tthis.castShadow = source.castShadow;\n\t\tthis.receiveShadow = source.receiveShadow;\n\n\t\tthis.frustumCulled = source.frustumCulled;\n\t\tthis.renderOrder = source.renderOrder;\n\n\t\tthis.userData = JSON.parse( JSON.stringify( source.userData ) );\n\n\t\tif ( recursive === true ) {\n\n\t\t\tfor ( let i = 0; i < source.children.length; i ++ ) {\n\n\t\t\t\tconst child = source.children[ i ];\n\t\t\t\tthis.add( child.clone() );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\nObject3D.DefaultUp = new Vector3( 0, 1, 0 );\nObject3D.DefaultMatrixAutoUpdate = true;\n\nObject3D.prototype.isObject3D = true;\n\nconst _v0$1 = /*@__PURE__*/ new Vector3();\nconst _v1$3 = /*@__PURE__*/ new Vector3();\nconst _v2$2 = /*@__PURE__*/ new Vector3();\nconst _v3$1 = /*@__PURE__*/ new Vector3();\n\nconst _vab = /*@__PURE__*/ new Vector3();\nconst _vac = /*@__PURE__*/ new Vector3();\nconst _vbc = /*@__PURE__*/ new Vector3();\nconst _vap = /*@__PURE__*/ new Vector3();\nconst _vbp = /*@__PURE__*/ new Vector3();\nconst _vcp = /*@__PURE__*/ new Vector3();\n\nclass Triangle {\n\n\tconstructor( a = new Vector3(), b = new Vector3(), c = new Vector3() ) {\n\n\t\tthis.a = a;\n\t\tthis.b = b;\n\t\tthis.c = c;\n\n\t}\n\n\tstatic getNormal( a, b, c, target ) {\n\n\t\ttarget.subVectors( c, b );\n\t\t_v0$1.subVectors( a, b );\n\t\ttarget.cross( _v0$1 );\n\n\t\tconst targetLengthSq = target.lengthSq();\n\t\tif ( targetLengthSq > 0 ) {\n\n\t\t\treturn target.multiplyScalar( 1 / Math.sqrt( targetLengthSq ) );\n\n\t\t}\n\n\t\treturn target.set( 0, 0, 0 );\n\n\t}\n\n\t// static/instance method to calculate barycentric coordinates\n\t// based on: http://www.blackpawn.com/texts/pointinpoly/default.html\n\tstatic getBarycoord( point, a, b, c, target ) {\n\n\t\t_v0$1.subVectors( c, a );\n\t\t_v1$3.subVectors( b, a );\n\t\t_v2$2.subVectors( point, a );\n\n\t\tconst dot00 = _v0$1.dot( _v0$1 );\n\t\tconst dot01 = _v0$1.dot( _v1$3 );\n\t\tconst dot02 = _v0$1.dot( _v2$2 );\n\t\tconst dot11 = _v1$3.dot( _v1$3 );\n\t\tconst dot12 = _v1$3.dot( _v2$2 );\n\n\t\tconst denom = ( dot00 * dot11 - dot01 * dot01 );\n\n\t\t// collinear or singular triangle\n\t\tif ( denom === 0 ) {\n\n\t\t\t// arbitrary location outside of triangle?\n\t\t\t// not sure if this is the best idea, maybe should be returning undefined\n\t\t\treturn target.set( - 2, - 1, - 1 );\n\n\t\t}\n\n\t\tconst invDenom = 1 / denom;\n\t\tconst u = ( dot11 * dot02 - dot01 * dot12 ) * invDenom;\n\t\tconst v = ( dot00 * dot12 - dot01 * dot02 ) * invDenom;\n\n\t\t// barycentric coordinates must always sum to 1\n\t\treturn target.set( 1 - u - v, v, u );\n\n\t}\n\n\tstatic containsPoint( point, a, b, c ) {\n\n\t\tthis.getBarycoord( point, a, b, c, _v3$1 );\n\n\t\treturn ( _v3$1.x >= 0 ) && ( _v3$1.y >= 0 ) && ( ( _v3$1.x + _v3$1.y ) <= 1 );\n\n\t}\n\n\tstatic getUV( point, p1, p2, p3, uv1, uv2, uv3, target ) {\n\n\t\tthis.getBarycoord( point, p1, p2, p3, _v3$1 );\n\n\t\ttarget.set( 0, 0 );\n\t\ttarget.addScaledVector( uv1, _v3$1.x );\n\t\ttarget.addScaledVector( uv2, _v3$1.y );\n\t\ttarget.addScaledVector( uv3, _v3$1.z );\n\n\t\treturn target;\n\n\t}\n\n\tstatic isFrontFacing( a, b, c, direction ) {\n\n\t\t_v0$1.subVectors( c, b );\n\t\t_v1$3.subVectors( a, b );\n\n\t\t// strictly front facing\n\t\treturn ( _v0$1.cross( _v1$3 ).dot( direction ) < 0 ) ? true : false;\n\n\t}\n\n\tset( a, b, c ) {\n\n\t\tthis.a.copy( a );\n\t\tthis.b.copy( b );\n\t\tthis.c.copy( c );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromPointsAndIndices( points, i0, i1, i2 ) {\n\n\t\tthis.a.copy( points[ i0 ] );\n\t\tthis.b.copy( points[ i1 ] );\n\t\tthis.c.copy( points[ i2 ] );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromAttributeAndIndices( attribute, i0, i1, i2 ) {\n\n\t\tthis.a.fromBufferAttribute( attribute, i0 );\n\t\tthis.b.fromBufferAttribute( attribute, i1 );\n\t\tthis.c.fromBufferAttribute( attribute, i2 );\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( triangle ) {\n\n\t\tthis.a.copy( triangle.a );\n\t\tthis.b.copy( triangle.b );\n\t\tthis.c.copy( triangle.c );\n\n\t\treturn this;\n\n\t}\n\n\tgetArea() {\n\n\t\t_v0$1.subVectors( this.c, this.b );\n\t\t_v1$3.subVectors( this.a, this.b );\n\n\t\treturn _v0$1.cross( _v1$3 ).length() * 0.5;\n\n\t}\n\n\tgetMidpoint( target ) {\n\n\t\treturn target.addVectors( this.a, this.b ).add( this.c ).multiplyScalar( 1 / 3 );\n\n\t}\n\n\tgetNormal( target ) {\n\n\t\treturn Triangle.getNormal( this.a, this.b, this.c, target );\n\n\t}\n\n\tgetPlane( target ) {\n\n\t\treturn target.setFromCoplanarPoints( this.a, this.b, this.c );\n\n\t}\n\n\tgetBarycoord( point, target ) {\n\n\t\treturn Triangle.getBarycoord( point, this.a, this.b, this.c, target );\n\n\t}\n\n\tgetUV( point, uv1, uv2, uv3, target ) {\n\n\t\treturn Triangle.getUV( point, this.a, this.b, this.c, uv1, uv2, uv3, target );\n\n\t}\n\n\tcontainsPoint( point ) {\n\n\t\treturn Triangle.containsPoint( point, this.a, this.b, this.c );\n\n\t}\n\n\tisFrontFacing( direction ) {\n\n\t\treturn Triangle.isFrontFacing( this.a, this.b, this.c, direction );\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\treturn box.intersectsTriangle( this );\n\n\t}\n\n\tclosestPointToPoint( p, target ) {\n\n\t\tconst a = this.a, b = this.b, c = this.c;\n\t\tlet v, w;\n\n\t\t// algorithm thanks to Real-Time Collision Detection by Christer Ericson,\n\t\t// published by Morgan Kaufmann Publishers, (c) 2005 Elsevier Inc.,\n\t\t// under the accompanying license; see chapter 5.1.5 for detailed explanation.\n\t\t// basically, we're distinguishing which of the voronoi regions of the triangle\n\t\t// the point lies in with the minimum amount of redundant computation.\n\n\t\t_vab.subVectors( b, a );\n\t\t_vac.subVectors( c, a );\n\t\t_vap.subVectors( p, a );\n\t\tconst d1 = _vab.dot( _vap );\n\t\tconst d2 = _vac.dot( _vap );\n\t\tif ( d1 <= 0 && d2 <= 0 ) {\n\n\t\t\t// vertex region of A; barycentric coords (1, 0, 0)\n\t\t\treturn target.copy( a );\n\n\t\t}\n\n\t\t_vbp.subVectors( p, b );\n\t\tconst d3 = _vab.dot( _vbp );\n\t\tconst d4 = _vac.dot( _vbp );\n\t\tif ( d3 >= 0 && d4 <= d3 ) {\n\n\t\t\t// vertex region of B; barycentric coords (0, 1, 0)\n\t\t\treturn target.copy( b );\n\n\t\t}\n\n\t\tconst vc = d1 * d4 - d3 * d2;\n\t\tif ( vc <= 0 && d1 >= 0 && d3 <= 0 ) {\n\n\t\t\tv = d1 / ( d1 - d3 );\n\t\t\t// edge region of AB; barycentric coords (1-v, v, 0)\n\t\t\treturn target.copy( a ).addScaledVector( _vab, v );\n\n\t\t}\n\n\t\t_vcp.subVectors( p, c );\n\t\tconst d5 = _vab.dot( _vcp );\n\t\tconst d6 = _vac.dot( _vcp );\n\t\tif ( d6 >= 0 && d5 <= d6 ) {\n\n\t\t\t// vertex region of C; barycentric coords (0, 0, 1)\n\t\t\treturn target.copy( c );\n\n\t\t}\n\n\t\tconst vb = d5 * d2 - d1 * d6;\n\t\tif ( vb <= 0 && d2 >= 0 && d6 <= 0 ) {\n\n\t\t\tw = d2 / ( d2 - d6 );\n\t\t\t// edge region of AC; barycentric coords (1-w, 0, w)\n\t\t\treturn target.copy( a ).addScaledVector( _vac, w );\n\n\t\t}\n\n\t\tconst va = d3 * d6 - d5 * d4;\n\t\tif ( va <= 0 && ( d4 - d3 ) >= 0 && ( d5 - d6 ) >= 0 ) {\n\n\t\t\t_vbc.subVectors( c, b );\n\t\t\tw = ( d4 - d3 ) / ( ( d4 - d3 ) + ( d5 - d6 ) );\n\t\t\t// edge region of BC; barycentric coords (0, 1-w, w)\n\t\t\treturn target.copy( b ).addScaledVector( _vbc, w ); // edge region of BC\n\n\t\t}\n\n\t\t// face region\n\t\tconst denom = 1 / ( va + vb + vc );\n\t\t// u = va * denom\n\t\tv = vb * denom;\n\t\tw = vc * denom;\n\n\t\treturn target.copy( a ).addScaledVector( _vab, v ).addScaledVector( _vac, w );\n\n\t}\n\n\tequals( triangle ) {\n\n\t\treturn triangle.a.equals( this.a ) && triangle.b.equals( this.b ) && triangle.c.equals( this.c );\n\n\t}\n\n}\n\nlet materialId = 0;\n\nclass Material extends EventDispatcher {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tObject.defineProperty( this, 'id', { value: materialId ++ } );\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.name = '';\n\t\tthis.type = 'Material';\n\n\t\tthis.fog = true;\n\n\t\tthis.blending = NormalBlending;\n\t\tthis.side = FrontSide;\n\t\tthis.vertexColors = false;\n\n\t\tthis.opacity = 1;\n\t\tthis.transparent = false;\n\n\t\tthis.blendSrc = SrcAlphaFactor;\n\t\tthis.blendDst = OneMinusSrcAlphaFactor;\n\t\tthis.blendEquation = AddEquation;\n\t\tthis.blendSrcAlpha = null;\n\t\tthis.blendDstAlpha = null;\n\t\tthis.blendEquationAlpha = null;\n\n\t\tthis.depthFunc = LessEqualDepth;\n\t\tthis.depthTest = true;\n\t\tthis.depthWrite = true;\n\n\t\tthis.stencilWriteMask = 0xff;\n\t\tthis.stencilFunc = AlwaysStencilFunc;\n\t\tthis.stencilRef = 0;\n\t\tthis.stencilFuncMask = 0xff;\n\t\tthis.stencilFail = KeepStencilOp;\n\t\tthis.stencilZFail = KeepStencilOp;\n\t\tthis.stencilZPass = KeepStencilOp;\n\t\tthis.stencilWrite = false;\n\n\t\tthis.clippingPlanes = null;\n\t\tthis.clipIntersection = false;\n\t\tthis.clipShadows = false;\n\n\t\tthis.shadowSide = null;\n\n\t\tthis.colorWrite = true;\n\n\t\tthis.precision = null; // override the renderer's default precision for this material\n\n\t\tthis.polygonOffset = false;\n\t\tthis.polygonOffsetFactor = 0;\n\t\tthis.polygonOffsetUnits = 0;\n\n\t\tthis.dithering = false;\n\n\t\tthis.alphaToCoverage = false;\n\t\tthis.premultipliedAlpha = false;\n\n\t\tthis.visible = true;\n\n\t\tthis.toneMapped = true;\n\n\t\tthis.userData = {};\n\n\t\tthis.version = 0;\n\n\t\tthis._alphaTest = 0;\n\n\t}\n\n\tget alphaTest() {\n\n\t\treturn this._alphaTest;\n\n\t}\n\n\tset alphaTest( value ) {\n\n\t\tif ( this._alphaTest > 0 !== value > 0 ) {\n\n\t\t\tthis.version ++;\n\n\t\t}\n\n\t\tthis._alphaTest = value;\n\n\t}\n\n\tonBuild( /* shaderobject, renderer */ ) {}\n\n\tonBeforeRender( /* renderer, scene, camera, geometry, object, group */ ) {}\n\n\tonBeforeCompile( /* shaderobject, renderer */ ) {}\n\n\tcustomProgramCacheKey() {\n\n\t\treturn this.onBeforeCompile.toString();\n\n\t}\n\n\tsetValues( values ) {\n\n\t\tif ( values === undefined ) return;\n\n\t\tfor ( const key in values ) {\n\n\t\t\tconst newValue = values[ key ];\n\n\t\t\tif ( newValue === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.Material: \\'' + key + '\\' parameter is undefined.' );\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\t// for backward compatability if shading is set in the constructor\n\t\t\tif ( key === 'shading' ) {\n\n\t\t\t\tconsole.warn( 'THREE.' + this.type + ': .shading has been removed. Use the boolean .flatShading instead.' );\n\t\t\t\tthis.flatShading = ( newValue === FlatShading ) ? true : false;\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\tconst currentValue = this[ key ];\n\n\t\t\tif ( currentValue === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.' + this.type + ': \\'' + key + '\\' is not a property of this material.' );\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\tif ( currentValue && currentValue.isColor ) {\n\n\t\t\t\tcurrentValue.set( newValue );\n\n\t\t\t} else if ( ( currentValue && currentValue.isVector3 ) && ( newValue && newValue.isVector3 ) ) {\n\n\t\t\t\tcurrentValue.copy( newValue );\n\n\t\t\t} else {\n\n\t\t\t\tthis[ key ] = newValue;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst isRootObject = ( meta === undefined || typeof meta === 'string' );\n\n\t\tif ( isRootObject ) {\n\n\t\t\tmeta = {\n\t\t\t\ttextures: {},\n\t\t\t\timages: {}\n\t\t\t};\n\n\t\t}\n\n\t\tconst data = {\n\t\t\tmetadata: {\n\t\t\t\tversion: 4.5,\n\t\t\t\ttype: 'Material',\n\t\t\t\tgenerator: 'Material.toJSON'\n\t\t\t}\n\t\t};\n\n\t\t// standard Material serialization\n\t\tdata.uuid = this.uuid;\n\t\tdata.type = this.type;\n\n\t\tif ( this.name !== '' ) data.name = this.name;\n\n\t\tif ( this.color && this.color.isColor ) data.color = this.color.getHex();\n\n\t\tif ( this.roughness !== undefined ) data.roughness = this.roughness;\n\t\tif ( this.metalness !== undefined ) data.metalness = this.metalness;\n\n\t\tif ( this.sheen !== undefined ) data.sheen = this.sheen;\n\t\tif ( this.sheenColor && this.sheenColor.isColor ) data.sheenColor = this.sheenColor.getHex();\n\t\tif ( this.sheenRoughness !== undefined ) data.sheenRoughness = this.sheenRoughness;\n\t\tif ( this.emissive && this.emissive.isColor ) data.emissive = this.emissive.getHex();\n\t\tif ( this.emissiveIntensity && this.emissiveIntensity !== 1 ) data.emissiveIntensity = this.emissiveIntensity;\n\n\t\tif ( this.specular && this.specular.isColor ) data.specular = this.specular.getHex();\n\t\tif ( this.specularIntensity !== undefined ) data.specularIntensity = this.specularIntensity;\n\t\tif ( this.specularColor && this.specularColor.isColor ) data.specularColor = this.specularColor.getHex();\n\t\tif ( this.shininess !== undefined ) data.shininess = this.shininess;\n\t\tif ( this.clearcoat !== undefined ) data.clearcoat = this.clearcoat;\n\t\tif ( this.clearcoatRoughness !== undefined ) data.clearcoatRoughness = this.clearcoatRoughness;\n\n\t\tif ( this.clearcoatMap && this.clearcoatMap.isTexture ) {\n\n\t\t\tdata.clearcoatMap = this.clearcoatMap.toJSON( meta ).uuid;\n\n\t\t}\n\n\t\tif ( this.clearcoatRoughnessMap && this.clearcoatRoughnessMap.isTexture ) {\n\n\t\t\tdata.clearcoatRoughnessMap = this.clearcoatRoughnessMap.toJSON( meta ).uuid;\n\n\t\t}\n\n\t\tif ( this.clearcoatNormalMap && this.clearcoatNormalMap.isTexture ) {\n\n\t\t\tdata.clearcoatNormalMap = this.clearcoatNormalMap.toJSON( meta ).uuid;\n\t\t\tdata.clearcoatNormalScale = this.clearcoatNormalScale.toArray();\n\n\t\t}\n\n\t\tif ( this.map && this.map.isTexture ) data.map = this.map.toJSON( meta ).uuid;\n\t\tif ( this.matcap && this.matcap.isTexture ) data.matcap = this.matcap.toJSON( meta ).uuid;\n\t\tif ( this.alphaMap && this.alphaMap.isTexture ) data.alphaMap = this.alphaMap.toJSON( meta ).uuid;\n\n\t\tif ( this.lightMap && this.lightMap.isTexture ) {\n\n\t\t\tdata.lightMap = this.lightMap.toJSON( meta ).uuid;\n\t\t\tdata.lightMapIntensity = this.lightMapIntensity;\n\n\t\t}\n\n\t\tif ( this.aoMap && this.aoMap.isTexture ) {\n\n\t\t\tdata.aoMap = this.aoMap.toJSON( meta ).uuid;\n\t\t\tdata.aoMapIntensity = this.aoMapIntensity;\n\n\t\t}\n\n\t\tif ( this.bumpMap && this.bumpMap.isTexture ) {\n\n\t\t\tdata.bumpMap = this.bumpMap.toJSON( meta ).uuid;\n\t\t\tdata.bumpScale = this.bumpScale;\n\n\t\t}\n\n\t\tif ( this.normalMap && this.normalMap.isTexture ) {\n\n\t\t\tdata.normalMap = this.normalMap.toJSON( meta ).uuid;\n\t\t\tdata.normalMapType = this.normalMapType;\n\t\t\tdata.normalScale = this.normalScale.toArray();\n\n\t\t}\n\n\t\tif ( this.displacementMap && this.displacementMap.isTexture ) {\n\n\t\t\tdata.displacementMap = this.displacementMap.toJSON( meta ).uuid;\n\t\t\tdata.displacementScale = this.displacementScale;\n\t\t\tdata.displacementBias = this.displacementBias;\n\n\t\t}\n\n\t\tif ( this.roughnessMap && this.roughnessMap.isTexture ) data.roughnessMap = this.roughnessMap.toJSON( meta ).uuid;\n\t\tif ( this.metalnessMap && this.metalnessMap.isTexture ) data.metalnessMap = this.metalnessMap.toJSON( meta ).uuid;\n\n\t\tif ( this.emissiveMap && this.emissiveMap.isTexture ) data.emissiveMap = this.emissiveMap.toJSON( meta ).uuid;\n\t\tif ( this.specularMap && this.specularMap.isTexture ) data.specularMap = this.specularMap.toJSON( meta ).uuid;\n\t\tif ( this.specularIntensityMap && this.specularIntensityMap.isTexture ) data.specularIntensityMap = this.specularIntensityMap.toJSON( meta ).uuid;\n\t\tif ( this.specularColorMap && this.specularColorMap.isTexture ) data.specularColorMap = this.specularColorMap.toJSON( meta ).uuid;\n\n\t\tif ( this.envMap && this.envMap.isTexture ) {\n\n\t\t\tdata.envMap = this.envMap.toJSON( meta ).uuid;\n\n\t\t\tif ( this.combine !== undefined ) data.combine = this.combine;\n\n\t\t}\n\n\t\tif ( this.envMapIntensity !== undefined ) data.envMapIntensity = this.envMapIntensity;\n\t\tif ( this.reflectivity !== undefined ) data.reflectivity = this.reflectivity;\n\t\tif ( this.refractionRatio !== undefined ) data.refractionRatio = this.refractionRatio;\n\n\t\tif ( this.gradientMap && this.gradientMap.isTexture ) {\n\n\t\t\tdata.gradientMap = this.gradientMap.toJSON( meta ).uuid;\n\n\t\t}\n\n\t\tif ( this.transmission !== undefined ) data.transmission = this.transmission;\n\t\tif ( this.transmissionMap && this.transmissionMap.isTexture ) data.transmissionMap = this.transmissionMap.toJSON( meta ).uuid;\n\t\tif ( this.thickness !== undefined ) data.thickness = this.thickness;\n\t\tif ( this.thicknessMap && this.thicknessMap.isTexture ) data.thicknessMap = this.thicknessMap.toJSON( meta ).uuid;\n\t\tif ( this.attenuationDistance !== undefined ) data.attenuationDistance = this.attenuationDistance;\n\t\tif ( this.attenuationColor !== undefined ) data.attenuationColor = this.attenuationColor.getHex();\n\n\t\tif ( this.size !== undefined ) data.size = this.size;\n\t\tif ( this.shadowSide !== null ) data.shadowSide = this.shadowSide;\n\t\tif ( this.sizeAttenuation !== undefined ) data.sizeAttenuation = this.sizeAttenuation;\n\n\t\tif ( this.blending !== NormalBlending ) data.blending = this.blending;\n\t\tif ( this.side !== FrontSide ) data.side = this.side;\n\t\tif ( this.vertexColors ) data.vertexColors = true;\n\n\t\tif ( this.opacity < 1 ) data.opacity = this.opacity;\n\t\tif ( this.transparent === true ) data.transparent = this.transparent;\n\n\t\tdata.depthFunc = this.depthFunc;\n\t\tdata.depthTest = this.depthTest;\n\t\tdata.depthWrite = this.depthWrite;\n\t\tdata.colorWrite = this.colorWrite;\n\n\t\tdata.stencilWrite = this.stencilWrite;\n\t\tdata.stencilWriteMask = this.stencilWriteMask;\n\t\tdata.stencilFunc = this.stencilFunc;\n\t\tdata.stencilRef = this.stencilRef;\n\t\tdata.stencilFuncMask = this.stencilFuncMask;\n\t\tdata.stencilFail = this.stencilFail;\n\t\tdata.stencilZFail = this.stencilZFail;\n\t\tdata.stencilZPass = this.stencilZPass;\n\n\t\t// rotation (SpriteMaterial)\n\t\tif ( this.rotation !== undefined && this.rotation !== 0 ) data.rotation = this.rotation;\n\n\t\tif ( this.polygonOffset === true ) data.polygonOffset = true;\n\t\tif ( this.polygonOffsetFactor !== 0 ) data.polygonOffsetFactor = this.polygonOffsetFactor;\n\t\tif ( this.polygonOffsetUnits !== 0 ) data.polygonOffsetUnits = this.polygonOffsetUnits;\n\n\t\tif ( this.linewidth !== undefined && this.linewidth !== 1 ) data.linewidth = this.linewidth;\n\t\tif ( this.dashSize !== undefined ) data.dashSize = this.dashSize;\n\t\tif ( this.gapSize !== undefined ) data.gapSize = this.gapSize;\n\t\tif ( this.scale !== undefined ) data.scale = this.scale;\n\n\t\tif ( this.dithering === true ) data.dithering = true;\n\n\t\tif ( this.alphaTest > 0 ) data.alphaTest = this.alphaTest;\n\t\tif ( this.alphaToCoverage === true ) data.alphaToCoverage = this.alphaToCoverage;\n\t\tif ( this.premultipliedAlpha === true ) data.premultipliedAlpha = this.premultipliedAlpha;\n\n\t\tif ( this.wireframe === true ) data.wireframe = this.wireframe;\n\t\tif ( this.wireframeLinewidth > 1 ) data.wireframeLinewidth = this.wireframeLinewidth;\n\t\tif ( this.wireframeLinecap !== 'round' ) data.wireframeLinecap = this.wireframeLinecap;\n\t\tif ( this.wireframeLinejoin !== 'round' ) data.wireframeLinejoin = this.wireframeLinejoin;\n\n\t\tif ( this.flatShading === true ) data.flatShading = this.flatShading;\n\n\t\tif ( this.visible === false ) data.visible = false;\n\n\t\tif ( this.toneMapped === false ) data.toneMapped = false;\n\n\t\tif ( JSON.stringify( this.userData ) !== '{}' ) data.userData = this.userData;\n\n\t\t// TODO: Copied from Object3D.toJSON\n\n\t\tfunction extractFromCache( cache ) {\n\n\t\t\tconst values = [];\n\n\t\t\tfor ( const key in cache ) {\n\n\t\t\t\tconst data = cache[ key ];\n\t\t\t\tdelete data.metadata;\n\t\t\t\tvalues.push( data );\n\n\t\t\t}\n\n\t\t\treturn values;\n\n\t\t}\n\n\t\tif ( isRootObject ) {\n\n\t\t\tconst textures = extractFromCache( meta.textures );\n\t\t\tconst images = extractFromCache( meta.images );\n\n\t\t\tif ( textures.length > 0 ) data.textures = textures;\n\t\t\tif ( images.length > 0 ) data.images = images;\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.name = source.name;\n\n\t\tthis.fog = source.fog;\n\n\t\tthis.blending = source.blending;\n\t\tthis.side = source.side;\n\t\tthis.vertexColors = source.vertexColors;\n\n\t\tthis.opacity = source.opacity;\n\t\tthis.transparent = source.transparent;\n\n\t\tthis.blendSrc = source.blendSrc;\n\t\tthis.blendDst = source.blendDst;\n\t\tthis.blendEquation = source.blendEquation;\n\t\tthis.blendSrcAlpha = source.blendSrcAlpha;\n\t\tthis.blendDstAlpha = source.blendDstAlpha;\n\t\tthis.blendEquationAlpha = source.blendEquationAlpha;\n\n\t\tthis.depthFunc = source.depthFunc;\n\t\tthis.depthTest = source.depthTest;\n\t\tthis.depthWrite = source.depthWrite;\n\n\t\tthis.stencilWriteMask = source.stencilWriteMask;\n\t\tthis.stencilFunc = source.stencilFunc;\n\t\tthis.stencilRef = source.stencilRef;\n\t\tthis.stencilFuncMask = source.stencilFuncMask;\n\t\tthis.stencilFail = source.stencilFail;\n\t\tthis.stencilZFail = source.stencilZFail;\n\t\tthis.stencilZPass = source.stencilZPass;\n\t\tthis.stencilWrite = source.stencilWrite;\n\n\t\tconst srcPlanes = source.clippingPlanes;\n\t\tlet dstPlanes = null;\n\n\t\tif ( srcPlanes !== null ) {\n\n\t\t\tconst n = srcPlanes.length;\n\t\t\tdstPlanes = new Array( n );\n\n\t\t\tfor ( let i = 0; i !== n; ++ i ) {\n\n\t\t\t\tdstPlanes[ i ] = srcPlanes[ i ].clone();\n\n\t\t\t}\n\n\t\t}\n\n\t\tthis.clippingPlanes = dstPlanes;\n\t\tthis.clipIntersection = source.clipIntersection;\n\t\tthis.clipShadows = source.clipShadows;\n\n\t\tthis.shadowSide = source.shadowSide;\n\n\t\tthis.colorWrite = source.colorWrite;\n\n\t\tthis.precision = source.precision;\n\n\t\tthis.polygonOffset = source.polygonOffset;\n\t\tthis.polygonOffsetFactor = source.polygonOffsetFactor;\n\t\tthis.polygonOffsetUnits = source.polygonOffsetUnits;\n\n\t\tthis.dithering = source.dithering;\n\n\t\tthis.alphaTest = source.alphaTest;\n\t\tthis.alphaToCoverage = source.alphaToCoverage;\n\t\tthis.premultipliedAlpha = source.premultipliedAlpha;\n\n\t\tthis.visible = source.visible;\n\n\t\tthis.toneMapped = source.toneMapped;\n\n\t\tthis.userData = JSON.parse( JSON.stringify( source.userData ) );\n\n\t\treturn this;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.dispatchEvent( { type: 'dispose' } );\n\n\t}\n\n\tset needsUpdate( value ) {\n\n\t\tif ( value === true ) this.version ++;\n\n\t}\n\n}\n\nMaterial.prototype.isMaterial = true;\n\nMaterial.fromType = function ( /*type*/ ) {\n\n\t// TODO: Behavior added in Materials.js\n\n\treturn null;\n\n};\n\n/**\n * parameters = {\n *  color: <hex>,\n *  opacity: <float>,\n *  map: new THREE.Texture( <Image> ),\n *\n *  lightMap: new THREE.Texture( <Image> ),\n *  lightMapIntensity: <float>\n *\n *  aoMap: new THREE.Texture( <Image> ),\n *  aoMapIntensity: <float>\n *\n *  specularMap: new THREE.Texture( <Image> ),\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  envMap: new THREE.CubeTexture( [posx, negx, posy, negy, posz, negz] ),\n *  combine: THREE.Multiply,\n *  reflectivity: <float>,\n *  refractionRatio: <float>,\n *\n *  depthTest: <bool>,\n *  depthWrite: <bool>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>,\n * }\n */\n\nclass MeshBasicMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'MeshBasicMaterial';\n\n\t\tthis.color = new Color( 0xffffff ); // emissive\n\n\t\tthis.map = null;\n\n\t\tthis.lightMap = null;\n\t\tthis.lightMapIntensity = 1.0;\n\n\t\tthis.aoMap = null;\n\t\tthis.aoMapIntensity = 1.0;\n\n\t\tthis.specularMap = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.envMap = null;\n\t\tthis.combine = MultiplyOperation;\n\t\tthis.reflectivity = 1;\n\t\tthis.refractionRatio = 0.98;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\t\tthis.wireframeLinecap = 'round';\n\t\tthis.wireframeLinejoin = 'round';\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.map = source.map;\n\n\t\tthis.lightMap = source.lightMap;\n\t\tthis.lightMapIntensity = source.lightMapIntensity;\n\n\t\tthis.aoMap = source.aoMap;\n\t\tthis.aoMapIntensity = source.aoMapIntensity;\n\n\t\tthis.specularMap = source.specularMap;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.envMap = source.envMap;\n\t\tthis.combine = source.combine;\n\t\tthis.reflectivity = source.reflectivity;\n\t\tthis.refractionRatio = source.refractionRatio;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\t\tthis.wireframeLinecap = source.wireframeLinecap;\n\t\tthis.wireframeLinejoin = source.wireframeLinejoin;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshBasicMaterial.prototype.isMeshBasicMaterial = true;\n\nconst _vector$9 = /*@__PURE__*/ new Vector3();\nconst _vector2$1 = /*@__PURE__*/ new Vector2();\n\nclass BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tif ( Array.isArray( array ) ) {\n\n\t\t\tthrow new TypeError( 'THREE.BufferAttribute: array should be a Typed Array.' );\n\n\t\t}\n\n\t\tthis.name = '';\n\n\t\tthis.array = array;\n\t\tthis.itemSize = itemSize;\n\t\tthis.count = array !== undefined ? array.length / itemSize : 0;\n\t\tthis.normalized = normalized === true;\n\n\t\tthis.usage = StaticDrawUsage;\n\t\tthis.updateRange = { offset: 0, count: - 1 };\n\n\t\tthis.version = 0;\n\n\t}\n\n\tonUploadCallback() {}\n\n\tset needsUpdate( value ) {\n\n\t\tif ( value === true ) this.version ++;\n\n\t}\n\n\tsetUsage( value ) {\n\n\t\tthis.usage = value;\n\n\t\treturn this;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.name = source.name;\n\t\tthis.array = new source.array.constructor( source.array );\n\t\tthis.itemSize = source.itemSize;\n\t\tthis.count = source.count;\n\t\tthis.normalized = source.normalized;\n\n\t\tthis.usage = source.usage;\n\n\t\treturn this;\n\n\t}\n\n\tcopyAt( index1, attribute, index2 ) {\n\n\t\tindex1 *= this.itemSize;\n\t\tindex2 *= attribute.itemSize;\n\n\t\tfor ( let i = 0, l = this.itemSize; i < l; i ++ ) {\n\n\t\t\tthis.array[ index1 + i ] = attribute.array[ index2 + i ];\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tcopyArray( array ) {\n\n\t\tthis.array.set( array );\n\n\t\treturn this;\n\n\t}\n\n\tcopyColorsArray( colors ) {\n\n\t\tconst array = this.array;\n\t\tlet offset = 0;\n\n\t\tfor ( let i = 0, l = colors.length; i < l; i ++ ) {\n\n\t\t\tlet color = colors[ i ];\n\n\t\t\tif ( color === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.BufferAttribute.copyColorsArray(): color is undefined', i );\n\t\t\t\tcolor = new Color();\n\n\t\t\t}\n\n\t\t\tarray[ offset ++ ] = color.r;\n\t\t\tarray[ offset ++ ] = color.g;\n\t\t\tarray[ offset ++ ] = color.b;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tcopyVector2sArray( vectors ) {\n\n\t\tconst array = this.array;\n\t\tlet offset = 0;\n\n\t\tfor ( let i = 0, l = vectors.length; i < l; i ++ ) {\n\n\t\t\tlet vector = vectors[ i ];\n\n\t\t\tif ( vector === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.BufferAttribute.copyVector2sArray(): vector is undefined', i );\n\t\t\t\tvector = new Vector2();\n\n\t\t\t}\n\n\t\t\tarray[ offset ++ ] = vector.x;\n\t\t\tarray[ offset ++ ] = vector.y;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tcopyVector3sArray( vectors ) {\n\n\t\tconst array = this.array;\n\t\tlet offset = 0;\n\n\t\tfor ( let i = 0, l = vectors.length; i < l; i ++ ) {\n\n\t\t\tlet vector = vectors[ i ];\n\n\t\t\tif ( vector === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.BufferAttribute.copyVector3sArray(): vector is undefined', i );\n\t\t\t\tvector = new Vector3();\n\n\t\t\t}\n\n\t\t\tarray[ offset ++ ] = vector.x;\n\t\t\tarray[ offset ++ ] = vector.y;\n\t\t\tarray[ offset ++ ] = vector.z;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tcopyVector4sArray( vectors ) {\n\n\t\tconst array = this.array;\n\t\tlet offset = 0;\n\n\t\tfor ( let i = 0, l = vectors.length; i < l; i ++ ) {\n\n\t\t\tlet vector = vectors[ i ];\n\n\t\t\tif ( vector === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.BufferAttribute.copyVector4sArray(): vector is undefined', i );\n\t\t\t\tvector = new Vector4();\n\n\t\t\t}\n\n\t\t\tarray[ offset ++ ] = vector.x;\n\t\t\tarray[ offset ++ ] = vector.y;\n\t\t\tarray[ offset ++ ] = vector.z;\n\t\t\tarray[ offset ++ ] = vector.w;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tapplyMatrix3( m ) {\n\n\t\tif ( this.itemSize === 2 ) {\n\n\t\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t\t_vector2$1.fromBufferAttribute( this, i );\n\t\t\t\t_vector2$1.applyMatrix3( m );\n\n\t\t\t\tthis.setXY( i, _vector2$1.x, _vector2$1.y );\n\n\t\t\t}\n\n\t\t} else if ( this.itemSize === 3 ) {\n\n\t\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t\t_vector$9.fromBufferAttribute( this, i );\n\t\t\t\t_vector$9.applyMatrix3( m );\n\n\t\t\t\tthis.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tapplyMatrix4( m ) {\n\n\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t_vector$9.x = this.getX( i );\n\t\t\t_vector$9.y = this.getY( i );\n\t\t\t_vector$9.z = this.getZ( i );\n\n\t\t\t_vector$9.applyMatrix4( m );\n\n\t\t\tthis.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tapplyNormalMatrix( m ) {\n\n\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t_vector$9.x = this.getX( i );\n\t\t\t_vector$9.y = this.getY( i );\n\t\t\t_vector$9.z = this.getZ( i );\n\n\t\t\t_vector$9.applyNormalMatrix( m );\n\n\t\t\tthis.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttransformDirection( m ) {\n\n\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t_vector$9.x = this.getX( i );\n\t\t\t_vector$9.y = this.getY( i );\n\t\t\t_vector$9.z = this.getZ( i );\n\n\t\t\t_vector$9.transformDirection( m );\n\n\t\t\tthis.setXYZ( i, _vector$9.x, _vector$9.y, _vector$9.z );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tset( value, offset = 0 ) {\n\n\t\tthis.array.set( value, offset );\n\n\t\treturn this;\n\n\t}\n\n\tgetX( index ) {\n\n\t\treturn this.array[ index * this.itemSize ];\n\n\t}\n\n\tsetX( index, x ) {\n\n\t\tthis.array[ index * this.itemSize ] = x;\n\n\t\treturn this;\n\n\t}\n\n\tgetY( index ) {\n\n\t\treturn this.array[ index * this.itemSize + 1 ];\n\n\t}\n\n\tsetY( index, y ) {\n\n\t\tthis.array[ index * this.itemSize + 1 ] = y;\n\n\t\treturn this;\n\n\t}\n\n\tgetZ( index ) {\n\n\t\treturn this.array[ index * this.itemSize + 2 ];\n\n\t}\n\n\tsetZ( index, z ) {\n\n\t\tthis.array[ index * this.itemSize + 2 ] = z;\n\n\t\treturn this;\n\n\t}\n\n\tgetW( index ) {\n\n\t\treturn this.array[ index * this.itemSize + 3 ];\n\n\t}\n\n\tsetW( index, w ) {\n\n\t\tthis.array[ index * this.itemSize + 3 ] = w;\n\n\t\treturn this;\n\n\t}\n\n\tsetXY( index, x, y ) {\n\n\t\tindex *= this.itemSize;\n\n\t\tthis.array[ index + 0 ] = x;\n\t\tthis.array[ index + 1 ] = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetXYZ( index, x, y, z ) {\n\n\t\tindex *= this.itemSize;\n\n\t\tthis.array[ index + 0 ] = x;\n\t\tthis.array[ index + 1 ] = y;\n\t\tthis.array[ index + 2 ] = z;\n\n\t\treturn this;\n\n\t}\n\n\tsetXYZW( index, x, y, z, w ) {\n\n\t\tindex *= this.itemSize;\n\n\t\tthis.array[ index + 0 ] = x;\n\t\tthis.array[ index + 1 ] = y;\n\t\tthis.array[ index + 2 ] = z;\n\t\tthis.array[ index + 3 ] = w;\n\n\t\treturn this;\n\n\t}\n\n\tonUpload( callback ) {\n\n\t\tthis.onUploadCallback = callback;\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this.array, this.itemSize ).copy( this );\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = {\n\t\t\titemSize: this.itemSize,\n\t\t\ttype: this.array.constructor.name,\n\t\t\tarray: Array.prototype.slice.call( this.array ),\n\t\t\tnormalized: this.normalized\n\t\t};\n\n\t\tif ( this.name !== '' ) data.name = this.name;\n\t\tif ( this.usage !== StaticDrawUsage ) data.usage = this.usage;\n\t\tif ( this.updateRange.offset !== 0 || this.updateRange.count !== - 1 ) data.updateRange = this.updateRange;\n\n\t\treturn data;\n\n\t}\n\n}\n\nBufferAttribute.prototype.isBufferAttribute = true;\n\n//\n\nclass Int8BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Int8Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Uint8BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Uint8Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Uint8ClampedBufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Uint8ClampedArray( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Int16BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Int16Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Uint16BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Uint16Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Int32BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Int32Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Uint32BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Uint32Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Float16BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Uint16Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nFloat16BufferAttribute.prototype.isFloat16BufferAttribute = true;\n\nclass Float32BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Float32Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nclass Float64BufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized ) {\n\n\t\tsuper( new Float64Array( array ), itemSize, normalized );\n\n\t}\n\n}\n\nlet _id$1 = 0;\n\nconst _m1 = /*@__PURE__*/ new Matrix4();\nconst _obj = /*@__PURE__*/ new Object3D();\nconst _offset = /*@__PURE__*/ new Vector3();\nconst _box$1 = /*@__PURE__*/ new Box3();\nconst _boxMorphTargets = /*@__PURE__*/ new Box3();\nconst _vector$8 = /*@__PURE__*/ new Vector3();\n\nclass BufferGeometry extends EventDispatcher {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tObject.defineProperty( this, 'id', { value: _id$1 ++ } );\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.name = '';\n\t\tthis.type = 'BufferGeometry';\n\n\t\tthis.index = null;\n\t\tthis.attributes = {};\n\n\t\tthis.morphAttributes = {};\n\t\tthis.morphTargetsRelative = false;\n\n\t\tthis.groups = [];\n\n\t\tthis.boundingBox = null;\n\t\tthis.boundingSphere = null;\n\n\t\tthis.drawRange = { start: 0, count: Infinity };\n\n\t\tthis.userData = {};\n\n\t}\n\n\tgetIndex() {\n\n\t\treturn this.index;\n\n\t}\n\n\tsetIndex( index ) {\n\n\t\tif ( Array.isArray( index ) ) {\n\n\t\t\tthis.index = new ( arrayNeedsUint32( index ) ? Uint32BufferAttribute : Uint16BufferAttribute )( index, 1 );\n\n\t\t} else {\n\n\t\t\tthis.index = index;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetAttribute( name ) {\n\n\t\treturn this.attributes[ name ];\n\n\t}\n\n\tsetAttribute( name, attribute ) {\n\n\t\tthis.attributes[ name ] = attribute;\n\n\t\treturn this;\n\n\t}\n\n\tdeleteAttribute( name ) {\n\n\t\tdelete this.attributes[ name ];\n\n\t\treturn this;\n\n\t}\n\n\thasAttribute( name ) {\n\n\t\treturn this.attributes[ name ] !== undefined;\n\n\t}\n\n\taddGroup( start, count, materialIndex = 0 ) {\n\n\t\tthis.groups.push( {\n\n\t\t\tstart: start,\n\t\t\tcount: count,\n\t\t\tmaterialIndex: materialIndex\n\n\t\t} );\n\n\t}\n\n\tclearGroups() {\n\n\t\tthis.groups = [];\n\n\t}\n\n\tsetDrawRange( start, count ) {\n\n\t\tthis.drawRange.start = start;\n\t\tthis.drawRange.count = count;\n\n\t}\n\n\tapplyMatrix4( matrix ) {\n\n\t\tconst position = this.attributes.position;\n\n\t\tif ( position !== undefined ) {\n\n\t\t\tposition.applyMatrix4( matrix );\n\n\t\t\tposition.needsUpdate = true;\n\n\t\t}\n\n\t\tconst normal = this.attributes.normal;\n\n\t\tif ( normal !== undefined ) {\n\n\t\t\tconst normalMatrix = new Matrix3().getNormalMatrix( matrix );\n\n\t\t\tnormal.applyNormalMatrix( normalMatrix );\n\n\t\t\tnormal.needsUpdate = true;\n\n\t\t}\n\n\t\tconst tangent = this.attributes.tangent;\n\n\t\tif ( tangent !== undefined ) {\n\n\t\t\ttangent.transformDirection( matrix );\n\n\t\t\ttangent.needsUpdate = true;\n\n\t\t}\n\n\t\tif ( this.boundingBox !== null ) {\n\n\t\t\tthis.computeBoundingBox();\n\n\t\t}\n\n\t\tif ( this.boundingSphere !== null ) {\n\n\t\t\tthis.computeBoundingSphere();\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tapplyQuaternion( q ) {\n\n\t\t_m1.makeRotationFromQuaternion( q );\n\n\t\tthis.applyMatrix4( _m1 );\n\n\t\treturn this;\n\n\t}\n\n\trotateX( angle ) {\n\n\t\t// rotate geometry around world x-axis\n\n\t\t_m1.makeRotationX( angle );\n\n\t\tthis.applyMatrix4( _m1 );\n\n\t\treturn this;\n\n\t}\n\n\trotateY( angle ) {\n\n\t\t// rotate geometry around world y-axis\n\n\t\t_m1.makeRotationY( angle );\n\n\t\tthis.applyMatrix4( _m1 );\n\n\t\treturn this;\n\n\t}\n\n\trotateZ( angle ) {\n\n\t\t// rotate geometry around world z-axis\n\n\t\t_m1.makeRotationZ( angle );\n\n\t\tthis.applyMatrix4( _m1 );\n\n\t\treturn this;\n\n\t}\n\n\ttranslate( x, y, z ) {\n\n\t\t// translate geometry\n\n\t\t_m1.makeTranslation( x, y, z );\n\n\t\tthis.applyMatrix4( _m1 );\n\n\t\treturn this;\n\n\t}\n\n\tscale( x, y, z ) {\n\n\t\t// scale geometry\n\n\t\t_m1.makeScale( x, y, z );\n\n\t\tthis.applyMatrix4( _m1 );\n\n\t\treturn this;\n\n\t}\n\n\tlookAt( vector ) {\n\n\t\t_obj.lookAt( vector );\n\n\t\t_obj.updateMatrix();\n\n\t\tthis.applyMatrix4( _obj.matrix );\n\n\t\treturn this;\n\n\t}\n\n\tcenter() {\n\n\t\tthis.computeBoundingBox();\n\n\t\tthis.boundingBox.getCenter( _offset ).negate();\n\n\t\tthis.translate( _offset.x, _offset.y, _offset.z );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromPoints( points ) {\n\n\t\tconst position = [];\n\n\t\tfor ( let i = 0, l = points.length; i < l; i ++ ) {\n\n\t\t\tconst point = points[ i ];\n\t\t\tposition.push( point.x, point.y, point.z || 0 );\n\n\t\t}\n\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( position, 3 ) );\n\n\t\treturn this;\n\n\t}\n\n\tcomputeBoundingBox() {\n\n\t\tif ( this.boundingBox === null ) {\n\n\t\t\tthis.boundingBox = new Box3();\n\n\t\t}\n\n\t\tconst position = this.attributes.position;\n\t\tconst morphAttributesPosition = this.morphAttributes.position;\n\n\t\tif ( position && position.isGLBufferAttribute ) {\n\n\t\t\tconsole.error( 'THREE.BufferGeometry.computeBoundingBox(): GLBufferAttribute requires a manual bounding box. Alternatively set \"mesh.frustumCulled\" to \"false\".', this );\n\n\t\t\tthis.boundingBox.set(\n\t\t\t\tnew Vector3( - Infinity, - Infinity, - Infinity ),\n\t\t\t\tnew Vector3( + Infinity, + Infinity, + Infinity )\n\t\t\t);\n\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( position !== undefined ) {\n\n\t\t\tthis.boundingBox.setFromBufferAttribute( position );\n\n\t\t\t// process morph attributes if present\n\n\t\t\tif ( morphAttributesPosition ) {\n\n\t\t\t\tfor ( let i = 0, il = morphAttributesPosition.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst morphAttribute = morphAttributesPosition[ i ];\n\t\t\t\t\t_box$1.setFromBufferAttribute( morphAttribute );\n\n\t\t\t\t\tif ( this.morphTargetsRelative ) {\n\n\t\t\t\t\t\t_vector$8.addVectors( this.boundingBox.min, _box$1.min );\n\t\t\t\t\t\tthis.boundingBox.expandByPoint( _vector$8 );\n\n\t\t\t\t\t\t_vector$8.addVectors( this.boundingBox.max, _box$1.max );\n\t\t\t\t\t\tthis.boundingBox.expandByPoint( _vector$8 );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tthis.boundingBox.expandByPoint( _box$1.min );\n\t\t\t\t\t\tthis.boundingBox.expandByPoint( _box$1.max );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tthis.boundingBox.makeEmpty();\n\n\t\t}\n\n\t\tif ( isNaN( this.boundingBox.min.x ) || isNaN( this.boundingBox.min.y ) || isNaN( this.boundingBox.min.z ) ) {\n\n\t\t\tconsole.error( 'THREE.BufferGeometry.computeBoundingBox(): Computed min/max have NaN values. The \"position\" attribute is likely to have NaN values.', this );\n\n\t\t}\n\n\t}\n\n\tcomputeBoundingSphere() {\n\n\t\tif ( this.boundingSphere === null ) {\n\n\t\t\tthis.boundingSphere = new Sphere();\n\n\t\t}\n\n\t\tconst position = this.attributes.position;\n\t\tconst morphAttributesPosition = this.morphAttributes.position;\n\n\t\tif ( position && position.isGLBufferAttribute ) {\n\n\t\t\tconsole.error( 'THREE.BufferGeometry.computeBoundingSphere(): GLBufferAttribute requires a manual bounding sphere. Alternatively set \"mesh.frustumCulled\" to \"false\".', this );\n\n\t\t\tthis.boundingSphere.set( new Vector3(), Infinity );\n\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( position ) {\n\n\t\t\t// first, find the center of the bounding sphere\n\n\t\t\tconst center = this.boundingSphere.center;\n\n\t\t\t_box$1.setFromBufferAttribute( position );\n\n\t\t\t// process morph attributes if present\n\n\t\t\tif ( morphAttributesPosition ) {\n\n\t\t\t\tfor ( let i = 0, il = morphAttributesPosition.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst morphAttribute = morphAttributesPosition[ i ];\n\t\t\t\t\t_boxMorphTargets.setFromBufferAttribute( morphAttribute );\n\n\t\t\t\t\tif ( this.morphTargetsRelative ) {\n\n\t\t\t\t\t\t_vector$8.addVectors( _box$1.min, _boxMorphTargets.min );\n\t\t\t\t\t\t_box$1.expandByPoint( _vector$8 );\n\n\t\t\t\t\t\t_vector$8.addVectors( _box$1.max, _boxMorphTargets.max );\n\t\t\t\t\t\t_box$1.expandByPoint( _vector$8 );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t_box$1.expandByPoint( _boxMorphTargets.min );\n\t\t\t\t\t\t_box$1.expandByPoint( _boxMorphTargets.max );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t_box$1.getCenter( center );\n\n\t\t\t// second, try to find a boundingSphere with a radius smaller than the\n\t\t\t// boundingSphere of the boundingBox: sqrt(3) smaller in the best case\n\n\t\t\tlet maxRadiusSq = 0;\n\n\t\t\tfor ( let i = 0, il = position.count; i < il; i ++ ) {\n\n\t\t\t\t_vector$8.fromBufferAttribute( position, i );\n\n\t\t\t\tmaxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( _vector$8 ) );\n\n\t\t\t}\n\n\t\t\t// process morph attributes if present\n\n\t\t\tif ( morphAttributesPosition ) {\n\n\t\t\t\tfor ( let i = 0, il = morphAttributesPosition.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst morphAttribute = morphAttributesPosition[ i ];\n\t\t\t\t\tconst morphTargetsRelative = this.morphTargetsRelative;\n\n\t\t\t\t\tfor ( let j = 0, jl = morphAttribute.count; j < jl; j ++ ) {\n\n\t\t\t\t\t\t_vector$8.fromBufferAttribute( morphAttribute, j );\n\n\t\t\t\t\t\tif ( morphTargetsRelative ) {\n\n\t\t\t\t\t\t\t_offset.fromBufferAttribute( position, j );\n\t\t\t\t\t\t\t_vector$8.add( _offset );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tmaxRadiusSq = Math.max( maxRadiusSq, center.distanceToSquared( _vector$8 ) );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis.boundingSphere.radius = Math.sqrt( maxRadiusSq );\n\n\t\t\tif ( isNaN( this.boundingSphere.radius ) ) {\n\n\t\t\t\tconsole.error( 'THREE.BufferGeometry.computeBoundingSphere(): Computed radius is NaN. The \"position\" attribute is likely to have NaN values.', this );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tcomputeTangents() {\n\n\t\tconst index = this.index;\n\t\tconst attributes = this.attributes;\n\n\t\t// based on http://www.terathon.com/code/tangent.html\n\t\t// (per vertex tangents)\n\n\t\tif ( index === null ||\n\t\t\t attributes.position === undefined ||\n\t\t\t attributes.normal === undefined ||\n\t\t\t attributes.uv === undefined ) {\n\n\t\t\tconsole.error( 'THREE.BufferGeometry: .computeTangents() failed. Missing required attributes (index, position, normal or uv)' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tconst indices = index.array;\n\t\tconst positions = attributes.position.array;\n\t\tconst normals = attributes.normal.array;\n\t\tconst uvs = attributes.uv.array;\n\n\t\tconst nVertices = positions.length / 3;\n\n\t\tif ( this.hasAttribute( 'tangent' ) === false ) {\n\n\t\t\tthis.setAttribute( 'tangent', new BufferAttribute( new Float32Array( 4 * nVertices ), 4 ) );\n\n\t\t}\n\n\t\tconst tangents = this.getAttribute( 'tangent' ).array;\n\n\t\tconst tan1 = [], tan2 = [];\n\n\t\tfor ( let i = 0; i < nVertices; i ++ ) {\n\n\t\t\ttan1[ i ] = new Vector3();\n\t\t\ttan2[ i ] = new Vector3();\n\n\t\t}\n\n\t\tconst vA = new Vector3(),\n\t\t\tvB = new Vector3(),\n\t\t\tvC = new Vector3(),\n\n\t\t\tuvA = new Vector2(),\n\t\t\tuvB = new Vector2(),\n\t\t\tuvC = new Vector2(),\n\n\t\t\tsdir = new Vector3(),\n\t\t\ttdir = new Vector3();\n\n\t\tfunction handleTriangle( a, b, c ) {\n\n\t\t\tvA.fromArray( positions, a * 3 );\n\t\t\tvB.fromArray( positions, b * 3 );\n\t\t\tvC.fromArray( positions, c * 3 );\n\n\t\t\tuvA.fromArray( uvs, a * 2 );\n\t\t\tuvB.fromArray( uvs, b * 2 );\n\t\t\tuvC.fromArray( uvs, c * 2 );\n\n\t\t\tvB.sub( vA );\n\t\t\tvC.sub( vA );\n\n\t\t\tuvB.sub( uvA );\n\t\t\tuvC.sub( uvA );\n\n\t\t\tconst r = 1.0 / ( uvB.x * uvC.y - uvC.x * uvB.y );\n\n\t\t\t// silently ignore degenerate uv triangles having coincident or colinear vertices\n\n\t\t\tif ( ! isFinite( r ) ) return;\n\n\t\t\tsdir.copy( vB ).multiplyScalar( uvC.y ).addScaledVector( vC, - uvB.y ).multiplyScalar( r );\n\t\t\ttdir.copy( vC ).multiplyScalar( uvB.x ).addScaledVector( vB, - uvC.x ).multiplyScalar( r );\n\n\t\t\ttan1[ a ].add( sdir );\n\t\t\ttan1[ b ].add( sdir );\n\t\t\ttan1[ c ].add( sdir );\n\n\t\t\ttan2[ a ].add( tdir );\n\t\t\ttan2[ b ].add( tdir );\n\t\t\ttan2[ c ].add( tdir );\n\n\t\t}\n\n\t\tlet groups = this.groups;\n\n\t\tif ( groups.length === 0 ) {\n\n\t\t\tgroups = [ {\n\t\t\t\tstart: 0,\n\t\t\t\tcount: indices.length\n\t\t\t} ];\n\n\t\t}\n\n\t\tfor ( let i = 0, il = groups.length; i < il; ++ i ) {\n\n\t\t\tconst group = groups[ i ];\n\n\t\t\tconst start = group.start;\n\t\t\tconst count = group.count;\n\n\t\t\tfor ( let j = start, jl = start + count; j < jl; j += 3 ) {\n\n\t\t\t\thandleTriangle(\n\t\t\t\t\tindices[ j + 0 ],\n\t\t\t\t\tindices[ j + 1 ],\n\t\t\t\t\tindices[ j + 2 ]\n\t\t\t\t);\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst tmp = new Vector3(), tmp2 = new Vector3();\n\t\tconst n = new Vector3(), n2 = new Vector3();\n\n\t\tfunction handleVertex( v ) {\n\n\t\t\tn.fromArray( normals, v * 3 );\n\t\t\tn2.copy( n );\n\n\t\t\tconst t = tan1[ v ];\n\n\t\t\t// Gram-Schmidt orthogonalize\n\n\t\t\ttmp.copy( t );\n\t\t\ttmp.sub( n.multiplyScalar( n.dot( t ) ) ).normalize();\n\n\t\t\t// Calculate handedness\n\n\t\t\ttmp2.crossVectors( n2, t );\n\t\t\tconst test = tmp2.dot( tan2[ v ] );\n\t\t\tconst w = ( test < 0.0 ) ? - 1.0 : 1.0;\n\n\t\t\ttangents[ v * 4 ] = tmp.x;\n\t\t\ttangents[ v * 4 + 1 ] = tmp.y;\n\t\t\ttangents[ v * 4 + 2 ] = tmp.z;\n\t\t\ttangents[ v * 4 + 3 ] = w;\n\n\t\t}\n\n\t\tfor ( let i = 0, il = groups.length; i < il; ++ i ) {\n\n\t\t\tconst group = groups[ i ];\n\n\t\t\tconst start = group.start;\n\t\t\tconst count = group.count;\n\n\t\t\tfor ( let j = start, jl = start + count; j < jl; j += 3 ) {\n\n\t\t\t\thandleVertex( indices[ j + 0 ] );\n\t\t\t\thandleVertex( indices[ j + 1 ] );\n\t\t\t\thandleVertex( indices[ j + 2 ] );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tcomputeVertexNormals() {\n\n\t\tconst index = this.index;\n\t\tconst positionAttribute = this.getAttribute( 'position' );\n\n\t\tif ( positionAttribute !== undefined ) {\n\n\t\t\tlet normalAttribute = this.getAttribute( 'normal' );\n\n\t\t\tif ( normalAttribute === undefined ) {\n\n\t\t\t\tnormalAttribute = new BufferAttribute( new Float32Array( positionAttribute.count * 3 ), 3 );\n\t\t\t\tthis.setAttribute( 'normal', normalAttribute );\n\n\t\t\t} else {\n\n\t\t\t\t// reset existing normals to zero\n\n\t\t\t\tfor ( let i = 0, il = normalAttribute.count; i < il; i ++ ) {\n\n\t\t\t\t\tnormalAttribute.setXYZ( i, 0, 0, 0 );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tconst pA = new Vector3(), pB = new Vector3(), pC = new Vector3();\n\t\t\tconst nA = new Vector3(), nB = new Vector3(), nC = new Vector3();\n\t\t\tconst cb = new Vector3(), ab = new Vector3();\n\n\t\t\t// indexed elements\n\n\t\t\tif ( index ) {\n\n\t\t\t\tfor ( let i = 0, il = index.count; i < il; i += 3 ) {\n\n\t\t\t\t\tconst vA = index.getX( i + 0 );\n\t\t\t\t\tconst vB = index.getX( i + 1 );\n\t\t\t\t\tconst vC = index.getX( i + 2 );\n\n\t\t\t\t\tpA.fromBufferAttribute( positionAttribute, vA );\n\t\t\t\t\tpB.fromBufferAttribute( positionAttribute, vB );\n\t\t\t\t\tpC.fromBufferAttribute( positionAttribute, vC );\n\n\t\t\t\t\tcb.subVectors( pC, pB );\n\t\t\t\t\tab.subVectors( pA, pB );\n\t\t\t\t\tcb.cross( ab );\n\n\t\t\t\t\tnA.fromBufferAttribute( normalAttribute, vA );\n\t\t\t\t\tnB.fromBufferAttribute( normalAttribute, vB );\n\t\t\t\t\tnC.fromBufferAttribute( normalAttribute, vC );\n\n\t\t\t\t\tnA.add( cb );\n\t\t\t\t\tnB.add( cb );\n\t\t\t\t\tnC.add( cb );\n\n\t\t\t\t\tnormalAttribute.setXYZ( vA, nA.x, nA.y, nA.z );\n\t\t\t\t\tnormalAttribute.setXYZ( vB, nB.x, nB.y, nB.z );\n\t\t\t\t\tnormalAttribute.setXYZ( vC, nC.x, nC.y, nC.z );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\t// non-indexed elements (unconnected triangle soup)\n\n\t\t\t\tfor ( let i = 0, il = positionAttribute.count; i < il; i += 3 ) {\n\n\t\t\t\t\tpA.fromBufferAttribute( positionAttribute, i + 0 );\n\t\t\t\t\tpB.fromBufferAttribute( positionAttribute, i + 1 );\n\t\t\t\t\tpC.fromBufferAttribute( positionAttribute, i + 2 );\n\n\t\t\t\t\tcb.subVectors( pC, pB );\n\t\t\t\t\tab.subVectors( pA, pB );\n\t\t\t\t\tcb.cross( ab );\n\n\t\t\t\t\tnormalAttribute.setXYZ( i + 0, cb.x, cb.y, cb.z );\n\t\t\t\t\tnormalAttribute.setXYZ( i + 1, cb.x, cb.y, cb.z );\n\t\t\t\t\tnormalAttribute.setXYZ( i + 2, cb.x, cb.y, cb.z );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis.normalizeNormals();\n\n\t\t\tnormalAttribute.needsUpdate = true;\n\n\t\t}\n\n\t}\n\n\tmerge( geometry, offset ) {\n\n\t\tif ( ! ( geometry && geometry.isBufferGeometry ) ) {\n\n\t\t\tconsole.error( 'THREE.BufferGeometry.merge(): geometry not an instance of THREE.BufferGeometry.', geometry );\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( offset === undefined ) {\n\n\t\t\toffset = 0;\n\n\t\t\tconsole.warn(\n\t\t\t\t'THREE.BufferGeometry.merge(): Overwriting original geometry, starting at offset=0. '\n\t\t\t\t+ 'Use BufferGeometryUtils.mergeBufferGeometries() for lossless merge.'\n\t\t\t);\n\n\t\t}\n\n\t\tconst attributes = this.attributes;\n\n\t\tfor ( const key in attributes ) {\n\n\t\t\tif ( geometry.attributes[ key ] === undefined ) continue;\n\n\t\t\tconst attribute1 = attributes[ key ];\n\t\t\tconst attributeArray1 = attribute1.array;\n\n\t\t\tconst attribute2 = geometry.attributes[ key ];\n\t\t\tconst attributeArray2 = attribute2.array;\n\n\t\t\tconst attributeOffset = attribute2.itemSize * offset;\n\t\t\tconst length = Math.min( attributeArray2.length, attributeArray1.length - attributeOffset );\n\n\t\t\tfor ( let i = 0, j = attributeOffset; i < length; i ++, j ++ ) {\n\n\t\t\t\tattributeArray1[ j ] = attributeArray2[ i ];\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tnormalizeNormals() {\n\n\t\tconst normals = this.attributes.normal;\n\n\t\tfor ( let i = 0, il = normals.count; i < il; i ++ ) {\n\n\t\t\t_vector$8.fromBufferAttribute( normals, i );\n\n\t\t\t_vector$8.normalize();\n\n\t\t\tnormals.setXYZ( i, _vector$8.x, _vector$8.y, _vector$8.z );\n\n\t\t}\n\n\t}\n\n\ttoNonIndexed() {\n\n\t\tfunction convertBufferAttribute( attribute, indices ) {\n\n\t\t\tconst array = attribute.array;\n\t\t\tconst itemSize = attribute.itemSize;\n\t\t\tconst normalized = attribute.normalized;\n\n\t\t\tconst array2 = new array.constructor( indices.length * itemSize );\n\n\t\t\tlet index = 0, index2 = 0;\n\n\t\t\tfor ( let i = 0, l = indices.length; i < l; i ++ ) {\n\n\t\t\t\tif ( attribute.isInterleavedBufferAttribute ) {\n\n\t\t\t\t\tindex = indices[ i ] * attribute.data.stride + attribute.offset;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tindex = indices[ i ] * itemSize;\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let j = 0; j < itemSize; j ++ ) {\n\n\t\t\t\t\tarray2[ index2 ++ ] = array[ index ++ ];\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn new BufferAttribute( array2, itemSize, normalized );\n\n\t\t}\n\n\t\t//\n\n\t\tif ( this.index === null ) {\n\n\t\t\tconsole.warn( 'THREE.BufferGeometry.toNonIndexed(): BufferGeometry is already non-indexed.' );\n\t\t\treturn this;\n\n\t\t}\n\n\t\tconst geometry2 = new BufferGeometry();\n\n\t\tconst indices = this.index.array;\n\t\tconst attributes = this.attributes;\n\n\t\t// attributes\n\n\t\tfor ( const name in attributes ) {\n\n\t\t\tconst attribute = attributes[ name ];\n\n\t\t\tconst newAttribute = convertBufferAttribute( attribute, indices );\n\n\t\t\tgeometry2.setAttribute( name, newAttribute );\n\n\t\t}\n\n\t\t// morph attributes\n\n\t\tconst morphAttributes = this.morphAttributes;\n\n\t\tfor ( const name in morphAttributes ) {\n\n\t\t\tconst morphArray = [];\n\t\t\tconst morphAttribute = morphAttributes[ name ]; // morphAttribute: array of Float32BufferAttributes\n\n\t\t\tfor ( let i = 0, il = morphAttribute.length; i < il; i ++ ) {\n\n\t\t\t\tconst attribute = morphAttribute[ i ];\n\n\t\t\t\tconst newAttribute = convertBufferAttribute( attribute, indices );\n\n\t\t\t\tmorphArray.push( newAttribute );\n\n\t\t\t}\n\n\t\t\tgeometry2.morphAttributes[ name ] = morphArray;\n\n\t\t}\n\n\t\tgeometry2.morphTargetsRelative = this.morphTargetsRelative;\n\n\t\t// groups\n\n\t\tconst groups = this.groups;\n\n\t\tfor ( let i = 0, l = groups.length; i < l; i ++ ) {\n\n\t\t\tconst group = groups[ i ];\n\t\t\tgeometry2.addGroup( group.start, group.count, group.materialIndex );\n\n\t\t}\n\n\t\treturn geometry2;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = {\n\t\t\tmetadata: {\n\t\t\t\tversion: 4.5,\n\t\t\t\ttype: 'BufferGeometry',\n\t\t\t\tgenerator: 'BufferGeometry.toJSON'\n\t\t\t}\n\t\t};\n\n\t\t// standard BufferGeometry serialization\n\n\t\tdata.uuid = this.uuid;\n\t\tdata.type = this.type;\n\t\tif ( this.name !== '' ) data.name = this.name;\n\t\tif ( Object.keys( this.userData ).length > 0 ) data.userData = this.userData;\n\n\t\tif ( this.parameters !== undefined ) {\n\n\t\t\tconst parameters = this.parameters;\n\n\t\t\tfor ( const key in parameters ) {\n\n\t\t\t\tif ( parameters[ key ] !== undefined ) data[ key ] = parameters[ key ];\n\n\t\t\t}\n\n\t\t\treturn data;\n\n\t\t}\n\n\t\t// for simplicity the code assumes attributes are not shared across geometries, see #15811\n\n\t\tdata.data = { attributes: {} };\n\n\t\tconst index = this.index;\n\n\t\tif ( index !== null ) {\n\n\t\t\tdata.data.index = {\n\t\t\t\ttype: index.array.constructor.name,\n\t\t\t\tarray: Array.prototype.slice.call( index.array )\n\t\t\t};\n\n\t\t}\n\n\t\tconst attributes = this.attributes;\n\n\t\tfor ( const key in attributes ) {\n\n\t\t\tconst attribute = attributes[ key ];\n\n\t\t\tdata.data.attributes[ key ] = attribute.toJSON( data.data );\n\n\t\t}\n\n\t\tconst morphAttributes = {};\n\t\tlet hasMorphAttributes = false;\n\n\t\tfor ( const key in this.morphAttributes ) {\n\n\t\t\tconst attributeArray = this.morphAttributes[ key ];\n\n\t\t\tconst array = [];\n\n\t\t\tfor ( let i = 0, il = attributeArray.length; i < il; i ++ ) {\n\n\t\t\t\tconst attribute = attributeArray[ i ];\n\n\t\t\t\tarray.push( attribute.toJSON( data.data ) );\n\n\t\t\t}\n\n\t\t\tif ( array.length > 0 ) {\n\n\t\t\t\tmorphAttributes[ key ] = array;\n\n\t\t\t\thasMorphAttributes = true;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( hasMorphAttributes ) {\n\n\t\t\tdata.data.morphAttributes = morphAttributes;\n\t\t\tdata.data.morphTargetsRelative = this.morphTargetsRelative;\n\n\t\t}\n\n\t\tconst groups = this.groups;\n\n\t\tif ( groups.length > 0 ) {\n\n\t\t\tdata.data.groups = JSON.parse( JSON.stringify( groups ) );\n\n\t\t}\n\n\t\tconst boundingSphere = this.boundingSphere;\n\n\t\tif ( boundingSphere !== null ) {\n\n\t\t\tdata.data.boundingSphere = {\n\t\t\t\tcenter: boundingSphere.center.toArray(),\n\t\t\t\tradius: boundingSphere.radius\n\t\t\t};\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n\tclone() {\n\n\t\t return new this.constructor().copy( this );\n\n\t}\n\n\tcopy( source ) {\n\n\t\t// reset\n\n\t\tthis.index = null;\n\t\tthis.attributes = {};\n\t\tthis.morphAttributes = {};\n\t\tthis.groups = [];\n\t\tthis.boundingBox = null;\n\t\tthis.boundingSphere = null;\n\n\t\t// used for storing cloned, shared data\n\n\t\tconst data = {};\n\n\t\t// name\n\n\t\tthis.name = source.name;\n\n\t\t// index\n\n\t\tconst index = source.index;\n\n\t\tif ( index !== null ) {\n\n\t\t\tthis.setIndex( index.clone( data ) );\n\n\t\t}\n\n\t\t// attributes\n\n\t\tconst attributes = source.attributes;\n\n\t\tfor ( const name in attributes ) {\n\n\t\t\tconst attribute = attributes[ name ];\n\t\t\tthis.setAttribute( name, attribute.clone( data ) );\n\n\t\t}\n\n\t\t// morph attributes\n\n\t\tconst morphAttributes = source.morphAttributes;\n\n\t\tfor ( const name in morphAttributes ) {\n\n\t\t\tconst array = [];\n\t\t\tconst morphAttribute = morphAttributes[ name ]; // morphAttribute: array of Float32BufferAttributes\n\n\t\t\tfor ( let i = 0, l = morphAttribute.length; i < l; i ++ ) {\n\n\t\t\t\tarray.push( morphAttribute[ i ].clone( data ) );\n\n\t\t\t}\n\n\t\t\tthis.morphAttributes[ name ] = array;\n\n\t\t}\n\n\t\tthis.morphTargetsRelative = source.morphTargetsRelative;\n\n\t\t// groups\n\n\t\tconst groups = source.groups;\n\n\t\tfor ( let i = 0, l = groups.length; i < l; i ++ ) {\n\n\t\t\tconst group = groups[ i ];\n\t\t\tthis.addGroup( group.start, group.count, group.materialIndex );\n\n\t\t}\n\n\t\t// bounding box\n\n\t\tconst boundingBox = source.boundingBox;\n\n\t\tif ( boundingBox !== null ) {\n\n\t\t\tthis.boundingBox = boundingBox.clone();\n\n\t\t}\n\n\t\t// bounding sphere\n\n\t\tconst boundingSphere = source.boundingSphere;\n\n\t\tif ( boundingSphere !== null ) {\n\n\t\t\tthis.boundingSphere = boundingSphere.clone();\n\n\t\t}\n\n\t\t// draw range\n\n\t\tthis.drawRange.start = source.drawRange.start;\n\t\tthis.drawRange.count = source.drawRange.count;\n\n\t\t// user data\n\n\t\tthis.userData = source.userData;\n\n\t\t// geometry generator parameters\n\n\t\tif ( source.parameters !== undefined ) this.parameters = Object.assign( {}, source.parameters );\n\n\t\treturn this;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.dispatchEvent( { type: 'dispose' } );\n\n\t}\n\n}\n\nBufferGeometry.prototype.isBufferGeometry = true;\n\nconst _inverseMatrix$2 = /*@__PURE__*/ new Matrix4();\nconst _ray$2 = /*@__PURE__*/ new Ray();\nconst _sphere$3 = /*@__PURE__*/ new Sphere();\n\nconst _vA$1 = /*@__PURE__*/ new Vector3();\nconst _vB$1 = /*@__PURE__*/ new Vector3();\nconst _vC$1 = /*@__PURE__*/ new Vector3();\n\nconst _tempA = /*@__PURE__*/ new Vector3();\nconst _tempB = /*@__PURE__*/ new Vector3();\nconst _tempC = /*@__PURE__*/ new Vector3();\n\nconst _morphA = /*@__PURE__*/ new Vector3();\nconst _morphB = /*@__PURE__*/ new Vector3();\nconst _morphC = /*@__PURE__*/ new Vector3();\n\nconst _uvA$1 = /*@__PURE__*/ new Vector2();\nconst _uvB$1 = /*@__PURE__*/ new Vector2();\nconst _uvC$1 = /*@__PURE__*/ new Vector2();\n\nconst _intersectionPoint = /*@__PURE__*/ new Vector3();\nconst _intersectionPointWorld = /*@__PURE__*/ new Vector3();\n\nclass Mesh extends Object3D {\n\n\tconstructor( geometry = new BufferGeometry(), material = new MeshBasicMaterial() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'Mesh';\n\n\t\tthis.geometry = geometry;\n\t\tthis.material = material;\n\n\t\tthis.updateMorphTargets();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tif ( source.morphTargetInfluences !== undefined ) {\n\n\t\t\tthis.morphTargetInfluences = source.morphTargetInfluences.slice();\n\n\t\t}\n\n\t\tif ( source.morphTargetDictionary !== undefined ) {\n\n\t\t\tthis.morphTargetDictionary = Object.assign( {}, source.morphTargetDictionary );\n\n\t\t}\n\n\t\tthis.material = source.material;\n\t\tthis.geometry = source.geometry;\n\n\t\treturn this;\n\n\t}\n\n\tupdateMorphTargets() {\n\n\t\tconst geometry = this.geometry;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\tconst morphAttributes = geometry.morphAttributes;\n\t\t\tconst keys = Object.keys( morphAttributes );\n\n\t\t\tif ( keys.length > 0 ) {\n\n\t\t\t\tconst morphAttribute = morphAttributes[ keys[ 0 ] ];\n\n\t\t\t\tif ( morphAttribute !== undefined ) {\n\n\t\t\t\t\tthis.morphTargetInfluences = [];\n\t\t\t\t\tthis.morphTargetDictionary = {};\n\n\t\t\t\t\tfor ( let m = 0, ml = morphAttribute.length; m < ml; m ++ ) {\n\n\t\t\t\t\t\tconst name = morphAttribute[ m ].name || String( m );\n\n\t\t\t\t\t\tthis.morphTargetInfluences.push( 0 );\n\t\t\t\t\t\tthis.morphTargetDictionary[ name ] = m;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconst morphTargets = geometry.morphTargets;\n\n\t\t\tif ( morphTargets !== undefined && morphTargets.length > 0 ) {\n\n\t\t\t\tconsole.error( 'THREE.Mesh.updateMorphTargets() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\traycast( raycaster, intersects ) {\n\n\t\tconst geometry = this.geometry;\n\t\tconst material = this.material;\n\t\tconst matrixWorld = this.matrixWorld;\n\n\t\tif ( material === undefined ) return;\n\n\t\t// Checking boundingSphere distance to ray\n\n\t\tif ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();\n\n\t\t_sphere$3.copy( geometry.boundingSphere );\n\t\t_sphere$3.applyMatrix4( matrixWorld );\n\n\t\tif ( raycaster.ray.intersectsSphere( _sphere$3 ) === false ) return;\n\n\t\t//\n\n\t\t_inverseMatrix$2.copy( matrixWorld ).invert();\n\t\t_ray$2.copy( raycaster.ray ).applyMatrix4( _inverseMatrix$2 );\n\n\t\t// Check boundingBox before continuing\n\n\t\tif ( geometry.boundingBox !== null ) {\n\n\t\t\tif ( _ray$2.intersectsBox( geometry.boundingBox ) === false ) return;\n\n\t\t}\n\n\t\tlet intersection;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\tconst index = geometry.index;\n\t\t\tconst position = geometry.attributes.position;\n\t\t\tconst morphPosition = geometry.morphAttributes.position;\n\t\t\tconst morphTargetsRelative = geometry.morphTargetsRelative;\n\t\t\tconst uv = geometry.attributes.uv;\n\t\t\tconst uv2 = geometry.attributes.uv2;\n\t\t\tconst groups = geometry.groups;\n\t\t\tconst drawRange = geometry.drawRange;\n\n\t\t\tif ( index !== null ) {\n\n\t\t\t\t// indexed buffer geometry\n\n\t\t\t\tif ( Array.isArray( material ) ) {\n\n\t\t\t\t\tfor ( let i = 0, il = groups.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tconst group = groups[ i ];\n\t\t\t\t\t\tconst groupMaterial = material[ group.materialIndex ];\n\n\t\t\t\t\t\tconst start = Math.max( group.start, drawRange.start );\n\t\t\t\t\t\tconst end = Math.min( index.count, Math.min( ( group.start + group.count ), ( drawRange.start + drawRange.count ) ) );\n\n\t\t\t\t\t\tfor ( let j = start, jl = end; j < jl; j += 3 ) {\n\n\t\t\t\t\t\t\tconst a = index.getX( j );\n\t\t\t\t\t\t\tconst b = index.getX( j + 1 );\n\t\t\t\t\t\t\tconst c = index.getX( j + 2 );\n\n\t\t\t\t\t\t\tintersection = checkBufferGeometryIntersection( this, groupMaterial, raycaster, _ray$2, position, morphPosition, morphTargetsRelative, uv, uv2, a, b, c );\n\n\t\t\t\t\t\t\tif ( intersection ) {\n\n\t\t\t\t\t\t\t\tintersection.faceIndex = Math.floor( j / 3 ); // triangle number in indexed buffer semantics\n\t\t\t\t\t\t\t\tintersection.face.materialIndex = group.materialIndex;\n\t\t\t\t\t\t\t\tintersects.push( intersection );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconst start = Math.max( 0, drawRange.start );\n\t\t\t\t\tconst end = Math.min( index.count, ( drawRange.start + drawRange.count ) );\n\n\t\t\t\t\tfor ( let i = start, il = end; i < il; i += 3 ) {\n\n\t\t\t\t\t\tconst a = index.getX( i );\n\t\t\t\t\t\tconst b = index.getX( i + 1 );\n\t\t\t\t\t\tconst c = index.getX( i + 2 );\n\n\t\t\t\t\t\tintersection = checkBufferGeometryIntersection( this, material, raycaster, _ray$2, position, morphPosition, morphTargetsRelative, uv, uv2, a, b, c );\n\n\t\t\t\t\t\tif ( intersection ) {\n\n\t\t\t\t\t\t\tintersection.faceIndex = Math.floor( i / 3 ); // triangle number in indexed buffer semantics\n\t\t\t\t\t\t\tintersects.push( intersection );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else if ( position !== undefined ) {\n\n\t\t\t\t// non-indexed buffer geometry\n\n\t\t\t\tif ( Array.isArray( material ) ) {\n\n\t\t\t\t\tfor ( let i = 0, il = groups.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tconst group = groups[ i ];\n\t\t\t\t\t\tconst groupMaterial = material[ group.materialIndex ];\n\n\t\t\t\t\t\tconst start = Math.max( group.start, drawRange.start );\n\t\t\t\t\t\tconst end = Math.min( position.count, Math.min( ( group.start + group.count ), ( drawRange.start + drawRange.count ) ) );\n\n\t\t\t\t\t\tfor ( let j = start, jl = end; j < jl; j += 3 ) {\n\n\t\t\t\t\t\t\tconst a = j;\n\t\t\t\t\t\t\tconst b = j + 1;\n\t\t\t\t\t\t\tconst c = j + 2;\n\n\t\t\t\t\t\t\tintersection = checkBufferGeometryIntersection( this, groupMaterial, raycaster, _ray$2, position, morphPosition, morphTargetsRelative, uv, uv2, a, b, c );\n\n\t\t\t\t\t\t\tif ( intersection ) {\n\n\t\t\t\t\t\t\t\tintersection.faceIndex = Math.floor( j / 3 ); // triangle number in non-indexed buffer semantics\n\t\t\t\t\t\t\t\tintersection.face.materialIndex = group.materialIndex;\n\t\t\t\t\t\t\t\tintersects.push( intersection );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconst start = Math.max( 0, drawRange.start );\n\t\t\t\t\tconst end = Math.min( position.count, ( drawRange.start + drawRange.count ) );\n\n\t\t\t\t\tfor ( let i = start, il = end; i < il; i += 3 ) {\n\n\t\t\t\t\t\tconst a = i;\n\t\t\t\t\t\tconst b = i + 1;\n\t\t\t\t\t\tconst c = i + 2;\n\n\t\t\t\t\t\tintersection = checkBufferGeometryIntersection( this, material, raycaster, _ray$2, position, morphPosition, morphTargetsRelative, uv, uv2, a, b, c );\n\n\t\t\t\t\t\tif ( intersection ) {\n\n\t\t\t\t\t\t\tintersection.faceIndex = Math.floor( i / 3 ); // triangle number in non-indexed buffer semantics\n\t\t\t\t\t\t\tintersects.push( intersection );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else if ( geometry.isGeometry ) {\n\n\t\t\tconsole.error( 'THREE.Mesh.raycast() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t}\n\n\t}\n\n}\n\nMesh.prototype.isMesh = true;\n\nfunction checkIntersection( object, material, raycaster, ray, pA, pB, pC, point ) {\n\n\tlet intersect;\n\n\tif ( material.side === BackSide ) {\n\n\t\tintersect = ray.intersectTriangle( pC, pB, pA, true, point );\n\n\t} else {\n\n\t\tintersect = ray.intersectTriangle( pA, pB, pC, material.side !== DoubleSide, point );\n\n\t}\n\n\tif ( intersect === null ) return null;\n\n\t_intersectionPointWorld.copy( point );\n\t_intersectionPointWorld.applyMatrix4( object.matrixWorld );\n\n\tconst distance = raycaster.ray.origin.distanceTo( _intersectionPointWorld );\n\n\tif ( distance < raycaster.near || distance > raycaster.far ) return null;\n\n\treturn {\n\t\tdistance: distance,\n\t\tpoint: _intersectionPointWorld.clone(),\n\t\tobject: object\n\t};\n\n}\n\nfunction checkBufferGeometryIntersection( object, material, raycaster, ray, position, morphPosition, morphTargetsRelative, uv, uv2, a, b, c ) {\n\n\t_vA$1.fromBufferAttribute( position, a );\n\t_vB$1.fromBufferAttribute( position, b );\n\t_vC$1.fromBufferAttribute( position, c );\n\n\tconst morphInfluences = object.morphTargetInfluences;\n\n\tif ( morphPosition && morphInfluences ) {\n\n\t\t_morphA.set( 0, 0, 0 );\n\t\t_morphB.set( 0, 0, 0 );\n\t\t_morphC.set( 0, 0, 0 );\n\n\t\tfor ( let i = 0, il = morphPosition.length; i < il; i ++ ) {\n\n\t\t\tconst influence = morphInfluences[ i ];\n\t\t\tconst morphAttribute = morphPosition[ i ];\n\n\t\t\tif ( influence === 0 ) continue;\n\n\t\t\t_tempA.fromBufferAttribute( morphAttribute, a );\n\t\t\t_tempB.fromBufferAttribute( morphAttribute, b );\n\t\t\t_tempC.fromBufferAttribute( morphAttribute, c );\n\n\t\t\tif ( morphTargetsRelative ) {\n\n\t\t\t\t_morphA.addScaledVector( _tempA, influence );\n\t\t\t\t_morphB.addScaledVector( _tempB, influence );\n\t\t\t\t_morphC.addScaledVector( _tempC, influence );\n\n\t\t\t} else {\n\n\t\t\t\t_morphA.addScaledVector( _tempA.sub( _vA$1 ), influence );\n\t\t\t\t_morphB.addScaledVector( _tempB.sub( _vB$1 ), influence );\n\t\t\t\t_morphC.addScaledVector( _tempC.sub( _vC$1 ), influence );\n\n\t\t\t}\n\n\t\t}\n\n\t\t_vA$1.add( _morphA );\n\t\t_vB$1.add( _morphB );\n\t\t_vC$1.add( _morphC );\n\n\t}\n\n\tif ( object.isSkinnedMesh ) {\n\n\t\tobject.boneTransform( a, _vA$1 );\n\t\tobject.boneTransform( b, _vB$1 );\n\t\tobject.boneTransform( c, _vC$1 );\n\n\t}\n\n\tconst intersection = checkIntersection( object, material, raycaster, ray, _vA$1, _vB$1, _vC$1, _intersectionPoint );\n\n\tif ( intersection ) {\n\n\t\tif ( uv ) {\n\n\t\t\t_uvA$1.fromBufferAttribute( uv, a );\n\t\t\t_uvB$1.fromBufferAttribute( uv, b );\n\t\t\t_uvC$1.fromBufferAttribute( uv, c );\n\n\t\t\tintersection.uv = Triangle.getUV( _intersectionPoint, _vA$1, _vB$1, _vC$1, _uvA$1, _uvB$1, _uvC$1, new Vector2() );\n\n\t\t}\n\n\t\tif ( uv2 ) {\n\n\t\t\t_uvA$1.fromBufferAttribute( uv2, a );\n\t\t\t_uvB$1.fromBufferAttribute( uv2, b );\n\t\t\t_uvC$1.fromBufferAttribute( uv2, c );\n\n\t\t\tintersection.uv2 = Triangle.getUV( _intersectionPoint, _vA$1, _vB$1, _vC$1, _uvA$1, _uvB$1, _uvC$1, new Vector2() );\n\n\t\t}\n\n\t\tconst face = {\n\t\t\ta: a,\n\t\t\tb: b,\n\t\t\tc: c,\n\t\t\tnormal: new Vector3(),\n\t\t\tmaterialIndex: 0\n\t\t};\n\n\t\tTriangle.getNormal( _vA$1, _vB$1, _vC$1, face.normal );\n\n\t\tintersection.face = face;\n\n\t}\n\n\treturn intersection;\n\n}\n\nclass BoxGeometry extends BufferGeometry {\n\n\tconstructor( width = 1, height = 1, depth = 1, widthSegments = 1, heightSegments = 1, depthSegments = 1 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'BoxGeometry';\n\n\t\tthis.parameters = {\n\t\t\twidth: width,\n\t\t\theight: height,\n\t\t\tdepth: depth,\n\t\t\twidthSegments: widthSegments,\n\t\t\theightSegments: heightSegments,\n\t\t\tdepthSegments: depthSegments\n\t\t};\n\n\t\tconst scope = this;\n\n\t\t// segments\n\n\t\twidthSegments = Math.floor( widthSegments );\n\t\theightSegments = Math.floor( heightSegments );\n\t\tdepthSegments = Math.floor( depthSegments );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// helper variables\n\n\t\tlet numberOfVertices = 0;\n\t\tlet groupStart = 0;\n\n\t\t// build each side of the box geometry\n\n\t\tbuildPlane( 'z', 'y', 'x', - 1, - 1, depth, height, width, depthSegments, heightSegments, 0 ); // px\n\t\tbuildPlane( 'z', 'y', 'x', 1, - 1, depth, height, - width, depthSegments, heightSegments, 1 ); // nx\n\t\tbuildPlane( 'x', 'z', 'y', 1, 1, width, depth, height, widthSegments, depthSegments, 2 ); // py\n\t\tbuildPlane( 'x', 'z', 'y', 1, - 1, width, depth, - height, widthSegments, depthSegments, 3 ); // ny\n\t\tbuildPlane( 'x', 'y', 'z', 1, - 1, width, height, depth, widthSegments, heightSegments, 4 ); // pz\n\t\tbuildPlane( 'x', 'y', 'z', - 1, - 1, width, height, - depth, widthSegments, heightSegments, 5 ); // nz\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t\tfunction buildPlane( u, v, w, udir, vdir, width, height, depth, gridX, gridY, materialIndex ) {\n\n\t\t\tconst segmentWidth = width / gridX;\n\t\t\tconst segmentHeight = height / gridY;\n\n\t\t\tconst widthHalf = width / 2;\n\t\t\tconst heightHalf = height / 2;\n\t\t\tconst depthHalf = depth / 2;\n\n\t\t\tconst gridX1 = gridX + 1;\n\t\t\tconst gridY1 = gridY + 1;\n\n\t\t\tlet vertexCounter = 0;\n\t\t\tlet groupCount = 0;\n\n\t\t\tconst vector = new Vector3();\n\n\t\t\t// generate vertices, normals and uvs\n\n\t\t\tfor ( let iy = 0; iy < gridY1; iy ++ ) {\n\n\t\t\t\tconst y = iy * segmentHeight - heightHalf;\n\n\t\t\t\tfor ( let ix = 0; ix < gridX1; ix ++ ) {\n\n\t\t\t\t\tconst x = ix * segmentWidth - widthHalf;\n\n\t\t\t\t\t// set values to correct vector component\n\n\t\t\t\t\tvector[ u ] = x * udir;\n\t\t\t\t\tvector[ v ] = y * vdir;\n\t\t\t\t\tvector[ w ] = depthHalf;\n\n\t\t\t\t\t// now apply vector to vertex buffer\n\n\t\t\t\t\tvertices.push( vector.x, vector.y, vector.z );\n\n\t\t\t\t\t// set values to correct vector component\n\n\t\t\t\t\tvector[ u ] = 0;\n\t\t\t\t\tvector[ v ] = 0;\n\t\t\t\t\tvector[ w ] = depth > 0 ? 1 : - 1;\n\n\t\t\t\t\t// now apply vector to normal buffer\n\n\t\t\t\t\tnormals.push( vector.x, vector.y, vector.z );\n\n\t\t\t\t\t// uvs\n\n\t\t\t\t\tuvs.push( ix / gridX );\n\t\t\t\t\tuvs.push( 1 - ( iy / gridY ) );\n\n\t\t\t\t\t// counters\n\n\t\t\t\t\tvertexCounter += 1;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// indices\n\n\t\t\t// 1. you need three indices to draw a single face\n\t\t\t// 2. a single segment consists of two faces\n\t\t\t// 3. so we need to generate six (2*3) indices per segment\n\n\t\t\tfor ( let iy = 0; iy < gridY; iy ++ ) {\n\n\t\t\t\tfor ( let ix = 0; ix < gridX; ix ++ ) {\n\n\t\t\t\t\tconst a = numberOfVertices + ix + gridX1 * iy;\n\t\t\t\t\tconst b = numberOfVertices + ix + gridX1 * ( iy + 1 );\n\t\t\t\t\tconst c = numberOfVertices + ( ix + 1 ) + gridX1 * ( iy + 1 );\n\t\t\t\t\tconst d = numberOfVertices + ( ix + 1 ) + gridX1 * iy;\n\n\t\t\t\t\t// faces\n\n\t\t\t\t\tindices.push( a, b, d );\n\t\t\t\t\tindices.push( b, c, d );\n\n\t\t\t\t\t// increase counter\n\n\t\t\t\t\tgroupCount += 6;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// add a group to the geometry. this will ensure multi material support\n\n\t\t\tscope.addGroup( groupStart, groupCount, materialIndex );\n\n\t\t\t// calculate new start value for groups\n\n\t\t\tgroupStart += groupCount;\n\n\t\t\t// update total number of vertices\n\n\t\t\tnumberOfVertices += vertexCounter;\n\n\t\t}\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new BoxGeometry( data.width, data.height, data.depth, data.widthSegments, data.heightSegments, data.depthSegments );\n\n\t}\n\n}\n\n/**\n * Uniform Utilities\n */\n\nfunction cloneUniforms( src ) {\n\n\tconst dst = {};\n\n\tfor ( const u in src ) {\n\n\t\tdst[ u ] = {};\n\n\t\tfor ( const p in src[ u ] ) {\n\n\t\t\tconst property = src[ u ][ p ];\n\n\t\t\tif ( property && ( property.isColor ||\n\t\t\t\tproperty.isMatrix3 || property.isMatrix4 ||\n\t\t\t\tproperty.isVector2 || property.isVector3 || property.isVector4 ||\n\t\t\t\tproperty.isTexture || property.isQuaternion ) ) {\n\n\t\t\t\tdst[ u ][ p ] = property.clone();\n\n\t\t\t} else if ( Array.isArray( property ) ) {\n\n\t\t\t\tdst[ u ][ p ] = property.slice();\n\n\t\t\t} else {\n\n\t\t\t\tdst[ u ][ p ] = property;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\treturn dst;\n\n}\n\nfunction mergeUniforms( uniforms ) {\n\n\tconst merged = {};\n\n\tfor ( let u = 0; u < uniforms.length; u ++ ) {\n\n\t\tconst tmp = cloneUniforms( uniforms[ u ] );\n\n\t\tfor ( const p in tmp ) {\n\n\t\t\tmerged[ p ] = tmp[ p ];\n\n\t\t}\n\n\t}\n\n\treturn merged;\n\n}\n\n// Legacy\n\nconst UniformsUtils = { clone: cloneUniforms, merge: mergeUniforms };\n\nvar default_vertex = \"void main() {\\n\\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\\n}\";\n\nvar default_fragment = \"void main() {\\n\\tgl_FragColor = vec4( 1.0, 0.0, 0.0, 1.0 );\\n}\";\n\n/**\n * parameters = {\n *  defines: { \"label\" : \"value\" },\n *  uniforms: { \"parameter1\": { value: 1.0 }, \"parameter2\": { value2: 2 } },\n *\n *  fragmentShader: <string>,\n *  vertexShader: <string>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>,\n *\n *  lights: <bool>\n * }\n */\n\nclass ShaderMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'ShaderMaterial';\n\n\t\tthis.defines = {};\n\t\tthis.uniforms = {};\n\n\t\tthis.vertexShader = default_vertex;\n\t\tthis.fragmentShader = default_fragment;\n\n\t\tthis.linewidth = 1;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\n\t\tthis.fog = false; // set to use scene fog\n\t\tthis.lights = false; // set to use scene lights\n\t\tthis.clipping = false; // set to use user-defined clipping planes\n\n\t\tthis.extensions = {\n\t\t\tderivatives: false, // set to use derivatives\n\t\t\tfragDepth: false, // set to use fragment depth values\n\t\t\tdrawBuffers: false, // set to use draw buffers\n\t\t\tshaderTextureLOD: false // set to use shader texture LOD\n\t\t};\n\n\t\t// When rendered geometry doesn't include these attributes but the material does,\n\t\t// use these default values in WebGL. This avoids errors when buffer data is missing.\n\t\tthis.defaultAttributeValues = {\n\t\t\t'color': [ 1, 1, 1 ],\n\t\t\t'uv': [ 0, 0 ],\n\t\t\t'uv2': [ 0, 0 ]\n\t\t};\n\n\t\tthis.index0AttributeName = undefined;\n\t\tthis.uniformsNeedUpdate = false;\n\n\t\tthis.glslVersion = null;\n\n\t\tif ( parameters !== undefined ) {\n\n\t\t\tif ( parameters.attributes !== undefined ) {\n\n\t\t\t\tconsole.error( 'THREE.ShaderMaterial: attributes should now be defined in THREE.BufferGeometry instead.' );\n\n\t\t\t}\n\n\t\t\tthis.setValues( parameters );\n\n\t\t}\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.fragmentShader = source.fragmentShader;\n\t\tthis.vertexShader = source.vertexShader;\n\n\t\tthis.uniforms = cloneUniforms( source.uniforms );\n\n\t\tthis.defines = Object.assign( {}, source.defines );\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\n\t\tthis.lights = source.lights;\n\t\tthis.clipping = source.clipping;\n\n\t\tthis.extensions = Object.assign( {}, source.extensions );\n\n\t\tthis.glslVersion = source.glslVersion;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tdata.glslVersion = this.glslVersion;\n\t\tdata.uniforms = {};\n\n\t\tfor ( const name in this.uniforms ) {\n\n\t\t\tconst uniform = this.uniforms[ name ];\n\t\t\tconst value = uniform.value;\n\n\t\t\tif ( value && value.isTexture ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 't',\n\t\t\t\t\tvalue: value.toJSON( meta ).uuid\n\t\t\t\t};\n\n\t\t\t} else if ( value && value.isColor ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 'c',\n\t\t\t\t\tvalue: value.getHex()\n\t\t\t\t};\n\n\t\t\t} else if ( value && value.isVector2 ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 'v2',\n\t\t\t\t\tvalue: value.toArray()\n\t\t\t\t};\n\n\t\t\t} else if ( value && value.isVector3 ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 'v3',\n\t\t\t\t\tvalue: value.toArray()\n\t\t\t\t};\n\n\t\t\t} else if ( value && value.isVector4 ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 'v4',\n\t\t\t\t\tvalue: value.toArray()\n\t\t\t\t};\n\n\t\t\t} else if ( value && value.isMatrix3 ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 'm3',\n\t\t\t\t\tvalue: value.toArray()\n\t\t\t\t};\n\n\t\t\t} else if ( value && value.isMatrix4 ) {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\ttype: 'm4',\n\t\t\t\t\tvalue: value.toArray()\n\t\t\t\t};\n\n\t\t\t} else {\n\n\t\t\t\tdata.uniforms[ name ] = {\n\t\t\t\t\tvalue: value\n\t\t\t\t};\n\n\t\t\t\t// note: the array variants v2v, v3v, v4v, m4v and tv are not supported so far\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( Object.keys( this.defines ).length > 0 ) data.defines = this.defines;\n\n\t\tdata.vertexShader = this.vertexShader;\n\t\tdata.fragmentShader = this.fragmentShader;\n\n\t\tconst extensions = {};\n\n\t\tfor ( const key in this.extensions ) {\n\n\t\t\tif ( this.extensions[ key ] === true ) extensions[ key ] = true;\n\n\t\t}\n\n\t\tif ( Object.keys( extensions ).length > 0 ) data.extensions = extensions;\n\n\t\treturn data;\n\n\t}\n\n}\n\nShaderMaterial.prototype.isShaderMaterial = true;\n\nclass Camera extends Object3D {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'Camera';\n\n\t\tthis.matrixWorldInverse = new Matrix4();\n\n\t\tthis.projectionMatrix = new Matrix4();\n\t\tthis.projectionMatrixInverse = new Matrix4();\n\n\t}\n\n\tcopy( source, recursive ) {\n\n\t\tsuper.copy( source, recursive );\n\n\t\tthis.matrixWorldInverse.copy( source.matrixWorldInverse );\n\n\t\tthis.projectionMatrix.copy( source.projectionMatrix );\n\t\tthis.projectionMatrixInverse.copy( source.projectionMatrixInverse );\n\n\t\treturn this;\n\n\t}\n\n\tgetWorldDirection( target ) {\n\n\t\tthis.updateWorldMatrix( true, false );\n\n\t\tconst e = this.matrixWorld.elements;\n\n\t\treturn target.set( - e[ 8 ], - e[ 9 ], - e[ 10 ] ).normalize();\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t\tthis.matrixWorldInverse.copy( this.matrixWorld ).invert();\n\n\t}\n\n\tupdateWorldMatrix( updateParents, updateChildren ) {\n\n\t\tsuper.updateWorldMatrix( updateParents, updateChildren );\n\n\t\tthis.matrixWorldInverse.copy( this.matrixWorld ).invert();\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nCamera.prototype.isCamera = true;\n\nclass PerspectiveCamera extends Camera {\n\n\tconstructor( fov = 50, aspect = 1, near = 0.1, far = 2000 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'PerspectiveCamera';\n\n\t\tthis.fov = fov;\n\t\tthis.zoom = 1;\n\n\t\tthis.near = near;\n\t\tthis.far = far;\n\t\tthis.focus = 10;\n\n\t\tthis.aspect = aspect;\n\t\tthis.view = null;\n\n\t\tthis.filmGauge = 35;\t// width of the film (default in millimeters)\n\t\tthis.filmOffset = 0;\t// horizontal film offset (same unit as gauge)\n\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\tcopy( source, recursive ) {\n\n\t\tsuper.copy( source, recursive );\n\n\t\tthis.fov = source.fov;\n\t\tthis.zoom = source.zoom;\n\n\t\tthis.near = source.near;\n\t\tthis.far = source.far;\n\t\tthis.focus = source.focus;\n\n\t\tthis.aspect = source.aspect;\n\t\tthis.view = source.view === null ? null : Object.assign( {}, source.view );\n\n\t\tthis.filmGauge = source.filmGauge;\n\t\tthis.filmOffset = source.filmOffset;\n\n\t\treturn this;\n\n\t}\n\n\t/**\n\t * Sets the FOV by focal length in respect to the current .filmGauge.\n\t *\n\t * The default film gauge is 35, so that the focal length can be specified for\n\t * a 35mm (full frame) camera.\n\t *\n\t * Values for focal length and film gauge must have the same unit.\n\t */\n\tsetFocalLength( focalLength ) {\n\n\t\t/** see {@link http://www.bobatkins.com/photography/technical/field_of_view.html} */\n\t\tconst vExtentSlope = 0.5 * this.getFilmHeight() / focalLength;\n\n\t\tthis.fov = RAD2DEG * 2 * Math.atan( vExtentSlope );\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\t/**\n\t * Calculates the focal length from the current .fov and .filmGauge.\n\t */\n\tgetFocalLength() {\n\n\t\tconst vExtentSlope = Math.tan( DEG2RAD * 0.5 * this.fov );\n\n\t\treturn 0.5 * this.getFilmHeight() / vExtentSlope;\n\n\t}\n\n\tgetEffectiveFOV() {\n\n\t\treturn RAD2DEG * 2 * Math.atan(\n\t\t\tMath.tan( DEG2RAD * 0.5 * this.fov ) / this.zoom );\n\n\t}\n\n\tgetFilmWidth() {\n\n\t\t// film not completely covered in portrait format (aspect < 1)\n\t\treturn this.filmGauge * Math.min( this.aspect, 1 );\n\n\t}\n\n\tgetFilmHeight() {\n\n\t\t// film not completely covered in landscape format (aspect > 1)\n\t\treturn this.filmGauge / Math.max( this.aspect, 1 );\n\n\t}\n\n\t/**\n\t * Sets an offset in a larger frustum. This is useful for multi-window or\n\t * multi-monitor/multi-machine setups.\n\t *\n\t * For example, if you have 3x2 monitors and each monitor is 1920x1080 and\n\t * the monitors are in grid like this\n\t *\n\t *   +---+---+---+\n\t *   | A | B | C |\n\t *   +---+---+---+\n\t *   | D | E | F |\n\t *   +---+---+---+\n\t *\n\t * then for each monitor you would call it like this\n\t *\n\t *   const w = 1920;\n\t *   const h = 1080;\n\t *   const fullWidth = w * 3;\n\t *   const fullHeight = h * 2;\n\t *\n\t *   --A--\n\t *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 0, w, h );\n\t *   --B--\n\t *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 0, w, h );\n\t *   --C--\n\t *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 0, w, h );\n\t *   --D--\n\t *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 1, w, h );\n\t *   --E--\n\t *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 1, w, h );\n\t *   --F--\n\t *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 1, w, h );\n\t *\n\t *   Note there is no reason monitors have to be the same size or in a grid.\n\t */\n\tsetViewOffset( fullWidth, fullHeight, x, y, width, height ) {\n\n\t\tthis.aspect = fullWidth / fullHeight;\n\n\t\tif ( this.view === null ) {\n\n\t\t\tthis.view = {\n\t\t\t\tenabled: true,\n\t\t\t\tfullWidth: 1,\n\t\t\t\tfullHeight: 1,\n\t\t\t\toffsetX: 0,\n\t\t\t\toffsetY: 0,\n\t\t\t\twidth: 1,\n\t\t\t\theight: 1\n\t\t\t};\n\n\t\t}\n\n\t\tthis.view.enabled = true;\n\t\tthis.view.fullWidth = fullWidth;\n\t\tthis.view.fullHeight = fullHeight;\n\t\tthis.view.offsetX = x;\n\t\tthis.view.offsetY = y;\n\t\tthis.view.width = width;\n\t\tthis.view.height = height;\n\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\tclearViewOffset() {\n\n\t\tif ( this.view !== null ) {\n\n\t\t\tthis.view.enabled = false;\n\n\t\t}\n\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\tupdateProjectionMatrix() {\n\n\t\tconst near = this.near;\n\t\tlet top = near * Math.tan( DEG2RAD * 0.5 * this.fov ) / this.zoom;\n\t\tlet height = 2 * top;\n\t\tlet width = this.aspect * height;\n\t\tlet left = - 0.5 * width;\n\t\tconst view = this.view;\n\n\t\tif ( this.view !== null && this.view.enabled ) {\n\n\t\t\tconst fullWidth = view.fullWidth,\n\t\t\t\tfullHeight = view.fullHeight;\n\n\t\t\tleft += view.offsetX * width / fullWidth;\n\t\t\ttop -= view.offsetY * height / fullHeight;\n\t\t\twidth *= view.width / fullWidth;\n\t\t\theight *= view.height / fullHeight;\n\n\t\t}\n\n\t\tconst skew = this.filmOffset;\n\t\tif ( skew !== 0 ) left += near * skew / this.getFilmWidth();\n\n\t\tthis.projectionMatrix.makePerspective( left, left + width, top, top - height, near, this.far );\n\n\t\tthis.projectionMatrixInverse.copy( this.projectionMatrix ).invert();\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tdata.object.fov = this.fov;\n\t\tdata.object.zoom = this.zoom;\n\n\t\tdata.object.near = this.near;\n\t\tdata.object.far = this.far;\n\t\tdata.object.focus = this.focus;\n\n\t\tdata.object.aspect = this.aspect;\n\n\t\tif ( this.view !== null ) data.object.view = Object.assign( {}, this.view );\n\n\t\tdata.object.filmGauge = this.filmGauge;\n\t\tdata.object.filmOffset = this.filmOffset;\n\n\t\treturn data;\n\n\t}\n\n}\n\nPerspectiveCamera.prototype.isPerspectiveCamera = true;\n\nconst fov = 90, aspect = 1;\n\nclass CubeCamera extends Object3D {\n\n\tconstructor( near, far, renderTarget ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'CubeCamera';\n\n\t\tif ( renderTarget.isWebGLCubeRenderTarget !== true ) {\n\n\t\t\tconsole.error( 'THREE.CubeCamera: The constructor now expects an instance of WebGLCubeRenderTarget as third parameter.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tthis.renderTarget = renderTarget;\n\n\t\tconst cameraPX = new PerspectiveCamera( fov, aspect, near, far );\n\t\tcameraPX.layers = this.layers;\n\t\tcameraPX.up.set( 0, - 1, 0 );\n\t\tcameraPX.lookAt( new Vector3( 1, 0, 0 ) );\n\t\tthis.add( cameraPX );\n\n\t\tconst cameraNX = new PerspectiveCamera( fov, aspect, near, far );\n\t\tcameraNX.layers = this.layers;\n\t\tcameraNX.up.set( 0, - 1, 0 );\n\t\tcameraNX.lookAt( new Vector3( - 1, 0, 0 ) );\n\t\tthis.add( cameraNX );\n\n\t\tconst cameraPY = new PerspectiveCamera( fov, aspect, near, far );\n\t\tcameraPY.layers = this.layers;\n\t\tcameraPY.up.set( 0, 0, 1 );\n\t\tcameraPY.lookAt( new Vector3( 0, 1, 0 ) );\n\t\tthis.add( cameraPY );\n\n\t\tconst cameraNY = new PerspectiveCamera( fov, aspect, near, far );\n\t\tcameraNY.layers = this.layers;\n\t\tcameraNY.up.set( 0, 0, - 1 );\n\t\tcameraNY.lookAt( new Vector3( 0, - 1, 0 ) );\n\t\tthis.add( cameraNY );\n\n\t\tconst cameraPZ = new PerspectiveCamera( fov, aspect, near, far );\n\t\tcameraPZ.layers = this.layers;\n\t\tcameraPZ.up.set( 0, - 1, 0 );\n\t\tcameraPZ.lookAt( new Vector3( 0, 0, 1 ) );\n\t\tthis.add( cameraPZ );\n\n\t\tconst cameraNZ = new PerspectiveCamera( fov, aspect, near, far );\n\t\tcameraNZ.layers = this.layers;\n\t\tcameraNZ.up.set( 0, - 1, 0 );\n\t\tcameraNZ.lookAt( new Vector3( 0, 0, - 1 ) );\n\t\tthis.add( cameraNZ );\n\n\t}\n\n\tupdate( renderer, scene ) {\n\n\t\tif ( this.parent === null ) this.updateMatrixWorld();\n\n\t\tconst renderTarget = this.renderTarget;\n\n\t\tconst [ cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ ] = this.children;\n\n\t\tconst currentXrEnabled = renderer.xr.enabled;\n\t\tconst currentRenderTarget = renderer.getRenderTarget();\n\n\t\trenderer.xr.enabled = false;\n\n\t\tconst generateMipmaps = renderTarget.texture.generateMipmaps;\n\n\t\trenderTarget.texture.generateMipmaps = false;\n\n\t\trenderer.setRenderTarget( renderTarget, 0 );\n\t\trenderer.render( scene, cameraPX );\n\n\t\trenderer.setRenderTarget( renderTarget, 1 );\n\t\trenderer.render( scene, cameraNX );\n\n\t\trenderer.setRenderTarget( renderTarget, 2 );\n\t\trenderer.render( scene, cameraPY );\n\n\t\trenderer.setRenderTarget( renderTarget, 3 );\n\t\trenderer.render( scene, cameraNY );\n\n\t\trenderer.setRenderTarget( renderTarget, 4 );\n\t\trenderer.render( scene, cameraPZ );\n\n\t\trenderTarget.texture.generateMipmaps = generateMipmaps;\n\n\t\trenderer.setRenderTarget( renderTarget, 5 );\n\t\trenderer.render( scene, cameraNZ );\n\n\t\trenderer.setRenderTarget( currentRenderTarget );\n\n\t\trenderer.xr.enabled = currentXrEnabled;\n\n\t\trenderTarget.texture.needsPMREMUpdate = true;\n\n\t}\n\n}\n\nclass CubeTexture extends Texture {\n\n\tconstructor( images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, encoding ) {\n\n\t\timages = images !== undefined ? images : [];\n\t\tmapping = mapping !== undefined ? mapping : CubeReflectionMapping;\n\n\t\tsuper( images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, encoding );\n\n\t\tthis.flipY = false;\n\n\t}\n\n\tget images() {\n\n\t\treturn this.image;\n\n\t}\n\n\tset images( value ) {\n\n\t\tthis.image = value;\n\n\t}\n\n}\n\nCubeTexture.prototype.isCubeTexture = true;\n\nclass WebGLCubeRenderTarget extends WebGLRenderTarget {\n\n\tconstructor( size, options = {} ) {\n\n\t\tsuper( size, size, options );\n\n\t\tconst image = { width: size, height: size, depth: 1 };\n\t\tconst images = [ image, image, image, image, image, image ];\n\n\t\tthis.texture = new CubeTexture( images, options.mapping, options.wrapS, options.wrapT, options.magFilter, options.minFilter, options.format, options.type, options.anisotropy, options.encoding );\n\n\t\t// By convention -- likely based on the RenderMan spec from the 1990's -- cube maps are specified by WebGL (and three.js)\n\t\t// in a coordinate system in which positive-x is to the right when looking up the positive-z axis -- in other words,\n\t\t// in a left-handed coordinate system. By continuing this convention, preexisting cube maps continued to render correctly.\n\n\t\t// three.js uses a right-handed coordinate system. So environment maps used in three.js appear to have px and nx swapped\n\t\t// and the flag isRenderTargetTexture controls this conversion. The flip is not required when using WebGLCubeRenderTarget.texture\n\t\t// as a cube texture (this is detected when isRenderTargetTexture is set to true for cube textures).\n\n\t\tthis.texture.isRenderTargetTexture = true;\n\n\t\tthis.texture.generateMipmaps = options.generateMipmaps !== undefined ? options.generateMipmaps : false;\n\t\tthis.texture.minFilter = options.minFilter !== undefined ? options.minFilter : LinearFilter;\n\n\t}\n\n\tfromEquirectangularTexture( renderer, texture ) {\n\n\t\tthis.texture.type = texture.type;\n\t\tthis.texture.format = RGBAFormat; // see #18859\n\t\tthis.texture.encoding = texture.encoding;\n\n\t\tthis.texture.generateMipmaps = texture.generateMipmaps;\n\t\tthis.texture.minFilter = texture.minFilter;\n\t\tthis.texture.magFilter = texture.magFilter;\n\n\t\tconst shader = {\n\n\t\t\tuniforms: {\n\t\t\t\ttEquirect: { value: null },\n\t\t\t},\n\n\t\t\tvertexShader: /* glsl */`\n\n\t\t\t\tvarying vec3 vWorldDirection;\n\n\t\t\t\tvec3 transformDirection( in vec3 dir, in mat4 matrix ) {\n\n\t\t\t\t\treturn normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );\n\n\t\t\t\t}\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\tvWorldDirection = transformDirection( position, modelMatrix );\n\n\t\t\t\t\t#include <begin_vertex>\n\t\t\t\t\t#include <project_vertex>\n\n\t\t\t\t}\n\t\t\t`,\n\n\t\t\tfragmentShader: /* glsl */`\n\n\t\t\t\tuniform sampler2D tEquirect;\n\n\t\t\t\tvarying vec3 vWorldDirection;\n\n\t\t\t\t#include <common>\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\tvec3 direction = normalize( vWorldDirection );\n\n\t\t\t\t\tvec2 sampleUV = equirectUv( direction );\n\n\t\t\t\t\tgl_FragColor = texture2D( tEquirect, sampleUV );\n\n\t\t\t\t}\n\t\t\t`\n\t\t};\n\n\t\tconst geometry = new BoxGeometry( 5, 5, 5 );\n\n\t\tconst material = new ShaderMaterial( {\n\n\t\t\tname: 'CubemapFromEquirect',\n\n\t\t\tuniforms: cloneUniforms( shader.uniforms ),\n\t\t\tvertexShader: shader.vertexShader,\n\t\t\tfragmentShader: shader.fragmentShader,\n\t\t\tside: BackSide,\n\t\t\tblending: NoBlending\n\n\t\t} );\n\n\t\tmaterial.uniforms.tEquirect.value = texture;\n\n\t\tconst mesh = new Mesh( geometry, material );\n\n\t\tconst currentMinFilter = texture.minFilter;\n\n\t\t// Avoid blurred poles\n\t\tif ( texture.minFilter === LinearMipmapLinearFilter ) texture.minFilter = LinearFilter;\n\n\t\tconst camera = new CubeCamera( 1, 10, this );\n\t\tcamera.update( renderer, mesh );\n\n\t\ttexture.minFilter = currentMinFilter;\n\n\t\tmesh.geometry.dispose();\n\t\tmesh.material.dispose();\n\n\t\treturn this;\n\n\t}\n\n\tclear( renderer, color, depth, stencil ) {\n\n\t\tconst currentRenderTarget = renderer.getRenderTarget();\n\n\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\trenderer.setRenderTarget( this, i );\n\n\t\t\trenderer.clear( color, depth, stencil );\n\n\t\t}\n\n\t\trenderer.setRenderTarget( currentRenderTarget );\n\n\t}\n\n}\n\nWebGLCubeRenderTarget.prototype.isWebGLCubeRenderTarget = true;\n\nconst _vector1 = /*@__PURE__*/ new Vector3();\nconst _vector2 = /*@__PURE__*/ new Vector3();\nconst _normalMatrix = /*@__PURE__*/ new Matrix3();\n\nclass Plane {\n\n\tconstructor( normal = new Vector3( 1, 0, 0 ), constant = 0 ) {\n\n\t\t// normal is assumed to be normalized\n\n\t\tthis.normal = normal;\n\t\tthis.constant = constant;\n\n\t}\n\n\tset( normal, constant ) {\n\n\t\tthis.normal.copy( normal );\n\t\tthis.constant = constant;\n\n\t\treturn this;\n\n\t}\n\n\tsetComponents( x, y, z, w ) {\n\n\t\tthis.normal.set( x, y, z );\n\t\tthis.constant = w;\n\n\t\treturn this;\n\n\t}\n\n\tsetFromNormalAndCoplanarPoint( normal, point ) {\n\n\t\tthis.normal.copy( normal );\n\t\tthis.constant = - point.dot( this.normal );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromCoplanarPoints( a, b, c ) {\n\n\t\tconst normal = _vector1.subVectors( c, b ).cross( _vector2.subVectors( a, b ) ).normalize();\n\n\t\t// Q: should an error be thrown if normal is zero (e.g. degenerate plane)?\n\n\t\tthis.setFromNormalAndCoplanarPoint( normal, a );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( plane ) {\n\n\t\tthis.normal.copy( plane.normal );\n\t\tthis.constant = plane.constant;\n\n\t\treturn this;\n\n\t}\n\n\tnormalize() {\n\n\t\t// Note: will lead to a divide by zero if the plane is invalid.\n\n\t\tconst inverseNormalLength = 1.0 / this.normal.length();\n\t\tthis.normal.multiplyScalar( inverseNormalLength );\n\t\tthis.constant *= inverseNormalLength;\n\n\t\treturn this;\n\n\t}\n\n\tnegate() {\n\n\t\tthis.constant *= - 1;\n\t\tthis.normal.negate();\n\n\t\treturn this;\n\n\t}\n\n\tdistanceToPoint( point ) {\n\n\t\treturn this.normal.dot( point ) + this.constant;\n\n\t}\n\n\tdistanceToSphere( sphere ) {\n\n\t\treturn this.distanceToPoint( sphere.center ) - sphere.radius;\n\n\t}\n\n\tprojectPoint( point, target ) {\n\n\t\treturn target.copy( this.normal ).multiplyScalar( - this.distanceToPoint( point ) ).add( point );\n\n\t}\n\n\tintersectLine( line, target ) {\n\n\t\tconst direction = line.delta( _vector1 );\n\n\t\tconst denominator = this.normal.dot( direction );\n\n\t\tif ( denominator === 0 ) {\n\n\t\t\t// line is coplanar, return origin\n\t\t\tif ( this.distanceToPoint( line.start ) === 0 ) {\n\n\t\t\t\treturn target.copy( line.start );\n\n\t\t\t}\n\n\t\t\t// Unsure if this is the correct method to handle this case.\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst t = - ( line.start.dot( this.normal ) + this.constant ) / denominator;\n\n\t\tif ( t < 0 || t > 1 ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\treturn target.copy( direction ).multiplyScalar( t ).add( line.start );\n\n\t}\n\n\tintersectsLine( line ) {\n\n\t\t// Note: this tests if a line intersects the plane, not whether it (or its end-points) are coplanar with it.\n\n\t\tconst startSign = this.distanceToPoint( line.start );\n\t\tconst endSign = this.distanceToPoint( line.end );\n\n\t\treturn ( startSign < 0 && endSign > 0 ) || ( endSign < 0 && startSign > 0 );\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\treturn box.intersectsPlane( this );\n\n\t}\n\n\tintersectsSphere( sphere ) {\n\n\t\treturn sphere.intersectsPlane( this );\n\n\t}\n\n\tcoplanarPoint( target ) {\n\n\t\treturn target.copy( this.normal ).multiplyScalar( - this.constant );\n\n\t}\n\n\tapplyMatrix4( matrix, optionalNormalMatrix ) {\n\n\t\tconst normalMatrix = optionalNormalMatrix || _normalMatrix.getNormalMatrix( matrix );\n\n\t\tconst referencePoint = this.coplanarPoint( _vector1 ).applyMatrix4( matrix );\n\n\t\tconst normal = this.normal.applyMatrix3( normalMatrix ).normalize();\n\n\t\tthis.constant = - referencePoint.dot( normal );\n\n\t\treturn this;\n\n\t}\n\n\ttranslate( offset ) {\n\n\t\tthis.constant -= offset.dot( this.normal );\n\n\t\treturn this;\n\n\t}\n\n\tequals( plane ) {\n\n\t\treturn plane.normal.equals( this.normal ) && ( plane.constant === this.constant );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nPlane.prototype.isPlane = true;\n\nconst _sphere$2 = /*@__PURE__*/ new Sphere();\nconst _vector$7 = /*@__PURE__*/ new Vector3();\n\nclass Frustum {\n\n\tconstructor( p0 = new Plane(), p1 = new Plane(), p2 = new Plane(), p3 = new Plane(), p4 = new Plane(), p5 = new Plane() ) {\n\n\t\tthis.planes = [ p0, p1, p2, p3, p4, p5 ];\n\n\t}\n\n\tset( p0, p1, p2, p3, p4, p5 ) {\n\n\t\tconst planes = this.planes;\n\n\t\tplanes[ 0 ].copy( p0 );\n\t\tplanes[ 1 ].copy( p1 );\n\t\tplanes[ 2 ].copy( p2 );\n\t\tplanes[ 3 ].copy( p3 );\n\t\tplanes[ 4 ].copy( p4 );\n\t\tplanes[ 5 ].copy( p5 );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( frustum ) {\n\n\t\tconst planes = this.planes;\n\n\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\tplanes[ i ].copy( frustum.planes[ i ] );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetFromProjectionMatrix( m ) {\n\n\t\tconst planes = this.planes;\n\t\tconst me = m.elements;\n\t\tconst me0 = me[ 0 ], me1 = me[ 1 ], me2 = me[ 2 ], me3 = me[ 3 ];\n\t\tconst me4 = me[ 4 ], me5 = me[ 5 ], me6 = me[ 6 ], me7 = me[ 7 ];\n\t\tconst me8 = me[ 8 ], me9 = me[ 9 ], me10 = me[ 10 ], me11 = me[ 11 ];\n\t\tconst me12 = me[ 12 ], me13 = me[ 13 ], me14 = me[ 14 ], me15 = me[ 15 ];\n\n\t\tplanes[ 0 ].setComponents( me3 - me0, me7 - me4, me11 - me8, me15 - me12 ).normalize();\n\t\tplanes[ 1 ].setComponents( me3 + me0, me7 + me4, me11 + me8, me15 + me12 ).normalize();\n\t\tplanes[ 2 ].setComponents( me3 + me1, me7 + me5, me11 + me9, me15 + me13 ).normalize();\n\t\tplanes[ 3 ].setComponents( me3 - me1, me7 - me5, me11 - me9, me15 - me13 ).normalize();\n\t\tplanes[ 4 ].setComponents( me3 - me2, me7 - me6, me11 - me10, me15 - me14 ).normalize();\n\t\tplanes[ 5 ].setComponents( me3 + me2, me7 + me6, me11 + me10, me15 + me14 ).normalize();\n\n\t\treturn this;\n\n\t}\n\n\tintersectsObject( object ) {\n\n\t\tconst geometry = object.geometry;\n\n\t\tif ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();\n\n\t\t_sphere$2.copy( geometry.boundingSphere ).applyMatrix4( object.matrixWorld );\n\n\t\treturn this.intersectsSphere( _sphere$2 );\n\n\t}\n\n\tintersectsSprite( sprite ) {\n\n\t\t_sphere$2.center.set( 0, 0, 0 );\n\t\t_sphere$2.radius = 0.7071067811865476;\n\t\t_sphere$2.applyMatrix4( sprite.matrixWorld );\n\n\t\treturn this.intersectsSphere( _sphere$2 );\n\n\t}\n\n\tintersectsSphere( sphere ) {\n\n\t\tconst planes = this.planes;\n\t\tconst center = sphere.center;\n\t\tconst negRadius = - sphere.radius;\n\n\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\tconst distance = planes[ i ].distanceToPoint( center );\n\n\t\t\tif ( distance < negRadius ) {\n\n\t\t\t\treturn false;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn true;\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\tconst planes = this.planes;\n\n\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\tconst plane = planes[ i ];\n\n\t\t\t// corner at max distance\n\n\t\t\t_vector$7.x = plane.normal.x > 0 ? box.max.x : box.min.x;\n\t\t\t_vector$7.y = plane.normal.y > 0 ? box.max.y : box.min.y;\n\t\t\t_vector$7.z = plane.normal.z > 0 ? box.max.z : box.min.z;\n\n\t\t\tif ( plane.distanceToPoint( _vector$7 ) < 0 ) {\n\n\t\t\t\treturn false;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn true;\n\n\t}\n\n\tcontainsPoint( point ) {\n\n\t\tconst planes = this.planes;\n\n\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\tif ( planes[ i ].distanceToPoint( point ) < 0 ) {\n\n\t\t\t\treturn false;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn true;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nfunction WebGLAnimation() {\n\n\tlet context = null;\n\tlet isAnimating = false;\n\tlet animationLoop = null;\n\tlet requestId = null;\n\n\tfunction onAnimationFrame( time, frame ) {\n\n\t\tanimationLoop( time, frame );\n\n\t\trequestId = context.requestAnimationFrame( onAnimationFrame );\n\n\t}\n\n\treturn {\n\n\t\tstart: function () {\n\n\t\t\tif ( isAnimating === true ) return;\n\t\t\tif ( animationLoop === null ) return;\n\n\t\t\trequestId = context.requestAnimationFrame( onAnimationFrame );\n\n\t\t\tisAnimating = true;\n\n\t\t},\n\n\t\tstop: function () {\n\n\t\t\tcontext.cancelAnimationFrame( requestId );\n\n\t\t\tisAnimating = false;\n\n\t\t},\n\n\t\tsetAnimationLoop: function ( callback ) {\n\n\t\t\tanimationLoop = callback;\n\n\t\t},\n\n\t\tsetContext: function ( value ) {\n\n\t\t\tcontext = value;\n\n\t\t}\n\n\t};\n\n}\n\nfunction WebGLAttributes( gl, capabilities ) {\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\n\tconst buffers = new WeakMap();\n\n\tfunction createBuffer( attribute, bufferType ) {\n\n\t\tconst array = attribute.array;\n\t\tconst usage = attribute.usage;\n\n\t\tconst buffer = gl.createBuffer();\n\n\t\tgl.bindBuffer( bufferType, buffer );\n\t\tgl.bufferData( bufferType, array, usage );\n\n\t\tattribute.onUploadCallback();\n\n\t\tlet type;\n\n\t\tif ( array instanceof Float32Array ) {\n\n\t\t\ttype = 5126;\n\n\t\t} else if ( array instanceof Uint16Array ) {\n\n\t\t\tif ( attribute.isFloat16BufferAttribute ) {\n\n\t\t\t\tif ( isWebGL2 ) {\n\n\t\t\t\t\ttype = 5131;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthrow new Error( 'THREE.WebGLAttributes: Usage of Float16BufferAttribute requires WebGL2.' );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\ttype = 5123;\n\n\t\t\t}\n\n\t\t} else if ( array instanceof Int16Array ) {\n\n\t\t\ttype = 5122;\n\n\t\t} else if ( array instanceof Uint32Array ) {\n\n\t\t\ttype = 5125;\n\n\t\t} else if ( array instanceof Int32Array ) {\n\n\t\t\ttype = 5124;\n\n\t\t} else if ( array instanceof Int8Array ) {\n\n\t\t\ttype = 5120;\n\n\t\t} else if ( array instanceof Uint8Array ) {\n\n\t\t\ttype = 5121;\n\n\t\t} else if ( array instanceof Uint8ClampedArray ) {\n\n\t\t\ttype = 5121;\n\n\t\t} else {\n\n\t\t\tthrow new Error( 'THREE.WebGLAttributes: Unsupported buffer data format: ' + array );\n\n\t\t}\n\n\t\treturn {\n\t\t\tbuffer: buffer,\n\t\t\ttype: type,\n\t\t\tbytesPerElement: array.BYTES_PER_ELEMENT,\n\t\t\tversion: attribute.version\n\t\t};\n\n\t}\n\n\tfunction updateBuffer( buffer, attribute, bufferType ) {\n\n\t\tconst array = attribute.array;\n\t\tconst updateRange = attribute.updateRange;\n\n\t\tgl.bindBuffer( bufferType, buffer );\n\n\t\tif ( updateRange.count === - 1 ) {\n\n\t\t\t// Not using update ranges\n\n\t\t\tgl.bufferSubData( bufferType, 0, array );\n\n\t\t} else {\n\n\t\t\tif ( isWebGL2 ) {\n\n\t\t\t\tgl.bufferSubData( bufferType, updateRange.offset * array.BYTES_PER_ELEMENT,\n\t\t\t\t\tarray, updateRange.offset, updateRange.count );\n\n\t\t\t} else {\n\n\t\t\t\tgl.bufferSubData( bufferType, updateRange.offset * array.BYTES_PER_ELEMENT,\n\t\t\t\t\tarray.subarray( updateRange.offset, updateRange.offset + updateRange.count ) );\n\n\t\t\t}\n\n\t\t\tupdateRange.count = - 1; // reset range\n\n\t\t}\n\n\t}\n\n\t//\n\n\tfunction get( attribute ) {\n\n\t\tif ( attribute.isInterleavedBufferAttribute ) attribute = attribute.data;\n\n\t\treturn buffers.get( attribute );\n\n\t}\n\n\tfunction remove( attribute ) {\n\n\t\tif ( attribute.isInterleavedBufferAttribute ) attribute = attribute.data;\n\n\t\tconst data = buffers.get( attribute );\n\n\t\tif ( data ) {\n\n\t\t\tgl.deleteBuffer( data.buffer );\n\n\t\t\tbuffers.delete( attribute );\n\n\t\t}\n\n\t}\n\n\tfunction update( attribute, bufferType ) {\n\n\t\tif ( attribute.isGLBufferAttribute ) {\n\n\t\t\tconst cached = buffers.get( attribute );\n\n\t\t\tif ( ! cached || cached.version < attribute.version ) {\n\n\t\t\t\tbuffers.set( attribute, {\n\t\t\t\t\tbuffer: attribute.buffer,\n\t\t\t\t\ttype: attribute.type,\n\t\t\t\t\tbytesPerElement: attribute.elementSize,\n\t\t\t\t\tversion: attribute.version\n\t\t\t\t} );\n\n\t\t\t}\n\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( attribute.isInterleavedBufferAttribute ) attribute = attribute.data;\n\n\t\tconst data = buffers.get( attribute );\n\n\t\tif ( data === undefined ) {\n\n\t\t\tbuffers.set( attribute, createBuffer( attribute, bufferType ) );\n\n\t\t} else if ( data.version < attribute.version ) {\n\n\t\t\tupdateBuffer( data.buffer, attribute, bufferType );\n\n\t\t\tdata.version = attribute.version;\n\n\t\t}\n\n\t}\n\n\treturn {\n\n\t\tget: get,\n\t\tremove: remove,\n\t\tupdate: update\n\n\t};\n\n}\n\nclass PlaneGeometry extends BufferGeometry {\n\n\tconstructor( width = 1, height = 1, widthSegments = 1, heightSegments = 1 ) {\n\n\t\tsuper();\n\t\tthis.type = 'PlaneGeometry';\n\n\t\tthis.parameters = {\n\t\t\twidth: width,\n\t\t\theight: height,\n\t\t\twidthSegments: widthSegments,\n\t\t\theightSegments: heightSegments\n\t\t};\n\n\t\tconst width_half = width / 2;\n\t\tconst height_half = height / 2;\n\n\t\tconst gridX = Math.floor( widthSegments );\n\t\tconst gridY = Math.floor( heightSegments );\n\n\t\tconst gridX1 = gridX + 1;\n\t\tconst gridY1 = gridY + 1;\n\n\t\tconst segment_width = width / gridX;\n\t\tconst segment_height = height / gridY;\n\n\t\t//\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\tfor ( let iy = 0; iy < gridY1; iy ++ ) {\n\n\t\t\tconst y = iy * segment_height - height_half;\n\n\t\t\tfor ( let ix = 0; ix < gridX1; ix ++ ) {\n\n\t\t\t\tconst x = ix * segment_width - width_half;\n\n\t\t\t\tvertices.push( x, - y, 0 );\n\n\t\t\t\tnormals.push( 0, 0, 1 );\n\n\t\t\t\tuvs.push( ix / gridX );\n\t\t\t\tuvs.push( 1 - ( iy / gridY ) );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfor ( let iy = 0; iy < gridY; iy ++ ) {\n\n\t\t\tfor ( let ix = 0; ix < gridX; ix ++ ) {\n\n\t\t\t\tconst a = ix + gridX1 * iy;\n\t\t\t\tconst b = ix + gridX1 * ( iy + 1 );\n\t\t\t\tconst c = ( ix + 1 ) + gridX1 * ( iy + 1 );\n\t\t\t\tconst d = ( ix + 1 ) + gridX1 * iy;\n\n\t\t\t\tindices.push( a, b, d );\n\t\t\t\tindices.push( b, c, d );\n\n\t\t\t}\n\n\t\t}\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new PlaneGeometry( data.width, data.height, data.widthSegments, data.heightSegments );\n\n\t}\n\n}\n\nvar alphamap_fragment = \"#ifdef USE_ALPHAMAP\\n\\tdiffuseColor.a *= texture2D( alphaMap, vUv ).g;\\n#endif\";\n\nvar alphamap_pars_fragment = \"#ifdef USE_ALPHAMAP\\n\\tuniform sampler2D alphaMap;\\n#endif\";\n\nvar alphatest_fragment = \"#ifdef USE_ALPHATEST\\n\\tif ( diffuseColor.a < alphaTest ) discard;\\n#endif\";\n\nvar alphatest_pars_fragment = \"#ifdef USE_ALPHATEST\\n\\tuniform float alphaTest;\\n#endif\";\n\nvar aomap_fragment = \"#ifdef USE_AOMAP\\n\\tfloat ambientOcclusion = ( texture2D( aoMap, vUv2 ).r - 1.0 ) * aoMapIntensity + 1.0;\\n\\treflectedLight.indirectDiffuse *= ambientOcclusion;\\n\\t#if defined( USE_ENVMAP ) && defined( STANDARD )\\n\\t\\tfloat dotNV = saturate( dot( geometry.normal, geometry.viewDir ) );\\n\\t\\treflectedLight.indirectSpecular *= computeSpecularOcclusion( dotNV, ambientOcclusion, material.roughness );\\n\\t#endif\\n#endif\";\n\nvar aomap_pars_fragment = \"#ifdef USE_AOMAP\\n\\tuniform sampler2D aoMap;\\n\\tuniform float aoMapIntensity;\\n#endif\";\n\nvar begin_vertex = \"vec3 transformed = vec3( position );\";\n\nvar beginnormal_vertex = \"vec3 objectNormal = vec3( normal );\\n#ifdef USE_TANGENT\\n\\tvec3 objectTangent = vec3( tangent.xyz );\\n#endif\";\n\nvar bsdfs = \"vec3 BRDF_Lambert( const in vec3 diffuseColor ) {\\n\\treturn RECIPROCAL_PI * diffuseColor;\\n}\\nvec3 F_Schlick( const in vec3 f0, const in float f90, const in float dotVH ) {\\n\\tfloat fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\\n\\treturn f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\\n}\\nfloat V_GGX_SmithCorrelated( const in float alpha, const in float dotNL, const in float dotNV ) {\\n\\tfloat a2 = pow2( alpha );\\n\\tfloat gv = dotNL * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );\\n\\tfloat gl = dotNV * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );\\n\\treturn 0.5 / max( gv + gl, EPSILON );\\n}\\nfloat D_GGX( const in float alpha, const in float dotNH ) {\\n\\tfloat a2 = pow2( alpha );\\n\\tfloat denom = pow2( dotNH ) * ( a2 - 1.0 ) + 1.0;\\n\\treturn RECIPROCAL_PI * a2 / pow2( denom );\\n}\\nvec3 BRDF_GGX( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in vec3 f0, const in float f90, const in float roughness ) {\\n\\tfloat alpha = pow2( roughness );\\n\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\tfloat dotNL = saturate( dot( normal, lightDir ) );\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\\n\\tvec3 F = F_Schlick( f0, f90, dotVH );\\n\\tfloat V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\\n\\tfloat D = D_GGX( alpha, dotNH );\\n\\treturn F * ( V * D );\\n}\\nvec2 LTC_Uv( const in vec3 N, const in vec3 V, const in float roughness ) {\\n\\tconst float LUT_SIZE = 64.0;\\n\\tconst float LUT_SCALE = ( LUT_SIZE - 1.0 ) / LUT_SIZE;\\n\\tconst float LUT_BIAS = 0.5 / LUT_SIZE;\\n\\tfloat dotNV = saturate( dot( N, V ) );\\n\\tvec2 uv = vec2( roughness, sqrt( 1.0 - dotNV ) );\\n\\tuv = uv * LUT_SCALE + LUT_BIAS;\\n\\treturn uv;\\n}\\nfloat LTC_ClippedSphereFormFactor( const in vec3 f ) {\\n\\tfloat l = length( f );\\n\\treturn max( ( l * l + f.z ) / ( l + 1.0 ), 0.0 );\\n}\\nvec3 LTC_EdgeVectorFormFactor( const in vec3 v1, const in vec3 v2 ) {\\n\\tfloat x = dot( v1, v2 );\\n\\tfloat y = abs( x );\\n\\tfloat a = 0.8543985 + ( 0.4965155 + 0.0145206 * y ) * y;\\n\\tfloat b = 3.4175940 + ( 4.1616724 + y ) * y;\\n\\tfloat v = a / b;\\n\\tfloat theta_sintheta = ( x > 0.0 ) ? v : 0.5 * inversesqrt( max( 1.0 - x * x, 1e-7 ) ) - v;\\n\\treturn cross( v1, v2 ) * theta_sintheta;\\n}\\nvec3 LTC_Evaluate( const in vec3 N, const in vec3 V, const in vec3 P, const in mat3 mInv, const in vec3 rectCoords[ 4 ] ) {\\n\\tvec3 v1 = rectCoords[ 1 ] - rectCoords[ 0 ];\\n\\tvec3 v2 = rectCoords[ 3 ] - rectCoords[ 0 ];\\n\\tvec3 lightNormal = cross( v1, v2 );\\n\\tif( dot( lightNormal, P - rectCoords[ 0 ] ) < 0.0 ) return vec3( 0.0 );\\n\\tvec3 T1, T2;\\n\\tT1 = normalize( V - N * dot( V, N ) );\\n\\tT2 = - cross( N, T1 );\\n\\tmat3 mat = mInv * transposeMat3( mat3( T1, T2, N ) );\\n\\tvec3 coords[ 4 ];\\n\\tcoords[ 0 ] = mat * ( rectCoords[ 0 ] - P );\\n\\tcoords[ 1 ] = mat * ( rectCoords[ 1 ] - P );\\n\\tcoords[ 2 ] = mat * ( rectCoords[ 2 ] - P );\\n\\tcoords[ 3 ] = mat * ( rectCoords[ 3 ] - P );\\n\\tcoords[ 0 ] = normalize( coords[ 0 ] );\\n\\tcoords[ 1 ] = normalize( coords[ 1 ] );\\n\\tcoords[ 2 ] = normalize( coords[ 2 ] );\\n\\tcoords[ 3 ] = normalize( coords[ 3 ] );\\n\\tvec3 vectorFormFactor = vec3( 0.0 );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 0 ], coords[ 1 ] );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 1 ], coords[ 2 ] );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 2 ], coords[ 3 ] );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 3 ], coords[ 0 ] );\\n\\tfloat result = LTC_ClippedSphereFormFactor( vectorFormFactor );\\n\\treturn vec3( result );\\n}\\nfloat G_BlinnPhong_Implicit( ) {\\n\\treturn 0.25;\\n}\\nfloat D_BlinnPhong( const in float shininess, const in float dotNH ) {\\n\\treturn RECIPROCAL_PI * ( shininess * 0.5 + 1.0 ) * pow( dotNH, shininess );\\n}\\nvec3 BRDF_BlinnPhong( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in vec3 specularColor, const in float shininess ) {\\n\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\\n\\tvec3 F = F_Schlick( specularColor, 1.0, dotVH );\\n\\tfloat G = G_BlinnPhong_Implicit( );\\n\\tfloat D = D_BlinnPhong( shininess, dotNH );\\n\\treturn F * ( G * D );\\n}\\n#if defined( USE_SHEEN )\\nfloat D_Charlie( float roughness, float dotNH ) {\\n\\tfloat alpha = pow2( roughness );\\n\\tfloat invAlpha = 1.0 / alpha;\\n\\tfloat cos2h = dotNH * dotNH;\\n\\tfloat sin2h = max( 1.0 - cos2h, 0.0078125 );\\n\\treturn ( 2.0 + invAlpha ) * pow( sin2h, invAlpha * 0.5 ) / ( 2.0 * PI );\\n}\\nfloat V_Neubelt( float dotNV, float dotNL ) {\\n\\treturn saturate( 1.0 / ( 4.0 * ( dotNL + dotNV - dotNL * dotNV ) ) );\\n}\\nvec3 BRDF_Sheen( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, vec3 sheenColor, const in float sheenRoughness ) {\\n\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\tfloat dotNL = saturate( dot( normal, lightDir ) );\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\tfloat D = D_Charlie( sheenRoughness, dotNH );\\n\\tfloat V = V_Neubelt( dotNV, dotNL );\\n\\treturn sheenColor * ( D * V );\\n}\\n#endif\";\n\nvar bumpmap_pars_fragment = \"#ifdef USE_BUMPMAP\\n\\tuniform sampler2D bumpMap;\\n\\tuniform float bumpScale;\\n\\tvec2 dHdxy_fwd() {\\n\\t\\tvec2 dSTdx = dFdx( vUv );\\n\\t\\tvec2 dSTdy = dFdy( vUv );\\n\\t\\tfloat Hll = bumpScale * texture2D( bumpMap, vUv ).x;\\n\\t\\tfloat dBx = bumpScale * texture2D( bumpMap, vUv + dSTdx ).x - Hll;\\n\\t\\tfloat dBy = bumpScale * texture2D( bumpMap, vUv + dSTdy ).x - Hll;\\n\\t\\treturn vec2( dBx, dBy );\\n\\t}\\n\\tvec3 perturbNormalArb( vec3 surf_pos, vec3 surf_norm, vec2 dHdxy, float faceDirection ) {\\n\\t\\tvec3 vSigmaX = vec3( dFdx( surf_pos.x ), dFdx( surf_pos.y ), dFdx( surf_pos.z ) );\\n\\t\\tvec3 vSigmaY = vec3( dFdy( surf_pos.x ), dFdy( surf_pos.y ), dFdy( surf_pos.z ) );\\n\\t\\tvec3 vN = surf_norm;\\n\\t\\tvec3 R1 = cross( vSigmaY, vN );\\n\\t\\tvec3 R2 = cross( vN, vSigmaX );\\n\\t\\tfloat fDet = dot( vSigmaX, R1 ) * faceDirection;\\n\\t\\tvec3 vGrad = sign( fDet ) * ( dHdxy.x * R1 + dHdxy.y * R2 );\\n\\t\\treturn normalize( abs( fDet ) * surf_norm - vGrad );\\n\\t}\\n#endif\";\n\nvar clipping_planes_fragment = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvec4 plane;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\\n\\t\\tplane = clippingPlanes[ i ];\\n\\t\\tif ( dot( vClipPosition, plane.xyz ) > plane.w ) discard;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\\n\\t\\tbool clipped = true;\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\\n\\t\\t\\tplane = clippingPlanes[ i ];\\n\\t\\t\\tclipped = ( dot( vClipPosition, plane.xyz ) > plane.w ) && clipped;\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t\\tif ( clipped ) discard;\\n\\t#endif\\n#endif\";\n\nvar clipping_planes_pars_fragment = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvarying vec3 vClipPosition;\\n\\tuniform vec4 clippingPlanes[ NUM_CLIPPING_PLANES ];\\n#endif\";\n\nvar clipping_planes_pars_vertex = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvarying vec3 vClipPosition;\\n#endif\";\n\nvar clipping_planes_vertex = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvClipPosition = - mvPosition.xyz;\\n#endif\";\n\nvar color_fragment = \"#if defined( USE_COLOR_ALPHA )\\n\\tdiffuseColor *= vColor;\\n#elif defined( USE_COLOR )\\n\\tdiffuseColor.rgb *= vColor;\\n#endif\";\n\nvar color_pars_fragment = \"#if defined( USE_COLOR_ALPHA )\\n\\tvarying vec4 vColor;\\n#elif defined( USE_COLOR )\\n\\tvarying vec3 vColor;\\n#endif\";\n\nvar color_pars_vertex = \"#if defined( USE_COLOR_ALPHA )\\n\\tvarying vec4 vColor;\\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR )\\n\\tvarying vec3 vColor;\\n#endif\";\n\nvar color_vertex = \"#if defined( USE_COLOR_ALPHA )\\n\\tvColor = vec4( 1.0 );\\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR )\\n\\tvColor = vec3( 1.0 );\\n#endif\\n#ifdef USE_COLOR\\n\\tvColor *= color;\\n#endif\\n#ifdef USE_INSTANCING_COLOR\\n\\tvColor.xyz *= instanceColor.xyz;\\n#endif\";\n\nvar common = \"#define PI 3.141592653589793\\n#define PI2 6.283185307179586\\n#define PI_HALF 1.5707963267948966\\n#define RECIPROCAL_PI 0.3183098861837907\\n#define RECIPROCAL_PI2 0.15915494309189535\\n#define EPSILON 1e-6\\n#ifndef saturate\\n#define saturate( a ) clamp( a, 0.0, 1.0 )\\n#endif\\n#define whiteComplement( a ) ( 1.0 - saturate( a ) )\\nfloat pow2( const in float x ) { return x*x; }\\nfloat pow3( const in float x ) { return x*x*x; }\\nfloat pow4( const in float x ) { float x2 = x*x; return x2*x2; }\\nfloat max3( const in vec3 v ) { return max( max( v.x, v.y ), v.z ); }\\nfloat average( const in vec3 color ) { return dot( color, vec3( 0.3333 ) ); }\\nhighp float rand( const in vec2 uv ) {\\n\\tconst highp float a = 12.9898, b = 78.233, c = 43758.5453;\\n\\thighp float dt = dot( uv.xy, vec2( a,b ) ), sn = mod( dt, PI );\\n\\treturn fract( sin( sn ) * c );\\n}\\n#ifdef HIGH_PRECISION\\n\\tfloat precisionSafeLength( vec3 v ) { return length( v ); }\\n#else\\n\\tfloat precisionSafeLength( vec3 v ) {\\n\\t\\tfloat maxComponent = max3( abs( v ) );\\n\\t\\treturn length( v / maxComponent ) * maxComponent;\\n\\t}\\n#endif\\nstruct IncidentLight {\\n\\tvec3 color;\\n\\tvec3 direction;\\n\\tbool visible;\\n};\\nstruct ReflectedLight {\\n\\tvec3 directDiffuse;\\n\\tvec3 directSpecular;\\n\\tvec3 indirectDiffuse;\\n\\tvec3 indirectSpecular;\\n};\\nstruct GeometricContext {\\n\\tvec3 position;\\n\\tvec3 normal;\\n\\tvec3 viewDir;\\n#ifdef USE_CLEARCOAT\\n\\tvec3 clearcoatNormal;\\n#endif\\n};\\nvec3 transformDirection( in vec3 dir, in mat4 matrix ) {\\n\\treturn normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );\\n}\\nvec3 inverseTransformDirection( in vec3 dir, in mat4 matrix ) {\\n\\treturn normalize( ( vec4( dir, 0.0 ) * matrix ).xyz );\\n}\\nmat3 transposeMat3( const in mat3 m ) {\\n\\tmat3 tmp;\\n\\ttmp[ 0 ] = vec3( m[ 0 ].x, m[ 1 ].x, m[ 2 ].x );\\n\\ttmp[ 1 ] = vec3( m[ 0 ].y, m[ 1 ].y, m[ 2 ].y );\\n\\ttmp[ 2 ] = vec3( m[ 0 ].z, m[ 1 ].z, m[ 2 ].z );\\n\\treturn tmp;\\n}\\nfloat linearToRelativeLuminance( const in vec3 color ) {\\n\\tvec3 weights = vec3( 0.2126, 0.7152, 0.0722 );\\n\\treturn dot( weights, color.rgb );\\n}\\nbool isPerspectiveMatrix( mat4 m ) {\\n\\treturn m[ 2 ][ 3 ] == - 1.0;\\n}\\nvec2 equirectUv( in vec3 dir ) {\\n\\tfloat u = atan( dir.z, dir.x ) * RECIPROCAL_PI2 + 0.5;\\n\\tfloat v = asin( clamp( dir.y, - 1.0, 1.0 ) ) * RECIPROCAL_PI + 0.5;\\n\\treturn vec2( u, v );\\n}\";\n\nvar cube_uv_reflection_fragment = \"#ifdef ENVMAP_TYPE_CUBE_UV\\n\\t#define cubeUV_minMipLevel 4.0\\n\\t#define cubeUV_minTileSize 16.0\\n\\tfloat getFace( vec3 direction ) {\\n\\t\\tvec3 absDirection = abs( direction );\\n\\t\\tfloat face = - 1.0;\\n\\t\\tif ( absDirection.x > absDirection.z ) {\\n\\t\\t\\tif ( absDirection.x > absDirection.y )\\n\\t\\t\\t\\tface = direction.x > 0.0 ? 0.0 : 3.0;\\n\\t\\t\\telse\\n\\t\\t\\t\\tface = direction.y > 0.0 ? 1.0 : 4.0;\\n\\t\\t} else {\\n\\t\\t\\tif ( absDirection.z > absDirection.y )\\n\\t\\t\\t\\tface = direction.z > 0.0 ? 2.0 : 5.0;\\n\\t\\t\\telse\\n\\t\\t\\t\\tface = direction.y > 0.0 ? 1.0 : 4.0;\\n\\t\\t}\\n\\t\\treturn face;\\n\\t}\\n\\tvec2 getUV( vec3 direction, float face ) {\\n\\t\\tvec2 uv;\\n\\t\\tif ( face == 0.0 ) {\\n\\t\\t\\tuv = vec2( direction.z, direction.y ) / abs( direction.x );\\n\\t\\t} else if ( face == 1.0 ) {\\n\\t\\t\\tuv = vec2( - direction.x, - direction.z ) / abs( direction.y );\\n\\t\\t} else if ( face == 2.0 ) {\\n\\t\\t\\tuv = vec2( - direction.x, direction.y ) / abs( direction.z );\\n\\t\\t} else if ( face == 3.0 ) {\\n\\t\\t\\tuv = vec2( - direction.z, direction.y ) / abs( direction.x );\\n\\t\\t} else if ( face == 4.0 ) {\\n\\t\\t\\tuv = vec2( - direction.x, direction.z ) / abs( direction.y );\\n\\t\\t} else {\\n\\t\\t\\tuv = vec2( direction.x, direction.y ) / abs( direction.z );\\n\\t\\t}\\n\\t\\treturn 0.5 * ( uv + 1.0 );\\n\\t}\\n\\tvec3 bilinearCubeUV( sampler2D envMap, vec3 direction, float mipInt ) {\\n\\t\\tfloat face = getFace( direction );\\n\\t\\tfloat filterInt = max( cubeUV_minMipLevel - mipInt, 0.0 );\\n\\t\\tmipInt = max( mipInt, cubeUV_minMipLevel );\\n\\t\\tfloat faceSize = exp2( mipInt );\\n\\t\\tvec2 uv = getUV( direction, face ) * ( faceSize - 1.0 ) + 0.5;\\n\\t\\tif ( face > 2.0 ) {\\n\\t\\t\\tuv.y += faceSize;\\n\\t\\t\\tface -= 3.0;\\n\\t\\t}\\n\\t\\tuv.x += face * faceSize;\\n\\t\\tuv.x += filterInt * 3.0 * cubeUV_minTileSize;\\n\\t\\tuv.y += 4.0 * ( exp2( CUBEUV_MAX_MIP ) - faceSize );\\n\\t\\tuv.x *= CUBEUV_TEXEL_WIDTH;\\n\\t\\tuv.y *= CUBEUV_TEXEL_HEIGHT;\\n\\t\\t#ifdef texture2DGradEXT\\n\\t\\t\\treturn texture2DGradEXT( envMap, uv, vec2( 0.0 ), vec2( 0.0 ) ).rgb;\\n\\t\\t#else\\n\\t\\t\\treturn texture2D( envMap, uv ).rgb;\\n\\t\\t#endif\\n\\t}\\n\\t#define r0 1.0\\n\\t#define v0 0.339\\n\\t#define m0 - 2.0\\n\\t#define r1 0.8\\n\\t#define v1 0.276\\n\\t#define m1 - 1.0\\n\\t#define r4 0.4\\n\\t#define v4 0.046\\n\\t#define m4 2.0\\n\\t#define r5 0.305\\n\\t#define v5 0.016\\n\\t#define m5 3.0\\n\\t#define r6 0.21\\n\\t#define v6 0.0038\\n\\t#define m6 4.0\\n\\tfloat roughnessToMip( float roughness ) {\\n\\t\\tfloat mip = 0.0;\\n\\t\\tif ( roughness >= r1 ) {\\n\\t\\t\\tmip = ( r0 - roughness ) * ( m1 - m0 ) / ( r0 - r1 ) + m0;\\n\\t\\t} else if ( roughness >= r4 ) {\\n\\t\\t\\tmip = ( r1 - roughness ) * ( m4 - m1 ) / ( r1 - r4 ) + m1;\\n\\t\\t} else if ( roughness >= r5 ) {\\n\\t\\t\\tmip = ( r4 - roughness ) * ( m5 - m4 ) / ( r4 - r5 ) + m4;\\n\\t\\t} else if ( roughness >= r6 ) {\\n\\t\\t\\tmip = ( r5 - roughness ) * ( m6 - m5 ) / ( r5 - r6 ) + m5;\\n\\t\\t} else {\\n\\t\\t\\tmip = - 2.0 * log2( 1.16 * roughness );\\t\\t}\\n\\t\\treturn mip;\\n\\t}\\n\\tvec4 textureCubeUV( sampler2D envMap, vec3 sampleDir, float roughness ) {\\n\\t\\tfloat mip = clamp( roughnessToMip( roughness ), m0, CUBEUV_MAX_MIP );\\n\\t\\tfloat mipF = fract( mip );\\n\\t\\tfloat mipInt = floor( mip );\\n\\t\\tvec3 color0 = bilinearCubeUV( envMap, sampleDir, mipInt );\\n\\t\\tif ( mipF == 0.0 ) {\\n\\t\\t\\treturn vec4( color0, 1.0 );\\n\\t\\t} else {\\n\\t\\t\\tvec3 color1 = bilinearCubeUV( envMap, sampleDir, mipInt + 1.0 );\\n\\t\\t\\treturn vec4( mix( color0, color1, mipF ), 1.0 );\\n\\t\\t}\\n\\t}\\n#endif\";\n\nvar defaultnormal_vertex = \"vec3 transformedNormal = objectNormal;\\n#ifdef USE_INSTANCING\\n\\tmat3 m = mat3( instanceMatrix );\\n\\ttransformedNormal /= vec3( dot( m[ 0 ], m[ 0 ] ), dot( m[ 1 ], m[ 1 ] ), dot( m[ 2 ], m[ 2 ] ) );\\n\\ttransformedNormal = m * transformedNormal;\\n#endif\\ntransformedNormal = normalMatrix * transformedNormal;\\n#ifdef FLIP_SIDED\\n\\ttransformedNormal = - transformedNormal;\\n#endif\\n#ifdef USE_TANGENT\\n\\tvec3 transformedTangent = ( modelViewMatrix * vec4( objectTangent, 0.0 ) ).xyz;\\n\\t#ifdef FLIP_SIDED\\n\\t\\ttransformedTangent = - transformedTangent;\\n\\t#endif\\n#endif\";\n\nvar displacementmap_pars_vertex = \"#ifdef USE_DISPLACEMENTMAP\\n\\tuniform sampler2D displacementMap;\\n\\tuniform float displacementScale;\\n\\tuniform float displacementBias;\\n#endif\";\n\nvar displacementmap_vertex = \"#ifdef USE_DISPLACEMENTMAP\\n\\ttransformed += normalize( objectNormal ) * ( texture2D( displacementMap, vUv ).x * displacementScale + displacementBias );\\n#endif\";\n\nvar emissivemap_fragment = \"#ifdef USE_EMISSIVEMAP\\n\\tvec4 emissiveColor = texture2D( emissiveMap, vUv );\\n\\ttotalEmissiveRadiance *= emissiveColor.rgb;\\n#endif\";\n\nvar emissivemap_pars_fragment = \"#ifdef USE_EMISSIVEMAP\\n\\tuniform sampler2D emissiveMap;\\n#endif\";\n\nvar encodings_fragment = \"gl_FragColor = linearToOutputTexel( gl_FragColor );\";\n\nvar encodings_pars_fragment = \"vec4 LinearToLinear( in vec4 value ) {\\n\\treturn value;\\n}\\nvec4 LinearTosRGB( in vec4 value ) {\\n\\treturn vec4( mix( pow( value.rgb, vec3( 0.41666 ) ) * 1.055 - vec3( 0.055 ), value.rgb * 12.92, vec3( lessThanEqual( value.rgb, vec3( 0.0031308 ) ) ) ), value.a );\\n}\";\n\nvar envmap_fragment = \"#ifdef USE_ENVMAP\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\tvec3 cameraToFrag;\\n\\t\\tif ( isOrthographic ) {\\n\\t\\t\\tcameraToFrag = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\\n\\t\\t} else {\\n\\t\\t\\tcameraToFrag = normalize( vWorldPosition - cameraPosition );\\n\\t\\t}\\n\\t\\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\\n\\t\\t#ifdef ENVMAP_MODE_REFLECTION\\n\\t\\t\\tvec3 reflectVec = reflect( cameraToFrag, worldNormal );\\n\\t\\t#else\\n\\t\\t\\tvec3 reflectVec = refract( cameraToFrag, worldNormal, refractionRatio );\\n\\t\\t#endif\\n\\t#else\\n\\t\\tvec3 reflectVec = vReflect;\\n\\t#endif\\n\\t#ifdef ENVMAP_TYPE_CUBE\\n\\t\\tvec4 envColor = textureCube( envMap, vec3( flipEnvMap * reflectVec.x, reflectVec.yz ) );\\n\\t#elif defined( ENVMAP_TYPE_CUBE_UV )\\n\\t\\tvec4 envColor = textureCubeUV( envMap, reflectVec, 0.0 );\\n\\t#else\\n\\t\\tvec4 envColor = vec4( 0.0 );\\n\\t#endif\\n\\t#ifdef ENVMAP_BLENDING_MULTIPLY\\n\\t\\toutgoingLight = mix( outgoingLight, outgoingLight * envColor.xyz, specularStrength * reflectivity );\\n\\t#elif defined( ENVMAP_BLENDING_MIX )\\n\\t\\toutgoingLight = mix( outgoingLight, envColor.xyz, specularStrength * reflectivity );\\n\\t#elif defined( ENVMAP_BLENDING_ADD )\\n\\t\\toutgoingLight += envColor.xyz * specularStrength * reflectivity;\\n\\t#endif\\n#endif\";\n\nvar envmap_common_pars_fragment = \"#ifdef USE_ENVMAP\\n\\tuniform float envMapIntensity;\\n\\tuniform float flipEnvMap;\\n\\t#ifdef ENVMAP_TYPE_CUBE\\n\\t\\tuniform samplerCube envMap;\\n\\t#else\\n\\t\\tuniform sampler2D envMap;\\n\\t#endif\\n\\t\\n#endif\";\n\nvar envmap_pars_fragment = \"#ifdef USE_ENVMAP\\n\\tuniform float reflectivity;\\n\\t#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG )\\n\\t\\t#define ENV_WORLDPOS\\n\\t#endif\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\tvarying vec3 vWorldPosition;\\n\\t\\tuniform float refractionRatio;\\n\\t#else\\n\\t\\tvarying vec3 vReflect;\\n\\t#endif\\n#endif\";\n\nvar envmap_pars_vertex = \"#ifdef USE_ENVMAP\\n\\t#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) ||defined( PHONG )\\n\\t\\t#define ENV_WORLDPOS\\n\\t#endif\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\t\\n\\t\\tvarying vec3 vWorldPosition;\\n\\t#else\\n\\t\\tvarying vec3 vReflect;\\n\\t\\tuniform float refractionRatio;\\n\\t#endif\\n#endif\";\n\nvar envmap_vertex = \"#ifdef USE_ENVMAP\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\tvWorldPosition = worldPosition.xyz;\\n\\t#else\\n\\t\\tvec3 cameraToVertex;\\n\\t\\tif ( isOrthographic ) {\\n\\t\\t\\tcameraToVertex = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\\n\\t\\t} else {\\n\\t\\t\\tcameraToVertex = normalize( worldPosition.xyz - cameraPosition );\\n\\t\\t}\\n\\t\\tvec3 worldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\\n\\t\\t#ifdef ENVMAP_MODE_REFLECTION\\n\\t\\t\\tvReflect = reflect( cameraToVertex, worldNormal );\\n\\t\\t#else\\n\\t\\t\\tvReflect = refract( cameraToVertex, worldNormal, refractionRatio );\\n\\t\\t#endif\\n\\t#endif\\n#endif\";\n\nvar fog_vertex = \"#ifdef USE_FOG\\n\\tvFogDepth = - mvPosition.z;\\n#endif\";\n\nvar fog_pars_vertex = \"#ifdef USE_FOG\\n\\tvarying float vFogDepth;\\n#endif\";\n\nvar fog_fragment = \"#ifdef USE_FOG\\n\\t#ifdef FOG_EXP2\\n\\t\\tfloat fogFactor = 1.0 - exp( - fogDensity * fogDensity * vFogDepth * vFogDepth );\\n\\t#else\\n\\t\\tfloat fogFactor = smoothstep( fogNear, fogFar, vFogDepth );\\n\\t#endif\\n\\tgl_FragColor.rgb = mix( gl_FragColor.rgb, fogColor, fogFactor );\\n#endif\";\n\nvar fog_pars_fragment = \"#ifdef USE_FOG\\n\\tuniform vec3 fogColor;\\n\\tvarying float vFogDepth;\\n\\t#ifdef FOG_EXP2\\n\\t\\tuniform float fogDensity;\\n\\t#else\\n\\t\\tuniform float fogNear;\\n\\t\\tuniform float fogFar;\\n\\t#endif\\n#endif\";\n\nvar gradientmap_pars_fragment = \"#ifdef USE_GRADIENTMAP\\n\\tuniform sampler2D gradientMap;\\n#endif\\nvec3 getGradientIrradiance( vec3 normal, vec3 lightDirection ) {\\n\\tfloat dotNL = dot( normal, lightDirection );\\n\\tvec2 coord = vec2( dotNL * 0.5 + 0.5, 0.0 );\\n\\t#ifdef USE_GRADIENTMAP\\n\\t\\treturn vec3( texture2D( gradientMap, coord ).r );\\n\\t#else\\n\\t\\treturn ( coord.x < 0.7 ) ? vec3( 0.7 ) : vec3( 1.0 );\\n\\t#endif\\n}\";\n\nvar lightmap_fragment = \"#ifdef USE_LIGHTMAP\\n\\tvec4 lightMapTexel = texture2D( lightMap, vUv2 );\\n\\tvec3 lightMapIrradiance = lightMapTexel.rgb * lightMapIntensity;\\n\\t#ifndef PHYSICALLY_CORRECT_LIGHTS\\n\\t\\tlightMapIrradiance *= PI;\\n\\t#endif\\n\\treflectedLight.indirectDiffuse += lightMapIrradiance;\\n#endif\";\n\nvar lightmap_pars_fragment = \"#ifdef USE_LIGHTMAP\\n\\tuniform sampler2D lightMap;\\n\\tuniform float lightMapIntensity;\\n#endif\";\n\nvar lights_lambert_vertex = \"vec3 diffuse = vec3( 1.0 );\\nGeometricContext geometry;\\ngeometry.position = mvPosition.xyz;\\ngeometry.normal = normalize( transformedNormal );\\ngeometry.viewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( -mvPosition.xyz );\\nGeometricContext backGeometry;\\nbackGeometry.position = geometry.position;\\nbackGeometry.normal = -geometry.normal;\\nbackGeometry.viewDir = geometry.viewDir;\\nvLightFront = vec3( 0.0 );\\nvIndirectFront = vec3( 0.0 );\\n#ifdef DOUBLE_SIDED\\n\\tvLightBack = vec3( 0.0 );\\n\\tvIndirectBack = vec3( 0.0 );\\n#endif\\nIncidentLight directLight;\\nfloat dotNL;\\nvec3 directLightColor_Diffuse;\\nvIndirectFront += getAmbientLightIrradiance( ambientLightColor );\\nvIndirectFront += getLightProbeIrradiance( lightProbe, geometry.normal );\\n#ifdef DOUBLE_SIDED\\n\\tvIndirectBack += getAmbientLightIrradiance( ambientLightColor );\\n\\tvIndirectBack += getLightProbeIrradiance( lightProbe, backGeometry.normal );\\n#endif\\n#if NUM_POINT_LIGHTS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {\\n\\t\\tgetPointLightInfo( pointLights[ i ], geometry, directLight );\\n\\t\\tdotNL = dot( geometry.normal, directLight.direction );\\n\\t\\tdirectLightColor_Diffuse = directLight.color;\\n\\t\\tvLightFront += saturate( dotNL ) * directLightColor_Diffuse;\\n\\t\\t#ifdef DOUBLE_SIDED\\n\\t\\t\\tvLightBack += saturate( - dotNL ) * directLightColor_Diffuse;\\n\\t\\t#endif\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if NUM_SPOT_LIGHTS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {\\n\\t\\tgetSpotLightInfo( spotLights[ i ], geometry, directLight );\\n\\t\\tdotNL = dot( geometry.normal, directLight.direction );\\n\\t\\tdirectLightColor_Diffuse = directLight.color;\\n\\t\\tvLightFront += saturate( dotNL ) * directLightColor_Diffuse;\\n\\t\\t#ifdef DOUBLE_SIDED\\n\\t\\t\\tvLightBack += saturate( - dotNL ) * directLightColor_Diffuse;\\n\\t\\t#endif\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if NUM_DIR_LIGHTS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {\\n\\t\\tgetDirectionalLightInfo( directionalLights[ i ], geometry, directLight );\\n\\t\\tdotNL = dot( geometry.normal, directLight.direction );\\n\\t\\tdirectLightColor_Diffuse = directLight.color;\\n\\t\\tvLightFront += saturate( dotNL ) * directLightColor_Diffuse;\\n\\t\\t#ifdef DOUBLE_SIDED\\n\\t\\t\\tvLightBack += saturate( - dotNL ) * directLightColor_Diffuse;\\n\\t\\t#endif\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if NUM_HEMI_LIGHTS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {\\n\\t\\tvIndirectFront += getHemisphereLightIrradiance( hemisphereLights[ i ], geometry.normal );\\n\\t\\t#ifdef DOUBLE_SIDED\\n\\t\\t\\tvIndirectBack += getHemisphereLightIrradiance( hemisphereLights[ i ], backGeometry.normal );\\n\\t\\t#endif\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\";\n\nvar lights_pars_begin = \"uniform bool receiveShadow;\\nuniform vec3 ambientLightColor;\\nuniform vec3 lightProbe[ 9 ];\\nvec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {\\n\\tfloat x = normal.x, y = normal.y, z = normal.z;\\n\\tvec3 result = shCoefficients[ 0 ] * 0.886227;\\n\\tresult += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;\\n\\tresult += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;\\n\\tresult += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;\\n\\tresult += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;\\n\\tresult += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;\\n\\tresult += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );\\n\\tresult += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;\\n\\tresult += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );\\n\\treturn result;\\n}\\nvec3 getLightProbeIrradiance( const in vec3 lightProbe[ 9 ], const in vec3 normal ) {\\n\\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\\n\\tvec3 irradiance = shGetIrradianceAt( worldNormal, lightProbe );\\n\\treturn irradiance;\\n}\\nvec3 getAmbientLightIrradiance( const in vec3 ambientLightColor ) {\\n\\tvec3 irradiance = ambientLightColor;\\n\\treturn irradiance;\\n}\\nfloat getDistanceAttenuation( const in float lightDistance, const in float cutoffDistance, const in float decayExponent ) {\\n\\t#if defined ( PHYSICALLY_CORRECT_LIGHTS )\\n\\t\\tfloat distanceFalloff = 1.0 / max( pow( lightDistance, decayExponent ), 0.01 );\\n\\t\\tif ( cutoffDistance > 0.0 ) {\\n\\t\\t\\tdistanceFalloff *= pow2( saturate( 1.0 - pow4( lightDistance / cutoffDistance ) ) );\\n\\t\\t}\\n\\t\\treturn distanceFalloff;\\n\\t#else\\n\\t\\tif ( cutoffDistance > 0.0 && decayExponent > 0.0 ) {\\n\\t\\t\\treturn pow( saturate( - lightDistance / cutoffDistance + 1.0 ), decayExponent );\\n\\t\\t}\\n\\t\\treturn 1.0;\\n\\t#endif\\n}\\nfloat getSpotAttenuation( const in float coneCosine, const in float penumbraCosine, const in float angleCosine ) {\\n\\treturn smoothstep( coneCosine, penumbraCosine, angleCosine );\\n}\\n#if NUM_DIR_LIGHTS > 0\\n\\tstruct DirectionalLight {\\n\\t\\tvec3 direction;\\n\\t\\tvec3 color;\\n\\t};\\n\\tuniform DirectionalLight directionalLights[ NUM_DIR_LIGHTS ];\\n\\tvoid getDirectionalLightInfo( const in DirectionalLight directionalLight, const in GeometricContext geometry, out IncidentLight light ) {\\n\\t\\tlight.color = directionalLight.color;\\n\\t\\tlight.direction = directionalLight.direction;\\n\\t\\tlight.visible = true;\\n\\t}\\n#endif\\n#if NUM_POINT_LIGHTS > 0\\n\\tstruct PointLight {\\n\\t\\tvec3 position;\\n\\t\\tvec3 color;\\n\\t\\tfloat distance;\\n\\t\\tfloat decay;\\n\\t};\\n\\tuniform PointLight pointLights[ NUM_POINT_LIGHTS ];\\n\\tvoid getPointLightInfo( const in PointLight pointLight, const in GeometricContext geometry, out IncidentLight light ) {\\n\\t\\tvec3 lVector = pointLight.position - geometry.position;\\n\\t\\tlight.direction = normalize( lVector );\\n\\t\\tfloat lightDistance = length( lVector );\\n\\t\\tlight.color = pointLight.color;\\n\\t\\tlight.color *= getDistanceAttenuation( lightDistance, pointLight.distance, pointLight.decay );\\n\\t\\tlight.visible = ( light.color != vec3( 0.0 ) );\\n\\t}\\n#endif\\n#if NUM_SPOT_LIGHTS > 0\\n\\tstruct SpotLight {\\n\\t\\tvec3 position;\\n\\t\\tvec3 direction;\\n\\t\\tvec3 color;\\n\\t\\tfloat distance;\\n\\t\\tfloat decay;\\n\\t\\tfloat coneCos;\\n\\t\\tfloat penumbraCos;\\n\\t};\\n\\tuniform SpotLight spotLights[ NUM_SPOT_LIGHTS ];\\n\\tvoid getSpotLightInfo( const in SpotLight spotLight, const in GeometricContext geometry, out IncidentLight light ) {\\n\\t\\tvec3 lVector = spotLight.position - geometry.position;\\n\\t\\tlight.direction = normalize( lVector );\\n\\t\\tfloat angleCos = dot( light.direction, spotLight.direction );\\n\\t\\tfloat spotAttenuation = getSpotAttenuation( spotLight.coneCos, spotLight.penumbraCos, angleCos );\\n\\t\\tif ( spotAttenuation > 0.0 ) {\\n\\t\\t\\tfloat lightDistance = length( lVector );\\n\\t\\t\\tlight.color = spotLight.color * spotAttenuation;\\n\\t\\t\\tlight.color *= getDistanceAttenuation( lightDistance, spotLight.distance, spotLight.decay );\\n\\t\\t\\tlight.visible = ( light.color != vec3( 0.0 ) );\\n\\t\\t} else {\\n\\t\\t\\tlight.color = vec3( 0.0 );\\n\\t\\t\\tlight.visible = false;\\n\\t\\t}\\n\\t}\\n#endif\\n#if NUM_RECT_AREA_LIGHTS > 0\\n\\tstruct RectAreaLight {\\n\\t\\tvec3 color;\\n\\t\\tvec3 position;\\n\\t\\tvec3 halfWidth;\\n\\t\\tvec3 halfHeight;\\n\\t};\\n\\tuniform sampler2D ltc_1;\\tuniform sampler2D ltc_2;\\n\\tuniform RectAreaLight rectAreaLights[ NUM_RECT_AREA_LIGHTS ];\\n#endif\\n#if NUM_HEMI_LIGHTS > 0\\n\\tstruct HemisphereLight {\\n\\t\\tvec3 direction;\\n\\t\\tvec3 skyColor;\\n\\t\\tvec3 groundColor;\\n\\t};\\n\\tuniform HemisphereLight hemisphereLights[ NUM_HEMI_LIGHTS ];\\n\\tvec3 getHemisphereLightIrradiance( const in HemisphereLight hemiLight, const in vec3 normal ) {\\n\\t\\tfloat dotNL = dot( normal, hemiLight.direction );\\n\\t\\tfloat hemiDiffuseWeight = 0.5 * dotNL + 0.5;\\n\\t\\tvec3 irradiance = mix( hemiLight.groundColor, hemiLight.skyColor, hemiDiffuseWeight );\\n\\t\\treturn irradiance;\\n\\t}\\n#endif\";\n\nvar envmap_physical_pars_fragment = \"#if defined( USE_ENVMAP )\\n\\t#ifdef ENVMAP_MODE_REFRACTION\\n\\t\\tuniform float refractionRatio;\\n\\t#endif\\n\\tvec3 getIBLIrradiance( const in vec3 normal ) {\\n\\t\\t#if defined( ENVMAP_TYPE_CUBE_UV )\\n\\t\\t\\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\\n\\t\\t\\tvec4 envMapColor = textureCubeUV( envMap, worldNormal, 1.0 );\\n\\t\\t\\treturn PI * envMapColor.rgb * envMapIntensity;\\n\\t\\t#else\\n\\t\\t\\treturn vec3( 0.0 );\\n\\t\\t#endif\\n\\t}\\n\\tvec3 getIBLRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness ) {\\n\\t\\t#if defined( ENVMAP_TYPE_CUBE_UV )\\n\\t\\t\\tvec3 reflectVec;\\n\\t\\t\\t#ifdef ENVMAP_MODE_REFLECTION\\n\\t\\t\\t\\treflectVec = reflect( - viewDir, normal );\\n\\t\\t\\t\\treflectVec = normalize( mix( reflectVec, normal, roughness * roughness) );\\n\\t\\t\\t#else\\n\\t\\t\\t\\treflectVec = refract( - viewDir, normal, refractionRatio );\\n\\t\\t\\t#endif\\n\\t\\t\\treflectVec = inverseTransformDirection( reflectVec, viewMatrix );\\n\\t\\t\\tvec4 envMapColor = textureCubeUV( envMap, reflectVec, roughness );\\n\\t\\t\\treturn envMapColor.rgb * envMapIntensity;\\n\\t\\t#else\\n\\t\\t\\treturn vec3( 0.0 );\\n\\t\\t#endif\\n\\t}\\n#endif\";\n\nvar lights_toon_fragment = \"ToonMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb;\";\n\nvar lights_toon_pars_fragment = \"varying vec3 vViewPosition;\\nstruct ToonMaterial {\\n\\tvec3 diffuseColor;\\n};\\nvoid RE_Direct_Toon( const in IncidentLight directLight, const in GeometricContext geometry, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tvec3 irradiance = getGradientIrradiance( geometry.normal, directLight.direction ) * directLight.color;\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectDiffuse_Toon( const in vec3 irradiance, const in GeometricContext geometry, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_Toon\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_Toon\\n#define Material_LightProbeLOD( material )\\t(0)\";\n\nvar lights_phong_fragment = \"BlinnPhongMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb;\\nmaterial.specularColor = specular;\\nmaterial.specularShininess = shininess;\\nmaterial.specularStrength = specularStrength;\";\n\nvar lights_phong_pars_fragment = \"varying vec3 vViewPosition;\\nstruct BlinnPhongMaterial {\\n\\tvec3 diffuseColor;\\n\\tvec3 specularColor;\\n\\tfloat specularShininess;\\n\\tfloat specularStrength;\\n};\\nvoid RE_Direct_BlinnPhong( const in IncidentLight directLight, const in GeometricContext geometry, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tfloat dotNL = saturate( dot( geometry.normal, directLight.direction ) );\\n\\tvec3 irradiance = dotNL * directLight.color;\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n\\treflectedLight.directSpecular += irradiance * BRDF_BlinnPhong( directLight.direction, geometry.viewDir, geometry.normal, material.specularColor, material.specularShininess ) * material.specularStrength;\\n}\\nvoid RE_IndirectDiffuse_BlinnPhong( const in vec3 irradiance, const in GeometricContext geometry, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_BlinnPhong\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_BlinnPhong\\n#define Material_LightProbeLOD( material )\\t(0)\";\n\nvar lights_physical_fragment = \"PhysicalMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb * ( 1.0 - metalnessFactor );\\nvec3 dxy = max( abs( dFdx( geometryNormal ) ), abs( dFdy( geometryNormal ) ) );\\nfloat geometryRoughness = max( max( dxy.x, dxy.y ), dxy.z );\\nmaterial.roughness = max( roughnessFactor, 0.0525 );material.roughness += geometryRoughness;\\nmaterial.roughness = min( material.roughness, 1.0 );\\n#ifdef IOR\\n\\t#ifdef SPECULAR\\n\\t\\tfloat specularIntensityFactor = specularIntensity;\\n\\t\\tvec3 specularColorFactor = specularColor;\\n\\t\\t#ifdef USE_SPECULARINTENSITYMAP\\n\\t\\t\\tspecularIntensityFactor *= texture2D( specularIntensityMap, vUv ).a;\\n\\t\\t#endif\\n\\t\\t#ifdef USE_SPECULARCOLORMAP\\n\\t\\t\\tspecularColorFactor *= texture2D( specularColorMap, vUv ).rgb;\\n\\t\\t#endif\\n\\t\\tmaterial.specularF90 = mix( specularIntensityFactor, 1.0, metalnessFactor );\\n\\t#else\\n\\t\\tfloat specularIntensityFactor = 1.0;\\n\\t\\tvec3 specularColorFactor = vec3( 1.0 );\\n\\t\\tmaterial.specularF90 = 1.0;\\n\\t#endif\\n\\tmaterial.specularColor = mix( min( pow2( ( ior - 1.0 ) / ( ior + 1.0 ) ) * specularColorFactor, vec3( 1.0 ) ) * specularIntensityFactor, diffuseColor.rgb, metalnessFactor );\\n#else\\n\\tmaterial.specularColor = mix( vec3( 0.04 ), diffuseColor.rgb, metalnessFactor );\\n\\tmaterial.specularF90 = 1.0;\\n#endif\\n#ifdef USE_CLEARCOAT\\n\\tmaterial.clearcoat = clearcoat;\\n\\tmaterial.clearcoatRoughness = clearcoatRoughness;\\n\\tmaterial.clearcoatF0 = vec3( 0.04 );\\n\\tmaterial.clearcoatF90 = 1.0;\\n\\t#ifdef USE_CLEARCOATMAP\\n\\t\\tmaterial.clearcoat *= texture2D( clearcoatMap, vUv ).x;\\n\\t#endif\\n\\t#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\t\\tmaterial.clearcoatRoughness *= texture2D( clearcoatRoughnessMap, vUv ).y;\\n\\t#endif\\n\\tmaterial.clearcoat = saturate( material.clearcoat );\\tmaterial.clearcoatRoughness = max( material.clearcoatRoughness, 0.0525 );\\n\\tmaterial.clearcoatRoughness += geometryRoughness;\\n\\tmaterial.clearcoatRoughness = min( material.clearcoatRoughness, 1.0 );\\n#endif\\n#ifdef USE_SHEEN\\n\\tmaterial.sheenColor = sheenColor;\\n\\t#ifdef USE_SHEENCOLORMAP\\n\\t\\tmaterial.sheenColor *= texture2D( sheenColorMap, vUv ).rgb;\\n\\t#endif\\n\\tmaterial.sheenRoughness = clamp( sheenRoughness, 0.07, 1.0 );\\n\\t#ifdef USE_SHEENROUGHNESSMAP\\n\\t\\tmaterial.sheenRoughness *= texture2D( sheenRoughnessMap, vUv ).a;\\n\\t#endif\\n#endif\";\n\nvar lights_physical_pars_fragment = \"struct PhysicalMaterial {\\n\\tvec3 diffuseColor;\\n\\tfloat roughness;\\n\\tvec3 specularColor;\\n\\tfloat specularF90;\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tfloat clearcoat;\\n\\t\\tfloat clearcoatRoughness;\\n\\t\\tvec3 clearcoatF0;\\n\\t\\tfloat clearcoatF90;\\n\\t#endif\\n\\t#ifdef USE_SHEEN\\n\\t\\tvec3 sheenColor;\\n\\t\\tfloat sheenRoughness;\\n\\t#endif\\n};\\nvec3 clearcoatSpecular = vec3( 0.0 );\\nvec3 sheenSpecular = vec3( 0.0 );\\nfloat IBLSheenBRDF( const in vec3 normal, const in vec3 viewDir, const in float roughness) {\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tfloat r2 = roughness * roughness;\\n\\tfloat a = roughness < 0.25 ? -339.2 * r2 + 161.4 * roughness - 25.9 : -8.48 * r2 + 14.3 * roughness - 9.95;\\n\\tfloat b = roughness < 0.25 ? 44.0 * r2 - 23.7 * roughness + 3.26 : 1.97 * r2 - 3.27 * roughness + 0.72;\\n\\tfloat DG = exp( a * dotNV + b ) + ( roughness < 0.25 ? 0.0 : 0.1 * ( roughness - 0.25 ) );\\n\\treturn saturate( DG * RECIPROCAL_PI );\\n}\\nvec2 DFGApprox( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tconst vec4 c0 = vec4( - 1, - 0.0275, - 0.572, 0.022 );\\n\\tconst vec4 c1 = vec4( 1, 0.0425, 1.04, - 0.04 );\\n\\tvec4 r = roughness * c0 + c1;\\n\\tfloat a004 = min( r.x * r.x, exp2( - 9.28 * dotNV ) ) * r.x + r.y;\\n\\tvec2 fab = vec2( - 1.04, 1.04 ) * a004 + r.zw;\\n\\treturn fab;\\n}\\nvec3 EnvironmentBRDF( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness ) {\\n\\tvec2 fab = DFGApprox( normal, viewDir, roughness );\\n\\treturn specularColor * fab.x + specularF90 * fab.y;\\n}\\nvoid computeMultiscattering( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\\n\\tvec2 fab = DFGApprox( normal, viewDir, roughness );\\n\\tvec3 FssEss = specularColor * fab.x + specularF90 * fab.y;\\n\\tfloat Ess = fab.x + fab.y;\\n\\tfloat Ems = 1.0 - Ess;\\n\\tvec3 Favg = specularColor + ( 1.0 - specularColor ) * 0.047619;\\tvec3 Fms = FssEss * Favg / ( 1.0 - Ems * Favg );\\n\\tsingleScatter += FssEss;\\n\\tmultiScatter += Fms * Ems;\\n}\\n#if NUM_RECT_AREA_LIGHTS > 0\\n\\tvoid RE_Direct_RectArea_Physical( const in RectAreaLight rectAreaLight, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\\n\\t\\tvec3 normal = geometry.normal;\\n\\t\\tvec3 viewDir = geometry.viewDir;\\n\\t\\tvec3 position = geometry.position;\\n\\t\\tvec3 lightPos = rectAreaLight.position;\\n\\t\\tvec3 halfWidth = rectAreaLight.halfWidth;\\n\\t\\tvec3 halfHeight = rectAreaLight.halfHeight;\\n\\t\\tvec3 lightColor = rectAreaLight.color;\\n\\t\\tfloat roughness = material.roughness;\\n\\t\\tvec3 rectCoords[ 4 ];\\n\\t\\trectCoords[ 0 ] = lightPos + halfWidth - halfHeight;\\t\\trectCoords[ 1 ] = lightPos - halfWidth - halfHeight;\\n\\t\\trectCoords[ 2 ] = lightPos - halfWidth + halfHeight;\\n\\t\\trectCoords[ 3 ] = lightPos + halfWidth + halfHeight;\\n\\t\\tvec2 uv = LTC_Uv( normal, viewDir, roughness );\\n\\t\\tvec4 t1 = texture2D( ltc_1, uv );\\n\\t\\tvec4 t2 = texture2D( ltc_2, uv );\\n\\t\\tmat3 mInv = mat3(\\n\\t\\t\\tvec3( t1.x, 0, t1.y ),\\n\\t\\t\\tvec3(    0, 1,    0 ),\\n\\t\\t\\tvec3( t1.z, 0, t1.w )\\n\\t\\t);\\n\\t\\tvec3 fresnel = ( material.specularColor * t2.x + ( vec3( 1.0 ) - material.specularColor ) * t2.y );\\n\\t\\treflectedLight.directSpecular += lightColor * fresnel * LTC_Evaluate( normal, viewDir, position, mInv, rectCoords );\\n\\t\\treflectedLight.directDiffuse += lightColor * material.diffuseColor * LTC_Evaluate( normal, viewDir, position, mat3( 1.0 ), rectCoords );\\n\\t}\\n#endif\\nvoid RE_Direct_Physical( const in IncidentLight directLight, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tfloat dotNL = saturate( dot( geometry.normal, directLight.direction ) );\\n\\tvec3 irradiance = dotNL * directLight.color;\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tfloat dotNLcc = saturate( dot( geometry.clearcoatNormal, directLight.direction ) );\\n\\t\\tvec3 ccIrradiance = dotNLcc * directLight.color;\\n\\t\\tclearcoatSpecular += ccIrradiance * BRDF_GGX( directLight.direction, geometry.viewDir, geometry.clearcoatNormal, material.clearcoatF0, material.clearcoatF90, material.clearcoatRoughness );\\n\\t#endif\\n\\t#ifdef USE_SHEEN\\n\\t\\tsheenSpecular += irradiance * BRDF_Sheen( directLight.direction, geometry.viewDir, geometry.normal, material.sheenColor, material.sheenRoughness );\\n\\t#endif\\n\\treflectedLight.directSpecular += irradiance * BRDF_GGX( directLight.direction, geometry.viewDir, geometry.normal, material.specularColor, material.specularF90, material.roughness );\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectDiffuse_Physical( const in vec3 irradiance, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectSpecular_Physical( const in vec3 radiance, const in vec3 irradiance, const in vec3 clearcoatRadiance, const in GeometricContext geometry, const in PhysicalMaterial material, inout ReflectedLight reflectedLight) {\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tclearcoatSpecular += clearcoatRadiance * EnvironmentBRDF( geometry.clearcoatNormal, geometry.viewDir, material.clearcoatF0, material.clearcoatF90, material.clearcoatRoughness );\\n\\t#endif\\n\\t#ifdef USE_SHEEN\\n\\t\\tsheenSpecular += irradiance * material.sheenColor * IBLSheenBRDF( geometry.normal, geometry.viewDir, material.sheenRoughness );\\n\\t#endif\\n\\tvec3 singleScattering = vec3( 0.0 );\\n\\tvec3 multiScattering = vec3( 0.0 );\\n\\tvec3 cosineWeightedIrradiance = irradiance * RECIPROCAL_PI;\\n\\tcomputeMultiscattering( geometry.normal, geometry.viewDir, material.specularColor, material.specularF90, material.roughness, singleScattering, multiScattering );\\n\\tvec3 diffuse = material.diffuseColor * ( 1.0 - ( singleScattering + multiScattering ) );\\n\\treflectedLight.indirectSpecular += radiance * singleScattering;\\n\\treflectedLight.indirectSpecular += multiScattering * cosineWeightedIrradiance;\\n\\treflectedLight.indirectDiffuse += diffuse * cosineWeightedIrradiance;\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_Physical\\n#define RE_Direct_RectArea\\t\\tRE_Direct_RectArea_Physical\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_Physical\\n#define RE_IndirectSpecular\\t\\tRE_IndirectSpecular_Physical\\nfloat computeSpecularOcclusion( const in float dotNV, const in float ambientOcclusion, const in float roughness ) {\\n\\treturn saturate( pow( dotNV + ambientOcclusion, exp2( - 16.0 * roughness - 1.0 ) ) - 1.0 + ambientOcclusion );\\n}\";\n\nvar lights_fragment_begin = \"\\nGeometricContext geometry;\\ngeometry.position = - vViewPosition;\\ngeometry.normal = normal;\\ngeometry.viewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( vViewPosition );\\n#ifdef USE_CLEARCOAT\\n\\tgeometry.clearcoatNormal = clearcoatNormal;\\n#endif\\nIncidentLight directLight;\\n#if ( NUM_POINT_LIGHTS > 0 ) && defined( RE_Direct )\\n\\tPointLight pointLight;\\n\\t#if defined( USE_SHADOWMAP ) && NUM_POINT_LIGHT_SHADOWS > 0\\n\\tPointLightShadow pointLightShadow;\\n\\t#endif\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {\\n\\t\\tpointLight = pointLights[ i ];\\n\\t\\tgetPointLightInfo( pointLight, geometry, directLight );\\n\\t\\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_POINT_LIGHT_SHADOWS )\\n\\t\\tpointLightShadow = pointLightShadows[ i ];\\n\\t\\tdirectLight.color *= all( bvec2( directLight.visible, receiveShadow ) ) ? getPointShadow( pointShadowMap[ i ], pointLightShadow.shadowMapSize, pointLightShadow.shadowBias, pointLightShadow.shadowRadius, vPointShadowCoord[ i ], pointLightShadow.shadowCameraNear, pointLightShadow.shadowCameraFar ) : 1.0;\\n\\t\\t#endif\\n\\t\\tRE_Direct( directLight, geometry, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if ( NUM_SPOT_LIGHTS > 0 ) && defined( RE_Direct )\\n\\tSpotLight spotLight;\\n\\t#if defined( USE_SHADOWMAP ) && NUM_SPOT_LIGHT_SHADOWS > 0\\n\\tSpotLightShadow spotLightShadow;\\n\\t#endif\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {\\n\\t\\tspotLight = spotLights[ i ];\\n\\t\\tgetSpotLightInfo( spotLight, geometry, directLight );\\n\\t\\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\\n\\t\\tspotLightShadow = spotLightShadows[ i ];\\n\\t\\tdirectLight.color *= all( bvec2( directLight.visible, receiveShadow ) ) ? getShadow( spotShadowMap[ i ], spotLightShadow.shadowMapSize, spotLightShadow.shadowBias, spotLightShadow.shadowRadius, vSpotShadowCoord[ i ] ) : 1.0;\\n\\t\\t#endif\\n\\t\\tRE_Direct( directLight, geometry, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if ( NUM_DIR_LIGHTS > 0 ) && defined( RE_Direct )\\n\\tDirectionalLight directionalLight;\\n\\t#if defined( USE_SHADOWMAP ) && NUM_DIR_LIGHT_SHADOWS > 0\\n\\tDirectionalLightShadow directionalLightShadow;\\n\\t#endif\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {\\n\\t\\tdirectionalLight = directionalLights[ i ];\\n\\t\\tgetDirectionalLightInfo( directionalLight, geometry, directLight );\\n\\t\\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_DIR_LIGHT_SHADOWS )\\n\\t\\tdirectionalLightShadow = directionalLightShadows[ i ];\\n\\t\\tdirectLight.color *= all( bvec2( directLight.visible, receiveShadow ) ) ? getShadow( directionalShadowMap[ i ], directionalLightShadow.shadowMapSize, directionalLightShadow.shadowBias, directionalLightShadow.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\\n\\t\\t#endif\\n\\t\\tRE_Direct( directLight, geometry, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if ( NUM_RECT_AREA_LIGHTS > 0 ) && defined( RE_Direct_RectArea )\\n\\tRectAreaLight rectAreaLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_RECT_AREA_LIGHTS; i ++ ) {\\n\\t\\trectAreaLight = rectAreaLights[ i ];\\n\\t\\tRE_Direct_RectArea( rectAreaLight, geometry, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if defined( RE_IndirectDiffuse )\\n\\tvec3 iblIrradiance = vec3( 0.0 );\\n\\tvec3 irradiance = getAmbientLightIrradiance( ambientLightColor );\\n\\tirradiance += getLightProbeIrradiance( lightProbe, geometry.normal );\\n\\t#if ( NUM_HEMI_LIGHTS > 0 )\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {\\n\\t\\t\\tirradiance += getHemisphereLightIrradiance( hemisphereLights[ i ], geometry.normal );\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t#endif\\n#endif\\n#if defined( RE_IndirectSpecular )\\n\\tvec3 radiance = vec3( 0.0 );\\n\\tvec3 clearcoatRadiance = vec3( 0.0 );\\n#endif\";\n\nvar lights_fragment_maps = \"#if defined( RE_IndirectDiffuse )\\n\\t#ifdef USE_LIGHTMAP\\n\\t\\tvec4 lightMapTexel = texture2D( lightMap, vUv2 );\\n\\t\\tvec3 lightMapIrradiance = lightMapTexel.rgb * lightMapIntensity;\\n\\t\\t#ifndef PHYSICALLY_CORRECT_LIGHTS\\n\\t\\t\\tlightMapIrradiance *= PI;\\n\\t\\t#endif\\n\\t\\tirradiance += lightMapIrradiance;\\n\\t#endif\\n\\t#if defined( USE_ENVMAP ) && defined( STANDARD ) && defined( ENVMAP_TYPE_CUBE_UV )\\n\\t\\tiblIrradiance += getIBLIrradiance( geometry.normal );\\n\\t#endif\\n#endif\\n#if defined( USE_ENVMAP ) && defined( RE_IndirectSpecular )\\n\\tradiance += getIBLRadiance( geometry.viewDir, geometry.normal, material.roughness );\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tclearcoatRadiance += getIBLRadiance( geometry.viewDir, geometry.clearcoatNormal, material.clearcoatRoughness );\\n\\t#endif\\n#endif\";\n\nvar lights_fragment_end = \"#if defined( RE_IndirectDiffuse )\\n\\tRE_IndirectDiffuse( irradiance, geometry, material, reflectedLight );\\n#endif\\n#if defined( RE_IndirectSpecular )\\n\\tRE_IndirectSpecular( radiance, iblIrradiance, clearcoatRadiance, geometry, material, reflectedLight );\\n#endif\";\n\nvar logdepthbuf_fragment = \"#if defined( USE_LOGDEPTHBUF ) && defined( USE_LOGDEPTHBUF_EXT )\\n\\tgl_FragDepthEXT = vIsPerspective == 0.0 ? gl_FragCoord.z : log2( vFragDepth ) * logDepthBufFC * 0.5;\\n#endif\";\n\nvar logdepthbuf_pars_fragment = \"#if defined( USE_LOGDEPTHBUF ) && defined( USE_LOGDEPTHBUF_EXT )\\n\\tuniform float logDepthBufFC;\\n\\tvarying float vFragDepth;\\n\\tvarying float vIsPerspective;\\n#endif\";\n\nvar logdepthbuf_pars_vertex = \"#ifdef USE_LOGDEPTHBUF\\n\\t#ifdef USE_LOGDEPTHBUF_EXT\\n\\t\\tvarying float vFragDepth;\\n\\t\\tvarying float vIsPerspective;\\n\\t#else\\n\\t\\tuniform float logDepthBufFC;\\n\\t#endif\\n#endif\";\n\nvar logdepthbuf_vertex = \"#ifdef USE_LOGDEPTHBUF\\n\\t#ifdef USE_LOGDEPTHBUF_EXT\\n\\t\\tvFragDepth = 1.0 + gl_Position.w;\\n\\t\\tvIsPerspective = float( isPerspectiveMatrix( projectionMatrix ) );\\n\\t#else\\n\\t\\tif ( isPerspectiveMatrix( projectionMatrix ) ) {\\n\\t\\t\\tgl_Position.z = log2( max( EPSILON, gl_Position.w + 1.0 ) ) * logDepthBufFC - 1.0;\\n\\t\\t\\tgl_Position.z *= gl_Position.w;\\n\\t\\t}\\n\\t#endif\\n#endif\";\n\nvar map_fragment = \"#ifdef USE_MAP\\n\\tvec4 sampledDiffuseColor = texture2D( map, vUv );\\n\\t#ifdef DECODE_VIDEO_TEXTURE\\n\\t\\tsampledDiffuseColor = vec4( mix( pow( sampledDiffuseColor.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), sampledDiffuseColor.rgb * 0.0773993808, vec3( lessThanEqual( sampledDiffuseColor.rgb, vec3( 0.04045 ) ) ) ), sampledDiffuseColor.w );\\n\\t#endif\\n\\tdiffuseColor *= sampledDiffuseColor;\\n#endif\";\n\nvar map_pars_fragment = \"#ifdef USE_MAP\\n\\tuniform sampler2D map;\\n#endif\";\n\nvar map_particle_fragment = \"#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\\n\\tvec2 uv = ( uvTransform * vec3( gl_PointCoord.x, 1.0 - gl_PointCoord.y, 1 ) ).xy;\\n#endif\\n#ifdef USE_MAP\\n\\tdiffuseColor *= texture2D( map, uv );\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tdiffuseColor.a *= texture2D( alphaMap, uv ).g;\\n#endif\";\n\nvar map_particle_pars_fragment = \"#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\\n\\tuniform mat3 uvTransform;\\n#endif\\n#ifdef USE_MAP\\n\\tuniform sampler2D map;\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tuniform sampler2D alphaMap;\\n#endif\";\n\nvar metalnessmap_fragment = \"float metalnessFactor = metalness;\\n#ifdef USE_METALNESSMAP\\n\\tvec4 texelMetalness = texture2D( metalnessMap, vUv );\\n\\tmetalnessFactor *= texelMetalness.b;\\n#endif\";\n\nvar metalnessmap_pars_fragment = \"#ifdef USE_METALNESSMAP\\n\\tuniform sampler2D metalnessMap;\\n#endif\";\n\nvar morphcolor_vertex = \"#if defined( USE_MORPHCOLORS ) && defined( MORPHTARGETS_TEXTURE )\\n\\tvColor *= morphTargetBaseInfluence;\\n\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\t#if defined( USE_COLOR_ALPHA )\\n\\t\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ) * morphTargetInfluences[ i ];\\n\\t\\t#elif defined( USE_COLOR )\\n\\t\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ).rgb * morphTargetInfluences[ i ]\\n\\t\\t#endif\\n\\t}\\n#endif\";\n\nvar morphnormal_vertex = \"#ifdef USE_MORPHNORMALS\\n\\tobjectNormal *= morphTargetBaseInfluence;\\n\\t#ifdef MORPHTARGETS_TEXTURE\\n\\t\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) objectNormal += getMorph( gl_VertexID, i, 1 ).xyz * morphTargetInfluences[ i ];\\n\\t\\t}\\n\\t#else\\n\\t\\tobjectNormal += morphNormal0 * morphTargetInfluences[ 0 ];\\n\\t\\tobjectNormal += morphNormal1 * morphTargetInfluences[ 1 ];\\n\\t\\tobjectNormal += morphNormal2 * morphTargetInfluences[ 2 ];\\n\\t\\tobjectNormal += morphNormal3 * morphTargetInfluences[ 3 ];\\n\\t#endif\\n#endif\";\n\nvar morphtarget_pars_vertex = \"#ifdef USE_MORPHTARGETS\\n\\tuniform float morphTargetBaseInfluence;\\n\\t#ifdef MORPHTARGETS_TEXTURE\\n\\t\\tuniform float morphTargetInfluences[ MORPHTARGETS_COUNT ];\\n\\t\\tuniform sampler2DArray morphTargetsTexture;\\n\\t\\tuniform vec2 morphTargetsTextureSize;\\n\\t\\tvec4 getMorph( const in int vertexIndex, const in int morphTargetIndex, const in int offset ) {\\n\\t\\t\\tfloat texelIndex = float( vertexIndex * MORPHTARGETS_TEXTURE_STRIDE + offset );\\n\\t\\t\\tfloat y = floor( texelIndex / morphTargetsTextureSize.x );\\n\\t\\t\\tfloat x = texelIndex - y * morphTargetsTextureSize.x;\\n\\t\\t\\tvec3 morphUV = vec3( ( x + 0.5 ) / morphTargetsTextureSize.x, y / morphTargetsTextureSize.y, morphTargetIndex );\\n\\t\\t\\treturn texture( morphTargetsTexture, morphUV );\\n\\t\\t}\\n\\t#else\\n\\t\\t#ifndef USE_MORPHNORMALS\\n\\t\\t\\tuniform float morphTargetInfluences[ 8 ];\\n\\t\\t#else\\n\\t\\t\\tuniform float morphTargetInfluences[ 4 ];\\n\\t\\t#endif\\n\\t#endif\\n#endif\";\n\nvar morphtarget_vertex = \"#ifdef USE_MORPHTARGETS\\n\\ttransformed *= morphTargetBaseInfluence;\\n\\t#ifdef MORPHTARGETS_TEXTURE\\n\\t\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) transformed += getMorph( gl_VertexID, i, 0 ).xyz * morphTargetInfluences[ i ];\\n\\t\\t}\\n\\t#else\\n\\t\\ttransformed += morphTarget0 * morphTargetInfluences[ 0 ];\\n\\t\\ttransformed += morphTarget1 * morphTargetInfluences[ 1 ];\\n\\t\\ttransformed += morphTarget2 * morphTargetInfluences[ 2 ];\\n\\t\\ttransformed += morphTarget3 * morphTargetInfluences[ 3 ];\\n\\t\\t#ifndef USE_MORPHNORMALS\\n\\t\\t\\ttransformed += morphTarget4 * morphTargetInfluences[ 4 ];\\n\\t\\t\\ttransformed += morphTarget5 * morphTargetInfluences[ 5 ];\\n\\t\\t\\ttransformed += morphTarget6 * morphTargetInfluences[ 6 ];\\n\\t\\t\\ttransformed += morphTarget7 * morphTargetInfluences[ 7 ];\\n\\t\\t#endif\\n\\t#endif\\n#endif\";\n\nvar normal_fragment_begin = \"float faceDirection = gl_FrontFacing ? 1.0 : - 1.0;\\n#ifdef FLAT_SHADED\\n\\tvec3 fdx = vec3( dFdx( vViewPosition.x ), dFdx( vViewPosition.y ), dFdx( vViewPosition.z ) );\\n\\tvec3 fdy = vec3( dFdy( vViewPosition.x ), dFdy( vViewPosition.y ), dFdy( vViewPosition.z ) );\\n\\tvec3 normal = normalize( cross( fdx, fdy ) );\\n#else\\n\\tvec3 normal = normalize( vNormal );\\n\\t#ifdef DOUBLE_SIDED\\n\\t\\tnormal = normal * faceDirection;\\n\\t#endif\\n\\t#ifdef USE_TANGENT\\n\\t\\tvec3 tangent = normalize( vTangent );\\n\\t\\tvec3 bitangent = normalize( vBitangent );\\n\\t\\t#ifdef DOUBLE_SIDED\\n\\t\\t\\ttangent = tangent * faceDirection;\\n\\t\\t\\tbitangent = bitangent * faceDirection;\\n\\t\\t#endif\\n\\t\\t#if defined( TANGENTSPACE_NORMALMAP ) || defined( USE_CLEARCOAT_NORMALMAP )\\n\\t\\t\\tmat3 vTBN = mat3( tangent, bitangent, normal );\\n\\t\\t#endif\\n\\t#endif\\n#endif\\nvec3 geometryNormal = normal;\";\n\nvar normal_fragment_maps = \"#ifdef OBJECTSPACE_NORMALMAP\\n\\tnormal = texture2D( normalMap, vUv ).xyz * 2.0 - 1.0;\\n\\t#ifdef FLIP_SIDED\\n\\t\\tnormal = - normal;\\n\\t#endif\\n\\t#ifdef DOUBLE_SIDED\\n\\t\\tnormal = normal * faceDirection;\\n\\t#endif\\n\\tnormal = normalize( normalMatrix * normal );\\n#elif defined( TANGENTSPACE_NORMALMAP )\\n\\tvec3 mapN = texture2D( normalMap, vUv ).xyz * 2.0 - 1.0;\\n\\tmapN.xy *= normalScale;\\n\\t#ifdef USE_TANGENT\\n\\t\\tnormal = normalize( vTBN * mapN );\\n\\t#else\\n\\t\\tnormal = perturbNormal2Arb( - vViewPosition, normal, mapN, faceDirection );\\n\\t#endif\\n#elif defined( USE_BUMPMAP )\\n\\tnormal = perturbNormalArb( - vViewPosition, normal, dHdxy_fwd(), faceDirection );\\n#endif\";\n\nvar normal_pars_fragment = \"#ifndef FLAT_SHADED\\n\\tvarying vec3 vNormal;\\n\\t#ifdef USE_TANGENT\\n\\t\\tvarying vec3 vTangent;\\n\\t\\tvarying vec3 vBitangent;\\n\\t#endif\\n#endif\";\n\nvar normal_pars_vertex = \"#ifndef FLAT_SHADED\\n\\tvarying vec3 vNormal;\\n\\t#ifdef USE_TANGENT\\n\\t\\tvarying vec3 vTangent;\\n\\t\\tvarying vec3 vBitangent;\\n\\t#endif\\n#endif\";\n\nvar normal_vertex = \"#ifndef FLAT_SHADED\\n\\tvNormal = normalize( transformedNormal );\\n\\t#ifdef USE_TANGENT\\n\\t\\tvTangent = normalize( transformedTangent );\\n\\t\\tvBitangent = normalize( cross( vNormal, vTangent ) * tangent.w );\\n\\t#endif\\n#endif\";\n\nvar normalmap_pars_fragment = \"#ifdef USE_NORMALMAP\\n\\tuniform sampler2D normalMap;\\n\\tuniform vec2 normalScale;\\n#endif\\n#ifdef OBJECTSPACE_NORMALMAP\\n\\tuniform mat3 normalMatrix;\\n#endif\\n#if ! defined ( USE_TANGENT ) && ( defined ( TANGENTSPACE_NORMALMAP ) || defined ( USE_CLEARCOAT_NORMALMAP ) )\\n\\tvec3 perturbNormal2Arb( vec3 eye_pos, vec3 surf_norm, vec3 mapN, float faceDirection ) {\\n\\t\\tvec3 q0 = vec3( dFdx( eye_pos.x ), dFdx( eye_pos.y ), dFdx( eye_pos.z ) );\\n\\t\\tvec3 q1 = vec3( dFdy( eye_pos.x ), dFdy( eye_pos.y ), dFdy( eye_pos.z ) );\\n\\t\\tvec2 st0 = dFdx( vUv.st );\\n\\t\\tvec2 st1 = dFdy( vUv.st );\\n\\t\\tvec3 N = surf_norm;\\n\\t\\tvec3 q1perp = cross( q1, N );\\n\\t\\tvec3 q0perp = cross( N, q0 );\\n\\t\\tvec3 T = q1perp * st0.x + q0perp * st1.x;\\n\\t\\tvec3 B = q1perp * st0.y + q0perp * st1.y;\\n\\t\\tfloat det = max( dot( T, T ), dot( B, B ) );\\n\\t\\tfloat scale = ( det == 0.0 ) ? 0.0 : faceDirection * inversesqrt( det );\\n\\t\\treturn normalize( T * ( mapN.x * scale ) + B * ( mapN.y * scale ) + N * mapN.z );\\n\\t}\\n#endif\";\n\nvar clearcoat_normal_fragment_begin = \"#ifdef USE_CLEARCOAT\\n\\tvec3 clearcoatNormal = geometryNormal;\\n#endif\";\n\nvar clearcoat_normal_fragment_maps = \"#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tvec3 clearcoatMapN = texture2D( clearcoatNormalMap, vUv ).xyz * 2.0 - 1.0;\\n\\tclearcoatMapN.xy *= clearcoatNormalScale;\\n\\t#ifdef USE_TANGENT\\n\\t\\tclearcoatNormal = normalize( vTBN * clearcoatMapN );\\n\\t#else\\n\\t\\tclearcoatNormal = perturbNormal2Arb( - vViewPosition, clearcoatNormal, clearcoatMapN, faceDirection );\\n\\t#endif\\n#endif\";\n\nvar clearcoat_pars_fragment = \"#ifdef USE_CLEARCOATMAP\\n\\tuniform sampler2D clearcoatMap;\\n#endif\\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\tuniform sampler2D clearcoatRoughnessMap;\\n#endif\\n#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tuniform sampler2D clearcoatNormalMap;\\n\\tuniform vec2 clearcoatNormalScale;\\n#endif\";\n\nvar output_fragment = \"#ifdef OPAQUE\\ndiffuseColor.a = 1.0;\\n#endif\\n#ifdef USE_TRANSMISSION\\ndiffuseColor.a *= transmissionAlpha + 0.1;\\n#endif\\ngl_FragColor = vec4( outgoingLight, diffuseColor.a );\";\n\nvar packing = \"vec3 packNormalToRGB( const in vec3 normal ) {\\n\\treturn normalize( normal ) * 0.5 + 0.5;\\n}\\nvec3 unpackRGBToNormal( const in vec3 rgb ) {\\n\\treturn 2.0 * rgb.xyz - 1.0;\\n}\\nconst float PackUpscale = 256. / 255.;const float UnpackDownscale = 255. / 256.;\\nconst vec3 PackFactors = vec3( 256. * 256. * 256., 256. * 256., 256. );\\nconst vec4 UnpackFactors = UnpackDownscale / vec4( PackFactors, 1. );\\nconst float ShiftRight8 = 1. / 256.;\\nvec4 packDepthToRGBA( const in float v ) {\\n\\tvec4 r = vec4( fract( v * PackFactors ), v );\\n\\tr.yzw -= r.xyz * ShiftRight8;\\treturn r * PackUpscale;\\n}\\nfloat unpackRGBAToDepth( const in vec4 v ) {\\n\\treturn dot( v, UnpackFactors );\\n}\\nvec4 pack2HalfToRGBA( vec2 v ) {\\n\\tvec4 r = vec4( v.x, fract( v.x * 255.0 ), v.y, fract( v.y * 255.0 ) );\\n\\treturn vec4( r.x - r.y / 255.0, r.y, r.z - r.w / 255.0, r.w );\\n}\\nvec2 unpackRGBATo2Half( vec4 v ) {\\n\\treturn vec2( v.x + ( v.y / 255.0 ), v.z + ( v.w / 255.0 ) );\\n}\\nfloat viewZToOrthographicDepth( const in float viewZ, const in float near, const in float far ) {\\n\\treturn ( viewZ + near ) / ( near - far );\\n}\\nfloat orthographicDepthToViewZ( const in float linearClipZ, const in float near, const in float far ) {\\n\\treturn linearClipZ * ( near - far ) - near;\\n}\\nfloat viewZToPerspectiveDepth( const in float viewZ, const in float near, const in float far ) {\\n\\treturn ( ( near + viewZ ) * far ) / ( ( far - near ) * viewZ );\\n}\\nfloat perspectiveDepthToViewZ( const in float invClipZ, const in float near, const in float far ) {\\n\\treturn ( near * far ) / ( ( far - near ) * invClipZ - far );\\n}\";\n\nvar premultiplied_alpha_fragment = \"#ifdef PREMULTIPLIED_ALPHA\\n\\tgl_FragColor.rgb *= gl_FragColor.a;\\n#endif\";\n\nvar project_vertex = \"vec4 mvPosition = vec4( transformed, 1.0 );\\n#ifdef USE_INSTANCING\\n\\tmvPosition = instanceMatrix * mvPosition;\\n#endif\\nmvPosition = modelViewMatrix * mvPosition;\\ngl_Position = projectionMatrix * mvPosition;\";\n\nvar dithering_fragment = \"#ifdef DITHERING\\n\\tgl_FragColor.rgb = dithering( gl_FragColor.rgb );\\n#endif\";\n\nvar dithering_pars_fragment = \"#ifdef DITHERING\\n\\tvec3 dithering( vec3 color ) {\\n\\t\\tfloat grid_position = rand( gl_FragCoord.xy );\\n\\t\\tvec3 dither_shift_RGB = vec3( 0.25 / 255.0, -0.25 / 255.0, 0.25 / 255.0 );\\n\\t\\tdither_shift_RGB = mix( 2.0 * dither_shift_RGB, -2.0 * dither_shift_RGB, grid_position );\\n\\t\\treturn color + dither_shift_RGB;\\n\\t}\\n#endif\";\n\nvar roughnessmap_fragment = \"float roughnessFactor = roughness;\\n#ifdef USE_ROUGHNESSMAP\\n\\tvec4 texelRoughness = texture2D( roughnessMap, vUv );\\n\\troughnessFactor *= texelRoughness.g;\\n#endif\";\n\nvar roughnessmap_pars_fragment = \"#ifdef USE_ROUGHNESSMAP\\n\\tuniform sampler2D roughnessMap;\\n#endif\";\n\nvar shadowmap_pars_fragment = \"#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\t\\tuniform sampler2D directionalShadowMap[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tstruct DirectionalLightShadow {\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\t\\tuniform sampler2D spotShadowMap[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vSpotShadowCoord[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t\\tstruct SpotLightShadow {\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\t\\tuniform sampler2D pointShadowMap[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tstruct PointLightShadow {\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t\\tfloat shadowCameraNear;\\n\\t\\t\\tfloat shadowCameraFar;\\n\\t\\t};\\n\\t\\tuniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t#endif\\n\\tfloat texture2DCompare( sampler2D depths, vec2 uv, float compare ) {\\n\\t\\treturn step( compare, unpackRGBAToDepth( texture2D( depths, uv ) ) );\\n\\t}\\n\\tvec2 texture2DDistribution( sampler2D shadow, vec2 uv ) {\\n\\t\\treturn unpackRGBATo2Half( texture2D( shadow, uv ) );\\n\\t}\\n\\tfloat VSMShadow (sampler2D shadow, vec2 uv, float compare ){\\n\\t\\tfloat occlusion = 1.0;\\n\\t\\tvec2 distribution = texture2DDistribution( shadow, uv );\\n\\t\\tfloat hard_shadow = step( compare , distribution.x );\\n\\t\\tif (hard_shadow != 1.0 ) {\\n\\t\\t\\tfloat distance = compare - distribution.x ;\\n\\t\\t\\tfloat variance = max( 0.00000, distribution.y * distribution.y );\\n\\t\\t\\tfloat softness_probability = variance / (variance + distance * distance );\\t\\t\\tsoftness_probability = clamp( ( softness_probability - 0.3 ) / ( 0.95 - 0.3 ), 0.0, 1.0 );\\t\\t\\tocclusion = clamp( max( hard_shadow, softness_probability ), 0.0, 1.0 );\\n\\t\\t}\\n\\t\\treturn occlusion;\\n\\t}\\n\\tfloat getShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowBias, float shadowRadius, vec4 shadowCoord ) {\\n\\t\\tfloat shadow = 1.0;\\n\\t\\tshadowCoord.xyz /= shadowCoord.w;\\n\\t\\tshadowCoord.z += shadowBias;\\n\\t\\tbvec4 inFrustumVec = bvec4 ( shadowCoord.x >= 0.0, shadowCoord.x <= 1.0, shadowCoord.y >= 0.0, shadowCoord.y <= 1.0 );\\n\\t\\tbool inFrustum = all( inFrustumVec );\\n\\t\\tbvec2 frustumTestVec = bvec2( inFrustum, shadowCoord.z <= 1.0 );\\n\\t\\tbool frustumTest = all( frustumTestVec );\\n\\t\\tif ( frustumTest ) {\\n\\t\\t#if defined( SHADOWMAP_TYPE_PCF )\\n\\t\\t\\tvec2 texelSize = vec2( 1.0 ) / shadowMapSize;\\n\\t\\t\\tfloat dx0 = - texelSize.x * shadowRadius;\\n\\t\\t\\tfloat dy0 = - texelSize.y * shadowRadius;\\n\\t\\t\\tfloat dx1 = + texelSize.x * shadowRadius;\\n\\t\\t\\tfloat dy1 = + texelSize.y * shadowRadius;\\n\\t\\t\\tfloat dx2 = dx0 / 2.0;\\n\\t\\t\\tfloat dy2 = dy0 / 2.0;\\n\\t\\t\\tfloat dx3 = dx1 / 2.0;\\n\\t\\t\\tfloat dy3 = dy1 / 2.0;\\n\\t\\t\\tshadow = (\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy2 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy2 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy2 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy3 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy3 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy3 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy1 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy1 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy1 ), shadowCoord.z )\\n\\t\\t\\t) * ( 1.0 / 17.0 );\\n\\t\\t#elif defined( SHADOWMAP_TYPE_PCF_SOFT )\\n\\t\\t\\tvec2 texelSize = vec2( 1.0 ) / shadowMapSize;\\n\\t\\t\\tfloat dx = texelSize.x;\\n\\t\\t\\tfloat dy = texelSize.y;\\n\\t\\t\\tvec2 uv = shadowCoord.xy;\\n\\t\\t\\tvec2 f = fract( uv * shadowMapSize + 0.5 );\\n\\t\\t\\tuv -= f * texelSize;\\n\\t\\t\\tshadow = (\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv, shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv + vec2( dx, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv + vec2( 0.0, dy ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv + texelSize, shadowCoord.z ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( -dx, 0.0 ), shadowCoord.z ), \\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 0.0 ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.x ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( -dx, dy ), shadowCoord.z ), \\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.x ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( 0.0, -dy ), shadowCoord.z ), \\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( 0.0, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.y ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( dx, -dy ), shadowCoord.z ), \\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( dx, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.y ) +\\n\\t\\t\\t\\tmix( mix( texture2DCompare( shadowMap, uv + vec2( -dx, -dy ), shadowCoord.z ), \\n\\t\\t\\t\\t\\t\\t  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, -dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t\\t  f.x ),\\n\\t\\t\\t\\t\\t mix( texture2DCompare( shadowMap, uv + vec2( -dx, 2.0 * dy ), shadowCoord.z ), \\n\\t\\t\\t\\t\\t\\t  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t\\t  f.x ),\\n\\t\\t\\t\\t\\t f.y )\\n\\t\\t\\t) * ( 1.0 / 9.0 );\\n\\t\\t#elif defined( SHADOWMAP_TYPE_VSM )\\n\\t\\t\\tshadow = VSMShadow( shadowMap, shadowCoord.xy, shadowCoord.z );\\n\\t\\t#else\\n\\t\\t\\tshadow = texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z );\\n\\t\\t#endif\\n\\t\\t}\\n\\t\\treturn shadow;\\n\\t}\\n\\tvec2 cubeToUV( vec3 v, float texelSizeY ) {\\n\\t\\tvec3 absV = abs( v );\\n\\t\\tfloat scaleToCube = 1.0 / max( absV.x, max( absV.y, absV.z ) );\\n\\t\\tabsV *= scaleToCube;\\n\\t\\tv *= scaleToCube * ( 1.0 - 2.0 * texelSizeY );\\n\\t\\tvec2 planar = v.xy;\\n\\t\\tfloat almostATexel = 1.5 * texelSizeY;\\n\\t\\tfloat almostOne = 1.0 - almostATexel;\\n\\t\\tif ( absV.z >= almostOne ) {\\n\\t\\t\\tif ( v.z > 0.0 )\\n\\t\\t\\t\\tplanar.x = 4.0 - v.x;\\n\\t\\t} else if ( absV.x >= almostOne ) {\\n\\t\\t\\tfloat signX = sign( v.x );\\n\\t\\t\\tplanar.x = v.z * signX + 2.0 * signX;\\n\\t\\t} else if ( absV.y >= almostOne ) {\\n\\t\\t\\tfloat signY = sign( v.y );\\n\\t\\t\\tplanar.x = v.x + 2.0 * signY + 2.0;\\n\\t\\t\\tplanar.y = v.z * signY - 2.0;\\n\\t\\t}\\n\\t\\treturn vec2( 0.125, 0.25 ) * planar + vec2( 0.375, 0.75 );\\n\\t}\\n\\tfloat getPointShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowBias, float shadowRadius, vec4 shadowCoord, float shadowCameraNear, float shadowCameraFar ) {\\n\\t\\tvec2 texelSize = vec2( 1.0 ) / ( shadowMapSize * vec2( 4.0, 2.0 ) );\\n\\t\\tvec3 lightToPosition = shadowCoord.xyz;\\n\\t\\tfloat dp = ( length( lightToPosition ) - shadowCameraNear ) / ( shadowCameraFar - shadowCameraNear );\\t\\tdp += shadowBias;\\n\\t\\tvec3 bd3D = normalize( lightToPosition );\\n\\t\\t#if defined( SHADOWMAP_TYPE_PCF ) || defined( SHADOWMAP_TYPE_PCF_SOFT ) || defined( SHADOWMAP_TYPE_VSM )\\n\\t\\t\\tvec2 offset = vec2( - 1, 1 ) * shadowRadius * texelSize.y;\\n\\t\\t\\treturn (\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyy, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyy, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyx, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyx, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxy, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxy, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxx, texelSize.y ), dp ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxx, texelSize.y ), dp )\\n\\t\\t\\t) * ( 1.0 / 9.0 );\\n\\t\\t#else\\n\\t\\t\\treturn texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp );\\n\\t\\t#endif\\n\\t}\\n#endif\";\n\nvar shadowmap_pars_vertex = \"#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\t\\tuniform mat4 directionalShadowMatrix[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tstruct DirectionalLightShadow {\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\t\\tuniform mat4 spotShadowMatrix[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vSpotShadowCoord[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t\\tstruct SpotLightShadow {\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\t\\tuniform mat4 pointShadowMatrix[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tstruct PointLightShadow {\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t\\tfloat shadowCameraNear;\\n\\t\\t\\tfloat shadowCameraFar;\\n\\t\\t};\\n\\t\\tuniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t#endif\\n#endif\";\n\nvar shadowmap_vertex = \"#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0 || NUM_SPOT_LIGHT_SHADOWS > 0 || NUM_POINT_LIGHT_SHADOWS > 0\\n\\t\\tvec3 shadowWorldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\\n\\t\\tvec4 shadowWorldPosition;\\n\\t#endif\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * directionalLightShadows[ i ].shadowNormalBias, 0 );\\n\\t\\tvDirectionalShadowCoord[ i ] = directionalShadowMatrix[ i ] * shadowWorldPosition;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * spotLightShadows[ i ].shadowNormalBias, 0 );\\n\\t\\tvSpotShadowCoord[ i ] = spotShadowMatrix[ i ] * shadowWorldPosition;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * pointLightShadows[ i ].shadowNormalBias, 0 );\\n\\t\\tvPointShadowCoord[ i ] = pointShadowMatrix[ i ] * shadowWorldPosition;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n#endif\";\n\nvar shadowmask_pars_fragment = \"float getShadowMask() {\\n\\tfloat shadow = 1.0;\\n\\t#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\tDirectionalLightShadow directionalLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tdirectionalLight = directionalLightShadows[ i ];\\n\\t\\tshadow *= receiveShadow ? getShadow( directionalShadowMap[ i ], directionalLight.shadowMapSize, directionalLight.shadowBias, directionalLight.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\tSpotLightShadow spotLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tspotLight = spotLightShadows[ i ];\\n\\t\\tshadow *= receiveShadow ? getShadow( spotShadowMap[ i ], spotLight.shadowMapSize, spotLight.shadowBias, spotLight.shadowRadius, vSpotShadowCoord[ i ] ) : 1.0;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\tPointLightShadow pointLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tpointLight = pointLightShadows[ i ];\\n\\t\\tshadow *= receiveShadow ? getPointShadow( pointShadowMap[ i ], pointLight.shadowMapSize, pointLight.shadowBias, pointLight.shadowRadius, vPointShadowCoord[ i ], pointLight.shadowCameraNear, pointLight.shadowCameraFar ) : 1.0;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#endif\\n\\treturn shadow;\\n}\";\n\nvar skinbase_vertex = \"#ifdef USE_SKINNING\\n\\tmat4 boneMatX = getBoneMatrix( skinIndex.x );\\n\\tmat4 boneMatY = getBoneMatrix( skinIndex.y );\\n\\tmat4 boneMatZ = getBoneMatrix( skinIndex.z );\\n\\tmat4 boneMatW = getBoneMatrix( skinIndex.w );\\n#endif\";\n\nvar skinning_pars_vertex = \"#ifdef USE_SKINNING\\n\\tuniform mat4 bindMatrix;\\n\\tuniform mat4 bindMatrixInverse;\\n\\t#ifdef BONE_TEXTURE\\n\\t\\tuniform highp sampler2D boneTexture;\\n\\t\\tuniform int boneTextureSize;\\n\\t\\tmat4 getBoneMatrix( const in float i ) {\\n\\t\\t\\tfloat j = i * 4.0;\\n\\t\\t\\tfloat x = mod( j, float( boneTextureSize ) );\\n\\t\\t\\tfloat y = floor( j / float( boneTextureSize ) );\\n\\t\\t\\tfloat dx = 1.0 / float( boneTextureSize );\\n\\t\\t\\tfloat dy = 1.0 / float( boneTextureSize );\\n\\t\\t\\ty = dy * ( y + 0.5 );\\n\\t\\t\\tvec4 v1 = texture2D( boneTexture, vec2( dx * ( x + 0.5 ), y ) );\\n\\t\\t\\tvec4 v2 = texture2D( boneTexture, vec2( dx * ( x + 1.5 ), y ) );\\n\\t\\t\\tvec4 v3 = texture2D( boneTexture, vec2( dx * ( x + 2.5 ), y ) );\\n\\t\\t\\tvec4 v4 = texture2D( boneTexture, vec2( dx * ( x + 3.5 ), y ) );\\n\\t\\t\\tmat4 bone = mat4( v1, v2, v3, v4 );\\n\\t\\t\\treturn bone;\\n\\t\\t}\\n\\t#else\\n\\t\\tuniform mat4 boneMatrices[ MAX_BONES ];\\n\\t\\tmat4 getBoneMatrix( const in float i ) {\\n\\t\\t\\tmat4 bone = boneMatrices[ int(i) ];\\n\\t\\t\\treturn bone;\\n\\t\\t}\\n\\t#endif\\n#endif\";\n\nvar skinning_vertex = \"#ifdef USE_SKINNING\\n\\tvec4 skinVertex = bindMatrix * vec4( transformed, 1.0 );\\n\\tvec4 skinned = vec4( 0.0 );\\n\\tskinned += boneMatX * skinVertex * skinWeight.x;\\n\\tskinned += boneMatY * skinVertex * skinWeight.y;\\n\\tskinned += boneMatZ * skinVertex * skinWeight.z;\\n\\tskinned += boneMatW * skinVertex * skinWeight.w;\\n\\ttransformed = ( bindMatrixInverse * skinned ).xyz;\\n#endif\";\n\nvar skinnormal_vertex = \"#ifdef USE_SKINNING\\n\\tmat4 skinMatrix = mat4( 0.0 );\\n\\tskinMatrix += skinWeight.x * boneMatX;\\n\\tskinMatrix += skinWeight.y * boneMatY;\\n\\tskinMatrix += skinWeight.z * boneMatZ;\\n\\tskinMatrix += skinWeight.w * boneMatW;\\n\\tskinMatrix = bindMatrixInverse * skinMatrix * bindMatrix;\\n\\tobjectNormal = vec4( skinMatrix * vec4( objectNormal, 0.0 ) ).xyz;\\n\\t#ifdef USE_TANGENT\\n\\t\\tobjectTangent = vec4( skinMatrix * vec4( objectTangent, 0.0 ) ).xyz;\\n\\t#endif\\n#endif\";\n\nvar specularmap_fragment = \"float specularStrength;\\n#ifdef USE_SPECULARMAP\\n\\tvec4 texelSpecular = texture2D( specularMap, vUv );\\n\\tspecularStrength = texelSpecular.r;\\n#else\\n\\tspecularStrength = 1.0;\\n#endif\";\n\nvar specularmap_pars_fragment = \"#ifdef USE_SPECULARMAP\\n\\tuniform sampler2D specularMap;\\n#endif\";\n\nvar tonemapping_fragment = \"#if defined( TONE_MAPPING )\\n\\tgl_FragColor.rgb = toneMapping( gl_FragColor.rgb );\\n#endif\";\n\nvar tonemapping_pars_fragment = \"#ifndef saturate\\n#define saturate( a ) clamp( a, 0.0, 1.0 )\\n#endif\\nuniform float toneMappingExposure;\\nvec3 LinearToneMapping( vec3 color ) {\\n\\treturn toneMappingExposure * color;\\n}\\nvec3 ReinhardToneMapping( vec3 color ) {\\n\\tcolor *= toneMappingExposure;\\n\\treturn saturate( color / ( vec3( 1.0 ) + color ) );\\n}\\nvec3 OptimizedCineonToneMapping( vec3 color ) {\\n\\tcolor *= toneMappingExposure;\\n\\tcolor = max( vec3( 0.0 ), color - 0.004 );\\n\\treturn pow( ( color * ( 6.2 * color + 0.5 ) ) / ( color * ( 6.2 * color + 1.7 ) + 0.06 ), vec3( 2.2 ) );\\n}\\nvec3 RRTAndODTFit( vec3 v ) {\\n\\tvec3 a = v * ( v + 0.0245786 ) - 0.000090537;\\n\\tvec3 b = v * ( 0.983729 * v + 0.4329510 ) + 0.238081;\\n\\treturn a / b;\\n}\\nvec3 ACESFilmicToneMapping( vec3 color ) {\\n\\tconst mat3 ACESInputMat = mat3(\\n\\t\\tvec3( 0.59719, 0.07600, 0.02840 ),\\t\\tvec3( 0.35458, 0.90834, 0.13383 ),\\n\\t\\tvec3( 0.04823, 0.01566, 0.83777 )\\n\\t);\\n\\tconst mat3 ACESOutputMat = mat3(\\n\\t\\tvec3(  1.60475, -0.10208, -0.00327 ),\\t\\tvec3( -0.53108,  1.10813, -0.07276 ),\\n\\t\\tvec3( -0.07367, -0.00605,  1.07602 )\\n\\t);\\n\\tcolor *= toneMappingExposure / 0.6;\\n\\tcolor = ACESInputMat * color;\\n\\tcolor = RRTAndODTFit( color );\\n\\tcolor = ACESOutputMat * color;\\n\\treturn saturate( color );\\n}\\nvec3 CustomToneMapping( vec3 color ) { return color; }\";\n\nvar transmission_fragment = \"#ifdef USE_TRANSMISSION\\n\\tfloat transmissionAlpha = 1.0;\\n\\tfloat transmissionFactor = transmission;\\n\\tfloat thicknessFactor = thickness;\\n\\t#ifdef USE_TRANSMISSIONMAP\\n\\t\\ttransmissionFactor *= texture2D( transmissionMap, vUv ).r;\\n\\t#endif\\n\\t#ifdef USE_THICKNESSMAP\\n\\t\\tthicknessFactor *= texture2D( thicknessMap, vUv ).g;\\n\\t#endif\\n\\tvec3 pos = vWorldPosition;\\n\\tvec3 v = normalize( cameraPosition - pos );\\n\\tvec3 n = inverseTransformDirection( normal, viewMatrix );\\n\\tvec4 transmission = getIBLVolumeRefraction(\\n\\t\\tn, v, roughnessFactor, material.diffuseColor, material.specularColor, material.specularF90,\\n\\t\\tpos, modelMatrix, viewMatrix, projectionMatrix, ior, thicknessFactor,\\n\\t\\tattenuationColor, attenuationDistance );\\n\\ttotalDiffuse = mix( totalDiffuse, transmission.rgb, transmissionFactor );\\n\\ttransmissionAlpha = mix( transmissionAlpha, transmission.a, transmissionFactor );\\n#endif\";\n\nvar transmission_pars_fragment = \"#ifdef USE_TRANSMISSION\\n\\tuniform float transmission;\\n\\tuniform float thickness;\\n\\tuniform float attenuationDistance;\\n\\tuniform vec3 attenuationColor;\\n\\t#ifdef USE_TRANSMISSIONMAP\\n\\t\\tuniform sampler2D transmissionMap;\\n\\t#endif\\n\\t#ifdef USE_THICKNESSMAP\\n\\t\\tuniform sampler2D thicknessMap;\\n\\t#endif\\n\\tuniform vec2 transmissionSamplerSize;\\n\\tuniform sampler2D transmissionSamplerMap;\\n\\tuniform mat4 modelMatrix;\\n\\tuniform mat4 projectionMatrix;\\n\\tvarying vec3 vWorldPosition;\\n\\tvec3 getVolumeTransmissionRay( const in vec3 n, const in vec3 v, const in float thickness, const in float ior, const in mat4 modelMatrix ) {\\n\\t\\tvec3 refractionVector = refract( - v, normalize( n ), 1.0 / ior );\\n\\t\\tvec3 modelScale;\\n\\t\\tmodelScale.x = length( vec3( modelMatrix[ 0 ].xyz ) );\\n\\t\\tmodelScale.y = length( vec3( modelMatrix[ 1 ].xyz ) );\\n\\t\\tmodelScale.z = length( vec3( modelMatrix[ 2 ].xyz ) );\\n\\t\\treturn normalize( refractionVector ) * thickness * modelScale;\\n\\t}\\n\\tfloat applyIorToRoughness( const in float roughness, const in float ior ) {\\n\\t\\treturn roughness * clamp( ior * 2.0 - 2.0, 0.0, 1.0 );\\n\\t}\\n\\tvec4 getTransmissionSample( const in vec2 fragCoord, const in float roughness, const in float ior ) {\\n\\t\\tfloat framebufferLod = log2( transmissionSamplerSize.x ) * applyIorToRoughness( roughness, ior );\\n\\t\\t#ifdef texture2DLodEXT\\n\\t\\t\\treturn texture2DLodEXT( transmissionSamplerMap, fragCoord.xy, framebufferLod );\\n\\t\\t#else\\n\\t\\t\\treturn texture2D( transmissionSamplerMap, fragCoord.xy, framebufferLod );\\n\\t\\t#endif\\n\\t}\\n\\tvec3 applyVolumeAttenuation( const in vec3 radiance, const in float transmissionDistance, const in vec3 attenuationColor, const in float attenuationDistance ) {\\n\\t\\tif ( attenuationDistance == 0.0 ) {\\n\\t\\t\\treturn radiance;\\n\\t\\t} else {\\n\\t\\t\\tvec3 attenuationCoefficient = -log( attenuationColor ) / attenuationDistance;\\n\\t\\t\\tvec3 transmittance = exp( - attenuationCoefficient * transmissionDistance );\\t\\t\\treturn transmittance * radiance;\\n\\t\\t}\\n\\t}\\n\\tvec4 getIBLVolumeRefraction( const in vec3 n, const in vec3 v, const in float roughness, const in vec3 diffuseColor,\\n\\t\\tconst in vec3 specularColor, const in float specularF90, const in vec3 position, const in mat4 modelMatrix,\\n\\t\\tconst in mat4 viewMatrix, const in mat4 projMatrix, const in float ior, const in float thickness,\\n\\t\\tconst in vec3 attenuationColor, const in float attenuationDistance ) {\\n\\t\\tvec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, ior, modelMatrix );\\n\\t\\tvec3 refractedRayExit = position + transmissionRay;\\n\\t\\tvec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\\n\\t\\tvec2 refractionCoords = ndcPos.xy / ndcPos.w;\\n\\t\\trefractionCoords += 1.0;\\n\\t\\trefractionCoords /= 2.0;\\n\\t\\tvec4 transmittedLight = getTransmissionSample( refractionCoords, roughness, ior );\\n\\t\\tvec3 attenuatedColor = applyVolumeAttenuation( transmittedLight.rgb, length( transmissionRay ), attenuationColor, attenuationDistance );\\n\\t\\tvec3 F = EnvironmentBRDF( n, v, specularColor, specularF90, roughness );\\n\\t\\treturn vec4( ( 1.0 - F ) * attenuatedColor * diffuseColor, transmittedLight.a );\\n\\t}\\n#endif\";\n\nvar uv_pars_fragment = \"#if ( defined( USE_UV ) && ! defined( UVS_VERTEX_ONLY ) )\\n\\tvarying vec2 vUv;\\n#endif\";\n\nvar uv_pars_vertex = \"#ifdef USE_UV\\n\\t#ifdef UVS_VERTEX_ONLY\\n\\t\\tvec2 vUv;\\n\\t#else\\n\\t\\tvarying vec2 vUv;\\n\\t#endif\\n\\tuniform mat3 uvTransform;\\n#endif\";\n\nvar uv_vertex = \"#ifdef USE_UV\\n\\tvUv = ( uvTransform * vec3( uv, 1 ) ).xy;\\n#endif\";\n\nvar uv2_pars_fragment = \"#if defined( USE_LIGHTMAP ) || defined( USE_AOMAP )\\n\\tvarying vec2 vUv2;\\n#endif\";\n\nvar uv2_pars_vertex = \"#if defined( USE_LIGHTMAP ) || defined( USE_AOMAP )\\n\\tattribute vec2 uv2;\\n\\tvarying vec2 vUv2;\\n\\tuniform mat3 uv2Transform;\\n#endif\";\n\nvar uv2_vertex = \"#if defined( USE_LIGHTMAP ) || defined( USE_AOMAP )\\n\\tvUv2 = ( uv2Transform * vec3( uv2, 1 ) ).xy;\\n#endif\";\n\nvar worldpos_vertex = \"#if defined( USE_ENVMAP ) || defined( DISTANCE ) || defined ( USE_SHADOWMAP ) || defined ( USE_TRANSMISSION )\\n\\tvec4 worldPosition = vec4( transformed, 1.0 );\\n\\t#ifdef USE_INSTANCING\\n\\t\\tworldPosition = instanceMatrix * worldPosition;\\n\\t#endif\\n\\tworldPosition = modelMatrix * worldPosition;\\n#endif\";\n\nconst vertex$g = \"varying vec2 vUv;\\nuniform mat3 uvTransform;\\nvoid main() {\\n\\tvUv = ( uvTransform * vec3( uv, 1 ) ).xy;\\n\\tgl_Position = vec4( position.xy, 1.0, 1.0 );\\n}\";\n\nconst fragment$g = \"uniform sampler2D t2D;\\nvarying vec2 vUv;\\nvoid main() {\\n\\tgl_FragColor = texture2D( t2D, vUv );\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n}\";\n\nconst vertex$f = \"varying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvWorldDirection = transformDirection( position, modelMatrix );\\n\\t#include <begin_vertex>\\n\\t#include <project_vertex>\\n\\tgl_Position.z = gl_Position.w;\\n}\";\n\nconst fragment$f = \"#include <envmap_common_pars_fragment>\\nuniform float opacity;\\nvarying vec3 vWorldDirection;\\n#include <cube_uv_reflection_fragment>\\nvoid main() {\\n\\tvec3 vReflect = vWorldDirection;\\n\\t#include <envmap_fragment>\\n\\tgl_FragColor = envColor;\\n\\tgl_FragColor.a *= opacity;\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n}\";\n\nconst vertex$e = \"#include <common>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvarying vec2 vHighPrecisionZW;\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#ifdef USE_DISPLACEMENTMAP\\n\\t\\t#include <beginnormal_vertex>\\n\\t\\t#include <morphnormal_vertex>\\n\\t\\t#include <skinnormal_vertex>\\n\\t#endif\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvHighPrecisionZW = gl_Position.zw;\\n}\";\n\nconst fragment$e = \"#if DEPTH_PACKING == 3200\\n\\tuniform float opacity;\\n#endif\\n#include <common>\\n#include <packing>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvarying vec2 vHighPrecisionZW;\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( 1.0 );\\n\\t#if DEPTH_PACKING == 3200\\n\\t\\tdiffuseColor.a = opacity;\\n\\t#endif\\n\\t#include <map_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <logdepthbuf_fragment>\\n\\tfloat fragCoordZ = 0.5 * vHighPrecisionZW[0] / vHighPrecisionZW[1] + 0.5;\\n\\t#if DEPTH_PACKING == 3200\\n\\t\\tgl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );\\n\\t#elif DEPTH_PACKING == 3201\\n\\t\\tgl_FragColor = packDepthToRGBA( fragCoordZ );\\n\\t#endif\\n}\";\n\nconst vertex$d = \"#define DISTANCE\\nvarying vec3 vWorldPosition;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#ifdef USE_DISPLACEMENTMAP\\n\\t\\t#include <beginnormal_vertex>\\n\\t\\t#include <morphnormal_vertex>\\n\\t\\t#include <skinnormal_vertex>\\n\\t#endif\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvWorldPosition = worldPosition.xyz;\\n}\";\n\nconst fragment$d = \"#define DISTANCE\\nuniform vec3 referencePosition;\\nuniform float nearDistance;\\nuniform float farDistance;\\nvarying vec3 vWorldPosition;\\n#include <common>\\n#include <packing>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main () {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( 1.0 );\\n\\t#include <map_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\tfloat dist = length( vWorldPosition - referencePosition );\\n\\tdist = ( dist - nearDistance ) / ( farDistance - nearDistance );\\n\\tdist = saturate( dist );\\n\\tgl_FragColor = packDepthToRGBA( dist );\\n}\";\n\nconst vertex$c = \"varying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvWorldDirection = transformDirection( position, modelMatrix );\\n\\t#include <begin_vertex>\\n\\t#include <project_vertex>\\n}\";\n\nconst fragment$c = \"uniform sampler2D tEquirect;\\nvarying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvec3 direction = normalize( vWorldDirection );\\n\\tvec2 sampleUV = equirectUv( direction );\\n\\tgl_FragColor = texture2D( tEquirect, sampleUV );\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n}\";\n\nconst vertex$b = \"uniform float scale;\\nattribute float lineDistance;\\nvarying float vLineDistance;\\n#include <common>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\tvLineDistance = scale * lineDistance;\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$b = \"uniform vec3 diffuse;\\nuniform float opacity;\\nuniform float dashSize;\\nuniform float totalSize;\\nvarying float vLineDistance;\\n#include <common>\\n#include <color_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tif ( mod( vLineDistance, totalSize ) > dashSize ) {\\n\\t\\tdiscard;\\n\\t}\\n\\tvec3 outgoingLight = vec3( 0.0 );\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <color_fragment>\\n\\toutgoingLight = diffuseColor.rgb;\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n}\";\n\nconst vertex$a = \"#include <common>\\n#include <uv_pars_vertex>\\n#include <uv2_pars_vertex>\\n#include <envmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <uv2_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#if defined ( USE_ENVMAP ) || defined ( USE_SKINNING )\\n\\t\\t#include <beginnormal_vertex>\\n\\t\\t#include <morphnormal_vertex>\\n\\t\\t#include <skinbase_vertex>\\n\\t\\t#include <skinnormal_vertex>\\n\\t\\t#include <defaultnormal_vertex>\\n\\t#endif\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <envmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$a = \"uniform vec3 diffuse;\\nuniform float opacity;\\n#ifndef FLAT_SHADED\\n\\tvarying vec3 vNormal;\\n#endif\\n#include <common>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <uv2_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_pars_fragment>\\n#include <cube_uv_reflection_fragment>\\n#include <fog_pars_fragment>\\n#include <specularmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <specularmap_fragment>\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\t#ifdef USE_LIGHTMAP\\n\\t\\tvec4 lightMapTexel= texture2D( lightMap, vUv2 );\\n\\t\\treflectedLight.indirectDiffuse += lightMapTexel.rgb * lightMapIntensity;\\n\\t#else\\n\\t\\treflectedLight.indirectDiffuse += vec3( 1.0 );\\n\\t#endif\\n\\t#include <aomap_fragment>\\n\\treflectedLight.indirectDiffuse *= diffuseColor.rgb;\\n\\tvec3 outgoingLight = reflectedLight.indirectDiffuse;\\n\\t#include <envmap_fragment>\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\n\nconst vertex$9 = \"#define LAMBERT\\nvarying vec3 vLightFront;\\nvarying vec3 vIndirectFront;\\n#ifdef DOUBLE_SIDED\\n\\tvarying vec3 vLightBack;\\n\\tvarying vec3 vIndirectBack;\\n#endif\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <uv2_pars_vertex>\\n#include <envmap_pars_vertex>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <uv2_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <envmap_vertex>\\n\\t#include <lights_lambert_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$9 = \"uniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform float opacity;\\nvarying vec3 vLightFront;\\nvarying vec3 vIndirectFront;\\n#ifdef DOUBLE_SIDED\\n\\tvarying vec3 vLightBack;\\n\\tvarying vec3 vIndirectBack;\\n#endif\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <uv2_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_pars_fragment>\\n#include <cube_uv_reflection_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <fog_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <shadowmask_pars_fragment>\\n#include <specularmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <specularmap_fragment>\\n\\t#include <emissivemap_fragment>\\n\\t#ifdef DOUBLE_SIDED\\n\\t\\treflectedLight.indirectDiffuse += ( gl_FrontFacing ) ? vIndirectFront : vIndirectBack;\\n\\t#else\\n\\t\\treflectedLight.indirectDiffuse += vIndirectFront;\\n\\t#endif\\n\\t#include <lightmap_fragment>\\n\\treflectedLight.indirectDiffuse *= BRDF_Lambert( diffuseColor.rgb );\\n\\t#ifdef DOUBLE_SIDED\\n\\t\\treflectedLight.directDiffuse = ( gl_FrontFacing ) ? vLightFront : vLightBack;\\n\\t#else\\n\\t\\treflectedLight.directDiffuse = vLightFront;\\n\\t#endif\\n\\treflectedLight.directDiffuse *= BRDF_Lambert( diffuseColor.rgb ) * getShadowMask();\\n\\t#include <aomap_fragment>\\n\\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\\n\\t#include <envmap_fragment>\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\n\nconst vertex$8 = \"#define MATCAP\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <color_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <fog_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n}\";\n\nconst fragment$8 = \"#define MATCAP\\nuniform vec3 diffuse;\\nuniform float opacity;\\nuniform sampler2D matcap;\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <normal_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\tvec3 viewDir = normalize( vViewPosition );\\n\\tvec3 x = normalize( vec3( viewDir.z, 0.0, - viewDir.x ) );\\n\\tvec3 y = cross( viewDir, x );\\n\\tvec2 uv = vec2( dot( x, normal ), dot( y, normal ) ) * 0.495 + 0.5;\\n\\t#ifdef USE_MATCAP\\n\\t\\tvec4 matcapColor = texture2D( matcap, uv );\\n\\t#else\\n\\t\\tvec4 matcapColor = vec4( vec3( mix( 0.2, 0.8, uv.y ) ), 1.0 );\\n\\t#endif\\n\\tvec3 outgoingLight = diffuseColor.rgb * matcapColor.rgb;\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\n\nconst vertex$7 = \"#define NORMAL\\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( TANGENTSPACE_NORMALMAP )\\n\\tvarying vec3 vViewPosition;\\n#endif\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( TANGENTSPACE_NORMALMAP )\\n\\tvViewPosition = - mvPosition.xyz;\\n#endif\\n}\";\n\nconst fragment$7 = \"#define NORMAL\\nuniform float opacity;\\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( TANGENTSPACE_NORMALMAP )\\n\\tvarying vec3 vViewPosition;\\n#endif\\n#include <packing>\\n#include <uv_pars_fragment>\\n#include <normal_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\tgl_FragColor = vec4( packNormalToRGB( normal ), opacity );\\n\\t#ifdef OPAQUE\\n\\t\\tgl_FragColor.a = 1.0;\\n\\t#endif\\n}\";\n\nconst vertex$6 = \"#define PHONG\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <uv2_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <envmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <uv2_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <envmap_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$6 = \"#define PHONG\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform vec3 specular;\\nuniform float shininess;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <uv2_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_pars_fragment>\\n#include <cube_uv_reflection_fragment>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_phong_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <specularmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <specularmap_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_phong_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;\\n\\t#include <envmap_fragment>\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\n\nconst vertex$5 = \"#define STANDARD\\nvarying vec3 vViewPosition;\\n#ifdef USE_TRANSMISSION\\n\\tvarying vec3 vWorldPosition;\\n#endif\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <uv2_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <uv2_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n#ifdef USE_TRANSMISSION\\n\\tvWorldPosition = worldPosition.xyz;\\n#endif\\n}\";\n\nconst fragment$5 = \"#define STANDARD\\n#ifdef PHYSICAL\\n\\t#define IOR\\n\\t#define SPECULAR\\n#endif\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform float roughness;\\nuniform float metalness;\\nuniform float opacity;\\n#ifdef IOR\\n\\tuniform float ior;\\n#endif\\n#ifdef SPECULAR\\n\\tuniform float specularIntensity;\\n\\tuniform vec3 specularColor;\\n\\t#ifdef USE_SPECULARINTENSITYMAP\\n\\t\\tuniform sampler2D specularIntensityMap;\\n\\t#endif\\n\\t#ifdef USE_SPECULARCOLORMAP\\n\\t\\tuniform sampler2D specularColorMap;\\n\\t#endif\\n#endif\\n#ifdef USE_CLEARCOAT\\n\\tuniform float clearcoat;\\n\\tuniform float clearcoatRoughness;\\n#endif\\n#ifdef USE_SHEEN\\n\\tuniform vec3 sheenColor;\\n\\tuniform float sheenRoughness;\\n\\t#ifdef USE_SHEENCOLORMAP\\n\\t\\tuniform sampler2D sheenColorMap;\\n\\t#endif\\n\\t#ifdef USE_SHEENROUGHNESSMAP\\n\\t\\tuniform sampler2D sheenRoughnessMap;\\n\\t#endif\\n#endif\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <uv2_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <bsdfs>\\n#include <cube_uv_reflection_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_physical_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_physical_pars_fragment>\\n#include <transmission_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <clearcoat_pars_fragment>\\n#include <roughnessmap_pars_fragment>\\n#include <metalnessmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <roughnessmap_fragment>\\n\\t#include <metalnessmap_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <clearcoat_normal_fragment_begin>\\n\\t#include <clearcoat_normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_physical_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 totalDiffuse = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse;\\n\\tvec3 totalSpecular = reflectedLight.directSpecular + reflectedLight.indirectSpecular;\\n\\t#include <transmission_fragment>\\n\\tvec3 outgoingLight = totalDiffuse + totalSpecular + totalEmissiveRadiance;\\n\\t#ifdef USE_SHEEN\\n\\t\\tfloat sheenEnergyComp = 1.0 - 0.157 * max3( material.sheenColor );\\n\\t\\toutgoingLight = outgoingLight * sheenEnergyComp + sheenSpecular;\\n\\t#endif\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tfloat dotNVcc = saturate( dot( geometry.clearcoatNormal, geometry.viewDir ) );\\n\\t\\tvec3 Fcc = F_Schlick( material.clearcoatF0, material.clearcoatF90, dotNVcc );\\n\\t\\toutgoingLight = outgoingLight * ( 1.0 - material.clearcoat * Fcc ) + clearcoatSpecular * material.clearcoat;\\n\\t#endif\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\n\nconst vertex$4 = \"#define TOON\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <uv2_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <uv2_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$4 = \"#define TOON\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <uv2_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <gradientmap_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_toon_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_toon_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\n\nconst vertex$3 = \"uniform float size;\\nuniform float scale;\\n#include <common>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <project_vertex>\\n\\tgl_PointSize = size;\\n\\t#ifdef USE_SIZEATTENUATION\\n\\t\\tbool isPerspective = isPerspectiveMatrix( projectionMatrix );\\n\\t\\tif ( isPerspective ) gl_PointSize *= ( scale / - mvPosition.z );\\n\\t#endif\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$3 = \"uniform vec3 diffuse;\\nuniform float opacity;\\n#include <common>\\n#include <color_pars_fragment>\\n#include <map_particle_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec3 outgoingLight = vec3( 0.0 );\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_particle_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphatest_fragment>\\n\\toutgoingLight = diffuseColor.rgb;\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n}\";\n\nconst vertex$2 = \"#include <common>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\nvoid main() {\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <project_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$2 = \"uniform vec3 color;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <shadowmap_pars_fragment>\\n#include <shadowmask_pars_fragment>\\nvoid main() {\\n\\tgl_FragColor = vec4( color, opacity * ( 1.0 - getShadowMask() ) );\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n}\";\n\nconst vertex$1 = \"uniform float rotation;\\nuniform vec2 center;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\tvec4 mvPosition = modelViewMatrix * vec4( 0.0, 0.0, 0.0, 1.0 );\\n\\tvec2 scale;\\n\\tscale.x = length( vec3( modelMatrix[ 0 ].x, modelMatrix[ 0 ].y, modelMatrix[ 0 ].z ) );\\n\\tscale.y = length( vec3( modelMatrix[ 1 ].x, modelMatrix[ 1 ].y, modelMatrix[ 1 ].z ) );\\n\\t#ifndef USE_SIZEATTENUATION\\n\\t\\tbool isPerspective = isPerspectiveMatrix( projectionMatrix );\\n\\t\\tif ( isPerspective ) scale *= - mvPosition.z;\\n\\t#endif\\n\\tvec2 alignedPosition = ( position.xy - ( center - vec2( 0.5 ) ) ) * scale;\\n\\tvec2 rotatedPosition;\\n\\trotatedPosition.x = cos( rotation ) * alignedPosition.x - sin( rotation ) * alignedPosition.y;\\n\\trotatedPosition.y = sin( rotation ) * alignedPosition.x + cos( rotation ) * alignedPosition.y;\\n\\tmvPosition.xy += rotatedPosition;\\n\\tgl_Position = projectionMatrix * mvPosition;\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <fog_vertex>\\n}\";\n\nconst fragment$1 = \"uniform vec3 diffuse;\\nuniform float opacity;\\n#include <common>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\t#include <clipping_planes_fragment>\\n\\tvec3 outgoingLight = vec3( 0.0 );\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\toutgoingLight = diffuseColor.rgb;\\n\\t#include <output_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <encodings_fragment>\\n\\t#include <fog_fragment>\\n}\";\n\nconst ShaderChunk = {\n\talphamap_fragment: alphamap_fragment,\n\talphamap_pars_fragment: alphamap_pars_fragment,\n\talphatest_fragment: alphatest_fragment,\n\talphatest_pars_fragment: alphatest_pars_fragment,\n\taomap_fragment: aomap_fragment,\n\taomap_pars_fragment: aomap_pars_fragment,\n\tbegin_vertex: begin_vertex,\n\tbeginnormal_vertex: beginnormal_vertex,\n\tbsdfs: bsdfs,\n\tbumpmap_pars_fragment: bumpmap_pars_fragment,\n\tclipping_planes_fragment: clipping_planes_fragment,\n\tclipping_planes_pars_fragment: clipping_planes_pars_fragment,\n\tclipping_planes_pars_vertex: clipping_planes_pars_vertex,\n\tclipping_planes_vertex: clipping_planes_vertex,\n\tcolor_fragment: color_fragment,\n\tcolor_pars_fragment: color_pars_fragment,\n\tcolor_pars_vertex: color_pars_vertex,\n\tcolor_vertex: color_vertex,\n\tcommon: common,\n\tcube_uv_reflection_fragment: cube_uv_reflection_fragment,\n\tdefaultnormal_vertex: defaultnormal_vertex,\n\tdisplacementmap_pars_vertex: displacementmap_pars_vertex,\n\tdisplacementmap_vertex: displacementmap_vertex,\n\temissivemap_fragment: emissivemap_fragment,\n\temissivemap_pars_fragment: emissivemap_pars_fragment,\n\tencodings_fragment: encodings_fragment,\n\tencodings_pars_fragment: encodings_pars_fragment,\n\tenvmap_fragment: envmap_fragment,\n\tenvmap_common_pars_fragment: envmap_common_pars_fragment,\n\tenvmap_pars_fragment: envmap_pars_fragment,\n\tenvmap_pars_vertex: envmap_pars_vertex,\n\tenvmap_physical_pars_fragment: envmap_physical_pars_fragment,\n\tenvmap_vertex: envmap_vertex,\n\tfog_vertex: fog_vertex,\n\tfog_pars_vertex: fog_pars_vertex,\n\tfog_fragment: fog_fragment,\n\tfog_pars_fragment: fog_pars_fragment,\n\tgradientmap_pars_fragment: gradientmap_pars_fragment,\n\tlightmap_fragment: lightmap_fragment,\n\tlightmap_pars_fragment: lightmap_pars_fragment,\n\tlights_lambert_vertex: lights_lambert_vertex,\n\tlights_pars_begin: lights_pars_begin,\n\tlights_toon_fragment: lights_toon_fragment,\n\tlights_toon_pars_fragment: lights_toon_pars_fragment,\n\tlights_phong_fragment: lights_phong_fragment,\n\tlights_phong_pars_fragment: lights_phong_pars_fragment,\n\tlights_physical_fragment: lights_physical_fragment,\n\tlights_physical_pars_fragment: lights_physical_pars_fragment,\n\tlights_fragment_begin: lights_fragment_begin,\n\tlights_fragment_maps: lights_fragment_maps,\n\tlights_fragment_end: lights_fragment_end,\n\tlogdepthbuf_fragment: logdepthbuf_fragment,\n\tlogdepthbuf_pars_fragment: logdepthbuf_pars_fragment,\n\tlogdepthbuf_pars_vertex: logdepthbuf_pars_vertex,\n\tlogdepthbuf_vertex: logdepthbuf_vertex,\n\tmap_fragment: map_fragment,\n\tmap_pars_fragment: map_pars_fragment,\n\tmap_particle_fragment: map_particle_fragment,\n\tmap_particle_pars_fragment: map_particle_pars_fragment,\n\tmetalnessmap_fragment: metalnessmap_fragment,\n\tmetalnessmap_pars_fragment: metalnessmap_pars_fragment,\n\tmorphcolor_vertex: morphcolor_vertex,\n\tmorphnormal_vertex: morphnormal_vertex,\n\tmorphtarget_pars_vertex: morphtarget_pars_vertex,\n\tmorphtarget_vertex: morphtarget_vertex,\n\tnormal_fragment_begin: normal_fragment_begin,\n\tnormal_fragment_maps: normal_fragment_maps,\n\tnormal_pars_fragment: normal_pars_fragment,\n\tnormal_pars_vertex: normal_pars_vertex,\n\tnormal_vertex: normal_vertex,\n\tnormalmap_pars_fragment: normalmap_pars_fragment,\n\tclearcoat_normal_fragment_begin: clearcoat_normal_fragment_begin,\n\tclearcoat_normal_fragment_maps: clearcoat_normal_fragment_maps,\n\tclearcoat_pars_fragment: clearcoat_pars_fragment,\n\toutput_fragment: output_fragment,\n\tpacking: packing,\n\tpremultiplied_alpha_fragment: premultiplied_alpha_fragment,\n\tproject_vertex: project_vertex,\n\tdithering_fragment: dithering_fragment,\n\tdithering_pars_fragment: dithering_pars_fragment,\n\troughnessmap_fragment: roughnessmap_fragment,\n\troughnessmap_pars_fragment: roughnessmap_pars_fragment,\n\tshadowmap_pars_fragment: shadowmap_pars_fragment,\n\tshadowmap_pars_vertex: shadowmap_pars_vertex,\n\tshadowmap_vertex: shadowmap_vertex,\n\tshadowmask_pars_fragment: shadowmask_pars_fragment,\n\tskinbase_vertex: skinbase_vertex,\n\tskinning_pars_vertex: skinning_pars_vertex,\n\tskinning_vertex: skinning_vertex,\n\tskinnormal_vertex: skinnormal_vertex,\n\tspecularmap_fragment: specularmap_fragment,\n\tspecularmap_pars_fragment: specularmap_pars_fragment,\n\ttonemapping_fragment: tonemapping_fragment,\n\ttonemapping_pars_fragment: tonemapping_pars_fragment,\n\ttransmission_fragment: transmission_fragment,\n\ttransmission_pars_fragment: transmission_pars_fragment,\n\tuv_pars_fragment: uv_pars_fragment,\n\tuv_pars_vertex: uv_pars_vertex,\n\tuv_vertex: uv_vertex,\n\tuv2_pars_fragment: uv2_pars_fragment,\n\tuv2_pars_vertex: uv2_pars_vertex,\n\tuv2_vertex: uv2_vertex,\n\tworldpos_vertex: worldpos_vertex,\n\n\tbackground_vert: vertex$g,\n\tbackground_frag: fragment$g,\n\tcube_vert: vertex$f,\n\tcube_frag: fragment$f,\n\tdepth_vert: vertex$e,\n\tdepth_frag: fragment$e,\n\tdistanceRGBA_vert: vertex$d,\n\tdistanceRGBA_frag: fragment$d,\n\tequirect_vert: vertex$c,\n\tequirect_frag: fragment$c,\n\tlinedashed_vert: vertex$b,\n\tlinedashed_frag: fragment$b,\n\tmeshbasic_vert: vertex$a,\n\tmeshbasic_frag: fragment$a,\n\tmeshlambert_vert: vertex$9,\n\tmeshlambert_frag: fragment$9,\n\tmeshmatcap_vert: vertex$8,\n\tmeshmatcap_frag: fragment$8,\n\tmeshnormal_vert: vertex$7,\n\tmeshnormal_frag: fragment$7,\n\tmeshphong_vert: vertex$6,\n\tmeshphong_frag: fragment$6,\n\tmeshphysical_vert: vertex$5,\n\tmeshphysical_frag: fragment$5,\n\tmeshtoon_vert: vertex$4,\n\tmeshtoon_frag: fragment$4,\n\tpoints_vert: vertex$3,\n\tpoints_frag: fragment$3,\n\tshadow_vert: vertex$2,\n\tshadow_frag: fragment$2,\n\tsprite_vert: vertex$1,\n\tsprite_frag: fragment$1\n};\n\n/**\n * Uniforms library for shared webgl shaders\n */\n\nconst UniformsLib = {\n\n\tcommon: {\n\n\t\tdiffuse: { value: new Color( 0xffffff ) },\n\t\topacity: { value: 1.0 },\n\n\t\tmap: { value: null },\n\t\tuvTransform: { value: new Matrix3() },\n\t\tuv2Transform: { value: new Matrix3() },\n\n\t\talphaMap: { value: null },\n\t\talphaTest: { value: 0 }\n\n\t},\n\n\tspecularmap: {\n\n\t\tspecularMap: { value: null },\n\n\t},\n\n\tenvmap: {\n\n\t\tenvMap: { value: null },\n\t\tflipEnvMap: { value: - 1 },\n\t\treflectivity: { value: 1.0 }, // basic, lambert, phong\n\t\tior: { value: 1.5 }, // standard, physical\n\t\trefractionRatio: { value: 0.98 }\n\n\t},\n\n\taomap: {\n\n\t\taoMap: { value: null },\n\t\taoMapIntensity: { value: 1 }\n\n\t},\n\n\tlightmap: {\n\n\t\tlightMap: { value: null },\n\t\tlightMapIntensity: { value: 1 }\n\n\t},\n\n\temissivemap: {\n\n\t\temissiveMap: { value: null }\n\n\t},\n\n\tbumpmap: {\n\n\t\tbumpMap: { value: null },\n\t\tbumpScale: { value: 1 }\n\n\t},\n\n\tnormalmap: {\n\n\t\tnormalMap: { value: null },\n\t\tnormalScale: { value: new Vector2( 1, 1 ) }\n\n\t},\n\n\tdisplacementmap: {\n\n\t\tdisplacementMap: { value: null },\n\t\tdisplacementScale: { value: 1 },\n\t\tdisplacementBias: { value: 0 }\n\n\t},\n\n\troughnessmap: {\n\n\t\troughnessMap: { value: null }\n\n\t},\n\n\tmetalnessmap: {\n\n\t\tmetalnessMap: { value: null }\n\n\t},\n\n\tgradientmap: {\n\n\t\tgradientMap: { value: null }\n\n\t},\n\n\tfog: {\n\n\t\tfogDensity: { value: 0.00025 },\n\t\tfogNear: { value: 1 },\n\t\tfogFar: { value: 2000 },\n\t\tfogColor: { value: new Color( 0xffffff ) }\n\n\t},\n\n\tlights: {\n\n\t\tambientLightColor: { value: [] },\n\n\t\tlightProbe: { value: [] },\n\n\t\tdirectionalLights: { value: [], properties: {\n\t\t\tdirection: {},\n\t\t\tcolor: {}\n\t\t} },\n\n\t\tdirectionalLightShadows: { value: [], properties: {\n\t\t\tshadowBias: {},\n\t\t\tshadowNormalBias: {},\n\t\t\tshadowRadius: {},\n\t\t\tshadowMapSize: {}\n\t\t} },\n\n\t\tdirectionalShadowMap: { value: [] },\n\t\tdirectionalShadowMatrix: { value: [] },\n\n\t\tspotLights: { value: [], properties: {\n\t\t\tcolor: {},\n\t\t\tposition: {},\n\t\t\tdirection: {},\n\t\t\tdistance: {},\n\t\t\tconeCos: {},\n\t\t\tpenumbraCos: {},\n\t\t\tdecay: {}\n\t\t} },\n\n\t\tspotLightShadows: { value: [], properties: {\n\t\t\tshadowBias: {},\n\t\t\tshadowNormalBias: {},\n\t\t\tshadowRadius: {},\n\t\t\tshadowMapSize: {}\n\t\t} },\n\n\t\tspotShadowMap: { value: [] },\n\t\tspotShadowMatrix: { value: [] },\n\n\t\tpointLights: { value: [], properties: {\n\t\t\tcolor: {},\n\t\t\tposition: {},\n\t\t\tdecay: {},\n\t\t\tdistance: {}\n\t\t} },\n\n\t\tpointLightShadows: { value: [], properties: {\n\t\t\tshadowBias: {},\n\t\t\tshadowNormalBias: {},\n\t\t\tshadowRadius: {},\n\t\t\tshadowMapSize: {},\n\t\t\tshadowCameraNear: {},\n\t\t\tshadowCameraFar: {}\n\t\t} },\n\n\t\tpointShadowMap: { value: [] },\n\t\tpointShadowMatrix: { value: [] },\n\n\t\themisphereLights: { value: [], properties: {\n\t\t\tdirection: {},\n\t\t\tskyColor: {},\n\t\t\tgroundColor: {}\n\t\t} },\n\n\t\t// TODO (abelnation): RectAreaLight BRDF data needs to be moved from example to main src\n\t\trectAreaLights: { value: [], properties: {\n\t\t\tcolor: {},\n\t\t\tposition: {},\n\t\t\twidth: {},\n\t\t\theight: {}\n\t\t} },\n\n\t\tltc_1: { value: null },\n\t\tltc_2: { value: null }\n\n\t},\n\n\tpoints: {\n\n\t\tdiffuse: { value: new Color( 0xffffff ) },\n\t\topacity: { value: 1.0 },\n\t\tsize: { value: 1.0 },\n\t\tscale: { value: 1.0 },\n\t\tmap: { value: null },\n\t\talphaMap: { value: null },\n\t\talphaTest: { value: 0 },\n\t\tuvTransform: { value: new Matrix3() }\n\n\t},\n\n\tsprite: {\n\n\t\tdiffuse: { value: new Color( 0xffffff ) },\n\t\topacity: { value: 1.0 },\n\t\tcenter: { value: new Vector2( 0.5, 0.5 ) },\n\t\trotation: { value: 0.0 },\n\t\tmap: { value: null },\n\t\talphaMap: { value: null },\n\t\talphaTest: { value: 0 },\n\t\tuvTransform: { value: new Matrix3() }\n\n\t}\n\n};\n\nconst ShaderLib = {\n\n\tbasic: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.specularmap,\n\t\t\tUniformsLib.envmap,\n\t\t\tUniformsLib.aomap,\n\t\t\tUniformsLib.lightmap,\n\t\t\tUniformsLib.fog\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshbasic_vert,\n\t\tfragmentShader: ShaderChunk.meshbasic_frag\n\n\t},\n\n\tlambert: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.specularmap,\n\t\t\tUniformsLib.envmap,\n\t\t\tUniformsLib.aomap,\n\t\t\tUniformsLib.lightmap,\n\t\t\tUniformsLib.emissivemap,\n\t\t\tUniformsLib.fog,\n\t\t\tUniformsLib.lights,\n\t\t\t{\n\t\t\t\temissive: { value: new Color( 0x000000 ) }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshlambert_vert,\n\t\tfragmentShader: ShaderChunk.meshlambert_frag\n\n\t},\n\n\tphong: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.specularmap,\n\t\t\tUniformsLib.envmap,\n\t\t\tUniformsLib.aomap,\n\t\t\tUniformsLib.lightmap,\n\t\t\tUniformsLib.emissivemap,\n\t\t\tUniformsLib.bumpmap,\n\t\t\tUniformsLib.normalmap,\n\t\t\tUniformsLib.displacementmap,\n\t\t\tUniformsLib.fog,\n\t\t\tUniformsLib.lights,\n\t\t\t{\n\t\t\t\temissive: { value: new Color( 0x000000 ) },\n\t\t\t\tspecular: { value: new Color( 0x111111 ) },\n\t\t\t\tshininess: { value: 30 }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshphong_vert,\n\t\tfragmentShader: ShaderChunk.meshphong_frag\n\n\t},\n\n\tstandard: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.envmap,\n\t\t\tUniformsLib.aomap,\n\t\t\tUniformsLib.lightmap,\n\t\t\tUniformsLib.emissivemap,\n\t\t\tUniformsLib.bumpmap,\n\t\t\tUniformsLib.normalmap,\n\t\t\tUniformsLib.displacementmap,\n\t\t\tUniformsLib.roughnessmap,\n\t\t\tUniformsLib.metalnessmap,\n\t\t\tUniformsLib.fog,\n\t\t\tUniformsLib.lights,\n\t\t\t{\n\t\t\t\temissive: { value: new Color( 0x000000 ) },\n\t\t\t\troughness: { value: 1.0 },\n\t\t\t\tmetalness: { value: 0.0 },\n\t\t\t\tenvMapIntensity: { value: 1 } // temporary\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshphysical_vert,\n\t\tfragmentShader: ShaderChunk.meshphysical_frag\n\n\t},\n\n\ttoon: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.aomap,\n\t\t\tUniformsLib.lightmap,\n\t\t\tUniformsLib.emissivemap,\n\t\t\tUniformsLib.bumpmap,\n\t\t\tUniformsLib.normalmap,\n\t\t\tUniformsLib.displacementmap,\n\t\t\tUniformsLib.gradientmap,\n\t\t\tUniformsLib.fog,\n\t\t\tUniformsLib.lights,\n\t\t\t{\n\t\t\t\temissive: { value: new Color( 0x000000 ) }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshtoon_vert,\n\t\tfragmentShader: ShaderChunk.meshtoon_frag\n\n\t},\n\n\tmatcap: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.bumpmap,\n\t\t\tUniformsLib.normalmap,\n\t\t\tUniformsLib.displacementmap,\n\t\t\tUniformsLib.fog,\n\t\t\t{\n\t\t\t\tmatcap: { value: null }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshmatcap_vert,\n\t\tfragmentShader: ShaderChunk.meshmatcap_frag\n\n\t},\n\n\tpoints: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.points,\n\t\t\tUniformsLib.fog\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.points_vert,\n\t\tfragmentShader: ShaderChunk.points_frag\n\n\t},\n\n\tdashed: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.fog,\n\t\t\t{\n\t\t\t\tscale: { value: 1 },\n\t\t\t\tdashSize: { value: 1 },\n\t\t\t\ttotalSize: { value: 2 }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.linedashed_vert,\n\t\tfragmentShader: ShaderChunk.linedashed_frag\n\n\t},\n\n\tdepth: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.displacementmap\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.depth_vert,\n\t\tfragmentShader: ShaderChunk.depth_frag\n\n\t},\n\n\tnormal: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.bumpmap,\n\t\t\tUniformsLib.normalmap,\n\t\t\tUniformsLib.displacementmap,\n\t\t\t{\n\t\t\t\topacity: { value: 1.0 }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.meshnormal_vert,\n\t\tfragmentShader: ShaderChunk.meshnormal_frag\n\n\t},\n\n\tsprite: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.sprite,\n\t\t\tUniformsLib.fog\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.sprite_vert,\n\t\tfragmentShader: ShaderChunk.sprite_frag\n\n\t},\n\n\tbackground: {\n\n\t\tuniforms: {\n\t\t\tuvTransform: { value: new Matrix3() },\n\t\t\tt2D: { value: null },\n\t\t},\n\n\t\tvertexShader: ShaderChunk.background_vert,\n\t\tfragmentShader: ShaderChunk.background_frag\n\n\t},\n\t/* -------------------------------------------------------------------------\n\t//\tCube map shader\n\t ------------------------------------------------------------------------- */\n\n\tcube: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.envmap,\n\t\t\t{\n\t\t\t\topacity: { value: 1.0 }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.cube_vert,\n\t\tfragmentShader: ShaderChunk.cube_frag\n\n\t},\n\n\tequirect: {\n\n\t\tuniforms: {\n\t\t\ttEquirect: { value: null },\n\t\t},\n\n\t\tvertexShader: ShaderChunk.equirect_vert,\n\t\tfragmentShader: ShaderChunk.equirect_frag\n\n\t},\n\n\tdistanceRGBA: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.common,\n\t\t\tUniformsLib.displacementmap,\n\t\t\t{\n\t\t\t\treferencePosition: { value: new Vector3() },\n\t\t\t\tnearDistance: { value: 1 },\n\t\t\t\tfarDistance: { value: 1000 }\n\t\t\t}\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.distanceRGBA_vert,\n\t\tfragmentShader: ShaderChunk.distanceRGBA_frag\n\n\t},\n\n\tshadow: {\n\n\t\tuniforms: mergeUniforms( [\n\t\t\tUniformsLib.lights,\n\t\t\tUniformsLib.fog,\n\t\t\t{\n\t\t\t\tcolor: { value: new Color( 0x00000 ) },\n\t\t\t\topacity: { value: 1.0 }\n\t\t\t},\n\t\t] ),\n\n\t\tvertexShader: ShaderChunk.shadow_vert,\n\t\tfragmentShader: ShaderChunk.shadow_frag\n\n\t}\n\n};\n\nShaderLib.physical = {\n\n\tuniforms: mergeUniforms( [\n\t\tShaderLib.standard.uniforms,\n\t\t{\n\t\t\tclearcoat: { value: 0 },\n\t\t\tclearcoatMap: { value: null },\n\t\t\tclearcoatRoughness: { value: 0 },\n\t\t\tclearcoatRoughnessMap: { value: null },\n\t\t\tclearcoatNormalScale: { value: new Vector2( 1, 1 ) },\n\t\t\tclearcoatNormalMap: { value: null },\n\t\t\tsheen: { value: 0 },\n\t\t\tsheenColor: { value: new Color( 0x000000 ) },\n\t\t\tsheenColorMap: { value: null },\n\t\t\tsheenRoughness: { value: 1 },\n\t\t\tsheenRoughnessMap: { value: null },\n\t\t\ttransmission: { value: 0 },\n\t\t\ttransmissionMap: { value: null },\n\t\t\ttransmissionSamplerSize: { value: new Vector2() },\n\t\t\ttransmissionSamplerMap: { value: null },\n\t\t\tthickness: { value: 0 },\n\t\t\tthicknessMap: { value: null },\n\t\t\tattenuationDistance: { value: 0 },\n\t\t\tattenuationColor: { value: new Color( 0x000000 ) },\n\t\t\tspecularIntensity: { value: 1 },\n\t\t\tspecularIntensityMap: { value: null },\n\t\t\tspecularColor: { value: new Color( 1, 1, 1 ) },\n\t\t\tspecularColorMap: { value: null },\n\t\t}\n\t] ),\n\n\tvertexShader: ShaderChunk.meshphysical_vert,\n\tfragmentShader: ShaderChunk.meshphysical_frag\n\n};\n\nfunction WebGLBackground( renderer, cubemaps, state, objects, alpha, premultipliedAlpha ) {\n\n\tconst clearColor = new Color( 0x000000 );\n\tlet clearAlpha = alpha === true ? 0 : 1;\n\n\tlet planeMesh;\n\tlet boxMesh;\n\n\tlet currentBackground = null;\n\tlet currentBackgroundVersion = 0;\n\tlet currentTonemapping = null;\n\n\tfunction render( renderList, scene ) {\n\n\t\tlet forceClear = false;\n\t\tlet background = scene.isScene === true ? scene.background : null;\n\n\t\tif ( background && background.isTexture ) {\n\n\t\t\tbackground = cubemaps.get( background );\n\n\t\t}\n\n\t\t// Ignore background in AR\n\t\t// TODO: Reconsider this.\n\n\t\tconst xr = renderer.xr;\n\t\tconst session = xr.getSession && xr.getSession();\n\n\t\tif ( session && session.environmentBlendMode === 'additive' ) {\n\n\t\t\tbackground = null;\n\n\t\t}\n\n\t\tif ( background === null ) {\n\n\t\t\tsetClear( clearColor, clearAlpha );\n\n\t\t} else if ( background && background.isColor ) {\n\n\t\t\tsetClear( background, 1 );\n\t\t\tforceClear = true;\n\n\t\t}\n\n\t\tif ( renderer.autoClear || forceClear ) {\n\n\t\t\trenderer.clear( renderer.autoClearColor, renderer.autoClearDepth, renderer.autoClearStencil );\n\n\t\t}\n\n\t\tif ( background && ( background.isCubeTexture || background.mapping === CubeUVReflectionMapping ) ) {\n\n\t\t\tif ( boxMesh === undefined ) {\n\n\t\t\t\tboxMesh = new Mesh(\n\t\t\t\t\tnew BoxGeometry( 1, 1, 1 ),\n\t\t\t\t\tnew ShaderMaterial( {\n\t\t\t\t\t\tname: 'BackgroundCubeMaterial',\n\t\t\t\t\t\tuniforms: cloneUniforms( ShaderLib.cube.uniforms ),\n\t\t\t\t\t\tvertexShader: ShaderLib.cube.vertexShader,\n\t\t\t\t\t\tfragmentShader: ShaderLib.cube.fragmentShader,\n\t\t\t\t\t\tside: BackSide,\n\t\t\t\t\t\tdepthTest: false,\n\t\t\t\t\t\tdepthWrite: false,\n\t\t\t\t\t\tfog: false\n\t\t\t\t\t} )\n\t\t\t\t);\n\n\t\t\t\tboxMesh.geometry.deleteAttribute( 'normal' );\n\t\t\t\tboxMesh.geometry.deleteAttribute( 'uv' );\n\n\t\t\t\tboxMesh.onBeforeRender = function ( renderer, scene, camera ) {\n\n\t\t\t\t\tthis.matrixWorld.copyPosition( camera.matrixWorld );\n\n\t\t\t\t};\n\n\t\t\t\t// enable code injection for non-built-in material\n\t\t\t\tObject.defineProperty( boxMesh.material, 'envMap', {\n\n\t\t\t\t\tget: function () {\n\n\t\t\t\t\t\treturn this.uniforms.envMap.value;\n\n\t\t\t\t\t}\n\n\t\t\t\t} );\n\n\t\t\t\tobjects.update( boxMesh );\n\n\t\t\t}\n\n\t\t\tboxMesh.material.uniforms.envMap.value = background;\n\t\t\tboxMesh.material.uniforms.flipEnvMap.value = ( background.isCubeTexture && background.isRenderTargetTexture === false ) ? - 1 : 1;\n\n\t\t\tif ( currentBackground !== background ||\n\t\t\t\tcurrentBackgroundVersion !== background.version ||\n\t\t\t\tcurrentTonemapping !== renderer.toneMapping ) {\n\n\t\t\t\tboxMesh.material.needsUpdate = true;\n\n\t\t\t\tcurrentBackground = background;\n\t\t\t\tcurrentBackgroundVersion = background.version;\n\t\t\t\tcurrentTonemapping = renderer.toneMapping;\n\n\t\t\t}\n\n\t\t\t// push to the pre-sorted opaque render list\n\t\t\trenderList.unshift( boxMesh, boxMesh.geometry, boxMesh.material, 0, 0, null );\n\n\t\t} else if ( background && background.isTexture ) {\n\n\t\t\tif ( planeMesh === undefined ) {\n\n\t\t\t\tplaneMesh = new Mesh(\n\t\t\t\t\tnew PlaneGeometry( 2, 2 ),\n\t\t\t\t\tnew ShaderMaterial( {\n\t\t\t\t\t\tname: 'BackgroundMaterial',\n\t\t\t\t\t\tuniforms: cloneUniforms( ShaderLib.background.uniforms ),\n\t\t\t\t\t\tvertexShader: ShaderLib.background.vertexShader,\n\t\t\t\t\t\tfragmentShader: ShaderLib.background.fragmentShader,\n\t\t\t\t\t\tside: FrontSide,\n\t\t\t\t\t\tdepthTest: false,\n\t\t\t\t\t\tdepthWrite: false,\n\t\t\t\t\t\tfog: false\n\t\t\t\t\t} )\n\t\t\t\t);\n\n\t\t\t\tplaneMesh.geometry.deleteAttribute( 'normal' );\n\n\t\t\t\t// enable code injection for non-built-in material\n\t\t\t\tObject.defineProperty( planeMesh.material, 'map', {\n\n\t\t\t\t\tget: function () {\n\n\t\t\t\t\t\treturn this.uniforms.t2D.value;\n\n\t\t\t\t\t}\n\n\t\t\t\t} );\n\n\t\t\t\tobjects.update( planeMesh );\n\n\t\t\t}\n\n\t\t\tplaneMesh.material.uniforms.t2D.value = background;\n\n\t\t\tif ( background.matrixAutoUpdate === true ) {\n\n\t\t\t\tbackground.updateMatrix();\n\n\t\t\t}\n\n\t\t\tplaneMesh.material.uniforms.uvTransform.value.copy( background.matrix );\n\n\t\t\tif ( currentBackground !== background ||\n\t\t\t\tcurrentBackgroundVersion !== background.version ||\n\t\t\t\tcurrentTonemapping !== renderer.toneMapping ) {\n\n\t\t\t\tplaneMesh.material.needsUpdate = true;\n\n\t\t\t\tcurrentBackground = background;\n\t\t\t\tcurrentBackgroundVersion = background.version;\n\t\t\t\tcurrentTonemapping = renderer.toneMapping;\n\n\t\t\t}\n\n\n\t\t\t// push to the pre-sorted opaque render list\n\t\t\trenderList.unshift( planeMesh, planeMesh.geometry, planeMesh.material, 0, 0, null );\n\n\t\t}\n\n\t}\n\n\tfunction setClear( color, alpha ) {\n\n\t\tstate.buffers.color.setClear( color.r, color.g, color.b, alpha, premultipliedAlpha );\n\n\t}\n\n\treturn {\n\n\t\tgetClearColor: function () {\n\n\t\t\treturn clearColor;\n\n\t\t},\n\t\tsetClearColor: function ( color, alpha = 1 ) {\n\n\t\t\tclearColor.set( color );\n\t\t\tclearAlpha = alpha;\n\t\t\tsetClear( clearColor, clearAlpha );\n\n\t\t},\n\t\tgetClearAlpha: function () {\n\n\t\t\treturn clearAlpha;\n\n\t\t},\n\t\tsetClearAlpha: function ( alpha ) {\n\n\t\t\tclearAlpha = alpha;\n\t\t\tsetClear( clearColor, clearAlpha );\n\n\t\t},\n\t\trender: render\n\n\t};\n\n}\n\nfunction WebGLBindingStates( gl, extensions, attributes, capabilities ) {\n\n\tconst maxVertexAttributes = gl.getParameter( 34921 );\n\n\tconst extension = capabilities.isWebGL2 ? null : extensions.get( 'OES_vertex_array_object' );\n\tconst vaoAvailable = capabilities.isWebGL2 || extension !== null;\n\n\tconst bindingStates = {};\n\n\tconst defaultState = createBindingState( null );\n\tlet currentState = defaultState;\n\n\tfunction setup( object, material, program, geometry, index ) {\n\n\t\tlet updateBuffers = false;\n\n\t\tif ( vaoAvailable ) {\n\n\t\t\tconst state = getBindingState( geometry, program, material );\n\n\t\t\tif ( currentState !== state ) {\n\n\t\t\t\tcurrentState = state;\n\t\t\t\tbindVertexArrayObject( currentState.object );\n\n\t\t\t}\n\n\t\t\tupdateBuffers = needsUpdate( geometry, index );\n\n\t\t\tif ( updateBuffers ) saveCache( geometry, index );\n\n\t\t} else {\n\n\t\t\tconst wireframe = ( material.wireframe === true );\n\n\t\t\tif ( currentState.geometry !== geometry.id ||\n\t\t\t\tcurrentState.program !== program.id ||\n\t\t\t\tcurrentState.wireframe !== wireframe ) {\n\n\t\t\t\tcurrentState.geometry = geometry.id;\n\t\t\t\tcurrentState.program = program.id;\n\t\t\t\tcurrentState.wireframe = wireframe;\n\n\t\t\t\tupdateBuffers = true;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( object.isInstancedMesh === true ) {\n\n\t\t\tupdateBuffers = true;\n\n\t\t}\n\n\t\tif ( index !== null ) {\n\n\t\t\tattributes.update( index, 34963 );\n\n\t\t}\n\n\t\tif ( updateBuffers ) {\n\n\t\t\tsetupVertexAttributes( object, material, program, geometry );\n\n\t\t\tif ( index !== null ) {\n\n\t\t\t\tgl.bindBuffer( 34963, attributes.get( index ).buffer );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tfunction createVertexArrayObject() {\n\n\t\tif ( capabilities.isWebGL2 ) return gl.createVertexArray();\n\n\t\treturn extension.createVertexArrayOES();\n\n\t}\n\n\tfunction bindVertexArrayObject( vao ) {\n\n\t\tif ( capabilities.isWebGL2 ) return gl.bindVertexArray( vao );\n\n\t\treturn extension.bindVertexArrayOES( vao );\n\n\t}\n\n\tfunction deleteVertexArrayObject( vao ) {\n\n\t\tif ( capabilities.isWebGL2 ) return gl.deleteVertexArray( vao );\n\n\t\treturn extension.deleteVertexArrayOES( vao );\n\n\t}\n\n\tfunction getBindingState( geometry, program, material ) {\n\n\t\tconst wireframe = ( material.wireframe === true );\n\n\t\tlet programMap = bindingStates[ geometry.id ];\n\n\t\tif ( programMap === undefined ) {\n\n\t\t\tprogramMap = {};\n\t\t\tbindingStates[ geometry.id ] = programMap;\n\n\t\t}\n\n\t\tlet stateMap = programMap[ program.id ];\n\n\t\tif ( stateMap === undefined ) {\n\n\t\t\tstateMap = {};\n\t\t\tprogramMap[ program.id ] = stateMap;\n\n\t\t}\n\n\t\tlet state = stateMap[ wireframe ];\n\n\t\tif ( state === undefined ) {\n\n\t\t\tstate = createBindingState( createVertexArrayObject() );\n\t\t\tstateMap[ wireframe ] = state;\n\n\t\t}\n\n\t\treturn state;\n\n\t}\n\n\tfunction createBindingState( vao ) {\n\n\t\tconst newAttributes = [];\n\t\tconst enabledAttributes = [];\n\t\tconst attributeDivisors = [];\n\n\t\tfor ( let i = 0; i < maxVertexAttributes; i ++ ) {\n\n\t\t\tnewAttributes[ i ] = 0;\n\t\t\tenabledAttributes[ i ] = 0;\n\t\t\tattributeDivisors[ i ] = 0;\n\n\t\t}\n\n\t\treturn {\n\n\t\t\t// for backward compatibility on non-VAO support browser\n\t\t\tgeometry: null,\n\t\t\tprogram: null,\n\t\t\twireframe: false,\n\n\t\t\tnewAttributes: newAttributes,\n\t\t\tenabledAttributes: enabledAttributes,\n\t\t\tattributeDivisors: attributeDivisors,\n\t\t\tobject: vao,\n\t\t\tattributes: {},\n\t\t\tindex: null\n\n\t\t};\n\n\t}\n\n\tfunction needsUpdate( geometry, index ) {\n\n\t\tconst cachedAttributes = currentState.attributes;\n\t\tconst geometryAttributes = geometry.attributes;\n\n\t\tlet attributesNum = 0;\n\n\t\tfor ( const key in geometryAttributes ) {\n\n\t\t\tconst cachedAttribute = cachedAttributes[ key ];\n\t\t\tconst geometryAttribute = geometryAttributes[ key ];\n\n\t\t\tif ( cachedAttribute === undefined ) return true;\n\n\t\t\tif ( cachedAttribute.attribute !== geometryAttribute ) return true;\n\n\t\t\tif ( cachedAttribute.data !== geometryAttribute.data ) return true;\n\n\t\t\tattributesNum ++;\n\n\t\t}\n\n\t\tif ( currentState.attributesNum !== attributesNum ) return true;\n\n\t\tif ( currentState.index !== index ) return true;\n\n\t\treturn false;\n\n\t}\n\n\tfunction saveCache( geometry, index ) {\n\n\t\tconst cache = {};\n\t\tconst attributes = geometry.attributes;\n\t\tlet attributesNum = 0;\n\n\t\tfor ( const key in attributes ) {\n\n\t\t\tconst attribute = attributes[ key ];\n\n\t\t\tconst data = {};\n\t\t\tdata.attribute = attribute;\n\n\t\t\tif ( attribute.data ) {\n\n\t\t\t\tdata.data = attribute.data;\n\n\t\t\t}\n\n\t\t\tcache[ key ] = data;\n\n\t\t\tattributesNum ++;\n\n\t\t}\n\n\t\tcurrentState.attributes = cache;\n\t\tcurrentState.attributesNum = attributesNum;\n\n\t\tcurrentState.index = index;\n\n\t}\n\n\tfunction initAttributes() {\n\n\t\tconst newAttributes = currentState.newAttributes;\n\n\t\tfor ( let i = 0, il = newAttributes.length; i < il; i ++ ) {\n\n\t\t\tnewAttributes[ i ] = 0;\n\n\t\t}\n\n\t}\n\n\tfunction enableAttribute( attribute ) {\n\n\t\tenableAttributeAndDivisor( attribute, 0 );\n\n\t}\n\n\tfunction enableAttributeAndDivisor( attribute, meshPerAttribute ) {\n\n\t\tconst newAttributes = currentState.newAttributes;\n\t\tconst enabledAttributes = currentState.enabledAttributes;\n\t\tconst attributeDivisors = currentState.attributeDivisors;\n\n\t\tnewAttributes[ attribute ] = 1;\n\n\t\tif ( enabledAttributes[ attribute ] === 0 ) {\n\n\t\t\tgl.enableVertexAttribArray( attribute );\n\t\t\tenabledAttributes[ attribute ] = 1;\n\n\t\t}\n\n\t\tif ( attributeDivisors[ attribute ] !== meshPerAttribute ) {\n\n\t\t\tconst extension = capabilities.isWebGL2 ? gl : extensions.get( 'ANGLE_instanced_arrays' );\n\n\t\t\textension[ capabilities.isWebGL2 ? 'vertexAttribDivisor' : 'vertexAttribDivisorANGLE' ]( attribute, meshPerAttribute );\n\t\t\tattributeDivisors[ attribute ] = meshPerAttribute;\n\n\t\t}\n\n\t}\n\n\tfunction disableUnusedAttributes() {\n\n\t\tconst newAttributes = currentState.newAttributes;\n\t\tconst enabledAttributes = currentState.enabledAttributes;\n\n\t\tfor ( let i = 0, il = enabledAttributes.length; i < il; i ++ ) {\n\n\t\t\tif ( enabledAttributes[ i ] !== newAttributes[ i ] ) {\n\n\t\t\t\tgl.disableVertexAttribArray( i );\n\t\t\t\tenabledAttributes[ i ] = 0;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tfunction vertexAttribPointer( index, size, type, normalized, stride, offset ) {\n\n\t\tif ( capabilities.isWebGL2 === true && ( type === 5124 || type === 5125 ) ) {\n\n\t\t\tgl.vertexAttribIPointer( index, size, type, stride, offset );\n\n\t\t} else {\n\n\t\t\tgl.vertexAttribPointer( index, size, type, normalized, stride, offset );\n\n\t\t}\n\n\t}\n\n\tfunction setupVertexAttributes( object, material, program, geometry ) {\n\n\t\tif ( capabilities.isWebGL2 === false && ( object.isInstancedMesh || geometry.isInstancedBufferGeometry ) ) {\n\n\t\t\tif ( extensions.get( 'ANGLE_instanced_arrays' ) === null ) return;\n\n\t\t}\n\n\t\tinitAttributes();\n\n\t\tconst geometryAttributes = geometry.attributes;\n\n\t\tconst programAttributes = program.getAttributes();\n\n\t\tconst materialDefaultAttributeValues = material.defaultAttributeValues;\n\n\t\tfor ( const name in programAttributes ) {\n\n\t\t\tconst programAttribute = programAttributes[ name ];\n\n\t\t\tif ( programAttribute.location >= 0 ) {\n\n\t\t\t\tlet geometryAttribute = geometryAttributes[ name ];\n\n\t\t\t\tif ( geometryAttribute === undefined ) {\n\n\t\t\t\t\tif ( name === 'instanceMatrix' && object.instanceMatrix ) geometryAttribute = object.instanceMatrix;\n\t\t\t\t\tif ( name === 'instanceColor' && object.instanceColor ) geometryAttribute = object.instanceColor;\n\n\t\t\t\t}\n\n\t\t\t\tif ( geometryAttribute !== undefined ) {\n\n\t\t\t\t\tconst normalized = geometryAttribute.normalized;\n\t\t\t\t\tconst size = geometryAttribute.itemSize;\n\n\t\t\t\t\tconst attribute = attributes.get( geometryAttribute );\n\n\t\t\t\t\t// TODO Attribute may not be available on context restore\n\n\t\t\t\t\tif ( attribute === undefined ) continue;\n\n\t\t\t\t\tconst buffer = attribute.buffer;\n\t\t\t\t\tconst type = attribute.type;\n\t\t\t\t\tconst bytesPerElement = attribute.bytesPerElement;\n\n\t\t\t\t\tif ( geometryAttribute.isInterleavedBufferAttribute ) {\n\n\t\t\t\t\t\tconst data = geometryAttribute.data;\n\t\t\t\t\t\tconst stride = data.stride;\n\t\t\t\t\t\tconst offset = geometryAttribute.offset;\n\n\t\t\t\t\t\tif ( data.isInstancedInterleavedBuffer ) {\n\n\t\t\t\t\t\t\tfor ( let i = 0; i < programAttribute.locationSize; i ++ ) {\n\n\t\t\t\t\t\t\t\tenableAttributeAndDivisor( programAttribute.location + i, data.meshPerAttribute );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif ( object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined ) {\n\n\t\t\t\t\t\t\t\tgeometry._maxInstanceCount = data.meshPerAttribute * data.count;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tfor ( let i = 0; i < programAttribute.locationSize; i ++ ) {\n\n\t\t\t\t\t\t\t\tenableAttribute( programAttribute.location + i );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tgl.bindBuffer( 34962, buffer );\n\n\t\t\t\t\t\tfor ( let i = 0; i < programAttribute.locationSize; i ++ ) {\n\n\t\t\t\t\t\t\tvertexAttribPointer(\n\t\t\t\t\t\t\t\tprogramAttribute.location + i,\n\t\t\t\t\t\t\t\tsize / programAttribute.locationSize,\n\t\t\t\t\t\t\t\ttype,\n\t\t\t\t\t\t\t\tnormalized,\n\t\t\t\t\t\t\t\tstride * bytesPerElement,\n\t\t\t\t\t\t\t\t( offset + ( size / programAttribute.locationSize ) * i ) * bytesPerElement\n\t\t\t\t\t\t\t);\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tif ( geometryAttribute.isInstancedBufferAttribute ) {\n\n\t\t\t\t\t\t\tfor ( let i = 0; i < programAttribute.locationSize; i ++ ) {\n\n\t\t\t\t\t\t\t\tenableAttributeAndDivisor( programAttribute.location + i, geometryAttribute.meshPerAttribute );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif ( object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined ) {\n\n\t\t\t\t\t\t\t\tgeometry._maxInstanceCount = geometryAttribute.meshPerAttribute * geometryAttribute.count;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tfor ( let i = 0; i < programAttribute.locationSize; i ++ ) {\n\n\t\t\t\t\t\t\t\tenableAttribute( programAttribute.location + i );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tgl.bindBuffer( 34962, buffer );\n\n\t\t\t\t\t\tfor ( let i = 0; i < programAttribute.locationSize; i ++ ) {\n\n\t\t\t\t\t\t\tvertexAttribPointer(\n\t\t\t\t\t\t\t\tprogramAttribute.location + i,\n\t\t\t\t\t\t\t\tsize / programAttribute.locationSize,\n\t\t\t\t\t\t\t\ttype,\n\t\t\t\t\t\t\t\tnormalized,\n\t\t\t\t\t\t\t\tsize * bytesPerElement,\n\t\t\t\t\t\t\t\t( size / programAttribute.locationSize ) * i * bytesPerElement\n\t\t\t\t\t\t\t);\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t} else if ( materialDefaultAttributeValues !== undefined ) {\n\n\t\t\t\t\tconst value = materialDefaultAttributeValues[ name ];\n\n\t\t\t\t\tif ( value !== undefined ) {\n\n\t\t\t\t\t\tswitch ( value.length ) {\n\n\t\t\t\t\t\t\tcase 2:\n\t\t\t\t\t\t\t\tgl.vertexAttrib2fv( programAttribute.location, value );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase 3:\n\t\t\t\t\t\t\t\tgl.vertexAttrib3fv( programAttribute.location, value );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase 4:\n\t\t\t\t\t\t\t\tgl.vertexAttrib4fv( programAttribute.location, value );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tgl.vertexAttrib1fv( programAttribute.location, value );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tdisableUnusedAttributes();\n\n\t}\n\n\tfunction dispose() {\n\n\t\treset();\n\n\t\tfor ( const geometryId in bindingStates ) {\n\n\t\t\tconst programMap = bindingStates[ geometryId ];\n\n\t\t\tfor ( const programId in programMap ) {\n\n\t\t\t\tconst stateMap = programMap[ programId ];\n\n\t\t\t\tfor ( const wireframe in stateMap ) {\n\n\t\t\t\t\tdeleteVertexArrayObject( stateMap[ wireframe ].object );\n\n\t\t\t\t\tdelete stateMap[ wireframe ];\n\n\t\t\t\t}\n\n\t\t\t\tdelete programMap[ programId ];\n\n\t\t\t}\n\n\t\t\tdelete bindingStates[ geometryId ];\n\n\t\t}\n\n\t}\n\n\tfunction releaseStatesOfGeometry( geometry ) {\n\n\t\tif ( bindingStates[ geometry.id ] === undefined ) return;\n\n\t\tconst programMap = bindingStates[ geometry.id ];\n\n\t\tfor ( const programId in programMap ) {\n\n\t\t\tconst stateMap = programMap[ programId ];\n\n\t\t\tfor ( const wireframe in stateMap ) {\n\n\t\t\t\tdeleteVertexArrayObject( stateMap[ wireframe ].object );\n\n\t\t\t\tdelete stateMap[ wireframe ];\n\n\t\t\t}\n\n\t\t\tdelete programMap[ programId ];\n\n\t\t}\n\n\t\tdelete bindingStates[ geometry.id ];\n\n\t}\n\n\tfunction releaseStatesOfProgram( program ) {\n\n\t\tfor ( const geometryId in bindingStates ) {\n\n\t\t\tconst programMap = bindingStates[ geometryId ];\n\n\t\t\tif ( programMap[ program.id ] === undefined ) continue;\n\n\t\t\tconst stateMap = programMap[ program.id ];\n\n\t\t\tfor ( const wireframe in stateMap ) {\n\n\t\t\t\tdeleteVertexArrayObject( stateMap[ wireframe ].object );\n\n\t\t\t\tdelete stateMap[ wireframe ];\n\n\t\t\t}\n\n\t\t\tdelete programMap[ program.id ];\n\n\t\t}\n\n\t}\n\n\tfunction reset() {\n\n\t\tresetDefaultState();\n\n\t\tif ( currentState === defaultState ) return;\n\n\t\tcurrentState = defaultState;\n\t\tbindVertexArrayObject( currentState.object );\n\n\t}\n\n\t// for backward-compatilibity\n\n\tfunction resetDefaultState() {\n\n\t\tdefaultState.geometry = null;\n\t\tdefaultState.program = null;\n\t\tdefaultState.wireframe = false;\n\n\t}\n\n\treturn {\n\n\t\tsetup: setup,\n\t\treset: reset,\n\t\tresetDefaultState: resetDefaultState,\n\t\tdispose: dispose,\n\t\treleaseStatesOfGeometry: releaseStatesOfGeometry,\n\t\treleaseStatesOfProgram: releaseStatesOfProgram,\n\n\t\tinitAttributes: initAttributes,\n\t\tenableAttribute: enableAttribute,\n\t\tdisableUnusedAttributes: disableUnusedAttributes\n\n\t};\n\n}\n\nfunction WebGLBufferRenderer( gl, extensions, info, capabilities ) {\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\n\tlet mode;\n\n\tfunction setMode( value ) {\n\n\t\tmode = value;\n\n\t}\n\n\tfunction render( start, count ) {\n\n\t\tgl.drawArrays( mode, start, count );\n\n\t\tinfo.update( count, mode, 1 );\n\n\t}\n\n\tfunction renderInstances( start, count, primcount ) {\n\n\t\tif ( primcount === 0 ) return;\n\n\t\tlet extension, methodName;\n\n\t\tif ( isWebGL2 ) {\n\n\t\t\textension = gl;\n\t\t\tmethodName = 'drawArraysInstanced';\n\n\t\t} else {\n\n\t\t\textension = extensions.get( 'ANGLE_instanced_arrays' );\n\t\t\tmethodName = 'drawArraysInstancedANGLE';\n\n\t\t\tif ( extension === null ) {\n\n\t\t\t\tconsole.error( 'THREE.WebGLBufferRenderer: using THREE.InstancedBufferGeometry but hardware does not support extension ANGLE_instanced_arrays.' );\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t}\n\n\t\textension[ methodName ]( mode, start, count, primcount );\n\n\t\tinfo.update( count, mode, primcount );\n\n\t}\n\n\t//\n\n\tthis.setMode = setMode;\n\tthis.render = render;\n\tthis.renderInstances = renderInstances;\n\n}\n\nfunction WebGLCapabilities( gl, extensions, parameters ) {\n\n\tlet maxAnisotropy;\n\n\tfunction getMaxAnisotropy() {\n\n\t\tif ( maxAnisotropy !== undefined ) return maxAnisotropy;\n\n\t\tif ( extensions.has( 'EXT_texture_filter_anisotropic' ) === true ) {\n\n\t\t\tconst extension = extensions.get( 'EXT_texture_filter_anisotropic' );\n\n\t\t\tmaxAnisotropy = gl.getParameter( extension.MAX_TEXTURE_MAX_ANISOTROPY_EXT );\n\n\t\t} else {\n\n\t\t\tmaxAnisotropy = 0;\n\n\t\t}\n\n\t\treturn maxAnisotropy;\n\n\t}\n\n\tfunction getMaxPrecision( precision ) {\n\n\t\tif ( precision === 'highp' ) {\n\n\t\t\tif ( gl.getShaderPrecisionFormat( 35633, 36338 ).precision > 0 &&\n\t\t\t\tgl.getShaderPrecisionFormat( 35632, 36338 ).precision > 0 ) {\n\n\t\t\t\treturn 'highp';\n\n\t\t\t}\n\n\t\t\tprecision = 'mediump';\n\n\t\t}\n\n\t\tif ( precision === 'mediump' ) {\n\n\t\t\tif ( gl.getShaderPrecisionFormat( 35633, 36337 ).precision > 0 &&\n\t\t\t\tgl.getShaderPrecisionFormat( 35632, 36337 ).precision > 0 ) {\n\n\t\t\t\treturn 'mediump';\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn 'lowp';\n\n\t}\n\n\tconst isWebGL2 = ( typeof WebGL2RenderingContext !== 'undefined' && gl instanceof WebGL2RenderingContext ) ||\n\t\t( typeof WebGL2ComputeRenderingContext !== 'undefined' && gl instanceof WebGL2ComputeRenderingContext );\n\n\tlet precision = parameters.precision !== undefined ? parameters.precision : 'highp';\n\tconst maxPrecision = getMaxPrecision( precision );\n\n\tif ( maxPrecision !== precision ) {\n\n\t\tconsole.warn( 'THREE.WebGLRenderer:', precision, 'not supported, using', maxPrecision, 'instead.' );\n\t\tprecision = maxPrecision;\n\n\t}\n\n\tconst drawBuffers = isWebGL2 || extensions.has( 'WEBGL_draw_buffers' );\n\n\tconst logarithmicDepthBuffer = parameters.logarithmicDepthBuffer === true;\n\n\tconst maxTextures = gl.getParameter( 34930 );\n\tconst maxVertexTextures = gl.getParameter( 35660 );\n\tconst maxTextureSize = gl.getParameter( 3379 );\n\tconst maxCubemapSize = gl.getParameter( 34076 );\n\n\tconst maxAttributes = gl.getParameter( 34921 );\n\tconst maxVertexUniforms = gl.getParameter( 36347 );\n\tconst maxVaryings = gl.getParameter( 36348 );\n\tconst maxFragmentUniforms = gl.getParameter( 36349 );\n\n\tconst vertexTextures = maxVertexTextures > 0;\n\tconst floatFragmentTextures = isWebGL2 || extensions.has( 'OES_texture_float' );\n\tconst floatVertexTextures = vertexTextures && floatFragmentTextures;\n\n\tconst maxSamples = isWebGL2 ? gl.getParameter( 36183 ) : 0;\n\n\treturn {\n\n\t\tisWebGL2: isWebGL2,\n\n\t\tdrawBuffers: drawBuffers,\n\n\t\tgetMaxAnisotropy: getMaxAnisotropy,\n\t\tgetMaxPrecision: getMaxPrecision,\n\n\t\tprecision: precision,\n\t\tlogarithmicDepthBuffer: logarithmicDepthBuffer,\n\n\t\tmaxTextures: maxTextures,\n\t\tmaxVertexTextures: maxVertexTextures,\n\t\tmaxTextureSize: maxTextureSize,\n\t\tmaxCubemapSize: maxCubemapSize,\n\n\t\tmaxAttributes: maxAttributes,\n\t\tmaxVertexUniforms: maxVertexUniforms,\n\t\tmaxVaryings: maxVaryings,\n\t\tmaxFragmentUniforms: maxFragmentUniforms,\n\n\t\tvertexTextures: vertexTextures,\n\t\tfloatFragmentTextures: floatFragmentTextures,\n\t\tfloatVertexTextures: floatVertexTextures,\n\n\t\tmaxSamples: maxSamples\n\n\t};\n\n}\n\nfunction WebGLClipping( properties ) {\n\n\tconst scope = this;\n\n\tlet globalState = null,\n\t\tnumGlobalPlanes = 0,\n\t\tlocalClippingEnabled = false,\n\t\trenderingShadows = false;\n\n\tconst plane = new Plane(),\n\t\tviewNormalMatrix = new Matrix3(),\n\n\t\tuniform = { value: null, needsUpdate: false };\n\n\tthis.uniform = uniform;\n\tthis.numPlanes = 0;\n\tthis.numIntersection = 0;\n\n\tthis.init = function ( planes, enableLocalClipping, camera ) {\n\n\t\tconst enabled =\n\t\t\tplanes.length !== 0 ||\n\t\t\tenableLocalClipping ||\n\t\t\t// enable state of previous frame - the clipping code has to\n\t\t\t// run another frame in order to reset the state:\n\t\t\tnumGlobalPlanes !== 0 ||\n\t\t\tlocalClippingEnabled;\n\n\t\tlocalClippingEnabled = enableLocalClipping;\n\n\t\tglobalState = projectPlanes( planes, camera, 0 );\n\t\tnumGlobalPlanes = planes.length;\n\n\t\treturn enabled;\n\n\t};\n\n\tthis.beginShadows = function () {\n\n\t\trenderingShadows = true;\n\t\tprojectPlanes( null );\n\n\t};\n\n\tthis.endShadows = function () {\n\n\t\trenderingShadows = false;\n\t\tresetGlobalState();\n\n\t};\n\n\tthis.setState = function ( material, camera, useCache ) {\n\n\t\tconst planes = material.clippingPlanes,\n\t\t\tclipIntersection = material.clipIntersection,\n\t\t\tclipShadows = material.clipShadows;\n\n\t\tconst materialProperties = properties.get( material );\n\n\t\tif ( ! localClippingEnabled || planes === null || planes.length === 0 || renderingShadows && ! clipShadows ) {\n\n\t\t\t// there's no local clipping\n\n\t\t\tif ( renderingShadows ) {\n\n\t\t\t\t// there's no global clipping\n\n\t\t\t\tprojectPlanes( null );\n\n\t\t\t} else {\n\n\t\t\t\tresetGlobalState();\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconst nGlobal = renderingShadows ? 0 : numGlobalPlanes,\n\t\t\t\tlGlobal = nGlobal * 4;\n\n\t\t\tlet dstArray = materialProperties.clippingState || null;\n\n\t\t\tuniform.value = dstArray; // ensure unique state\n\n\t\t\tdstArray = projectPlanes( planes, camera, lGlobal, useCache );\n\n\t\t\tfor ( let i = 0; i !== lGlobal; ++ i ) {\n\n\t\t\t\tdstArray[ i ] = globalState[ i ];\n\n\t\t\t}\n\n\t\t\tmaterialProperties.clippingState = dstArray;\n\t\t\tthis.numIntersection = clipIntersection ? this.numPlanes : 0;\n\t\t\tthis.numPlanes += nGlobal;\n\n\t\t}\n\n\n\t};\n\n\tfunction resetGlobalState() {\n\n\t\tif ( uniform.value !== globalState ) {\n\n\t\t\tuniform.value = globalState;\n\t\t\tuniform.needsUpdate = numGlobalPlanes > 0;\n\n\t\t}\n\n\t\tscope.numPlanes = numGlobalPlanes;\n\t\tscope.numIntersection = 0;\n\n\t}\n\n\tfunction projectPlanes( planes, camera, dstOffset, skipTransform ) {\n\n\t\tconst nPlanes = planes !== null ? planes.length : 0;\n\t\tlet dstArray = null;\n\n\t\tif ( nPlanes !== 0 ) {\n\n\t\t\tdstArray = uniform.value;\n\n\t\t\tif ( skipTransform !== true || dstArray === null ) {\n\n\t\t\t\tconst flatSize = dstOffset + nPlanes * 4,\n\t\t\t\t\tviewMatrix = camera.matrixWorldInverse;\n\n\t\t\t\tviewNormalMatrix.getNormalMatrix( viewMatrix );\n\n\t\t\t\tif ( dstArray === null || dstArray.length < flatSize ) {\n\n\t\t\t\t\tdstArray = new Float32Array( flatSize );\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let i = 0, i4 = dstOffset; i !== nPlanes; ++ i, i4 += 4 ) {\n\n\t\t\t\t\tplane.copy( planes[ i ] ).applyMatrix4( viewMatrix, viewNormalMatrix );\n\n\t\t\t\t\tplane.normal.toArray( dstArray, i4 );\n\t\t\t\t\tdstArray[ i4 + 3 ] = plane.constant;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tuniform.value = dstArray;\n\t\t\tuniform.needsUpdate = true;\n\n\t\t}\n\n\t\tscope.numPlanes = nPlanes;\n\t\tscope.numIntersection = 0;\n\n\t\treturn dstArray;\n\n\t}\n\n}\n\nfunction WebGLCubeMaps( renderer ) {\n\n\tlet cubemaps = new WeakMap();\n\n\tfunction mapTextureMapping( texture, mapping ) {\n\n\t\tif ( mapping === EquirectangularReflectionMapping ) {\n\n\t\t\ttexture.mapping = CubeReflectionMapping;\n\n\t\t} else if ( mapping === EquirectangularRefractionMapping ) {\n\n\t\t\ttexture.mapping = CubeRefractionMapping;\n\n\t\t}\n\n\t\treturn texture;\n\n\t}\n\n\tfunction get( texture ) {\n\n\t\tif ( texture && texture.isTexture && texture.isRenderTargetTexture === false ) {\n\n\t\t\tconst mapping = texture.mapping;\n\n\t\t\tif ( mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping ) {\n\n\t\t\t\tif ( cubemaps.has( texture ) ) {\n\n\t\t\t\t\tconst cubemap = cubemaps.get( texture ).texture;\n\t\t\t\t\treturn mapTextureMapping( cubemap, texture.mapping );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconst image = texture.image;\n\n\t\t\t\t\tif ( image && image.height > 0 ) {\n\n\t\t\t\t\t\tconst renderTarget = new WebGLCubeRenderTarget( image.height / 2 );\n\t\t\t\t\t\trenderTarget.fromEquirectangularTexture( renderer, texture );\n\t\t\t\t\t\tcubemaps.set( texture, renderTarget );\n\n\t\t\t\t\t\ttexture.addEventListener( 'dispose', onTextureDispose );\n\n\t\t\t\t\t\treturn mapTextureMapping( renderTarget.texture, texture.mapping );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t// image not yet ready. try the conversion next frame\n\n\t\t\t\t\t\treturn null;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn texture;\n\n\t}\n\n\tfunction onTextureDispose( event ) {\n\n\t\tconst texture = event.target;\n\n\t\ttexture.removeEventListener( 'dispose', onTextureDispose );\n\n\t\tconst cubemap = cubemaps.get( texture );\n\n\t\tif ( cubemap !== undefined ) {\n\n\t\t\tcubemaps.delete( texture );\n\t\t\tcubemap.dispose();\n\n\t\t}\n\n\t}\n\n\tfunction dispose() {\n\n\t\tcubemaps = new WeakMap();\n\n\t}\n\n\treturn {\n\t\tget: get,\n\t\tdispose: dispose\n\t};\n\n}\n\nclass OrthographicCamera extends Camera {\n\n\tconstructor( left = - 1, right = 1, top = 1, bottom = - 1, near = 0.1, far = 2000 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'OrthographicCamera';\n\n\t\tthis.zoom = 1;\n\t\tthis.view = null;\n\n\t\tthis.left = left;\n\t\tthis.right = right;\n\t\tthis.top = top;\n\t\tthis.bottom = bottom;\n\n\t\tthis.near = near;\n\t\tthis.far = far;\n\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\tcopy( source, recursive ) {\n\n\t\tsuper.copy( source, recursive );\n\n\t\tthis.left = source.left;\n\t\tthis.right = source.right;\n\t\tthis.top = source.top;\n\t\tthis.bottom = source.bottom;\n\t\tthis.near = source.near;\n\t\tthis.far = source.far;\n\n\t\tthis.zoom = source.zoom;\n\t\tthis.view = source.view === null ? null : Object.assign( {}, source.view );\n\n\t\treturn this;\n\n\t}\n\n\tsetViewOffset( fullWidth, fullHeight, x, y, width, height ) {\n\n\t\tif ( this.view === null ) {\n\n\t\t\tthis.view = {\n\t\t\t\tenabled: true,\n\t\t\t\tfullWidth: 1,\n\t\t\t\tfullHeight: 1,\n\t\t\t\toffsetX: 0,\n\t\t\t\toffsetY: 0,\n\t\t\t\twidth: 1,\n\t\t\t\theight: 1\n\t\t\t};\n\n\t\t}\n\n\t\tthis.view.enabled = true;\n\t\tthis.view.fullWidth = fullWidth;\n\t\tthis.view.fullHeight = fullHeight;\n\t\tthis.view.offsetX = x;\n\t\tthis.view.offsetY = y;\n\t\tthis.view.width = width;\n\t\tthis.view.height = height;\n\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\tclearViewOffset() {\n\n\t\tif ( this.view !== null ) {\n\n\t\t\tthis.view.enabled = false;\n\n\t\t}\n\n\t\tthis.updateProjectionMatrix();\n\n\t}\n\n\tupdateProjectionMatrix() {\n\n\t\tconst dx = ( this.right - this.left ) / ( 2 * this.zoom );\n\t\tconst dy = ( this.top - this.bottom ) / ( 2 * this.zoom );\n\t\tconst cx = ( this.right + this.left ) / 2;\n\t\tconst cy = ( this.top + this.bottom ) / 2;\n\n\t\tlet left = cx - dx;\n\t\tlet right = cx + dx;\n\t\tlet top = cy + dy;\n\t\tlet bottom = cy - dy;\n\n\t\tif ( this.view !== null && this.view.enabled ) {\n\n\t\t\tconst scaleW = ( this.right - this.left ) / this.view.fullWidth / this.zoom;\n\t\t\tconst scaleH = ( this.top - this.bottom ) / this.view.fullHeight / this.zoom;\n\n\t\t\tleft += scaleW * this.view.offsetX;\n\t\t\tright = left + scaleW * this.view.width;\n\t\t\ttop -= scaleH * this.view.offsetY;\n\t\t\tbottom = top - scaleH * this.view.height;\n\n\t\t}\n\n\t\tthis.projectionMatrix.makeOrthographic( left, right, top, bottom, this.near, this.far );\n\n\t\tthis.projectionMatrixInverse.copy( this.projectionMatrix ).invert();\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tdata.object.zoom = this.zoom;\n\t\tdata.object.left = this.left;\n\t\tdata.object.right = this.right;\n\t\tdata.object.top = this.top;\n\t\tdata.object.bottom = this.bottom;\n\t\tdata.object.near = this.near;\n\t\tdata.object.far = this.far;\n\n\t\tif ( this.view !== null ) data.object.view = Object.assign( {}, this.view );\n\n\t\treturn data;\n\n\t}\n\n}\n\nOrthographicCamera.prototype.isOrthographicCamera = true;\n\nconst LOD_MIN = 4;\n\n// The standard deviations (radians) associated with the extra mips. These are\n// chosen to approximate a Trowbridge-Reitz distribution function times the\n// geometric shadowing function. These sigma values squared must match the\n// variance #defines in cube_uv_reflection_fragment.glsl.js.\nconst EXTRA_LOD_SIGMA = [ 0.125, 0.215, 0.35, 0.446, 0.526, 0.582 ];\n\n// The maximum length of the blur for loop. Smaller sigmas will use fewer\n// samples and exit early, but not recompile the shader.\nconst MAX_SAMPLES = 20;\n\nconst _flatCamera = /*@__PURE__*/ new OrthographicCamera();\nconst _clearColor = /*@__PURE__*/ new Color();\nlet _oldTarget = null;\n\n// Golden Ratio\nconst PHI = ( 1 + Math.sqrt( 5 ) ) / 2;\nconst INV_PHI = 1 / PHI;\n\n// Vertices of a dodecahedron (except the opposites, which represent the\n// same axis), used as axis directions evenly spread on a sphere.\nconst _axisDirections = [\n\t/*@__PURE__*/ new Vector3( 1, 1, 1 ),\n\t/*@__PURE__*/ new Vector3( - 1, 1, 1 ),\n\t/*@__PURE__*/ new Vector3( 1, 1, - 1 ),\n\t/*@__PURE__*/ new Vector3( - 1, 1, - 1 ),\n\t/*@__PURE__*/ new Vector3( 0, PHI, INV_PHI ),\n\t/*@__PURE__*/ new Vector3( 0, PHI, - INV_PHI ),\n\t/*@__PURE__*/ new Vector3( INV_PHI, 0, PHI ),\n\t/*@__PURE__*/ new Vector3( - INV_PHI, 0, PHI ),\n\t/*@__PURE__*/ new Vector3( PHI, INV_PHI, 0 ),\n\t/*@__PURE__*/ new Vector3( - PHI, INV_PHI, 0 ) ];\n\n/**\n * This class generates a Prefiltered, Mipmapped Radiance Environment Map\n * (PMREM) from a cubeMap environment texture. This allows different levels of\n * blur to be quickly accessed based on material roughness. It is packed into a\n * special CubeUV format that allows us to perform custom interpolation so that\n * we can support nonlinear formats such as RGBE. Unlike a traditional mipmap\n * chain, it only goes down to the LOD_MIN level (above), and then creates extra\n * even more filtered 'mips' at the same LOD_MIN resolution, associated with\n * higher roughness levels. In this way we maintain resolution to smoothly\n * interpolate diffuse lighting while limiting sampling computation.\n *\n * Paper: Fast, Accurate Image-Based Lighting\n * https://drive.google.com/file/d/15y8r_UpKlU9SvV4ILb0C3qCPecS8pvLz/view\n*/\n\nclass PMREMGenerator {\n\n\tconstructor( renderer ) {\n\n\t\tthis._renderer = renderer;\n\t\tthis._pingPongRenderTarget = null;\n\n\t\tthis._lodMax = 0;\n\t\tthis._cubeSize = 0;\n\t\tthis._lodPlanes = [];\n\t\tthis._sizeLods = [];\n\t\tthis._sigmas = [];\n\n\t\tthis._blurMaterial = null;\n\t\tthis._cubemapMaterial = null;\n\t\tthis._equirectMaterial = null;\n\n\t\tthis._compileMaterial( this._blurMaterial );\n\n\t}\n\n\t/**\n\t * Generates a PMREM from a supplied Scene, which can be faster than using an\n\t * image if networking bandwidth is low. Optional sigma specifies a blur radius\n\t * in radians to be applied to the scene before PMREM generation. Optional near\n\t * and far planes ensure the scene is rendered in its entirety (the cubeCamera\n\t * is placed at the origin).\n\t */\n\tfromScene( scene, sigma = 0, near = 0.1, far = 100 ) {\n\n\t\t_oldTarget = this._renderer.getRenderTarget();\n\n\t\tthis._setSize( 256 );\n\n\t\tconst cubeUVRenderTarget = this._allocateTargets();\n\t\tcubeUVRenderTarget.depthBuffer = true;\n\n\t\tthis._sceneToCubeUV( scene, near, far, cubeUVRenderTarget );\n\n\t\tif ( sigma > 0 ) {\n\n\t\t\tthis._blur( cubeUVRenderTarget, 0, 0, sigma );\n\n\t\t}\n\n\t\tthis._applyPMREM( cubeUVRenderTarget );\n\t\tthis._cleanup( cubeUVRenderTarget );\n\n\t\treturn cubeUVRenderTarget;\n\n\t}\n\n\t/**\n\t * Generates a PMREM from an equirectangular texture, which can be either LDR\n\t * or HDR. The ideal input image size is 1k (1024 x 512),\n\t * as this matches best with the 256 x 256 cubemap output.\n\t */\n\tfromEquirectangular( equirectangular, renderTarget = null ) {\n\n\t\treturn this._fromTexture( equirectangular, renderTarget );\n\n\t}\n\n\t/**\n\t * Generates a PMREM from an cubemap texture, which can be either LDR\n\t * or HDR. The ideal input cube size is 256 x 256,\n\t * as this matches best with the 256 x 256 cubemap output.\n\t */\n\tfromCubemap( cubemap, renderTarget = null ) {\n\n\t\treturn this._fromTexture( cubemap, renderTarget );\n\n\t}\n\n\t/**\n\t * Pre-compiles the cubemap shader. You can get faster start-up by invoking this method during\n\t * your texture's network fetch for increased concurrency.\n\t */\n\tcompileCubemapShader() {\n\n\t\tif ( this._cubemapMaterial === null ) {\n\n\t\t\tthis._cubemapMaterial = _getCubemapMaterial();\n\t\t\tthis._compileMaterial( this._cubemapMaterial );\n\n\t\t}\n\n\t}\n\n\t/**\n\t * Pre-compiles the equirectangular shader. You can get faster start-up by invoking this method during\n\t * your texture's network fetch for increased concurrency.\n\t */\n\tcompileEquirectangularShader() {\n\n\t\tif ( this._equirectMaterial === null ) {\n\n\t\t\tthis._equirectMaterial = _getEquirectMaterial();\n\t\t\tthis._compileMaterial( this._equirectMaterial );\n\n\t\t}\n\n\t}\n\n\t/**\n\t * Disposes of the PMREMGenerator's internal memory. Note that PMREMGenerator is a static class,\n\t * so you should not need more than one PMREMGenerator object. If you do, calling dispose() on\n\t * one of them will cause any others to also become unusable.\n\t */\n\tdispose() {\n\n\t\tthis._dispose();\n\n\t\tif ( this._cubemapMaterial !== null ) this._cubemapMaterial.dispose();\n\t\tif ( this._equirectMaterial !== null ) this._equirectMaterial.dispose();\n\n\t}\n\n\t// private interface\n\n\t_setSize( cubeSize ) {\n\n\t\tthis._lodMax = Math.floor( Math.log2( cubeSize ) );\n\t\tthis._cubeSize = Math.pow( 2, this._lodMax );\n\n\t}\n\n\t_dispose() {\n\n\t\tthis._blurMaterial.dispose();\n\n\t\tif ( this._pingPongRenderTarget !== null ) this._pingPongRenderTarget.dispose();\n\n\t\tfor ( let i = 0; i < this._lodPlanes.length; i ++ ) {\n\n\t\t\tthis._lodPlanes[ i ].dispose();\n\n\t\t}\n\n\t}\n\n\t_cleanup( outputTarget ) {\n\n\t\tthis._renderer.setRenderTarget( _oldTarget );\n\t\toutputTarget.scissorTest = false;\n\t\t_setViewport( outputTarget, 0, 0, outputTarget.width, outputTarget.height );\n\n\t}\n\n\t_fromTexture( texture, renderTarget ) {\n\n\t\tif ( texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping ) {\n\n\t\t\tthis._setSize( texture.image.length === 0 ? 16 : ( texture.image[ 0 ].width || texture.image[ 0 ].image.width ) );\n\n\t\t} else { // Equirectangular\n\n\t\t\tthis._setSize( texture.image.width / 4 );\n\n\t\t}\n\n\t\t_oldTarget = this._renderer.getRenderTarget();\n\n\t\tconst cubeUVRenderTarget = renderTarget || this._allocateTargets();\n\t\tthis._textureToCubeUV( texture, cubeUVRenderTarget );\n\t\tthis._applyPMREM( cubeUVRenderTarget );\n\t\tthis._cleanup( cubeUVRenderTarget );\n\n\t\treturn cubeUVRenderTarget;\n\n\t}\n\n\t_allocateTargets() {\n\n\t\tconst width = 3 * Math.max( this._cubeSize, 16 * 7 );\n\t\tconst height = 4 * this._cubeSize - 32;\n\n\t\tconst params = {\n\t\t\tmagFilter: LinearFilter,\n\t\t\tminFilter: LinearFilter,\n\t\t\tgenerateMipmaps: false,\n\t\t\ttype: HalfFloatType,\n\t\t\tformat: RGBAFormat,\n\t\t\tencoding: LinearEncoding,\n\t\t\tdepthBuffer: false\n\t\t};\n\n\t\tconst cubeUVRenderTarget = _createRenderTarget( width, height, params );\n\n\t\tif ( this._pingPongRenderTarget === null || this._pingPongRenderTarget.width !== width ) {\n\n\t\t\tif ( this._pingPongRenderTarget !== null ) {\n\n\t\t\t\tthis._dispose();\n\n\t\t\t}\n\n\t\t\tthis._pingPongRenderTarget = _createRenderTarget( width, height, params );\n\n\t\t\tconst { _lodMax } = this;\n\t\t\t( { sizeLods: this._sizeLods, lodPlanes: this._lodPlanes, sigmas: this._sigmas } = _createPlanes( _lodMax ) );\n\n\t\t\tthis._blurMaterial = _getBlurShader( _lodMax, width, height );\n\n\t\t}\n\n\t\treturn cubeUVRenderTarget;\n\n\t}\n\n\t_compileMaterial( material ) {\n\n\t\tconst tmpMesh = new Mesh( this._lodPlanes[ 0 ], material );\n\t\tthis._renderer.compile( tmpMesh, _flatCamera );\n\n\t}\n\n\t_sceneToCubeUV( scene, near, far, cubeUVRenderTarget ) {\n\n\t\tconst fov = 90;\n\t\tconst aspect = 1;\n\t\tconst cubeCamera = new PerspectiveCamera( fov, aspect, near, far );\n\t\tconst upSign = [ 1, - 1, 1, 1, 1, 1 ];\n\t\tconst forwardSign = [ 1, 1, 1, - 1, - 1, - 1 ];\n\t\tconst renderer = this._renderer;\n\n\t\tconst originalAutoClear = renderer.autoClear;\n\t\tconst toneMapping = renderer.toneMapping;\n\t\trenderer.getClearColor( _clearColor );\n\n\t\trenderer.toneMapping = NoToneMapping;\n\t\trenderer.autoClear = false;\n\n\t\tconst backgroundMaterial = new MeshBasicMaterial( {\n\t\t\tname: 'PMREM.Background',\n\t\t\tside: BackSide,\n\t\t\tdepthWrite: false,\n\t\t\tdepthTest: false,\n\t\t} );\n\n\t\tconst backgroundBox = new Mesh( new BoxGeometry(), backgroundMaterial );\n\n\t\tlet useSolidColor = false;\n\t\tconst background = scene.background;\n\n\t\tif ( background ) {\n\n\t\t\tif ( background.isColor ) {\n\n\t\t\t\tbackgroundMaterial.color.copy( background );\n\t\t\t\tscene.background = null;\n\t\t\t\tuseSolidColor = true;\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tbackgroundMaterial.color.copy( _clearColor );\n\t\t\tuseSolidColor = true;\n\n\t\t}\n\n\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\tconst col = i % 3;\n\n\t\t\tif ( col === 0 ) {\n\n\t\t\t\tcubeCamera.up.set( 0, upSign[ i ], 0 );\n\t\t\t\tcubeCamera.lookAt( forwardSign[ i ], 0, 0 );\n\n\t\t\t} else if ( col === 1 ) {\n\n\t\t\t\tcubeCamera.up.set( 0, 0, upSign[ i ] );\n\t\t\t\tcubeCamera.lookAt( 0, forwardSign[ i ], 0 );\n\n\t\t\t} else {\n\n\t\t\t\tcubeCamera.up.set( 0, upSign[ i ], 0 );\n\t\t\t\tcubeCamera.lookAt( 0, 0, forwardSign[ i ] );\n\n\t\t\t}\n\n\t\t\tconst size = this._cubeSize;\n\n\t\t\t_setViewport( cubeUVRenderTarget, col * size, i > 2 ? size : 0, size, size );\n\n\t\t\trenderer.setRenderTarget( cubeUVRenderTarget );\n\n\t\t\tif ( useSolidColor ) {\n\n\t\t\t\trenderer.render( backgroundBox, cubeCamera );\n\n\t\t\t}\n\n\t\t\trenderer.render( scene, cubeCamera );\n\n\t\t}\n\n\t\tbackgroundBox.geometry.dispose();\n\t\tbackgroundBox.material.dispose();\n\n\t\trenderer.toneMapping = toneMapping;\n\t\trenderer.autoClear = originalAutoClear;\n\t\tscene.background = background;\n\n\t}\n\n\t_textureToCubeUV( texture, cubeUVRenderTarget ) {\n\n\t\tconst renderer = this._renderer;\n\n\t\tconst isCubeTexture = ( texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping );\n\n\t\tif ( isCubeTexture ) {\n\n\t\t\tif ( this._cubemapMaterial === null ) {\n\n\t\t\t\tthis._cubemapMaterial = _getCubemapMaterial();\n\n\t\t\t}\n\n\t\t\tthis._cubemapMaterial.uniforms.flipEnvMap.value = ( texture.isRenderTargetTexture === false ) ? - 1 : 1;\n\n\t\t} else {\n\n\t\t\tif ( this._equirectMaterial === null ) {\n\n\t\t\t\tthis._equirectMaterial = _getEquirectMaterial();\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst material = isCubeTexture ? this._cubemapMaterial : this._equirectMaterial;\n\t\tconst mesh = new Mesh( this._lodPlanes[ 0 ], material );\n\n\t\tconst uniforms = material.uniforms;\n\n\t\tuniforms[ 'envMap' ].value = texture;\n\n\t\tconst size = this._cubeSize;\n\n\t\t_setViewport( cubeUVRenderTarget, 0, 0, 3 * size, 2 * size );\n\n\t\trenderer.setRenderTarget( cubeUVRenderTarget );\n\t\trenderer.render( mesh, _flatCamera );\n\n\t}\n\n\t_applyPMREM( cubeUVRenderTarget ) {\n\n\t\tconst renderer = this._renderer;\n\t\tconst autoClear = renderer.autoClear;\n\t\trenderer.autoClear = false;\n\n\t\tfor ( let i = 1; i < this._lodPlanes.length; i ++ ) {\n\n\t\t\tconst sigma = Math.sqrt( this._sigmas[ i ] * this._sigmas[ i ] - this._sigmas[ i - 1 ] * this._sigmas[ i - 1 ] );\n\n\t\t\tconst poleAxis = _axisDirections[ ( i - 1 ) % _axisDirections.length ];\n\n\t\t\tthis._blur( cubeUVRenderTarget, i - 1, i, sigma, poleAxis );\n\n\t\t}\n\n\t\trenderer.autoClear = autoClear;\n\n\t}\n\n\t/**\n\t * This is a two-pass Gaussian blur for a cubemap. Normally this is done\n\t * vertically and horizontally, but this breaks down on a cube. Here we apply\n\t * the blur latitudinally (around the poles), and then longitudinally (towards\n\t * the poles) to approximate the orthogonally-separable blur. It is least\n\t * accurate at the poles, but still does a decent job.\n\t */\n\t_blur( cubeUVRenderTarget, lodIn, lodOut, sigma, poleAxis ) {\n\n\t\tconst pingPongRenderTarget = this._pingPongRenderTarget;\n\n\t\tthis._halfBlur(\n\t\t\tcubeUVRenderTarget,\n\t\t\tpingPongRenderTarget,\n\t\t\tlodIn,\n\t\t\tlodOut,\n\t\t\tsigma,\n\t\t\t'latitudinal',\n\t\t\tpoleAxis );\n\n\t\tthis._halfBlur(\n\t\t\tpingPongRenderTarget,\n\t\t\tcubeUVRenderTarget,\n\t\t\tlodOut,\n\t\t\tlodOut,\n\t\t\tsigma,\n\t\t\t'longitudinal',\n\t\t\tpoleAxis );\n\n\t}\n\n\t_halfBlur( targetIn, targetOut, lodIn, lodOut, sigmaRadians, direction, poleAxis ) {\n\n\t\tconst renderer = this._renderer;\n\t\tconst blurMaterial = this._blurMaterial;\n\n\t\tif ( direction !== 'latitudinal' && direction !== 'longitudinal' ) {\n\n\t\t\tconsole.error(\n\t\t\t\t'blur direction must be either latitudinal or longitudinal!' );\n\n\t\t}\n\n\t\t// Number of standard deviations at which to cut off the discrete approximation.\n\t\tconst STANDARD_DEVIATIONS = 3;\n\n\t\tconst blurMesh = new Mesh( this._lodPlanes[ lodOut ], blurMaterial );\n\t\tconst blurUniforms = blurMaterial.uniforms;\n\n\t\tconst pixels = this._sizeLods[ lodIn ] - 1;\n\t\tconst radiansPerPixel = isFinite( sigmaRadians ) ? Math.PI / ( 2 * pixels ) : 2 * Math.PI / ( 2 * MAX_SAMPLES - 1 );\n\t\tconst sigmaPixels = sigmaRadians / radiansPerPixel;\n\t\tconst samples = isFinite( sigmaRadians ) ? 1 + Math.floor( STANDARD_DEVIATIONS * sigmaPixels ) : MAX_SAMPLES;\n\n\t\tif ( samples > MAX_SAMPLES ) {\n\n\t\t\tconsole.warn( `sigmaRadians, ${\n\t\t\t\tsigmaRadians}, is too large and will clip, as it requested ${\n\t\t\t\tsamples} samples when the maximum is set to ${MAX_SAMPLES}` );\n\n\t\t}\n\n\t\tconst weights = [];\n\t\tlet sum = 0;\n\n\t\tfor ( let i = 0; i < MAX_SAMPLES; ++ i ) {\n\n\t\t\tconst x = i / sigmaPixels;\n\t\t\tconst weight = Math.exp( - x * x / 2 );\n\t\t\tweights.push( weight );\n\n\t\t\tif ( i === 0 ) {\n\n\t\t\t\tsum += weight;\n\n\t\t\t} else if ( i < samples ) {\n\n\t\t\t\tsum += 2 * weight;\n\n\t\t\t}\n\n\t\t}\n\n\t\tfor ( let i = 0; i < weights.length; i ++ ) {\n\n\t\t\tweights[ i ] = weights[ i ] / sum;\n\n\t\t}\n\n\t\tblurUniforms[ 'envMap' ].value = targetIn.texture;\n\t\tblurUniforms[ 'samples' ].value = samples;\n\t\tblurUniforms[ 'weights' ].value = weights;\n\t\tblurUniforms[ 'latitudinal' ].value = direction === 'latitudinal';\n\n\t\tif ( poleAxis ) {\n\n\t\t\tblurUniforms[ 'poleAxis' ].value = poleAxis;\n\n\t\t}\n\n\t\tconst { _lodMax } = this;\n\t\tblurUniforms[ 'dTheta' ].value = radiansPerPixel;\n\t\tblurUniforms[ 'mipInt' ].value = _lodMax - lodIn;\n\n\t\tconst outputSize = this._sizeLods[ lodOut ];\n\t\tconst x = 3 * outputSize * ( lodOut > _lodMax - LOD_MIN ? lodOut - _lodMax + LOD_MIN : 0 );\n\t\tconst y = 4 * ( this._cubeSize - outputSize );\n\n\t\t_setViewport( targetOut, x, y, 3 * outputSize, 2 * outputSize );\n\t\trenderer.setRenderTarget( targetOut );\n\t\trenderer.render( blurMesh, _flatCamera );\n\n\t}\n\n}\n\n\n\nfunction _createPlanes( lodMax ) {\n\n\tconst lodPlanes = [];\n\tconst sizeLods = [];\n\tconst sigmas = [];\n\n\tlet lod = lodMax;\n\n\tconst totalLods = lodMax - LOD_MIN + 1 + EXTRA_LOD_SIGMA.length;\n\n\tfor ( let i = 0; i < totalLods; i ++ ) {\n\n\t\tconst sizeLod = Math.pow( 2, lod );\n\t\tsizeLods.push( sizeLod );\n\t\tlet sigma = 1.0 / sizeLod;\n\n\t\tif ( i > lodMax - LOD_MIN ) {\n\n\t\t\tsigma = EXTRA_LOD_SIGMA[ i - lodMax + LOD_MIN - 1 ];\n\n\t\t} else if ( i === 0 ) {\n\n\t\t\tsigma = 0;\n\n\t\t}\n\n\t\tsigmas.push( sigma );\n\n\t\tconst texelSize = 1.0 / ( sizeLod - 1 );\n\t\tconst min = - texelSize / 2;\n\t\tconst max = 1 + texelSize / 2;\n\t\tconst uv1 = [ min, min, max, min, max, max, min, min, max, max, min, max ];\n\n\t\tconst cubeFaces = 6;\n\t\tconst vertices = 6;\n\t\tconst positionSize = 3;\n\t\tconst uvSize = 2;\n\t\tconst faceIndexSize = 1;\n\n\t\tconst position = new Float32Array( positionSize * vertices * cubeFaces );\n\t\tconst uv = new Float32Array( uvSize * vertices * cubeFaces );\n\t\tconst faceIndex = new Float32Array( faceIndexSize * vertices * cubeFaces );\n\n\t\tfor ( let face = 0; face < cubeFaces; face ++ ) {\n\n\t\t\tconst x = ( face % 3 ) * 2 / 3 - 1;\n\t\t\tconst y = face > 2 ? 0 : - 1;\n\t\t\tconst coordinates = [\n\t\t\t\tx, y, 0,\n\t\t\t\tx + 2 / 3, y, 0,\n\t\t\t\tx + 2 / 3, y + 1, 0,\n\t\t\t\tx, y, 0,\n\t\t\t\tx + 2 / 3, y + 1, 0,\n\t\t\t\tx, y + 1, 0\n\t\t\t];\n\t\t\tposition.set( coordinates, positionSize * vertices * face );\n\t\t\tuv.set( uv1, uvSize * vertices * face );\n\t\t\tconst fill = [ face, face, face, face, face, face ];\n\t\t\tfaceIndex.set( fill, faceIndexSize * vertices * face );\n\n\t\t}\n\n\t\tconst planes = new BufferGeometry();\n\t\tplanes.setAttribute( 'position', new BufferAttribute( position, positionSize ) );\n\t\tplanes.setAttribute( 'uv', new BufferAttribute( uv, uvSize ) );\n\t\tplanes.setAttribute( 'faceIndex', new BufferAttribute( faceIndex, faceIndexSize ) );\n\t\tlodPlanes.push( planes );\n\n\t\tif ( lod > LOD_MIN ) {\n\n\t\t\tlod --;\n\n\t\t}\n\n\t}\n\n\treturn { lodPlanes, sizeLods, sigmas };\n\n}\n\nfunction _createRenderTarget( width, height, params ) {\n\n\tconst cubeUVRenderTarget = new WebGLRenderTarget( width, height, params );\n\tcubeUVRenderTarget.texture.mapping = CubeUVReflectionMapping;\n\tcubeUVRenderTarget.texture.name = 'PMREM.cubeUv';\n\tcubeUVRenderTarget.scissorTest = true;\n\treturn cubeUVRenderTarget;\n\n}\n\nfunction _setViewport( target, x, y, width, height ) {\n\n\ttarget.viewport.set( x, y, width, height );\n\ttarget.scissor.set( x, y, width, height );\n\n}\n\nfunction _getBlurShader( lodMax, width, height ) {\n\n\tconst weights = new Float32Array( MAX_SAMPLES );\n\tconst poleAxis = new Vector3( 0, 1, 0 );\n\tconst shaderMaterial = new ShaderMaterial( {\n\n\t\tname: 'SphericalGaussianBlur',\n\n\t\tdefines: {\n\t\t\t'n': MAX_SAMPLES,\n\t\t\t'CUBEUV_TEXEL_WIDTH': 1.0 / width,\n\t\t\t'CUBEUV_TEXEL_HEIGHT': 1.0 / height,\n\t\t\t'CUBEUV_MAX_MIP': `${lodMax}.0`,\n\t\t},\n\n\t\tuniforms: {\n\t\t\t'envMap': { value: null },\n\t\t\t'samples': { value: 1 },\n\t\t\t'weights': { value: weights },\n\t\t\t'latitudinal': { value: false },\n\t\t\t'dTheta': { value: 0 },\n\t\t\t'mipInt': { value: 0 },\n\t\t\t'poleAxis': { value: poleAxis }\n\t\t},\n\n\t\tvertexShader: _getCommonVertexShader(),\n\n\t\tfragmentShader: /* glsl */`\n\n\t\t\tprecision mediump float;\n\t\t\tprecision mediump int;\n\n\t\t\tvarying vec3 vOutputDirection;\n\n\t\t\tuniform sampler2D envMap;\n\t\t\tuniform int samples;\n\t\t\tuniform float weights[ n ];\n\t\t\tuniform bool latitudinal;\n\t\t\tuniform float dTheta;\n\t\t\tuniform float mipInt;\n\t\t\tuniform vec3 poleAxis;\n\n\t\t\t#define ENVMAP_TYPE_CUBE_UV\n\t\t\t#include <cube_uv_reflection_fragment>\n\n\t\t\tvec3 getSample( float theta, vec3 axis ) {\n\n\t\t\t\tfloat cosTheta = cos( theta );\n\t\t\t\t// Rodrigues' axis-angle rotation\n\t\t\t\tvec3 sampleDirection = vOutputDirection * cosTheta\n\t\t\t\t\t+ cross( axis, vOutputDirection ) * sin( theta )\n\t\t\t\t\t+ axis * dot( axis, vOutputDirection ) * ( 1.0 - cosTheta );\n\n\t\t\t\treturn bilinearCubeUV( envMap, sampleDirection, mipInt );\n\n\t\t\t}\n\n\t\t\tvoid main() {\n\n\t\t\t\tvec3 axis = latitudinal ? poleAxis : cross( poleAxis, vOutputDirection );\n\n\t\t\t\tif ( all( equal( axis, vec3( 0.0 ) ) ) ) {\n\n\t\t\t\t\taxis = vec3( vOutputDirection.z, 0.0, - vOutputDirection.x );\n\n\t\t\t\t}\n\n\t\t\t\taxis = normalize( axis );\n\n\t\t\t\tgl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );\n\t\t\t\tgl_FragColor.rgb += weights[ 0 ] * getSample( 0.0, axis );\n\n\t\t\t\tfor ( int i = 1; i < n; i++ ) {\n\n\t\t\t\t\tif ( i >= samples ) {\n\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tfloat theta = dTheta * float( i );\n\t\t\t\t\tgl_FragColor.rgb += weights[ i ] * getSample( -1.0 * theta, axis );\n\t\t\t\t\tgl_FragColor.rgb += weights[ i ] * getSample( theta, axis );\n\n\t\t\t\t}\n\n\t\t\t}\n\t\t`,\n\n\t\tblending: NoBlending,\n\t\tdepthTest: false,\n\t\tdepthWrite: false\n\n\t} );\n\n\treturn shaderMaterial;\n\n}\n\nfunction _getEquirectMaterial() {\n\n\treturn new ShaderMaterial( {\n\n\t\tname: 'EquirectangularToCubeUV',\n\n\t\tuniforms: {\n\t\t\t'envMap': { value: null }\n\t\t},\n\n\t\tvertexShader: _getCommonVertexShader(),\n\n\t\tfragmentShader: /* glsl */`\n\n\t\t\tprecision mediump float;\n\t\t\tprecision mediump int;\n\n\t\t\tvarying vec3 vOutputDirection;\n\n\t\t\tuniform sampler2D envMap;\n\n\t\t\t#include <common>\n\n\t\t\tvoid main() {\n\n\t\t\t\tvec3 outputDirection = normalize( vOutputDirection );\n\t\t\t\tvec2 uv = equirectUv( outputDirection );\n\n\t\t\t\tgl_FragColor = vec4( texture2D ( envMap, uv ).rgb, 1.0 );\n\n\t\t\t}\n\t\t`,\n\n\t\tblending: NoBlending,\n\t\tdepthTest: false,\n\t\tdepthWrite: false\n\n\t} );\n\n}\n\nfunction _getCubemapMaterial() {\n\n\treturn new ShaderMaterial( {\n\n\t\tname: 'CubemapToCubeUV',\n\n\t\tuniforms: {\n\t\t\t'envMap': { value: null },\n\t\t\t'flipEnvMap': { value: - 1 }\n\t\t},\n\n\t\tvertexShader: _getCommonVertexShader(),\n\n\t\tfragmentShader: /* glsl */`\n\n\t\t\tprecision mediump float;\n\t\t\tprecision mediump int;\n\n\t\t\tuniform float flipEnvMap;\n\n\t\t\tvarying vec3 vOutputDirection;\n\n\t\t\tuniform samplerCube envMap;\n\n\t\t\tvoid main() {\n\n\t\t\t\tgl_FragColor = textureCube( envMap, vec3( flipEnvMap * vOutputDirection.x, vOutputDirection.yz ) );\n\n\t\t\t}\n\t\t`,\n\n\t\tblending: NoBlending,\n\t\tdepthTest: false,\n\t\tdepthWrite: false\n\n\t} );\n\n}\n\nfunction _getCommonVertexShader() {\n\n\treturn /* glsl */`\n\n\t\tprecision mediump float;\n\t\tprecision mediump int;\n\n\t\tattribute float faceIndex;\n\n\t\tvarying vec3 vOutputDirection;\n\n\t\t// RH coordinate system; PMREM face-indexing convention\n\t\tvec3 getDirection( vec2 uv, float face ) {\n\n\t\t\tuv = 2.0 * uv - 1.0;\n\n\t\t\tvec3 direction = vec3( uv, 1.0 );\n\n\t\t\tif ( face == 0.0 ) {\n\n\t\t\t\tdirection = direction.zyx; // ( 1, v, u ) pos x\n\n\t\t\t} else if ( face == 1.0 ) {\n\n\t\t\t\tdirection = direction.xzy;\n\t\t\t\tdirection.xz *= -1.0; // ( -u, 1, -v ) pos y\n\n\t\t\t} else if ( face == 2.0 ) {\n\n\t\t\t\tdirection.x *= -1.0; // ( -u, v, 1 ) pos z\n\n\t\t\t} else if ( face == 3.0 ) {\n\n\t\t\t\tdirection = direction.zyx;\n\t\t\t\tdirection.xz *= -1.0; // ( -1, v, -u ) neg x\n\n\t\t\t} else if ( face == 4.0 ) {\n\n\t\t\t\tdirection = direction.xzy;\n\t\t\t\tdirection.xy *= -1.0; // ( -u, -1, v ) neg y\n\n\t\t\t} else if ( face == 5.0 ) {\n\n\t\t\t\tdirection.z *= -1.0; // ( u, v, -1 ) neg z\n\n\t\t\t}\n\n\t\t\treturn direction;\n\n\t\t}\n\n\t\tvoid main() {\n\n\t\t\tvOutputDirection = getDirection( uv, faceIndex );\n\t\t\tgl_Position = vec4( position, 1.0 );\n\n\t\t}\n\t`;\n\n}\n\nfunction WebGLCubeUVMaps( renderer ) {\n\n\tlet cubeUVmaps = new WeakMap();\n\n\tlet pmremGenerator = null;\n\n\tfunction get( texture ) {\n\n\t\tif ( texture && texture.isTexture ) {\n\n\t\t\tconst mapping = texture.mapping;\n\n\t\t\tconst isEquirectMap = ( mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping );\n\t\t\tconst isCubeMap = ( mapping === CubeReflectionMapping || mapping === CubeRefractionMapping );\n\n\t\t\t// equirect/cube map to cubeUV conversion\n\n\t\t\tif ( isEquirectMap || isCubeMap ) {\n\n\t\t\t\tif ( texture.isRenderTargetTexture && texture.needsPMREMUpdate === true ) {\n\n\t\t\t\t\ttexture.needsPMREMUpdate = false;\n\n\t\t\t\t\tlet renderTarget = cubeUVmaps.get( texture );\n\n\t\t\t\t\tif ( pmremGenerator === null ) pmremGenerator = new PMREMGenerator( renderer );\n\n\t\t\t\t\trenderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular( texture, renderTarget ) : pmremGenerator.fromCubemap( texture, renderTarget );\n\t\t\t\t\tcubeUVmaps.set( texture, renderTarget );\n\n\t\t\t\t\treturn renderTarget.texture;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( cubeUVmaps.has( texture ) ) {\n\n\t\t\t\t\t\treturn cubeUVmaps.get( texture ).texture;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tconst image = texture.image;\n\n\t\t\t\t\t\tif ( ( isEquirectMap && image && image.height > 0 ) || ( isCubeMap && image && isCubeTextureComplete( image ) ) ) {\n\n\t\t\t\t\t\t\tif ( pmremGenerator === null ) pmremGenerator = new PMREMGenerator( renderer );\n\n\t\t\t\t\t\t\tconst renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular( texture ) : pmremGenerator.fromCubemap( texture );\n\t\t\t\t\t\t\tcubeUVmaps.set( texture, renderTarget );\n\n\t\t\t\t\t\t\ttexture.addEventListener( 'dispose', onTextureDispose );\n\n\t\t\t\t\t\t\treturn renderTarget.texture;\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t// image not yet ready. try the conversion next frame\n\n\t\t\t\t\t\t\treturn null;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn texture;\n\n\t}\n\n\tfunction isCubeTextureComplete( image ) {\n\n\t\tlet count = 0;\n\t\tconst length = 6;\n\n\t\tfor ( let i = 0; i < length; i ++ ) {\n\n\t\t\tif ( image[ i ] !== undefined ) count ++;\n\n\t\t}\n\n\t\treturn count === length;\n\n\n\t}\n\n\tfunction onTextureDispose( event ) {\n\n\t\tconst texture = event.target;\n\n\t\ttexture.removeEventListener( 'dispose', onTextureDispose );\n\n\t\tconst cubemapUV = cubeUVmaps.get( texture );\n\n\t\tif ( cubemapUV !== undefined ) {\n\n\t\t\tcubeUVmaps.delete( texture );\n\t\t\tcubemapUV.dispose();\n\n\t\t}\n\n\t}\n\n\tfunction dispose() {\n\n\t\tcubeUVmaps = new WeakMap();\n\n\t\tif ( pmremGenerator !== null ) {\n\n\t\t\tpmremGenerator.dispose();\n\t\t\tpmremGenerator = null;\n\n\t\t}\n\n\t}\n\n\treturn {\n\t\tget: get,\n\t\tdispose: dispose\n\t};\n\n}\n\nfunction WebGLExtensions( gl ) {\n\n\tconst extensions = {};\n\n\tfunction getExtension( name ) {\n\n\t\tif ( extensions[ name ] !== undefined ) {\n\n\t\t\treturn extensions[ name ];\n\n\t\t}\n\n\t\tlet extension;\n\n\t\tswitch ( name ) {\n\n\t\t\tcase 'WEBGL_depth_texture':\n\t\t\t\textension = gl.getExtension( 'WEBGL_depth_texture' ) || gl.getExtension( 'MOZ_WEBGL_depth_texture' ) || gl.getExtension( 'WEBKIT_WEBGL_depth_texture' );\n\t\t\t\tbreak;\n\n\t\t\tcase 'EXT_texture_filter_anisotropic':\n\t\t\t\textension = gl.getExtension( 'EXT_texture_filter_anisotropic' ) || gl.getExtension( 'MOZ_EXT_texture_filter_anisotropic' ) || gl.getExtension( 'WEBKIT_EXT_texture_filter_anisotropic' );\n\t\t\t\tbreak;\n\n\t\t\tcase 'WEBGL_compressed_texture_s3tc':\n\t\t\t\textension = gl.getExtension( 'WEBGL_compressed_texture_s3tc' ) || gl.getExtension( 'MOZ_WEBGL_compressed_texture_s3tc' ) || gl.getExtension( 'WEBKIT_WEBGL_compressed_texture_s3tc' );\n\t\t\t\tbreak;\n\n\t\t\tcase 'WEBGL_compressed_texture_pvrtc':\n\t\t\t\textension = gl.getExtension( 'WEBGL_compressed_texture_pvrtc' ) || gl.getExtension( 'WEBKIT_WEBGL_compressed_texture_pvrtc' );\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\textension = gl.getExtension( name );\n\n\t\t}\n\n\t\textensions[ name ] = extension;\n\n\t\treturn extension;\n\n\t}\n\n\treturn {\n\n\t\thas: function ( name ) {\n\n\t\t\treturn getExtension( name ) !== null;\n\n\t\t},\n\n\t\tinit: function ( capabilities ) {\n\n\t\t\tif ( capabilities.isWebGL2 ) {\n\n\t\t\t\tgetExtension( 'EXT_color_buffer_float' );\n\n\t\t\t} else {\n\n\t\t\t\tgetExtension( 'WEBGL_depth_texture' );\n\t\t\t\tgetExtension( 'OES_texture_float' );\n\t\t\t\tgetExtension( 'OES_texture_half_float' );\n\t\t\t\tgetExtension( 'OES_texture_half_float_linear' );\n\t\t\t\tgetExtension( 'OES_standard_derivatives' );\n\t\t\t\tgetExtension( 'OES_element_index_uint' );\n\t\t\t\tgetExtension( 'OES_vertex_array_object' );\n\t\t\t\tgetExtension( 'ANGLE_instanced_arrays' );\n\n\t\t\t}\n\n\t\t\tgetExtension( 'OES_texture_float_linear' );\n\t\t\tgetExtension( 'EXT_color_buffer_half_float' );\n\t\t\tgetExtension( 'WEBGL_multisampled_render_to_texture' );\n\n\t\t},\n\n\t\tget: function ( name ) {\n\n\t\t\tconst extension = getExtension( name );\n\n\t\t\tif ( extension === null ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: ' + name + ' extension not supported.' );\n\n\t\t\t}\n\n\t\t\treturn extension;\n\n\t\t}\n\n\t};\n\n}\n\nfunction WebGLGeometries( gl, attributes, info, bindingStates ) {\n\n\tconst geometries = {};\n\tconst wireframeAttributes = new WeakMap();\n\n\tfunction onGeometryDispose( event ) {\n\n\t\tconst geometry = event.target;\n\n\t\tif ( geometry.index !== null ) {\n\n\t\t\tattributes.remove( geometry.index );\n\n\t\t}\n\n\t\tfor ( const name in geometry.attributes ) {\n\n\t\t\tattributes.remove( geometry.attributes[ name ] );\n\n\t\t}\n\n\t\tgeometry.removeEventListener( 'dispose', onGeometryDispose );\n\n\t\tdelete geometries[ geometry.id ];\n\n\t\tconst attribute = wireframeAttributes.get( geometry );\n\n\t\tif ( attribute ) {\n\n\t\t\tattributes.remove( attribute );\n\t\t\twireframeAttributes.delete( geometry );\n\n\t\t}\n\n\t\tbindingStates.releaseStatesOfGeometry( geometry );\n\n\t\tif ( geometry.isInstancedBufferGeometry === true ) {\n\n\t\t\tdelete geometry._maxInstanceCount;\n\n\t\t}\n\n\t\t//\n\n\t\tinfo.memory.geometries --;\n\n\t}\n\n\tfunction get( object, geometry ) {\n\n\t\tif ( geometries[ geometry.id ] === true ) return geometry;\n\n\t\tgeometry.addEventListener( 'dispose', onGeometryDispose );\n\n\t\tgeometries[ geometry.id ] = true;\n\n\t\tinfo.memory.geometries ++;\n\n\t\treturn geometry;\n\n\t}\n\n\tfunction update( geometry ) {\n\n\t\tconst geometryAttributes = geometry.attributes;\n\n\t\t// Updating index buffer in VAO now. See WebGLBindingStates.\n\n\t\tfor ( const name in geometryAttributes ) {\n\n\t\t\tattributes.update( geometryAttributes[ name ], 34962 );\n\n\t\t}\n\n\t\t// morph targets\n\n\t\tconst morphAttributes = geometry.morphAttributes;\n\n\t\tfor ( const name in morphAttributes ) {\n\n\t\t\tconst array = morphAttributes[ name ];\n\n\t\t\tfor ( let i = 0, l = array.length; i < l; i ++ ) {\n\n\t\t\t\tattributes.update( array[ i ], 34962 );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tfunction updateWireframeAttribute( geometry ) {\n\n\t\tconst indices = [];\n\n\t\tconst geometryIndex = geometry.index;\n\t\tconst geometryPosition = geometry.attributes.position;\n\t\tlet version = 0;\n\n\t\tif ( geometryIndex !== null ) {\n\n\t\t\tconst array = geometryIndex.array;\n\t\t\tversion = geometryIndex.version;\n\n\t\t\tfor ( let i = 0, l = array.length; i < l; i += 3 ) {\n\n\t\t\t\tconst a = array[ i + 0 ];\n\t\t\t\tconst b = array[ i + 1 ];\n\t\t\t\tconst c = array[ i + 2 ];\n\n\t\t\t\tindices.push( a, b, b, c, c, a );\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconst array = geometryPosition.array;\n\t\t\tversion = geometryPosition.version;\n\n\t\t\tfor ( let i = 0, l = ( array.length / 3 ) - 1; i < l; i += 3 ) {\n\n\t\t\t\tconst a = i + 0;\n\t\t\t\tconst b = i + 1;\n\t\t\t\tconst c = i + 2;\n\n\t\t\t\tindices.push( a, b, b, c, c, a );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst attribute = new ( arrayNeedsUint32( indices ) ? Uint32BufferAttribute : Uint16BufferAttribute )( indices, 1 );\n\t\tattribute.version = version;\n\n\t\t// Updating index buffer in VAO now. See WebGLBindingStates\n\n\t\t//\n\n\t\tconst previousAttribute = wireframeAttributes.get( geometry );\n\n\t\tif ( previousAttribute ) attributes.remove( previousAttribute );\n\n\t\t//\n\n\t\twireframeAttributes.set( geometry, attribute );\n\n\t}\n\n\tfunction getWireframeAttribute( geometry ) {\n\n\t\tconst currentAttribute = wireframeAttributes.get( geometry );\n\n\t\tif ( currentAttribute ) {\n\n\t\t\tconst geometryIndex = geometry.index;\n\n\t\t\tif ( geometryIndex !== null ) {\n\n\t\t\t\t// if the attribute is obsolete, create a new one\n\n\t\t\t\tif ( currentAttribute.version < geometryIndex.version ) {\n\n\t\t\t\t\tupdateWireframeAttribute( geometry );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tupdateWireframeAttribute( geometry );\n\n\t\t}\n\n\t\treturn wireframeAttributes.get( geometry );\n\n\t}\n\n\treturn {\n\n\t\tget: get,\n\t\tupdate: update,\n\n\t\tgetWireframeAttribute: getWireframeAttribute\n\n\t};\n\n}\n\nfunction WebGLIndexedBufferRenderer( gl, extensions, info, capabilities ) {\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\n\tlet mode;\n\n\tfunction setMode( value ) {\n\n\t\tmode = value;\n\n\t}\n\n\tlet type, bytesPerElement;\n\n\tfunction setIndex( value ) {\n\n\t\ttype = value.type;\n\t\tbytesPerElement = value.bytesPerElement;\n\n\t}\n\n\tfunction render( start, count ) {\n\n\t\tgl.drawElements( mode, count, type, start * bytesPerElement );\n\n\t\tinfo.update( count, mode, 1 );\n\n\t}\n\n\tfunction renderInstances( start, count, primcount ) {\n\n\t\tif ( primcount === 0 ) return;\n\n\t\tlet extension, methodName;\n\n\t\tif ( isWebGL2 ) {\n\n\t\t\textension = gl;\n\t\t\tmethodName = 'drawElementsInstanced';\n\n\t\t} else {\n\n\t\t\textension = extensions.get( 'ANGLE_instanced_arrays' );\n\t\t\tmethodName = 'drawElementsInstancedANGLE';\n\n\t\t\tif ( extension === null ) {\n\n\t\t\t\tconsole.error( 'THREE.WebGLIndexedBufferRenderer: using THREE.InstancedBufferGeometry but hardware does not support extension ANGLE_instanced_arrays.' );\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t}\n\n\t\textension[ methodName ]( mode, count, type, start * bytesPerElement, primcount );\n\n\t\tinfo.update( count, mode, primcount );\n\n\t}\n\n\t//\n\n\tthis.setMode = setMode;\n\tthis.setIndex = setIndex;\n\tthis.render = render;\n\tthis.renderInstances = renderInstances;\n\n}\n\nfunction WebGLInfo( gl ) {\n\n\tconst memory = {\n\t\tgeometries: 0,\n\t\ttextures: 0\n\t};\n\n\tconst render = {\n\t\tframe: 0,\n\t\tcalls: 0,\n\t\ttriangles: 0,\n\t\tpoints: 0,\n\t\tlines: 0\n\t};\n\n\tfunction update( count, mode, instanceCount ) {\n\n\t\trender.calls ++;\n\n\t\tswitch ( mode ) {\n\n\t\t\tcase 4:\n\t\t\t\trender.triangles += instanceCount * ( count / 3 );\n\t\t\t\tbreak;\n\n\t\t\tcase 1:\n\t\t\t\trender.lines += instanceCount * ( count / 2 );\n\t\t\t\tbreak;\n\n\t\t\tcase 3:\n\t\t\t\trender.lines += instanceCount * ( count - 1 );\n\t\t\t\tbreak;\n\n\t\t\tcase 2:\n\t\t\t\trender.lines += instanceCount * count;\n\t\t\t\tbreak;\n\n\t\t\tcase 0:\n\t\t\t\trender.points += instanceCount * count;\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tconsole.error( 'THREE.WebGLInfo: Unknown draw mode:', mode );\n\t\t\t\tbreak;\n\n\t\t}\n\n\t}\n\n\tfunction reset() {\n\n\t\trender.frame ++;\n\t\trender.calls = 0;\n\t\trender.triangles = 0;\n\t\trender.points = 0;\n\t\trender.lines = 0;\n\n\t}\n\n\treturn {\n\t\tmemory: memory,\n\t\trender: render,\n\t\tprograms: null,\n\t\tautoReset: true,\n\t\treset: reset,\n\t\tupdate: update\n\t};\n\n}\n\nfunction numericalSort( a, b ) {\n\n\treturn a[ 0 ] - b[ 0 ];\n\n}\n\nfunction absNumericalSort( a, b ) {\n\n\treturn Math.abs( b[ 1 ] ) - Math.abs( a[ 1 ] );\n\n}\n\nfunction denormalize( morph, attribute ) {\n\n\tlet denominator = 1;\n\tconst array = attribute.isInterleavedBufferAttribute ? attribute.data.array : attribute.array;\n\n\tif ( array instanceof Int8Array ) denominator = 127;\n\telse if ( array instanceof Int16Array ) denominator = 32767;\n\telse if ( array instanceof Int32Array ) denominator = 2147483647;\n\telse console.error( 'THREE.WebGLMorphtargets: Unsupported morph attribute data type: ', array );\n\n\tmorph.divideScalar( denominator );\n\n}\n\nfunction WebGLMorphtargets( gl, capabilities, textures ) {\n\n\tconst influencesList = {};\n\tconst morphInfluences = new Float32Array( 8 );\n\tconst morphTextures = new WeakMap();\n\tconst morph = new Vector4();\n\n\tconst workInfluences = [];\n\n\tfor ( let i = 0; i < 8; i ++ ) {\n\n\t\tworkInfluences[ i ] = [ i, 0 ];\n\n\t}\n\n\tfunction update( object, geometry, material, program ) {\n\n\t\tconst objectInfluences = object.morphTargetInfluences;\n\n\t\tif ( capabilities.isWebGL2 === true ) {\n\n\t\t\t// instead of using attributes, the WebGL 2 code path encodes morph targets\n\t\t\t// into an array of data textures. Each layer represents a single morph target.\n\n\t\t\tconst morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;\n\t\t\tconst morphTargetsCount = ( morphAttribute !== undefined ) ? morphAttribute.length : 0;\n\n\t\t\tlet entry = morphTextures.get( geometry );\n\n\t\t\tif ( entry === undefined || entry.count !== morphTargetsCount ) {\n\n\t\t\t\tif ( entry !== undefined ) entry.texture.dispose();\n\n\t\t\t\tconst hasMorphPosition = geometry.morphAttributes.position !== undefined;\n\t\t\t\tconst hasMorphNormals = geometry.morphAttributes.normal !== undefined;\n\t\t\t\tconst hasMorphColors = geometry.morphAttributes.color !== undefined;\n\n\t\t\t\tconst morphTargets = geometry.morphAttributes.position || [];\n\t\t\t\tconst morphNormals = geometry.morphAttributes.normal || [];\n\t\t\t\tconst morphColors = geometry.morphAttributes.color || [];\n\n\t\t\t\tlet vertexDataCount = 0;\n\n\t\t\t\tif ( hasMorphPosition === true ) vertexDataCount = 1;\n\t\t\t\tif ( hasMorphNormals === true ) vertexDataCount = 2;\n\t\t\t\tif ( hasMorphColors === true ) vertexDataCount = 3;\n\n\t\t\t\tlet width = geometry.attributes.position.count * vertexDataCount;\n\t\t\t\tlet height = 1;\n\n\t\t\t\tif ( width > capabilities.maxTextureSize ) {\n\n\t\t\t\t\theight = Math.ceil( width / capabilities.maxTextureSize );\n\t\t\t\t\twidth = capabilities.maxTextureSize;\n\n\t\t\t\t}\n\n\t\t\t\tconst buffer = new Float32Array( width * height * 4 * morphTargetsCount );\n\n\t\t\t\tconst texture = new DataArrayTexture( buffer, width, height, morphTargetsCount );\n\t\t\t\ttexture.format = RGBAFormat; // using RGBA since RGB might be emulated (and is thus slower)\n\t\t\t\ttexture.type = FloatType;\n\t\t\t\ttexture.needsUpdate = true;\n\n\t\t\t\t// fill buffer\n\n\t\t\t\tconst vertexDataStride = vertexDataCount * 4;\n\n\t\t\t\tfor ( let i = 0; i < morphTargetsCount; i ++ ) {\n\n\t\t\t\t\tconst morphTarget = morphTargets[ i ];\n\t\t\t\t\tconst morphNormal = morphNormals[ i ];\n\t\t\t\t\tconst morphColor = morphColors[ i ];\n\n\t\t\t\t\tconst offset = width * height * 4 * i;\n\n\t\t\t\t\tfor ( let j = 0; j < morphTarget.count; j ++ ) {\n\n\t\t\t\t\t\tconst stride = j * vertexDataStride;\n\n\t\t\t\t\t\tif ( hasMorphPosition === true ) {\n\n\t\t\t\t\t\t\tmorph.fromBufferAttribute( morphTarget, j );\n\n\t\t\t\t\t\t\tif ( morphTarget.normalized === true ) denormalize( morph, morphTarget );\n\n\t\t\t\t\t\t\tbuffer[ offset + stride + 0 ] = morph.x;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 1 ] = morph.y;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 2 ] = morph.z;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 3 ] = 0;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ( hasMorphNormals === true ) {\n\n\t\t\t\t\t\t\tmorph.fromBufferAttribute( morphNormal, j );\n\n\t\t\t\t\t\t\tif ( morphNormal.normalized === true ) denormalize( morph, morphNormal );\n\n\t\t\t\t\t\t\tbuffer[ offset + stride + 4 ] = morph.x;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 5 ] = morph.y;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 6 ] = morph.z;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 7 ] = 0;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ( hasMorphColors === true ) {\n\n\t\t\t\t\t\t\tmorph.fromBufferAttribute( morphColor, j );\n\n\t\t\t\t\t\t\tif ( morphColor.normalized === true ) denormalize( morph, morphNormal );\n\n\t\t\t\t\t\t\tbuffer[ offset + stride + 8 ] = morph.x;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 9 ] = morph.y;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 10 ] = morph.z;\n\t\t\t\t\t\t\tbuffer[ offset + stride + 11 ] = ( morphColor.itemSize === 4 ) ? morph.w : 1;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tentry = {\n\t\t\t\t\tcount: morphTargetsCount,\n\t\t\t\t\ttexture: texture,\n\t\t\t\t\tsize: new Vector2( width, height )\n\t\t\t\t};\n\n\t\t\t\tmorphTextures.set( geometry, entry );\n\n\t\t\t\tfunction disposeTexture() {\n\n\t\t\t\t\ttexture.dispose();\n\n\t\t\t\t\tmorphTextures.delete( geometry );\n\n\t\t\t\t\tgeometry.removeEventListener( 'dispose', disposeTexture );\n\n\t\t\t\t}\n\n\t\t\t\tgeometry.addEventListener( 'dispose', disposeTexture );\n\n\t\t\t}\n\n\t\t\t//\n\n\t\t\tlet morphInfluencesSum = 0;\n\n\t\t\tfor ( let i = 0; i < objectInfluences.length; i ++ ) {\n\n\t\t\t\tmorphInfluencesSum += objectInfluences[ i ];\n\n\t\t\t}\n\n\t\t\tconst morphBaseInfluence = geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;\n\n\t\t\tprogram.getUniforms().setValue( gl, 'morphTargetBaseInfluence', morphBaseInfluence );\n\t\t\tprogram.getUniforms().setValue( gl, 'morphTargetInfluences', objectInfluences );\n\n\t\t\tprogram.getUniforms().setValue( gl, 'morphTargetsTexture', entry.texture, textures );\n\t\t\tprogram.getUniforms().setValue( gl, 'morphTargetsTextureSize', entry.size );\n\n\n\t\t} else {\n\n\t\t\t// When object doesn't have morph target influences defined, we treat it as a 0-length array\n\t\t\t// This is important to make sure we set up morphTargetBaseInfluence / morphTargetInfluences\n\n\t\t\tconst length = objectInfluences === undefined ? 0 : objectInfluences.length;\n\n\t\t\tlet influences = influencesList[ geometry.id ];\n\n\t\t\tif ( influences === undefined || influences.length !== length ) {\n\n\t\t\t\t// initialise list\n\n\t\t\t\tinfluences = [];\n\n\t\t\t\tfor ( let i = 0; i < length; i ++ ) {\n\n\t\t\t\t\tinfluences[ i ] = [ i, 0 ];\n\n\t\t\t\t}\n\n\t\t\t\tinfluencesList[ geometry.id ] = influences;\n\n\t\t\t}\n\n\t\t\t// Collect influences\n\n\t\t\tfor ( let i = 0; i < length; i ++ ) {\n\n\t\t\t\tconst influence = influences[ i ];\n\n\t\t\t\tinfluence[ 0 ] = i;\n\t\t\t\tinfluence[ 1 ] = objectInfluences[ i ];\n\n\t\t\t}\n\n\t\t\tinfluences.sort( absNumericalSort );\n\n\t\t\tfor ( let i = 0; i < 8; i ++ ) {\n\n\t\t\t\tif ( i < length && influences[ i ][ 1 ] ) {\n\n\t\t\t\t\tworkInfluences[ i ][ 0 ] = influences[ i ][ 0 ];\n\t\t\t\t\tworkInfluences[ i ][ 1 ] = influences[ i ][ 1 ];\n\n\t\t\t\t} else {\n\n\t\t\t\t\tworkInfluences[ i ][ 0 ] = Number.MAX_SAFE_INTEGER;\n\t\t\t\t\tworkInfluences[ i ][ 1 ] = 0;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tworkInfluences.sort( numericalSort );\n\n\t\t\tconst morphTargets = geometry.morphAttributes.position;\n\t\t\tconst morphNormals = geometry.morphAttributes.normal;\n\n\t\t\tlet morphInfluencesSum = 0;\n\n\t\t\tfor ( let i = 0; i < 8; i ++ ) {\n\n\t\t\t\tconst influence = workInfluences[ i ];\n\t\t\t\tconst index = influence[ 0 ];\n\t\t\t\tconst value = influence[ 1 ];\n\n\t\t\t\tif ( index !== Number.MAX_SAFE_INTEGER && value ) {\n\n\t\t\t\t\tif ( morphTargets && geometry.getAttribute( 'morphTarget' + i ) !== morphTargets[ index ] ) {\n\n\t\t\t\t\t\tgeometry.setAttribute( 'morphTarget' + i, morphTargets[ index ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( morphNormals && geometry.getAttribute( 'morphNormal' + i ) !== morphNormals[ index ] ) {\n\n\t\t\t\t\t\tgeometry.setAttribute( 'morphNormal' + i, morphNormals[ index ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tmorphInfluences[ i ] = value;\n\t\t\t\t\tmorphInfluencesSum += value;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( morphTargets && geometry.hasAttribute( 'morphTarget' + i ) === true ) {\n\n\t\t\t\t\t\tgeometry.deleteAttribute( 'morphTarget' + i );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( morphNormals && geometry.hasAttribute( 'morphNormal' + i ) === true ) {\n\n\t\t\t\t\t\tgeometry.deleteAttribute( 'morphNormal' + i );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tmorphInfluences[ i ] = 0;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// GLSL shader uses formula baseinfluence * base + sum(target * influence)\n\t\t\t// This allows us to switch between absolute morphs and relative morphs without changing shader code\n\t\t\t// When baseinfluence = 1 - sum(influence), the above is equivalent to sum((target - base) * influence)\n\t\t\tconst morphBaseInfluence = geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;\n\n\t\t\tprogram.getUniforms().setValue( gl, 'morphTargetBaseInfluence', morphBaseInfluence );\n\t\t\tprogram.getUniforms().setValue( gl, 'morphTargetInfluences', morphInfluences );\n\n\t\t}\n\n\t}\n\n\treturn {\n\n\t\tupdate: update\n\n\t};\n\n}\n\nfunction WebGLObjects( gl, geometries, attributes, info ) {\n\n\tlet updateMap = new WeakMap();\n\n\tfunction update( object ) {\n\n\t\tconst frame = info.render.frame;\n\n\t\tconst geometry = object.geometry;\n\t\tconst buffergeometry = geometries.get( object, geometry );\n\n\t\t// Update once per frame\n\n\t\tif ( updateMap.get( buffergeometry ) !== frame ) {\n\n\t\t\tgeometries.update( buffergeometry );\n\n\t\t\tupdateMap.set( buffergeometry, frame );\n\n\t\t}\n\n\t\tif ( object.isInstancedMesh ) {\n\n\t\t\tif ( object.hasEventListener( 'dispose', onInstancedMeshDispose ) === false ) {\n\n\t\t\t\tobject.addEventListener( 'dispose', onInstancedMeshDispose );\n\n\t\t\t}\n\n\t\t\tattributes.update( object.instanceMatrix, 34962 );\n\n\t\t\tif ( object.instanceColor !== null ) {\n\n\t\t\t\tattributes.update( object.instanceColor, 34962 );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn buffergeometry;\n\n\t}\n\n\tfunction dispose() {\n\n\t\tupdateMap = new WeakMap();\n\n\t}\n\n\tfunction onInstancedMeshDispose( event ) {\n\n\t\tconst instancedMesh = event.target;\n\n\t\tinstancedMesh.removeEventListener( 'dispose', onInstancedMeshDispose );\n\n\t\tattributes.remove( instancedMesh.instanceMatrix );\n\n\t\tif ( instancedMesh.instanceColor !== null ) attributes.remove( instancedMesh.instanceColor );\n\n\t}\n\n\treturn {\n\n\t\tupdate: update,\n\t\tdispose: dispose\n\n\t};\n\n}\n\n/**\n * Uniforms of a program.\n * Those form a tree structure with a special top-level container for the root,\n * which you get by calling 'new WebGLUniforms( gl, program )'.\n *\n *\n * Properties of inner nodes including the top-level container:\n *\n * .seq - array of nested uniforms\n * .map - nested uniforms by name\n *\n *\n * Methods of all nodes except the top-level container:\n *\n * .setValue( gl, value, [textures] )\n *\n * \t\tuploads a uniform value(s)\n *  \tthe 'textures' parameter is needed for sampler uniforms\n *\n *\n * Static methods of the top-level container (textures factorizations):\n *\n * .upload( gl, seq, values, textures )\n *\n * \t\tsets uniforms in 'seq' to 'values[id].value'\n *\n * .seqWithValue( seq, values ) : filteredSeq\n *\n * \t\tfilters 'seq' entries with corresponding entry in values\n *\n *\n * Methods of the top-level container (textures factorizations):\n *\n * .setValue( gl, name, value, textures )\n *\n * \t\tsets uniform with  name 'name' to 'value'\n *\n * .setOptional( gl, obj, prop )\n *\n * \t\tlike .set for an optional property of the object\n *\n */\n\nconst emptyTexture = new Texture();\nconst emptyArrayTexture = new DataArrayTexture();\nconst empty3dTexture = new Data3DTexture();\nconst emptyCubeTexture = new CubeTexture();\n\n// --- Utilities ---\n\n// Array Caches (provide typed arrays for temporary by size)\n\nconst arrayCacheF32 = [];\nconst arrayCacheI32 = [];\n\n// Float32Array caches used for uploading Matrix uniforms\n\nconst mat4array = new Float32Array( 16 );\nconst mat3array = new Float32Array( 9 );\nconst mat2array = new Float32Array( 4 );\n\n// Flattening for arrays of vectors and matrices\n\nfunction flatten( array, nBlocks, blockSize ) {\n\n\tconst firstElem = array[ 0 ];\n\n\tif ( firstElem <= 0 || firstElem > 0 ) return array;\n\t// unoptimized: ! isNaN( firstElem )\n\t// see http://jacksondunstan.com/articles/983\n\n\tconst n = nBlocks * blockSize;\n\tlet r = arrayCacheF32[ n ];\n\n\tif ( r === undefined ) {\n\n\t\tr = new Float32Array( n );\n\t\tarrayCacheF32[ n ] = r;\n\n\t}\n\n\tif ( nBlocks !== 0 ) {\n\n\t\tfirstElem.toArray( r, 0 );\n\n\t\tfor ( let i = 1, offset = 0; i !== nBlocks; ++ i ) {\n\n\t\t\toffset += blockSize;\n\t\t\tarray[ i ].toArray( r, offset );\n\n\t\t}\n\n\t}\n\n\treturn r;\n\n}\n\nfunction arraysEqual( a, b ) {\n\n\tif ( a.length !== b.length ) return false;\n\n\tfor ( let i = 0, l = a.length; i < l; i ++ ) {\n\n\t\tif ( a[ i ] !== b[ i ] ) return false;\n\n\t}\n\n\treturn true;\n\n}\n\nfunction copyArray( a, b ) {\n\n\tfor ( let i = 0, l = b.length; i < l; i ++ ) {\n\n\t\ta[ i ] = b[ i ];\n\n\t}\n\n}\n\n// Texture unit allocation\n\nfunction allocTexUnits( textures, n ) {\n\n\tlet r = arrayCacheI32[ n ];\n\n\tif ( r === undefined ) {\n\n\t\tr = new Int32Array( n );\n\t\tarrayCacheI32[ n ] = r;\n\n\t}\n\n\tfor ( let i = 0; i !== n; ++ i ) {\n\n\t\tr[ i ] = textures.allocateTextureUnit();\n\n\t}\n\n\treturn r;\n\n}\n\n// --- Setters ---\n\n// Note: Defining these methods externally, because they come in a bunch\n// and this way their names minify.\n\n// Single scalar\n\nfunction setValueV1f( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( cache[ 0 ] === v ) return;\n\n\tgl.uniform1f( this.addr, v );\n\n\tcache[ 0 ] = v;\n\n}\n\n// Single float vector (from flat array or THREE.VectorN)\n\nfunction setValueV2f( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( v.x !== undefined ) {\n\n\t\tif ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y ) {\n\n\t\t\tgl.uniform2f( this.addr, v.x, v.y );\n\n\t\t\tcache[ 0 ] = v.x;\n\t\t\tcache[ 1 ] = v.y;\n\n\t\t}\n\n\t} else {\n\n\t\tif ( arraysEqual( cache, v ) ) return;\n\n\t\tgl.uniform2fv( this.addr, v );\n\n\t\tcopyArray( cache, v );\n\n\t}\n\n}\n\nfunction setValueV3f( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( v.x !== undefined ) {\n\n\t\tif ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z ) {\n\n\t\t\tgl.uniform3f( this.addr, v.x, v.y, v.z );\n\n\t\t\tcache[ 0 ] = v.x;\n\t\t\tcache[ 1 ] = v.y;\n\t\t\tcache[ 2 ] = v.z;\n\n\t\t}\n\n\t} else if ( v.r !== undefined ) {\n\n\t\tif ( cache[ 0 ] !== v.r || cache[ 1 ] !== v.g || cache[ 2 ] !== v.b ) {\n\n\t\t\tgl.uniform3f( this.addr, v.r, v.g, v.b );\n\n\t\t\tcache[ 0 ] = v.r;\n\t\t\tcache[ 1 ] = v.g;\n\t\t\tcache[ 2 ] = v.b;\n\n\t\t}\n\n\t} else {\n\n\t\tif ( arraysEqual( cache, v ) ) return;\n\n\t\tgl.uniform3fv( this.addr, v );\n\n\t\tcopyArray( cache, v );\n\n\t}\n\n}\n\nfunction setValueV4f( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( v.x !== undefined ) {\n\n\t\tif ( cache[ 0 ] !== v.x || cache[ 1 ] !== v.y || cache[ 2 ] !== v.z || cache[ 3 ] !== v.w ) {\n\n\t\t\tgl.uniform4f( this.addr, v.x, v.y, v.z, v.w );\n\n\t\t\tcache[ 0 ] = v.x;\n\t\t\tcache[ 1 ] = v.y;\n\t\t\tcache[ 2 ] = v.z;\n\t\t\tcache[ 3 ] = v.w;\n\n\t\t}\n\n\t} else {\n\n\t\tif ( arraysEqual( cache, v ) ) return;\n\n\t\tgl.uniform4fv( this.addr, v );\n\n\t\tcopyArray( cache, v );\n\n\t}\n\n}\n\n// Single matrix (from flat array or THREE.MatrixN)\n\nfunction setValueM2( gl, v ) {\n\n\tconst cache = this.cache;\n\tconst elements = v.elements;\n\n\tif ( elements === undefined ) {\n\n\t\tif ( arraysEqual( cache, v ) ) return;\n\n\t\tgl.uniformMatrix2fv( this.addr, false, v );\n\n\t\tcopyArray( cache, v );\n\n\t} else {\n\n\t\tif ( arraysEqual( cache, elements ) ) return;\n\n\t\tmat2array.set( elements );\n\n\t\tgl.uniformMatrix2fv( this.addr, false, mat2array );\n\n\t\tcopyArray( cache, elements );\n\n\t}\n\n}\n\nfunction setValueM3( gl, v ) {\n\n\tconst cache = this.cache;\n\tconst elements = v.elements;\n\n\tif ( elements === undefined ) {\n\n\t\tif ( arraysEqual( cache, v ) ) return;\n\n\t\tgl.uniformMatrix3fv( this.addr, false, v );\n\n\t\tcopyArray( cache, v );\n\n\t} else {\n\n\t\tif ( arraysEqual( cache, elements ) ) return;\n\n\t\tmat3array.set( elements );\n\n\t\tgl.uniformMatrix3fv( this.addr, false, mat3array );\n\n\t\tcopyArray( cache, elements );\n\n\t}\n\n}\n\nfunction setValueM4( gl, v ) {\n\n\tconst cache = this.cache;\n\tconst elements = v.elements;\n\n\tif ( elements === undefined ) {\n\n\t\tif ( arraysEqual( cache, v ) ) return;\n\n\t\tgl.uniformMatrix4fv( this.addr, false, v );\n\n\t\tcopyArray( cache, v );\n\n\t} else {\n\n\t\tif ( arraysEqual( cache, elements ) ) return;\n\n\t\tmat4array.set( elements );\n\n\t\tgl.uniformMatrix4fv( this.addr, false, mat4array );\n\n\t\tcopyArray( cache, elements );\n\n\t}\n\n}\n\n// Single integer / boolean\n\nfunction setValueV1i( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( cache[ 0 ] === v ) return;\n\n\tgl.uniform1i( this.addr, v );\n\n\tcache[ 0 ] = v;\n\n}\n\n// Single integer / boolean vector (from flat array)\n\nfunction setValueV2i( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( arraysEqual( cache, v ) ) return;\n\n\tgl.uniform2iv( this.addr, v );\n\n\tcopyArray( cache, v );\n\n}\n\nfunction setValueV3i( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( arraysEqual( cache, v ) ) return;\n\n\tgl.uniform3iv( this.addr, v );\n\n\tcopyArray( cache, v );\n\n}\n\nfunction setValueV4i( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( arraysEqual( cache, v ) ) return;\n\n\tgl.uniform4iv( this.addr, v );\n\n\tcopyArray( cache, v );\n\n}\n\n// Single unsigned integer\n\nfunction setValueV1ui( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( cache[ 0 ] === v ) return;\n\n\tgl.uniform1ui( this.addr, v );\n\n\tcache[ 0 ] = v;\n\n}\n\n// Single unsigned integer vector (from flat array)\n\nfunction setValueV2ui( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( arraysEqual( cache, v ) ) return;\n\n\tgl.uniform2uiv( this.addr, v );\n\n\tcopyArray( cache, v );\n\n}\n\nfunction setValueV3ui( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( arraysEqual( cache, v ) ) return;\n\n\tgl.uniform3uiv( this.addr, v );\n\n\tcopyArray( cache, v );\n\n}\n\nfunction setValueV4ui( gl, v ) {\n\n\tconst cache = this.cache;\n\n\tif ( arraysEqual( cache, v ) ) return;\n\n\tgl.uniform4uiv( this.addr, v );\n\n\tcopyArray( cache, v );\n\n}\n\n\n// Single texture (2D / Cube)\n\nfunction setValueT1( gl, v, textures ) {\n\n\tconst cache = this.cache;\n\tconst unit = textures.allocateTextureUnit();\n\n\tif ( cache[ 0 ] !== unit ) {\n\n\t\tgl.uniform1i( this.addr, unit );\n\t\tcache[ 0 ] = unit;\n\n\t}\n\n\ttextures.setTexture2D( v || emptyTexture, unit );\n\n}\n\nfunction setValueT3D1( gl, v, textures ) {\n\n\tconst cache = this.cache;\n\tconst unit = textures.allocateTextureUnit();\n\n\tif ( cache[ 0 ] !== unit ) {\n\n\t\tgl.uniform1i( this.addr, unit );\n\t\tcache[ 0 ] = unit;\n\n\t}\n\n\ttextures.setTexture3D( v || empty3dTexture, unit );\n\n}\n\nfunction setValueT6( gl, v, textures ) {\n\n\tconst cache = this.cache;\n\tconst unit = textures.allocateTextureUnit();\n\n\tif ( cache[ 0 ] !== unit ) {\n\n\t\tgl.uniform1i( this.addr, unit );\n\t\tcache[ 0 ] = unit;\n\n\t}\n\n\ttextures.setTextureCube( v || emptyCubeTexture, unit );\n\n}\n\nfunction setValueT2DArray1( gl, v, textures ) {\n\n\tconst cache = this.cache;\n\tconst unit = textures.allocateTextureUnit();\n\n\tif ( cache[ 0 ] !== unit ) {\n\n\t\tgl.uniform1i( this.addr, unit );\n\t\tcache[ 0 ] = unit;\n\n\t}\n\n\ttextures.setTexture2DArray( v || emptyArrayTexture, unit );\n\n}\n\n// Helper to pick the right setter for the singular case\n\nfunction getSingularSetter( type ) {\n\n\tswitch ( type ) {\n\n\t\tcase 0x1406: return setValueV1f; // FLOAT\n\t\tcase 0x8b50: return setValueV2f; // _VEC2\n\t\tcase 0x8b51: return setValueV3f; // _VEC3\n\t\tcase 0x8b52: return setValueV4f; // _VEC4\n\n\t\tcase 0x8b5a: return setValueM2; // _MAT2\n\t\tcase 0x8b5b: return setValueM3; // _MAT3\n\t\tcase 0x8b5c: return setValueM4; // _MAT4\n\n\t\tcase 0x1404: case 0x8b56: return setValueV1i; // INT, BOOL\n\t\tcase 0x8b53: case 0x8b57: return setValueV2i; // _VEC2\n\t\tcase 0x8b54: case 0x8b58: return setValueV3i; // _VEC3\n\t\tcase 0x8b55: case 0x8b59: return setValueV4i; // _VEC4\n\n\t\tcase 0x1405: return setValueV1ui; // UINT\n\t\tcase 0x8dc6: return setValueV2ui; // _VEC2\n\t\tcase 0x8dc7: return setValueV3ui; // _VEC3\n\t\tcase 0x8dc8: return setValueV4ui; // _VEC4\n\n\t\tcase 0x8b5e: // SAMPLER_2D\n\t\tcase 0x8d66: // SAMPLER_EXTERNAL_OES\n\t\tcase 0x8dca: // INT_SAMPLER_2D\n\t\tcase 0x8dd2: // UNSIGNED_INT_SAMPLER_2D\n\t\tcase 0x8b62: // SAMPLER_2D_SHADOW\n\t\t\treturn setValueT1;\n\n\t\tcase 0x8b5f: // SAMPLER_3D\n\t\tcase 0x8dcb: // INT_SAMPLER_3D\n\t\tcase 0x8dd3: // UNSIGNED_INT_SAMPLER_3D\n\t\t\treturn setValueT3D1;\n\n\t\tcase 0x8b60: // SAMPLER_CUBE\n\t\tcase 0x8dcc: // INT_SAMPLER_CUBE\n\t\tcase 0x8dd4: // UNSIGNED_INT_SAMPLER_CUBE\n\t\tcase 0x8dc5: // SAMPLER_CUBE_SHADOW\n\t\t\treturn setValueT6;\n\n\t\tcase 0x8dc1: // SAMPLER_2D_ARRAY\n\t\tcase 0x8dcf: // INT_SAMPLER_2D_ARRAY\n\t\tcase 0x8dd7: // UNSIGNED_INT_SAMPLER_2D_ARRAY\n\t\tcase 0x8dc4: // SAMPLER_2D_ARRAY_SHADOW\n\t\t\treturn setValueT2DArray1;\n\n\t}\n\n}\n\n\n// Array of scalars\n\nfunction setValueV1fArray( gl, v ) {\n\n\tgl.uniform1fv( this.addr, v );\n\n}\n\n// Array of vectors (from flat array or array of THREE.VectorN)\n\nfunction setValueV2fArray( gl, v ) {\n\n\tconst data = flatten( v, this.size, 2 );\n\n\tgl.uniform2fv( this.addr, data );\n\n}\n\nfunction setValueV3fArray( gl, v ) {\n\n\tconst data = flatten( v, this.size, 3 );\n\n\tgl.uniform3fv( this.addr, data );\n\n}\n\nfunction setValueV4fArray( gl, v ) {\n\n\tconst data = flatten( v, this.size, 4 );\n\n\tgl.uniform4fv( this.addr, data );\n\n}\n\n// Array of matrices (from flat array or array of THREE.MatrixN)\n\nfunction setValueM2Array( gl, v ) {\n\n\tconst data = flatten( v, this.size, 4 );\n\n\tgl.uniformMatrix2fv( this.addr, false, data );\n\n}\n\nfunction setValueM3Array( gl, v ) {\n\n\tconst data = flatten( v, this.size, 9 );\n\n\tgl.uniformMatrix3fv( this.addr, false, data );\n\n}\n\nfunction setValueM4Array( gl, v ) {\n\n\tconst data = flatten( v, this.size, 16 );\n\n\tgl.uniformMatrix4fv( this.addr, false, data );\n\n}\n\n// Array of integer / boolean\n\nfunction setValueV1iArray( gl, v ) {\n\n\tgl.uniform1iv( this.addr, v );\n\n}\n\n// Array of integer / boolean vectors (from flat array)\n\nfunction setValueV2iArray( gl, v ) {\n\n\tgl.uniform2iv( this.addr, v );\n\n}\n\nfunction setValueV3iArray( gl, v ) {\n\n\tgl.uniform3iv( this.addr, v );\n\n}\n\nfunction setValueV4iArray( gl, v ) {\n\n\tgl.uniform4iv( this.addr, v );\n\n}\n\n// Array of unsigned integer\n\nfunction setValueV1uiArray( gl, v ) {\n\n\tgl.uniform1uiv( this.addr, v );\n\n}\n\n// Array of unsigned integer vectors (from flat array)\n\nfunction setValueV2uiArray( gl, v ) {\n\n\tgl.uniform2uiv( this.addr, v );\n\n}\n\nfunction setValueV3uiArray( gl, v ) {\n\n\tgl.uniform3uiv( this.addr, v );\n\n}\n\nfunction setValueV4uiArray( gl, v ) {\n\n\tgl.uniform4uiv( this.addr, v );\n\n}\n\n\n// Array of textures (2D / 3D / Cube / 2DArray)\n\nfunction setValueT1Array( gl, v, textures ) {\n\n\tconst n = v.length;\n\n\tconst units = allocTexUnits( textures, n );\n\n\tgl.uniform1iv( this.addr, units );\n\n\tfor ( let i = 0; i !== n; ++ i ) {\n\n\t\ttextures.setTexture2D( v[ i ] || emptyTexture, units[ i ] );\n\n\t}\n\n}\n\nfunction setValueT3DArray( gl, v, textures ) {\n\n\tconst n = v.length;\n\n\tconst units = allocTexUnits( textures, n );\n\n\tgl.uniform1iv( this.addr, units );\n\n\tfor ( let i = 0; i !== n; ++ i ) {\n\n\t\ttextures.setTexture3D( v[ i ] || empty3dTexture, units[ i ] );\n\n\t}\n\n}\n\nfunction setValueT6Array( gl, v, textures ) {\n\n\tconst n = v.length;\n\n\tconst units = allocTexUnits( textures, n );\n\n\tgl.uniform1iv( this.addr, units );\n\n\tfor ( let i = 0; i !== n; ++ i ) {\n\n\t\ttextures.setTextureCube( v[ i ] || emptyCubeTexture, units[ i ] );\n\n\t}\n\n}\n\nfunction setValueT2DArrayArray( gl, v, textures ) {\n\n\tconst n = v.length;\n\n\tconst units = allocTexUnits( textures, n );\n\n\tgl.uniform1iv( this.addr, units );\n\n\tfor ( let i = 0; i !== n; ++ i ) {\n\n\t\ttextures.setTexture2DArray( v[ i ] || emptyArrayTexture, units[ i ] );\n\n\t}\n\n}\n\n\n// Helper to pick the right setter for a pure (bottom-level) array\n\nfunction getPureArraySetter( type ) {\n\n\tswitch ( type ) {\n\n\t\tcase 0x1406: return setValueV1fArray; // FLOAT\n\t\tcase 0x8b50: return setValueV2fArray; // _VEC2\n\t\tcase 0x8b51: return setValueV3fArray; // _VEC3\n\t\tcase 0x8b52: return setValueV4fArray; // _VEC4\n\n\t\tcase 0x8b5a: return setValueM2Array; // _MAT2\n\t\tcase 0x8b5b: return setValueM3Array; // _MAT3\n\t\tcase 0x8b5c: return setValueM4Array; // _MAT4\n\n\t\tcase 0x1404: case 0x8b56: return setValueV1iArray; // INT, BOOL\n\t\tcase 0x8b53: case 0x8b57: return setValueV2iArray; // _VEC2\n\t\tcase 0x8b54: case 0x8b58: return setValueV3iArray; // _VEC3\n\t\tcase 0x8b55: case 0x8b59: return setValueV4iArray; // _VEC4\n\n\t\tcase 0x1405: return setValueV1uiArray; // UINT\n\t\tcase 0x8dc6: return setValueV2uiArray; // _VEC2\n\t\tcase 0x8dc7: return setValueV3uiArray; // _VEC3\n\t\tcase 0x8dc8: return setValueV4uiArray; // _VEC4\n\n\t\tcase 0x8b5e: // SAMPLER_2D\n\t\tcase 0x8d66: // SAMPLER_EXTERNAL_OES\n\t\tcase 0x8dca: // INT_SAMPLER_2D\n\t\tcase 0x8dd2: // UNSIGNED_INT_SAMPLER_2D\n\t\tcase 0x8b62: // SAMPLER_2D_SHADOW\n\t\t\treturn setValueT1Array;\n\n\t\tcase 0x8b5f: // SAMPLER_3D\n\t\tcase 0x8dcb: // INT_SAMPLER_3D\n\t\tcase 0x8dd3: // UNSIGNED_INT_SAMPLER_3D\n\t\t\treturn setValueT3DArray;\n\n\t\tcase 0x8b60: // SAMPLER_CUBE\n\t\tcase 0x8dcc: // INT_SAMPLER_CUBE\n\t\tcase 0x8dd4: // UNSIGNED_INT_SAMPLER_CUBE\n\t\tcase 0x8dc5: // SAMPLER_CUBE_SHADOW\n\t\t\treturn setValueT6Array;\n\n\t\tcase 0x8dc1: // SAMPLER_2D_ARRAY\n\t\tcase 0x8dcf: // INT_SAMPLER_2D_ARRAY\n\t\tcase 0x8dd7: // UNSIGNED_INT_SAMPLER_2D_ARRAY\n\t\tcase 0x8dc4: // SAMPLER_2D_ARRAY_SHADOW\n\t\t\treturn setValueT2DArrayArray;\n\n\t}\n\n}\n\n// --- Uniform Classes ---\n\nfunction SingleUniform( id, activeInfo, addr ) {\n\n\tthis.id = id;\n\tthis.addr = addr;\n\tthis.cache = [];\n\tthis.setValue = getSingularSetter( activeInfo.type );\n\n\t// this.path = activeInfo.name; // DEBUG\n\n}\n\nfunction PureArrayUniform( id, activeInfo, addr ) {\n\n\tthis.id = id;\n\tthis.addr = addr;\n\tthis.cache = [];\n\tthis.size = activeInfo.size;\n\tthis.setValue = getPureArraySetter( activeInfo.type );\n\n\t// this.path = activeInfo.name; // DEBUG\n\n}\n\nPureArrayUniform.prototype.updateCache = function ( data ) {\n\n\tconst cache = this.cache;\n\n\tif ( data instanceof Float32Array && cache.length !== data.length ) {\n\n\t\tthis.cache = new Float32Array( data.length );\n\n\t}\n\n\tcopyArray( cache, data );\n\n};\n\nfunction StructuredUniform( id ) {\n\n\tthis.id = id;\n\n\tthis.seq = [];\n\tthis.map = {};\n\n}\n\nStructuredUniform.prototype.setValue = function ( gl, value, textures ) {\n\n\tconst seq = this.seq;\n\n\tfor ( let i = 0, n = seq.length; i !== n; ++ i ) {\n\n\t\tconst u = seq[ i ];\n\t\tu.setValue( gl, value[ u.id ], textures );\n\n\t}\n\n};\n\n// --- Top-level ---\n\n// Parser - builds up the property tree from the path strings\n\nconst RePathPart = /(\\w+)(\\])?(\\[|\\.)?/g;\n\n// extracts\n// \t- the identifier (member name or array index)\n//  - followed by an optional right bracket (found when array index)\n//  - followed by an optional left bracket or dot (type of subscript)\n//\n// Note: These portions can be read in a non-overlapping fashion and\n// allow straightforward parsing of the hierarchy that WebGL encodes\n// in the uniform names.\n\nfunction addUniform( container, uniformObject ) {\n\n\tcontainer.seq.push( uniformObject );\n\tcontainer.map[ uniformObject.id ] = uniformObject;\n\n}\n\nfunction parseUniform( activeInfo, addr, container ) {\n\n\tconst path = activeInfo.name,\n\t\tpathLength = path.length;\n\n\t// reset RegExp object, because of the early exit of a previous run\n\tRePathPart.lastIndex = 0;\n\n\twhile ( true ) {\n\n\t\tconst match = RePathPart.exec( path ),\n\t\t\tmatchEnd = RePathPart.lastIndex;\n\n\t\tlet id = match[ 1 ];\n\t\tconst idIsIndex = match[ 2 ] === ']',\n\t\t\tsubscript = match[ 3 ];\n\n\t\tif ( idIsIndex ) id = id | 0; // convert to integer\n\n\t\tif ( subscript === undefined || subscript === '[' && matchEnd + 2 === pathLength ) {\n\n\t\t\t// bare name or \"pure\" bottom-level array \"[0]\" suffix\n\n\t\t\taddUniform( container, subscript === undefined ?\n\t\t\t\tnew SingleUniform( id, activeInfo, addr ) :\n\t\t\t\tnew PureArrayUniform( id, activeInfo, addr ) );\n\n\t\t\tbreak;\n\n\t\t} else {\n\n\t\t\t// step into inner node / create it in case it doesn't exist\n\n\t\t\tconst map = container.map;\n\t\t\tlet next = map[ id ];\n\n\t\t\tif ( next === undefined ) {\n\n\t\t\t\tnext = new StructuredUniform( id );\n\t\t\t\taddUniform( container, next );\n\n\t\t\t}\n\n\t\t\tcontainer = next;\n\n\t\t}\n\n\t}\n\n}\n\n// Root Container\n\nfunction WebGLUniforms( gl, program ) {\n\n\tthis.seq = [];\n\tthis.map = {};\n\n\tconst n = gl.getProgramParameter( program, 35718 );\n\n\tfor ( let i = 0; i < n; ++ i ) {\n\n\t\tconst info = gl.getActiveUniform( program, i ),\n\t\t\taddr = gl.getUniformLocation( program, info.name );\n\n\t\tparseUniform( info, addr, this );\n\n\t}\n\n}\n\nWebGLUniforms.prototype.setValue = function ( gl, name, value, textures ) {\n\n\tconst u = this.map[ name ];\n\n\tif ( u !== undefined ) u.setValue( gl, value, textures );\n\n};\n\nWebGLUniforms.prototype.setOptional = function ( gl, object, name ) {\n\n\tconst v = object[ name ];\n\n\tif ( v !== undefined ) this.setValue( gl, name, v );\n\n};\n\n\n// Static interface\n\nWebGLUniforms.upload = function ( gl, seq, values, textures ) {\n\n\tfor ( let i = 0, n = seq.length; i !== n; ++ i ) {\n\n\t\tconst u = seq[ i ],\n\t\t\tv = values[ u.id ];\n\n\t\tif ( v.needsUpdate !== false ) {\n\n\t\t\t// note: always updating when .needsUpdate is undefined\n\t\t\tu.setValue( gl, v.value, textures );\n\n\t\t}\n\n\t}\n\n};\n\nWebGLUniforms.seqWithValue = function ( seq, values ) {\n\n\tconst r = [];\n\n\tfor ( let i = 0, n = seq.length; i !== n; ++ i ) {\n\n\t\tconst u = seq[ i ];\n\t\tif ( u.id in values ) r.push( u );\n\n\t}\n\n\treturn r;\n\n};\n\nfunction WebGLShader( gl, type, string ) {\n\n\tconst shader = gl.createShader( type );\n\n\tgl.shaderSource( shader, string );\n\tgl.compileShader( shader );\n\n\treturn shader;\n\n}\n\nlet programIdCount = 0;\n\nfunction addLineNumbers( string ) {\n\n\tconst lines = string.split( '\\n' );\n\n\tfor ( let i = 0; i < lines.length; i ++ ) {\n\n\t\tlines[ i ] = ( i + 1 ) + ': ' + lines[ i ];\n\n\t}\n\n\treturn lines.join( '\\n' );\n\n}\n\nfunction getEncodingComponents( encoding ) {\n\n\tswitch ( encoding ) {\n\n\t\tcase LinearEncoding:\n\t\t\treturn [ 'Linear', '( value )' ];\n\t\tcase sRGBEncoding:\n\t\t\treturn [ 'sRGB', '( value )' ];\n\t\tdefault:\n\t\t\tconsole.warn( 'THREE.WebGLProgram: Unsupported encoding:', encoding );\n\t\t\treturn [ 'Linear', '( value )' ];\n\n\t}\n\n}\n\nfunction getShaderErrors( gl, shader, type ) {\n\n\tconst status = gl.getShaderParameter( shader, 35713 );\n\tconst errors = gl.getShaderInfoLog( shader ).trim();\n\n\tif ( status && errors === '' ) return '';\n\n\t// --enable-privileged-webgl-extension\n\t// console.log( '**' + type + '**', gl.getExtension( 'WEBGL_debug_shaders' ).getTranslatedShaderSource( shader ) );\n\n\treturn type.toUpperCase() + '\\n\\n' + errors + '\\n\\n' + addLineNumbers( gl.getShaderSource( shader ) );\n\n}\n\nfunction getTexelEncodingFunction( functionName, encoding ) {\n\n\tconst components = getEncodingComponents( encoding );\n\treturn 'vec4 ' + functionName + '( vec4 value ) { return LinearTo' + components[ 0 ] + components[ 1 ] + '; }';\n\n}\n\nfunction getToneMappingFunction( functionName, toneMapping ) {\n\n\tlet toneMappingName;\n\n\tswitch ( toneMapping ) {\n\n\t\tcase LinearToneMapping:\n\t\t\ttoneMappingName = 'Linear';\n\t\t\tbreak;\n\n\t\tcase ReinhardToneMapping:\n\t\t\ttoneMappingName = 'Reinhard';\n\t\t\tbreak;\n\n\t\tcase CineonToneMapping:\n\t\t\ttoneMappingName = 'OptimizedCineon';\n\t\t\tbreak;\n\n\t\tcase ACESFilmicToneMapping:\n\t\t\ttoneMappingName = 'ACESFilmic';\n\t\t\tbreak;\n\n\t\tcase CustomToneMapping:\n\t\t\ttoneMappingName = 'Custom';\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tconsole.warn( 'THREE.WebGLProgram: Unsupported toneMapping:', toneMapping );\n\t\t\ttoneMappingName = 'Linear';\n\n\t}\n\n\treturn 'vec3 ' + functionName + '( vec3 color ) { return ' + toneMappingName + 'ToneMapping( color ); }';\n\n}\n\nfunction generateExtensions( parameters ) {\n\n\tconst chunks = [\n\t\t( parameters.extensionDerivatives || !! parameters.envMapCubeUVHeight || parameters.bumpMap || parameters.tangentSpaceNormalMap || parameters.clearcoatNormalMap || parameters.flatShading || parameters.shaderID === 'physical' ) ? '#extension GL_OES_standard_derivatives : enable' : '',\n\t\t( parameters.extensionFragDepth || parameters.logarithmicDepthBuffer ) && parameters.rendererExtensionFragDepth ? '#extension GL_EXT_frag_depth : enable' : '',\n\t\t( parameters.extensionDrawBuffers && parameters.rendererExtensionDrawBuffers ) ? '#extension GL_EXT_draw_buffers : require' : '',\n\t\t( parameters.extensionShaderTextureLOD || parameters.envMap || parameters.transmission ) && parameters.rendererExtensionShaderTextureLod ? '#extension GL_EXT_shader_texture_lod : enable' : ''\n\t];\n\n\treturn chunks.filter( filterEmptyLine ).join( '\\n' );\n\n}\n\nfunction generateDefines( defines ) {\n\n\tconst chunks = [];\n\n\tfor ( const name in defines ) {\n\n\t\tconst value = defines[ name ];\n\n\t\tif ( value === false ) continue;\n\n\t\tchunks.push( '#define ' + name + ' ' + value );\n\n\t}\n\n\treturn chunks.join( '\\n' );\n\n}\n\nfunction fetchAttributeLocations( gl, program ) {\n\n\tconst attributes = {};\n\n\tconst n = gl.getProgramParameter( program, 35721 );\n\n\tfor ( let i = 0; i < n; i ++ ) {\n\n\t\tconst info = gl.getActiveAttrib( program, i );\n\t\tconst name = info.name;\n\n\t\tlet locationSize = 1;\n\t\tif ( info.type === 35674 ) locationSize = 2;\n\t\tif ( info.type === 35675 ) locationSize = 3;\n\t\tif ( info.type === 35676 ) locationSize = 4;\n\n\t\t// console.log( 'THREE.WebGLProgram: ACTIVE VERTEX ATTRIBUTE:', name, i );\n\n\t\tattributes[ name ] = {\n\t\t\ttype: info.type,\n\t\t\tlocation: gl.getAttribLocation( program, name ),\n\t\t\tlocationSize: locationSize\n\t\t};\n\n\t}\n\n\treturn attributes;\n\n}\n\nfunction filterEmptyLine( string ) {\n\n\treturn string !== '';\n\n}\n\nfunction replaceLightNums( string, parameters ) {\n\n\treturn string\n\t\t.replace( /NUM_DIR_LIGHTS/g, parameters.numDirLights )\n\t\t.replace( /NUM_SPOT_LIGHTS/g, parameters.numSpotLights )\n\t\t.replace( /NUM_RECT_AREA_LIGHTS/g, parameters.numRectAreaLights )\n\t\t.replace( /NUM_POINT_LIGHTS/g, parameters.numPointLights )\n\t\t.replace( /NUM_HEMI_LIGHTS/g, parameters.numHemiLights )\n\t\t.replace( /NUM_DIR_LIGHT_SHADOWS/g, parameters.numDirLightShadows )\n\t\t.replace( /NUM_SPOT_LIGHT_SHADOWS/g, parameters.numSpotLightShadows )\n\t\t.replace( /NUM_POINT_LIGHT_SHADOWS/g, parameters.numPointLightShadows );\n\n}\n\nfunction replaceClippingPlaneNums( string, parameters ) {\n\n\treturn string\n\t\t.replace( /NUM_CLIPPING_PLANES/g, parameters.numClippingPlanes )\n\t\t.replace( /UNION_CLIPPING_PLANES/g, ( parameters.numClippingPlanes - parameters.numClipIntersection ) );\n\n}\n\n// Resolve Includes\n\nconst includePattern = /^[ \\t]*#include +<([\\w\\d./]+)>/gm;\n\nfunction resolveIncludes( string ) {\n\n\treturn string.replace( includePattern, includeReplacer );\n\n}\n\nfunction includeReplacer( match, include ) {\n\n\tconst string = ShaderChunk[ include ];\n\n\tif ( string === undefined ) {\n\n\t\tthrow new Error( 'Can not resolve #include <' + include + '>' );\n\n\t}\n\n\treturn resolveIncludes( string );\n\n}\n\n// Unroll Loops\n\nconst deprecatedUnrollLoopPattern = /#pragma unroll_loop[\\s]+?for \\( int i \\= (\\d+)\\; i < (\\d+)\\; i \\+\\+ \\) \\{([\\s\\S]+?)(?=\\})\\}/g;\nconst unrollLoopPattern = /#pragma unroll_loop_start\\s+for\\s*\\(\\s*int\\s+i\\s*=\\s*(\\d+)\\s*;\\s*i\\s*<\\s*(\\d+)\\s*;\\s*i\\s*\\+\\+\\s*\\)\\s*{([\\s\\S]+?)}\\s+#pragma unroll_loop_end/g;\n\nfunction unrollLoops( string ) {\n\n\treturn string\n\t\t.replace( unrollLoopPattern, loopReplacer )\n\t\t.replace( deprecatedUnrollLoopPattern, deprecatedLoopReplacer );\n\n}\n\nfunction deprecatedLoopReplacer( match, start, end, snippet ) {\n\n\tconsole.warn( 'WebGLProgram: #pragma unroll_loop shader syntax is deprecated. Please use #pragma unroll_loop_start syntax instead.' );\n\treturn loopReplacer( match, start, end, snippet );\n\n}\n\nfunction loopReplacer( match, start, end, snippet ) {\n\n\tlet string = '';\n\n\tfor ( let i = parseInt( start ); i < parseInt( end ); i ++ ) {\n\n\t\tstring += snippet\n\t\t\t.replace( /\\[\\s*i\\s*\\]/g, '[ ' + i + ' ]' )\n\t\t\t.replace( /UNROLLED_LOOP_INDEX/g, i );\n\n\t}\n\n\treturn string;\n\n}\n\n//\n\nfunction generatePrecision( parameters ) {\n\n\tlet precisionstring = 'precision ' + parameters.precision + ' float;\\nprecision ' + parameters.precision + ' int;';\n\n\tif ( parameters.precision === 'highp' ) {\n\n\t\tprecisionstring += '\\n#define HIGH_PRECISION';\n\n\t} else if ( parameters.precision === 'mediump' ) {\n\n\t\tprecisionstring += '\\n#define MEDIUM_PRECISION';\n\n\t} else if ( parameters.precision === 'lowp' ) {\n\n\t\tprecisionstring += '\\n#define LOW_PRECISION';\n\n\t}\n\n\treturn precisionstring;\n\n}\n\nfunction generateShadowMapTypeDefine( parameters ) {\n\n\tlet shadowMapTypeDefine = 'SHADOWMAP_TYPE_BASIC';\n\n\tif ( parameters.shadowMapType === PCFShadowMap ) {\n\n\t\tshadowMapTypeDefine = 'SHADOWMAP_TYPE_PCF';\n\n\t} else if ( parameters.shadowMapType === PCFSoftShadowMap ) {\n\n\t\tshadowMapTypeDefine = 'SHADOWMAP_TYPE_PCF_SOFT';\n\n\t} else if ( parameters.shadowMapType === VSMShadowMap ) {\n\n\t\tshadowMapTypeDefine = 'SHADOWMAP_TYPE_VSM';\n\n\t}\n\n\treturn shadowMapTypeDefine;\n\n}\n\nfunction generateEnvMapTypeDefine( parameters ) {\n\n\tlet envMapTypeDefine = 'ENVMAP_TYPE_CUBE';\n\n\tif ( parameters.envMap ) {\n\n\t\tswitch ( parameters.envMapMode ) {\n\n\t\t\tcase CubeReflectionMapping:\n\t\t\tcase CubeRefractionMapping:\n\t\t\t\tenvMapTypeDefine = 'ENVMAP_TYPE_CUBE';\n\t\t\t\tbreak;\n\n\t\t\tcase CubeUVReflectionMapping:\n\t\t\tcase CubeUVRefractionMapping:\n\t\t\t\tenvMapTypeDefine = 'ENVMAP_TYPE_CUBE_UV';\n\t\t\t\tbreak;\n\n\t\t}\n\n\t}\n\n\treturn envMapTypeDefine;\n\n}\n\nfunction generateEnvMapModeDefine( parameters ) {\n\n\tlet envMapModeDefine = 'ENVMAP_MODE_REFLECTION';\n\n\tif ( parameters.envMap ) {\n\n\t\tswitch ( parameters.envMapMode ) {\n\n\t\t\tcase CubeRefractionMapping:\n\t\t\tcase CubeUVRefractionMapping:\n\n\t\t\t\tenvMapModeDefine = 'ENVMAP_MODE_REFRACTION';\n\t\t\t\tbreak;\n\n\t\t}\n\n\t}\n\n\treturn envMapModeDefine;\n\n}\n\nfunction generateEnvMapBlendingDefine( parameters ) {\n\n\tlet envMapBlendingDefine = 'ENVMAP_BLENDING_NONE';\n\n\tif ( parameters.envMap ) {\n\n\t\tswitch ( parameters.combine ) {\n\n\t\t\tcase MultiplyOperation:\n\t\t\t\tenvMapBlendingDefine = 'ENVMAP_BLENDING_MULTIPLY';\n\t\t\t\tbreak;\n\n\t\t\tcase MixOperation:\n\t\t\t\tenvMapBlendingDefine = 'ENVMAP_BLENDING_MIX';\n\t\t\t\tbreak;\n\n\t\t\tcase AddOperation:\n\t\t\t\tenvMapBlendingDefine = 'ENVMAP_BLENDING_ADD';\n\t\t\t\tbreak;\n\n\t\t}\n\n\t}\n\n\treturn envMapBlendingDefine;\n\n}\n\nfunction generateCubeUVSize( parameters ) {\n\n\tconst imageHeight = parameters.envMapCubeUVHeight;\n\n\tif ( imageHeight === null ) return null;\n\n\tconst maxMip = Math.log2( imageHeight / 32 + 1 ) + 3;\n\n\tconst texelHeight = 1.0 / imageHeight;\n\n\tconst texelWidth = 1.0 / ( 3 * Math.max( Math.pow( 2, maxMip ), 7 * 16 ) );\n\n\treturn { texelWidth, texelHeight, maxMip };\n\n}\n\nfunction WebGLProgram( renderer, cacheKey, parameters, bindingStates ) {\n\n\t// TODO Send this event to Three.js DevTools\n\t// console.log( 'WebGLProgram', cacheKey );\n\n\tconst gl = renderer.getContext();\n\n\tconst defines = parameters.defines;\n\n\tlet vertexShader = parameters.vertexShader;\n\tlet fragmentShader = parameters.fragmentShader;\n\n\tconst shadowMapTypeDefine = generateShadowMapTypeDefine( parameters );\n\tconst envMapTypeDefine = generateEnvMapTypeDefine( parameters );\n\tconst envMapModeDefine = generateEnvMapModeDefine( parameters );\n\tconst envMapBlendingDefine = generateEnvMapBlendingDefine( parameters );\n\tconst envMapCubeUVSize = generateCubeUVSize( parameters );\n\n\tconst customExtensions = parameters.isWebGL2 ? '' : generateExtensions( parameters );\n\n\tconst customDefines = generateDefines( defines );\n\n\tconst program = gl.createProgram();\n\n\tlet prefixVertex, prefixFragment;\n\tlet versionString = parameters.glslVersion ? '#version ' + parameters.glslVersion + '\\n' : '';\n\n\tif ( parameters.isRawShaderMaterial ) {\n\n\t\tprefixVertex = [\n\n\t\t\tcustomDefines\n\n\t\t].filter( filterEmptyLine ).join( '\\n' );\n\n\t\tif ( prefixVertex.length > 0 ) {\n\n\t\t\tprefixVertex += '\\n';\n\n\t\t}\n\n\t\tprefixFragment = [\n\n\t\t\tcustomExtensions,\n\t\t\tcustomDefines\n\n\t\t].filter( filterEmptyLine ).join( '\\n' );\n\n\t\tif ( prefixFragment.length > 0 ) {\n\n\t\t\tprefixFragment += '\\n';\n\n\t\t}\n\n\t} else {\n\n\t\tprefixVertex = [\n\n\t\t\tgeneratePrecision( parameters ),\n\n\t\t\t'#define SHADER_NAME ' + parameters.shaderName,\n\n\t\t\tcustomDefines,\n\n\t\t\tparameters.instancing ? '#define USE_INSTANCING' : '',\n\t\t\tparameters.instancingColor ? '#define USE_INSTANCING_COLOR' : '',\n\n\t\t\tparameters.supportsVertexTextures ? '#define VERTEX_TEXTURES' : '',\n\n\t\t\t'#define MAX_BONES ' + parameters.maxBones,\n\t\t\t( parameters.useFog && parameters.fog ) ? '#define USE_FOG' : '',\n\t\t\t( parameters.useFog && parameters.fogExp2 ) ? '#define FOG_EXP2' : '',\n\n\t\t\tparameters.map ? '#define USE_MAP' : '',\n\t\t\tparameters.envMap ? '#define USE_ENVMAP' : '',\n\t\t\tparameters.envMap ? '#define ' + envMapModeDefine : '',\n\t\t\tparameters.lightMap ? '#define USE_LIGHTMAP' : '',\n\t\t\tparameters.aoMap ? '#define USE_AOMAP' : '',\n\t\t\tparameters.emissiveMap ? '#define USE_EMISSIVEMAP' : '',\n\t\t\tparameters.bumpMap ? '#define USE_BUMPMAP' : '',\n\t\t\tparameters.normalMap ? '#define USE_NORMALMAP' : '',\n\t\t\t( parameters.normalMap && parameters.objectSpaceNormalMap ) ? '#define OBJECTSPACE_NORMALMAP' : '',\n\t\t\t( parameters.normalMap && parameters.tangentSpaceNormalMap ) ? '#define TANGENTSPACE_NORMALMAP' : '',\n\n\t\t\tparameters.clearcoatMap ? '#define USE_CLEARCOATMAP' : '',\n\t\t\tparameters.clearcoatRoughnessMap ? '#define USE_CLEARCOAT_ROUGHNESSMAP' : '',\n\t\t\tparameters.clearcoatNormalMap ? '#define USE_CLEARCOAT_NORMALMAP' : '',\n\n\t\t\tparameters.displacementMap && parameters.supportsVertexTextures ? '#define USE_DISPLACEMENTMAP' : '',\n\n\t\t\tparameters.specularMap ? '#define USE_SPECULARMAP' : '',\n\t\t\tparameters.specularIntensityMap ? '#define USE_SPECULARINTENSITYMAP' : '',\n\t\t\tparameters.specularColorMap ? '#define USE_SPECULARCOLORMAP' : '',\n\n\t\t\tparameters.roughnessMap ? '#define USE_ROUGHNESSMAP' : '',\n\t\t\tparameters.metalnessMap ? '#define USE_METALNESSMAP' : '',\n\t\t\tparameters.alphaMap ? '#define USE_ALPHAMAP' : '',\n\n\t\t\tparameters.transmission ? '#define USE_TRANSMISSION' : '',\n\t\t\tparameters.transmissionMap ? '#define USE_TRANSMISSIONMAP' : '',\n\t\t\tparameters.thicknessMap ? '#define USE_THICKNESSMAP' : '',\n\n\t\t\tparameters.sheenColorMap ? '#define USE_SHEENCOLORMAP' : '',\n\t\t\tparameters.sheenRoughnessMap ? '#define USE_SHEENROUGHNESSMAP' : '',\n\n\t\t\tparameters.vertexTangents ? '#define USE_TANGENT' : '',\n\t\t\tparameters.vertexColors ? '#define USE_COLOR' : '',\n\t\t\tparameters.vertexAlphas ? '#define USE_COLOR_ALPHA' : '',\n\t\t\tparameters.vertexUvs ? '#define USE_UV' : '',\n\t\t\tparameters.uvsVertexOnly ? '#define UVS_VERTEX_ONLY' : '',\n\n\t\t\tparameters.flatShading ? '#define FLAT_SHADED' : '',\n\n\t\t\tparameters.skinning ? '#define USE_SKINNING' : '',\n\t\t\tparameters.useVertexTexture ? '#define BONE_TEXTURE' : '',\n\n\t\t\tparameters.morphTargets ? '#define USE_MORPHTARGETS' : '',\n\t\t\tparameters.morphNormals && parameters.flatShading === false ? '#define USE_MORPHNORMALS' : '',\n\t\t\t( parameters.morphColors && parameters.isWebGL2 ) ? '#define USE_MORPHCOLORS' : '',\n\t\t\t( parameters.morphTargetsCount > 0 && parameters.isWebGL2 ) ? '#define MORPHTARGETS_TEXTURE' : '',\n\t\t\t( parameters.morphTargetsCount > 0 && parameters.isWebGL2 ) ? '#define MORPHTARGETS_TEXTURE_STRIDE ' + parameters.morphTextureStride : '',\n\t\t\t( parameters.morphTargetsCount > 0 && parameters.isWebGL2 ) ? '#define MORPHTARGETS_COUNT ' + parameters.morphTargetsCount : '',\n\t\t\tparameters.doubleSided ? '#define DOUBLE_SIDED' : '',\n\t\t\tparameters.flipSided ? '#define FLIP_SIDED' : '',\n\n\t\t\tparameters.shadowMapEnabled ? '#define USE_SHADOWMAP' : '',\n\t\t\tparameters.shadowMapEnabled ? '#define ' + shadowMapTypeDefine : '',\n\n\t\t\tparameters.sizeAttenuation ? '#define USE_SIZEATTENUATION' : '',\n\n\t\t\tparameters.logarithmicDepthBuffer ? '#define USE_LOGDEPTHBUF' : '',\n\t\t\t( parameters.logarithmicDepthBuffer && parameters.rendererExtensionFragDepth ) ? '#define USE_LOGDEPTHBUF_EXT' : '',\n\n\t\t\t'uniform mat4 modelMatrix;',\n\t\t\t'uniform mat4 modelViewMatrix;',\n\t\t\t'uniform mat4 projectionMatrix;',\n\t\t\t'uniform mat4 viewMatrix;',\n\t\t\t'uniform mat3 normalMatrix;',\n\t\t\t'uniform vec3 cameraPosition;',\n\t\t\t'uniform bool isOrthographic;',\n\n\t\t\t'#ifdef USE_INSTANCING',\n\n\t\t\t'\tattribute mat4 instanceMatrix;',\n\n\t\t\t'#endif',\n\n\t\t\t'#ifdef USE_INSTANCING_COLOR',\n\n\t\t\t'\tattribute vec3 instanceColor;',\n\n\t\t\t'#endif',\n\n\t\t\t'attribute vec3 position;',\n\t\t\t'attribute vec3 normal;',\n\t\t\t'attribute vec2 uv;',\n\n\t\t\t'#ifdef USE_TANGENT',\n\n\t\t\t'\tattribute vec4 tangent;',\n\n\t\t\t'#endif',\n\n\t\t\t'#if defined( USE_COLOR_ALPHA )',\n\n\t\t\t'\tattribute vec4 color;',\n\n\t\t\t'#elif defined( USE_COLOR )',\n\n\t\t\t'\tattribute vec3 color;',\n\n\t\t\t'#endif',\n\n\t\t\t'#if ( defined( USE_MORPHTARGETS ) && ! defined( MORPHTARGETS_TEXTURE ) )',\n\n\t\t\t'\tattribute vec3 morphTarget0;',\n\t\t\t'\tattribute vec3 morphTarget1;',\n\t\t\t'\tattribute vec3 morphTarget2;',\n\t\t\t'\tattribute vec3 morphTarget3;',\n\n\t\t\t'\t#ifdef USE_MORPHNORMALS',\n\n\t\t\t'\t\tattribute vec3 morphNormal0;',\n\t\t\t'\t\tattribute vec3 morphNormal1;',\n\t\t\t'\t\tattribute vec3 morphNormal2;',\n\t\t\t'\t\tattribute vec3 morphNormal3;',\n\n\t\t\t'\t#else',\n\n\t\t\t'\t\tattribute vec3 morphTarget4;',\n\t\t\t'\t\tattribute vec3 morphTarget5;',\n\t\t\t'\t\tattribute vec3 morphTarget6;',\n\t\t\t'\t\tattribute vec3 morphTarget7;',\n\n\t\t\t'\t#endif',\n\n\t\t\t'#endif',\n\n\t\t\t'#ifdef USE_SKINNING',\n\n\t\t\t'\tattribute vec4 skinIndex;',\n\t\t\t'\tattribute vec4 skinWeight;',\n\n\t\t\t'#endif',\n\n\t\t\t'\\n'\n\n\t\t].filter( filterEmptyLine ).join( '\\n' );\n\n\t\tprefixFragment = [\n\n\t\t\tcustomExtensions,\n\n\t\t\tgeneratePrecision( parameters ),\n\n\t\t\t'#define SHADER_NAME ' + parameters.shaderName,\n\n\t\t\tcustomDefines,\n\n\t\t\t( parameters.useFog && parameters.fog ) ? '#define USE_FOG' : '',\n\t\t\t( parameters.useFog && parameters.fogExp2 ) ? '#define FOG_EXP2' : '',\n\n\t\t\tparameters.map ? '#define USE_MAP' : '',\n\t\t\tparameters.matcap ? '#define USE_MATCAP' : '',\n\t\t\tparameters.envMap ? '#define USE_ENVMAP' : '',\n\t\t\tparameters.envMap ? '#define ' + envMapTypeDefine : '',\n\t\t\tparameters.envMap ? '#define ' + envMapModeDefine : '',\n\t\t\tparameters.envMap ? '#define ' + envMapBlendingDefine : '',\n\t\t\tenvMapCubeUVSize ? '#define CUBEUV_TEXEL_WIDTH ' + envMapCubeUVSize.texelWidth : '',\n\t\t\tenvMapCubeUVSize ? '#define CUBEUV_TEXEL_HEIGHT ' + envMapCubeUVSize.texelHeight : '',\n\t\t\tenvMapCubeUVSize ? '#define CUBEUV_MAX_MIP ' + envMapCubeUVSize.maxMip + '.0' : '',\n\t\t\tparameters.lightMap ? '#define USE_LIGHTMAP' : '',\n\t\t\tparameters.aoMap ? '#define USE_AOMAP' : '',\n\t\t\tparameters.emissiveMap ? '#define USE_EMISSIVEMAP' : '',\n\t\t\tparameters.bumpMap ? '#define USE_BUMPMAP' : '',\n\t\t\tparameters.normalMap ? '#define USE_NORMALMAP' : '',\n\t\t\t( parameters.normalMap && parameters.objectSpaceNormalMap ) ? '#define OBJECTSPACE_NORMALMAP' : '',\n\t\t\t( parameters.normalMap && parameters.tangentSpaceNormalMap ) ? '#define TANGENTSPACE_NORMALMAP' : '',\n\n\t\t\tparameters.clearcoat ? '#define USE_CLEARCOAT' : '',\n\t\t\tparameters.clearcoatMap ? '#define USE_CLEARCOATMAP' : '',\n\t\t\tparameters.clearcoatRoughnessMap ? '#define USE_CLEARCOAT_ROUGHNESSMAP' : '',\n\t\t\tparameters.clearcoatNormalMap ? '#define USE_CLEARCOAT_NORMALMAP' : '',\n\n\t\t\tparameters.specularMap ? '#define USE_SPECULARMAP' : '',\n\t\t\tparameters.specularIntensityMap ? '#define USE_SPECULARINTENSITYMAP' : '',\n\t\t\tparameters.specularColorMap ? '#define USE_SPECULARCOLORMAP' : '',\n\t\t\tparameters.roughnessMap ? '#define USE_ROUGHNESSMAP' : '',\n\t\t\tparameters.metalnessMap ? '#define USE_METALNESSMAP' : '',\n\n\t\t\tparameters.alphaMap ? '#define USE_ALPHAMAP' : '',\n\t\t\tparameters.alphaTest ? '#define USE_ALPHATEST' : '',\n\n\t\t\tparameters.sheen ? '#define USE_SHEEN' : '',\n\t\t\tparameters.sheenColorMap ? '#define USE_SHEENCOLORMAP' : '',\n\t\t\tparameters.sheenRoughnessMap ? '#define USE_SHEENROUGHNESSMAP' : '',\n\n\t\t\tparameters.transmission ? '#define USE_TRANSMISSION' : '',\n\t\t\tparameters.transmissionMap ? '#define USE_TRANSMISSIONMAP' : '',\n\t\t\tparameters.thicknessMap ? '#define USE_THICKNESSMAP' : '',\n\n\t\t\tparameters.decodeVideoTexture ? '#define DECODE_VIDEO_TEXTURE' : '',\n\n\t\t\tparameters.vertexTangents ? '#define USE_TANGENT' : '',\n\t\t\tparameters.vertexColors || parameters.instancingColor ? '#define USE_COLOR' : '',\n\t\t\tparameters.vertexAlphas ? '#define USE_COLOR_ALPHA' : '',\n\t\t\tparameters.vertexUvs ? '#define USE_UV' : '',\n\t\t\tparameters.uvsVertexOnly ? '#define UVS_VERTEX_ONLY' : '',\n\n\t\t\tparameters.gradientMap ? '#define USE_GRADIENTMAP' : '',\n\n\t\t\tparameters.flatShading ? '#define FLAT_SHADED' : '',\n\n\t\t\tparameters.doubleSided ? '#define DOUBLE_SIDED' : '',\n\t\t\tparameters.flipSided ? '#define FLIP_SIDED' : '',\n\n\t\t\tparameters.shadowMapEnabled ? '#define USE_SHADOWMAP' : '',\n\t\t\tparameters.shadowMapEnabled ? '#define ' + shadowMapTypeDefine : '',\n\n\t\t\tparameters.premultipliedAlpha ? '#define PREMULTIPLIED_ALPHA' : '',\n\n\t\t\tparameters.physicallyCorrectLights ? '#define PHYSICALLY_CORRECT_LIGHTS' : '',\n\n\t\t\tparameters.logarithmicDepthBuffer ? '#define USE_LOGDEPTHBUF' : '',\n\t\t\t( parameters.logarithmicDepthBuffer && parameters.rendererExtensionFragDepth ) ? '#define USE_LOGDEPTHBUF_EXT' : '',\n\n\t\t\t'uniform mat4 viewMatrix;',\n\t\t\t'uniform vec3 cameraPosition;',\n\t\t\t'uniform bool isOrthographic;',\n\n\t\t\t( parameters.toneMapping !== NoToneMapping ) ? '#define TONE_MAPPING' : '',\n\t\t\t( parameters.toneMapping !== NoToneMapping ) ? ShaderChunk[ 'tonemapping_pars_fragment' ] : '', // this code is required here because it is used by the toneMapping() function defined below\n\t\t\t( parameters.toneMapping !== NoToneMapping ) ? getToneMappingFunction( 'toneMapping', parameters.toneMapping ) : '',\n\n\t\t\tparameters.dithering ? '#define DITHERING' : '',\n\t\t\tparameters.opaque ? '#define OPAQUE' : '',\n\n\t\t\tShaderChunk[ 'encodings_pars_fragment' ], // this code is required here because it is used by the various encoding/decoding function defined below\n\t\t\tgetTexelEncodingFunction( 'linearToOutputTexel', parameters.outputEncoding ),\n\n\t\t\tparameters.depthPacking ? '#define DEPTH_PACKING ' + parameters.depthPacking : '',\n\n\t\t\t'\\n'\n\n\t\t].filter( filterEmptyLine ).join( '\\n' );\n\n\t}\n\n\tvertexShader = resolveIncludes( vertexShader );\n\tvertexShader = replaceLightNums( vertexShader, parameters );\n\tvertexShader = replaceClippingPlaneNums( vertexShader, parameters );\n\n\tfragmentShader = resolveIncludes( fragmentShader );\n\tfragmentShader = replaceLightNums( fragmentShader, parameters );\n\tfragmentShader = replaceClippingPlaneNums( fragmentShader, parameters );\n\n\tvertexShader = unrollLoops( vertexShader );\n\tfragmentShader = unrollLoops( fragmentShader );\n\n\tif ( parameters.isWebGL2 && parameters.isRawShaderMaterial !== true ) {\n\n\t\t// GLSL 3.0 conversion for built-in materials and ShaderMaterial\n\n\t\tversionString = '#version 300 es\\n';\n\n\t\tprefixVertex = [\n\t\t\t'precision mediump sampler2DArray;',\n\t\t\t'#define attribute in',\n\t\t\t'#define varying out',\n\t\t\t'#define texture2D texture'\n\t\t].join( '\\n' ) + '\\n' + prefixVertex;\n\n\t\tprefixFragment = [\n\t\t\t'#define varying in',\n\t\t\t( parameters.glslVersion === GLSL3 ) ? '' : 'layout(location = 0) out highp vec4 pc_fragColor;',\n\t\t\t( parameters.glslVersion === GLSL3 ) ? '' : '#define gl_FragColor pc_fragColor',\n\t\t\t'#define gl_FragDepthEXT gl_FragDepth',\n\t\t\t'#define texture2D texture',\n\t\t\t'#define textureCube texture',\n\t\t\t'#define texture2DProj textureProj',\n\t\t\t'#define texture2DLodEXT textureLod',\n\t\t\t'#define texture2DProjLodEXT textureProjLod',\n\t\t\t'#define textureCubeLodEXT textureLod',\n\t\t\t'#define texture2DGradEXT textureGrad',\n\t\t\t'#define texture2DProjGradEXT textureProjGrad',\n\t\t\t'#define textureCubeGradEXT textureGrad'\n\t\t].join( '\\n' ) + '\\n' + prefixFragment;\n\n\t}\n\n\tconst vertexGlsl = versionString + prefixVertex + vertexShader;\n\tconst fragmentGlsl = versionString + prefixFragment + fragmentShader;\n\n\t// console.log( '*VERTEX*', vertexGlsl );\n\t// console.log( '*FRAGMENT*', fragmentGlsl );\n\n\tconst glVertexShader = WebGLShader( gl, 35633, vertexGlsl );\n\tconst glFragmentShader = WebGLShader( gl, 35632, fragmentGlsl );\n\n\tgl.attachShader( program, glVertexShader );\n\tgl.attachShader( program, glFragmentShader );\n\n\t// Force a particular attribute to index 0.\n\n\tif ( parameters.index0AttributeName !== undefined ) {\n\n\t\tgl.bindAttribLocation( program, 0, parameters.index0AttributeName );\n\n\t} else if ( parameters.morphTargets === true ) {\n\n\t\t// programs with morphTargets displace position out of attribute 0\n\t\tgl.bindAttribLocation( program, 0, 'position' );\n\n\t}\n\n\tgl.linkProgram( program );\n\n\t// check for link errors\n\tif ( renderer.debug.checkShaderErrors ) {\n\n\t\tconst programLog = gl.getProgramInfoLog( program ).trim();\n\t\tconst vertexLog = gl.getShaderInfoLog( glVertexShader ).trim();\n\t\tconst fragmentLog = gl.getShaderInfoLog( glFragmentShader ).trim();\n\n\t\tlet runnable = true;\n\t\tlet haveDiagnostics = true;\n\n\t\tif ( gl.getProgramParameter( program, 35714 ) === false ) {\n\n\t\t\trunnable = false;\n\n\t\t\tconst vertexErrors = getShaderErrors( gl, glVertexShader, 'vertex' );\n\t\t\tconst fragmentErrors = getShaderErrors( gl, glFragmentShader, 'fragment' );\n\n\t\t\tconsole.error(\n\t\t\t\t'THREE.WebGLProgram: Shader Error ' + gl.getError() + ' - ' +\n\t\t\t\t'VALIDATE_STATUS ' + gl.getProgramParameter( program, 35715 ) + '\\n\\n' +\n\t\t\t\t'Program Info Log: ' + programLog + '\\n' +\n\t\t\t\tvertexErrors + '\\n' +\n\t\t\t\tfragmentErrors\n\t\t\t);\n\n\t\t} else if ( programLog !== '' ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLProgram: Program Info Log:', programLog );\n\n\t\t} else if ( vertexLog === '' || fragmentLog === '' ) {\n\n\t\t\thaveDiagnostics = false;\n\n\t\t}\n\n\t\tif ( haveDiagnostics ) {\n\n\t\t\tthis.diagnostics = {\n\n\t\t\t\trunnable: runnable,\n\n\t\t\t\tprogramLog: programLog,\n\n\t\t\t\tvertexShader: {\n\n\t\t\t\t\tlog: vertexLog,\n\t\t\t\t\tprefix: prefixVertex\n\n\t\t\t\t},\n\n\t\t\t\tfragmentShader: {\n\n\t\t\t\t\tlog: fragmentLog,\n\t\t\t\t\tprefix: prefixFragment\n\n\t\t\t\t}\n\n\t\t\t};\n\n\t\t}\n\n\t}\n\n\t// Clean up\n\n\t// Crashes in iOS9 and iOS10. #18402\n\t// gl.detachShader( program, glVertexShader );\n\t// gl.detachShader( program, glFragmentShader );\n\n\tgl.deleteShader( glVertexShader );\n\tgl.deleteShader( glFragmentShader );\n\n\t// set up caching for uniform locations\n\n\tlet cachedUniforms;\n\n\tthis.getUniforms = function () {\n\n\t\tif ( cachedUniforms === undefined ) {\n\n\t\t\tcachedUniforms = new WebGLUniforms( gl, program );\n\n\t\t}\n\n\t\treturn cachedUniforms;\n\n\t};\n\n\t// set up caching for attribute locations\n\n\tlet cachedAttributes;\n\n\tthis.getAttributes = function () {\n\n\t\tif ( cachedAttributes === undefined ) {\n\n\t\t\tcachedAttributes = fetchAttributeLocations( gl, program );\n\n\t\t}\n\n\t\treturn cachedAttributes;\n\n\t};\n\n\t// free resource\n\n\tthis.destroy = function () {\n\n\t\tbindingStates.releaseStatesOfProgram( this );\n\n\t\tgl.deleteProgram( program );\n\t\tthis.program = undefined;\n\n\t};\n\n\t//\n\n\tthis.name = parameters.shaderName;\n\tthis.id = programIdCount ++;\n\tthis.cacheKey = cacheKey;\n\tthis.usedTimes = 1;\n\tthis.program = program;\n\tthis.vertexShader = glVertexShader;\n\tthis.fragmentShader = glFragmentShader;\n\n\treturn this;\n\n}\n\nlet _id = 0;\n\nclass WebGLShaderCache {\n\n\tconstructor() {\n\n\t\tthis.shaderCache = new Map();\n\t\tthis.materialCache = new Map();\n\n\t}\n\n\tupdate( material ) {\n\n\t\tconst vertexShader = material.vertexShader;\n\t\tconst fragmentShader = material.fragmentShader;\n\n\t\tconst vertexShaderStage = this._getShaderStage( vertexShader );\n\t\tconst fragmentShaderStage = this._getShaderStage( fragmentShader );\n\n\t\tconst materialShaders = this._getShaderCacheForMaterial( material );\n\n\t\tif ( materialShaders.has( vertexShaderStage ) === false ) {\n\n\t\t\tmaterialShaders.add( vertexShaderStage );\n\t\t\tvertexShaderStage.usedTimes ++;\n\n\t\t}\n\n\t\tif ( materialShaders.has( fragmentShaderStage ) === false ) {\n\n\t\t\tmaterialShaders.add( fragmentShaderStage );\n\t\t\tfragmentShaderStage.usedTimes ++;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tremove( material ) {\n\n\t\tconst materialShaders = this.materialCache.get( material );\n\n\t\tfor ( const shaderStage of materialShaders ) {\n\n\t\t\tshaderStage.usedTimes --;\n\n\t\t\tif ( shaderStage.usedTimes === 0 ) this.shaderCache.delete( shaderStage );\n\n\t\t}\n\n\t\tthis.materialCache.delete( material );\n\n\t\treturn this;\n\n\t}\n\n\tgetVertexShaderID( material ) {\n\n\t\treturn this._getShaderStage( material.vertexShader ).id;\n\n\t}\n\n\tgetFragmentShaderID( material ) {\n\n\t\treturn this._getShaderStage( material.fragmentShader ).id;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.shaderCache.clear();\n\t\tthis.materialCache.clear();\n\n\t}\n\n\t_getShaderCacheForMaterial( material ) {\n\n\t\tconst cache = this.materialCache;\n\n\t\tif ( cache.has( material ) === false ) {\n\n\t\t\tcache.set( material, new Set() );\n\n\t\t}\n\n\t\treturn cache.get( material );\n\n\t}\n\n\t_getShaderStage( code ) {\n\n\t\tconst cache = this.shaderCache;\n\n\t\tif ( cache.has( code ) === false ) {\n\n\t\t\tconst stage = new WebGLShaderStage();\n\t\t\tcache.set( code, stage );\n\n\t\t}\n\n\t\treturn cache.get( code );\n\n\t}\n\n}\n\nclass WebGLShaderStage {\n\n\tconstructor() {\n\n\t\tthis.id = _id ++;\n\n\t\tthis.usedTimes = 0;\n\n\t}\n\n}\n\nfunction WebGLPrograms( renderer, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping ) {\n\n\tconst _programLayers = new Layers();\n\tconst _customShaders = new WebGLShaderCache();\n\tconst programs = [];\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\tconst logarithmicDepthBuffer = capabilities.logarithmicDepthBuffer;\n\tconst floatVertexTextures = capabilities.floatVertexTextures;\n\tconst maxVertexUniforms = capabilities.maxVertexUniforms;\n\tconst vertexTextures = capabilities.vertexTextures;\n\tlet precision = capabilities.precision;\n\n\tconst shaderIDs = {\n\t\tMeshDepthMaterial: 'depth',\n\t\tMeshDistanceMaterial: 'distanceRGBA',\n\t\tMeshNormalMaterial: 'normal',\n\t\tMeshBasicMaterial: 'basic',\n\t\tMeshLambertMaterial: 'lambert',\n\t\tMeshPhongMaterial: 'phong',\n\t\tMeshToonMaterial: 'toon',\n\t\tMeshStandardMaterial: 'physical',\n\t\tMeshPhysicalMaterial: 'physical',\n\t\tMeshMatcapMaterial: 'matcap',\n\t\tLineBasicMaterial: 'basic',\n\t\tLineDashedMaterial: 'dashed',\n\t\tPointsMaterial: 'points',\n\t\tShadowMaterial: 'shadow',\n\t\tSpriteMaterial: 'sprite'\n\t};\n\n\tfunction getMaxBones( object ) {\n\n\t\tconst skeleton = object.skeleton;\n\t\tconst bones = skeleton.bones;\n\n\t\tif ( floatVertexTextures ) {\n\n\t\t\treturn 1024;\n\n\t\t} else {\n\n\t\t\t// default for when object is not specified\n\t\t\t// ( for example when prebuilding shader to be used with multiple objects )\n\t\t\t//\n\t\t\t//  - leave some extra space for other uniforms\n\t\t\t//  - limit here is ANGLE's 254 max uniform vectors\n\t\t\t//    (up to 54 should be safe)\n\n\t\t\tconst nVertexUniforms = maxVertexUniforms;\n\t\t\tconst nVertexMatrices = Math.floor( ( nVertexUniforms - 20 ) / 4 );\n\n\t\t\tconst maxBones = Math.min( nVertexMatrices, bones.length );\n\n\t\t\tif ( maxBones < bones.length ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Skeleton has ' + bones.length + ' bones. This GPU supports ' + maxBones + '.' );\n\t\t\t\treturn 0;\n\n\t\t\t}\n\n\t\t\treturn maxBones;\n\n\t\t}\n\n\t}\n\n\tfunction getParameters( material, lights, shadows, scene, object ) {\n\n\t\tconst fog = scene.fog;\n\t\tconst geometry = object.geometry;\n\t\tconst environment = material.isMeshStandardMaterial ? scene.environment : null;\n\n\t\tconst envMap = ( material.isMeshStandardMaterial ? cubeuvmaps : cubemaps ).get( material.envMap || environment );\n\t\tconst envMapCubeUVHeight = ( !! envMap ) && ( ( envMap.mapping === CubeUVReflectionMapping ) || ( envMap.mapping === CubeUVRefractionMapping ) ) ? envMap.image.height : null;\n\n\t\tconst shaderID = shaderIDs[ material.type ];\n\n\t\t// heuristics to create shader parameters according to lights in the scene\n\t\t// (not to blow over maxLights budget)\n\n\t\tconst maxBones = object.isSkinnedMesh ? getMaxBones( object ) : 0;\n\n\t\tif ( material.precision !== null ) {\n\n\t\t\tprecision = capabilities.getMaxPrecision( material.precision );\n\n\t\t\tif ( precision !== material.precision ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLProgram.getParameters:', material.precision, 'not supported, using', precision, 'instead.' );\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\n\t\tconst morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;\n\t\tconst morphTargetsCount = ( morphAttribute !== undefined ) ? morphAttribute.length : 0;\n\n\t\tlet morphTextureStride = 0;\n\n\t\tif ( geometry.morphAttributes.position !== undefined ) morphTextureStride = 1;\n\t\tif ( geometry.morphAttributes.normal !== undefined ) morphTextureStride = 2;\n\t\tif ( geometry.morphAttributes.color !== undefined ) morphTextureStride = 3;\n\n\t\t//\n\n\t\tlet vertexShader, fragmentShader;\n\t\tlet customVertexShaderID, customFragmentShaderID;\n\n\t\tif ( shaderID ) {\n\n\t\t\tconst shader = ShaderLib[ shaderID ];\n\n\t\t\tvertexShader = shader.vertexShader;\n\t\t\tfragmentShader = shader.fragmentShader;\n\n\t\t} else {\n\n\t\t\tvertexShader = material.vertexShader;\n\t\t\tfragmentShader = material.fragmentShader;\n\n\t\t\t_customShaders.update( material );\n\n\t\t\tcustomVertexShaderID = _customShaders.getVertexShaderID( material );\n\t\t\tcustomFragmentShaderID = _customShaders.getFragmentShaderID( material );\n\n\t\t}\n\n\t\tconst currentRenderTarget = renderer.getRenderTarget();\n\n\t\tconst useAlphaTest = material.alphaTest > 0;\n\t\tconst useClearcoat = material.clearcoat > 0;\n\n\t\tconst parameters = {\n\n\t\t\tisWebGL2: isWebGL2,\n\n\t\t\tshaderID: shaderID,\n\t\t\tshaderName: material.type,\n\n\t\t\tvertexShader: vertexShader,\n\t\t\tfragmentShader: fragmentShader,\n\t\t\tdefines: material.defines,\n\n\t\t\tcustomVertexShaderID: customVertexShaderID,\n\t\t\tcustomFragmentShaderID: customFragmentShaderID,\n\n\t\t\tisRawShaderMaterial: material.isRawShaderMaterial === true,\n\t\t\tglslVersion: material.glslVersion,\n\n\t\t\tprecision: precision,\n\n\t\t\tinstancing: object.isInstancedMesh === true,\n\t\t\tinstancingColor: object.isInstancedMesh === true && object.instanceColor !== null,\n\n\t\t\tsupportsVertexTextures: vertexTextures,\n\t\t\toutputEncoding: ( currentRenderTarget === null ) ? renderer.outputEncoding : ( currentRenderTarget.isXRRenderTarget === true ? currentRenderTarget.texture.encoding : LinearEncoding ),\n\t\t\tmap: !! material.map,\n\t\t\tmatcap: !! material.matcap,\n\t\t\tenvMap: !! envMap,\n\t\t\tenvMapMode: envMap && envMap.mapping,\n\t\t\tenvMapCubeUVHeight: envMapCubeUVHeight,\n\t\t\tlightMap: !! material.lightMap,\n\t\t\taoMap: !! material.aoMap,\n\t\t\temissiveMap: !! material.emissiveMap,\n\t\t\tbumpMap: !! material.bumpMap,\n\t\t\tnormalMap: !! material.normalMap,\n\t\t\tobjectSpaceNormalMap: material.normalMapType === ObjectSpaceNormalMap,\n\t\t\ttangentSpaceNormalMap: material.normalMapType === TangentSpaceNormalMap,\n\n\t\t\tdecodeVideoTexture: !! material.map && ( material.map.isVideoTexture === true ) && ( material.map.encoding === sRGBEncoding ),\n\n\t\t\tclearcoat: useClearcoat,\n\t\t\tclearcoatMap: useClearcoat && !! material.clearcoatMap,\n\t\t\tclearcoatRoughnessMap: useClearcoat && !! material.clearcoatRoughnessMap,\n\t\t\tclearcoatNormalMap: useClearcoat && !! material.clearcoatNormalMap,\n\n\t\t\tdisplacementMap: !! material.displacementMap,\n\t\t\troughnessMap: !! material.roughnessMap,\n\t\t\tmetalnessMap: !! material.metalnessMap,\n\t\t\tspecularMap: !! material.specularMap,\n\t\t\tspecularIntensityMap: !! material.specularIntensityMap,\n\t\t\tspecularColorMap: !! material.specularColorMap,\n\n\t\t\topaque: material.transparent === false && material.blending === NormalBlending,\n\n\t\t\talphaMap: !! material.alphaMap,\n\t\t\talphaTest: useAlphaTest,\n\n\t\t\tgradientMap: !! material.gradientMap,\n\n\t\t\tsheen: material.sheen > 0,\n\t\t\tsheenColorMap: !! material.sheenColorMap,\n\t\t\tsheenRoughnessMap: !! material.sheenRoughnessMap,\n\n\t\t\ttransmission: material.transmission > 0,\n\t\t\ttransmissionMap: !! material.transmissionMap,\n\t\t\tthicknessMap: !! material.thicknessMap,\n\n\t\t\tcombine: material.combine,\n\n\t\t\tvertexTangents: ( !! material.normalMap && !! geometry.attributes.tangent ),\n\t\t\tvertexColors: material.vertexColors,\n\t\t\tvertexAlphas: material.vertexColors === true && !! geometry.attributes.color && geometry.attributes.color.itemSize === 4,\n\t\t\tvertexUvs: !! material.map || !! material.bumpMap || !! material.normalMap || !! material.specularMap || !! material.alphaMap || !! material.emissiveMap || !! material.roughnessMap || !! material.metalnessMap || !! material.clearcoatMap || !! material.clearcoatRoughnessMap || !! material.clearcoatNormalMap || !! material.displacementMap || !! material.transmissionMap || !! material.thicknessMap || !! material.specularIntensityMap || !! material.specularColorMap || !! material.sheenColorMap || !! material.sheenRoughnessMap,\n\t\t\tuvsVertexOnly: ! ( !! material.map || !! material.bumpMap || !! material.normalMap || !! material.specularMap || !! material.alphaMap || !! material.emissiveMap || !! material.roughnessMap || !! material.metalnessMap || !! material.clearcoatNormalMap || material.transmission > 0 || !! material.transmissionMap || !! material.thicknessMap || !! material.specularIntensityMap || !! material.specularColorMap || material.sheen > 0 || !! material.sheenColorMap || !! material.sheenRoughnessMap ) && !! material.displacementMap,\n\n\t\t\tfog: !! fog,\n\t\t\tuseFog: material.fog,\n\t\t\tfogExp2: ( fog && fog.isFogExp2 ),\n\n\t\t\tflatShading: !! material.flatShading,\n\n\t\t\tsizeAttenuation: material.sizeAttenuation,\n\t\t\tlogarithmicDepthBuffer: logarithmicDepthBuffer,\n\n\t\t\tskinning: object.isSkinnedMesh === true && maxBones > 0,\n\t\t\tmaxBones: maxBones,\n\t\t\tuseVertexTexture: floatVertexTextures,\n\n\t\t\tmorphTargets: geometry.morphAttributes.position !== undefined,\n\t\t\tmorphNormals: geometry.morphAttributes.normal !== undefined,\n\t\t\tmorphColors: geometry.morphAttributes.color !== undefined,\n\t\t\tmorphTargetsCount: morphTargetsCount,\n\t\t\tmorphTextureStride: morphTextureStride,\n\n\t\t\tnumDirLights: lights.directional.length,\n\t\t\tnumPointLights: lights.point.length,\n\t\t\tnumSpotLights: lights.spot.length,\n\t\t\tnumRectAreaLights: lights.rectArea.length,\n\t\t\tnumHemiLights: lights.hemi.length,\n\n\t\t\tnumDirLightShadows: lights.directionalShadowMap.length,\n\t\t\tnumPointLightShadows: lights.pointShadowMap.length,\n\t\t\tnumSpotLightShadows: lights.spotShadowMap.length,\n\n\t\t\tnumClippingPlanes: clipping.numPlanes,\n\t\t\tnumClipIntersection: clipping.numIntersection,\n\n\t\t\tdithering: material.dithering,\n\n\t\t\tshadowMapEnabled: renderer.shadowMap.enabled && shadows.length > 0,\n\t\t\tshadowMapType: renderer.shadowMap.type,\n\n\t\t\ttoneMapping: material.toneMapped ? renderer.toneMapping : NoToneMapping,\n\t\t\tphysicallyCorrectLights: renderer.physicallyCorrectLights,\n\n\t\t\tpremultipliedAlpha: material.premultipliedAlpha,\n\n\t\t\tdoubleSided: material.side === DoubleSide,\n\t\t\tflipSided: material.side === BackSide,\n\n\t\t\tdepthPacking: ( material.depthPacking !== undefined ) ? material.depthPacking : false,\n\n\t\t\tindex0AttributeName: material.index0AttributeName,\n\n\t\t\textensionDerivatives: material.extensions && material.extensions.derivatives,\n\t\t\textensionFragDepth: material.extensions && material.extensions.fragDepth,\n\t\t\textensionDrawBuffers: material.extensions && material.extensions.drawBuffers,\n\t\t\textensionShaderTextureLOD: material.extensions && material.extensions.shaderTextureLOD,\n\n\t\t\trendererExtensionFragDepth: isWebGL2 || extensions.has( 'EXT_frag_depth' ),\n\t\t\trendererExtensionDrawBuffers: isWebGL2 || extensions.has( 'WEBGL_draw_buffers' ),\n\t\t\trendererExtensionShaderTextureLod: isWebGL2 || extensions.has( 'EXT_shader_texture_lod' ),\n\n\t\t\tcustomProgramCacheKey: material.customProgramCacheKey()\n\n\t\t};\n\n\t\treturn parameters;\n\n\t}\n\n\tfunction getProgramCacheKey( parameters ) {\n\n\t\tconst array = [];\n\n\t\tif ( parameters.shaderID ) {\n\n\t\t\tarray.push( parameters.shaderID );\n\n\t\t} else {\n\n\t\t\tarray.push( parameters.customVertexShaderID );\n\t\t\tarray.push( parameters.customFragmentShaderID );\n\n\t\t}\n\n\t\tif ( parameters.defines !== undefined ) {\n\n\t\t\tfor ( const name in parameters.defines ) {\n\n\t\t\t\tarray.push( name );\n\t\t\t\tarray.push( parameters.defines[ name ] );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( parameters.isRawShaderMaterial === false ) {\n\n\t\t\tgetProgramCacheKeyParameters( array, parameters );\n\t\t\tgetProgramCacheKeyBooleans( array, parameters );\n\t\t\tarray.push( renderer.outputEncoding );\n\n\t\t}\n\n\t\tarray.push( parameters.customProgramCacheKey );\n\n\t\treturn array.join();\n\n\t}\n\n\tfunction getProgramCacheKeyParameters( array, parameters ) {\n\n\t\tarray.push( parameters.precision );\n\t\tarray.push( parameters.outputEncoding );\n\t\tarray.push( parameters.envMapMode );\n\t\tarray.push( parameters.envMapCubeUVHeight );\n\t\tarray.push( parameters.combine );\n\t\tarray.push( parameters.vertexUvs );\n\t\tarray.push( parameters.fogExp2 );\n\t\tarray.push( parameters.sizeAttenuation );\n\t\tarray.push( parameters.maxBones );\n\t\tarray.push( parameters.morphTargetsCount );\n\t\tarray.push( parameters.morphAttributeCount );\n\t\tarray.push( parameters.numDirLights );\n\t\tarray.push( parameters.numPointLights );\n\t\tarray.push( parameters.numSpotLights );\n\t\tarray.push( parameters.numHemiLights );\n\t\tarray.push( parameters.numRectAreaLights );\n\t\tarray.push( parameters.numDirLightShadows );\n\t\tarray.push( parameters.numPointLightShadows );\n\t\tarray.push( parameters.numSpotLightShadows );\n\t\tarray.push( parameters.shadowMapType );\n\t\tarray.push( parameters.toneMapping );\n\t\tarray.push( parameters.numClippingPlanes );\n\t\tarray.push( parameters.numClipIntersection );\n\n\t}\n\n\tfunction getProgramCacheKeyBooleans( array, parameters ) {\n\n\t\t_programLayers.disableAll();\n\n\t\tif ( parameters.isWebGL2 )\n\t\t\t_programLayers.enable( 0 );\n\t\tif ( parameters.supportsVertexTextures )\n\t\t\t_programLayers.enable( 1 );\n\t\tif ( parameters.instancing )\n\t\t\t_programLayers.enable( 2 );\n\t\tif ( parameters.instancingColor )\n\t\t\t_programLayers.enable( 3 );\n\t\tif ( parameters.map )\n\t\t\t_programLayers.enable( 4 );\n\t\tif ( parameters.matcap )\n\t\t\t_programLayers.enable( 5 );\n\t\tif ( parameters.envMap )\n\t\t\t_programLayers.enable( 6 );\n\t\tif ( parameters.lightMap )\n\t\t\t_programLayers.enable( 7 );\n\t\tif ( parameters.aoMap )\n\t\t\t_programLayers.enable( 8 );\n\t\tif ( parameters.emissiveMap )\n\t\t\t_programLayers.enable( 9 );\n\t\tif ( parameters.bumpMap )\n\t\t\t_programLayers.enable( 10 );\n\t\tif ( parameters.normalMap )\n\t\t\t_programLayers.enable( 11 );\n\t\tif ( parameters.objectSpaceNormalMap )\n\t\t\t_programLayers.enable( 12 );\n\t\tif ( parameters.tangentSpaceNormalMap )\n\t\t\t_programLayers.enable( 13 );\n\t\tif ( parameters.clearcoat )\n\t\t\t_programLayers.enable( 14 );\n\t\tif ( parameters.clearcoatMap )\n\t\t\t_programLayers.enable( 15 );\n\t\tif ( parameters.clearcoatRoughnessMap )\n\t\t\t_programLayers.enable( 16 );\n\t\tif ( parameters.clearcoatNormalMap )\n\t\t\t_programLayers.enable( 17 );\n\t\tif ( parameters.displacementMap )\n\t\t\t_programLayers.enable( 18 );\n\t\tif ( parameters.specularMap )\n\t\t\t_programLayers.enable( 19 );\n\t\tif ( parameters.roughnessMap )\n\t\t\t_programLayers.enable( 20 );\n\t\tif ( parameters.metalnessMap )\n\t\t\t_programLayers.enable( 21 );\n\t\tif ( parameters.gradientMap )\n\t\t\t_programLayers.enable( 22 );\n\t\tif ( parameters.alphaMap )\n\t\t\t_programLayers.enable( 23 );\n\t\tif ( parameters.alphaTest )\n\t\t\t_programLayers.enable( 24 );\n\t\tif ( parameters.vertexColors )\n\t\t\t_programLayers.enable( 25 );\n\t\tif ( parameters.vertexAlphas )\n\t\t\t_programLayers.enable( 26 );\n\t\tif ( parameters.vertexUvs )\n\t\t\t_programLayers.enable( 27 );\n\t\tif ( parameters.vertexTangents )\n\t\t\t_programLayers.enable( 28 );\n\t\tif ( parameters.uvsVertexOnly )\n\t\t\t_programLayers.enable( 29 );\n\t\tif ( parameters.fog )\n\t\t\t_programLayers.enable( 30 );\n\n\t\tarray.push( _programLayers.mask );\n\t\t_programLayers.disableAll();\n\n\t\tif ( parameters.useFog )\n\t\t\t_programLayers.enable( 0 );\n\t\tif ( parameters.flatShading )\n\t\t\t_programLayers.enable( 1 );\n\t\tif ( parameters.logarithmicDepthBuffer )\n\t\t\t_programLayers.enable( 2 );\n\t\tif ( parameters.skinning )\n\t\t\t_programLayers.enable( 3 );\n\t\tif ( parameters.useVertexTexture )\n\t\t\t_programLayers.enable( 4 );\n\t\tif ( parameters.morphTargets )\n\t\t\t_programLayers.enable( 5 );\n\t\tif ( parameters.morphNormals )\n\t\t\t_programLayers.enable( 6 );\n\t\tif ( parameters.morphColors )\n\t\t\t_programLayers.enable( 7 );\n\t\tif ( parameters.premultipliedAlpha )\n\t\t\t_programLayers.enable( 8 );\n\t\tif ( parameters.shadowMapEnabled )\n\t\t\t_programLayers.enable( 9 );\n\t\tif ( parameters.physicallyCorrectLights )\n\t\t\t_programLayers.enable( 10 );\n\t\tif ( parameters.doubleSided )\n\t\t\t_programLayers.enable( 11 );\n\t\tif ( parameters.flipSided )\n\t\t\t_programLayers.enable( 12 );\n\t\tif ( parameters.depthPacking )\n\t\t\t_programLayers.enable( 13 );\n\t\tif ( parameters.dithering )\n\t\t\t_programLayers.enable( 14 );\n\t\tif ( parameters.specularIntensityMap )\n\t\t\t_programLayers.enable( 15 );\n\t\tif ( parameters.specularColorMap )\n\t\t\t_programLayers.enable( 16 );\n\t\tif ( parameters.transmission )\n\t\t\t_programLayers.enable( 17 );\n\t\tif ( parameters.transmissionMap )\n\t\t\t_programLayers.enable( 18 );\n\t\tif ( parameters.thicknessMap )\n\t\t\t_programLayers.enable( 19 );\n\t\tif ( parameters.sheen )\n\t\t\t_programLayers.enable( 20 );\n\t\tif ( parameters.sheenColorMap )\n\t\t\t_programLayers.enable( 21 );\n\t\tif ( parameters.sheenRoughnessMap )\n\t\t\t_programLayers.enable( 22 );\n\t\tif ( parameters.decodeVideoTexture )\n\t\t\t_programLayers.enable( 23 );\n\t\tif ( parameters.opaque )\n\t\t\t_programLayers.enable( 24 );\n\n\t\tarray.push( _programLayers.mask );\n\n\t}\n\n\tfunction getUniforms( material ) {\n\n\t\tconst shaderID = shaderIDs[ material.type ];\n\t\tlet uniforms;\n\n\t\tif ( shaderID ) {\n\n\t\t\tconst shader = ShaderLib[ shaderID ];\n\t\t\tuniforms = UniformsUtils.clone( shader.uniforms );\n\n\t\t} else {\n\n\t\t\tuniforms = material.uniforms;\n\n\t\t}\n\n\t\treturn uniforms;\n\n\t}\n\n\tfunction acquireProgram( parameters, cacheKey ) {\n\n\t\tlet program;\n\n\t\t// Check if code has been already compiled\n\t\tfor ( let p = 0, pl = programs.length; p < pl; p ++ ) {\n\n\t\t\tconst preexistingProgram = programs[ p ];\n\n\t\t\tif ( preexistingProgram.cacheKey === cacheKey ) {\n\n\t\t\t\tprogram = preexistingProgram;\n\t\t\t\t++ program.usedTimes;\n\n\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( program === undefined ) {\n\n\t\t\tprogram = new WebGLProgram( renderer, cacheKey, parameters, bindingStates );\n\t\t\tprograms.push( program );\n\n\t\t}\n\n\t\treturn program;\n\n\t}\n\n\tfunction releaseProgram( program ) {\n\n\t\tif ( -- program.usedTimes === 0 ) {\n\n\t\t\t// Remove from unordered set\n\t\t\tconst i = programs.indexOf( program );\n\t\t\tprograms[ i ] = programs[ programs.length - 1 ];\n\t\t\tprograms.pop();\n\n\t\t\t// Free WebGL resources\n\t\t\tprogram.destroy();\n\n\t\t}\n\n\t}\n\n\tfunction releaseShaderCache( material ) {\n\n\t\t_customShaders.remove( material );\n\n\t}\n\n\tfunction dispose() {\n\n\t\t_customShaders.dispose();\n\n\t}\n\n\treturn {\n\t\tgetParameters: getParameters,\n\t\tgetProgramCacheKey: getProgramCacheKey,\n\t\tgetUniforms: getUniforms,\n\t\tacquireProgram: acquireProgram,\n\t\treleaseProgram: releaseProgram,\n\t\treleaseShaderCache: releaseShaderCache,\n\t\t// Exposed for resource monitoring & error feedback via renderer.info:\n\t\tprograms: programs,\n\t\tdispose: dispose\n\t};\n\n}\n\nfunction WebGLProperties() {\n\n\tlet properties = new WeakMap();\n\n\tfunction get( object ) {\n\n\t\tlet map = properties.get( object );\n\n\t\tif ( map === undefined ) {\n\n\t\t\tmap = {};\n\t\t\tproperties.set( object, map );\n\n\t\t}\n\n\t\treturn map;\n\n\t}\n\n\tfunction remove( object ) {\n\n\t\tproperties.delete( object );\n\n\t}\n\n\tfunction update( object, key, value ) {\n\n\t\tproperties.get( object )[ key ] = value;\n\n\t}\n\n\tfunction dispose() {\n\n\t\tproperties = new WeakMap();\n\n\t}\n\n\treturn {\n\t\tget: get,\n\t\tremove: remove,\n\t\tupdate: update,\n\t\tdispose: dispose\n\t};\n\n}\n\nfunction painterSortStable( a, b ) {\n\n\tif ( a.groupOrder !== b.groupOrder ) {\n\n\t\treturn a.groupOrder - b.groupOrder;\n\n\t} else if ( a.renderOrder !== b.renderOrder ) {\n\n\t\treturn a.renderOrder - b.renderOrder;\n\n\t} else if ( a.material.id !== b.material.id ) {\n\n\t\treturn a.material.id - b.material.id;\n\n\t} else if ( a.z !== b.z ) {\n\n\t\treturn a.z - b.z;\n\n\t} else {\n\n\t\treturn a.id - b.id;\n\n\t}\n\n}\n\nfunction reversePainterSortStable( a, b ) {\n\n\tif ( a.groupOrder !== b.groupOrder ) {\n\n\t\treturn a.groupOrder - b.groupOrder;\n\n\t} else if ( a.renderOrder !== b.renderOrder ) {\n\n\t\treturn a.renderOrder - b.renderOrder;\n\n\t} else if ( a.z !== b.z ) {\n\n\t\treturn b.z - a.z;\n\n\t} else {\n\n\t\treturn a.id - b.id;\n\n\t}\n\n}\n\n\nfunction WebGLRenderList() {\n\n\tconst renderItems = [];\n\tlet renderItemsIndex = 0;\n\n\tconst opaque = [];\n\tconst transmissive = [];\n\tconst transparent = [];\n\n\tfunction init() {\n\n\t\trenderItemsIndex = 0;\n\n\t\topaque.length = 0;\n\t\ttransmissive.length = 0;\n\t\ttransparent.length = 0;\n\n\t}\n\n\tfunction getNextRenderItem( object, geometry, material, groupOrder, z, group ) {\n\n\t\tlet renderItem = renderItems[ renderItemsIndex ];\n\n\t\tif ( renderItem === undefined ) {\n\n\t\t\trenderItem = {\n\t\t\t\tid: object.id,\n\t\t\t\tobject: object,\n\t\t\t\tgeometry: geometry,\n\t\t\t\tmaterial: material,\n\t\t\t\tgroupOrder: groupOrder,\n\t\t\t\trenderOrder: object.renderOrder,\n\t\t\t\tz: z,\n\t\t\t\tgroup: group\n\t\t\t};\n\n\t\t\trenderItems[ renderItemsIndex ] = renderItem;\n\n\t\t} else {\n\n\t\t\trenderItem.id = object.id;\n\t\t\trenderItem.object = object;\n\t\t\trenderItem.geometry = geometry;\n\t\t\trenderItem.material = material;\n\t\t\trenderItem.groupOrder = groupOrder;\n\t\t\trenderItem.renderOrder = object.renderOrder;\n\t\t\trenderItem.z = z;\n\t\t\trenderItem.group = group;\n\n\t\t}\n\n\t\trenderItemsIndex ++;\n\n\t\treturn renderItem;\n\n\t}\n\n\tfunction push( object, geometry, material, groupOrder, z, group ) {\n\n\t\tconst renderItem = getNextRenderItem( object, geometry, material, groupOrder, z, group );\n\n\t\tif ( material.transmission > 0.0 ) {\n\n\t\t\ttransmissive.push( renderItem );\n\n\t\t} else if ( material.transparent === true ) {\n\n\t\t\ttransparent.push( renderItem );\n\n\t\t} else {\n\n\t\t\topaque.push( renderItem );\n\n\t\t}\n\n\t}\n\n\tfunction unshift( object, geometry, material, groupOrder, z, group ) {\n\n\t\tconst renderItem = getNextRenderItem( object, geometry, material, groupOrder, z, group );\n\n\t\tif ( material.transmission > 0.0 ) {\n\n\t\t\ttransmissive.unshift( renderItem );\n\n\t\t} else if ( material.transparent === true ) {\n\n\t\t\ttransparent.unshift( renderItem );\n\n\t\t} else {\n\n\t\t\topaque.unshift( renderItem );\n\n\t\t}\n\n\t}\n\n\tfunction sort( customOpaqueSort, customTransparentSort ) {\n\n\t\tif ( opaque.length > 1 ) opaque.sort( customOpaqueSort || painterSortStable );\n\t\tif ( transmissive.length > 1 ) transmissive.sort( customTransparentSort || reversePainterSortStable );\n\t\tif ( transparent.length > 1 ) transparent.sort( customTransparentSort || reversePainterSortStable );\n\n\t}\n\n\tfunction finish() {\n\n\t\t// Clear references from inactive renderItems in the list\n\n\t\tfor ( let i = renderItemsIndex, il = renderItems.length; i < il; i ++ ) {\n\n\t\t\tconst renderItem = renderItems[ i ];\n\n\t\t\tif ( renderItem.id === null ) break;\n\n\t\t\trenderItem.id = null;\n\t\t\trenderItem.object = null;\n\t\t\trenderItem.geometry = null;\n\t\t\trenderItem.material = null;\n\t\t\trenderItem.group = null;\n\n\t\t}\n\n\t}\n\n\treturn {\n\n\t\topaque: opaque,\n\t\ttransmissive: transmissive,\n\t\ttransparent: transparent,\n\n\t\tinit: init,\n\t\tpush: push,\n\t\tunshift: unshift,\n\t\tfinish: finish,\n\n\t\tsort: sort\n\t};\n\n}\n\nfunction WebGLRenderLists() {\n\n\tlet lists = new WeakMap();\n\n\tfunction get( scene, renderCallDepth ) {\n\n\t\tlet list;\n\n\t\tif ( lists.has( scene ) === false ) {\n\n\t\t\tlist = new WebGLRenderList();\n\t\t\tlists.set( scene, [ list ] );\n\n\t\t} else {\n\n\t\t\tif ( renderCallDepth >= lists.get( scene ).length ) {\n\n\t\t\t\tlist = new WebGLRenderList();\n\t\t\t\tlists.get( scene ).push( list );\n\n\t\t\t} else {\n\n\t\t\t\tlist = lists.get( scene )[ renderCallDepth ];\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn list;\n\n\t}\n\n\tfunction dispose() {\n\n\t\tlists = new WeakMap();\n\n\t}\n\n\treturn {\n\t\tget: get,\n\t\tdispose: dispose\n\t};\n\n}\n\nfunction UniformsCache() {\n\n\tconst lights = {};\n\n\treturn {\n\n\t\tget: function ( light ) {\n\n\t\t\tif ( lights[ light.id ] !== undefined ) {\n\n\t\t\t\treturn lights[ light.id ];\n\n\t\t\t}\n\n\t\t\tlet uniforms;\n\n\t\t\tswitch ( light.type ) {\n\n\t\t\t\tcase 'DirectionalLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tdirection: new Vector3(),\n\t\t\t\t\t\tcolor: new Color()\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'SpotLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tposition: new Vector3(),\n\t\t\t\t\t\tdirection: new Vector3(),\n\t\t\t\t\t\tcolor: new Color(),\n\t\t\t\t\t\tdistance: 0,\n\t\t\t\t\t\tconeCos: 0,\n\t\t\t\t\t\tpenumbraCos: 0,\n\t\t\t\t\t\tdecay: 0\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'PointLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tposition: new Vector3(),\n\t\t\t\t\t\tcolor: new Color(),\n\t\t\t\t\t\tdistance: 0,\n\t\t\t\t\t\tdecay: 0\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'HemisphereLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tdirection: new Vector3(),\n\t\t\t\t\t\tskyColor: new Color(),\n\t\t\t\t\t\tgroundColor: new Color()\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'RectAreaLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tcolor: new Color(),\n\t\t\t\t\t\tposition: new Vector3(),\n\t\t\t\t\t\thalfWidth: new Vector3(),\n\t\t\t\t\t\thalfHeight: new Vector3()\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\tlights[ light.id ] = uniforms;\n\n\t\t\treturn uniforms;\n\n\t\t}\n\n\t};\n\n}\n\nfunction ShadowUniformsCache() {\n\n\tconst lights = {};\n\n\treturn {\n\n\t\tget: function ( light ) {\n\n\t\t\tif ( lights[ light.id ] !== undefined ) {\n\n\t\t\t\treturn lights[ light.id ];\n\n\t\t\t}\n\n\t\t\tlet uniforms;\n\n\t\t\tswitch ( light.type ) {\n\n\t\t\t\tcase 'DirectionalLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tshadowBias: 0,\n\t\t\t\t\t\tshadowNormalBias: 0,\n\t\t\t\t\t\tshadowRadius: 1,\n\t\t\t\t\t\tshadowMapSize: new Vector2()\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'SpotLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tshadowBias: 0,\n\t\t\t\t\t\tshadowNormalBias: 0,\n\t\t\t\t\t\tshadowRadius: 1,\n\t\t\t\t\t\tshadowMapSize: new Vector2()\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'PointLight':\n\t\t\t\t\tuniforms = {\n\t\t\t\t\t\tshadowBias: 0,\n\t\t\t\t\t\tshadowNormalBias: 0,\n\t\t\t\t\t\tshadowRadius: 1,\n\t\t\t\t\t\tshadowMapSize: new Vector2(),\n\t\t\t\t\t\tshadowCameraNear: 1,\n\t\t\t\t\t\tshadowCameraFar: 1000\n\t\t\t\t\t};\n\t\t\t\t\tbreak;\n\n\t\t\t\t// TODO (abelnation): set RectAreaLight shadow uniforms\n\n\t\t\t}\n\n\t\t\tlights[ light.id ] = uniforms;\n\n\t\t\treturn uniforms;\n\n\t\t}\n\n\t};\n\n}\n\n\n\nlet nextVersion = 0;\n\nfunction shadowCastingLightsFirst( lightA, lightB ) {\n\n\treturn ( lightB.castShadow ? 1 : 0 ) - ( lightA.castShadow ? 1 : 0 );\n\n}\n\nfunction WebGLLights( extensions, capabilities ) {\n\n\tconst cache = new UniformsCache();\n\n\tconst shadowCache = ShadowUniformsCache();\n\n\tconst state = {\n\n\t\tversion: 0,\n\n\t\thash: {\n\t\t\tdirectionalLength: - 1,\n\t\t\tpointLength: - 1,\n\t\t\tspotLength: - 1,\n\t\t\trectAreaLength: - 1,\n\t\t\themiLength: - 1,\n\n\t\t\tnumDirectionalShadows: - 1,\n\t\t\tnumPointShadows: - 1,\n\t\t\tnumSpotShadows: - 1\n\t\t},\n\n\t\tambient: [ 0, 0, 0 ],\n\t\tprobe: [],\n\t\tdirectional: [],\n\t\tdirectionalShadow: [],\n\t\tdirectionalShadowMap: [],\n\t\tdirectionalShadowMatrix: [],\n\t\tspot: [],\n\t\tspotShadow: [],\n\t\tspotShadowMap: [],\n\t\tspotShadowMatrix: [],\n\t\trectArea: [],\n\t\trectAreaLTC1: null,\n\t\trectAreaLTC2: null,\n\t\tpoint: [],\n\t\tpointShadow: [],\n\t\tpointShadowMap: [],\n\t\tpointShadowMatrix: [],\n\t\themi: []\n\n\t};\n\n\tfor ( let i = 0; i < 9; i ++ ) state.probe.push( new Vector3() );\n\n\tconst vector3 = new Vector3();\n\tconst matrix4 = new Matrix4();\n\tconst matrix42 = new Matrix4();\n\n\tfunction setup( lights, physicallyCorrectLights ) {\n\n\t\tlet r = 0, g = 0, b = 0;\n\n\t\tfor ( let i = 0; i < 9; i ++ ) state.probe[ i ].set( 0, 0, 0 );\n\n\t\tlet directionalLength = 0;\n\t\tlet pointLength = 0;\n\t\tlet spotLength = 0;\n\t\tlet rectAreaLength = 0;\n\t\tlet hemiLength = 0;\n\n\t\tlet numDirectionalShadows = 0;\n\t\tlet numPointShadows = 0;\n\t\tlet numSpotShadows = 0;\n\n\t\tlights.sort( shadowCastingLightsFirst );\n\n\t\t// artist-friendly light intensity scaling factor\n\t\tconst scaleFactor = ( physicallyCorrectLights !== true ) ? Math.PI : 1;\n\n\t\tfor ( let i = 0, l = lights.length; i < l; i ++ ) {\n\n\t\t\tconst light = lights[ i ];\n\n\t\t\tconst color = light.color;\n\t\t\tconst intensity = light.intensity;\n\t\t\tconst distance = light.distance;\n\n\t\t\tconst shadowMap = ( light.shadow && light.shadow.map ) ? light.shadow.map.texture : null;\n\n\t\t\tif ( light.isAmbientLight ) {\n\n\t\t\t\tr += color.r * intensity * scaleFactor;\n\t\t\t\tg += color.g * intensity * scaleFactor;\n\t\t\t\tb += color.b * intensity * scaleFactor;\n\n\t\t\t} else if ( light.isLightProbe ) {\n\n\t\t\t\tfor ( let j = 0; j < 9; j ++ ) {\n\n\t\t\t\t\tstate.probe[ j ].addScaledVector( light.sh.coefficients[ j ], intensity );\n\n\t\t\t\t}\n\n\t\t\t} else if ( light.isDirectionalLight ) {\n\n\t\t\t\tconst uniforms = cache.get( light );\n\n\t\t\t\tuniforms.color.copy( light.color ).multiplyScalar( light.intensity * scaleFactor );\n\n\t\t\t\tif ( light.castShadow ) {\n\n\t\t\t\t\tconst shadow = light.shadow;\n\n\t\t\t\t\tconst shadowUniforms = shadowCache.get( light );\n\n\t\t\t\t\tshadowUniforms.shadowBias = shadow.bias;\n\t\t\t\t\tshadowUniforms.shadowNormalBias = shadow.normalBias;\n\t\t\t\t\tshadowUniforms.shadowRadius = shadow.radius;\n\t\t\t\t\tshadowUniforms.shadowMapSize = shadow.mapSize;\n\n\t\t\t\t\tstate.directionalShadow[ directionalLength ] = shadowUniforms;\n\t\t\t\t\tstate.directionalShadowMap[ directionalLength ] = shadowMap;\n\t\t\t\t\tstate.directionalShadowMatrix[ directionalLength ] = light.shadow.matrix;\n\n\t\t\t\t\tnumDirectionalShadows ++;\n\n\t\t\t\t}\n\n\t\t\t\tstate.directional[ directionalLength ] = uniforms;\n\n\t\t\t\tdirectionalLength ++;\n\n\t\t\t} else if ( light.isSpotLight ) {\n\n\t\t\t\tconst uniforms = cache.get( light );\n\n\t\t\t\tuniforms.position.setFromMatrixPosition( light.matrixWorld );\n\n\t\t\t\tuniforms.color.copy( color ).multiplyScalar( intensity * scaleFactor );\n\t\t\t\tuniforms.distance = distance;\n\n\t\t\t\tuniforms.coneCos = Math.cos( light.angle );\n\t\t\t\tuniforms.penumbraCos = Math.cos( light.angle * ( 1 - light.penumbra ) );\n\t\t\t\tuniforms.decay = light.decay;\n\n\t\t\t\tif ( light.castShadow ) {\n\n\t\t\t\t\tconst shadow = light.shadow;\n\n\t\t\t\t\tconst shadowUniforms = shadowCache.get( light );\n\n\t\t\t\t\tshadowUniforms.shadowBias = shadow.bias;\n\t\t\t\t\tshadowUniforms.shadowNormalBias = shadow.normalBias;\n\t\t\t\t\tshadowUniforms.shadowRadius = shadow.radius;\n\t\t\t\t\tshadowUniforms.shadowMapSize = shadow.mapSize;\n\n\t\t\t\t\tstate.spotShadow[ spotLength ] = shadowUniforms;\n\t\t\t\t\tstate.spotShadowMap[ spotLength ] = shadowMap;\n\t\t\t\t\tstate.spotShadowMatrix[ spotLength ] = light.shadow.matrix;\n\n\t\t\t\t\tnumSpotShadows ++;\n\n\t\t\t\t}\n\n\t\t\t\tstate.spot[ spotLength ] = uniforms;\n\n\t\t\t\tspotLength ++;\n\n\t\t\t} else if ( light.isRectAreaLight ) {\n\n\t\t\t\tconst uniforms = cache.get( light );\n\n\t\t\t\t// (a) intensity is the total visible light emitted\n\t\t\t\t//uniforms.color.copy( color ).multiplyScalar( intensity / ( light.width * light.height * Math.PI ) );\n\n\t\t\t\t// (b) intensity is the brightness of the light\n\t\t\t\tuniforms.color.copy( color ).multiplyScalar( intensity );\n\n\t\t\t\tuniforms.halfWidth.set( light.width * 0.5, 0.0, 0.0 );\n\t\t\t\tuniforms.halfHeight.set( 0.0, light.height * 0.5, 0.0 );\n\n\t\t\t\tstate.rectArea[ rectAreaLength ] = uniforms;\n\n\t\t\t\trectAreaLength ++;\n\n\t\t\t} else if ( light.isPointLight ) {\n\n\t\t\t\tconst uniforms = cache.get( light );\n\n\t\t\t\tuniforms.color.copy( light.color ).multiplyScalar( light.intensity * scaleFactor );\n\t\t\t\tuniforms.distance = light.distance;\n\t\t\t\tuniforms.decay = light.decay;\n\n\t\t\t\tif ( light.castShadow ) {\n\n\t\t\t\t\tconst shadow = light.shadow;\n\n\t\t\t\t\tconst shadowUniforms = shadowCache.get( light );\n\n\t\t\t\t\tshadowUniforms.shadowBias = shadow.bias;\n\t\t\t\t\tshadowUniforms.shadowNormalBias = shadow.normalBias;\n\t\t\t\t\tshadowUniforms.shadowRadius = shadow.radius;\n\t\t\t\t\tshadowUniforms.shadowMapSize = shadow.mapSize;\n\t\t\t\t\tshadowUniforms.shadowCameraNear = shadow.camera.near;\n\t\t\t\t\tshadowUniforms.shadowCameraFar = shadow.camera.far;\n\n\t\t\t\t\tstate.pointShadow[ pointLength ] = shadowUniforms;\n\t\t\t\t\tstate.pointShadowMap[ pointLength ] = shadowMap;\n\t\t\t\t\tstate.pointShadowMatrix[ pointLength ] = light.shadow.matrix;\n\n\t\t\t\t\tnumPointShadows ++;\n\n\t\t\t\t}\n\n\t\t\t\tstate.point[ pointLength ] = uniforms;\n\n\t\t\t\tpointLength ++;\n\n\t\t\t} else if ( light.isHemisphereLight ) {\n\n\t\t\t\tconst uniforms = cache.get( light );\n\n\t\t\t\tuniforms.skyColor.copy( light.color ).multiplyScalar( intensity * scaleFactor );\n\t\t\t\tuniforms.groundColor.copy( light.groundColor ).multiplyScalar( intensity * scaleFactor );\n\n\t\t\t\tstate.hemi[ hemiLength ] = uniforms;\n\n\t\t\t\themiLength ++;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( rectAreaLength > 0 ) {\n\n\t\t\tif ( capabilities.isWebGL2 ) {\n\n\t\t\t\t// WebGL 2\n\n\t\t\t\tstate.rectAreaLTC1 = UniformsLib.LTC_FLOAT_1;\n\t\t\t\tstate.rectAreaLTC2 = UniformsLib.LTC_FLOAT_2;\n\n\t\t\t} else {\n\n\t\t\t\t// WebGL 1\n\n\t\t\t\tif ( extensions.has( 'OES_texture_float_linear' ) === true ) {\n\n\t\t\t\t\tstate.rectAreaLTC1 = UniformsLib.LTC_FLOAT_1;\n\t\t\t\t\tstate.rectAreaLTC2 = UniformsLib.LTC_FLOAT_2;\n\n\t\t\t\t} else if ( extensions.has( 'OES_texture_half_float_linear' ) === true ) {\n\n\t\t\t\t\tstate.rectAreaLTC1 = UniformsLib.LTC_HALF_1;\n\t\t\t\t\tstate.rectAreaLTC2 = UniformsLib.LTC_HALF_2;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( 'THREE.WebGLRenderer: Unable to use RectAreaLight. Missing WebGL extensions.' );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tstate.ambient[ 0 ] = r;\n\t\tstate.ambient[ 1 ] = g;\n\t\tstate.ambient[ 2 ] = b;\n\n\t\tconst hash = state.hash;\n\n\t\tif ( hash.directionalLength !== directionalLength ||\n\t\t\thash.pointLength !== pointLength ||\n\t\t\thash.spotLength !== spotLength ||\n\t\t\thash.rectAreaLength !== rectAreaLength ||\n\t\t\thash.hemiLength !== hemiLength ||\n\t\t\thash.numDirectionalShadows !== numDirectionalShadows ||\n\t\t\thash.numPointShadows !== numPointShadows ||\n\t\t\thash.numSpotShadows !== numSpotShadows ) {\n\n\t\t\tstate.directional.length = directionalLength;\n\t\t\tstate.spot.length = spotLength;\n\t\t\tstate.rectArea.length = rectAreaLength;\n\t\t\tstate.point.length = pointLength;\n\t\t\tstate.hemi.length = hemiLength;\n\n\t\t\tstate.directionalShadow.length = numDirectionalShadows;\n\t\t\tstate.directionalShadowMap.length = numDirectionalShadows;\n\t\t\tstate.pointShadow.length = numPointShadows;\n\t\t\tstate.pointShadowMap.length = numPointShadows;\n\t\t\tstate.spotShadow.length = numSpotShadows;\n\t\t\tstate.spotShadowMap.length = numSpotShadows;\n\t\t\tstate.directionalShadowMatrix.length = numDirectionalShadows;\n\t\t\tstate.pointShadowMatrix.length = numPointShadows;\n\t\t\tstate.spotShadowMatrix.length = numSpotShadows;\n\n\t\t\thash.directionalLength = directionalLength;\n\t\t\thash.pointLength = pointLength;\n\t\t\thash.spotLength = spotLength;\n\t\t\thash.rectAreaLength = rectAreaLength;\n\t\t\thash.hemiLength = hemiLength;\n\n\t\t\thash.numDirectionalShadows = numDirectionalShadows;\n\t\t\thash.numPointShadows = numPointShadows;\n\t\t\thash.numSpotShadows = numSpotShadows;\n\n\t\t\tstate.version = nextVersion ++;\n\n\t\t}\n\n\t}\n\n\tfunction setupView( lights, camera ) {\n\n\t\tlet directionalLength = 0;\n\t\tlet pointLength = 0;\n\t\tlet spotLength = 0;\n\t\tlet rectAreaLength = 0;\n\t\tlet hemiLength = 0;\n\n\t\tconst viewMatrix = camera.matrixWorldInverse;\n\n\t\tfor ( let i = 0, l = lights.length; i < l; i ++ ) {\n\n\t\t\tconst light = lights[ i ];\n\n\t\t\tif ( light.isDirectionalLight ) {\n\n\t\t\t\tconst uniforms = state.directional[ directionalLength ];\n\n\t\t\t\tuniforms.direction.setFromMatrixPosition( light.matrixWorld );\n\t\t\t\tvector3.setFromMatrixPosition( light.target.matrixWorld );\n\t\t\t\tuniforms.direction.sub( vector3 );\n\t\t\t\tuniforms.direction.transformDirection( viewMatrix );\n\n\t\t\t\tdirectionalLength ++;\n\n\t\t\t} else if ( light.isSpotLight ) {\n\n\t\t\t\tconst uniforms = state.spot[ spotLength ];\n\n\t\t\t\tuniforms.position.setFromMatrixPosition( light.matrixWorld );\n\t\t\t\tuniforms.position.applyMatrix4( viewMatrix );\n\n\t\t\t\tuniforms.direction.setFromMatrixPosition( light.matrixWorld );\n\t\t\t\tvector3.setFromMatrixPosition( light.target.matrixWorld );\n\t\t\t\tuniforms.direction.sub( vector3 );\n\t\t\t\tuniforms.direction.transformDirection( viewMatrix );\n\n\t\t\t\tspotLength ++;\n\n\t\t\t} else if ( light.isRectAreaLight ) {\n\n\t\t\t\tconst uniforms = state.rectArea[ rectAreaLength ];\n\n\t\t\t\tuniforms.position.setFromMatrixPosition( light.matrixWorld );\n\t\t\t\tuniforms.position.applyMatrix4( viewMatrix );\n\n\t\t\t\t// extract local rotation of light to derive width/height half vectors\n\t\t\t\tmatrix42.identity();\n\t\t\t\tmatrix4.copy( light.matrixWorld );\n\t\t\t\tmatrix4.premultiply( viewMatrix );\n\t\t\t\tmatrix42.extractRotation( matrix4 );\n\n\t\t\t\tuniforms.halfWidth.set( light.width * 0.5, 0.0, 0.0 );\n\t\t\t\tuniforms.halfHeight.set( 0.0, light.height * 0.5, 0.0 );\n\n\t\t\t\tuniforms.halfWidth.applyMatrix4( matrix42 );\n\t\t\t\tuniforms.halfHeight.applyMatrix4( matrix42 );\n\n\t\t\t\trectAreaLength ++;\n\n\t\t\t} else if ( light.isPointLight ) {\n\n\t\t\t\tconst uniforms = state.point[ pointLength ];\n\n\t\t\t\tuniforms.position.setFromMatrixPosition( light.matrixWorld );\n\t\t\t\tuniforms.position.applyMatrix4( viewMatrix );\n\n\t\t\t\tpointLength ++;\n\n\t\t\t} else if ( light.isHemisphereLight ) {\n\n\t\t\t\tconst uniforms = state.hemi[ hemiLength ];\n\n\t\t\t\tuniforms.direction.setFromMatrixPosition( light.matrixWorld );\n\t\t\t\tuniforms.direction.transformDirection( viewMatrix );\n\t\t\t\tuniforms.direction.normalize();\n\n\t\t\t\themiLength ++;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\treturn {\n\t\tsetup: setup,\n\t\tsetupView: setupView,\n\t\tstate: state\n\t};\n\n}\n\nfunction WebGLRenderState( extensions, capabilities ) {\n\n\tconst lights = new WebGLLights( extensions, capabilities );\n\n\tconst lightsArray = [];\n\tconst shadowsArray = [];\n\n\tfunction init() {\n\n\t\tlightsArray.length = 0;\n\t\tshadowsArray.length = 0;\n\n\t}\n\n\tfunction pushLight( light ) {\n\n\t\tlightsArray.push( light );\n\n\t}\n\n\tfunction pushShadow( shadowLight ) {\n\n\t\tshadowsArray.push( shadowLight );\n\n\t}\n\n\tfunction setupLights( physicallyCorrectLights ) {\n\n\t\tlights.setup( lightsArray, physicallyCorrectLights );\n\n\t}\n\n\tfunction setupLightsView( camera ) {\n\n\t\tlights.setupView( lightsArray, camera );\n\n\t}\n\n\tconst state = {\n\t\tlightsArray: lightsArray,\n\t\tshadowsArray: shadowsArray,\n\n\t\tlights: lights\n\t};\n\n\treturn {\n\t\tinit: init,\n\t\tstate: state,\n\t\tsetupLights: setupLights,\n\t\tsetupLightsView: setupLightsView,\n\n\t\tpushLight: pushLight,\n\t\tpushShadow: pushShadow\n\t};\n\n}\n\nfunction WebGLRenderStates( extensions, capabilities ) {\n\n\tlet renderStates = new WeakMap();\n\n\tfunction get( scene, renderCallDepth = 0 ) {\n\n\t\tlet renderState;\n\n\t\tif ( renderStates.has( scene ) === false ) {\n\n\t\t\trenderState = new WebGLRenderState( extensions, capabilities );\n\t\t\trenderStates.set( scene, [ renderState ] );\n\n\t\t} else {\n\n\t\t\tif ( renderCallDepth >= renderStates.get( scene ).length ) {\n\n\t\t\t\trenderState = new WebGLRenderState( extensions, capabilities );\n\t\t\t\trenderStates.get( scene ).push( renderState );\n\n\t\t\t} else {\n\n\t\t\t\trenderState = renderStates.get( scene )[ renderCallDepth ];\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn renderState;\n\n\t}\n\n\tfunction dispose() {\n\n\t\trenderStates = new WeakMap();\n\n\t}\n\n\treturn {\n\t\tget: get,\n\t\tdispose: dispose\n\t};\n\n}\n\n/**\n * parameters = {\n *\n *  opacity: <float>,\n *\n *  map: new THREE.Texture( <Image> ),\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>\n * }\n */\n\nclass MeshDepthMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'MeshDepthMaterial';\n\n\t\tthis.depthPacking = BasicDepthPacking;\n\n\t\tthis.map = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\n\t\tthis.fog = false;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.depthPacking = source.depthPacking;\n\n\t\tthis.map = source.map;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshDepthMaterial.prototype.isMeshDepthMaterial = true;\n\n/**\n * parameters = {\n *\n *  referencePosition: <float>,\n *  nearDistance: <float>,\n *  farDistance: <float>,\n *\n *  map: new THREE.Texture( <Image> ),\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>\n *\n * }\n */\n\nclass MeshDistanceMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'MeshDistanceMaterial';\n\n\t\tthis.referencePosition = new Vector3();\n\t\tthis.nearDistance = 1;\n\t\tthis.farDistance = 1000;\n\n\t\tthis.map = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.fog = false;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.referencePosition.copy( source.referencePosition );\n\t\tthis.nearDistance = source.nearDistance;\n\t\tthis.farDistance = source.farDistance;\n\n\t\tthis.map = source.map;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshDistanceMaterial.prototype.isMeshDistanceMaterial = true;\n\nconst vertex = \"void main() {\\n\\tgl_Position = vec4( position, 1.0 );\\n}\";\n\nconst fragment = \"uniform sampler2D shadow_pass;\\nuniform vec2 resolution;\\nuniform float radius;\\n#include <packing>\\nvoid main() {\\n\\tconst float samples = float( VSM_SAMPLES );\\n\\tfloat mean = 0.0;\\n\\tfloat squared_mean = 0.0;\\n\\tfloat uvStride = samples <= 1.0 ? 0.0 : 2.0 / ( samples - 1.0 );\\n\\tfloat uvStart = samples <= 1.0 ? 0.0 : - 1.0;\\n\\tfor ( float i = 0.0; i < samples; i ++ ) {\\n\\t\\tfloat uvOffset = uvStart + i * uvStride;\\n\\t\\t#ifdef HORIZONTAL_PASS\\n\\t\\t\\tvec2 distribution = unpackRGBATo2Half( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( uvOffset, 0.0 ) * radius ) / resolution ) );\\n\\t\\t\\tmean += distribution.x;\\n\\t\\t\\tsquared_mean += distribution.y * distribution.y + distribution.x * distribution.x;\\n\\t\\t#else\\n\\t\\t\\tfloat depth = unpackRGBAToDepth( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( 0.0, uvOffset ) * radius ) / resolution ) );\\n\\t\\t\\tmean += depth;\\n\\t\\t\\tsquared_mean += depth * depth;\\n\\t\\t#endif\\n\\t}\\n\\tmean = mean / samples;\\n\\tsquared_mean = squared_mean / samples;\\n\\tfloat std_dev = sqrt( squared_mean - mean * mean );\\n\\tgl_FragColor = pack2HalfToRGBA( vec2( mean, std_dev ) );\\n}\";\n\nfunction WebGLShadowMap( _renderer, _objects, _capabilities ) {\n\n\tlet _frustum = new Frustum();\n\n\tconst _shadowMapSize = new Vector2(),\n\t\t_viewportSize = new Vector2(),\n\n\t\t_viewport = new Vector4(),\n\n\t\t_depthMaterial = new MeshDepthMaterial( { depthPacking: RGBADepthPacking } ),\n\t\t_distanceMaterial = new MeshDistanceMaterial(),\n\n\t\t_materialCache = {},\n\n\t\t_maxTextureSize = _capabilities.maxTextureSize;\n\n\tconst shadowSide = { 0: BackSide, 1: FrontSide, 2: DoubleSide };\n\n\tconst shadowMaterialVertical = new ShaderMaterial( {\n\t\tdefines: {\n\t\t\tVSM_SAMPLES: 8\n\t\t},\n\t\tuniforms: {\n\t\t\tshadow_pass: { value: null },\n\t\t\tresolution: { value: new Vector2() },\n\t\t\tradius: { value: 4.0 }\n\t\t},\n\n\t\tvertexShader: vertex,\n\t\tfragmentShader: fragment\n\n\t} );\n\n\tconst shadowMaterialHorizontal = shadowMaterialVertical.clone();\n\tshadowMaterialHorizontal.defines.HORIZONTAL_PASS = 1;\n\n\tconst fullScreenTri = new BufferGeometry();\n\tfullScreenTri.setAttribute(\n\t\t'position',\n\t\tnew BufferAttribute(\n\t\t\tnew Float32Array( [ - 1, - 1, 0.5, 3, - 1, 0.5, - 1, 3, 0.5 ] ),\n\t\t\t3\n\t\t)\n\t);\n\n\tconst fullScreenMesh = new Mesh( fullScreenTri, shadowMaterialVertical );\n\n\tconst scope = this;\n\n\tthis.enabled = false;\n\n\tthis.autoUpdate = true;\n\tthis.needsUpdate = false;\n\n\tthis.type = PCFShadowMap;\n\n\tthis.render = function ( lights, scene, camera ) {\n\n\t\tif ( scope.enabled === false ) return;\n\t\tif ( scope.autoUpdate === false && scope.needsUpdate === false ) return;\n\n\t\tif ( lights.length === 0 ) return;\n\n\t\tconst currentRenderTarget = _renderer.getRenderTarget();\n\t\tconst activeCubeFace = _renderer.getActiveCubeFace();\n\t\tconst activeMipmapLevel = _renderer.getActiveMipmapLevel();\n\n\t\tconst _state = _renderer.state;\n\n\t\t// Set GL state for depth map.\n\t\t_state.setBlending( NoBlending );\n\t\t_state.buffers.color.setClear( 1, 1, 1, 1 );\n\t\t_state.buffers.depth.setTest( true );\n\t\t_state.setScissorTest( false );\n\n\t\t// render depth map\n\n\t\tfor ( let i = 0, il = lights.length; i < il; i ++ ) {\n\n\t\t\tconst light = lights[ i ];\n\t\t\tconst shadow = light.shadow;\n\n\t\t\tif ( shadow === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLShadowMap:', light, 'has no shadow.' );\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\tif ( shadow.autoUpdate === false && shadow.needsUpdate === false ) continue;\n\n\t\t\t_shadowMapSize.copy( shadow.mapSize );\n\n\t\t\tconst shadowFrameExtents = shadow.getFrameExtents();\n\n\t\t\t_shadowMapSize.multiply( shadowFrameExtents );\n\n\t\t\t_viewportSize.copy( shadow.mapSize );\n\n\t\t\tif ( _shadowMapSize.x > _maxTextureSize || _shadowMapSize.y > _maxTextureSize ) {\n\n\t\t\t\tif ( _shadowMapSize.x > _maxTextureSize ) {\n\n\t\t\t\t\t_viewportSize.x = Math.floor( _maxTextureSize / shadowFrameExtents.x );\n\t\t\t\t\t_shadowMapSize.x = _viewportSize.x * shadowFrameExtents.x;\n\t\t\t\t\tshadow.mapSize.x = _viewportSize.x;\n\n\t\t\t\t}\n\n\t\t\t\tif ( _shadowMapSize.y > _maxTextureSize ) {\n\n\t\t\t\t\t_viewportSize.y = Math.floor( _maxTextureSize / shadowFrameExtents.y );\n\t\t\t\t\t_shadowMapSize.y = _viewportSize.y * shadowFrameExtents.y;\n\t\t\t\t\tshadow.mapSize.y = _viewportSize.y;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( shadow.map === null && ! shadow.isPointLightShadow && this.type === VSMShadowMap ) {\n\n\t\t\t\tconst pars = { minFilter: LinearFilter, magFilter: LinearFilter, format: RGBAFormat };\n\n\t\t\t\tshadow.map = new WebGLRenderTarget( _shadowMapSize.x, _shadowMapSize.y, pars );\n\t\t\t\tshadow.map.texture.name = light.name + '.shadowMap';\n\n\t\t\t\tshadow.mapPass = new WebGLRenderTarget( _shadowMapSize.x, _shadowMapSize.y, pars );\n\n\t\t\t\tshadow.camera.updateProjectionMatrix();\n\n\t\t\t}\n\n\t\t\tif ( shadow.map === null ) {\n\n\t\t\t\tconst pars = { minFilter: NearestFilter, magFilter: NearestFilter, format: RGBAFormat };\n\n\t\t\t\tshadow.map = new WebGLRenderTarget( _shadowMapSize.x, _shadowMapSize.y, pars );\n\t\t\t\tshadow.map.texture.name = light.name + '.shadowMap';\n\n\t\t\t\tshadow.camera.updateProjectionMatrix();\n\n\t\t\t}\n\n\t\t\t_renderer.setRenderTarget( shadow.map );\n\t\t\t_renderer.clear();\n\n\t\t\tconst viewportCount = shadow.getViewportCount();\n\n\t\t\tfor ( let vp = 0; vp < viewportCount; vp ++ ) {\n\n\t\t\t\tconst viewport = shadow.getViewport( vp );\n\n\t\t\t\t_viewport.set(\n\t\t\t\t\t_viewportSize.x * viewport.x,\n\t\t\t\t\t_viewportSize.y * viewport.y,\n\t\t\t\t\t_viewportSize.x * viewport.z,\n\t\t\t\t\t_viewportSize.y * viewport.w\n\t\t\t\t);\n\n\t\t\t\t_state.viewport( _viewport );\n\n\t\t\t\tshadow.updateMatrices( light, vp );\n\n\t\t\t\t_frustum = shadow.getFrustum();\n\n\t\t\t\trenderObject( scene, camera, shadow.camera, light, this.type );\n\n\t\t\t}\n\n\t\t\t// do blur pass for VSM\n\n\t\t\tif ( ! shadow.isPointLightShadow && this.type === VSMShadowMap ) {\n\n\t\t\t\tVSMPass( shadow, camera );\n\n\t\t\t}\n\n\t\t\tshadow.needsUpdate = false;\n\n\t\t}\n\n\t\tscope.needsUpdate = false;\n\n\t\t_renderer.setRenderTarget( currentRenderTarget, activeCubeFace, activeMipmapLevel );\n\n\t};\n\n\tfunction VSMPass( shadow, camera ) {\n\n\t\tconst geometry = _objects.update( fullScreenMesh );\n\n\t\tif ( shadowMaterialVertical.defines.VSM_SAMPLES !== shadow.blurSamples ) {\n\n\t\t\tshadowMaterialVertical.defines.VSM_SAMPLES = shadow.blurSamples;\n\t\t\tshadowMaterialHorizontal.defines.VSM_SAMPLES = shadow.blurSamples;\n\n\t\t\tshadowMaterialVertical.needsUpdate = true;\n\t\t\tshadowMaterialHorizontal.needsUpdate = true;\n\n\t\t}\n\n\t\t// vertical pass\n\n\t\tshadowMaterialVertical.uniforms.shadow_pass.value = shadow.map.texture;\n\t\tshadowMaterialVertical.uniforms.resolution.value = shadow.mapSize;\n\t\tshadowMaterialVertical.uniforms.radius.value = shadow.radius;\n\t\t_renderer.setRenderTarget( shadow.mapPass );\n\t\t_renderer.clear();\n\t\t_renderer.renderBufferDirect( camera, null, geometry, shadowMaterialVertical, fullScreenMesh, null );\n\n\t\t// horizontal pass\n\n\t\tshadowMaterialHorizontal.uniforms.shadow_pass.value = shadow.mapPass.texture;\n\t\tshadowMaterialHorizontal.uniforms.resolution.value = shadow.mapSize;\n\t\tshadowMaterialHorizontal.uniforms.radius.value = shadow.radius;\n\t\t_renderer.setRenderTarget( shadow.map );\n\t\t_renderer.clear();\n\t\t_renderer.renderBufferDirect( camera, null, geometry, shadowMaterialHorizontal, fullScreenMesh, null );\n\n\t}\n\n\tfunction getDepthMaterial( object, material, light, shadowCameraNear, shadowCameraFar, type ) {\n\n\t\tlet result = null;\n\n\t\tconst customMaterial = ( light.isPointLight === true ) ? object.customDistanceMaterial : object.customDepthMaterial;\n\n\t\tif ( customMaterial !== undefined ) {\n\n\t\t\tresult = customMaterial;\n\n\t\t} else {\n\n\t\t\tresult = ( light.isPointLight === true ) ? _distanceMaterial : _depthMaterial;\n\n\t\t}\n\n\t\tif ( ( _renderer.localClippingEnabled && material.clipShadows === true && material.clippingPlanes.length !== 0 ) ||\n\t\t\t( material.displacementMap && material.displacementScale !== 0 ) ||\n\t\t\t( material.alphaMap && material.alphaTest > 0 ) ) {\n\n\t\t\t// in this case we need a unique material instance reflecting the\n\t\t\t// appropriate state\n\n\t\t\tconst keyA = result.uuid, keyB = material.uuid;\n\n\t\t\tlet materialsForVariant = _materialCache[ keyA ];\n\n\t\t\tif ( materialsForVariant === undefined ) {\n\n\t\t\t\tmaterialsForVariant = {};\n\t\t\t\t_materialCache[ keyA ] = materialsForVariant;\n\n\t\t\t}\n\n\t\t\tlet cachedMaterial = materialsForVariant[ keyB ];\n\n\t\t\tif ( cachedMaterial === undefined ) {\n\n\t\t\t\tcachedMaterial = result.clone();\n\t\t\t\tmaterialsForVariant[ keyB ] = cachedMaterial;\n\n\t\t\t}\n\n\t\t\tresult = cachedMaterial;\n\n\t\t}\n\n\t\tresult.visible = material.visible;\n\t\tresult.wireframe = material.wireframe;\n\n\t\tif ( type === VSMShadowMap ) {\n\n\t\t\tresult.side = ( material.shadowSide !== null ) ? material.shadowSide : material.side;\n\n\t\t} else {\n\n\t\t\tresult.side = ( material.shadowSide !== null ) ? material.shadowSide : shadowSide[ material.side ];\n\n\t\t}\n\n\t\tresult.alphaMap = material.alphaMap;\n\t\tresult.alphaTest = material.alphaTest;\n\n\t\tresult.clipShadows = material.clipShadows;\n\t\tresult.clippingPlanes = material.clippingPlanes;\n\t\tresult.clipIntersection = material.clipIntersection;\n\n\t\tresult.displacementMap = material.displacementMap;\n\t\tresult.displacementScale = material.displacementScale;\n\t\tresult.displacementBias = material.displacementBias;\n\n\t\tresult.wireframeLinewidth = material.wireframeLinewidth;\n\t\tresult.linewidth = material.linewidth;\n\n\t\tif ( light.isPointLight === true && result.isMeshDistanceMaterial === true ) {\n\n\t\t\tresult.referencePosition.setFromMatrixPosition( light.matrixWorld );\n\t\t\tresult.nearDistance = shadowCameraNear;\n\t\t\tresult.farDistance = shadowCameraFar;\n\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n\tfunction renderObject( object, camera, shadowCamera, light, type ) {\n\n\t\tif ( object.visible === false ) return;\n\n\t\tconst visible = object.layers.test( camera.layers );\n\n\t\tif ( visible && ( object.isMesh || object.isLine || object.isPoints ) ) {\n\n\t\t\tif ( ( object.castShadow || ( object.receiveShadow && type === VSMShadowMap ) ) && ( ! object.frustumCulled || _frustum.intersectsObject( object ) ) ) {\n\n\t\t\t\tobject.modelViewMatrix.multiplyMatrices( shadowCamera.matrixWorldInverse, object.matrixWorld );\n\n\t\t\t\tconst geometry = _objects.update( object );\n\t\t\t\tconst material = object.material;\n\n\t\t\t\tif ( Array.isArray( material ) ) {\n\n\t\t\t\t\tconst groups = geometry.groups;\n\n\t\t\t\t\tfor ( let k = 0, kl = groups.length; k < kl; k ++ ) {\n\n\t\t\t\t\t\tconst group = groups[ k ];\n\t\t\t\t\t\tconst groupMaterial = material[ group.materialIndex ];\n\n\t\t\t\t\t\tif ( groupMaterial && groupMaterial.visible ) {\n\n\t\t\t\t\t\t\tconst depthMaterial = getDepthMaterial( object, groupMaterial, light, shadowCamera.near, shadowCamera.far, type );\n\n\t\t\t\t\t\t\t_renderer.renderBufferDirect( shadowCamera, null, geometry, depthMaterial, object, group );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t} else if ( material.visible ) {\n\n\t\t\t\t\tconst depthMaterial = getDepthMaterial( object, material, light, shadowCamera.near, shadowCamera.far, type );\n\n\t\t\t\t\t_renderer.renderBufferDirect( shadowCamera, null, geometry, depthMaterial, object, null );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst children = object.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\trenderObject( children[ i ], camera, shadowCamera, light, type );\n\n\t\t}\n\n\t}\n\n}\n\nfunction WebGLState( gl, extensions, capabilities ) {\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\n\tfunction ColorBuffer() {\n\n\t\tlet locked = false;\n\n\t\tconst color = new Vector4();\n\t\tlet currentColorMask = null;\n\t\tconst currentColorClear = new Vector4( 0, 0, 0, 0 );\n\n\t\treturn {\n\n\t\t\tsetMask: function ( colorMask ) {\n\n\t\t\t\tif ( currentColorMask !== colorMask && ! locked ) {\n\n\t\t\t\t\tgl.colorMask( colorMask, colorMask, colorMask, colorMask );\n\t\t\t\t\tcurrentColorMask = colorMask;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetLocked: function ( lock ) {\n\n\t\t\t\tlocked = lock;\n\n\t\t\t},\n\n\t\t\tsetClear: function ( r, g, b, a, premultipliedAlpha ) {\n\n\t\t\t\tif ( premultipliedAlpha === true ) {\n\n\t\t\t\t\tr *= a; g *= a; b *= a;\n\n\t\t\t\t}\n\n\t\t\t\tcolor.set( r, g, b, a );\n\n\t\t\t\tif ( currentColorClear.equals( color ) === false ) {\n\n\t\t\t\t\tgl.clearColor( r, g, b, a );\n\t\t\t\t\tcurrentColorClear.copy( color );\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\treset: function () {\n\n\t\t\t\tlocked = false;\n\n\t\t\t\tcurrentColorMask = null;\n\t\t\t\tcurrentColorClear.set( - 1, 0, 0, 0 ); // set to invalid state\n\n\t\t\t}\n\n\t\t};\n\n\t}\n\n\tfunction DepthBuffer() {\n\n\t\tlet locked = false;\n\n\t\tlet currentDepthMask = null;\n\t\tlet currentDepthFunc = null;\n\t\tlet currentDepthClear = null;\n\n\t\treturn {\n\n\t\t\tsetTest: function ( depthTest ) {\n\n\t\t\t\tif ( depthTest ) {\n\n\t\t\t\t\tenable( 2929 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tdisable( 2929 );\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetMask: function ( depthMask ) {\n\n\t\t\t\tif ( currentDepthMask !== depthMask && ! locked ) {\n\n\t\t\t\t\tgl.depthMask( depthMask );\n\t\t\t\t\tcurrentDepthMask = depthMask;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetFunc: function ( depthFunc ) {\n\n\t\t\t\tif ( currentDepthFunc !== depthFunc ) {\n\n\t\t\t\t\tif ( depthFunc ) {\n\n\t\t\t\t\t\tswitch ( depthFunc ) {\n\n\t\t\t\t\t\t\tcase NeverDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 512 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase AlwaysDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 519 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase LessDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 513 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase LessEqualDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 515 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase EqualDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 514 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase GreaterEqualDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 518 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase GreaterDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 516 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tcase NotEqualDepth:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 517 );\n\t\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t\tdefault:\n\n\t\t\t\t\t\t\t\tgl.depthFunc( 515 );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tgl.depthFunc( 515 );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tcurrentDepthFunc = depthFunc;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetLocked: function ( lock ) {\n\n\t\t\t\tlocked = lock;\n\n\t\t\t},\n\n\t\t\tsetClear: function ( depth ) {\n\n\t\t\t\tif ( currentDepthClear !== depth ) {\n\n\t\t\t\t\tgl.clearDepth( depth );\n\t\t\t\t\tcurrentDepthClear = depth;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\treset: function () {\n\n\t\t\t\tlocked = false;\n\n\t\t\t\tcurrentDepthMask = null;\n\t\t\t\tcurrentDepthFunc = null;\n\t\t\t\tcurrentDepthClear = null;\n\n\t\t\t}\n\n\t\t};\n\n\t}\n\n\tfunction StencilBuffer() {\n\n\t\tlet locked = false;\n\n\t\tlet currentStencilMask = null;\n\t\tlet currentStencilFunc = null;\n\t\tlet currentStencilRef = null;\n\t\tlet currentStencilFuncMask = null;\n\t\tlet currentStencilFail = null;\n\t\tlet currentStencilZFail = null;\n\t\tlet currentStencilZPass = null;\n\t\tlet currentStencilClear = null;\n\n\t\treturn {\n\n\t\t\tsetTest: function ( stencilTest ) {\n\n\t\t\t\tif ( ! locked ) {\n\n\t\t\t\t\tif ( stencilTest ) {\n\n\t\t\t\t\t\tenable( 2960 );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tdisable( 2960 );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetMask: function ( stencilMask ) {\n\n\t\t\t\tif ( currentStencilMask !== stencilMask && ! locked ) {\n\n\t\t\t\t\tgl.stencilMask( stencilMask );\n\t\t\t\t\tcurrentStencilMask = stencilMask;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetFunc: function ( stencilFunc, stencilRef, stencilMask ) {\n\n\t\t\t\tif ( currentStencilFunc !== stencilFunc ||\n\t\t\t\t     currentStencilRef !== stencilRef ||\n\t\t\t\t     currentStencilFuncMask !== stencilMask ) {\n\n\t\t\t\t\tgl.stencilFunc( stencilFunc, stencilRef, stencilMask );\n\n\t\t\t\t\tcurrentStencilFunc = stencilFunc;\n\t\t\t\t\tcurrentStencilRef = stencilRef;\n\t\t\t\t\tcurrentStencilFuncMask = stencilMask;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetOp: function ( stencilFail, stencilZFail, stencilZPass ) {\n\n\t\t\t\tif ( currentStencilFail !== stencilFail ||\n\t\t\t\t     currentStencilZFail !== stencilZFail ||\n\t\t\t\t     currentStencilZPass !== stencilZPass ) {\n\n\t\t\t\t\tgl.stencilOp( stencilFail, stencilZFail, stencilZPass );\n\n\t\t\t\t\tcurrentStencilFail = stencilFail;\n\t\t\t\t\tcurrentStencilZFail = stencilZFail;\n\t\t\t\t\tcurrentStencilZPass = stencilZPass;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\tsetLocked: function ( lock ) {\n\n\t\t\t\tlocked = lock;\n\n\t\t\t},\n\n\t\t\tsetClear: function ( stencil ) {\n\n\t\t\t\tif ( currentStencilClear !== stencil ) {\n\n\t\t\t\t\tgl.clearStencil( stencil );\n\t\t\t\t\tcurrentStencilClear = stencil;\n\n\t\t\t\t}\n\n\t\t\t},\n\n\t\t\treset: function () {\n\n\t\t\t\tlocked = false;\n\n\t\t\t\tcurrentStencilMask = null;\n\t\t\t\tcurrentStencilFunc = null;\n\t\t\t\tcurrentStencilRef = null;\n\t\t\t\tcurrentStencilFuncMask = null;\n\t\t\t\tcurrentStencilFail = null;\n\t\t\t\tcurrentStencilZFail = null;\n\t\t\t\tcurrentStencilZPass = null;\n\t\t\t\tcurrentStencilClear = null;\n\n\t\t\t}\n\n\t\t};\n\n\t}\n\n\t//\n\n\tconst colorBuffer = new ColorBuffer();\n\tconst depthBuffer = new DepthBuffer();\n\tconst stencilBuffer = new StencilBuffer();\n\n\tlet enabledCapabilities = {};\n\n\tlet currentBoundFramebuffers = {};\n\tlet currentDrawbuffers = new WeakMap();\n\tlet defaultDrawbuffers = [];\n\n\tlet currentProgram = null;\n\n\tlet currentBlendingEnabled = false;\n\tlet currentBlending = null;\n\tlet currentBlendEquation = null;\n\tlet currentBlendSrc = null;\n\tlet currentBlendDst = null;\n\tlet currentBlendEquationAlpha = null;\n\tlet currentBlendSrcAlpha = null;\n\tlet currentBlendDstAlpha = null;\n\tlet currentPremultipledAlpha = false;\n\n\tlet currentFlipSided = null;\n\tlet currentCullFace = null;\n\n\tlet currentLineWidth = null;\n\n\tlet currentPolygonOffsetFactor = null;\n\tlet currentPolygonOffsetUnits = null;\n\n\tconst maxTextures = gl.getParameter( 35661 );\n\n\tlet lineWidthAvailable = false;\n\tlet version = 0;\n\tconst glVersion = gl.getParameter( 7938 );\n\n\tif ( glVersion.indexOf( 'WebGL' ) !== - 1 ) {\n\n\t\tversion = parseFloat( /^WebGL (\\d)/.exec( glVersion )[ 1 ] );\n\t\tlineWidthAvailable = ( version >= 1.0 );\n\n\t} else if ( glVersion.indexOf( 'OpenGL ES' ) !== - 1 ) {\n\n\t\tversion = parseFloat( /^OpenGL ES (\\d)/.exec( glVersion )[ 1 ] );\n\t\tlineWidthAvailable = ( version >= 2.0 );\n\n\t}\n\n\tlet currentTextureSlot = null;\n\tlet currentBoundTextures = {};\n\n\tconst scissorParam = gl.getParameter( 3088 );\n\tconst viewportParam = gl.getParameter( 2978 );\n\n\tconst currentScissor = new Vector4().fromArray( scissorParam );\n\tconst currentViewport = new Vector4().fromArray( viewportParam );\n\n\tfunction createTexture( type, target, count ) {\n\n\t\tconst data = new Uint8Array( 4 ); // 4 is required to match default unpack alignment of 4.\n\t\tconst texture = gl.createTexture();\n\n\t\tgl.bindTexture( type, texture );\n\t\tgl.texParameteri( type, 10241, 9728 );\n\t\tgl.texParameteri( type, 10240, 9728 );\n\n\t\tfor ( let i = 0; i < count; i ++ ) {\n\n\t\t\tgl.texImage2D( target + i, 0, 6408, 1, 1, 0, 6408, 5121, data );\n\n\t\t}\n\n\t\treturn texture;\n\n\t}\n\n\tconst emptyTextures = {};\n\temptyTextures[ 3553 ] = createTexture( 3553, 3553, 1 );\n\temptyTextures[ 34067 ] = createTexture( 34067, 34069, 6 );\n\n\t// init\n\n\tcolorBuffer.setClear( 0, 0, 0, 1 );\n\tdepthBuffer.setClear( 1 );\n\tstencilBuffer.setClear( 0 );\n\n\tenable( 2929 );\n\tdepthBuffer.setFunc( LessEqualDepth );\n\n\tsetFlipSided( false );\n\tsetCullFace( CullFaceBack );\n\tenable( 2884 );\n\n\tsetBlending( NoBlending );\n\n\t//\n\n\tfunction enable( id ) {\n\n\t\tif ( enabledCapabilities[ id ] !== true ) {\n\n\t\t\tgl.enable( id );\n\t\t\tenabledCapabilities[ id ] = true;\n\n\t\t}\n\n\t}\n\n\tfunction disable( id ) {\n\n\t\tif ( enabledCapabilities[ id ] !== false ) {\n\n\t\t\tgl.disable( id );\n\t\t\tenabledCapabilities[ id ] = false;\n\n\t\t}\n\n\t}\n\n\tfunction bindFramebuffer( target, framebuffer ) {\n\n\t\tif ( currentBoundFramebuffers[ target ] !== framebuffer ) {\n\n\t\t\tgl.bindFramebuffer( target, framebuffer );\n\n\t\t\tcurrentBoundFramebuffers[ target ] = framebuffer;\n\n\t\t\tif ( isWebGL2 ) {\n\n\t\t\t\t// 36009 is equivalent to 36160\n\n\t\t\t\tif ( target === 36009 ) {\n\n\t\t\t\t\tcurrentBoundFramebuffers[ 36160 ] = framebuffer;\n\n\t\t\t\t}\n\n\t\t\t\tif ( target === 36160 ) {\n\n\t\t\t\t\tcurrentBoundFramebuffers[ 36009 ] = framebuffer;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn true;\n\n\t\t}\n\n\t\treturn false;\n\n\t}\n\n\tfunction drawBuffers( renderTarget, framebuffer ) {\n\n\t\tlet drawBuffers = defaultDrawbuffers;\n\n\t\tlet needsUpdate = false;\n\n\t\tif ( renderTarget ) {\n\n\t\t\tdrawBuffers = currentDrawbuffers.get( framebuffer );\n\n\t\t\tif ( drawBuffers === undefined ) {\n\n\t\t\t\tdrawBuffers = [];\n\t\t\t\tcurrentDrawbuffers.set( framebuffer, drawBuffers );\n\n\t\t\t}\n\n\t\t\tif ( renderTarget.isWebGLMultipleRenderTargets ) {\n\n\t\t\t\tconst textures = renderTarget.texture;\n\n\t\t\t\tif ( drawBuffers.length !== textures.length || drawBuffers[ 0 ] !== 36064 ) {\n\n\t\t\t\t\tfor ( let i = 0, il = textures.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tdrawBuffers[ i ] = 36064 + i;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tdrawBuffers.length = textures.length;\n\n\t\t\t\t\tneedsUpdate = true;\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tif ( drawBuffers[ 0 ] !== 36064 ) {\n\n\t\t\t\t\tdrawBuffers[ 0 ] = 36064;\n\n\t\t\t\t\tneedsUpdate = true;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tif ( drawBuffers[ 0 ] !== 1029 ) {\n\n\t\t\t\tdrawBuffers[ 0 ] = 1029;\n\n\t\t\t\tneedsUpdate = true;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( needsUpdate ) {\n\n\t\t\tif ( capabilities.isWebGL2 ) {\n\n\t\t\t\tgl.drawBuffers( drawBuffers );\n\n\t\t\t} else {\n\n\t\t\t\textensions.get( 'WEBGL_draw_buffers' ).drawBuffersWEBGL( drawBuffers );\n\n\t\t\t}\n\n\t\t}\n\n\n\t}\n\n\tfunction useProgram( program ) {\n\n\t\tif ( currentProgram !== program ) {\n\n\t\t\tgl.useProgram( program );\n\n\t\t\tcurrentProgram = program;\n\n\t\t\treturn true;\n\n\t\t}\n\n\t\treturn false;\n\n\t}\n\n\tconst equationToGL = {\n\t\t[ AddEquation ]: 32774,\n\t\t[ SubtractEquation ]: 32778,\n\t\t[ ReverseSubtractEquation ]: 32779\n\t};\n\n\tif ( isWebGL2 ) {\n\n\t\tequationToGL[ MinEquation ] = 32775;\n\t\tequationToGL[ MaxEquation ] = 32776;\n\n\t} else {\n\n\t\tconst extension = extensions.get( 'EXT_blend_minmax' );\n\n\t\tif ( extension !== null ) {\n\n\t\t\tequationToGL[ MinEquation ] = extension.MIN_EXT;\n\t\t\tequationToGL[ MaxEquation ] = extension.MAX_EXT;\n\n\t\t}\n\n\t}\n\n\tconst factorToGL = {\n\t\t[ ZeroFactor ]: 0,\n\t\t[ OneFactor ]: 1,\n\t\t[ SrcColorFactor ]: 768,\n\t\t[ SrcAlphaFactor ]: 770,\n\t\t[ SrcAlphaSaturateFactor ]: 776,\n\t\t[ DstColorFactor ]: 774,\n\t\t[ DstAlphaFactor ]: 772,\n\t\t[ OneMinusSrcColorFactor ]: 769,\n\t\t[ OneMinusSrcAlphaFactor ]: 771,\n\t\t[ OneMinusDstColorFactor ]: 775,\n\t\t[ OneMinusDstAlphaFactor ]: 773\n\t};\n\n\tfunction setBlending( blending, blendEquation, blendSrc, blendDst, blendEquationAlpha, blendSrcAlpha, blendDstAlpha, premultipliedAlpha ) {\n\n\t\tif ( blending === NoBlending ) {\n\n\t\t\tif ( currentBlendingEnabled === true ) {\n\n\t\t\t\tdisable( 3042 );\n\t\t\t\tcurrentBlendingEnabled = false;\n\n\t\t\t}\n\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( currentBlendingEnabled === false ) {\n\n\t\t\tenable( 3042 );\n\t\t\tcurrentBlendingEnabled = true;\n\n\t\t}\n\n\t\tif ( blending !== CustomBlending ) {\n\n\t\t\tif ( blending !== currentBlending || premultipliedAlpha !== currentPremultipledAlpha ) {\n\n\t\t\t\tif ( currentBlendEquation !== AddEquation || currentBlendEquationAlpha !== AddEquation ) {\n\n\t\t\t\t\tgl.blendEquation( 32774 );\n\n\t\t\t\t\tcurrentBlendEquation = AddEquation;\n\t\t\t\t\tcurrentBlendEquationAlpha = AddEquation;\n\n\t\t\t\t}\n\n\t\t\t\tif ( premultipliedAlpha ) {\n\n\t\t\t\t\tswitch ( blending ) {\n\n\t\t\t\t\t\tcase NormalBlending:\n\t\t\t\t\t\t\tgl.blendFuncSeparate( 1, 771, 1, 771 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase AdditiveBlending:\n\t\t\t\t\t\t\tgl.blendFunc( 1, 1 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase SubtractiveBlending:\n\t\t\t\t\t\t\tgl.blendFuncSeparate( 0, 769, 0, 1 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase MultiplyBlending:\n\t\t\t\t\t\t\tgl.blendFuncSeparate( 0, 768, 0, 770 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tconsole.error( 'THREE.WebGLState: Invalid blending: ', blending );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tswitch ( blending ) {\n\n\t\t\t\t\t\tcase NormalBlending:\n\t\t\t\t\t\t\tgl.blendFuncSeparate( 770, 771, 1, 771 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase AdditiveBlending:\n\t\t\t\t\t\t\tgl.blendFunc( 770, 1 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase SubtractiveBlending:\n\t\t\t\t\t\t\tgl.blendFuncSeparate( 0, 769, 0, 1 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase MultiplyBlending:\n\t\t\t\t\t\t\tgl.blendFunc( 0, 768 );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tconsole.error( 'THREE.WebGLState: Invalid blending: ', blending );\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tcurrentBlendSrc = null;\n\t\t\t\tcurrentBlendDst = null;\n\t\t\t\tcurrentBlendSrcAlpha = null;\n\t\t\t\tcurrentBlendDstAlpha = null;\n\n\t\t\t\tcurrentBlending = blending;\n\t\t\t\tcurrentPremultipledAlpha = premultipliedAlpha;\n\n\t\t\t}\n\n\t\t\treturn;\n\n\t\t}\n\n\t\t// custom blending\n\n\t\tblendEquationAlpha = blendEquationAlpha || blendEquation;\n\t\tblendSrcAlpha = blendSrcAlpha || blendSrc;\n\t\tblendDstAlpha = blendDstAlpha || blendDst;\n\n\t\tif ( blendEquation !== currentBlendEquation || blendEquationAlpha !== currentBlendEquationAlpha ) {\n\n\t\t\tgl.blendEquationSeparate( equationToGL[ blendEquation ], equationToGL[ blendEquationAlpha ] );\n\n\t\t\tcurrentBlendEquation = blendEquation;\n\t\t\tcurrentBlendEquationAlpha = blendEquationAlpha;\n\n\t\t}\n\n\t\tif ( blendSrc !== currentBlendSrc || blendDst !== currentBlendDst || blendSrcAlpha !== currentBlendSrcAlpha || blendDstAlpha !== currentBlendDstAlpha ) {\n\n\t\t\tgl.blendFuncSeparate( factorToGL[ blendSrc ], factorToGL[ blendDst ], factorToGL[ blendSrcAlpha ], factorToGL[ blendDstAlpha ] );\n\n\t\t\tcurrentBlendSrc = blendSrc;\n\t\t\tcurrentBlendDst = blendDst;\n\t\t\tcurrentBlendSrcAlpha = blendSrcAlpha;\n\t\t\tcurrentBlendDstAlpha = blendDstAlpha;\n\n\t\t}\n\n\t\tcurrentBlending = blending;\n\t\tcurrentPremultipledAlpha = null;\n\n\t}\n\n\tfunction setMaterial( material, frontFaceCW ) {\n\n\t\tmaterial.side === DoubleSide\n\t\t\t? disable( 2884 )\n\t\t\t: enable( 2884 );\n\n\t\tlet flipSided = ( material.side === BackSide );\n\t\tif ( frontFaceCW ) flipSided = ! flipSided;\n\n\t\tsetFlipSided( flipSided );\n\n\t\t( material.blending === NormalBlending && material.transparent === false )\n\t\t\t? setBlending( NoBlending )\n\t\t\t: setBlending( material.blending, material.blendEquation, material.blendSrc, material.blendDst, material.blendEquationAlpha, material.blendSrcAlpha, material.blendDstAlpha, material.premultipliedAlpha );\n\n\t\tdepthBuffer.setFunc( material.depthFunc );\n\t\tdepthBuffer.setTest( material.depthTest );\n\t\tdepthBuffer.setMask( material.depthWrite );\n\t\tcolorBuffer.setMask( material.colorWrite );\n\n\t\tconst stencilWrite = material.stencilWrite;\n\t\tstencilBuffer.setTest( stencilWrite );\n\t\tif ( stencilWrite ) {\n\n\t\t\tstencilBuffer.setMask( material.stencilWriteMask );\n\t\t\tstencilBuffer.setFunc( material.stencilFunc, material.stencilRef, material.stencilFuncMask );\n\t\t\tstencilBuffer.setOp( material.stencilFail, material.stencilZFail, material.stencilZPass );\n\n\t\t}\n\n\t\tsetPolygonOffset( material.polygonOffset, material.polygonOffsetFactor, material.polygonOffsetUnits );\n\n\t\tmaterial.alphaToCoverage === true\n\t\t\t? enable( 32926 )\n\t\t\t: disable( 32926 );\n\n\t}\n\n\t//\n\n\tfunction setFlipSided( flipSided ) {\n\n\t\tif ( currentFlipSided !== flipSided ) {\n\n\t\t\tif ( flipSided ) {\n\n\t\t\t\tgl.frontFace( 2304 );\n\n\t\t\t} else {\n\n\t\t\t\tgl.frontFace( 2305 );\n\n\t\t\t}\n\n\t\t\tcurrentFlipSided = flipSided;\n\n\t\t}\n\n\t}\n\n\tfunction setCullFace( cullFace ) {\n\n\t\tif ( cullFace !== CullFaceNone ) {\n\n\t\t\tenable( 2884 );\n\n\t\t\tif ( cullFace !== currentCullFace ) {\n\n\t\t\t\tif ( cullFace === CullFaceBack ) {\n\n\t\t\t\t\tgl.cullFace( 1029 );\n\n\t\t\t\t} else if ( cullFace === CullFaceFront ) {\n\n\t\t\t\t\tgl.cullFace( 1028 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tgl.cullFace( 1032 );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tdisable( 2884 );\n\n\t\t}\n\n\t\tcurrentCullFace = cullFace;\n\n\t}\n\n\tfunction setLineWidth( width ) {\n\n\t\tif ( width !== currentLineWidth ) {\n\n\t\t\tif ( lineWidthAvailable ) gl.lineWidth( width );\n\n\t\t\tcurrentLineWidth = width;\n\n\t\t}\n\n\t}\n\n\tfunction setPolygonOffset( polygonOffset, factor, units ) {\n\n\t\tif ( polygonOffset ) {\n\n\t\t\tenable( 32823 );\n\n\t\t\tif ( currentPolygonOffsetFactor !== factor || currentPolygonOffsetUnits !== units ) {\n\n\t\t\t\tgl.polygonOffset( factor, units );\n\n\t\t\t\tcurrentPolygonOffsetFactor = factor;\n\t\t\t\tcurrentPolygonOffsetUnits = units;\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tdisable( 32823 );\n\n\t\t}\n\n\t}\n\n\tfunction setScissorTest( scissorTest ) {\n\n\t\tif ( scissorTest ) {\n\n\t\t\tenable( 3089 );\n\n\t\t} else {\n\n\t\t\tdisable( 3089 );\n\n\t\t}\n\n\t}\n\n\t// texture\n\n\tfunction activeTexture( webglSlot ) {\n\n\t\tif ( webglSlot === undefined ) webglSlot = 33984 + maxTextures - 1;\n\n\t\tif ( currentTextureSlot !== webglSlot ) {\n\n\t\t\tgl.activeTexture( webglSlot );\n\t\t\tcurrentTextureSlot = webglSlot;\n\n\t\t}\n\n\t}\n\n\tfunction bindTexture( webglType, webglTexture ) {\n\n\t\tif ( currentTextureSlot === null ) {\n\n\t\t\tactiveTexture();\n\n\t\t}\n\n\t\tlet boundTexture = currentBoundTextures[ currentTextureSlot ];\n\n\t\tif ( boundTexture === undefined ) {\n\n\t\t\tboundTexture = { type: undefined, texture: undefined };\n\t\t\tcurrentBoundTextures[ currentTextureSlot ] = boundTexture;\n\n\t\t}\n\n\t\tif ( boundTexture.type !== webglType || boundTexture.texture !== webglTexture ) {\n\n\t\t\tgl.bindTexture( webglType, webglTexture || emptyTextures[ webglType ] );\n\n\t\t\tboundTexture.type = webglType;\n\t\t\tboundTexture.texture = webglTexture;\n\n\t\t}\n\n\t}\n\n\tfunction unbindTexture() {\n\n\t\tconst boundTexture = currentBoundTextures[ currentTextureSlot ];\n\n\t\tif ( boundTexture !== undefined && boundTexture.type !== undefined ) {\n\n\t\t\tgl.bindTexture( boundTexture.type, null );\n\n\t\t\tboundTexture.type = undefined;\n\t\t\tboundTexture.texture = undefined;\n\n\t\t}\n\n\t}\n\n\tfunction compressedTexImage2D() {\n\n\t\ttry {\n\n\t\t\tgl.compressedTexImage2D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction texSubImage2D() {\n\n\t\ttry {\n\n\t\t\tgl.texSubImage2D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction texSubImage3D() {\n\n\t\ttry {\n\n\t\t\tgl.texSubImage3D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction compressedTexSubImage2D() {\n\n\t\ttry {\n\n\t\t\tgl.compressedTexSubImage2D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction texStorage2D() {\n\n\t\ttry {\n\n\t\t\tgl.texStorage2D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction texStorage3D() {\n\n\t\ttry {\n\n\t\t\tgl.texStorage3D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction texImage2D() {\n\n\t\ttry {\n\n\t\t\tgl.texImage2D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\tfunction texImage3D() {\n\n\t\ttry {\n\n\t\t\tgl.texImage3D.apply( gl, arguments );\n\n\t\t} catch ( error ) {\n\n\t\t\tconsole.error( 'THREE.WebGLState:', error );\n\n\t\t}\n\n\t}\n\n\t//\n\n\tfunction scissor( scissor ) {\n\n\t\tif ( currentScissor.equals( scissor ) === false ) {\n\n\t\t\tgl.scissor( scissor.x, scissor.y, scissor.z, scissor.w );\n\t\t\tcurrentScissor.copy( scissor );\n\n\t\t}\n\n\t}\n\n\tfunction viewport( viewport ) {\n\n\t\tif ( currentViewport.equals( viewport ) === false ) {\n\n\t\t\tgl.viewport( viewport.x, viewport.y, viewport.z, viewport.w );\n\t\t\tcurrentViewport.copy( viewport );\n\n\t\t}\n\n\t}\n\n\t//\n\n\tfunction reset() {\n\n\t\t// reset state\n\n\t\tgl.disable( 3042 );\n\t\tgl.disable( 2884 );\n\t\tgl.disable( 2929 );\n\t\tgl.disable( 32823 );\n\t\tgl.disable( 3089 );\n\t\tgl.disable( 2960 );\n\t\tgl.disable( 32926 );\n\n\t\tgl.blendEquation( 32774 );\n\t\tgl.blendFunc( 1, 0 );\n\t\tgl.blendFuncSeparate( 1, 0, 1, 0 );\n\n\t\tgl.colorMask( true, true, true, true );\n\t\tgl.clearColor( 0, 0, 0, 0 );\n\n\t\tgl.depthMask( true );\n\t\tgl.depthFunc( 513 );\n\t\tgl.clearDepth( 1 );\n\n\t\tgl.stencilMask( 0xffffffff );\n\t\tgl.stencilFunc( 519, 0, 0xffffffff );\n\t\tgl.stencilOp( 7680, 7680, 7680 );\n\t\tgl.clearStencil( 0 );\n\n\t\tgl.cullFace( 1029 );\n\t\tgl.frontFace( 2305 );\n\n\t\tgl.polygonOffset( 0, 0 );\n\n\t\tgl.activeTexture( 33984 );\n\n\t\tgl.bindFramebuffer( 36160, null );\n\n\t\tif ( isWebGL2 === true ) {\n\n\t\t\tgl.bindFramebuffer( 36009, null );\n\t\t\tgl.bindFramebuffer( 36008, null );\n\n\t\t}\n\n\t\tgl.useProgram( null );\n\n\t\tgl.lineWidth( 1 );\n\n\t\tgl.scissor( 0, 0, gl.canvas.width, gl.canvas.height );\n\t\tgl.viewport( 0, 0, gl.canvas.width, gl.canvas.height );\n\n\t\t// reset internals\n\n\t\tenabledCapabilities = {};\n\n\t\tcurrentTextureSlot = null;\n\t\tcurrentBoundTextures = {};\n\n\t\tcurrentBoundFramebuffers = {};\n\t\tcurrentDrawbuffers = new WeakMap();\n\t\tdefaultDrawbuffers = [];\n\n\t\tcurrentProgram = null;\n\n\t\tcurrentBlendingEnabled = false;\n\t\tcurrentBlending = null;\n\t\tcurrentBlendEquation = null;\n\t\tcurrentBlendSrc = null;\n\t\tcurrentBlendDst = null;\n\t\tcurrentBlendEquationAlpha = null;\n\t\tcurrentBlendSrcAlpha = null;\n\t\tcurrentBlendDstAlpha = null;\n\t\tcurrentPremultipledAlpha = false;\n\n\t\tcurrentFlipSided = null;\n\t\tcurrentCullFace = null;\n\n\t\tcurrentLineWidth = null;\n\n\t\tcurrentPolygonOffsetFactor = null;\n\t\tcurrentPolygonOffsetUnits = null;\n\n\t\tcurrentScissor.set( 0, 0, gl.canvas.width, gl.canvas.height );\n\t\tcurrentViewport.set( 0, 0, gl.canvas.width, gl.canvas.height );\n\n\t\tcolorBuffer.reset();\n\t\tdepthBuffer.reset();\n\t\tstencilBuffer.reset();\n\n\t}\n\n\treturn {\n\n\t\tbuffers: {\n\t\t\tcolor: colorBuffer,\n\t\t\tdepth: depthBuffer,\n\t\t\tstencil: stencilBuffer\n\t\t},\n\n\t\tenable: enable,\n\t\tdisable: disable,\n\n\t\tbindFramebuffer: bindFramebuffer,\n\t\tdrawBuffers: drawBuffers,\n\n\t\tuseProgram: useProgram,\n\n\t\tsetBlending: setBlending,\n\t\tsetMaterial: setMaterial,\n\n\t\tsetFlipSided: setFlipSided,\n\t\tsetCullFace: setCullFace,\n\n\t\tsetLineWidth: setLineWidth,\n\t\tsetPolygonOffset: setPolygonOffset,\n\n\t\tsetScissorTest: setScissorTest,\n\n\t\tactiveTexture: activeTexture,\n\t\tbindTexture: bindTexture,\n\t\tunbindTexture: unbindTexture,\n\t\tcompressedTexImage2D: compressedTexImage2D,\n\t\ttexImage2D: texImage2D,\n\t\ttexImage3D: texImage3D,\n\n\t\ttexStorage2D: texStorage2D,\n\t\ttexStorage3D: texStorage3D,\n\t\ttexSubImage2D: texSubImage2D,\n\t\ttexSubImage3D: texSubImage3D,\n\t\tcompressedTexSubImage2D: compressedTexSubImage2D,\n\n\t\tscissor: scissor,\n\t\tviewport: viewport,\n\n\t\treset: reset\n\n\t};\n\n}\n\nfunction WebGLTextures( _gl, extensions, state, properties, capabilities, utils, info ) {\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\tconst maxTextures = capabilities.maxTextures;\n\tconst maxCubemapSize = capabilities.maxCubemapSize;\n\tconst maxTextureSize = capabilities.maxTextureSize;\n\tconst maxSamples = capabilities.maxSamples;\n\tconst multisampledRTTExt = extensions.has( 'WEBGL_multisampled_render_to_texture' ) ? extensions.get( 'WEBGL_multisampled_render_to_texture' ) : null;\n\n\tconst _videoTextures = new WeakMap();\n\tlet _canvas;\n\n\tconst _sources = new WeakMap(); // maps WebglTexture objects to instances of Source\n\n\t// cordova iOS (as of 5.0) still uses UIWebView, which provides OffscreenCanvas,\n\t// also OffscreenCanvas.getContext(\"webgl\"), but not OffscreenCanvas.getContext(\"2d\")!\n\t// Some implementations may only implement OffscreenCanvas partially (e.g. lacking 2d).\n\n\tlet useOffscreenCanvas = false;\n\n\ttry {\n\n\t\tuseOffscreenCanvas = typeof OffscreenCanvas !== 'undefined'\n\t\t\t&& ( new OffscreenCanvas( 1, 1 ).getContext( '2d' ) ) !== null;\n\n\t} catch ( err ) {\n\n\t\t// Ignore any errors\n\n\t}\n\n\tfunction createCanvas( width, height ) {\n\n\t\t// Use OffscreenCanvas when available. Specially needed in web workers\n\n\t\treturn useOffscreenCanvas ?\n\t\t\tnew OffscreenCanvas( width, height ) : createElementNS( 'canvas' );\n\n\t}\n\n\tfunction resizeImage( image, needsPowerOfTwo, needsNewCanvas, maxSize ) {\n\n\t\tlet scale = 1;\n\n\t\t// handle case if texture exceeds max size\n\n\t\tif ( image.width > maxSize || image.height > maxSize ) {\n\n\t\t\tscale = maxSize / Math.max( image.width, image.height );\n\n\t\t}\n\n\t\t// only perform resize if necessary\n\n\t\tif ( scale < 1 || needsPowerOfTwo === true ) {\n\n\t\t\t// only perform resize for certain image types\n\n\t\t\tif ( ( typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement ) ||\n\t\t\t\t( typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement ) ||\n\t\t\t\t( typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap ) ) {\n\n\t\t\t\tconst floor = needsPowerOfTwo ? floorPowerOfTwo : Math.floor;\n\n\t\t\t\tconst width = floor( scale * image.width );\n\t\t\t\tconst height = floor( scale * image.height );\n\n\t\t\t\tif ( _canvas === undefined ) _canvas = createCanvas( width, height );\n\n\t\t\t\t// cube textures can't reuse the same canvas\n\n\t\t\t\tconst canvas = needsNewCanvas ? createCanvas( width, height ) : _canvas;\n\n\t\t\t\tcanvas.width = width;\n\t\t\t\tcanvas.height = height;\n\n\t\t\t\tconst context = canvas.getContext( '2d' );\n\t\t\t\tcontext.drawImage( image, 0, 0, width, height );\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Texture has been resized from (' + image.width + 'x' + image.height + ') to (' + width + 'x' + height + ').' );\n\n\t\t\t\treturn canvas;\n\n\t\t\t} else {\n\n\t\t\t\tif ( 'data' in image ) {\n\n\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Image in DataTexture is too big (' + image.width + 'x' + image.height + ').' );\n\n\t\t\t\t}\n\n\t\t\t\treturn image;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn image;\n\n\t}\n\n\tfunction isPowerOfTwo$1( image ) {\n\n\t\treturn isPowerOfTwo( image.width ) && isPowerOfTwo( image.height );\n\n\t}\n\n\tfunction textureNeedsPowerOfTwo( texture ) {\n\n\t\tif ( isWebGL2 ) return false;\n\n\t\treturn ( texture.wrapS !== ClampToEdgeWrapping || texture.wrapT !== ClampToEdgeWrapping ) ||\n\t\t\t( texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter );\n\n\t}\n\n\tfunction textureNeedsGenerateMipmaps( texture, supportsMips ) {\n\n\t\treturn texture.generateMipmaps && supportsMips &&\n\t\t\ttexture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter;\n\n\t}\n\n\tfunction generateMipmap( target ) {\n\n\t\t_gl.generateMipmap( target );\n\n\t}\n\n\tfunction getInternalFormat( internalFormatName, glFormat, glType, encoding, isVideoTexture = false ) {\n\n\t\tif ( isWebGL2 === false ) return glFormat;\n\n\t\tif ( internalFormatName !== null ) {\n\n\t\t\tif ( _gl[ internalFormatName ] !== undefined ) return _gl[ internalFormatName ];\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: Attempt to use non-existing WebGL internal format \\'' + internalFormatName + '\\'' );\n\n\t\t}\n\n\t\tlet internalFormat = glFormat;\n\n\t\tif ( glFormat === 6403 ) {\n\n\t\t\tif ( glType === 5126 ) internalFormat = 33326;\n\t\t\tif ( glType === 5131 ) internalFormat = 33325;\n\t\t\tif ( glType === 5121 ) internalFormat = 33321;\n\n\t\t}\n\n\t\tif ( glFormat === 33319 ) {\n\n\t\t\tif ( glType === 5126 ) internalFormat = 33328;\n\t\t\tif ( glType === 5131 ) internalFormat = 33327;\n\t\t\tif ( glType === 5121 ) internalFormat = 33323;\n\n\t\t}\n\n\t\tif ( glFormat === 6408 ) {\n\n\t\t\tif ( glType === 5126 ) internalFormat = 34836;\n\t\t\tif ( glType === 5131 ) internalFormat = 34842;\n\t\t\tif ( glType === 5121 ) internalFormat = ( encoding === sRGBEncoding && isVideoTexture === false ) ? 35907 : 32856;\n\t\t\tif ( glType === 32819 ) internalFormat = 32854;\n\t\t\tif ( glType === 32820 ) internalFormat = 32855;\n\n\t\t}\n\n\t\tif ( internalFormat === 33325 || internalFormat === 33326 ||\n\t\t\tinternalFormat === 33327 || internalFormat === 33328 ||\n\t\t\tinternalFormat === 34842 || internalFormat === 34836 ) {\n\n\t\t\textensions.get( 'EXT_color_buffer_float' );\n\n\t\t}\n\n\t\treturn internalFormat;\n\n\t}\n\n\tfunction getMipLevels( texture, image, supportsMips ) {\n\n\t\tif ( textureNeedsGenerateMipmaps( texture, supportsMips ) === true || ( texture.isFramebufferTexture && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter ) ) {\n\n\t\t\treturn Math.log2( Math.max( image.width, image.height ) ) + 1;\n\n\t\t} else if ( texture.mipmaps !== undefined && texture.mipmaps.length > 0 ) {\n\n\t\t\t// user-defined mipmaps\n\n\t\t\treturn texture.mipmaps.length;\n\n\t\t} else if ( texture.isCompressedTexture && Array.isArray( texture.image ) ) {\n\n\t\t\treturn image.mipmaps.length;\n\n\t\t} else {\n\n\t\t\t// texture without mipmaps (only base level)\n\n\t\t\treturn 1;\n\n\t\t}\n\n\t}\n\n\t// Fallback filters for non-power-of-2 textures\n\n\tfunction filterFallback( f ) {\n\n\t\tif ( f === NearestFilter || f === NearestMipmapNearestFilter || f === NearestMipmapLinearFilter ) {\n\n\t\t\treturn 9728;\n\n\t\t}\n\n\t\treturn 9729;\n\n\t}\n\n\t//\n\n\tfunction onTextureDispose( event ) {\n\n\t\tconst texture = event.target;\n\n\t\ttexture.removeEventListener( 'dispose', onTextureDispose );\n\n\t\tdeallocateTexture( texture );\n\n\t\tif ( texture.isVideoTexture ) {\n\n\t\t\t_videoTextures.delete( texture );\n\n\t\t}\n\n\t}\n\n\tfunction onRenderTargetDispose( event ) {\n\n\t\tconst renderTarget = event.target;\n\n\t\trenderTarget.removeEventListener( 'dispose', onRenderTargetDispose );\n\n\t\tdeallocateRenderTarget( renderTarget );\n\n\t}\n\n\t//\n\n\tfunction deallocateTexture( texture ) {\n\n\t\tconst textureProperties = properties.get( texture );\n\n\t\tif ( textureProperties.__webglInit === undefined ) return;\n\n\t\t// check if it's necessary to remove the WebGLTexture object\n\n\t\tconst source = texture.source;\n\t\tconst webglTextures = _sources.get( source );\n\n\t\tif ( webglTextures ) {\n\n\t\t\tconst webglTexture = webglTextures[ textureProperties.__cacheKey ];\n\t\t\twebglTexture.usedTimes --;\n\n\t\t\t// the WebGLTexture object is not used anymore, remove it\n\n\t\t\tif ( webglTexture.usedTimes === 0 ) {\n\n\t\t\t\tdeleteTexture( texture );\n\n\t\t\t}\n\n\t\t\t// remove the weak map entry if no WebGLTexture uses the source anymore\n\n\t\t\tif ( Object.keys( webglTextures ).length === 0 ) {\n\n\t\t\t\t_sources.delete( source );\n\n\t\t\t}\n\n\t\t}\n\n\t\tproperties.remove( texture );\n\n\t}\n\n\tfunction deleteTexture( texture ) {\n\n\t\tconst textureProperties = properties.get( texture );\n\t\t_gl.deleteTexture( textureProperties.__webglTexture );\n\n\t\tconst source = texture.source;\n\t\tconst webglTextures = _sources.get( source );\n\t\tdelete webglTextures[ textureProperties.__cacheKey ];\n\n\t\tinfo.memory.textures --;\n\n\t}\n\n\tfunction deallocateRenderTarget( renderTarget ) {\n\n\t\tconst texture = renderTarget.texture;\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\t\tconst textureProperties = properties.get( texture );\n\n\t\tif ( textureProperties.__webglTexture !== undefined ) {\n\n\t\t\t_gl.deleteTexture( textureProperties.__webglTexture );\n\n\t\t\tinfo.memory.textures --;\n\n\t\t}\n\n\t\tif ( renderTarget.depthTexture ) {\n\n\t\t\trenderTarget.depthTexture.dispose();\n\n\t\t}\n\n\t\tif ( renderTarget.isWebGLCubeRenderTarget ) {\n\n\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\t_gl.deleteFramebuffer( renderTargetProperties.__webglFramebuffer[ i ] );\n\t\t\t\tif ( renderTargetProperties.__webglDepthbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglDepthbuffer[ i ] );\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\t_gl.deleteFramebuffer( renderTargetProperties.__webglFramebuffer );\n\t\t\tif ( renderTargetProperties.__webglDepthbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglDepthbuffer );\n\t\t\tif ( renderTargetProperties.__webglMultisampledFramebuffer ) _gl.deleteFramebuffer( renderTargetProperties.__webglMultisampledFramebuffer );\n\t\t\tif ( renderTargetProperties.__webglColorRenderbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglColorRenderbuffer );\n\t\t\tif ( renderTargetProperties.__webglDepthRenderbuffer ) _gl.deleteRenderbuffer( renderTargetProperties.__webglDepthRenderbuffer );\n\n\t\t}\n\n\t\tif ( renderTarget.isWebGLMultipleRenderTargets ) {\n\n\t\t\tfor ( let i = 0, il = texture.length; i < il; i ++ ) {\n\n\t\t\t\tconst attachmentProperties = properties.get( texture[ i ] );\n\n\t\t\t\tif ( attachmentProperties.__webglTexture ) {\n\n\t\t\t\t\t_gl.deleteTexture( attachmentProperties.__webglTexture );\n\n\t\t\t\t\tinfo.memory.textures --;\n\n\t\t\t\t}\n\n\t\t\t\tproperties.remove( texture[ i ] );\n\n\t\t\t}\n\n\t\t}\n\n\t\tproperties.remove( texture );\n\t\tproperties.remove( renderTarget );\n\n\t}\n\n\t//\n\n\tlet textureUnits = 0;\n\n\tfunction resetTextureUnits() {\n\n\t\ttextureUnits = 0;\n\n\t}\n\n\tfunction allocateTextureUnit() {\n\n\t\tconst textureUnit = textureUnits;\n\n\t\tif ( textureUnit >= maxTextures ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLTextures: Trying to use ' + textureUnit + ' texture units while this GPU supports only ' + maxTextures );\n\n\t\t}\n\n\t\ttextureUnits += 1;\n\n\t\treturn textureUnit;\n\n\t}\n\n\tfunction getTextureCacheKey( texture ) {\n\n\t\tconst array = [];\n\n\t\tarray.push( texture.wrapS );\n\t\tarray.push( texture.wrapT );\n\t\tarray.push( texture.magFilter );\n\t\tarray.push( texture.minFilter );\n\t\tarray.push( texture.anisotropy );\n\t\tarray.push( texture.internalFormat );\n\t\tarray.push( texture.format );\n\t\tarray.push( texture.type );\n\t\tarray.push( texture.generateMipmaps );\n\t\tarray.push( texture.premultiplyAlpha );\n\t\tarray.push( texture.flipY );\n\t\tarray.push( texture.unpackAlignment );\n\t\tarray.push( texture.encoding );\n\n\t\treturn array.join();\n\n\t}\n\n\t//\n\n\tfunction setTexture2D( texture, slot ) {\n\n\t\tconst textureProperties = properties.get( texture );\n\n\t\tif ( texture.isVideoTexture ) updateVideoTexture( texture );\n\n\t\tif ( texture.isRenderTargetTexture === false && texture.version > 0 && textureProperties.__version !== texture.version ) {\n\n\t\t\tconst image = texture.image;\n\n\t\t\tif ( image === null ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Texture marked for update but no image data found.' );\n\n\t\t\t} else if ( image.complete === false ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Texture marked for update but image is incomplete' );\n\n\t\t\t} else {\n\n\t\t\t\tuploadTexture( textureProperties, texture, slot );\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t}\n\n\t\tstate.activeTexture( 33984 + slot );\n\t\tstate.bindTexture( 3553, textureProperties.__webglTexture );\n\n\t}\n\n\tfunction setTexture2DArray( texture, slot ) {\n\n\t\tconst textureProperties = properties.get( texture );\n\n\t\tif ( texture.version > 0 && textureProperties.__version !== texture.version ) {\n\n\t\t\tuploadTexture( textureProperties, texture, slot );\n\t\t\treturn;\n\n\t\t}\n\n\t\tstate.activeTexture( 33984 + slot );\n\t\tstate.bindTexture( 35866, textureProperties.__webglTexture );\n\n\t}\n\n\tfunction setTexture3D( texture, slot ) {\n\n\t\tconst textureProperties = properties.get( texture );\n\n\t\tif ( texture.version > 0 && textureProperties.__version !== texture.version ) {\n\n\t\t\tuploadTexture( textureProperties, texture, slot );\n\t\t\treturn;\n\n\t\t}\n\n\t\tstate.activeTexture( 33984 + slot );\n\t\tstate.bindTexture( 32879, textureProperties.__webglTexture );\n\n\t}\n\n\tfunction setTextureCube( texture, slot ) {\n\n\t\tconst textureProperties = properties.get( texture );\n\n\t\tif ( texture.version > 0 && textureProperties.__version !== texture.version ) {\n\n\t\t\tuploadCubeTexture( textureProperties, texture, slot );\n\t\t\treturn;\n\n\t\t}\n\n\t\tstate.activeTexture( 33984 + slot );\n\t\tstate.bindTexture( 34067, textureProperties.__webglTexture );\n\n\t}\n\n\tconst wrappingToGL = {\n\t\t[ RepeatWrapping ]: 10497,\n\t\t[ ClampToEdgeWrapping ]: 33071,\n\t\t[ MirroredRepeatWrapping ]: 33648\n\t};\n\n\tconst filterToGL = {\n\t\t[ NearestFilter ]: 9728,\n\t\t[ NearestMipmapNearestFilter ]: 9984,\n\t\t[ NearestMipmapLinearFilter ]: 9986,\n\n\t\t[ LinearFilter ]: 9729,\n\t\t[ LinearMipmapNearestFilter ]: 9985,\n\t\t[ LinearMipmapLinearFilter ]: 9987\n\t};\n\n\tfunction setTextureParameters( textureType, texture, supportsMips ) {\n\n\t\tif ( supportsMips ) {\n\n\t\t\t_gl.texParameteri( textureType, 10242, wrappingToGL[ texture.wrapS ] );\n\t\t\t_gl.texParameteri( textureType, 10243, wrappingToGL[ texture.wrapT ] );\n\n\t\t\tif ( textureType === 32879 || textureType === 35866 ) {\n\n\t\t\t\t_gl.texParameteri( textureType, 32882, wrappingToGL[ texture.wrapR ] );\n\n\t\t\t}\n\n\t\t\t_gl.texParameteri( textureType, 10240, filterToGL[ texture.magFilter ] );\n\t\t\t_gl.texParameteri( textureType, 10241, filterToGL[ texture.minFilter ] );\n\n\t\t} else {\n\n\t\t\t_gl.texParameteri( textureType, 10242, 33071 );\n\t\t\t_gl.texParameteri( textureType, 10243, 33071 );\n\n\t\t\tif ( textureType === 32879 || textureType === 35866 ) {\n\n\t\t\t\t_gl.texParameteri( textureType, 32882, 33071 );\n\n\t\t\t}\n\n\t\t\tif ( texture.wrapS !== ClampToEdgeWrapping || texture.wrapT !== ClampToEdgeWrapping ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Texture is not power of two. Texture.wrapS and Texture.wrapT should be set to THREE.ClampToEdgeWrapping.' );\n\n\t\t\t}\n\n\t\t\t_gl.texParameteri( textureType, 10240, filterFallback( texture.magFilter ) );\n\t\t\t_gl.texParameteri( textureType, 10241, filterFallback( texture.minFilter ) );\n\n\t\t\tif ( texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Texture is not power of two. Texture.minFilter should be set to THREE.NearestFilter or THREE.LinearFilter.' );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( extensions.has( 'EXT_texture_filter_anisotropic' ) === true ) {\n\n\t\t\tconst extension = extensions.get( 'EXT_texture_filter_anisotropic' );\n\n\t\t\tif ( texture.type === FloatType && extensions.has( 'OES_texture_float_linear' ) === false ) return; // verify extension for WebGL 1 and WebGL 2\n\t\t\tif ( isWebGL2 === false && ( texture.type === HalfFloatType && extensions.has( 'OES_texture_half_float_linear' ) === false ) ) return; // verify extension for WebGL 1 only\n\n\t\t\tif ( texture.anisotropy > 1 || properties.get( texture ).__currentAnisotropy ) {\n\n\t\t\t\t_gl.texParameterf( textureType, extension.TEXTURE_MAX_ANISOTROPY_EXT, Math.min( texture.anisotropy, capabilities.getMaxAnisotropy() ) );\n\t\t\t\tproperties.get( texture ).__currentAnisotropy = texture.anisotropy;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tfunction initTexture( textureProperties, texture ) {\n\n\t\tlet forceUpload = false;\n\n\t\tif ( textureProperties.__webglInit === undefined ) {\n\n\t\t\ttextureProperties.__webglInit = true;\n\n\t\t\ttexture.addEventListener( 'dispose', onTextureDispose );\n\n\t\t}\n\n\t\t// create Source <-> WebGLTextures mapping if necessary\n\n\t\tconst source = texture.source;\n\t\tlet webglTextures = _sources.get( source );\n\n\t\tif ( webglTextures === undefined ) {\n\n\t\t\twebglTextures = {};\n\t\t\t_sources.set( source, webglTextures );\n\n\t\t}\n\n\t\t// check if there is already a WebGLTexture object for the given texture parameters\n\n\t\tconst textureCacheKey = getTextureCacheKey( texture );\n\n\t\tif ( textureCacheKey !== textureProperties.__cacheKey ) {\n\n\t\t\t// if not, create a new instance of WebGLTexture\n\n\t\t\tif ( webglTextures[ textureCacheKey ] === undefined ) {\n\n\t\t\t\t// create new entry\n\n\t\t\t\twebglTextures[ textureCacheKey ] = {\n\t\t\t\t\ttexture: _gl.createTexture(),\n\t\t\t\t\tusedTimes: 0\n\t\t\t\t};\n\n\t\t\t\tinfo.memory.textures ++;\n\n\t\t\t\t// when a new instance of WebGLTexture was created, a texture upload is required\n\t\t\t\t// even if the image contents are identical\n\n\t\t\t\tforceUpload = true;\n\n\t\t\t}\n\n\t\t\twebglTextures[ textureCacheKey ].usedTimes ++;\n\n\t\t\t// every time the texture cache key changes, it's necessary to check if an instance of\n\t\t\t// WebGLTexture can be deleted in order to avoid a memory leak.\n\n\t\t\tconst webglTexture = webglTextures[ textureProperties.__cacheKey ];\n\n\t\t\tif ( webglTexture !== undefined ) {\n\n\t\t\t\twebglTextures[ textureProperties.__cacheKey ].usedTimes --;\n\n\t\t\t\tif ( webglTexture.usedTimes === 0 ) {\n\n\t\t\t\t\tdeleteTexture( texture );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// store references to cache key and WebGLTexture object\n\n\t\t\ttextureProperties.__cacheKey = textureCacheKey;\n\t\t\ttextureProperties.__webglTexture = webglTextures[ textureCacheKey ].texture;\n\n\t\t}\n\n\t\treturn forceUpload;\n\n\t}\n\n\tfunction uploadTexture( textureProperties, texture, slot ) {\n\n\t\tlet textureType = 3553;\n\n\t\tif ( texture.isDataArrayTexture ) textureType = 35866;\n\t\tif ( texture.isData3DTexture ) textureType = 32879;\n\n\t\tconst forceUpload = initTexture( textureProperties, texture );\n\t\tconst source = texture.source;\n\n\t\tstate.activeTexture( 33984 + slot );\n\t\tstate.bindTexture( textureType, textureProperties.__webglTexture );\n\n\t\tif ( source.version !== source.__currentVersion || forceUpload === true ) {\n\n\t\t\t_gl.pixelStorei( 37440, texture.flipY );\n\t\t\t_gl.pixelStorei( 37441, texture.premultiplyAlpha );\n\t\t\t_gl.pixelStorei( 3317, texture.unpackAlignment );\n\t\t\t_gl.pixelStorei( 37443, 0 );\n\n\t\t\tconst needsPowerOfTwo = textureNeedsPowerOfTwo( texture ) && isPowerOfTwo$1( texture.image ) === false;\n\t\t\tlet image = resizeImage( texture.image, needsPowerOfTwo, false, maxTextureSize );\n\t\t\timage = verifyColorSpace( texture, image );\n\n\t\t\tconst supportsMips = isPowerOfTwo$1( image ) || isWebGL2,\n\t\t\t\tglFormat = utils.convert( texture.format, texture.encoding );\n\n\t\t\tlet glType = utils.convert( texture.type ),\n\t\t\t\tglInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.encoding, texture.isVideoTexture );\n\n\t\t\tsetTextureParameters( textureType, texture, supportsMips );\n\n\t\t\tlet mipmap;\n\t\t\tconst mipmaps = texture.mipmaps;\n\n\t\t\tconst useTexStorage = ( isWebGL2 && texture.isVideoTexture !== true );\n\t\t\tconst allocateMemory = ( textureProperties.__version === undefined );\n\t\t\tconst levels = getMipLevels( texture, image, supportsMips );\n\n\t\t\tif ( texture.isDepthTexture ) {\n\n\t\t\t\t// populate depth texture with dummy data\n\n\t\t\t\tglInternalFormat = 6402;\n\n\t\t\t\tif ( isWebGL2 ) {\n\n\t\t\t\t\tif ( texture.type === FloatType ) {\n\n\t\t\t\t\t\tglInternalFormat = 36012;\n\n\t\t\t\t\t} else if ( texture.type === UnsignedIntType ) {\n\n\t\t\t\t\t\tglInternalFormat = 33190;\n\n\t\t\t\t\t} else if ( texture.type === UnsignedInt248Type ) {\n\n\t\t\t\t\t\tglInternalFormat = 35056;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tglInternalFormat = 33189; // WebGL2 requires sized internalformat for glTexImage2D\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( texture.type === FloatType ) {\n\n\t\t\t\t\t\tconsole.error( 'WebGLRenderer: Floating point depth texture requires WebGL2.' );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\t// validation checks for WebGL 1\n\n\t\t\t\tif ( texture.format === DepthFormat && glInternalFormat === 6402 ) {\n\n\t\t\t\t\t// The error INVALID_OPERATION is generated by texImage2D if format and internalformat are\n\t\t\t\t\t// DEPTH_COMPONENT and type is not UNSIGNED_SHORT or UNSIGNED_INT\n\t\t\t\t\t// (https://www.khronos.org/registry/webgl/extensions/WEBGL_depth_texture/)\n\t\t\t\t\tif ( texture.type !== UnsignedShortType && texture.type !== UnsignedIntType ) {\n\n\t\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Use UnsignedShortType or UnsignedIntType for DepthFormat DepthTexture.' );\n\n\t\t\t\t\t\ttexture.type = UnsignedShortType;\n\t\t\t\t\t\tglType = utils.convert( texture.type );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tif ( texture.format === DepthStencilFormat && glInternalFormat === 6402 ) {\n\n\t\t\t\t\t// Depth stencil textures need the DEPTH_STENCIL internal format\n\t\t\t\t\t// (https://www.khronos.org/registry/webgl/extensions/WEBGL_depth_texture/)\n\t\t\t\t\tglInternalFormat = 34041;\n\n\t\t\t\t\t// The error INVALID_OPERATION is generated by texImage2D if format and internalformat are\n\t\t\t\t\t// DEPTH_STENCIL and type is not UNSIGNED_INT_24_8_WEBGL.\n\t\t\t\t\t// (https://www.khronos.org/registry/webgl/extensions/WEBGL_depth_texture/)\n\t\t\t\t\tif ( texture.type !== UnsignedInt248Type ) {\n\n\t\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Use UnsignedInt248Type for DepthStencilFormat DepthTexture.' );\n\n\t\t\t\t\t\ttexture.type = UnsignedInt248Type;\n\t\t\t\t\t\tglType = utils.convert( texture.type );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\t//\n\n\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\tstate.texStorage2D( 3553, 1, glInternalFormat, image.width, image.height );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tstate.texImage2D( 3553, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, null );\n\n\t\t\t\t}\n\n\t\t\t} else if ( texture.isDataTexture ) {\n\n\t\t\t\t// use manually created mipmaps if available\n\t\t\t\t// if there are no manual mipmaps\n\t\t\t\t// set 0 level mipmap and then use GL to generate other mipmap levels\n\n\t\t\t\tif ( mipmaps.length > 0 && supportsMips ) {\n\n\t\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\t\tstate.texStorage2D( 3553, levels, glInternalFormat, mipmaps[ 0 ].width, mipmaps[ 0 ].height );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tfor ( let i = 0, il = mipmaps.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tmipmap = mipmaps[ i ];\n\n\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\tstate.texSubImage2D( 3553, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tstate.texImage2D( 3553, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttexture.generateMipmaps = false;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\tif ( allocateMemory ) {\n\n\t\t\t\t\t\t\tstate.texStorage2D( 3553, levels, glInternalFormat, image.width, image.height );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tstate.texSubImage2D( 3553, 0, 0, 0, image.width, image.height, glFormat, glType, image.data );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tstate.texImage2D( 3553, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, image.data );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else if ( texture.isCompressedTexture ) {\n\n\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\tstate.texStorage2D( 3553, levels, glInternalFormat, mipmaps[ 0 ].width, mipmaps[ 0 ].height );\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let i = 0, il = mipmaps.length; i < il; i ++ ) {\n\n\t\t\t\t\tmipmap = mipmaps[ i ];\n\n\t\t\t\t\tif ( texture.format !== RGBAFormat ) {\n\n\t\t\t\t\t\tif ( glFormat !== null ) {\n\n\t\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\t\tstate.compressedTexSubImage2D( 3553, i, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\tstate.compressedTexImage2D( 3553, i, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()' );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\tstate.texSubImage2D( 3553, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tstate.texImage2D( 3553, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else if ( texture.isDataArrayTexture ) {\n\n\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\tif ( allocateMemory ) {\n\n\t\t\t\t\t\tstate.texStorage3D( 35866, levels, glInternalFormat, image.width, image.height, image.depth );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tstate.texSubImage3D( 35866, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tstate.texImage3D( 35866, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data );\n\n\t\t\t\t}\n\n\t\t\t} else if ( texture.isData3DTexture ) {\n\n\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\tif ( allocateMemory ) {\n\n\t\t\t\t\t\tstate.texStorage3D( 32879, levels, glInternalFormat, image.width, image.height, image.depth );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tstate.texSubImage3D( 32879, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tstate.texImage3D( 32879, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data );\n\n\t\t\t\t}\n\n\t\t\t} else if ( texture.isFramebufferTexture ) {\n\n\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\tstate.texStorage2D( 3553, levels, glInternalFormat, image.width, image.height );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tstate.texImage2D( 3553, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, null );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\t// regular Texture (image, video, canvas)\n\n\t\t\t\t// use manually created mipmaps if available\n\t\t\t\t// if there are no manual mipmaps\n\t\t\t\t// set 0 level mipmap and then use GL to generate other mipmap levels\n\n\t\t\t\tif ( mipmaps.length > 0 && supportsMips ) {\n\n\t\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\t\tstate.texStorage2D( 3553, levels, glInternalFormat, mipmaps[ 0 ].width, mipmaps[ 0 ].height );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tfor ( let i = 0, il = mipmaps.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tmipmap = mipmaps[ i ];\n\n\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\tstate.texSubImage2D( 3553, i, 0, 0, glFormat, glType, mipmap );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tstate.texImage2D( 3553, i, glInternalFormat, glFormat, glType, mipmap );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttexture.generateMipmaps = false;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\tif ( allocateMemory ) {\n\n\t\t\t\t\t\t\tstate.texStorage2D( 3553, levels, glInternalFormat, image.width, image.height );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tstate.texSubImage2D( 3553, 0, 0, 0, glFormat, glType, image );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tstate.texImage2D( 3553, 0, glInternalFormat, glFormat, glType, image );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( textureNeedsGenerateMipmaps( texture, supportsMips ) ) {\n\n\t\t\t\tgenerateMipmap( textureType );\n\n\t\t\t}\n\n\t\t\tsource.__currentVersion = source.version;\n\n\t\t\tif ( texture.onUpdate ) texture.onUpdate( texture );\n\n\t\t}\n\n\t\ttextureProperties.__version = texture.version;\n\n\t}\n\n\tfunction uploadCubeTexture( textureProperties, texture, slot ) {\n\n\t\tif ( texture.image.length !== 6 ) return;\n\n\t\tconst forceUpload = initTexture( textureProperties, texture );\n\t\tconst source = texture.source;\n\n\t\tstate.activeTexture( 33984 + slot );\n\t\tstate.bindTexture( 34067, textureProperties.__webglTexture );\n\n\t\tif ( source.version !== source.__currentVersion || forceUpload === true ) {\n\n\t\t\t_gl.pixelStorei( 37440, texture.flipY );\n\t\t\t_gl.pixelStorei( 37441, texture.premultiplyAlpha );\n\t\t\t_gl.pixelStorei( 3317, texture.unpackAlignment );\n\t\t\t_gl.pixelStorei( 37443, 0 );\n\n\t\t\tconst isCompressed = ( texture.isCompressedTexture || texture.image[ 0 ].isCompressedTexture );\n\t\t\tconst isDataTexture = ( texture.image[ 0 ] && texture.image[ 0 ].isDataTexture );\n\n\t\t\tconst cubeImage = [];\n\n\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\tif ( ! isCompressed && ! isDataTexture ) {\n\n\t\t\t\t\tcubeImage[ i ] = resizeImage( texture.image[ i ], false, true, maxCubemapSize );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tcubeImage[ i ] = isDataTexture ? texture.image[ i ].image : texture.image[ i ];\n\n\t\t\t\t}\n\n\t\t\t\tcubeImage[ i ] = verifyColorSpace( texture, cubeImage[ i ] );\n\n\t\t\t}\n\n\t\t\tconst image = cubeImage[ 0 ],\n\t\t\t\tsupportsMips = isPowerOfTwo$1( image ) || isWebGL2,\n\t\t\t\tglFormat = utils.convert( texture.format, texture.encoding ),\n\t\t\t\tglType = utils.convert( texture.type ),\n\t\t\t\tglInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.encoding );\n\n\t\t\tconst useTexStorage = ( isWebGL2 && texture.isVideoTexture !== true );\n\t\t\tconst allocateMemory = ( textureProperties.__version === undefined );\n\t\t\tlet levels = getMipLevels( texture, image, supportsMips );\n\n\t\t\tsetTextureParameters( 34067, texture, supportsMips );\n\n\t\t\tlet mipmaps;\n\n\t\t\tif ( isCompressed ) {\n\n\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\tstate.texStorage2D( 34067, levels, glInternalFormat, image.width, image.height );\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\t\tmipmaps = cubeImage[ i ].mipmaps;\n\n\t\t\t\t\tfor ( let j = 0; j < mipmaps.length; j ++ ) {\n\n\t\t\t\t\t\tconst mipmap = mipmaps[ j ];\n\n\t\t\t\t\t\tif ( texture.format !== RGBAFormat ) {\n\n\t\t\t\t\t\t\tif ( glFormat !== null ) {\n\n\t\t\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\t\t\tstate.compressedTexSubImage2D( 34069 + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data );\n\n\t\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\t\tstate.compressedTexImage2D( 34069 + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data );\n\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .setTextureCube()' );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\t\tstate.texSubImage2D( 34069 + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\tstate.texImage2D( 34069 + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tmipmaps = texture.mipmaps;\n\n\t\t\t\tif ( useTexStorage && allocateMemory ) {\n\n\t\t\t\t\t// TODO: Uniformly handle mipmap definitions\n\t\t\t\t\t// Normal textures and compressed cube textures define base level + mips with their mipmap array\n\t\t\t\t\t// Uncompressed cube textures use their mipmap array only for mips (no base level)\n\n\t\t\t\t\tif ( mipmaps.length > 0 ) levels ++;\n\n\t\t\t\t\tstate.texStorage2D( 34067, levels, glInternalFormat, cubeImage[ 0 ].width, cubeImage[ 0 ].height );\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\t\tif ( isDataTexture ) {\n\n\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\tstate.texSubImage2D( 34069 + i, 0, 0, 0, cubeImage[ i ].width, cubeImage[ i ].height, glFormat, glType, cubeImage[ i ].data );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tstate.texImage2D( 34069 + i, 0, glInternalFormat, cubeImage[ i ].width, cubeImage[ i ].height, 0, glFormat, glType, cubeImage[ i ].data );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tfor ( let j = 0; j < mipmaps.length; j ++ ) {\n\n\t\t\t\t\t\t\tconst mipmap = mipmaps[ j ];\n\t\t\t\t\t\t\tconst mipmapImage = mipmap.image[ i ].image;\n\n\t\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\t\tstate.texSubImage2D( 34069 + i, j + 1, 0, 0, mipmapImage.width, mipmapImage.height, glFormat, glType, mipmapImage.data );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\tstate.texImage2D( 34069 + i, j + 1, glInternalFormat, mipmapImage.width, mipmapImage.height, 0, glFormat, glType, mipmapImage.data );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\tstate.texSubImage2D( 34069 + i, 0, 0, 0, glFormat, glType, cubeImage[ i ] );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tstate.texImage2D( 34069 + i, 0, glInternalFormat, glFormat, glType, cubeImage[ i ] );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tfor ( let j = 0; j < mipmaps.length; j ++ ) {\n\n\t\t\t\t\t\t\tconst mipmap = mipmaps[ j ];\n\n\t\t\t\t\t\t\tif ( useTexStorage ) {\n\n\t\t\t\t\t\t\t\tstate.texSubImage2D( 34069 + i, j + 1, 0, 0, glFormat, glType, mipmap.image[ i ] );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\tstate.texImage2D( 34069 + i, j + 1, glInternalFormat, glFormat, glType, mipmap.image[ i ] );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( textureNeedsGenerateMipmaps( texture, supportsMips ) ) {\n\n\t\t\t\t// We assume images for cube map have the same size.\n\t\t\t\tgenerateMipmap( 34067 );\n\n\t\t\t}\n\n\t\t\tsource.__currentVersion = source.version;\n\n\t\t\tif ( texture.onUpdate ) texture.onUpdate( texture );\n\n\t\t}\n\n\t\ttextureProperties.__version = texture.version;\n\n\t}\n\n\t// Render targets\n\n\t// Setup storage for target texture and bind it to correct framebuffer\n\tfunction setupFrameBufferTexture( framebuffer, renderTarget, texture, attachment, textureTarget ) {\n\n\t\tconst glFormat = utils.convert( texture.format, texture.encoding );\n\t\tconst glType = utils.convert( texture.type );\n\t\tconst glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.encoding );\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\n\t\tif ( ! renderTargetProperties.__hasExternalTextures ) {\n\n\t\t\tif ( textureTarget === 32879 || textureTarget === 35866 ) {\n\n\t\t\t\tstate.texImage3D( textureTarget, 0, glInternalFormat, renderTarget.width, renderTarget.height, renderTarget.depth, 0, glFormat, glType, null );\n\n\t\t\t} else {\n\n\t\t\t\tstate.texImage2D( textureTarget, 0, glInternalFormat, renderTarget.width, renderTarget.height, 0, glFormat, glType, null );\n\n\t\t\t}\n\n\t\t}\n\n\t\tstate.bindFramebuffer( 36160, framebuffer );\n\n\t\tif ( useMultisampledRTT( renderTarget ) ) {\n\n\t\t\tmultisampledRTTExt.framebufferTexture2DMultisampleEXT( 36160, attachment, textureTarget, properties.get( texture ).__webglTexture, 0, getRenderTargetSamples( renderTarget ) );\n\n\t\t} else {\n\n\t\t\t_gl.framebufferTexture2D( 36160, attachment, textureTarget, properties.get( texture ).__webglTexture, 0 );\n\n\t\t}\n\n\t\tstate.bindFramebuffer( 36160, null );\n\n\t}\n\n\n\t// Setup storage for internal depth/stencil buffers and bind to correct framebuffer\n\tfunction setupRenderBufferStorage( renderbuffer, renderTarget, isMultisample ) {\n\n\t\t_gl.bindRenderbuffer( 36161, renderbuffer );\n\n\t\tif ( renderTarget.depthBuffer && ! renderTarget.stencilBuffer ) {\n\n\t\t\tlet glInternalFormat = 33189;\n\n\t\t\tif ( isMultisample || useMultisampledRTT( renderTarget ) ) {\n\n\t\t\t\tconst depthTexture = renderTarget.depthTexture;\n\n\t\t\t\tif ( depthTexture && depthTexture.isDepthTexture ) {\n\n\t\t\t\t\tif ( depthTexture.type === FloatType ) {\n\n\t\t\t\t\t\tglInternalFormat = 36012;\n\n\t\t\t\t\t} else if ( depthTexture.type === UnsignedIntType ) {\n\n\t\t\t\t\t\tglInternalFormat = 33190;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tconst samples = getRenderTargetSamples( renderTarget );\n\n\t\t\t\tif ( useMultisampledRTT( renderTarget ) ) {\n\n\t\t\t\t\tmultisampledRTTExt.renderbufferStorageMultisampleEXT( 36161, samples, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t_gl.renderbufferStorageMultisample( 36161, samples, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\t_gl.renderbufferStorage( 36161, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t}\n\n\t\t\t_gl.framebufferRenderbuffer( 36160, 36096, 36161, renderbuffer );\n\n\t\t} else if ( renderTarget.depthBuffer && renderTarget.stencilBuffer ) {\n\n\t\t\tconst samples = getRenderTargetSamples( renderTarget );\n\n\t\t\tif ( isMultisample && useMultisampledRTT( renderTarget ) === false ) {\n\n\t\t\t\t_gl.renderbufferStorageMultisample( 36161, samples, 35056, renderTarget.width, renderTarget.height );\n\n\t\t\t} else if ( useMultisampledRTT( renderTarget ) ) {\n\n\t\t\t\tmultisampledRTTExt.renderbufferStorageMultisampleEXT( 36161, samples, 35056, renderTarget.width, renderTarget.height );\n\n\t\t\t} else {\n\n\t\t\t\t_gl.renderbufferStorage( 36161, 34041, renderTarget.width, renderTarget.height );\n\n\t\t\t}\n\n\n\t\t\t_gl.framebufferRenderbuffer( 36160, 33306, 36161, renderbuffer );\n\n\t\t} else {\n\n\t\t\t// Use the first texture for MRT so far\n\t\t\tconst texture = renderTarget.isWebGLMultipleRenderTargets === true ? renderTarget.texture[ 0 ] : renderTarget.texture;\n\n\t\t\tconst glFormat = utils.convert( texture.format, texture.encoding );\n\t\t\tconst glType = utils.convert( texture.type );\n\t\t\tconst glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.encoding );\n\t\t\tconst samples = getRenderTargetSamples( renderTarget );\n\n\t\t\tif ( isMultisample && useMultisampledRTT( renderTarget ) === false ) {\n\n\t\t\t\t_gl.renderbufferStorageMultisample( 36161, samples, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t} else if ( useMultisampledRTT( renderTarget ) ) {\n\n\t\t\t\tmultisampledRTTExt.renderbufferStorageMultisampleEXT( 36161, samples, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t} else {\n\n\t\t\t\t_gl.renderbufferStorage( 36161, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t}\n\n\t\t}\n\n\t\t_gl.bindRenderbuffer( 36161, null );\n\n\t}\n\n\t// Setup resources for a Depth Texture for a FBO (needs an extension)\n\tfunction setupDepthTexture( framebuffer, renderTarget ) {\n\n\t\tconst isCube = ( renderTarget && renderTarget.isWebGLCubeRenderTarget );\n\t\tif ( isCube ) throw new Error( 'Depth Texture with cube render targets is not supported' );\n\n\t\tstate.bindFramebuffer( 36160, framebuffer );\n\n\t\tif ( ! ( renderTarget.depthTexture && renderTarget.depthTexture.isDepthTexture ) ) {\n\n\t\t\tthrow new Error( 'renderTarget.depthTexture must be an instance of THREE.DepthTexture' );\n\n\t\t}\n\n\t\t// upload an empty depth texture with framebuffer size\n\t\tif ( ! properties.get( renderTarget.depthTexture ).__webglTexture ||\n\t\t\t\trenderTarget.depthTexture.image.width !== renderTarget.width ||\n\t\t\t\trenderTarget.depthTexture.image.height !== renderTarget.height ) {\n\n\t\t\trenderTarget.depthTexture.image.width = renderTarget.width;\n\t\t\trenderTarget.depthTexture.image.height = renderTarget.height;\n\t\t\trenderTarget.depthTexture.needsUpdate = true;\n\n\t\t}\n\n\t\tsetTexture2D( renderTarget.depthTexture, 0 );\n\n\t\tconst webglDepthTexture = properties.get( renderTarget.depthTexture ).__webglTexture;\n\t\tconst samples = getRenderTargetSamples( renderTarget );\n\n\t\tif ( renderTarget.depthTexture.format === DepthFormat ) {\n\n\t\t\tif ( useMultisampledRTT( renderTarget ) ) {\n\n\t\t\t\tmultisampledRTTExt.framebufferTexture2DMultisampleEXT( 36160, 36096, 3553, webglDepthTexture, 0, samples );\n\n\t\t\t} else {\n\n\t\t\t\t_gl.framebufferTexture2D( 36160, 36096, 3553, webglDepthTexture, 0 );\n\n\t\t\t}\n\n\t\t} else if ( renderTarget.depthTexture.format === DepthStencilFormat ) {\n\n\t\t\tif ( useMultisampledRTT( renderTarget ) ) {\n\n\t\t\t\tmultisampledRTTExt.framebufferTexture2DMultisampleEXT( 36160, 33306, 3553, webglDepthTexture, 0, samples );\n\n\t\t\t} else {\n\n\t\t\t\t_gl.framebufferTexture2D( 36160, 33306, 3553, webglDepthTexture, 0 );\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tthrow new Error( 'Unknown depthTexture format' );\n\n\t\t}\n\n\t}\n\n\t// Setup GL resources for a non-texture depth buffer\n\tfunction setupDepthRenderbuffer( renderTarget ) {\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\t\tconst isCube = ( renderTarget.isWebGLCubeRenderTarget === true );\n\n\t\tif ( renderTarget.depthTexture && ! renderTargetProperties.__autoAllocateDepthBuffer ) {\n\n\t\t\tif ( isCube ) throw new Error( 'target.depthTexture not supported in Cube render targets' );\n\n\t\t\tsetupDepthTexture( renderTargetProperties.__webglFramebuffer, renderTarget );\n\n\t\t} else {\n\n\t\t\tif ( isCube ) {\n\n\t\t\t\trenderTargetProperties.__webglDepthbuffer = [];\n\n\t\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\t\tstate.bindFramebuffer( 36160, renderTargetProperties.__webglFramebuffer[ i ] );\n\t\t\t\t\trenderTargetProperties.__webglDepthbuffer[ i ] = _gl.createRenderbuffer();\n\t\t\t\t\tsetupRenderBufferStorage( renderTargetProperties.__webglDepthbuffer[ i ], renderTarget, false );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tstate.bindFramebuffer( 36160, renderTargetProperties.__webglFramebuffer );\n\t\t\t\trenderTargetProperties.__webglDepthbuffer = _gl.createRenderbuffer();\n\t\t\t\tsetupRenderBufferStorage( renderTargetProperties.__webglDepthbuffer, renderTarget, false );\n\n\t\t\t}\n\n\t\t}\n\n\t\tstate.bindFramebuffer( 36160, null );\n\n\t}\n\n\t// rebind framebuffer with external textures\n\tfunction rebindTextures( renderTarget, colorTexture, depthTexture ) {\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\n\t\tif ( colorTexture !== undefined ) {\n\n\t\t\tsetupFrameBufferTexture( renderTargetProperties.__webglFramebuffer, renderTarget, renderTarget.texture, 36064, 3553 );\n\n\t\t}\n\n\t\tif ( depthTexture !== undefined ) {\n\n\t\t\tsetupDepthRenderbuffer( renderTarget );\n\n\t\t}\n\n\t}\n\n\t// Set up GL resources for the render target\n\tfunction setupRenderTarget( renderTarget ) {\n\n\t\tconst texture = renderTarget.texture;\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\t\tconst textureProperties = properties.get( texture );\n\n\t\trenderTarget.addEventListener( 'dispose', onRenderTargetDispose );\n\n\t\tif ( renderTarget.isWebGLMultipleRenderTargets !== true ) {\n\n\t\t\tif ( textureProperties.__webglTexture === undefined ) {\n\n\t\t\t\ttextureProperties.__webglTexture = _gl.createTexture();\n\n\t\t\t}\n\n\t\t\ttextureProperties.__version = texture.version;\n\t\t\tinfo.memory.textures ++;\n\n\t\t}\n\n\t\tconst isCube = ( renderTarget.isWebGLCubeRenderTarget === true );\n\t\tconst isMultipleRenderTargets = ( renderTarget.isWebGLMultipleRenderTargets === true );\n\t\tconst supportsMips = isPowerOfTwo$1( renderTarget ) || isWebGL2;\n\n\t\t// Setup framebuffer\n\n\t\tif ( isCube ) {\n\n\t\t\trenderTargetProperties.__webglFramebuffer = [];\n\n\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\trenderTargetProperties.__webglFramebuffer[ i ] = _gl.createFramebuffer();\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\trenderTargetProperties.__webglFramebuffer = _gl.createFramebuffer();\n\n\t\t\tif ( isMultipleRenderTargets ) {\n\n\t\t\t\tif ( capabilities.drawBuffers ) {\n\n\t\t\t\t\tconst textures = renderTarget.texture;\n\n\t\t\t\t\tfor ( let i = 0, il = textures.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tconst attachmentProperties = properties.get( textures[ i ] );\n\n\t\t\t\t\t\tif ( attachmentProperties.__webglTexture === undefined ) {\n\n\t\t\t\t\t\t\tattachmentProperties.__webglTexture = _gl.createTexture();\n\n\t\t\t\t\t\t\tinfo.memory.textures ++;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: WebGLMultipleRenderTargets can only be used with WebGL2 or WEBGL_draw_buffers extension.' );\n\n\t\t\t\t}\n\n\t\t\t} else if ( ( isWebGL2 && renderTarget.samples > 0 ) && useMultisampledRTT( renderTarget ) === false ) {\n\n\t\t\t\trenderTargetProperties.__webglMultisampledFramebuffer = _gl.createFramebuffer();\n\t\t\t\trenderTargetProperties.__webglColorRenderbuffer = _gl.createRenderbuffer();\n\n\t\t\t\t_gl.bindRenderbuffer( 36161, renderTargetProperties.__webglColorRenderbuffer );\n\n\t\t\t\tconst glFormat = utils.convert( texture.format, texture.encoding );\n\t\t\t\tconst glType = utils.convert( texture.type );\n\t\t\t\tconst glInternalFormat = getInternalFormat( texture.internalFormat, glFormat, glType, texture.encoding );\n\t\t\t\tconst samples = getRenderTargetSamples( renderTarget );\n\t\t\t\t_gl.renderbufferStorageMultisample( 36161, samples, glInternalFormat, renderTarget.width, renderTarget.height );\n\n\t\t\t\tstate.bindFramebuffer( 36160, renderTargetProperties.__webglMultisampledFramebuffer );\n\t\t\t\t_gl.framebufferRenderbuffer( 36160, 36064, 36161, renderTargetProperties.__webglColorRenderbuffer );\n\t\t\t\t_gl.bindRenderbuffer( 36161, null );\n\n\t\t\t\tif ( renderTarget.depthBuffer ) {\n\n\t\t\t\t\trenderTargetProperties.__webglDepthRenderbuffer = _gl.createRenderbuffer();\n\t\t\t\t\tsetupRenderBufferStorage( renderTargetProperties.__webglDepthRenderbuffer, renderTarget, true );\n\n\t\t\t\t}\n\n\t\t\t\tstate.bindFramebuffer( 36160, null );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Setup color buffer\n\n\t\tif ( isCube ) {\n\n\t\t\tstate.bindTexture( 34067, textureProperties.__webglTexture );\n\t\t\tsetTextureParameters( 34067, texture, supportsMips );\n\n\t\t\tfor ( let i = 0; i < 6; i ++ ) {\n\n\t\t\t\tsetupFrameBufferTexture( renderTargetProperties.__webglFramebuffer[ i ], renderTarget, texture, 36064, 34069 + i );\n\n\t\t\t}\n\n\t\t\tif ( textureNeedsGenerateMipmaps( texture, supportsMips ) ) {\n\n\t\t\t\tgenerateMipmap( 34067 );\n\n\t\t\t}\n\n\t\t\tstate.unbindTexture();\n\n\t\t} else if ( isMultipleRenderTargets ) {\n\n\t\t\tconst textures = renderTarget.texture;\n\n\t\t\tfor ( let i = 0, il = textures.length; i < il; i ++ ) {\n\n\t\t\t\tconst attachment = textures[ i ];\n\t\t\t\tconst attachmentProperties = properties.get( attachment );\n\n\t\t\t\tstate.bindTexture( 3553, attachmentProperties.__webglTexture );\n\t\t\t\tsetTextureParameters( 3553, attachment, supportsMips );\n\t\t\t\tsetupFrameBufferTexture( renderTargetProperties.__webglFramebuffer, renderTarget, attachment, 36064 + i, 3553 );\n\n\t\t\t\tif ( textureNeedsGenerateMipmaps( attachment, supportsMips ) ) {\n\n\t\t\t\t\tgenerateMipmap( 3553 );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tstate.unbindTexture();\n\n\t\t} else {\n\n\t\t\tlet glTextureType = 3553;\n\n\t\t\tif ( renderTarget.isWebGL3DRenderTarget || renderTarget.isWebGLArrayRenderTarget ) {\n\n\t\t\t\tif ( isWebGL2 ) {\n\n\t\t\t\t\tglTextureType = renderTarget.isWebGL3DRenderTarget ? 32879 : 35866;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( 'THREE.WebGLTextures: THREE.Data3DTexture and THREE.DataArrayTexture only supported with WebGL2.' );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tstate.bindTexture( glTextureType, textureProperties.__webglTexture );\n\t\t\tsetTextureParameters( glTextureType, texture, supportsMips );\n\t\t\tsetupFrameBufferTexture( renderTargetProperties.__webglFramebuffer, renderTarget, texture, 36064, glTextureType );\n\n\t\t\tif ( textureNeedsGenerateMipmaps( texture, supportsMips ) ) {\n\n\t\t\t\tgenerateMipmap( glTextureType );\n\n\t\t\t}\n\n\t\t\tstate.unbindTexture();\n\n\t\t}\n\n\t\t// Setup depth and stencil buffers\n\n\t\tif ( renderTarget.depthBuffer ) {\n\n\t\t\tsetupDepthRenderbuffer( renderTarget );\n\n\t\t}\n\n\t}\n\n\tfunction updateRenderTargetMipmap( renderTarget ) {\n\n\t\tconst supportsMips = isPowerOfTwo$1( renderTarget ) || isWebGL2;\n\n\t\tconst textures = renderTarget.isWebGLMultipleRenderTargets === true ? renderTarget.texture : [ renderTarget.texture ];\n\n\t\tfor ( let i = 0, il = textures.length; i < il; i ++ ) {\n\n\t\t\tconst texture = textures[ i ];\n\n\t\t\tif ( textureNeedsGenerateMipmaps( texture, supportsMips ) ) {\n\n\t\t\t\tconst target = renderTarget.isWebGLCubeRenderTarget ? 34067 : 3553;\n\t\t\t\tconst webglTexture = properties.get( texture ).__webglTexture;\n\n\t\t\t\tstate.bindTexture( target, webglTexture );\n\t\t\t\tgenerateMipmap( target );\n\t\t\t\tstate.unbindTexture();\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tfunction updateMultisampleRenderTarget( renderTarget ) {\n\n\t\tif ( ( isWebGL2 && renderTarget.samples > 0 ) && useMultisampledRTT( renderTarget ) === false ) {\n\n\t\t\tconst width = renderTarget.width;\n\t\t\tconst height = renderTarget.height;\n\t\t\tlet mask = 16384;\n\t\t\tconst invalidationArray = [ 36064 ];\n\t\t\tconst depthStyle = renderTarget.stencilBuffer ? 33306 : 36096;\n\n\t\t\tif ( renderTarget.depthBuffer ) {\n\n\t\t\t\tinvalidationArray.push( depthStyle );\n\n\t\t\t}\n\n\t\t\tconst renderTargetProperties = properties.get( renderTarget );\n\t\t\tconst ignoreDepthValues = ( renderTargetProperties.__ignoreDepthValues !== undefined ) ? renderTargetProperties.__ignoreDepthValues : false;\n\n\t\t\tif ( ignoreDepthValues === false ) {\n\n\t\t\t\tif ( renderTarget.depthBuffer ) mask |= 256;\n\t\t\t\tif ( renderTarget.stencilBuffer ) mask |= 1024;\n\n\t\t\t}\n\n\t\t\tstate.bindFramebuffer( 36008, renderTargetProperties.__webglMultisampledFramebuffer );\n\t\t\tstate.bindFramebuffer( 36009, renderTargetProperties.__webglFramebuffer );\n\n\t\t\tif ( ignoreDepthValues === true ) {\n\n\t\t\t\t_gl.invalidateFramebuffer( 36008, [ depthStyle ] );\n\t\t\t\t_gl.invalidateFramebuffer( 36009, [ depthStyle ] );\n\n\t\t\t}\n\n\t\t\t_gl.blitFramebuffer( 0, 0, width, height, 0, 0, width, height, mask, 9728 );\n\t\t\t_gl.invalidateFramebuffer( 36008, invalidationArray );\n\n\t\t\tstate.bindFramebuffer( 36008, null );\n\t\t\tstate.bindFramebuffer( 36009, renderTargetProperties.__webglMultisampledFramebuffer );\n\n\t\t}\n\n\t}\n\n\tfunction getRenderTargetSamples( renderTarget ) {\n\n\t\treturn Math.min( maxSamples, renderTarget.samples );\n\n\t}\n\n\tfunction useMultisampledRTT( renderTarget ) {\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\n\t\treturn isWebGL2 && renderTarget.samples > 0 && extensions.has( 'WEBGL_multisampled_render_to_texture' ) === true && renderTargetProperties.__useRenderToTexture !== false;\n\n\t}\n\n\tfunction updateVideoTexture( texture ) {\n\n\t\tconst frame = info.render.frame;\n\n\t\t// Check the last frame we updated the VideoTexture\n\n\t\tif ( _videoTextures.get( texture ) !== frame ) {\n\n\t\t\t_videoTextures.set( texture, frame );\n\t\t\ttexture.update();\n\n\t\t}\n\n\t}\n\n\tfunction verifyColorSpace( texture, image ) {\n\n\t\tconst encoding = texture.encoding;\n\t\tconst format = texture.format;\n\t\tconst type = texture.type;\n\n\t\tif ( texture.isCompressedTexture === true || texture.isVideoTexture === true || texture.format === _SRGBAFormat ) return image;\n\n\t\tif ( encoding !== LinearEncoding ) {\n\n\t\t\t// sRGB\n\n\t\t\tif ( encoding === sRGBEncoding ) {\n\n\t\t\t\tif ( isWebGL2 === false ) {\n\n\t\t\t\t\t// in WebGL 1, try to use EXT_sRGB extension and unsized formats\n\n\t\t\t\t\tif ( extensions.has( 'EXT_sRGB' ) === true && format === RGBAFormat ) {\n\n\t\t\t\t\t\ttexture.format = _SRGBAFormat;\n\n\t\t\t\t\t\t// it's not possible to generate mips in WebGL 1 with this extension\n\n\t\t\t\t\t\ttexture.minFilter = LinearFilter;\n\t\t\t\t\t\ttexture.generateMipmaps = false;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t// slow fallback (CPU decode)\n\n\t\t\t\t\t\timage = ImageUtils.sRGBToLinear( image );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// in WebGL 2 uncompressed textures can only be sRGB encoded if they have the RGBA8 format\n\n\t\t\t\t\tif ( format !== RGBAFormat || type !== UnsignedByteType ) {\n\n\t\t\t\t\t\tconsole.warn( 'THREE.WebGLTextures: sRGB encoded textures have to use RGBAFormat and UnsignedByteType.' );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tconsole.error( 'THREE.WebGLTextures: Unsupported texture encoding:', encoding );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn image;\n\n\t}\n\n\t//\n\n\tthis.allocateTextureUnit = allocateTextureUnit;\n\tthis.resetTextureUnits = resetTextureUnits;\n\n\tthis.setTexture2D = setTexture2D;\n\tthis.setTexture2DArray = setTexture2DArray;\n\tthis.setTexture3D = setTexture3D;\n\tthis.setTextureCube = setTextureCube;\n\tthis.rebindTextures = rebindTextures;\n\tthis.setupRenderTarget = setupRenderTarget;\n\tthis.updateRenderTargetMipmap = updateRenderTargetMipmap;\n\tthis.updateMultisampleRenderTarget = updateMultisampleRenderTarget;\n\tthis.setupDepthRenderbuffer = setupDepthRenderbuffer;\n\tthis.setupFrameBufferTexture = setupFrameBufferTexture;\n\tthis.useMultisampledRTT = useMultisampledRTT;\n\n}\n\nfunction WebGLUtils( gl, extensions, capabilities ) {\n\n\tconst isWebGL2 = capabilities.isWebGL2;\n\n\tfunction convert( p, encoding = null ) {\n\n\t\tlet extension;\n\n\t\tif ( p === UnsignedByteType ) return 5121;\n\t\tif ( p === UnsignedShort4444Type ) return 32819;\n\t\tif ( p === UnsignedShort5551Type ) return 32820;\n\n\t\tif ( p === ByteType ) return 5120;\n\t\tif ( p === ShortType ) return 5122;\n\t\tif ( p === UnsignedShortType ) return 5123;\n\t\tif ( p === IntType ) return 5124;\n\t\tif ( p === UnsignedIntType ) return 5125;\n\t\tif ( p === FloatType ) return 5126;\n\n\t\tif ( p === HalfFloatType ) {\n\n\t\t\tif ( isWebGL2 ) return 5131;\n\n\t\t\textension = extensions.get( 'OES_texture_half_float' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\treturn extension.HALF_FLOAT_OES;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( p === AlphaFormat ) return 6406;\n\t\tif ( p === RGBAFormat ) return 6408;\n\t\tif ( p === LuminanceFormat ) return 6409;\n\t\tif ( p === LuminanceAlphaFormat ) return 6410;\n\t\tif ( p === DepthFormat ) return 6402;\n\t\tif ( p === DepthStencilFormat ) return 34041;\n\t\tif ( p === RedFormat ) return 6403;\n\n\t\tif ( p === RGBFormat ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: THREE.RGBFormat has been removed. Use THREE.RGBAFormat instead. https://github.com/mrdoob/three.js/pull/23228' );\n\t\t\treturn 6408;\n\n\t\t}\n\n\t\t// WebGL 1 sRGB fallback\n\n\t\tif ( p === _SRGBAFormat ) {\n\n\t\t\textension = extensions.get( 'EXT_sRGB' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\treturn extension.SRGB_ALPHA_EXT;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// WebGL2 formats.\n\n\t\tif ( p === RedIntegerFormat ) return 36244;\n\t\tif ( p === RGFormat ) return 33319;\n\t\tif ( p === RGIntegerFormat ) return 33320;\n\t\tif ( p === RGBAIntegerFormat ) return 36249;\n\n\t\t// S3TC\n\n\t\tif ( p === RGB_S3TC_DXT1_Format || p === RGBA_S3TC_DXT1_Format || p === RGBA_S3TC_DXT3_Format || p === RGBA_S3TC_DXT5_Format ) {\n\n\t\t\tif ( encoding === sRGBEncoding ) {\n\n\t\t\t\textension = extensions.get( 'WEBGL_compressed_texture_s3tc_srgb' );\n\n\t\t\t\tif ( extension !== null ) {\n\n\t\t\t\t\tif ( p === RGB_S3TC_DXT1_Format ) return extension.COMPRESSED_SRGB_S3TC_DXT1_EXT;\n\t\t\t\t\tif ( p === RGBA_S3TC_DXT1_Format ) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT;\n\t\t\t\t\tif ( p === RGBA_S3TC_DXT3_Format ) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT;\n\t\t\t\t\tif ( p === RGBA_S3TC_DXT5_Format ) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT;\n\n\t\t\t\t} else {\n\n\t\t\t\t\treturn null;\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\textension = extensions.get( 'WEBGL_compressed_texture_s3tc' );\n\n\t\t\t\tif ( extension !== null ) {\n\n\t\t\t\t\tif ( p === RGB_S3TC_DXT1_Format ) return extension.COMPRESSED_RGB_S3TC_DXT1_EXT;\n\t\t\t\t\tif ( p === RGBA_S3TC_DXT1_Format ) return extension.COMPRESSED_RGBA_S3TC_DXT1_EXT;\n\t\t\t\t\tif ( p === RGBA_S3TC_DXT3_Format ) return extension.COMPRESSED_RGBA_S3TC_DXT3_EXT;\n\t\t\t\t\tif ( p === RGBA_S3TC_DXT5_Format ) return extension.COMPRESSED_RGBA_S3TC_DXT5_EXT;\n\n\t\t\t\t} else {\n\n\t\t\t\t\treturn null;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\t// PVRTC\n\n\t\tif ( p === RGB_PVRTC_4BPPV1_Format || p === RGB_PVRTC_2BPPV1_Format || p === RGBA_PVRTC_4BPPV1_Format || p === RGBA_PVRTC_2BPPV1_Format ) {\n\n\t\t\textension = extensions.get( 'WEBGL_compressed_texture_pvrtc' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\tif ( p === RGB_PVRTC_4BPPV1_Format ) return extension.COMPRESSED_RGB_PVRTC_4BPPV1_IMG;\n\t\t\t\tif ( p === RGB_PVRTC_2BPPV1_Format ) return extension.COMPRESSED_RGB_PVRTC_2BPPV1_IMG;\n\t\t\t\tif ( p === RGBA_PVRTC_4BPPV1_Format ) return extension.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;\n\t\t\t\tif ( p === RGBA_PVRTC_2BPPV1_Format ) return extension.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// ETC1\n\n\t\tif ( p === RGB_ETC1_Format ) {\n\n\t\t\textension = extensions.get( 'WEBGL_compressed_texture_etc1' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\treturn extension.COMPRESSED_RGB_ETC1_WEBGL;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// ETC2\n\n\t\tif ( p === RGB_ETC2_Format || p === RGBA_ETC2_EAC_Format ) {\n\n\t\t\textension = extensions.get( 'WEBGL_compressed_texture_etc' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\tif ( p === RGB_ETC2_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ETC2 : extension.COMPRESSED_RGB8_ETC2;\n\t\t\t\tif ( p === RGBA_ETC2_EAC_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC : extension.COMPRESSED_RGBA8_ETC2_EAC;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// ASTC\n\n\t\tif ( p === RGBA_ASTC_4x4_Format || p === RGBA_ASTC_5x4_Format || p === RGBA_ASTC_5x5_Format ||\n\t\t\tp === RGBA_ASTC_6x5_Format || p === RGBA_ASTC_6x6_Format || p === RGBA_ASTC_8x5_Format ||\n\t\t\tp === RGBA_ASTC_8x6_Format || p === RGBA_ASTC_8x8_Format || p === RGBA_ASTC_10x5_Format ||\n\t\t\tp === RGBA_ASTC_10x6_Format || p === RGBA_ASTC_10x8_Format || p === RGBA_ASTC_10x10_Format ||\n\t\t\tp === RGBA_ASTC_12x10_Format || p === RGBA_ASTC_12x12_Format ) {\n\n\t\t\textension = extensions.get( 'WEBGL_compressed_texture_astc' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\tif ( p === RGBA_ASTC_4x4_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR : extension.COMPRESSED_RGBA_ASTC_4x4_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_5x4_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR : extension.COMPRESSED_RGBA_ASTC_5x4_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_5x5_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR : extension.COMPRESSED_RGBA_ASTC_5x5_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_6x5_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR : extension.COMPRESSED_RGBA_ASTC_6x5_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_6x6_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR : extension.COMPRESSED_RGBA_ASTC_6x6_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_8x5_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR : extension.COMPRESSED_RGBA_ASTC_8x5_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_8x6_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR : extension.COMPRESSED_RGBA_ASTC_8x6_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_8x8_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR : extension.COMPRESSED_RGBA_ASTC_8x8_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_10x5_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR : extension.COMPRESSED_RGBA_ASTC_10x5_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_10x6_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR : extension.COMPRESSED_RGBA_ASTC_10x6_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_10x8_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR : extension.COMPRESSED_RGBA_ASTC_10x8_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_10x10_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR : extension.COMPRESSED_RGBA_ASTC_10x10_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_12x10_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR : extension.COMPRESSED_RGBA_ASTC_12x10_KHR;\n\t\t\t\tif ( p === RGBA_ASTC_12x12_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR : extension.COMPRESSED_RGBA_ASTC_12x12_KHR;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// BPTC\n\n\t\tif ( p === RGBA_BPTC_Format ) {\n\n\t\t\textension = extensions.get( 'EXT_texture_compression_bptc' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\tif ( p === RGBA_BPTC_Format ) return ( encoding === sRGBEncoding ) ? extension.COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT : extension.COMPRESSED_RGBA_BPTC_UNORM_EXT;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\n\t\tif ( p === UnsignedInt248Type ) {\n\n\t\t\tif ( isWebGL2 ) return 34042;\n\n\t\t\textension = extensions.get( 'WEBGL_depth_texture' );\n\n\t\t\tif ( extension !== null ) {\n\n\t\t\t\treturn extension.UNSIGNED_INT_24_8_WEBGL;\n\n\t\t\t} else {\n\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\treturn { convert: convert };\n\n}\n\nclass ArrayCamera extends PerspectiveCamera {\n\n\tconstructor( array = [] ) {\n\n\t\tsuper();\n\n\t\tthis.cameras = array;\n\n\t}\n\n}\n\nArrayCamera.prototype.isArrayCamera = true;\n\nclass Group extends Object3D {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'Group';\n\n\t}\n\n}\n\nGroup.prototype.isGroup = true;\n\nconst _moveEvent = { type: 'move' };\n\nclass WebXRController {\n\n\tconstructor() {\n\n\t\tthis._targetRay = null;\n\t\tthis._grip = null;\n\t\tthis._hand = null;\n\n\t}\n\n\tgetHandSpace() {\n\n\t\tif ( this._hand === null ) {\n\n\t\t\tthis._hand = new Group();\n\t\t\tthis._hand.matrixAutoUpdate = false;\n\t\t\tthis._hand.visible = false;\n\n\t\t\tthis._hand.joints = {};\n\t\t\tthis._hand.inputState = { pinching: false };\n\n\t\t}\n\n\t\treturn this._hand;\n\n\t}\n\n\tgetTargetRaySpace() {\n\n\t\tif ( this._targetRay === null ) {\n\n\t\t\tthis._targetRay = new Group();\n\t\t\tthis._targetRay.matrixAutoUpdate = false;\n\t\t\tthis._targetRay.visible = false;\n\t\t\tthis._targetRay.hasLinearVelocity = false;\n\t\t\tthis._targetRay.linearVelocity = new Vector3();\n\t\t\tthis._targetRay.hasAngularVelocity = false;\n\t\t\tthis._targetRay.angularVelocity = new Vector3();\n\n\t\t}\n\n\t\treturn this._targetRay;\n\n\t}\n\n\tgetGripSpace() {\n\n\t\tif ( this._grip === null ) {\n\n\t\t\tthis._grip = new Group();\n\t\t\tthis._grip.matrixAutoUpdate = false;\n\t\t\tthis._grip.visible = false;\n\t\t\tthis._grip.hasLinearVelocity = false;\n\t\t\tthis._grip.linearVelocity = new Vector3();\n\t\t\tthis._grip.hasAngularVelocity = false;\n\t\t\tthis._grip.angularVelocity = new Vector3();\n\n\t\t}\n\n\t\treturn this._grip;\n\n\t}\n\n\tdispatchEvent( event ) {\n\n\t\tif ( this._targetRay !== null ) {\n\n\t\t\tthis._targetRay.dispatchEvent( event );\n\n\t\t}\n\n\t\tif ( this._grip !== null ) {\n\n\t\t\tthis._grip.dispatchEvent( event );\n\n\t\t}\n\n\t\tif ( this._hand !== null ) {\n\n\t\t\tthis._hand.dispatchEvent( event );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tdisconnect( inputSource ) {\n\n\t\tthis.dispatchEvent( { type: 'disconnected', data: inputSource } );\n\n\t\tif ( this._targetRay !== null ) {\n\n\t\t\tthis._targetRay.visible = false;\n\n\t\t}\n\n\t\tif ( this._grip !== null ) {\n\n\t\t\tthis._grip.visible = false;\n\n\t\t}\n\n\t\tif ( this._hand !== null ) {\n\n\t\t\tthis._hand.visible = false;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tupdate( inputSource, frame, referenceSpace ) {\n\n\t\tlet inputPose = null;\n\t\tlet gripPose = null;\n\t\tlet handPose = null;\n\n\t\tconst targetRay = this._targetRay;\n\t\tconst grip = this._grip;\n\t\tconst hand = this._hand;\n\n\t\tif ( inputSource && frame.session.visibilityState !== 'visible-blurred' ) {\n\n\t\t\tif ( targetRay !== null ) {\n\n\t\t\t\tinputPose = frame.getPose( inputSource.targetRaySpace, referenceSpace );\n\n\t\t\t\tif ( inputPose !== null ) {\n\n\t\t\t\t\ttargetRay.matrix.fromArray( inputPose.transform.matrix );\n\t\t\t\t\ttargetRay.matrix.decompose( targetRay.position, targetRay.rotation, targetRay.scale );\n\n\t\t\t\t\tif ( inputPose.linearVelocity ) {\n\n\t\t\t\t\t\ttargetRay.hasLinearVelocity = true;\n\t\t\t\t\t\ttargetRay.linearVelocity.copy( inputPose.linearVelocity );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\ttargetRay.hasLinearVelocity = false;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( inputPose.angularVelocity ) {\n\n\t\t\t\t\t\ttargetRay.hasAngularVelocity = true;\n\t\t\t\t\t\ttargetRay.angularVelocity.copy( inputPose.angularVelocity );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\ttargetRay.hasAngularVelocity = false;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tthis.dispatchEvent( _moveEvent );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( hand && inputSource.hand ) {\n\n\t\t\t\thandPose = true;\n\n\t\t\t\tfor ( const inputjoint of inputSource.hand.values() ) {\n\n\t\t\t\t\t// Update the joints groups with the XRJoint poses\n\t\t\t\t\tconst jointPose = frame.getJointPose( inputjoint, referenceSpace );\n\n\t\t\t\t\tif ( hand.joints[ inputjoint.jointName ] === undefined ) {\n\n\t\t\t\t\t\t// The transform of this joint will be updated with the joint pose on each frame\n\t\t\t\t\t\tconst joint = new Group();\n\t\t\t\t\t\tjoint.matrixAutoUpdate = false;\n\t\t\t\t\t\tjoint.visible = false;\n\t\t\t\t\t\thand.joints[ inputjoint.jointName ] = joint;\n\t\t\t\t\t\t// ??\n\t\t\t\t\t\thand.add( joint );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst joint = hand.joints[ inputjoint.jointName ];\n\n\t\t\t\t\tif ( jointPose !== null ) {\n\n\t\t\t\t\t\tjoint.matrix.fromArray( jointPose.transform.matrix );\n\t\t\t\t\t\tjoint.matrix.decompose( joint.position, joint.rotation, joint.scale );\n\t\t\t\t\t\tjoint.jointRadius = jointPose.radius;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tjoint.visible = jointPose !== null;\n\n\t\t\t\t}\n\n\t\t\t\t// Custom events\n\n\t\t\t\t// Check pinchz\n\t\t\t\tconst indexTip = hand.joints[ 'index-finger-tip' ];\n\t\t\t\tconst thumbTip = hand.joints[ 'thumb-tip' ];\n\t\t\t\tconst distance = indexTip.position.distanceTo( thumbTip.position );\n\n\t\t\t\tconst distanceToPinch = 0.02;\n\t\t\t\tconst threshold = 0.005;\n\n\t\t\t\tif ( hand.inputState.pinching && distance > distanceToPinch + threshold ) {\n\n\t\t\t\t\thand.inputState.pinching = false;\n\t\t\t\t\tthis.dispatchEvent( {\n\t\t\t\t\t\ttype: 'pinchend',\n\t\t\t\t\t\thandedness: inputSource.handedness,\n\t\t\t\t\t\ttarget: this\n\t\t\t\t\t} );\n\n\t\t\t\t} else if ( ! hand.inputState.pinching && distance <= distanceToPinch - threshold ) {\n\n\t\t\t\t\thand.inputState.pinching = true;\n\t\t\t\t\tthis.dispatchEvent( {\n\t\t\t\t\t\ttype: 'pinchstart',\n\t\t\t\t\t\thandedness: inputSource.handedness,\n\t\t\t\t\t\ttarget: this\n\t\t\t\t\t} );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tif ( grip !== null && inputSource.gripSpace ) {\n\n\t\t\t\t\tgripPose = frame.getPose( inputSource.gripSpace, referenceSpace );\n\n\t\t\t\t\tif ( gripPose !== null ) {\n\n\t\t\t\t\t\tgrip.matrix.fromArray( gripPose.transform.matrix );\n\t\t\t\t\t\tgrip.matrix.decompose( grip.position, grip.rotation, grip.scale );\n\n\t\t\t\t\t\tif ( gripPose.linearVelocity ) {\n\n\t\t\t\t\t\t\tgrip.hasLinearVelocity = true;\n\t\t\t\t\t\t\tgrip.linearVelocity.copy( gripPose.linearVelocity );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tgrip.hasLinearVelocity = false;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ( gripPose.angularVelocity ) {\n\n\t\t\t\t\t\t\tgrip.hasAngularVelocity = true;\n\t\t\t\t\t\t\tgrip.angularVelocity.copy( gripPose.angularVelocity );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tgrip.hasAngularVelocity = false;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( targetRay !== null ) {\n\n\t\t\ttargetRay.visible = ( inputPose !== null );\n\n\t\t}\n\n\t\tif ( grip !== null ) {\n\n\t\t\tgrip.visible = ( gripPose !== null );\n\n\t\t}\n\n\t\tif ( hand !== null ) {\n\n\t\t\thand.visible = ( handPose !== null );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass DepthTexture extends Texture {\n\n\tconstructor( width, height, type, mapping, wrapS, wrapT, magFilter, minFilter, anisotropy, format ) {\n\n\t\tformat = format !== undefined ? format : DepthFormat;\n\n\t\tif ( format !== DepthFormat && format !== DepthStencilFormat ) {\n\n\t\t\tthrow new Error( 'DepthTexture format must be either THREE.DepthFormat or THREE.DepthStencilFormat' );\n\n\t\t}\n\n\t\tif ( type === undefined && format === DepthFormat ) type = UnsignedShortType;\n\t\tif ( type === undefined && format === DepthStencilFormat ) type = UnsignedInt248Type;\n\n\t\tsuper( null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy );\n\n\t\tthis.image = { width: width, height: height };\n\n\t\tthis.magFilter = magFilter !== undefined ? magFilter : NearestFilter;\n\t\tthis.minFilter = minFilter !== undefined ? minFilter : NearestFilter;\n\n\t\tthis.flipY = false;\n\t\tthis.generateMipmaps\t= false;\n\n\t}\n\n\n}\n\nDepthTexture.prototype.isDepthTexture = true;\n\nclass WebXRManager extends EventDispatcher {\n\n\tconstructor( renderer, gl ) {\n\n\t\tsuper();\n\n\t\tconst scope = this;\n\n\t\tlet session = null;\n\t\tlet framebufferScaleFactor = 1.0;\n\n\t\tlet referenceSpace = null;\n\t\tlet referenceSpaceType = 'local-floor';\n\n\t\tlet pose = null;\n\t\tlet glBinding = null;\n\t\tlet glProjLayer = null;\n\t\tlet glBaseLayer = null;\n\t\tlet xrFrame = null;\n\t\tconst attributes = gl.getContextAttributes();\n\t\tlet initialRenderTarget = null;\n\t\tlet newRenderTarget = null;\n\n\t\tconst controllers = [];\n\t\tconst inputSourcesMap = new Map();\n\n\t\t//\n\n\t\tconst cameraL = new PerspectiveCamera();\n\t\tcameraL.layers.enable( 1 );\n\t\tcameraL.viewport = new Vector4();\n\n\t\tconst cameraR = new PerspectiveCamera();\n\t\tcameraR.layers.enable( 2 );\n\t\tcameraR.viewport = new Vector4();\n\n\t\tconst cameras = [ cameraL, cameraR ];\n\n\t\tconst cameraVR = new ArrayCamera();\n\t\tcameraVR.layers.enable( 1 );\n\t\tcameraVR.layers.enable( 2 );\n\n\t\tlet _currentDepthNear = null;\n\t\tlet _currentDepthFar = null;\n\n\t\t//\n\n\t\tthis.cameraAutoUpdate = true;\n\t\tthis.enabled = false;\n\n\t\tthis.isPresenting = false;\n\n\t\tthis.getController = function ( index ) {\n\n\t\t\tlet controller = controllers[ index ];\n\n\t\t\tif ( controller === undefined ) {\n\n\t\t\t\tcontroller = new WebXRController();\n\t\t\t\tcontrollers[ index ] = controller;\n\n\t\t\t}\n\n\t\t\treturn controller.getTargetRaySpace();\n\n\t\t};\n\n\t\tthis.getControllerGrip = function ( index ) {\n\n\t\t\tlet controller = controllers[ index ];\n\n\t\t\tif ( controller === undefined ) {\n\n\t\t\t\tcontroller = new WebXRController();\n\t\t\t\tcontrollers[ index ] = controller;\n\n\t\t\t}\n\n\t\t\treturn controller.getGripSpace();\n\n\t\t};\n\n\t\tthis.getHand = function ( index ) {\n\n\t\t\tlet controller = controllers[ index ];\n\n\t\t\tif ( controller === undefined ) {\n\n\t\t\t\tcontroller = new WebXRController();\n\t\t\t\tcontrollers[ index ] = controller;\n\n\t\t\t}\n\n\t\t\treturn controller.getHandSpace();\n\n\t\t};\n\n\t\t//\n\n\t\tfunction onSessionEvent( event ) {\n\n\t\t\tconst controller = inputSourcesMap.get( event.inputSource );\n\n\t\t\tif ( controller ) {\n\n\t\t\t\tcontroller.dispatchEvent( { type: event.type, data: event.inputSource } );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onSessionEnd() {\n\n\t\t\tinputSourcesMap.forEach( function ( controller, inputSource ) {\n\n\t\t\t\tcontroller.disconnect( inputSource );\n\n\t\t\t} );\n\n\t\t\tinputSourcesMap.clear();\n\n\t\t\t_currentDepthNear = null;\n\t\t\t_currentDepthFar = null;\n\n\t\t\t// restore framebuffer/rendering state\n\n\t\t\trenderer.setRenderTarget( initialRenderTarget );\n\n\t\t\tglBaseLayer = null;\n\t\t\tglProjLayer = null;\n\t\t\tglBinding = null;\n\t\t\tsession = null;\n\t\t\tnewRenderTarget = null;\n\n\t\t\t//\n\n\t\t\tanimation.stop();\n\n\t\t\tscope.isPresenting = false;\n\n\t\t\tscope.dispatchEvent( { type: 'sessionend' } );\n\n\t\t}\n\n\t\tthis.setFramebufferScaleFactor = function ( value ) {\n\n\t\t\tframebufferScaleFactor = value;\n\n\t\t\tif ( scope.isPresenting === true ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebXRManager: Cannot change framebuffer scale while presenting.' );\n\n\t\t\t}\n\n\t\t};\n\n\t\tthis.setReferenceSpaceType = function ( value ) {\n\n\t\t\treferenceSpaceType = value;\n\n\t\t\tif ( scope.isPresenting === true ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebXRManager: Cannot change reference space type while presenting.' );\n\n\t\t\t}\n\n\t\t};\n\n\t\tthis.getReferenceSpace = function () {\n\n\t\t\treturn referenceSpace;\n\n\t\t};\n\n\t\tthis.getBaseLayer = function () {\n\n\t\t\treturn glProjLayer !== null ? glProjLayer : glBaseLayer;\n\n\t\t};\n\n\t\tthis.getBinding = function () {\n\n\t\t\treturn glBinding;\n\n\t\t};\n\n\t\tthis.getFrame = function () {\n\n\t\t\treturn xrFrame;\n\n\t\t};\n\n\t\tthis.getSession = function () {\n\n\t\t\treturn session;\n\n\t\t};\n\n\t\tthis.setSession = async function ( value ) {\n\n\t\t\tsession = value;\n\n\t\t\tif ( session !== null ) {\n\n\t\t\t\tinitialRenderTarget = renderer.getRenderTarget();\n\n\t\t\t\tsession.addEventListener( 'select', onSessionEvent );\n\t\t\t\tsession.addEventListener( 'selectstart', onSessionEvent );\n\t\t\t\tsession.addEventListener( 'selectend', onSessionEvent );\n\t\t\t\tsession.addEventListener( 'squeeze', onSessionEvent );\n\t\t\t\tsession.addEventListener( 'squeezestart', onSessionEvent );\n\t\t\t\tsession.addEventListener( 'squeezeend', onSessionEvent );\n\t\t\t\tsession.addEventListener( 'end', onSessionEnd );\n\t\t\t\tsession.addEventListener( 'inputsourceschange', onInputSourcesChange );\n\n\t\t\t\tif ( attributes.xrCompatible !== true ) {\n\n\t\t\t\t\tawait gl.makeXRCompatible();\n\n\t\t\t\t}\n\n\t\t\t\tif ( ( session.renderState.layers === undefined ) || ( renderer.capabilities.isWebGL2 === false ) ) {\n\n\t\t\t\t\tconst layerInit = {\n\t\t\t\t\t\tantialias: ( session.renderState.layers === undefined ) ? attributes.antialias : true,\n\t\t\t\t\t\talpha: attributes.alpha,\n\t\t\t\t\t\tdepth: attributes.depth,\n\t\t\t\t\t\tstencil: attributes.stencil,\n\t\t\t\t\t\tframebufferScaleFactor: framebufferScaleFactor\n\t\t\t\t\t};\n\n\t\t\t\t\tglBaseLayer = new XRWebGLLayer( session, gl, layerInit );\n\n\t\t\t\t\tsession.updateRenderState( { baseLayer: glBaseLayer } );\n\n\t\t\t\t\tnewRenderTarget = new WebGLRenderTarget(\n\t\t\t\t\t\tglBaseLayer.framebufferWidth,\n\t\t\t\t\t\tglBaseLayer.framebufferHeight,\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tformat: RGBAFormat,\n\t\t\t\t\t\t\ttype: UnsignedByteType,\n\t\t\t\t\t\t\tencoding: renderer.outputEncoding\n\t\t\t\t\t\t}\n\t\t\t\t\t);\n\n\t\t\t\t} else {\n\n\t\t\t\t\tlet depthFormat = null;\n\t\t\t\t\tlet depthType = null;\n\t\t\t\t\tlet glDepthFormat = null;\n\n\t\t\t\t\tif ( attributes.depth ) {\n\n\t\t\t\t\t\tglDepthFormat = attributes.stencil ? 35056 : 33190;\n\t\t\t\t\t\tdepthFormat = attributes.stencil ? DepthStencilFormat : DepthFormat;\n\t\t\t\t\t\tdepthType = attributes.stencil ? UnsignedInt248Type : UnsignedShortType;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst projectionlayerInit = {\n\t\t\t\t\t\tcolorFormat: ( renderer.outputEncoding === sRGBEncoding ) ? 35907 : 32856,\n\t\t\t\t\t\tdepthFormat: glDepthFormat,\n\t\t\t\t\t\tscaleFactor: framebufferScaleFactor\n\t\t\t\t\t};\n\n\t\t\t\t\tglBinding = new XRWebGLBinding( session, gl );\n\n\t\t\t\t\tglProjLayer = glBinding.createProjectionLayer( projectionlayerInit );\n\n\t\t\t\t\tsession.updateRenderState( { layers: [ glProjLayer ] } );\n\n\t\t\t\t\tnewRenderTarget = new WebGLRenderTarget(\n\t\t\t\t\t\tglProjLayer.textureWidth,\n\t\t\t\t\t\tglProjLayer.textureHeight,\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tformat: RGBAFormat,\n\t\t\t\t\t\t\ttype: UnsignedByteType,\n\t\t\t\t\t\t\tdepthTexture: new DepthTexture( glProjLayer.textureWidth, glProjLayer.textureHeight, depthType, undefined, undefined, undefined, undefined, undefined, undefined, depthFormat ),\n\t\t\t\t\t\t\tstencilBuffer: attributes.stencil,\n\t\t\t\t\t\t\tencoding: renderer.outputEncoding,\n\t\t\t\t\t\t\tsamples: attributes.antialias ? 4 : 0\n\t\t\t\t\t\t} );\n\n\t\t\t\t\tconst renderTargetProperties = renderer.properties.get( newRenderTarget );\n\t\t\t\t\trenderTargetProperties.__ignoreDepthValues = glProjLayer.ignoreDepthValues;\n\n\t\t\t\t}\n\n\t\t\t\tnewRenderTarget.isXRRenderTarget = true; // TODO Remove this when possible, see #23278\n\n\t\t\t\t// Set foveation to maximum.\n\t\t\t\tthis.setFoveation( 1.0 );\n\n\t\t\t\treferenceSpace = await session.requestReferenceSpace( referenceSpaceType );\n\n\t\t\t\tanimation.setContext( session );\n\t\t\t\tanimation.start();\n\n\t\t\t\tscope.isPresenting = true;\n\n\t\t\t\tscope.dispatchEvent( { type: 'sessionstart' } );\n\n\t\t\t}\n\n\t\t};\n\n\t\tfunction onInputSourcesChange( event ) {\n\n\t\t\tconst inputSources = session.inputSources;\n\n\t\t\t// Assign inputSources to available controllers\n\n\t\t\tfor ( let i = 0; i < controllers.length; i ++ ) {\n\n\t\t\t\tinputSourcesMap.set( inputSources[ i ], controllers[ i ] );\n\n\t\t\t}\n\n\t\t\t// Notify disconnected\n\n\t\t\tfor ( let i = 0; i < event.removed.length; i ++ ) {\n\n\t\t\t\tconst inputSource = event.removed[ i ];\n\t\t\t\tconst controller = inputSourcesMap.get( inputSource );\n\n\t\t\t\tif ( controller ) {\n\n\t\t\t\t\tcontroller.dispatchEvent( { type: 'disconnected', data: inputSource } );\n\t\t\t\t\tinputSourcesMap.delete( inputSource );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// Notify connected\n\n\t\t\tfor ( let i = 0; i < event.added.length; i ++ ) {\n\n\t\t\t\tconst inputSource = event.added[ i ];\n\t\t\t\tconst controller = inputSourcesMap.get( inputSource );\n\n\t\t\t\tif ( controller ) {\n\n\t\t\t\t\tcontroller.dispatchEvent( { type: 'connected', data: inputSource } );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\n\t\tconst cameraLPos = new Vector3();\n\t\tconst cameraRPos = new Vector3();\n\n\t\t/**\n\t\t * Assumes 2 cameras that are parallel and share an X-axis, and that\n\t\t * the cameras' projection and world matrices have already been set.\n\t\t * And that near and far planes are identical for both cameras.\n\t\t * Visualization of this technique: https://computergraphics.stackexchange.com/a/4765\n\t\t */\n\t\tfunction setProjectionFromUnion( camera, cameraL, cameraR ) {\n\n\t\t\tcameraLPos.setFromMatrixPosition( cameraL.matrixWorld );\n\t\t\tcameraRPos.setFromMatrixPosition( cameraR.matrixWorld );\n\n\t\t\tconst ipd = cameraLPos.distanceTo( cameraRPos );\n\n\t\t\tconst projL = cameraL.projectionMatrix.elements;\n\t\t\tconst projR = cameraR.projectionMatrix.elements;\n\n\t\t\t// VR systems will have identical far and near planes, and\n\t\t\t// most likely identical top and bottom frustum extents.\n\t\t\t// Use the left camera for these values.\n\t\t\tconst near = projL[ 14 ] / ( projL[ 10 ] - 1 );\n\t\t\tconst far = projL[ 14 ] / ( projL[ 10 ] + 1 );\n\t\t\tconst topFov = ( projL[ 9 ] + 1 ) / projL[ 5 ];\n\t\t\tconst bottomFov = ( projL[ 9 ] - 1 ) / projL[ 5 ];\n\n\t\t\tconst leftFov = ( projL[ 8 ] - 1 ) / projL[ 0 ];\n\t\t\tconst rightFov = ( projR[ 8 ] + 1 ) / projR[ 0 ];\n\t\t\tconst left = near * leftFov;\n\t\t\tconst right = near * rightFov;\n\n\t\t\t// Calculate the new camera's position offset from the\n\t\t\t// left camera. xOffset should be roughly half `ipd`.\n\t\t\tconst zOffset = ipd / ( - leftFov + rightFov );\n\t\t\tconst xOffset = zOffset * - leftFov;\n\n\t\t\t// TODO: Better way to apply this offset?\n\t\t\tcameraL.matrixWorld.decompose( camera.position, camera.quaternion, camera.scale );\n\t\t\tcamera.translateX( xOffset );\n\t\t\tcamera.translateZ( zOffset );\n\t\t\tcamera.matrixWorld.compose( camera.position, camera.quaternion, camera.scale );\n\t\t\tcamera.matrixWorldInverse.copy( camera.matrixWorld ).invert();\n\n\t\t\t// Find the union of the frustum values of the cameras and scale\n\t\t\t// the values so that the near plane's position does not change in world space,\n\t\t\t// although must now be relative to the new union camera.\n\t\t\tconst near2 = near + zOffset;\n\t\t\tconst far2 = far + zOffset;\n\t\t\tconst left2 = left - xOffset;\n\t\t\tconst right2 = right + ( ipd - xOffset );\n\t\t\tconst top2 = topFov * far / far2 * near2;\n\t\t\tconst bottom2 = bottomFov * far / far2 * near2;\n\n\t\t\tcamera.projectionMatrix.makePerspective( left2, right2, top2, bottom2, near2, far2 );\n\n\t\t}\n\n\t\tfunction updateCamera( camera, parent ) {\n\n\t\t\tif ( parent === null ) {\n\n\t\t\t\tcamera.matrixWorld.copy( camera.matrix );\n\n\t\t\t} else {\n\n\t\t\t\tcamera.matrixWorld.multiplyMatrices( parent.matrixWorld, camera.matrix );\n\n\t\t\t}\n\n\t\t\tcamera.matrixWorldInverse.copy( camera.matrixWorld ).invert();\n\n\t\t}\n\n\t\tthis.updateCamera = function ( camera ) {\n\n\t\t\tif ( session === null ) return;\n\n\t\t\tcameraVR.near = cameraR.near = cameraL.near = camera.near;\n\t\t\tcameraVR.far = cameraR.far = cameraL.far = camera.far;\n\n\t\t\tif ( _currentDepthNear !== cameraVR.near || _currentDepthFar !== cameraVR.far ) {\n\n\t\t\t\t// Note that the new renderState won't apply until the next frame. See #18320\n\n\t\t\t\tsession.updateRenderState( {\n\t\t\t\t\tdepthNear: cameraVR.near,\n\t\t\t\t\tdepthFar: cameraVR.far\n\t\t\t\t} );\n\n\t\t\t\t_currentDepthNear = cameraVR.near;\n\t\t\t\t_currentDepthFar = cameraVR.far;\n\n\t\t\t}\n\n\t\t\tconst parent = camera.parent;\n\t\t\tconst cameras = cameraVR.cameras;\n\n\t\t\tupdateCamera( cameraVR, parent );\n\n\t\t\tfor ( let i = 0; i < cameras.length; i ++ ) {\n\n\t\t\t\tupdateCamera( cameras[ i ], parent );\n\n\t\t\t}\n\n\t\t\tcameraVR.matrixWorld.decompose( cameraVR.position, cameraVR.quaternion, cameraVR.scale );\n\n\t\t\t// update user camera and its children\n\n\t\t\tcamera.position.copy( cameraVR.position );\n\t\t\tcamera.quaternion.copy( cameraVR.quaternion );\n\t\t\tcamera.scale.copy( cameraVR.scale );\n\t\t\tcamera.matrix.copy( cameraVR.matrix );\n\t\t\tcamera.matrixWorld.copy( cameraVR.matrixWorld );\n\n\t\t\tconst children = camera.children;\n\n\t\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\t\tchildren[ i ].updateMatrixWorld( true );\n\n\t\t\t}\n\n\t\t\t// update projection matrix for proper view frustum culling\n\n\t\t\tif ( cameras.length === 2 ) {\n\n\t\t\t\tsetProjectionFromUnion( cameraVR, cameraL, cameraR );\n\n\t\t\t} else {\n\n\t\t\t\t// assume single camera setup (AR)\n\n\t\t\t\tcameraVR.projectionMatrix.copy( cameraL.projectionMatrix );\n\n\t\t\t}\n\n\t\t};\n\n\t\tthis.getCamera = function () {\n\n\t\t\treturn cameraVR;\n\n\t\t};\n\n\t\tthis.getFoveation = function () {\n\n\t\t\tif ( glProjLayer !== null ) {\n\n\t\t\t\treturn glProjLayer.fixedFoveation;\n\n\t\t\t}\n\n\t\t\tif ( glBaseLayer !== null ) {\n\n\t\t\t\treturn glBaseLayer.fixedFoveation;\n\n\t\t\t}\n\n\t\t\treturn undefined;\n\n\t\t};\n\n\t\tthis.setFoveation = function ( foveation ) {\n\n\t\t\t// 0 = no foveation = full resolution\n\t\t\t// 1 = maximum foveation = the edges render at lower resolution\n\n\t\t\tif ( glProjLayer !== null ) {\n\n\t\t\t\tglProjLayer.fixedFoveation = foveation;\n\n\t\t\t}\n\n\t\t\tif ( glBaseLayer !== null && glBaseLayer.fixedFoveation !== undefined ) {\n\n\t\t\t\tglBaseLayer.fixedFoveation = foveation;\n\n\t\t\t}\n\n\t\t};\n\n\t\t// Animation Loop\n\n\t\tlet onAnimationFrameCallback = null;\n\n\t\tfunction onAnimationFrame( time, frame ) {\n\n\t\t\tpose = frame.getViewerPose( referenceSpace );\n\t\t\txrFrame = frame;\n\n\t\t\tif ( pose !== null ) {\n\n\t\t\t\tconst views = pose.views;\n\n\t\t\t\tif ( glBaseLayer !== null ) {\n\n\t\t\t\t\trenderer.setRenderTargetFramebuffer( newRenderTarget, glBaseLayer.framebuffer );\n\t\t\t\t\trenderer.setRenderTarget( newRenderTarget );\n\n\t\t\t\t}\n\n\t\t\t\tlet cameraVRNeedsUpdate = false;\n\n\t\t\t\t// check if it's necessary to rebuild cameraVR's camera list\n\n\t\t\t\tif ( views.length !== cameraVR.cameras.length ) {\n\n\t\t\t\t\tcameraVR.cameras.length = 0;\n\t\t\t\t\tcameraVRNeedsUpdate = true;\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let i = 0; i < views.length; i ++ ) {\n\n\t\t\t\t\tconst view = views[ i ];\n\n\t\t\t\t\tlet viewport = null;\n\n\t\t\t\t\tif ( glBaseLayer !== null ) {\n\n\t\t\t\t\t\tviewport = glBaseLayer.getViewport( view );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tconst glSubImage = glBinding.getViewSubImage( glProjLayer, view );\n\t\t\t\t\t\tviewport = glSubImage.viewport;\n\n\t\t\t\t\t\t// For side-by-side projection, we only produce a single texture for both eyes.\n\t\t\t\t\t\tif ( i === 0 ) {\n\n\t\t\t\t\t\t\trenderer.setRenderTargetTextures(\n\t\t\t\t\t\t\t\tnewRenderTarget,\n\t\t\t\t\t\t\t\tglSubImage.colorTexture,\n\t\t\t\t\t\t\t\tglProjLayer.ignoreDepthValues ? undefined : glSubImage.depthStencilTexture );\n\n\t\t\t\t\t\t\trenderer.setRenderTarget( newRenderTarget );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst camera = cameras[ i ];\n\n\t\t\t\t\tcamera.matrix.fromArray( view.transform.matrix );\n\t\t\t\t\tcamera.projectionMatrix.fromArray( view.projectionMatrix );\n\t\t\t\t\tcamera.viewport.set( viewport.x, viewport.y, viewport.width, viewport.height );\n\n\t\t\t\t\tif ( i === 0 ) {\n\n\t\t\t\t\t\tcameraVR.matrix.copy( camera.matrix );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( cameraVRNeedsUpdate === true ) {\n\n\t\t\t\t\t\tcameraVR.cameras.push( camera );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t//\n\n\t\t\tconst inputSources = session.inputSources;\n\n\t\t\tfor ( let i = 0; i < controllers.length; i ++ ) {\n\n\t\t\t\tconst controller = controllers[ i ];\n\t\t\t\tconst inputSource = inputSources[ i ];\n\n\t\t\t\tcontroller.update( inputSource, frame, referenceSpace );\n\n\t\t\t}\n\n\t\t\tif ( onAnimationFrameCallback ) onAnimationFrameCallback( time, frame );\n\n\t\t\txrFrame = null;\n\n\t\t}\n\n\t\tconst animation = new WebGLAnimation();\n\n\t\tanimation.setAnimationLoop( onAnimationFrame );\n\n\t\tthis.setAnimationLoop = function ( callback ) {\n\n\t\t\tonAnimationFrameCallback = callback;\n\n\t\t};\n\n\t\tthis.dispose = function () {};\n\n\t}\n\n}\n\nfunction WebGLMaterials( properties ) {\n\n\tfunction refreshFogUniforms( uniforms, fog ) {\n\n\t\tuniforms.fogColor.value.copy( fog.color );\n\n\t\tif ( fog.isFog ) {\n\n\t\t\tuniforms.fogNear.value = fog.near;\n\t\t\tuniforms.fogFar.value = fog.far;\n\n\t\t} else if ( fog.isFogExp2 ) {\n\n\t\t\tuniforms.fogDensity.value = fog.density;\n\n\t\t}\n\n\t}\n\n\tfunction refreshMaterialUniforms( uniforms, material, pixelRatio, height, transmissionRenderTarget ) {\n\n\t\tif ( material.isMeshBasicMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\n\t\t} else if ( material.isMeshLambertMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsLambert( uniforms, material );\n\n\t\t} else if ( material.isMeshToonMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsToon( uniforms, material );\n\n\t\t} else if ( material.isMeshPhongMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsPhong( uniforms, material );\n\n\t\t} else if ( material.isMeshStandardMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\n\t\t\tif ( material.isMeshPhysicalMaterial ) {\n\n\t\t\t\trefreshUniformsPhysical( uniforms, material, transmissionRenderTarget );\n\n\t\t\t} else {\n\n\t\t\t\trefreshUniformsStandard( uniforms, material );\n\n\t\t\t}\n\n\t\t} else if ( material.isMeshMatcapMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsMatcap( uniforms, material );\n\n\t\t} else if ( material.isMeshDepthMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsDepth( uniforms, material );\n\n\t\t} else if ( material.isMeshDistanceMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsDistance( uniforms, material );\n\n\t\t} else if ( material.isMeshNormalMaterial ) {\n\n\t\t\trefreshUniformsCommon( uniforms, material );\n\t\t\trefreshUniformsNormal( uniforms, material );\n\n\t\t} else if ( material.isLineBasicMaterial ) {\n\n\t\t\trefreshUniformsLine( uniforms, material );\n\n\t\t\tif ( material.isLineDashedMaterial ) {\n\n\t\t\t\trefreshUniformsDash( uniforms, material );\n\n\t\t\t}\n\n\t\t} else if ( material.isPointsMaterial ) {\n\n\t\t\trefreshUniformsPoints( uniforms, material, pixelRatio, height );\n\n\t\t} else if ( material.isSpriteMaterial ) {\n\n\t\t\trefreshUniformsSprites( uniforms, material );\n\n\t\t} else if ( material.isShadowMaterial ) {\n\n\t\t\tuniforms.color.value.copy( material.color );\n\t\t\tuniforms.opacity.value = material.opacity;\n\n\t\t} else if ( material.isShaderMaterial ) {\n\n\t\t\tmaterial.uniformsNeedUpdate = false; // #15581\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsCommon( uniforms, material ) {\n\n\t\tuniforms.opacity.value = material.opacity;\n\n\t\tif ( material.color ) {\n\n\t\t\tuniforms.diffuse.value.copy( material.color );\n\n\t\t}\n\n\t\tif ( material.emissive ) {\n\n\t\t\tuniforms.emissive.value.copy( material.emissive ).multiplyScalar( material.emissiveIntensity );\n\n\t\t}\n\n\t\tif ( material.map ) {\n\n\t\t\tuniforms.map.value = material.map;\n\n\t\t}\n\n\t\tif ( material.alphaMap ) {\n\n\t\t\tuniforms.alphaMap.value = material.alphaMap;\n\n\t\t}\n\n\t\tif ( material.specularMap ) {\n\n\t\t\tuniforms.specularMap.value = material.specularMap;\n\n\t\t}\n\n\t\tif ( material.alphaTest > 0 ) {\n\n\t\t\tuniforms.alphaTest.value = material.alphaTest;\n\n\t\t}\n\n\t\tconst envMap = properties.get( material ).envMap;\n\n\t\tif ( envMap ) {\n\n\t\t\tuniforms.envMap.value = envMap;\n\n\t\t\tuniforms.flipEnvMap.value = ( envMap.isCubeTexture && envMap.isRenderTargetTexture === false ) ? - 1 : 1;\n\n\t\t\tuniforms.reflectivity.value = material.reflectivity;\n\t\t\tuniforms.ior.value = material.ior;\n\t\t\tuniforms.refractionRatio.value = material.refractionRatio;\n\n\t\t}\n\n\t\tif ( material.lightMap ) {\n\n\t\t\tuniforms.lightMap.value = material.lightMap;\n\t\t\tuniforms.lightMapIntensity.value = material.lightMapIntensity;\n\n\t\t}\n\n\t\tif ( material.aoMap ) {\n\n\t\t\tuniforms.aoMap.value = material.aoMap;\n\t\t\tuniforms.aoMapIntensity.value = material.aoMapIntensity;\n\n\t\t}\n\n\t\t// uv repeat and offset setting priorities\n\t\t// 1. color map\n\t\t// 2. specular map\n\t\t// 3. displacementMap map\n\t\t// 4. normal map\n\t\t// 5. bump map\n\t\t// 6. roughnessMap map\n\t\t// 7. metalnessMap map\n\t\t// 8. alphaMap map\n\t\t// 9. emissiveMap map\n\t\t// 10. clearcoat map\n\t\t// 11. clearcoat normal map\n\t\t// 12. clearcoat roughnessMap map\n\t\t// 13. specular intensity map\n\t\t// 14. specular tint map\n\t\t// 15. transmission map\n\t\t// 16. thickness map\n\n\t\tlet uvScaleMap;\n\n\t\tif ( material.map ) {\n\n\t\t\tuvScaleMap = material.map;\n\n\t\t} else if ( material.specularMap ) {\n\n\t\t\tuvScaleMap = material.specularMap;\n\n\t\t} else if ( material.displacementMap ) {\n\n\t\t\tuvScaleMap = material.displacementMap;\n\n\t\t} else if ( material.normalMap ) {\n\n\t\t\tuvScaleMap = material.normalMap;\n\n\t\t} else if ( material.bumpMap ) {\n\n\t\t\tuvScaleMap = material.bumpMap;\n\n\t\t} else if ( material.roughnessMap ) {\n\n\t\t\tuvScaleMap = material.roughnessMap;\n\n\t\t} else if ( material.metalnessMap ) {\n\n\t\t\tuvScaleMap = material.metalnessMap;\n\n\t\t} else if ( material.alphaMap ) {\n\n\t\t\tuvScaleMap = material.alphaMap;\n\n\t\t} else if ( material.emissiveMap ) {\n\n\t\t\tuvScaleMap = material.emissiveMap;\n\n\t\t} else if ( material.clearcoatMap ) {\n\n\t\t\tuvScaleMap = material.clearcoatMap;\n\n\t\t} else if ( material.clearcoatNormalMap ) {\n\n\t\t\tuvScaleMap = material.clearcoatNormalMap;\n\n\t\t} else if ( material.clearcoatRoughnessMap ) {\n\n\t\t\tuvScaleMap = material.clearcoatRoughnessMap;\n\n\t\t} else if ( material.specularIntensityMap ) {\n\n\t\t\tuvScaleMap = material.specularIntensityMap;\n\n\t\t} else if ( material.specularColorMap ) {\n\n\t\t\tuvScaleMap = material.specularColorMap;\n\n\t\t} else if ( material.transmissionMap ) {\n\n\t\t\tuvScaleMap = material.transmissionMap;\n\n\t\t} else if ( material.thicknessMap ) {\n\n\t\t\tuvScaleMap = material.thicknessMap;\n\n\t\t} else if ( material.sheenColorMap ) {\n\n\t\t\tuvScaleMap = material.sheenColorMap;\n\n\t\t} else if ( material.sheenRoughnessMap ) {\n\n\t\t\tuvScaleMap = material.sheenRoughnessMap;\n\n\t\t}\n\n\t\tif ( uvScaleMap !== undefined ) {\n\n\t\t\t// backwards compatibility\n\t\t\tif ( uvScaleMap.isWebGLRenderTarget ) {\n\n\t\t\t\tuvScaleMap = uvScaleMap.texture;\n\n\t\t\t}\n\n\t\t\tif ( uvScaleMap.matrixAutoUpdate === true ) {\n\n\t\t\t\tuvScaleMap.updateMatrix();\n\n\t\t\t}\n\n\t\t\tuniforms.uvTransform.value.copy( uvScaleMap.matrix );\n\n\t\t}\n\n\t\t// uv repeat and offset setting priorities for uv2\n\t\t// 1. ao map\n\t\t// 2. light map\n\n\t\tlet uv2ScaleMap;\n\n\t\tif ( material.aoMap ) {\n\n\t\t\tuv2ScaleMap = material.aoMap;\n\n\t\t} else if ( material.lightMap ) {\n\n\t\t\tuv2ScaleMap = material.lightMap;\n\n\t\t}\n\n\t\tif ( uv2ScaleMap !== undefined ) {\n\n\t\t\t// backwards compatibility\n\t\t\tif ( uv2ScaleMap.isWebGLRenderTarget ) {\n\n\t\t\t\tuv2ScaleMap = uv2ScaleMap.texture;\n\n\t\t\t}\n\n\t\t\tif ( uv2ScaleMap.matrixAutoUpdate === true ) {\n\n\t\t\t\tuv2ScaleMap.updateMatrix();\n\n\t\t\t}\n\n\t\t\tuniforms.uv2Transform.value.copy( uv2ScaleMap.matrix );\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsLine( uniforms, material ) {\n\n\t\tuniforms.diffuse.value.copy( material.color );\n\t\tuniforms.opacity.value = material.opacity;\n\n\t}\n\n\tfunction refreshUniformsDash( uniforms, material ) {\n\n\t\tuniforms.dashSize.value = material.dashSize;\n\t\tuniforms.totalSize.value = material.dashSize + material.gapSize;\n\t\tuniforms.scale.value = material.scale;\n\n\t}\n\n\tfunction refreshUniformsPoints( uniforms, material, pixelRatio, height ) {\n\n\t\tuniforms.diffuse.value.copy( material.color );\n\t\tuniforms.opacity.value = material.opacity;\n\t\tuniforms.size.value = material.size * pixelRatio;\n\t\tuniforms.scale.value = height * 0.5;\n\n\t\tif ( material.map ) {\n\n\t\t\tuniforms.map.value = material.map;\n\n\t\t}\n\n\t\tif ( material.alphaMap ) {\n\n\t\t\tuniforms.alphaMap.value = material.alphaMap;\n\n\t\t}\n\n\t\tif ( material.alphaTest > 0 ) {\n\n\t\t\tuniforms.alphaTest.value = material.alphaTest;\n\n\t\t}\n\n\t\t// uv repeat and offset setting priorities\n\t\t// 1. color map\n\t\t// 2. alpha map\n\n\t\tlet uvScaleMap;\n\n\t\tif ( material.map ) {\n\n\t\t\tuvScaleMap = material.map;\n\n\t\t} else if ( material.alphaMap ) {\n\n\t\t\tuvScaleMap = material.alphaMap;\n\n\t\t}\n\n\t\tif ( uvScaleMap !== undefined ) {\n\n\t\t\tif ( uvScaleMap.matrixAutoUpdate === true ) {\n\n\t\t\t\tuvScaleMap.updateMatrix();\n\n\t\t\t}\n\n\t\t\tuniforms.uvTransform.value.copy( uvScaleMap.matrix );\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsSprites( uniforms, material ) {\n\n\t\tuniforms.diffuse.value.copy( material.color );\n\t\tuniforms.opacity.value = material.opacity;\n\t\tuniforms.rotation.value = material.rotation;\n\n\t\tif ( material.map ) {\n\n\t\t\tuniforms.map.value = material.map;\n\n\t\t}\n\n\t\tif ( material.alphaMap ) {\n\n\t\t\tuniforms.alphaMap.value = material.alphaMap;\n\n\t\t}\n\n\t\tif ( material.alphaTest > 0 ) {\n\n\t\t\tuniforms.alphaTest.value = material.alphaTest;\n\n\t\t}\n\n\t\t// uv repeat and offset setting priorities\n\t\t// 1. color map\n\t\t// 2. alpha map\n\n\t\tlet uvScaleMap;\n\n\t\tif ( material.map ) {\n\n\t\t\tuvScaleMap = material.map;\n\n\t\t} else if ( material.alphaMap ) {\n\n\t\t\tuvScaleMap = material.alphaMap;\n\n\t\t}\n\n\t\tif ( uvScaleMap !== undefined ) {\n\n\t\t\tif ( uvScaleMap.matrixAutoUpdate === true ) {\n\n\t\t\t\tuvScaleMap.updateMatrix();\n\n\t\t\t}\n\n\t\t\tuniforms.uvTransform.value.copy( uvScaleMap.matrix );\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsLambert( uniforms, material ) {\n\n\t\tif ( material.emissiveMap ) {\n\n\t\t\tuniforms.emissiveMap.value = material.emissiveMap;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsPhong( uniforms, material ) {\n\n\t\tuniforms.specular.value.copy( material.specular );\n\t\tuniforms.shininess.value = Math.max( material.shininess, 1e-4 ); // to prevent pow( 0.0, 0.0 )\n\n\t\tif ( material.emissiveMap ) {\n\n\t\t\tuniforms.emissiveMap.value = material.emissiveMap;\n\n\t\t}\n\n\t\tif ( material.bumpMap ) {\n\n\t\t\tuniforms.bumpMap.value = material.bumpMap;\n\t\t\tuniforms.bumpScale.value = material.bumpScale;\n\t\t\tif ( material.side === BackSide ) uniforms.bumpScale.value *= - 1;\n\n\t\t}\n\n\t\tif ( material.normalMap ) {\n\n\t\t\tuniforms.normalMap.value = material.normalMap;\n\t\t\tuniforms.normalScale.value.copy( material.normalScale );\n\t\t\tif ( material.side === BackSide ) uniforms.normalScale.value.negate();\n\n\t\t}\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsToon( uniforms, material ) {\n\n\t\tif ( material.gradientMap ) {\n\n\t\t\tuniforms.gradientMap.value = material.gradientMap;\n\n\t\t}\n\n\t\tif ( material.emissiveMap ) {\n\n\t\t\tuniforms.emissiveMap.value = material.emissiveMap;\n\n\t\t}\n\n\t\tif ( material.bumpMap ) {\n\n\t\t\tuniforms.bumpMap.value = material.bumpMap;\n\t\t\tuniforms.bumpScale.value = material.bumpScale;\n\t\t\tif ( material.side === BackSide ) uniforms.bumpScale.value *= - 1;\n\n\t\t}\n\n\t\tif ( material.normalMap ) {\n\n\t\t\tuniforms.normalMap.value = material.normalMap;\n\t\t\tuniforms.normalScale.value.copy( material.normalScale );\n\t\t\tif ( material.side === BackSide ) uniforms.normalScale.value.negate();\n\n\t\t}\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsStandard( uniforms, material ) {\n\n\t\tuniforms.roughness.value = material.roughness;\n\t\tuniforms.metalness.value = material.metalness;\n\n\t\tif ( material.roughnessMap ) {\n\n\t\t\tuniforms.roughnessMap.value = material.roughnessMap;\n\n\t\t}\n\n\t\tif ( material.metalnessMap ) {\n\n\t\t\tuniforms.metalnessMap.value = material.metalnessMap;\n\n\t\t}\n\n\t\tif ( material.emissiveMap ) {\n\n\t\t\tuniforms.emissiveMap.value = material.emissiveMap;\n\n\t\t}\n\n\t\tif ( material.bumpMap ) {\n\n\t\t\tuniforms.bumpMap.value = material.bumpMap;\n\t\t\tuniforms.bumpScale.value = material.bumpScale;\n\t\t\tif ( material.side === BackSide ) uniforms.bumpScale.value *= - 1;\n\n\t\t}\n\n\t\tif ( material.normalMap ) {\n\n\t\t\tuniforms.normalMap.value = material.normalMap;\n\t\t\tuniforms.normalScale.value.copy( material.normalScale );\n\t\t\tif ( material.side === BackSide ) uniforms.normalScale.value.negate();\n\n\t\t}\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t\tconst envMap = properties.get( material ).envMap;\n\n\t\tif ( envMap ) {\n\n\t\t\t//uniforms.envMap.value = material.envMap; // part of uniforms common\n\t\t\tuniforms.envMapIntensity.value = material.envMapIntensity;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsPhysical( uniforms, material, transmissionRenderTarget ) {\n\n\t\trefreshUniformsStandard( uniforms, material );\n\n\t\tuniforms.ior.value = material.ior; // also part of uniforms common\n\n\t\tif ( material.sheen > 0 ) {\n\n\t\t\tuniforms.sheenColor.value.copy( material.sheenColor ).multiplyScalar( material.sheen );\n\n\t\t\tuniforms.sheenRoughness.value = material.sheenRoughness;\n\n\t\t\tif ( material.sheenColorMap ) {\n\n\t\t\t\tuniforms.sheenColorMap.value = material.sheenColorMap;\n\n\t\t\t}\n\n\t\t\tif ( material.sheenRoughnessMap ) {\n\n\t\t\t\tuniforms.sheenRoughnessMap.value = material.sheenRoughnessMap;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( material.clearcoat > 0 ) {\n\n\t\t\tuniforms.clearcoat.value = material.clearcoat;\n\t\t\tuniforms.clearcoatRoughness.value = material.clearcoatRoughness;\n\n\t\t\tif ( material.clearcoatMap ) {\n\n\t\t\t\tuniforms.clearcoatMap.value = material.clearcoatMap;\n\n\t\t\t}\n\n\t\t\tif ( material.clearcoatRoughnessMap ) {\n\n\t\t\t\tuniforms.clearcoatRoughnessMap.value = material.clearcoatRoughnessMap;\n\n\t\t\t}\n\n\t\t\tif ( material.clearcoatNormalMap ) {\n\n\t\t\t\tuniforms.clearcoatNormalScale.value.copy( material.clearcoatNormalScale );\n\t\t\t\tuniforms.clearcoatNormalMap.value = material.clearcoatNormalMap;\n\n\t\t\t\tif ( material.side === BackSide ) {\n\n\t\t\t\t\tuniforms.clearcoatNormalScale.value.negate();\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( material.transmission > 0 ) {\n\n\t\t\tuniforms.transmission.value = material.transmission;\n\t\t\tuniforms.transmissionSamplerMap.value = transmissionRenderTarget.texture;\n\t\t\tuniforms.transmissionSamplerSize.value.set( transmissionRenderTarget.width, transmissionRenderTarget.height );\n\n\t\t\tif ( material.transmissionMap ) {\n\n\t\t\t\tuniforms.transmissionMap.value = material.transmissionMap;\n\n\t\t\t}\n\n\t\t\tuniforms.thickness.value = material.thickness;\n\n\t\t\tif ( material.thicknessMap ) {\n\n\t\t\t\tuniforms.thicknessMap.value = material.thicknessMap;\n\n\t\t\t}\n\n\t\t\tuniforms.attenuationDistance.value = material.attenuationDistance;\n\t\t\tuniforms.attenuationColor.value.copy( material.attenuationColor );\n\n\t\t}\n\n\t\tuniforms.specularIntensity.value = material.specularIntensity;\n\t\tuniforms.specularColor.value.copy( material.specularColor );\n\n\t\tif ( material.specularIntensityMap ) {\n\n\t\t\tuniforms.specularIntensityMap.value = material.specularIntensityMap;\n\n\t\t}\n\n\t\tif ( material.specularColorMap ) {\n\n\t\t\tuniforms.specularColorMap.value = material.specularColorMap;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsMatcap( uniforms, material ) {\n\n\t\tif ( material.matcap ) {\n\n\t\t\tuniforms.matcap.value = material.matcap;\n\n\t\t}\n\n\t\tif ( material.bumpMap ) {\n\n\t\t\tuniforms.bumpMap.value = material.bumpMap;\n\t\t\tuniforms.bumpScale.value = material.bumpScale;\n\t\t\tif ( material.side === BackSide ) uniforms.bumpScale.value *= - 1;\n\n\t\t}\n\n\t\tif ( material.normalMap ) {\n\n\t\t\tuniforms.normalMap.value = material.normalMap;\n\t\t\tuniforms.normalScale.value.copy( material.normalScale );\n\t\t\tif ( material.side === BackSide ) uniforms.normalScale.value.negate();\n\n\t\t}\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsDepth( uniforms, material ) {\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t}\n\n\tfunction refreshUniformsDistance( uniforms, material ) {\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t\tuniforms.referencePosition.value.copy( material.referencePosition );\n\t\tuniforms.nearDistance.value = material.nearDistance;\n\t\tuniforms.farDistance.value = material.farDistance;\n\n\t}\n\n\tfunction refreshUniformsNormal( uniforms, material ) {\n\n\t\tif ( material.bumpMap ) {\n\n\t\t\tuniforms.bumpMap.value = material.bumpMap;\n\t\t\tuniforms.bumpScale.value = material.bumpScale;\n\t\t\tif ( material.side === BackSide ) uniforms.bumpScale.value *= - 1;\n\n\t\t}\n\n\t\tif ( material.normalMap ) {\n\n\t\t\tuniforms.normalMap.value = material.normalMap;\n\t\t\tuniforms.normalScale.value.copy( material.normalScale );\n\t\t\tif ( material.side === BackSide ) uniforms.normalScale.value.negate();\n\n\t\t}\n\n\t\tif ( material.displacementMap ) {\n\n\t\t\tuniforms.displacementMap.value = material.displacementMap;\n\t\t\tuniforms.displacementScale.value = material.displacementScale;\n\t\t\tuniforms.displacementBias.value = material.displacementBias;\n\n\t\t}\n\n\t}\n\n\treturn {\n\t\trefreshFogUniforms: refreshFogUniforms,\n\t\trefreshMaterialUniforms: refreshMaterialUniforms\n\t};\n\n}\n\nfunction createCanvasElement() {\n\n\tconst canvas = createElementNS( 'canvas' );\n\tcanvas.style.display = 'block';\n\treturn canvas;\n\n}\n\nfunction WebGLRenderer( parameters = {} ) {\n\n\tconst _canvas = parameters.canvas !== undefined ? parameters.canvas : createCanvasElement(),\n\t\t_context = parameters.context !== undefined ? parameters.context : null,\n\n\t\t_depth = parameters.depth !== undefined ? parameters.depth : true,\n\t\t_stencil = parameters.stencil !== undefined ? parameters.stencil : true,\n\t\t_antialias = parameters.antialias !== undefined ? parameters.antialias : false,\n\t\t_premultipliedAlpha = parameters.premultipliedAlpha !== undefined ? parameters.premultipliedAlpha : true,\n\t\t_preserveDrawingBuffer = parameters.preserveDrawingBuffer !== undefined ? parameters.preserveDrawingBuffer : false,\n\t\t_powerPreference = parameters.powerPreference !== undefined ? parameters.powerPreference : 'default',\n\t\t_failIfMajorPerformanceCaveat = parameters.failIfMajorPerformanceCaveat !== undefined ? parameters.failIfMajorPerformanceCaveat : false;\n\n\tlet _alpha;\n\n\tif ( parameters.context !== undefined ) {\n\n\t\t_alpha = _context.getContextAttributes().alpha;\n\n\t} else {\n\n\t\t_alpha = parameters.alpha !== undefined ? parameters.alpha : false;\n\n\t}\n\n\tlet currentRenderList = null;\n\tlet currentRenderState = null;\n\n\t// render() can be called from within a callback triggered by another render.\n\t// We track this so that the nested render call gets its list and state isolated from the parent render call.\n\n\tconst renderListStack = [];\n\tconst renderStateStack = [];\n\n\t// public properties\n\n\tthis.domElement = _canvas;\n\n\t// Debug configuration container\n\tthis.debug = {\n\n\t\t/**\n\t\t * Enables error checking and reporting when shader programs are being compiled\n\t\t * @type {boolean}\n\t\t */\n\t\tcheckShaderErrors: true\n\t};\n\n\t// clearing\n\n\tthis.autoClear = true;\n\tthis.autoClearColor = true;\n\tthis.autoClearDepth = true;\n\tthis.autoClearStencil = true;\n\n\t// scene graph\n\n\tthis.sortObjects = true;\n\n\t// user-defined clipping\n\n\tthis.clippingPlanes = [];\n\tthis.localClippingEnabled = false;\n\n\t// physically based shading\n\n\tthis.outputEncoding = LinearEncoding;\n\n\t// physical lights\n\n\tthis.physicallyCorrectLights = false;\n\n\t// tone mapping\n\n\tthis.toneMapping = NoToneMapping;\n\tthis.toneMappingExposure = 1.0;\n\n\t// internal properties\n\n\tconst _this = this;\n\n\tlet _isContextLost = false;\n\n\t// internal state cache\n\n\tlet _currentActiveCubeFace = 0;\n\tlet _currentActiveMipmapLevel = 0;\n\tlet _currentRenderTarget = null;\n\tlet _currentMaterialId = - 1;\n\n\tlet _currentCamera = null;\n\n\tconst _currentViewport = new Vector4();\n\tconst _currentScissor = new Vector4();\n\tlet _currentScissorTest = null;\n\n\t//\n\n\tlet _width = _canvas.width;\n\tlet _height = _canvas.height;\n\n\tlet _pixelRatio = 1;\n\tlet _opaqueSort = null;\n\tlet _transparentSort = null;\n\n\tconst _viewport = new Vector4( 0, 0, _width, _height );\n\tconst _scissor = new Vector4( 0, 0, _width, _height );\n\tlet _scissorTest = false;\n\n\t// frustum\n\n\tconst _frustum = new Frustum();\n\n\t// clipping\n\n\tlet _clippingEnabled = false;\n\tlet _localClippingEnabled = false;\n\n\t// transmission\n\n\tlet _transmissionRenderTarget = null;\n\n\t// camera matrices cache\n\n\tconst _projScreenMatrix = new Matrix4();\n\n\tconst _vector2 = new Vector2();\n\tconst _vector3 = new Vector3();\n\n\tconst _emptyScene = { background: null, fog: null, environment: null, overrideMaterial: null, isScene: true };\n\n\tfunction getTargetPixelRatio() {\n\n\t\treturn _currentRenderTarget === null ? _pixelRatio : 1;\n\n\t}\n\n\t// initialize\n\n\tlet _gl = _context;\n\n\tfunction getContext( contextNames, contextAttributes ) {\n\n\t\tfor ( let i = 0; i < contextNames.length; i ++ ) {\n\n\t\t\tconst contextName = contextNames[ i ];\n\t\t\tconst context = _canvas.getContext( contextName, contextAttributes );\n\t\t\tif ( context !== null ) return context;\n\n\t\t}\n\n\t\treturn null;\n\n\t}\n\n\ttry {\n\n\t\tconst contextAttributes = {\n\t\t\talpha: true,\n\t\t\tdepth: _depth,\n\t\t\tstencil: _stencil,\n\t\t\tantialias: _antialias,\n\t\t\tpremultipliedAlpha: _premultipliedAlpha,\n\t\t\tpreserveDrawingBuffer: _preserveDrawingBuffer,\n\t\t\tpowerPreference: _powerPreference,\n\t\t\tfailIfMajorPerformanceCaveat: _failIfMajorPerformanceCaveat\n\t\t};\n\n\t\t// OffscreenCanvas does not have setAttribute, see #22811\n\t\tif ( 'setAttribute' in _canvas ) _canvas.setAttribute( 'data-engine', `three.js r${REVISION}` );\n\n\t\t// event listeners must be registered before WebGL context is created, see #12753\n\t\t_canvas.addEventListener( 'webglcontextlost', onContextLost, false );\n\t\t_canvas.addEventListener( 'webglcontextrestored', onContextRestore, false );\n\n\t\tif ( _gl === null ) {\n\n\t\t\tconst contextNames = [ 'webgl2', 'webgl', 'experimental-webgl' ];\n\n\t\t\tif ( _this.isWebGL1Renderer === true ) {\n\n\t\t\t\tcontextNames.shift();\n\n\t\t\t}\n\n\t\t\t_gl = getContext( contextNames, contextAttributes );\n\n\t\t\tif ( _gl === null ) {\n\n\t\t\t\tif ( getContext( contextNames ) ) {\n\n\t\t\t\t\tthrow new Error( 'Error creating WebGL context with your selected attributes.' );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthrow new Error( 'Error creating WebGL context.' );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Some experimental-webgl implementations do not have getShaderPrecisionFormat\n\n\t\tif ( _gl.getShaderPrecisionFormat === undefined ) {\n\n\t\t\t_gl.getShaderPrecisionFormat = function () {\n\n\t\t\t\treturn { 'rangeMin': 1, 'rangeMax': 1, 'precision': 1 };\n\n\t\t\t};\n\n\t\t}\n\n\t} catch ( error ) {\n\n\t\tconsole.error( 'THREE.WebGLRenderer: ' + error.message );\n\t\tthrow error;\n\n\t}\n\n\tlet extensions, capabilities, state, info;\n\tlet properties, textures, cubemaps, cubeuvmaps, attributes, geometries, objects;\n\tlet programCache, materials, renderLists, renderStates, clipping, shadowMap;\n\n\tlet background, morphtargets, bufferRenderer, indexedBufferRenderer;\n\n\tlet utils, bindingStates;\n\n\tfunction initGLContext() {\n\n\t\textensions = new WebGLExtensions( _gl );\n\n\t\tcapabilities = new WebGLCapabilities( _gl, extensions, parameters );\n\n\t\textensions.init( capabilities );\n\n\t\tutils = new WebGLUtils( _gl, extensions, capabilities );\n\n\t\tstate = new WebGLState( _gl, extensions, capabilities );\n\n\t\tinfo = new WebGLInfo( _gl );\n\t\tproperties = new WebGLProperties();\n\t\ttextures = new WebGLTextures( _gl, extensions, state, properties, capabilities, utils, info );\n\t\tcubemaps = new WebGLCubeMaps( _this );\n\t\tcubeuvmaps = new WebGLCubeUVMaps( _this );\n\t\tattributes = new WebGLAttributes( _gl, capabilities );\n\t\tbindingStates = new WebGLBindingStates( _gl, extensions, attributes, capabilities );\n\t\tgeometries = new WebGLGeometries( _gl, attributes, info, bindingStates );\n\t\tobjects = new WebGLObjects( _gl, geometries, attributes, info );\n\t\tmorphtargets = new WebGLMorphtargets( _gl, capabilities, textures );\n\t\tclipping = new WebGLClipping( properties );\n\t\tprogramCache = new WebGLPrograms( _this, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping );\n\t\tmaterials = new WebGLMaterials( properties );\n\t\trenderLists = new WebGLRenderLists();\n\t\trenderStates = new WebGLRenderStates( extensions, capabilities );\n\t\tbackground = new WebGLBackground( _this, cubemaps, state, objects, _alpha, _premultipliedAlpha );\n\t\tshadowMap = new WebGLShadowMap( _this, objects, capabilities );\n\n\t\tbufferRenderer = new WebGLBufferRenderer( _gl, extensions, info, capabilities );\n\t\tindexedBufferRenderer = new WebGLIndexedBufferRenderer( _gl, extensions, info, capabilities );\n\n\t\tinfo.programs = programCache.programs;\n\n\t\t_this.capabilities = capabilities;\n\t\t_this.extensions = extensions;\n\t\t_this.properties = properties;\n\t\t_this.renderLists = renderLists;\n\t\t_this.shadowMap = shadowMap;\n\t\t_this.state = state;\n\t\t_this.info = info;\n\n\t}\n\n\tinitGLContext();\n\n\t// xr\n\n\tconst xr = new WebXRManager( _this, _gl );\n\n\tthis.xr = xr;\n\n\t// API\n\n\tthis.getContext = function () {\n\n\t\treturn _gl;\n\n\t};\n\n\tthis.getContextAttributes = function () {\n\n\t\treturn _gl.getContextAttributes();\n\n\t};\n\n\tthis.forceContextLoss = function () {\n\n\t\tconst extension = extensions.get( 'WEBGL_lose_context' );\n\t\tif ( extension ) extension.loseContext();\n\n\t};\n\n\tthis.forceContextRestore = function () {\n\n\t\tconst extension = extensions.get( 'WEBGL_lose_context' );\n\t\tif ( extension ) extension.restoreContext();\n\n\t};\n\n\tthis.getPixelRatio = function () {\n\n\t\treturn _pixelRatio;\n\n\t};\n\n\tthis.setPixelRatio = function ( value ) {\n\n\t\tif ( value === undefined ) return;\n\n\t\t_pixelRatio = value;\n\n\t\tthis.setSize( _width, _height, false );\n\n\t};\n\n\tthis.getSize = function ( target ) {\n\n\t\treturn target.set( _width, _height );\n\n\t};\n\n\tthis.setSize = function ( width, height, updateStyle ) {\n\n\t\tif ( xr.isPresenting ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: Can\\'t change size while VR device is presenting.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\t_width = width;\n\t\t_height = height;\n\n\t\t_canvas.width = Math.floor( width * _pixelRatio );\n\t\t_canvas.height = Math.floor( height * _pixelRatio );\n\n\t\tif ( updateStyle !== false ) {\n\n\t\t\t_canvas.style.width = width + 'px';\n\t\t\t_canvas.style.height = height + 'px';\n\n\t\t}\n\n\t\tthis.setViewport( 0, 0, width, height );\n\n\t};\n\n\tthis.getDrawingBufferSize = function ( target ) {\n\n\t\treturn target.set( _width * _pixelRatio, _height * _pixelRatio ).floor();\n\n\t};\n\n\tthis.setDrawingBufferSize = function ( width, height, pixelRatio ) {\n\n\t\t_width = width;\n\t\t_height = height;\n\n\t\t_pixelRatio = pixelRatio;\n\n\t\t_canvas.width = Math.floor( width * pixelRatio );\n\t\t_canvas.height = Math.floor( height * pixelRatio );\n\n\t\tthis.setViewport( 0, 0, width, height );\n\n\t};\n\n\tthis.getCurrentViewport = function ( target ) {\n\n\t\treturn target.copy( _currentViewport );\n\n\t};\n\n\tthis.getViewport = function ( target ) {\n\n\t\treturn target.copy( _viewport );\n\n\t};\n\n\tthis.setViewport = function ( x, y, width, height ) {\n\n\t\tif ( x.isVector4 ) {\n\n\t\t\t_viewport.set( x.x, x.y, x.z, x.w );\n\n\t\t} else {\n\n\t\t\t_viewport.set( x, y, width, height );\n\n\t\t}\n\n\t\tstate.viewport( _currentViewport.copy( _viewport ).multiplyScalar( _pixelRatio ).floor() );\n\n\t};\n\n\tthis.getScissor = function ( target ) {\n\n\t\treturn target.copy( _scissor );\n\n\t};\n\n\tthis.setScissor = function ( x, y, width, height ) {\n\n\t\tif ( x.isVector4 ) {\n\n\t\t\t_scissor.set( x.x, x.y, x.z, x.w );\n\n\t\t} else {\n\n\t\t\t_scissor.set( x, y, width, height );\n\n\t\t}\n\n\t\tstate.scissor( _currentScissor.copy( _scissor ).multiplyScalar( _pixelRatio ).floor() );\n\n\t};\n\n\tthis.getScissorTest = function () {\n\n\t\treturn _scissorTest;\n\n\t};\n\n\tthis.setScissorTest = function ( boolean ) {\n\n\t\tstate.setScissorTest( _scissorTest = boolean );\n\n\t};\n\n\tthis.setOpaqueSort = function ( method ) {\n\n\t\t_opaqueSort = method;\n\n\t};\n\n\tthis.setTransparentSort = function ( method ) {\n\n\t\t_transparentSort = method;\n\n\t};\n\n\t// Clearing\n\n\tthis.getClearColor = function ( target ) {\n\n\t\treturn target.copy( background.getClearColor() );\n\n\t};\n\n\tthis.setClearColor = function () {\n\n\t\tbackground.setClearColor.apply( background, arguments );\n\n\t};\n\n\tthis.getClearAlpha = function () {\n\n\t\treturn background.getClearAlpha();\n\n\t};\n\n\tthis.setClearAlpha = function () {\n\n\t\tbackground.setClearAlpha.apply( background, arguments );\n\n\t};\n\n\tthis.clear = function ( color = true, depth = true, stencil = true ) {\n\n\t\tlet bits = 0;\n\n\t\tif ( color ) bits |= 16384;\n\t\tif ( depth ) bits |= 256;\n\t\tif ( stencil ) bits |= 1024;\n\n\t\t_gl.clear( bits );\n\n\t};\n\n\tthis.clearColor = function () {\n\n\t\tthis.clear( true, false, false );\n\n\t};\n\n\tthis.clearDepth = function () {\n\n\t\tthis.clear( false, true, false );\n\n\t};\n\n\tthis.clearStencil = function () {\n\n\t\tthis.clear( false, false, true );\n\n\t};\n\n\t//\n\n\tthis.dispose = function () {\n\n\t\t_canvas.removeEventListener( 'webglcontextlost', onContextLost, false );\n\t\t_canvas.removeEventListener( 'webglcontextrestored', onContextRestore, false );\n\n\t\trenderLists.dispose();\n\t\trenderStates.dispose();\n\t\tproperties.dispose();\n\t\tcubemaps.dispose();\n\t\tcubeuvmaps.dispose();\n\t\tobjects.dispose();\n\t\tbindingStates.dispose();\n\t\tprogramCache.dispose();\n\n\t\txr.dispose();\n\n\t\txr.removeEventListener( 'sessionstart', onXRSessionStart );\n\t\txr.removeEventListener( 'sessionend', onXRSessionEnd );\n\n\t\tif ( _transmissionRenderTarget ) {\n\n\t\t\t_transmissionRenderTarget.dispose();\n\t\t\t_transmissionRenderTarget = null;\n\n\t\t}\n\n\t\tanimation.stop();\n\n\t};\n\n\t// Events\n\n\tfunction onContextLost( event ) {\n\n\t\tevent.preventDefault();\n\n\t\tconsole.log( 'THREE.WebGLRenderer: Context Lost.' );\n\n\t\t_isContextLost = true;\n\n\t}\n\n\tfunction onContextRestore( /* event */ ) {\n\n\t\tconsole.log( 'THREE.WebGLRenderer: Context Restored.' );\n\n\t\t_isContextLost = false;\n\n\t\tconst infoAutoReset = info.autoReset;\n\t\tconst shadowMapEnabled = shadowMap.enabled;\n\t\tconst shadowMapAutoUpdate = shadowMap.autoUpdate;\n\t\tconst shadowMapNeedsUpdate = shadowMap.needsUpdate;\n\t\tconst shadowMapType = shadowMap.type;\n\n\t\tinitGLContext();\n\n\t\tinfo.autoReset = infoAutoReset;\n\t\tshadowMap.enabled = shadowMapEnabled;\n\t\tshadowMap.autoUpdate = shadowMapAutoUpdate;\n\t\tshadowMap.needsUpdate = shadowMapNeedsUpdate;\n\t\tshadowMap.type = shadowMapType;\n\n\t}\n\n\tfunction onMaterialDispose( event ) {\n\n\t\tconst material = event.target;\n\n\t\tmaterial.removeEventListener( 'dispose', onMaterialDispose );\n\n\t\tdeallocateMaterial( material );\n\n\t}\n\n\t// Buffer deallocation\n\n\tfunction deallocateMaterial( material ) {\n\n\t\treleaseMaterialProgramReferences( material );\n\n\t\tproperties.remove( material );\n\n\t}\n\n\n\tfunction releaseMaterialProgramReferences( material ) {\n\n\t\tconst programs = properties.get( material ).programs;\n\n\t\tif ( programs !== undefined ) {\n\n\t\t\tprograms.forEach( function ( program ) {\n\n\t\t\t\tprogramCache.releaseProgram( program );\n\n\t\t\t} );\n\n\t\t\tif ( material.isShaderMaterial ) {\n\n\t\t\t\tprogramCache.releaseShaderCache( material );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t// Buffer rendering\n\n\tthis.renderBufferDirect = function ( camera, scene, geometry, material, object, group ) {\n\n\t\tif ( scene === null ) scene = _emptyScene; // renderBufferDirect second parameter used to be fog (could be null)\n\n\t\tconst frontFaceCW = ( object.isMesh && object.matrixWorld.determinant() < 0 );\n\n\t\tconst program = setProgram( camera, scene, geometry, material, object );\n\n\t\tstate.setMaterial( material, frontFaceCW );\n\n\t\t//\n\n\t\tlet index = geometry.index;\n\t\tconst position = geometry.attributes.position;\n\n\t\t//\n\n\t\tif ( index === null ) {\n\n\t\t\tif ( position === undefined || position.count === 0 ) return;\n\n\t\t} else if ( index.count === 0 ) {\n\n\t\t\treturn;\n\n\t\t}\n\n\t\t//\n\n\t\tlet rangeFactor = 1;\n\n\t\tif ( material.wireframe === true ) {\n\n\t\t\tindex = geometries.getWireframeAttribute( geometry );\n\t\t\trangeFactor = 2;\n\n\t\t}\n\n\t\tbindingStates.setup( object, material, program, geometry, index );\n\n\t\tlet attribute;\n\t\tlet renderer = bufferRenderer;\n\n\t\tif ( index !== null ) {\n\n\t\t\tattribute = attributes.get( index );\n\n\t\t\trenderer = indexedBufferRenderer;\n\t\t\trenderer.setIndex( attribute );\n\n\t\t}\n\n\t\t//\n\n\t\tconst dataCount = ( index !== null ) ? index.count : position.count;\n\n\t\tconst rangeStart = geometry.drawRange.start * rangeFactor;\n\t\tconst rangeCount = geometry.drawRange.count * rangeFactor;\n\n\t\tconst groupStart = group !== null ? group.start * rangeFactor : 0;\n\t\tconst groupCount = group !== null ? group.count * rangeFactor : Infinity;\n\n\t\tconst drawStart = Math.max( rangeStart, groupStart );\n\t\tconst drawEnd = Math.min( dataCount, rangeStart + rangeCount, groupStart + groupCount ) - 1;\n\n\t\tconst drawCount = Math.max( 0, drawEnd - drawStart + 1 );\n\n\t\tif ( drawCount === 0 ) return;\n\n\t\t//\n\n\t\tif ( object.isMesh ) {\n\n\t\t\tif ( material.wireframe === true ) {\n\n\t\t\t\tstate.setLineWidth( material.wireframeLinewidth * getTargetPixelRatio() );\n\t\t\t\trenderer.setMode( 1 );\n\n\t\t\t} else {\n\n\t\t\t\trenderer.setMode( 4 );\n\n\t\t\t}\n\n\t\t} else if ( object.isLine ) {\n\n\t\t\tlet lineWidth = material.linewidth;\n\n\t\t\tif ( lineWidth === undefined ) lineWidth = 1; // Not using Line*Material\n\n\t\t\tstate.setLineWidth( lineWidth * getTargetPixelRatio() );\n\n\t\t\tif ( object.isLineSegments ) {\n\n\t\t\t\trenderer.setMode( 1 );\n\n\t\t\t} else if ( object.isLineLoop ) {\n\n\t\t\t\trenderer.setMode( 2 );\n\n\t\t\t} else {\n\n\t\t\t\trenderer.setMode( 3 );\n\n\t\t\t}\n\n\t\t} else if ( object.isPoints ) {\n\n\t\t\trenderer.setMode( 0 );\n\n\t\t} else if ( object.isSprite ) {\n\n\t\t\trenderer.setMode( 4 );\n\n\t\t}\n\n\t\tif ( object.isInstancedMesh ) {\n\n\t\t\trenderer.renderInstances( drawStart, drawCount, object.count );\n\n\t\t} else if ( geometry.isInstancedBufferGeometry ) {\n\n\t\t\tconst instanceCount = Math.min( geometry.instanceCount, geometry._maxInstanceCount );\n\n\t\t\trenderer.renderInstances( drawStart, drawCount, instanceCount );\n\n\t\t} else {\n\n\t\t\trenderer.render( drawStart, drawCount );\n\n\t\t}\n\n\t};\n\n\t// Compile\n\n\tthis.compile = function ( scene, camera ) {\n\n\t\tcurrentRenderState = renderStates.get( scene );\n\t\tcurrentRenderState.init();\n\n\t\trenderStateStack.push( currentRenderState );\n\n\t\tscene.traverseVisible( function ( object ) {\n\n\t\t\tif ( object.isLight && object.layers.test( camera.layers ) ) {\n\n\t\t\t\tcurrentRenderState.pushLight( object );\n\n\t\t\t\tif ( object.castShadow ) {\n\n\t\t\t\t\tcurrentRenderState.pushShadow( object );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} );\n\n\t\tcurrentRenderState.setupLights( _this.physicallyCorrectLights );\n\n\t\tscene.traverse( function ( object ) {\n\n\t\t\tconst material = object.material;\n\n\t\t\tif ( material ) {\n\n\t\t\t\tif ( Array.isArray( material ) ) {\n\n\t\t\t\t\tfor ( let i = 0; i < material.length; i ++ ) {\n\n\t\t\t\t\t\tconst material2 = material[ i ];\n\n\t\t\t\t\t\tgetProgram( material2, scene, object );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tgetProgram( material, scene, object );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} );\n\n\t\trenderStateStack.pop();\n\t\tcurrentRenderState = null;\n\n\t};\n\n\t// Animation Loop\n\n\tlet onAnimationFrameCallback = null;\n\n\tfunction onAnimationFrame( time ) {\n\n\t\tif ( onAnimationFrameCallback ) onAnimationFrameCallback( time );\n\n\t}\n\n\tfunction onXRSessionStart() {\n\n\t\tanimation.stop();\n\n\t}\n\n\tfunction onXRSessionEnd() {\n\n\t\tanimation.start();\n\n\t}\n\n\tconst animation = new WebGLAnimation();\n\tanimation.setAnimationLoop( onAnimationFrame );\n\n\tif ( typeof window !== 'undefined' ) animation.setContext( window );\n\n\tthis.setAnimationLoop = function ( callback ) {\n\n\t\tonAnimationFrameCallback = callback;\n\t\txr.setAnimationLoop( callback );\n\n\t\t( callback === null ) ? animation.stop() : animation.start();\n\n\t};\n\n\txr.addEventListener( 'sessionstart', onXRSessionStart );\n\txr.addEventListener( 'sessionend', onXRSessionEnd );\n\n\t// Rendering\n\n\tthis.render = function ( scene, camera ) {\n\n\t\tif ( camera !== undefined && camera.isCamera !== true ) {\n\n\t\t\tconsole.error( 'THREE.WebGLRenderer.render: camera is not an instance of THREE.Camera.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( _isContextLost === true ) return;\n\n\t\t// update scene graph\n\n\t\tif ( scene.autoUpdate === true ) scene.updateMatrixWorld();\n\n\t\t// update camera matrices and frustum\n\n\t\tif ( camera.parent === null ) camera.updateMatrixWorld();\n\n\t\tif ( xr.enabled === true && xr.isPresenting === true ) {\n\n\t\t\tif ( xr.cameraAutoUpdate === true ) xr.updateCamera( camera );\n\n\t\t\tcamera = xr.getCamera(); // use XR camera for rendering\n\n\t\t}\n\n\t\t//\n\t\tif ( scene.isScene === true ) scene.onBeforeRender( _this, scene, camera, _currentRenderTarget );\n\n\t\tcurrentRenderState = renderStates.get( scene, renderStateStack.length );\n\t\tcurrentRenderState.init();\n\n\t\trenderStateStack.push( currentRenderState );\n\n\t\t_projScreenMatrix.multiplyMatrices( camera.projectionMatrix, camera.matrixWorldInverse );\n\t\t_frustum.setFromProjectionMatrix( _projScreenMatrix );\n\n\t\t_localClippingEnabled = this.localClippingEnabled;\n\t\t_clippingEnabled = clipping.init( this.clippingPlanes, _localClippingEnabled, camera );\n\n\t\tcurrentRenderList = renderLists.get( scene, renderListStack.length );\n\t\tcurrentRenderList.init();\n\n\t\trenderListStack.push( currentRenderList );\n\n\t\tprojectObject( scene, camera, 0, _this.sortObjects );\n\n\t\tcurrentRenderList.finish();\n\n\t\tif ( _this.sortObjects === true ) {\n\n\t\t\tcurrentRenderList.sort( _opaqueSort, _transparentSort );\n\n\t\t}\n\n\t\t//\n\n\t\tif ( _clippingEnabled === true ) clipping.beginShadows();\n\n\t\tconst shadowsArray = currentRenderState.state.shadowsArray;\n\n\t\tshadowMap.render( shadowsArray, scene, camera );\n\n\t\tif ( _clippingEnabled === true ) clipping.endShadows();\n\n\t\t//\n\n\t\tif ( this.info.autoReset === true ) this.info.reset();\n\n\t\t//\n\n\t\tbackground.render( currentRenderList, scene );\n\n\t\t// render scene\n\n\t\tcurrentRenderState.setupLights( _this.physicallyCorrectLights );\n\n\t\tif ( camera.isArrayCamera ) {\n\n\t\t\tconst cameras = camera.cameras;\n\n\t\t\tfor ( let i = 0, l = cameras.length; i < l; i ++ ) {\n\n\t\t\t\tconst camera2 = cameras[ i ];\n\n\t\t\t\trenderScene( currentRenderList, scene, camera2, camera2.viewport );\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\trenderScene( currentRenderList, scene, camera );\n\n\t\t}\n\n\t\t//\n\n\t\tif ( _currentRenderTarget !== null ) {\n\n\t\t\t// resolve multisample renderbuffers to a single-sample texture if necessary\n\n\t\t\ttextures.updateMultisampleRenderTarget( _currentRenderTarget );\n\n\t\t\t// Generate mipmap if we're using any kind of mipmap filtering\n\n\t\t\ttextures.updateRenderTargetMipmap( _currentRenderTarget );\n\n\t\t}\n\n\t\t//\n\n\t\tif ( scene.isScene === true ) scene.onAfterRender( _this, scene, camera );\n\n\t\t// _gl.finish();\n\n\t\tbindingStates.resetDefaultState();\n\t\t_currentMaterialId = - 1;\n\t\t_currentCamera = null;\n\n\t\trenderStateStack.pop();\n\n\t\tif ( renderStateStack.length > 0 ) {\n\n\t\t\tcurrentRenderState = renderStateStack[ renderStateStack.length - 1 ];\n\n\t\t} else {\n\n\t\t\tcurrentRenderState = null;\n\n\t\t}\n\n\t\trenderListStack.pop();\n\n\t\tif ( renderListStack.length > 0 ) {\n\n\t\t\tcurrentRenderList = renderListStack[ renderListStack.length - 1 ];\n\n\t\t} else {\n\n\t\t\tcurrentRenderList = null;\n\n\t\t}\n\n\t};\n\n\tfunction projectObject( object, camera, groupOrder, sortObjects ) {\n\n\t\tif ( object.visible === false ) return;\n\n\t\tconst visible = object.layers.test( camera.layers );\n\n\t\tif ( visible ) {\n\n\t\t\tif ( object.isGroup ) {\n\n\t\t\t\tgroupOrder = object.renderOrder;\n\n\t\t\t} else if ( object.isLOD ) {\n\n\t\t\t\tif ( object.autoUpdate === true ) object.update( camera );\n\n\t\t\t} else if ( object.isLight ) {\n\n\t\t\t\tcurrentRenderState.pushLight( object );\n\n\t\t\t\tif ( object.castShadow ) {\n\n\t\t\t\t\tcurrentRenderState.pushShadow( object );\n\n\t\t\t\t}\n\n\t\t\t} else if ( object.isSprite ) {\n\n\t\t\t\tif ( ! object.frustumCulled || _frustum.intersectsSprite( object ) ) {\n\n\t\t\t\t\tif ( sortObjects ) {\n\n\t\t\t\t\t\t_vector3.setFromMatrixPosition( object.matrixWorld )\n\t\t\t\t\t\t\t.applyMatrix4( _projScreenMatrix );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst geometry = objects.update( object );\n\t\t\t\t\tconst material = object.material;\n\n\t\t\t\t\tif ( material.visible ) {\n\n\t\t\t\t\t\tcurrentRenderList.push( object, geometry, material, groupOrder, _vector3.z, null );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else if ( object.isMesh || object.isLine || object.isPoints ) {\n\n\t\t\t\tif ( object.isSkinnedMesh ) {\n\n\t\t\t\t\t// update skeleton only once in a frame\n\n\t\t\t\t\tif ( object.skeleton.frame !== info.render.frame ) {\n\n\t\t\t\t\t\tobject.skeleton.update();\n\t\t\t\t\t\tobject.skeleton.frame = info.render.frame;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tif ( ! object.frustumCulled || _frustum.intersectsObject( object ) ) {\n\n\t\t\t\t\tif ( sortObjects ) {\n\n\t\t\t\t\t\t_vector3.setFromMatrixPosition( object.matrixWorld )\n\t\t\t\t\t\t\t.applyMatrix4( _projScreenMatrix );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst geometry = objects.update( object );\n\t\t\t\t\tconst material = object.material;\n\n\t\t\t\t\tif ( Array.isArray( material ) ) {\n\n\t\t\t\t\t\tconst groups = geometry.groups;\n\n\t\t\t\t\t\tfor ( let i = 0, l = groups.length; i < l; i ++ ) {\n\n\t\t\t\t\t\t\tconst group = groups[ i ];\n\t\t\t\t\t\t\tconst groupMaterial = material[ group.materialIndex ];\n\n\t\t\t\t\t\t\tif ( groupMaterial && groupMaterial.visible ) {\n\n\t\t\t\t\t\t\t\tcurrentRenderList.push( object, geometry, groupMaterial, groupOrder, _vector3.z, group );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else if ( material.visible ) {\n\n\t\t\t\t\t\tcurrentRenderList.push( object, geometry, material, groupOrder, _vector3.z, null );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst children = object.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\tprojectObject( children[ i ], camera, groupOrder, sortObjects );\n\n\t\t}\n\n\t}\n\n\tfunction renderScene( currentRenderList, scene, camera, viewport ) {\n\n\t\tconst opaqueObjects = currentRenderList.opaque;\n\t\tconst transmissiveObjects = currentRenderList.transmissive;\n\t\tconst transparentObjects = currentRenderList.transparent;\n\n\t\tcurrentRenderState.setupLightsView( camera );\n\n\t\tif ( transmissiveObjects.length > 0 ) renderTransmissionPass( opaqueObjects, scene, camera );\n\n\t\tif ( viewport ) state.viewport( _currentViewport.copy( viewport ) );\n\n\t\tif ( opaqueObjects.length > 0 ) renderObjects( opaqueObjects, scene, camera );\n\t\tif ( transmissiveObjects.length > 0 ) renderObjects( transmissiveObjects, scene, camera );\n\t\tif ( transparentObjects.length > 0 ) renderObjects( transparentObjects, scene, camera );\n\n\t\t// Ensure depth buffer writing is enabled so it can be cleared on next render\n\n\t\tstate.buffers.depth.setTest( true );\n\t\tstate.buffers.depth.setMask( true );\n\t\tstate.buffers.color.setMask( true );\n\n\t\tstate.setPolygonOffset( false );\n\n\t}\n\n\tfunction renderTransmissionPass( opaqueObjects, scene, camera ) {\n\n\t\tconst isWebGL2 = capabilities.isWebGL2;\n\n\t\tif ( _transmissionRenderTarget === null ) {\n\n\t\t\t_transmissionRenderTarget = new WebGLRenderTarget( 1, 1, {\n\t\t\t\tgenerateMipmaps: true,\n\t\t\t\ttype: utils.convert( HalfFloatType ) !== null ? HalfFloatType : UnsignedByteType,\n\t\t\t\tminFilter: LinearMipmapLinearFilter,\n\t\t\t\tsamples: ( isWebGL2 && _antialias === true ) ? 4 : 0\n\t\t\t} );\n\n\t\t}\n\n\t\t_this.getDrawingBufferSize( _vector2 );\n\n\t\tif ( isWebGL2 ) {\n\n\t\t\t_transmissionRenderTarget.setSize( _vector2.x, _vector2.y );\n\n\t\t} else {\n\n\t\t\t_transmissionRenderTarget.setSize( floorPowerOfTwo( _vector2.x ), floorPowerOfTwo( _vector2.y ) );\n\n\t\t}\n\n\t\t//\n\n\t\tconst currentRenderTarget = _this.getRenderTarget();\n\t\t_this.setRenderTarget( _transmissionRenderTarget );\n\t\t_this.clear();\n\n\t\t// Turn off the features which can affect the frag color for opaque objects pass.\n\t\t// Otherwise they are applied twice in opaque objects pass and transmission objects pass.\n\t\tconst currentToneMapping = _this.toneMapping;\n\t\t_this.toneMapping = NoToneMapping;\n\n\t\trenderObjects( opaqueObjects, scene, camera );\n\n\t\t_this.toneMapping = currentToneMapping;\n\n\t\ttextures.updateMultisampleRenderTarget( _transmissionRenderTarget );\n\t\ttextures.updateRenderTargetMipmap( _transmissionRenderTarget );\n\n\t\t_this.setRenderTarget( currentRenderTarget );\n\n\t}\n\n\tfunction renderObjects( renderList, scene, camera ) {\n\n\t\tconst overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;\n\n\t\tfor ( let i = 0, l = renderList.length; i < l; i ++ ) {\n\n\t\t\tconst renderItem = renderList[ i ];\n\n\t\t\tconst object = renderItem.object;\n\t\t\tconst geometry = renderItem.geometry;\n\t\t\tconst material = overrideMaterial === null ? renderItem.material : overrideMaterial;\n\t\t\tconst group = renderItem.group;\n\n\t\t\tif ( object.layers.test( camera.layers ) ) {\n\n\t\t\t\trenderObject( object, scene, camera, geometry, material, group );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tfunction renderObject( object, scene, camera, geometry, material, group ) {\n\n\t\tobject.onBeforeRender( _this, scene, camera, geometry, material, group );\n\n\t\tobject.modelViewMatrix.multiplyMatrices( camera.matrixWorldInverse, object.matrixWorld );\n\t\tobject.normalMatrix.getNormalMatrix( object.modelViewMatrix );\n\n\t\tmaterial.onBeforeRender( _this, scene, camera, geometry, object, group );\n\n\t\tif ( material.transparent === true && material.side === DoubleSide ) {\n\n\t\t\tmaterial.side = BackSide;\n\t\t\tmaterial.needsUpdate = true;\n\t\t\t_this.renderBufferDirect( camera, scene, geometry, material, object, group );\n\n\t\t\tmaterial.side = FrontSide;\n\t\t\tmaterial.needsUpdate = true;\n\t\t\t_this.renderBufferDirect( camera, scene, geometry, material, object, group );\n\n\t\t\tmaterial.side = DoubleSide;\n\n\t\t} else {\n\n\t\t\t_this.renderBufferDirect( camera, scene, geometry, material, object, group );\n\n\t\t}\n\n\t\tobject.onAfterRender( _this, scene, camera, geometry, material, group );\n\n\t}\n\n\tfunction getProgram( material, scene, object ) {\n\n\t\tif ( scene.isScene !== true ) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...\n\n\t\tconst materialProperties = properties.get( material );\n\n\t\tconst lights = currentRenderState.state.lights;\n\t\tconst shadowsArray = currentRenderState.state.shadowsArray;\n\n\t\tconst lightsStateVersion = lights.state.version;\n\n\t\tconst parameters = programCache.getParameters( material, lights.state, shadowsArray, scene, object );\n\t\tconst programCacheKey = programCache.getProgramCacheKey( parameters );\n\n\t\tlet programs = materialProperties.programs;\n\n\t\t// always update environment and fog - changing these trigger an getProgram call, but it's possible that the program doesn't change\n\n\t\tmaterialProperties.environment = material.isMeshStandardMaterial ? scene.environment : null;\n\t\tmaterialProperties.fog = scene.fog;\n\t\tmaterialProperties.envMap = ( material.isMeshStandardMaterial ? cubeuvmaps : cubemaps ).get( material.envMap || materialProperties.environment );\n\n\t\tif ( programs === undefined ) {\n\n\t\t\t// new material\n\n\t\t\tmaterial.addEventListener( 'dispose', onMaterialDispose );\n\n\t\t\tprograms = new Map();\n\t\t\tmaterialProperties.programs = programs;\n\n\t\t}\n\n\t\tlet program = programs.get( programCacheKey );\n\n\t\tif ( program !== undefined ) {\n\n\t\t\t// early out if program and light state is identical\n\n\t\t\tif ( materialProperties.currentProgram === program && materialProperties.lightsStateVersion === lightsStateVersion ) {\n\n\t\t\t\tupdateCommonMaterialProperties( material, parameters );\n\n\t\t\t\treturn program;\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tparameters.uniforms = programCache.getUniforms( material );\n\n\t\t\tmaterial.onBuild( object, parameters, _this );\n\n\t\t\tmaterial.onBeforeCompile( parameters, _this );\n\n\t\t\tprogram = programCache.acquireProgram( parameters, programCacheKey );\n\t\t\tprograms.set( programCacheKey, program );\n\n\t\t\tmaterialProperties.uniforms = parameters.uniforms;\n\n\t\t}\n\n\t\tconst uniforms = materialProperties.uniforms;\n\n\t\tif ( ( ! material.isShaderMaterial && ! material.isRawShaderMaterial ) || material.clipping === true ) {\n\n\t\t\tuniforms.clippingPlanes = clipping.uniform;\n\n\t\t}\n\n\t\tupdateCommonMaterialProperties( material, parameters );\n\n\t\t// store the light setup it was created for\n\n\t\tmaterialProperties.needsLights = materialNeedsLights( material );\n\t\tmaterialProperties.lightsStateVersion = lightsStateVersion;\n\n\t\tif ( materialProperties.needsLights ) {\n\n\t\t\t// wire up the material to this renderer's lighting state\n\n\t\t\tuniforms.ambientLightColor.value = lights.state.ambient;\n\t\t\tuniforms.lightProbe.value = lights.state.probe;\n\t\t\tuniforms.directionalLights.value = lights.state.directional;\n\t\t\tuniforms.directionalLightShadows.value = lights.state.directionalShadow;\n\t\t\tuniforms.spotLights.value = lights.state.spot;\n\t\t\tuniforms.spotLightShadows.value = lights.state.spotShadow;\n\t\t\tuniforms.rectAreaLights.value = lights.state.rectArea;\n\t\t\tuniforms.ltc_1.value = lights.state.rectAreaLTC1;\n\t\t\tuniforms.ltc_2.value = lights.state.rectAreaLTC2;\n\t\t\tuniforms.pointLights.value = lights.state.point;\n\t\t\tuniforms.pointLightShadows.value = lights.state.pointShadow;\n\t\t\tuniforms.hemisphereLights.value = lights.state.hemi;\n\n\t\t\tuniforms.directionalShadowMap.value = lights.state.directionalShadowMap;\n\t\t\tuniforms.directionalShadowMatrix.value = lights.state.directionalShadowMatrix;\n\t\t\tuniforms.spotShadowMap.value = lights.state.spotShadowMap;\n\t\t\tuniforms.spotShadowMatrix.value = lights.state.spotShadowMatrix;\n\t\t\tuniforms.pointShadowMap.value = lights.state.pointShadowMap;\n\t\t\tuniforms.pointShadowMatrix.value = lights.state.pointShadowMatrix;\n\t\t\t// TODO (abelnation): add area lights shadow info to uniforms\n\n\t\t}\n\n\t\tconst progUniforms = program.getUniforms();\n\t\tconst uniformsList = WebGLUniforms.seqWithValue( progUniforms.seq, uniforms );\n\n\t\tmaterialProperties.currentProgram = program;\n\t\tmaterialProperties.uniformsList = uniformsList;\n\n\t\treturn program;\n\n\t}\n\n\tfunction updateCommonMaterialProperties( material, parameters ) {\n\n\t\tconst materialProperties = properties.get( material );\n\n\t\tmaterialProperties.outputEncoding = parameters.outputEncoding;\n\t\tmaterialProperties.instancing = parameters.instancing;\n\t\tmaterialProperties.skinning = parameters.skinning;\n\t\tmaterialProperties.morphTargets = parameters.morphTargets;\n\t\tmaterialProperties.morphNormals = parameters.morphNormals;\n\t\tmaterialProperties.morphColors = parameters.morphColors;\n\t\tmaterialProperties.morphTargetsCount = parameters.morphTargetsCount;\n\t\tmaterialProperties.numClippingPlanes = parameters.numClippingPlanes;\n\t\tmaterialProperties.numIntersection = parameters.numClipIntersection;\n\t\tmaterialProperties.vertexAlphas = parameters.vertexAlphas;\n\t\tmaterialProperties.vertexTangents = parameters.vertexTangents;\n\t\tmaterialProperties.toneMapping = parameters.toneMapping;\n\n\t}\n\n\tfunction setProgram( camera, scene, geometry, material, object ) {\n\n\t\tif ( scene.isScene !== true ) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...\n\n\t\ttextures.resetTextureUnits();\n\n\t\tconst fog = scene.fog;\n\t\tconst environment = material.isMeshStandardMaterial ? scene.environment : null;\n\t\tconst encoding = ( _currentRenderTarget === null ) ? _this.outputEncoding : ( _currentRenderTarget.isXRRenderTarget === true ? _currentRenderTarget.texture.encoding : LinearEncoding );\n\t\tconst envMap = ( material.isMeshStandardMaterial ? cubeuvmaps : cubemaps ).get( material.envMap || environment );\n\t\tconst vertexAlphas = material.vertexColors === true && !! geometry.attributes.color && geometry.attributes.color.itemSize === 4;\n\t\tconst vertexTangents = !! material.normalMap && !! geometry.attributes.tangent;\n\t\tconst morphTargets = !! geometry.morphAttributes.position;\n\t\tconst morphNormals = !! geometry.morphAttributes.normal;\n\t\tconst morphColors = !! geometry.morphAttributes.color;\n\t\tconst toneMapping = material.toneMapped ? _this.toneMapping : NoToneMapping;\n\n\t\tconst morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;\n\t\tconst morphTargetsCount = ( morphAttribute !== undefined ) ? morphAttribute.length : 0;\n\n\t\tconst materialProperties = properties.get( material );\n\t\tconst lights = currentRenderState.state.lights;\n\n\t\tif ( _clippingEnabled === true ) {\n\n\t\t\tif ( _localClippingEnabled === true || camera !== _currentCamera ) {\n\n\t\t\t\tconst useCache =\n\t\t\t\t\tcamera === _currentCamera &&\n\t\t\t\t\tmaterial.id === _currentMaterialId;\n\n\t\t\t\t// we might want to call this function with some ClippingGroup\n\t\t\t\t// object instead of the material, once it becomes feasible\n\t\t\t\t// (#8465, #8379)\n\t\t\t\tclipping.setState( material, camera, useCache );\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\n\t\tlet needsProgramChange = false;\n\n\t\tif ( material.version === materialProperties.__version ) {\n\n\t\t\tif ( materialProperties.needsLights && ( materialProperties.lightsStateVersion !== lights.state.version ) ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.outputEncoding !== encoding ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( object.isInstancedMesh && materialProperties.instancing === false ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( ! object.isInstancedMesh && materialProperties.instancing === true ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( object.isSkinnedMesh && materialProperties.skinning === false ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( ! object.isSkinnedMesh && materialProperties.skinning === true ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.envMap !== envMap ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( material.fog && materialProperties.fog !== fog ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.numClippingPlanes !== undefined &&\n\t\t\t\t( materialProperties.numClippingPlanes !== clipping.numPlanes ||\n\t\t\t\tmaterialProperties.numIntersection !== clipping.numIntersection ) ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.vertexAlphas !== vertexAlphas ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.vertexTangents !== vertexTangents ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.morphTargets !== morphTargets ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.morphNormals !== morphNormals ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.morphColors !== morphColors ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( materialProperties.toneMapping !== toneMapping ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t} else if ( capabilities.isWebGL2 === true && materialProperties.morphTargetsCount !== morphTargetsCount ) {\n\n\t\t\t\tneedsProgramChange = true;\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tneedsProgramChange = true;\n\t\t\tmaterialProperties.__version = material.version;\n\n\t\t}\n\n\t\t//\n\n\t\tlet program = materialProperties.currentProgram;\n\n\t\tif ( needsProgramChange === true ) {\n\n\t\t\tprogram = getProgram( material, scene, object );\n\n\t\t}\n\n\t\tlet refreshProgram = false;\n\t\tlet refreshMaterial = false;\n\t\tlet refreshLights = false;\n\n\t\tconst p_uniforms = program.getUniforms(),\n\t\t\tm_uniforms = materialProperties.uniforms;\n\n\t\tif ( state.useProgram( program.program ) ) {\n\n\t\t\trefreshProgram = true;\n\t\t\trefreshMaterial = true;\n\t\t\trefreshLights = true;\n\n\t\t}\n\n\t\tif ( material.id !== _currentMaterialId ) {\n\n\t\t\t_currentMaterialId = material.id;\n\n\t\t\trefreshMaterial = true;\n\n\t\t}\n\n\t\tif ( refreshProgram || _currentCamera !== camera ) {\n\n\t\t\tp_uniforms.setValue( _gl, 'projectionMatrix', camera.projectionMatrix );\n\n\t\t\tif ( capabilities.logarithmicDepthBuffer ) {\n\n\t\t\t\tp_uniforms.setValue( _gl, 'logDepthBufFC',\n\t\t\t\t\t2.0 / ( Math.log( camera.far + 1.0 ) / Math.LN2 ) );\n\n\t\t\t}\n\n\t\t\tif ( _currentCamera !== camera ) {\n\n\t\t\t\t_currentCamera = camera;\n\n\t\t\t\t// lighting uniforms depend on the camera so enforce an update\n\t\t\t\t// now, in case this material supports lights - or later, when\n\t\t\t\t// the next material that does gets activated:\n\n\t\t\t\trefreshMaterial = true;\t\t// set to true on material change\n\t\t\t\trefreshLights = true;\t\t// remains set until update done\n\n\t\t\t}\n\n\t\t\t// load material specific uniforms\n\t\t\t// (shader material also gets them for the sake of genericity)\n\n\t\t\tif ( material.isShaderMaterial ||\n\t\t\t\tmaterial.isMeshPhongMaterial ||\n\t\t\t\tmaterial.isMeshToonMaterial ||\n\t\t\t\tmaterial.isMeshStandardMaterial ||\n\t\t\t\tmaterial.envMap ) {\n\n\t\t\t\tconst uCamPos = p_uniforms.map.cameraPosition;\n\n\t\t\t\tif ( uCamPos !== undefined ) {\n\n\t\t\t\t\tuCamPos.setValue( _gl,\n\t\t\t\t\t\t_vector3.setFromMatrixPosition( camera.matrixWorld ) );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( material.isMeshPhongMaterial ||\n\t\t\t\tmaterial.isMeshToonMaterial ||\n\t\t\t\tmaterial.isMeshLambertMaterial ||\n\t\t\t\tmaterial.isMeshBasicMaterial ||\n\t\t\t\tmaterial.isMeshStandardMaterial ||\n\t\t\t\tmaterial.isShaderMaterial ) {\n\n\t\t\t\tp_uniforms.setValue( _gl, 'isOrthographic', camera.isOrthographicCamera === true );\n\n\t\t\t}\n\n\t\t\tif ( material.isMeshPhongMaterial ||\n\t\t\t\tmaterial.isMeshToonMaterial ||\n\t\t\t\tmaterial.isMeshLambertMaterial ||\n\t\t\t\tmaterial.isMeshBasicMaterial ||\n\t\t\t\tmaterial.isMeshStandardMaterial ||\n\t\t\t\tmaterial.isShaderMaterial ||\n\t\t\t\tmaterial.isShadowMaterial ||\n\t\t\t\tobject.isSkinnedMesh ) {\n\n\t\t\t\tp_uniforms.setValue( _gl, 'viewMatrix', camera.matrixWorldInverse );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// skinning and morph target uniforms must be set even if material didn't change\n\t\t// auto-setting of texture unit for bone and morph texture must go before other textures\n\t\t// otherwise textures used for skinning and morphing can take over texture units reserved for other material textures\n\n\t\tif ( object.isSkinnedMesh ) {\n\n\t\t\tp_uniforms.setOptional( _gl, object, 'bindMatrix' );\n\t\t\tp_uniforms.setOptional( _gl, object, 'bindMatrixInverse' );\n\n\t\t\tconst skeleton = object.skeleton;\n\n\t\t\tif ( skeleton ) {\n\n\t\t\t\tif ( capabilities.floatVertexTextures ) {\n\n\t\t\t\t\tif ( skeleton.boneTexture === null ) skeleton.computeBoneTexture();\n\n\t\t\t\t\tp_uniforms.setValue( _gl, 'boneTexture', skeleton.boneTexture, textures );\n\t\t\t\t\tp_uniforms.setValue( _gl, 'boneTextureSize', skeleton.boneTextureSize );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tp_uniforms.setOptional( _gl, skeleton, 'boneMatrices' );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst morphAttributes = geometry.morphAttributes;\n\n\t\tif ( morphAttributes.position !== undefined || morphAttributes.normal !== undefined || ( morphAttributes.color !== undefined && capabilities.isWebGL2 === true ) ) {\n\n\t\t\tmorphtargets.update( object, geometry, material, program );\n\n\t\t}\n\n\n\t\tif ( refreshMaterial || materialProperties.receiveShadow !== object.receiveShadow ) {\n\n\t\t\tmaterialProperties.receiveShadow = object.receiveShadow;\n\t\t\tp_uniforms.setValue( _gl, 'receiveShadow', object.receiveShadow );\n\n\t\t}\n\n\t\tif ( refreshMaterial ) {\n\n\t\t\tp_uniforms.setValue( _gl, 'toneMappingExposure', _this.toneMappingExposure );\n\n\t\t\tif ( materialProperties.needsLights ) {\n\n\t\t\t\t// the current material requires lighting info\n\n\t\t\t\t// note: all lighting uniforms are always set correctly\n\t\t\t\t// they simply reference the renderer's state for their\n\t\t\t\t// values\n\t\t\t\t//\n\t\t\t\t// use the current material's .needsUpdate flags to set\n\t\t\t\t// the GL state when required\n\n\t\t\t\tmarkUniformsLightsNeedsUpdate( m_uniforms, refreshLights );\n\n\t\t\t}\n\n\t\t\t// refresh uniforms common to several materials\n\n\t\t\tif ( fog && material.fog ) {\n\n\t\t\t\tmaterials.refreshFogUniforms( m_uniforms, fog );\n\n\t\t\t}\n\n\t\t\tmaterials.refreshMaterialUniforms( m_uniforms, material, _pixelRatio, _height, _transmissionRenderTarget );\n\n\t\t\tWebGLUniforms.upload( _gl, materialProperties.uniformsList, m_uniforms, textures );\n\n\t\t}\n\n\t\tif ( material.isShaderMaterial && material.uniformsNeedUpdate === true ) {\n\n\t\t\tWebGLUniforms.upload( _gl, materialProperties.uniformsList, m_uniforms, textures );\n\t\t\tmaterial.uniformsNeedUpdate = false;\n\n\t\t}\n\n\t\tif ( material.isSpriteMaterial ) {\n\n\t\t\tp_uniforms.setValue( _gl, 'center', object.center );\n\n\t\t}\n\n\t\t// common matrices\n\n\t\tp_uniforms.setValue( _gl, 'modelViewMatrix', object.modelViewMatrix );\n\t\tp_uniforms.setValue( _gl, 'normalMatrix', object.normalMatrix );\n\t\tp_uniforms.setValue( _gl, 'modelMatrix', object.matrixWorld );\n\n\t\treturn program;\n\n\t}\n\n\t// If uniforms are marked as clean, they don't need to be loaded to the GPU.\n\n\tfunction markUniformsLightsNeedsUpdate( uniforms, value ) {\n\n\t\tuniforms.ambientLightColor.needsUpdate = value;\n\t\tuniforms.lightProbe.needsUpdate = value;\n\n\t\tuniforms.directionalLights.needsUpdate = value;\n\t\tuniforms.directionalLightShadows.needsUpdate = value;\n\t\tuniforms.pointLights.needsUpdate = value;\n\t\tuniforms.pointLightShadows.needsUpdate = value;\n\t\tuniforms.spotLights.needsUpdate = value;\n\t\tuniforms.spotLightShadows.needsUpdate = value;\n\t\tuniforms.rectAreaLights.needsUpdate = value;\n\t\tuniforms.hemisphereLights.needsUpdate = value;\n\n\t}\n\n\tfunction materialNeedsLights( material ) {\n\n\t\treturn material.isMeshLambertMaterial || material.isMeshToonMaterial || material.isMeshPhongMaterial ||\n\t\t\tmaterial.isMeshStandardMaterial || material.isShadowMaterial ||\n\t\t\t( material.isShaderMaterial && material.lights === true );\n\n\t}\n\n\tthis.getActiveCubeFace = function () {\n\n\t\treturn _currentActiveCubeFace;\n\n\t};\n\n\tthis.getActiveMipmapLevel = function () {\n\n\t\treturn _currentActiveMipmapLevel;\n\n\t};\n\n\tthis.getRenderTarget = function () {\n\n\t\treturn _currentRenderTarget;\n\n\t};\n\n\tthis.setRenderTargetTextures = function ( renderTarget, colorTexture, depthTexture ) {\n\n\t\tproperties.get( renderTarget.texture ).__webglTexture = colorTexture;\n\t\tproperties.get( renderTarget.depthTexture ).__webglTexture = depthTexture;\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\t\trenderTargetProperties.__hasExternalTextures = true;\n\n\t\tif ( renderTargetProperties.__hasExternalTextures ) {\n\n\t\t\trenderTargetProperties.__autoAllocateDepthBuffer = depthTexture === undefined;\n\n\t\t\tif ( ! renderTargetProperties.__autoAllocateDepthBuffer ) {\n\n\t\t\t\t// The multisample_render_to_texture extension doesn't work properly if there\n\t\t\t\t// are midframe flushes and an external depth buffer. Disable use of the extension.\n\t\t\t\tif ( extensions.has( 'WEBGL_multisampled_render_to_texture' ) === true ) {\n\n\t\t\t\t\tconsole.warn( 'THREE.WebGLRenderer: Render-to-texture extension was disabled because an external texture was provided' );\n\t\t\t\t\trenderTargetProperties.__useRenderToTexture = false;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t};\n\n\tthis.setRenderTargetFramebuffer = function ( renderTarget, defaultFramebuffer ) {\n\n\t\tconst renderTargetProperties = properties.get( renderTarget );\n\t\trenderTargetProperties.__webglFramebuffer = defaultFramebuffer;\n\t\trenderTargetProperties.__useDefaultFramebuffer = defaultFramebuffer === undefined;\n\n\t};\n\n\tthis.setRenderTarget = function ( renderTarget, activeCubeFace = 0, activeMipmapLevel = 0 ) {\n\n\t\t_currentRenderTarget = renderTarget;\n\t\t_currentActiveCubeFace = activeCubeFace;\n\t\t_currentActiveMipmapLevel = activeMipmapLevel;\n\n\t\tlet useDefaultFramebuffer = true;\n\n\t\tif ( renderTarget ) {\n\n\t\t\tconst renderTargetProperties = properties.get( renderTarget );\n\n\t\t\tif ( renderTargetProperties.__useDefaultFramebuffer !== undefined ) {\n\n\t\t\t\t// We need to make sure to rebind the framebuffer.\n\t\t\t\tstate.bindFramebuffer( 36160, null );\n\t\t\t\tuseDefaultFramebuffer = false;\n\n\t\t\t} else if ( renderTargetProperties.__webglFramebuffer === undefined ) {\n\n\t\t\t\ttextures.setupRenderTarget( renderTarget );\n\n\t\t\t} else if ( renderTargetProperties.__hasExternalTextures ) {\n\n\t\t\t\t// Color and depth texture must be rebound in order for the swapchain to update.\n\t\t\t\ttextures.rebindTextures( renderTarget, properties.get( renderTarget.texture ).__webglTexture, properties.get( renderTarget.depthTexture ).__webglTexture );\n\n\t\t\t}\n\n\t\t}\n\n\t\tlet framebuffer = null;\n\t\tlet isCube = false;\n\t\tlet isRenderTarget3D = false;\n\n\t\tif ( renderTarget ) {\n\n\t\t\tconst texture = renderTarget.texture;\n\n\t\t\tif ( texture.isData3DTexture || texture.isDataArrayTexture ) {\n\n\t\t\t\tisRenderTarget3D = true;\n\n\t\t\t}\n\n\t\t\tconst __webglFramebuffer = properties.get( renderTarget ).__webglFramebuffer;\n\n\t\t\tif ( renderTarget.isWebGLCubeRenderTarget ) {\n\n\t\t\t\tframebuffer = __webglFramebuffer[ activeCubeFace ];\n\t\t\t\tisCube = true;\n\n\t\t\t} else if ( ( capabilities.isWebGL2 && renderTarget.samples > 0 ) && textures.useMultisampledRTT( renderTarget ) === false ) {\n\n\t\t\t\tframebuffer = properties.get( renderTarget ).__webglMultisampledFramebuffer;\n\n\t\t\t} else {\n\n\t\t\t\tframebuffer = __webglFramebuffer;\n\n\t\t\t}\n\n\t\t\t_currentViewport.copy( renderTarget.viewport );\n\t\t\t_currentScissor.copy( renderTarget.scissor );\n\t\t\t_currentScissorTest = renderTarget.scissorTest;\n\n\t\t} else {\n\n\t\t\t_currentViewport.copy( _viewport ).multiplyScalar( _pixelRatio ).floor();\n\t\t\t_currentScissor.copy( _scissor ).multiplyScalar( _pixelRatio ).floor();\n\t\t\t_currentScissorTest = _scissorTest;\n\n\t\t}\n\n\t\tconst framebufferBound = state.bindFramebuffer( 36160, framebuffer );\n\n\t\tif ( framebufferBound && capabilities.drawBuffers && useDefaultFramebuffer ) {\n\n\t\t\tstate.drawBuffers( renderTarget, framebuffer );\n\n\t\t}\n\n\t\tstate.viewport( _currentViewport );\n\t\tstate.scissor( _currentScissor );\n\t\tstate.setScissorTest( _currentScissorTest );\n\n\t\tif ( isCube ) {\n\n\t\t\tconst textureProperties = properties.get( renderTarget.texture );\n\t\t\t_gl.framebufferTexture2D( 36160, 36064, 34069 + activeCubeFace, textureProperties.__webglTexture, activeMipmapLevel );\n\n\t\t} else if ( isRenderTarget3D ) {\n\n\t\t\tconst textureProperties = properties.get( renderTarget.texture );\n\t\t\tconst layer = activeCubeFace || 0;\n\t\t\t_gl.framebufferTextureLayer( 36160, 36064, textureProperties.__webglTexture, activeMipmapLevel || 0, layer );\n\n\t\t}\n\n\t\t_currentMaterialId = - 1; // reset current material to ensure correct uniform bindings\n\n\t};\n\n\tthis.readRenderTargetPixels = function ( renderTarget, x, y, width, height, buffer, activeCubeFaceIndex ) {\n\n\t\tif ( ! ( renderTarget && renderTarget.isWebGLRenderTarget ) ) {\n\n\t\t\tconsole.error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tlet framebuffer = properties.get( renderTarget ).__webglFramebuffer;\n\n\t\tif ( renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined ) {\n\n\t\t\tframebuffer = framebuffer[ activeCubeFaceIndex ];\n\n\t\t}\n\n\t\tif ( framebuffer ) {\n\n\t\t\tstate.bindFramebuffer( 36160, framebuffer );\n\n\t\t\ttry {\n\n\t\t\t\tconst texture = renderTarget.texture;\n\t\t\t\tconst textureFormat = texture.format;\n\t\t\t\tconst textureType = texture.type;\n\n\t\t\t\tif ( textureFormat !== RGBAFormat && utils.convert( textureFormat ) !== _gl.getParameter( 35739 ) ) {\n\n\t\t\t\t\tconsole.error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in RGBA or implementation defined format.' );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t\tconst halfFloatSupportedByExt = ( textureType === HalfFloatType ) && ( extensions.has( 'EXT_color_buffer_half_float' ) || ( capabilities.isWebGL2 && extensions.has( 'EXT_color_buffer_float' ) ) );\n\n\t\t\t\tif ( textureType !== UnsignedByteType && utils.convert( textureType ) !== _gl.getParameter( 35738 ) && // Edge and Chrome Mac < 52 (#9513)\n\t\t\t\t\t! ( textureType === FloatType && ( capabilities.isWebGL2 || extensions.has( 'OES_texture_float' ) || extensions.has( 'WEBGL_color_buffer_float' ) ) ) && // Chrome Mac >= 52 and Firefox\n\t\t\t\t\t! halfFloatSupportedByExt ) {\n\n\t\t\t\t\tconsole.error( 'THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in UnsignedByteType or implementation defined type.' );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t\tif ( _gl.checkFramebufferStatus( 36160 ) === 36053 ) {\n\n\t\t\t\t\t// the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)\n\n\t\t\t\t\tif ( ( x >= 0 && x <= ( renderTarget.width - width ) ) && ( y >= 0 && y <= ( renderTarget.height - height ) ) ) {\n\n\t\t\t\t\t\t_gl.readPixels( x, y, width, height, utils.convert( textureFormat ), utils.convert( textureType ), buffer );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( 'THREE.WebGLRenderer.readRenderTargetPixels: readPixels from renderTarget failed. Framebuffer not complete.' );\n\n\t\t\t\t}\n\n\t\t\t} finally {\n\n\t\t\t\t// restore framebuffer of current render target if necessary\n\n\t\t\t\tconst framebuffer = ( _currentRenderTarget !== null ) ? properties.get( _currentRenderTarget ).__webglFramebuffer : null;\n\t\t\t\tstate.bindFramebuffer( 36160, framebuffer );\n\n\t\t\t}\n\n\t\t}\n\n\t};\n\n\tthis.copyFramebufferToTexture = function ( position, texture, level = 0 ) {\n\n\t\tif ( texture.isFramebufferTexture !== true ) {\n\n\t\t\tconsole.error( 'THREE.WebGLRenderer: copyFramebufferToTexture() can only be used with FramebufferTexture.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tconst levelScale = Math.pow( 2, - level );\n\t\tconst width = Math.floor( texture.image.width * levelScale );\n\t\tconst height = Math.floor( texture.image.height * levelScale );\n\n\t\ttextures.setTexture2D( texture, 0 );\n\n\t\t_gl.copyTexSubImage2D( 3553, level, 0, 0, position.x, position.y, width, height );\n\n\t\tstate.unbindTexture();\n\n\t};\n\n\tthis.copyTextureToTexture = function ( position, srcTexture, dstTexture, level = 0 ) {\n\n\t\tconst width = srcTexture.image.width;\n\t\tconst height = srcTexture.image.height;\n\t\tconst glFormat = utils.convert( dstTexture.format );\n\t\tconst glType = utils.convert( dstTexture.type );\n\n\t\ttextures.setTexture2D( dstTexture, 0 );\n\n\t\t// As another texture upload may have changed pixelStorei\n\t\t// parameters, make sure they are correct for the dstTexture\n\t\t_gl.pixelStorei( 37440, dstTexture.flipY );\n\t\t_gl.pixelStorei( 37441, dstTexture.premultiplyAlpha );\n\t\t_gl.pixelStorei( 3317, dstTexture.unpackAlignment );\n\n\t\tif ( srcTexture.isDataTexture ) {\n\n\t\t\t_gl.texSubImage2D( 3553, level, position.x, position.y, width, height, glFormat, glType, srcTexture.image.data );\n\n\t\t} else {\n\n\t\t\tif ( srcTexture.isCompressedTexture ) {\n\n\t\t\t\t_gl.compressedTexSubImage2D( 3553, level, position.x, position.y, srcTexture.mipmaps[ 0 ].width, srcTexture.mipmaps[ 0 ].height, glFormat, srcTexture.mipmaps[ 0 ].data );\n\n\t\t\t} else {\n\n\t\t\t\t_gl.texSubImage2D( 3553, level, position.x, position.y, glFormat, glType, srcTexture.image );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Generate mipmaps only when copying level 0\n\t\tif ( level === 0 && dstTexture.generateMipmaps ) _gl.generateMipmap( 3553 );\n\n\t\tstate.unbindTexture();\n\n\t};\n\n\tthis.copyTextureToTexture3D = function ( sourceBox, position, srcTexture, dstTexture, level = 0 ) {\n\n\t\tif ( _this.isWebGL1Renderer ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer.copyTextureToTexture3D: can only be used with WebGL2.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tconst width = sourceBox.max.x - sourceBox.min.x + 1;\n\t\tconst height = sourceBox.max.y - sourceBox.min.y + 1;\n\t\tconst depth = sourceBox.max.z - sourceBox.min.z + 1;\n\t\tconst glFormat = utils.convert( dstTexture.format );\n\t\tconst glType = utils.convert( dstTexture.type );\n\t\tlet glTarget;\n\n\t\tif ( dstTexture.isData3DTexture ) {\n\n\t\t\ttextures.setTexture3D( dstTexture, 0 );\n\t\t\tglTarget = 32879;\n\n\t\t} else if ( dstTexture.isDataArrayTexture ) {\n\n\t\t\ttextures.setTexture2DArray( dstTexture, 0 );\n\t\t\tglTarget = 35866;\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer.copyTextureToTexture3D: only supports THREE.DataTexture3D and THREE.DataTexture2DArray.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\t_gl.pixelStorei( 37440, dstTexture.flipY );\n\t\t_gl.pixelStorei( 37441, dstTexture.premultiplyAlpha );\n\t\t_gl.pixelStorei( 3317, dstTexture.unpackAlignment );\n\n\t\tconst unpackRowLen = _gl.getParameter( 3314 );\n\t\tconst unpackImageHeight = _gl.getParameter( 32878 );\n\t\tconst unpackSkipPixels = _gl.getParameter( 3316 );\n\t\tconst unpackSkipRows = _gl.getParameter( 3315 );\n\t\tconst unpackSkipImages = _gl.getParameter( 32877 );\n\n\t\tconst image = srcTexture.isCompressedTexture ? srcTexture.mipmaps[ 0 ] : srcTexture.image;\n\n\t\t_gl.pixelStorei( 3314, image.width );\n\t\t_gl.pixelStorei( 32878, image.height );\n\t\t_gl.pixelStorei( 3316, sourceBox.min.x );\n\t\t_gl.pixelStorei( 3315, sourceBox.min.y );\n\t\t_gl.pixelStorei( 32877, sourceBox.min.z );\n\n\t\tif ( srcTexture.isDataTexture || srcTexture.isData3DTexture ) {\n\n\t\t\t_gl.texSubImage3D( glTarget, level, position.x, position.y, position.z, width, height, depth, glFormat, glType, image.data );\n\n\t\t} else {\n\n\t\t\tif ( srcTexture.isCompressedTexture ) {\n\n\t\t\t\tconsole.warn( 'THREE.WebGLRenderer.copyTextureToTexture3D: untested support for compressed srcTexture.' );\n\t\t\t\t_gl.compressedTexSubImage3D( glTarget, level, position.x, position.y, position.z, width, height, depth, glFormat, image.data );\n\n\t\t\t} else {\n\n\t\t\t\t_gl.texSubImage3D( glTarget, level, position.x, position.y, position.z, width, height, depth, glFormat, glType, image );\n\n\t\t\t}\n\n\t\t}\n\n\t\t_gl.pixelStorei( 3314, unpackRowLen );\n\t\t_gl.pixelStorei( 32878, unpackImageHeight );\n\t\t_gl.pixelStorei( 3316, unpackSkipPixels );\n\t\t_gl.pixelStorei( 3315, unpackSkipRows );\n\t\t_gl.pixelStorei( 32877, unpackSkipImages );\n\n\t\t// Generate mipmaps only when copying level 0\n\t\tif ( level === 0 && dstTexture.generateMipmaps ) _gl.generateMipmap( glTarget );\n\n\t\tstate.unbindTexture();\n\n\t};\n\n\tthis.initTexture = function ( texture ) {\n\n\t\ttextures.setTexture2D( texture, 0 );\n\n\t\tstate.unbindTexture();\n\n\t};\n\n\tthis.resetState = function () {\n\n\t\t_currentActiveCubeFace = 0;\n\t\t_currentActiveMipmapLevel = 0;\n\t\t_currentRenderTarget = null;\n\n\t\tstate.reset();\n\t\tbindingStates.reset();\n\n\t};\n\n\tif ( typeof __THREE_DEVTOOLS__ !== 'undefined' ) {\n\n\t\t__THREE_DEVTOOLS__.dispatchEvent( new CustomEvent( 'observe', { detail: this } ) );\n\n\t}\n\n}\n\nWebGLRenderer.prototype.isWebGLRenderer = true;\n\nclass WebGL1Renderer extends WebGLRenderer {}\n\nWebGL1Renderer.prototype.isWebGL1Renderer = true;\n\nclass FogExp2 {\n\n\tconstructor( color, density = 0.00025 ) {\n\n\t\tthis.name = '';\n\n\t\tthis.color = new Color( color );\n\t\tthis.density = density;\n\n\t}\n\n\tclone() {\n\n\t\treturn new FogExp2( this.color, this.density );\n\n\t}\n\n\ttoJSON( /* meta */ ) {\n\n\t\treturn {\n\t\t\ttype: 'FogExp2',\n\t\t\tcolor: this.color.getHex(),\n\t\t\tdensity: this.density\n\t\t};\n\n\t}\n\n}\n\nFogExp2.prototype.isFogExp2 = true;\n\nclass Fog {\n\n\tconstructor( color, near = 1, far = 1000 ) {\n\n\t\tthis.name = '';\n\n\t\tthis.color = new Color( color );\n\n\t\tthis.near = near;\n\t\tthis.far = far;\n\n\t}\n\n\tclone() {\n\n\t\treturn new Fog( this.color, this.near, this.far );\n\n\t}\n\n\ttoJSON( /* meta */ ) {\n\n\t\treturn {\n\t\t\ttype: 'Fog',\n\t\t\tcolor: this.color.getHex(),\n\t\t\tnear: this.near,\n\t\t\tfar: this.far\n\t\t};\n\n\t}\n\n}\n\nFog.prototype.isFog = true;\n\nclass Scene extends Object3D {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'Scene';\n\n\t\tthis.background = null;\n\t\tthis.environment = null;\n\t\tthis.fog = null;\n\n\t\tthis.overrideMaterial = null;\n\n\t\tthis.autoUpdate = true; // checked by the renderer\n\n\t\tif ( typeof __THREE_DEVTOOLS__ !== 'undefined' ) {\n\n\t\t\t__THREE_DEVTOOLS__.dispatchEvent( new CustomEvent( 'observe', { detail: this } ) );\n\n\t\t}\n\n\t}\n\n\tcopy( source, recursive ) {\n\n\t\tsuper.copy( source, recursive );\n\n\t\tif ( source.background !== null ) this.background = source.background.clone();\n\t\tif ( source.environment !== null ) this.environment = source.environment.clone();\n\t\tif ( source.fog !== null ) this.fog = source.fog.clone();\n\n\t\tif ( source.overrideMaterial !== null ) this.overrideMaterial = source.overrideMaterial.clone();\n\n\t\tthis.autoUpdate = source.autoUpdate;\n\t\tthis.matrixAutoUpdate = source.matrixAutoUpdate;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tif ( this.fog !== null ) data.object.fog = this.fog.toJSON();\n\n\t\treturn data;\n\n\t}\n\n}\n\nScene.prototype.isScene = true;\n\nclass InterleavedBuffer {\n\n\tconstructor( array, stride ) {\n\n\t\tthis.array = array;\n\t\tthis.stride = stride;\n\t\tthis.count = array !== undefined ? array.length / stride : 0;\n\n\t\tthis.usage = StaticDrawUsage;\n\t\tthis.updateRange = { offset: 0, count: - 1 };\n\n\t\tthis.version = 0;\n\n\t\tthis.uuid = generateUUID();\n\n\t}\n\n\tonUploadCallback() {}\n\n\tset needsUpdate( value ) {\n\n\t\tif ( value === true ) this.version ++;\n\n\t}\n\n\tsetUsage( value ) {\n\n\t\tthis.usage = value;\n\n\t\treturn this;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.array = new source.array.constructor( source.array );\n\t\tthis.count = source.count;\n\t\tthis.stride = source.stride;\n\t\tthis.usage = source.usage;\n\n\t\treturn this;\n\n\t}\n\n\tcopyAt( index1, attribute, index2 ) {\n\n\t\tindex1 *= this.stride;\n\t\tindex2 *= attribute.stride;\n\n\t\tfor ( let i = 0, l = this.stride; i < l; i ++ ) {\n\n\t\t\tthis.array[ index1 + i ] = attribute.array[ index2 + i ];\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tset( value, offset = 0 ) {\n\n\t\tthis.array.set( value, offset );\n\n\t\treturn this;\n\n\t}\n\n\tclone( data ) {\n\n\t\tif ( data.arrayBuffers === undefined ) {\n\n\t\t\tdata.arrayBuffers = {};\n\n\t\t}\n\n\t\tif ( this.array.buffer._uuid === undefined ) {\n\n\t\t\tthis.array.buffer._uuid = generateUUID();\n\n\t\t}\n\n\t\tif ( data.arrayBuffers[ this.array.buffer._uuid ] === undefined ) {\n\n\t\t\tdata.arrayBuffers[ this.array.buffer._uuid ] = this.array.slice( 0 ).buffer;\n\n\t\t}\n\n\t\tconst array = new this.array.constructor( data.arrayBuffers[ this.array.buffer._uuid ] );\n\n\t\tconst ib = new this.constructor( array, this.stride );\n\t\tib.setUsage( this.usage );\n\n\t\treturn ib;\n\n\t}\n\n\tonUpload( callback ) {\n\n\t\tthis.onUploadCallback = callback;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( data ) {\n\n\t\tif ( data.arrayBuffers === undefined ) {\n\n\t\t\tdata.arrayBuffers = {};\n\n\t\t}\n\n\t\t// generate UUID for array buffer if necessary\n\n\t\tif ( this.array.buffer._uuid === undefined ) {\n\n\t\t\tthis.array.buffer._uuid = generateUUID();\n\n\t\t}\n\n\t\tif ( data.arrayBuffers[ this.array.buffer._uuid ] === undefined ) {\n\n\t\t\tdata.arrayBuffers[ this.array.buffer._uuid ] = Array.prototype.slice.call( new Uint32Array( this.array.buffer ) );\n\n\t\t}\n\n\t\t//\n\n\t\treturn {\n\t\t\tuuid: this.uuid,\n\t\t\tbuffer: this.array.buffer._uuid,\n\t\t\ttype: this.array.constructor.name,\n\t\t\tstride: this.stride\n\t\t};\n\n\t}\n\n}\n\nInterleavedBuffer.prototype.isInterleavedBuffer = true;\n\nconst _vector$6 = /*@__PURE__*/ new Vector3();\n\nclass InterleavedBufferAttribute {\n\n\tconstructor( interleavedBuffer, itemSize, offset, normalized = false ) {\n\n\t\tthis.name = '';\n\n\t\tthis.data = interleavedBuffer;\n\t\tthis.itemSize = itemSize;\n\t\tthis.offset = offset;\n\n\t\tthis.normalized = normalized === true;\n\n\t}\n\n\tget count() {\n\n\t\treturn this.data.count;\n\n\t}\n\n\tget array() {\n\n\t\treturn this.data.array;\n\n\t}\n\n\tset needsUpdate( value ) {\n\n\t\tthis.data.needsUpdate = value;\n\n\t}\n\n\tapplyMatrix4( m ) {\n\n\t\tfor ( let i = 0, l = this.data.count; i < l; i ++ ) {\n\n\t\t\t_vector$6.x = this.getX( i );\n\t\t\t_vector$6.y = this.getY( i );\n\t\t\t_vector$6.z = this.getZ( i );\n\n\t\t\t_vector$6.applyMatrix4( m );\n\n\t\t\tthis.setXYZ( i, _vector$6.x, _vector$6.y, _vector$6.z );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tapplyNormalMatrix( m ) {\n\n\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t_vector$6.x = this.getX( i );\n\t\t\t_vector$6.y = this.getY( i );\n\t\t\t_vector$6.z = this.getZ( i );\n\n\t\t\t_vector$6.applyNormalMatrix( m );\n\n\t\t\tthis.setXYZ( i, _vector$6.x, _vector$6.y, _vector$6.z );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttransformDirection( m ) {\n\n\t\tfor ( let i = 0, l = this.count; i < l; i ++ ) {\n\n\t\t\t_vector$6.x = this.getX( i );\n\t\t\t_vector$6.y = this.getY( i );\n\t\t\t_vector$6.z = this.getZ( i );\n\n\t\t\t_vector$6.transformDirection( m );\n\n\t\t\tthis.setXYZ( i, _vector$6.x, _vector$6.y, _vector$6.z );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetX( index, x ) {\n\n\t\tthis.data.array[ index * this.data.stride + this.offset ] = x;\n\n\t\treturn this;\n\n\t}\n\n\tsetY( index, y ) {\n\n\t\tthis.data.array[ index * this.data.stride + this.offset + 1 ] = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetZ( index, z ) {\n\n\t\tthis.data.array[ index * this.data.stride + this.offset + 2 ] = z;\n\n\t\treturn this;\n\n\t}\n\n\tsetW( index, w ) {\n\n\t\tthis.data.array[ index * this.data.stride + this.offset + 3 ] = w;\n\n\t\treturn this;\n\n\t}\n\n\tgetX( index ) {\n\n\t\treturn this.data.array[ index * this.data.stride + this.offset ];\n\n\t}\n\n\tgetY( index ) {\n\n\t\treturn this.data.array[ index * this.data.stride + this.offset + 1 ];\n\n\t}\n\n\tgetZ( index ) {\n\n\t\treturn this.data.array[ index * this.data.stride + this.offset + 2 ];\n\n\t}\n\n\tgetW( index ) {\n\n\t\treturn this.data.array[ index * this.data.stride + this.offset + 3 ];\n\n\t}\n\n\tsetXY( index, x, y ) {\n\n\t\tindex = index * this.data.stride + this.offset;\n\n\t\tthis.data.array[ index + 0 ] = x;\n\t\tthis.data.array[ index + 1 ] = y;\n\n\t\treturn this;\n\n\t}\n\n\tsetXYZ( index, x, y, z ) {\n\n\t\tindex = index * this.data.stride + this.offset;\n\n\t\tthis.data.array[ index + 0 ] = x;\n\t\tthis.data.array[ index + 1 ] = y;\n\t\tthis.data.array[ index + 2 ] = z;\n\n\t\treturn this;\n\n\t}\n\n\tsetXYZW( index, x, y, z, w ) {\n\n\t\tindex = index * this.data.stride + this.offset;\n\n\t\tthis.data.array[ index + 0 ] = x;\n\t\tthis.data.array[ index + 1 ] = y;\n\t\tthis.data.array[ index + 2 ] = z;\n\t\tthis.data.array[ index + 3 ] = w;\n\n\t\treturn this;\n\n\t}\n\n\tclone( data ) {\n\n\t\tif ( data === undefined ) {\n\n\t\t\tconsole.log( 'THREE.InterleavedBufferAttribute.clone(): Cloning an interlaved buffer attribute will deinterleave buffer data.' );\n\n\t\t\tconst array = [];\n\n\t\t\tfor ( let i = 0; i < this.count; i ++ ) {\n\n\t\t\t\tconst index = i * this.data.stride + this.offset;\n\n\t\t\t\tfor ( let j = 0; j < this.itemSize; j ++ ) {\n\n\t\t\t\t\tarray.push( this.data.array[ index + j ] );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn new BufferAttribute( new this.array.constructor( array ), this.itemSize, this.normalized );\n\n\t\t} else {\n\n\t\t\tif ( data.interleavedBuffers === undefined ) {\n\n\t\t\t\tdata.interleavedBuffers = {};\n\n\t\t\t}\n\n\t\t\tif ( data.interleavedBuffers[ this.data.uuid ] === undefined ) {\n\n\t\t\t\tdata.interleavedBuffers[ this.data.uuid ] = this.data.clone( data );\n\n\t\t\t}\n\n\t\t\treturn new InterleavedBufferAttribute( data.interleavedBuffers[ this.data.uuid ], this.itemSize, this.offset, this.normalized );\n\n\t\t}\n\n\t}\n\n\ttoJSON( data ) {\n\n\t\tif ( data === undefined ) {\n\n\t\t\tconsole.log( 'THREE.InterleavedBufferAttribute.toJSON(): Serializing an interlaved buffer attribute will deinterleave buffer data.' );\n\n\t\t\tconst array = [];\n\n\t\t\tfor ( let i = 0; i < this.count; i ++ ) {\n\n\t\t\t\tconst index = i * this.data.stride + this.offset;\n\n\t\t\t\tfor ( let j = 0; j < this.itemSize; j ++ ) {\n\n\t\t\t\t\tarray.push( this.data.array[ index + j ] );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// deinterleave data and save it as an ordinary buffer attribute for now\n\n\t\t\treturn {\n\t\t\t\titemSize: this.itemSize,\n\t\t\t\ttype: this.array.constructor.name,\n\t\t\t\tarray: array,\n\t\t\t\tnormalized: this.normalized\n\t\t\t};\n\n\t\t} else {\n\n\t\t\t// save as true interlaved attribtue\n\n\t\t\tif ( data.interleavedBuffers === undefined ) {\n\n\t\t\t\tdata.interleavedBuffers = {};\n\n\t\t\t}\n\n\t\t\tif ( data.interleavedBuffers[ this.data.uuid ] === undefined ) {\n\n\t\t\t\tdata.interleavedBuffers[ this.data.uuid ] = this.data.toJSON( data );\n\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\tisInterleavedBufferAttribute: true,\n\t\t\t\titemSize: this.itemSize,\n\t\t\t\tdata: this.data.uuid,\n\t\t\t\toffset: this.offset,\n\t\t\t\tnormalized: this.normalized\n\t\t\t};\n\n\t\t}\n\n\t}\n\n}\n\nInterleavedBufferAttribute.prototype.isInterleavedBufferAttribute = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  map: new THREE.Texture( <Image> ),\n *  alphaMap: new THREE.Texture( <Image> ),\n *  rotation: <float>,\n *  sizeAttenuation: <bool>\n * }\n */\n\nclass SpriteMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'SpriteMaterial';\n\n\t\tthis.color = new Color( 0xffffff );\n\n\t\tthis.map = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.rotation = 0;\n\n\t\tthis.sizeAttenuation = true;\n\n\t\tthis.transparent = true;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.map = source.map;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.rotation = source.rotation;\n\n\t\tthis.sizeAttenuation = source.sizeAttenuation;\n\n\t\treturn this;\n\n\t}\n\n}\n\nSpriteMaterial.prototype.isSpriteMaterial = true;\n\nlet _geometry;\n\nconst _intersectPoint = /*@__PURE__*/ new Vector3();\nconst _worldScale = /*@__PURE__*/ new Vector3();\nconst _mvPosition = /*@__PURE__*/ new Vector3();\n\nconst _alignedPosition = /*@__PURE__*/ new Vector2();\nconst _rotatedPosition = /*@__PURE__*/ new Vector2();\nconst _viewWorldMatrix = /*@__PURE__*/ new Matrix4();\n\nconst _vA = /*@__PURE__*/ new Vector3();\nconst _vB = /*@__PURE__*/ new Vector3();\nconst _vC = /*@__PURE__*/ new Vector3();\n\nconst _uvA = /*@__PURE__*/ new Vector2();\nconst _uvB = /*@__PURE__*/ new Vector2();\nconst _uvC = /*@__PURE__*/ new Vector2();\n\nclass Sprite extends Object3D {\n\n\tconstructor( material ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'Sprite';\n\n\t\tif ( _geometry === undefined ) {\n\n\t\t\t_geometry = new BufferGeometry();\n\n\t\t\tconst float32Array = new Float32Array( [\n\t\t\t\t- 0.5, - 0.5, 0, 0, 0,\n\t\t\t\t0.5, - 0.5, 0, 1, 0,\n\t\t\t\t0.5, 0.5, 0, 1, 1,\n\t\t\t\t- 0.5, 0.5, 0, 0, 1\n\t\t\t] );\n\n\t\t\tconst interleavedBuffer = new InterleavedBuffer( float32Array, 5 );\n\n\t\t\t_geometry.setIndex( [ 0, 1, 2,\t0, 2, 3 ] );\n\t\t\t_geometry.setAttribute( 'position', new InterleavedBufferAttribute( interleavedBuffer, 3, 0, false ) );\n\t\t\t_geometry.setAttribute( 'uv', new InterleavedBufferAttribute( interleavedBuffer, 2, 3, false ) );\n\n\t\t}\n\n\t\tthis.geometry = _geometry;\n\t\tthis.material = ( material !== undefined ) ? material : new SpriteMaterial();\n\n\t\tthis.center = new Vector2( 0.5, 0.5 );\n\n\t}\n\n\traycast( raycaster, intersects ) {\n\n\t\tif ( raycaster.camera === null ) {\n\n\t\t\tconsole.error( 'THREE.Sprite: \"Raycaster.camera\" needs to be set in order to raycast against sprites.' );\n\n\t\t}\n\n\t\t_worldScale.setFromMatrixScale( this.matrixWorld );\n\n\t\t_viewWorldMatrix.copy( raycaster.camera.matrixWorld );\n\t\tthis.modelViewMatrix.multiplyMatrices( raycaster.camera.matrixWorldInverse, this.matrixWorld );\n\n\t\t_mvPosition.setFromMatrixPosition( this.modelViewMatrix );\n\n\t\tif ( raycaster.camera.isPerspectiveCamera && this.material.sizeAttenuation === false ) {\n\n\t\t\t_worldScale.multiplyScalar( - _mvPosition.z );\n\n\t\t}\n\n\t\tconst rotation = this.material.rotation;\n\t\tlet sin, cos;\n\n\t\tif ( rotation !== 0 ) {\n\n\t\t\tcos = Math.cos( rotation );\n\t\t\tsin = Math.sin( rotation );\n\n\t\t}\n\n\t\tconst center = this.center;\n\n\t\ttransformVertex( _vA.set( - 0.5, - 0.5, 0 ), _mvPosition, center, _worldScale, sin, cos );\n\t\ttransformVertex( _vB.set( 0.5, - 0.5, 0 ), _mvPosition, center, _worldScale, sin, cos );\n\t\ttransformVertex( _vC.set( 0.5, 0.5, 0 ), _mvPosition, center, _worldScale, sin, cos );\n\n\t\t_uvA.set( 0, 0 );\n\t\t_uvB.set( 1, 0 );\n\t\t_uvC.set( 1, 1 );\n\n\t\t// check first triangle\n\t\tlet intersect = raycaster.ray.intersectTriangle( _vA, _vB, _vC, false, _intersectPoint );\n\n\t\tif ( intersect === null ) {\n\n\t\t\t// check second triangle\n\t\t\ttransformVertex( _vB.set( - 0.5, 0.5, 0 ), _mvPosition, center, _worldScale, sin, cos );\n\t\t\t_uvB.set( 0, 1 );\n\n\t\t\tintersect = raycaster.ray.intersectTriangle( _vA, _vC, _vB, false, _intersectPoint );\n\t\t\tif ( intersect === null ) {\n\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst distance = raycaster.ray.origin.distanceTo( _intersectPoint );\n\n\t\tif ( distance < raycaster.near || distance > raycaster.far ) return;\n\n\t\tintersects.push( {\n\n\t\t\tdistance: distance,\n\t\t\tpoint: _intersectPoint.clone(),\n\t\t\tuv: Triangle.getUV( _intersectPoint, _vA, _vB, _vC, _uvA, _uvB, _uvC, new Vector2() ),\n\t\t\tface: null,\n\t\t\tobject: this\n\n\t\t} );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tif ( source.center !== undefined ) this.center.copy( source.center );\n\n\t\tthis.material = source.material;\n\n\t\treturn this;\n\n\t}\n\n}\n\nSprite.prototype.isSprite = true;\n\nfunction transformVertex( vertexPosition, mvPosition, center, scale, sin, cos ) {\n\n\t// compute position in camera space\n\t_alignedPosition.subVectors( vertexPosition, center ).addScalar( 0.5 ).multiply( scale );\n\n\t// to check if rotation is not zero\n\tif ( sin !== undefined ) {\n\n\t\t_rotatedPosition.x = ( cos * _alignedPosition.x ) - ( sin * _alignedPosition.y );\n\t\t_rotatedPosition.y = ( sin * _alignedPosition.x ) + ( cos * _alignedPosition.y );\n\n\t} else {\n\n\t\t_rotatedPosition.copy( _alignedPosition );\n\n\t}\n\n\n\tvertexPosition.copy( mvPosition );\n\tvertexPosition.x += _rotatedPosition.x;\n\tvertexPosition.y += _rotatedPosition.y;\n\n\t// transform to world space\n\tvertexPosition.applyMatrix4( _viewWorldMatrix );\n\n}\n\nconst _v1$2 = /*@__PURE__*/ new Vector3();\nconst _v2$1 = /*@__PURE__*/ new Vector3();\n\nclass LOD extends Object3D {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis._currentLevel = 0;\n\n\t\tthis.type = 'LOD';\n\n\t\tObject.defineProperties( this, {\n\t\t\tlevels: {\n\t\t\t\tenumerable: true,\n\t\t\t\tvalue: []\n\t\t\t},\n\t\t\tisLOD: {\n\t\t\t\tvalue: true,\n\t\t\t}\n\t\t} );\n\n\t\tthis.autoUpdate = true;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source, false );\n\n\t\tconst levels = source.levels;\n\n\t\tfor ( let i = 0, l = levels.length; i < l; i ++ ) {\n\n\t\t\tconst level = levels[ i ];\n\n\t\t\tthis.addLevel( level.object.clone(), level.distance );\n\n\t\t}\n\n\t\tthis.autoUpdate = source.autoUpdate;\n\n\t\treturn this;\n\n\t}\n\n\taddLevel( object, distance = 0 ) {\n\n\t\tdistance = Math.abs( distance );\n\n\t\tconst levels = this.levels;\n\n\t\tlet l;\n\n\t\tfor ( l = 0; l < levels.length; l ++ ) {\n\n\t\t\tif ( distance < levels[ l ].distance ) {\n\n\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t}\n\n\t\tlevels.splice( l, 0, { distance: distance, object: object } );\n\n\t\tthis.add( object );\n\n\t\treturn this;\n\n\t}\n\n\tgetCurrentLevel() {\n\n\t\treturn this._currentLevel;\n\n\t}\n\n\tgetObjectForDistance( distance ) {\n\n\t\tconst levels = this.levels;\n\n\t\tif ( levels.length > 0 ) {\n\n\t\t\tlet i, l;\n\n\t\t\tfor ( i = 1, l = levels.length; i < l; i ++ ) {\n\n\t\t\t\tif ( distance < levels[ i ].distance ) {\n\n\t\t\t\t\tbreak;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn levels[ i - 1 ].object;\n\n\t\t}\n\n\t\treturn null;\n\n\t}\n\n\traycast( raycaster, intersects ) {\n\n\t\tconst levels = this.levels;\n\n\t\tif ( levels.length > 0 ) {\n\n\t\t\t_v1$2.setFromMatrixPosition( this.matrixWorld );\n\n\t\t\tconst distance = raycaster.ray.origin.distanceTo( _v1$2 );\n\n\t\t\tthis.getObjectForDistance( distance ).raycast( raycaster, intersects );\n\n\t\t}\n\n\t}\n\n\tupdate( camera ) {\n\n\t\tconst levels = this.levels;\n\n\t\tif ( levels.length > 1 ) {\n\n\t\t\t_v1$2.setFromMatrixPosition( camera.matrixWorld );\n\t\t\t_v2$1.setFromMatrixPosition( this.matrixWorld );\n\n\t\t\tconst distance = _v1$2.distanceTo( _v2$1 ) / camera.zoom;\n\n\t\t\tlevels[ 0 ].object.visible = true;\n\n\t\t\tlet i, l;\n\n\t\t\tfor ( i = 1, l = levels.length; i < l; i ++ ) {\n\n\t\t\t\tif ( distance >= levels[ i ].distance ) {\n\n\t\t\t\t\tlevels[ i - 1 ].object.visible = false;\n\t\t\t\t\tlevels[ i ].object.visible = true;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tbreak;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis._currentLevel = i - 1;\n\n\t\t\tfor ( ; i < l; i ++ ) {\n\n\t\t\t\tlevels[ i ].object.visible = false;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tif ( this.autoUpdate === false ) data.object.autoUpdate = false;\n\n\t\tdata.object.levels = [];\n\n\t\tconst levels = this.levels;\n\n\t\tfor ( let i = 0, l = levels.length; i < l; i ++ ) {\n\n\t\t\tconst level = levels[ i ];\n\n\t\t\tdata.object.levels.push( {\n\t\t\t\tobject: level.object.uuid,\n\t\t\t\tdistance: level.distance\n\t\t\t} );\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n}\n\nconst _basePosition = /*@__PURE__*/ new Vector3();\n\nconst _skinIndex = /*@__PURE__*/ new Vector4();\nconst _skinWeight = /*@__PURE__*/ new Vector4();\n\nconst _vector$5 = /*@__PURE__*/ new Vector3();\nconst _matrix = /*@__PURE__*/ new Matrix4();\n\nclass SkinnedMesh extends Mesh {\n\n\tconstructor( geometry, material ) {\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'SkinnedMesh';\n\n\t\tthis.bindMode = 'attached';\n\t\tthis.bindMatrix = new Matrix4();\n\t\tthis.bindMatrixInverse = new Matrix4();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.bindMode = source.bindMode;\n\t\tthis.bindMatrix.copy( source.bindMatrix );\n\t\tthis.bindMatrixInverse.copy( source.bindMatrixInverse );\n\n\t\tthis.skeleton = source.skeleton;\n\n\t\treturn this;\n\n\t}\n\n\tbind( skeleton, bindMatrix ) {\n\n\t\tthis.skeleton = skeleton;\n\n\t\tif ( bindMatrix === undefined ) {\n\n\t\t\tthis.updateMatrixWorld( true );\n\n\t\t\tthis.skeleton.calculateInverses();\n\n\t\t\tbindMatrix = this.matrixWorld;\n\n\t\t}\n\n\t\tthis.bindMatrix.copy( bindMatrix );\n\t\tthis.bindMatrixInverse.copy( bindMatrix ).invert();\n\n\t}\n\n\tpose() {\n\n\t\tthis.skeleton.pose();\n\n\t}\n\n\tnormalizeSkinWeights() {\n\n\t\tconst vector = new Vector4();\n\n\t\tconst skinWeight = this.geometry.attributes.skinWeight;\n\n\t\tfor ( let i = 0, l = skinWeight.count; i < l; i ++ ) {\n\n\t\t\tvector.x = skinWeight.getX( i );\n\t\t\tvector.y = skinWeight.getY( i );\n\t\t\tvector.z = skinWeight.getZ( i );\n\t\t\tvector.w = skinWeight.getW( i );\n\n\t\t\tconst scale = 1.0 / vector.manhattanLength();\n\n\t\t\tif ( scale !== Infinity ) {\n\n\t\t\t\tvector.multiplyScalar( scale );\n\n\t\t\t} else {\n\n\t\t\t\tvector.set( 1, 0, 0, 0 ); // do something reasonable\n\n\t\t\t}\n\n\t\t\tskinWeight.setXYZW( i, vector.x, vector.y, vector.z, vector.w );\n\n\t\t}\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t\tif ( this.bindMode === 'attached' ) {\n\n\t\t\tthis.bindMatrixInverse.copy( this.matrixWorld ).invert();\n\n\t\t} else if ( this.bindMode === 'detached' ) {\n\n\t\t\tthis.bindMatrixInverse.copy( this.bindMatrix ).invert();\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.SkinnedMesh: Unrecognized bindMode: ' + this.bindMode );\n\n\t\t}\n\n\t}\n\n\tboneTransform( index, target ) {\n\n\t\tconst skeleton = this.skeleton;\n\t\tconst geometry = this.geometry;\n\n\t\t_skinIndex.fromBufferAttribute( geometry.attributes.skinIndex, index );\n\t\t_skinWeight.fromBufferAttribute( geometry.attributes.skinWeight, index );\n\n\t\t_basePosition.copy( target ).applyMatrix4( this.bindMatrix );\n\n\t\ttarget.set( 0, 0, 0 );\n\n\t\tfor ( let i = 0; i < 4; i ++ ) {\n\n\t\t\tconst weight = _skinWeight.getComponent( i );\n\n\t\t\tif ( weight !== 0 ) {\n\n\t\t\t\tconst boneIndex = _skinIndex.getComponent( i );\n\n\t\t\t\t_matrix.multiplyMatrices( skeleton.bones[ boneIndex ].matrixWorld, skeleton.boneInverses[ boneIndex ] );\n\n\t\t\t\ttarget.addScaledVector( _vector$5.copy( _basePosition ).applyMatrix4( _matrix ), weight );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn target.applyMatrix4( this.bindMatrixInverse );\n\n\t}\n\n}\n\nSkinnedMesh.prototype.isSkinnedMesh = true;\n\nclass Bone extends Object3D {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'Bone';\n\n\t}\n\n}\n\nBone.prototype.isBone = true;\n\nclass DataTexture extends Texture {\n\n\tconstructor( data = null, width = 1, height = 1, format, type, mapping, wrapS, wrapT, magFilter = NearestFilter, minFilter = NearestFilter, anisotropy, encoding ) {\n\n\t\tsuper( null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, encoding );\n\n\t\tthis.image = { data: data, width: width, height: height };\n\n\t\tthis.generateMipmaps = false;\n\t\tthis.flipY = false;\n\t\tthis.unpackAlignment = 1;\n\n\t}\n\n}\n\nDataTexture.prototype.isDataTexture = true;\n\nconst _offsetMatrix = /*@__PURE__*/ new Matrix4();\nconst _identityMatrix = /*@__PURE__*/ new Matrix4();\n\nclass Skeleton {\n\n\tconstructor( bones = [], boneInverses = [] ) {\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.bones = bones.slice( 0 );\n\t\tthis.boneInverses = boneInverses;\n\t\tthis.boneMatrices = null;\n\n\t\tthis.boneTexture = null;\n\t\tthis.boneTextureSize = 0;\n\n\t\tthis.frame = - 1;\n\n\t\tthis.init();\n\n\t}\n\n\tinit() {\n\n\t\tconst bones = this.bones;\n\t\tconst boneInverses = this.boneInverses;\n\n\t\tthis.boneMatrices = new Float32Array( bones.length * 16 );\n\n\t\t// calculate inverse bone matrices if necessary\n\n\t\tif ( boneInverses.length === 0 ) {\n\n\t\t\tthis.calculateInverses();\n\n\t\t} else {\n\n\t\t\t// handle special case\n\n\t\t\tif ( bones.length !== boneInverses.length ) {\n\n\t\t\t\tconsole.warn( 'THREE.Skeleton: Number of inverse bone matrices does not match amount of bones.' );\n\n\t\t\t\tthis.boneInverses = [];\n\n\t\t\t\tfor ( let i = 0, il = this.bones.length; i < il; i ++ ) {\n\n\t\t\t\t\tthis.boneInverses.push( new Matrix4() );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tcalculateInverses() {\n\n\t\tthis.boneInverses.length = 0;\n\n\t\tfor ( let i = 0, il = this.bones.length; i < il; i ++ ) {\n\n\t\t\tconst inverse = new Matrix4();\n\n\t\t\tif ( this.bones[ i ] ) {\n\n\t\t\t\tinverse.copy( this.bones[ i ].matrixWorld ).invert();\n\n\t\t\t}\n\n\t\t\tthis.boneInverses.push( inverse );\n\n\t\t}\n\n\t}\n\n\tpose() {\n\n\t\t// recover the bind-time world matrices\n\n\t\tfor ( let i = 0, il = this.bones.length; i < il; i ++ ) {\n\n\t\t\tconst bone = this.bones[ i ];\n\n\t\t\tif ( bone ) {\n\n\t\t\t\tbone.matrixWorld.copy( this.boneInverses[ i ] ).invert();\n\n\t\t\t}\n\n\t\t}\n\n\t\t// compute the local matrices, positions, rotations and scales\n\n\t\tfor ( let i = 0, il = this.bones.length; i < il; i ++ ) {\n\n\t\t\tconst bone = this.bones[ i ];\n\n\t\t\tif ( bone ) {\n\n\t\t\t\tif ( bone.parent && bone.parent.isBone ) {\n\n\t\t\t\t\tbone.matrix.copy( bone.parent.matrixWorld ).invert();\n\t\t\t\t\tbone.matrix.multiply( bone.matrixWorld );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tbone.matrix.copy( bone.matrixWorld );\n\n\t\t\t\t}\n\n\t\t\t\tbone.matrix.decompose( bone.position, bone.quaternion, bone.scale );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tupdate() {\n\n\t\tconst bones = this.bones;\n\t\tconst boneInverses = this.boneInverses;\n\t\tconst boneMatrices = this.boneMatrices;\n\t\tconst boneTexture = this.boneTexture;\n\n\t\t// flatten bone matrices to array\n\n\t\tfor ( let i = 0, il = bones.length; i < il; i ++ ) {\n\n\t\t\t// compute the offset between the current and the original transform\n\n\t\t\tconst matrix = bones[ i ] ? bones[ i ].matrixWorld : _identityMatrix;\n\n\t\t\t_offsetMatrix.multiplyMatrices( matrix, boneInverses[ i ] );\n\t\t\t_offsetMatrix.toArray( boneMatrices, i * 16 );\n\n\t\t}\n\n\t\tif ( boneTexture !== null ) {\n\n\t\t\tboneTexture.needsUpdate = true;\n\n\t\t}\n\n\t}\n\n\tclone() {\n\n\t\treturn new Skeleton( this.bones, this.boneInverses );\n\n\t}\n\n\tcomputeBoneTexture() {\n\n\t\t// layout (1 matrix = 4 pixels)\n\t\t//      RGBA RGBA RGBA RGBA (=> column1, column2, column3, column4)\n\t\t//  with  8x8  pixel texture max   16 bones * 4 pixels =  (8 * 8)\n\t\t//       16x16 pixel texture max   64 bones * 4 pixels = (16 * 16)\n\t\t//       32x32 pixel texture max  256 bones * 4 pixels = (32 * 32)\n\t\t//       64x64 pixel texture max 1024 bones * 4 pixels = (64 * 64)\n\n\t\tlet size = Math.sqrt( this.bones.length * 4 ); // 4 pixels needed for 1 matrix\n\t\tsize = ceilPowerOfTwo( size );\n\t\tsize = Math.max( size, 4 );\n\n\t\tconst boneMatrices = new Float32Array( size * size * 4 ); // 4 floats per RGBA pixel\n\t\tboneMatrices.set( this.boneMatrices ); // copy current values\n\n\t\tconst boneTexture = new DataTexture( boneMatrices, size, size, RGBAFormat, FloatType );\n\t\tboneTexture.needsUpdate = true;\n\n\t\tthis.boneMatrices = boneMatrices;\n\t\tthis.boneTexture = boneTexture;\n\t\tthis.boneTextureSize = size;\n\n\t\treturn this;\n\n\t}\n\n\tgetBoneByName( name ) {\n\n\t\tfor ( let i = 0, il = this.bones.length; i < il; i ++ ) {\n\n\t\t\tconst bone = this.bones[ i ];\n\n\t\t\tif ( bone.name === name ) {\n\n\t\t\t\treturn bone;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn undefined;\n\n\t}\n\n\tdispose( ) {\n\n\t\tif ( this.boneTexture !== null ) {\n\n\t\t\tthis.boneTexture.dispose();\n\n\t\t\tthis.boneTexture = null;\n\n\t\t}\n\n\t}\n\n\tfromJSON( json, bones ) {\n\n\t\tthis.uuid = json.uuid;\n\n\t\tfor ( let i = 0, l = json.bones.length; i < l; i ++ ) {\n\n\t\t\tconst uuid = json.bones[ i ];\n\t\t\tlet bone = bones[ uuid ];\n\n\t\t\tif ( bone === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.Skeleton: No bone found with UUID:', uuid );\n\t\t\t\tbone = new Bone();\n\n\t\t\t}\n\n\t\t\tthis.bones.push( bone );\n\t\t\tthis.boneInverses.push( new Matrix4().fromArray( json.boneInverses[ i ] ) );\n\n\t\t}\n\n\t\tthis.init();\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = {\n\t\t\tmetadata: {\n\t\t\t\tversion: 4.5,\n\t\t\t\ttype: 'Skeleton',\n\t\t\t\tgenerator: 'Skeleton.toJSON'\n\t\t\t},\n\t\t\tbones: [],\n\t\t\tboneInverses: []\n\t\t};\n\n\t\tdata.uuid = this.uuid;\n\n\t\tconst bones = this.bones;\n\t\tconst boneInverses = this.boneInverses;\n\n\t\tfor ( let i = 0, l = bones.length; i < l; i ++ ) {\n\n\t\t\tconst bone = bones[ i ];\n\t\t\tdata.bones.push( bone.uuid );\n\n\t\t\tconst boneInverse = boneInverses[ i ];\n\t\t\tdata.boneInverses.push( boneInverse.toArray() );\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n}\n\nclass InstancedBufferAttribute extends BufferAttribute {\n\n\tconstructor( array, itemSize, normalized, meshPerAttribute = 1 ) {\n\n\t\tif ( typeof normalized === 'number' ) {\n\n\t\t\tmeshPerAttribute = normalized;\n\n\t\t\tnormalized = false;\n\n\t\t\tconsole.error( 'THREE.InstancedBufferAttribute: The constructor now expects normalized as the third argument.' );\n\n\t\t}\n\n\t\tsuper( array, itemSize, normalized );\n\n\t\tthis.meshPerAttribute = meshPerAttribute;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.meshPerAttribute = source.meshPerAttribute;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.meshPerAttribute = this.meshPerAttribute;\n\n\t\tdata.isInstancedBufferAttribute = true;\n\n\t\treturn data;\n\n\t}\n\n}\n\nInstancedBufferAttribute.prototype.isInstancedBufferAttribute = true;\n\nconst _instanceLocalMatrix = /*@__PURE__*/ new Matrix4();\nconst _instanceWorldMatrix = /*@__PURE__*/ new Matrix4();\n\nconst _instanceIntersects = [];\n\nconst _mesh = /*@__PURE__*/ new Mesh();\n\nclass InstancedMesh extends Mesh {\n\n\tconstructor( geometry, material, count ) {\n\n\t\tsuper( geometry, material );\n\n\t\tthis.instanceMatrix = new InstancedBufferAttribute( new Float32Array( count * 16 ), 16 );\n\t\tthis.instanceColor = null;\n\n\t\tthis.count = count;\n\n\t\tthis.frustumCulled = false;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.instanceMatrix.copy( source.instanceMatrix );\n\n\t\tif ( source.instanceColor !== null ) this.instanceColor = source.instanceColor.clone();\n\n\t\tthis.count = source.count;\n\n\t\treturn this;\n\n\t}\n\n\tgetColorAt( index, color ) {\n\n\t\tcolor.fromArray( this.instanceColor.array, index * 3 );\n\n\t}\n\n\tgetMatrixAt( index, matrix ) {\n\n\t\tmatrix.fromArray( this.instanceMatrix.array, index * 16 );\n\n\t}\n\n\traycast( raycaster, intersects ) {\n\n\t\tconst matrixWorld = this.matrixWorld;\n\t\tconst raycastTimes = this.count;\n\n\t\t_mesh.geometry = this.geometry;\n\t\t_mesh.material = this.material;\n\n\t\tif ( _mesh.material === undefined ) return;\n\n\t\tfor ( let instanceId = 0; instanceId < raycastTimes; instanceId ++ ) {\n\n\t\t\t// calculate the world matrix for each instance\n\n\t\t\tthis.getMatrixAt( instanceId, _instanceLocalMatrix );\n\n\t\t\t_instanceWorldMatrix.multiplyMatrices( matrixWorld, _instanceLocalMatrix );\n\n\t\t\t// the mesh represents this single instance\n\n\t\t\t_mesh.matrixWorld = _instanceWorldMatrix;\n\n\t\t\t_mesh.raycast( raycaster, _instanceIntersects );\n\n\t\t\t// process the result of raycast\n\n\t\t\tfor ( let i = 0, l = _instanceIntersects.length; i < l; i ++ ) {\n\n\t\t\t\tconst intersect = _instanceIntersects[ i ];\n\t\t\t\tintersect.instanceId = instanceId;\n\t\t\t\tintersect.object = this;\n\t\t\t\tintersects.push( intersect );\n\n\t\t\t}\n\n\t\t\t_instanceIntersects.length = 0;\n\n\t\t}\n\n\t}\n\n\tsetColorAt( index, color ) {\n\n\t\tif ( this.instanceColor === null ) {\n\n\t\t\tthis.instanceColor = new InstancedBufferAttribute( new Float32Array( this.instanceMatrix.count * 3 ), 3 );\n\n\t\t}\n\n\t\tcolor.toArray( this.instanceColor.array, index * 3 );\n\n\t}\n\n\tsetMatrixAt( index, matrix ) {\n\n\t\tmatrix.toArray( this.instanceMatrix.array, index * 16 );\n\n\t}\n\n\tupdateMorphTargets() {\n\n\t}\n\n\tdispose() {\n\n\t\tthis.dispatchEvent( { type: 'dispose' } );\n\n\t}\n\n}\n\nInstancedMesh.prototype.isInstancedMesh = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  opacity: <float>,\n *\n *  linewidth: <float>,\n *  linecap: \"round\",\n *  linejoin: \"round\"\n * }\n */\n\nclass LineBasicMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'LineBasicMaterial';\n\n\t\tthis.color = new Color( 0xffffff );\n\n\t\tthis.linewidth = 1;\n\t\tthis.linecap = 'round';\n\t\tthis.linejoin = 'round';\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.linewidth = source.linewidth;\n\t\tthis.linecap = source.linecap;\n\t\tthis.linejoin = source.linejoin;\n\n\t\treturn this;\n\n\t}\n\n}\n\nLineBasicMaterial.prototype.isLineBasicMaterial = true;\n\nconst _start$1 = /*@__PURE__*/ new Vector3();\nconst _end$1 = /*@__PURE__*/ new Vector3();\nconst _inverseMatrix$1 = /*@__PURE__*/ new Matrix4();\nconst _ray$1 = /*@__PURE__*/ new Ray();\nconst _sphere$1 = /*@__PURE__*/ new Sphere();\n\nclass Line extends Object3D {\n\n\tconstructor( geometry = new BufferGeometry(), material = new LineBasicMaterial() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'Line';\n\n\t\tthis.geometry = geometry;\n\t\tthis.material = material;\n\n\t\tthis.updateMorphTargets();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.material = source.material;\n\t\tthis.geometry = source.geometry;\n\n\t\treturn this;\n\n\t}\n\n\tcomputeLineDistances() {\n\n\t\tconst geometry = this.geometry;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\t// we assume non-indexed geometry\n\n\t\t\tif ( geometry.index === null ) {\n\n\t\t\t\tconst positionAttribute = geometry.attributes.position;\n\t\t\t\tconst lineDistances = [ 0 ];\n\n\t\t\t\tfor ( let i = 1, l = positionAttribute.count; i < l; i ++ ) {\n\n\t\t\t\t\t_start$1.fromBufferAttribute( positionAttribute, i - 1 );\n\t\t\t\t\t_end$1.fromBufferAttribute( positionAttribute, i );\n\n\t\t\t\t\tlineDistances[ i ] = lineDistances[ i - 1 ];\n\t\t\t\t\tlineDistances[ i ] += _start$1.distanceTo( _end$1 );\n\n\t\t\t\t}\n\n\t\t\t\tgeometry.setAttribute( 'lineDistance', new Float32BufferAttribute( lineDistances, 1 ) );\n\n\t\t\t} else {\n\n\t\t\t\tconsole.warn( 'THREE.Line.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.' );\n\n\t\t\t}\n\n\t\t} else if ( geometry.isGeometry ) {\n\n\t\t\tconsole.error( 'THREE.Line.computeLineDistances() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\traycast( raycaster, intersects ) {\n\n\t\tconst geometry = this.geometry;\n\t\tconst matrixWorld = this.matrixWorld;\n\t\tconst threshold = raycaster.params.Line.threshold;\n\t\tconst drawRange = geometry.drawRange;\n\n\t\t// Checking boundingSphere distance to ray\n\n\t\tif ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();\n\n\t\t_sphere$1.copy( geometry.boundingSphere );\n\t\t_sphere$1.applyMatrix4( matrixWorld );\n\t\t_sphere$1.radius += threshold;\n\n\t\tif ( raycaster.ray.intersectsSphere( _sphere$1 ) === false ) return;\n\n\t\t//\n\n\t\t_inverseMatrix$1.copy( matrixWorld ).invert();\n\t\t_ray$1.copy( raycaster.ray ).applyMatrix4( _inverseMatrix$1 );\n\n\t\tconst localThreshold = threshold / ( ( this.scale.x + this.scale.y + this.scale.z ) / 3 );\n\t\tconst localThresholdSq = localThreshold * localThreshold;\n\n\t\tconst vStart = new Vector3();\n\t\tconst vEnd = new Vector3();\n\t\tconst interSegment = new Vector3();\n\t\tconst interRay = new Vector3();\n\t\tconst step = this.isLineSegments ? 2 : 1;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\tconst index = geometry.index;\n\t\t\tconst attributes = geometry.attributes;\n\t\t\tconst positionAttribute = attributes.position;\n\n\t\t\tif ( index !== null ) {\n\n\t\t\t\tconst start = Math.max( 0, drawRange.start );\n\t\t\t\tconst end = Math.min( index.count, ( drawRange.start + drawRange.count ) );\n\n\t\t\t\tfor ( let i = start, l = end - 1; i < l; i += step ) {\n\n\t\t\t\t\tconst a = index.getX( i );\n\t\t\t\t\tconst b = index.getX( i + 1 );\n\n\t\t\t\t\tvStart.fromBufferAttribute( positionAttribute, a );\n\t\t\t\t\tvEnd.fromBufferAttribute( positionAttribute, b );\n\n\t\t\t\t\tconst distSq = _ray$1.distanceSqToSegment( vStart, vEnd, interRay, interSegment );\n\n\t\t\t\t\tif ( distSq > localThresholdSq ) continue;\n\n\t\t\t\t\tinterRay.applyMatrix4( this.matrixWorld ); //Move back to world space for distance calculation\n\n\t\t\t\t\tconst distance = raycaster.ray.origin.distanceTo( interRay );\n\n\t\t\t\t\tif ( distance < raycaster.near || distance > raycaster.far ) continue;\n\n\t\t\t\t\tintersects.push( {\n\n\t\t\t\t\t\tdistance: distance,\n\t\t\t\t\t\t// What do we want? intersection point on the ray or on the segment??\n\t\t\t\t\t\t// point: raycaster.ray.at( distance ),\n\t\t\t\t\t\tpoint: interSegment.clone().applyMatrix4( this.matrixWorld ),\n\t\t\t\t\t\tindex: i,\n\t\t\t\t\t\tface: null,\n\t\t\t\t\t\tfaceIndex: null,\n\t\t\t\t\t\tobject: this\n\n\t\t\t\t\t} );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tconst start = Math.max( 0, drawRange.start );\n\t\t\t\tconst end = Math.min( positionAttribute.count, ( drawRange.start + drawRange.count ) );\n\n\t\t\t\tfor ( let i = start, l = end - 1; i < l; i += step ) {\n\n\t\t\t\t\tvStart.fromBufferAttribute( positionAttribute, i );\n\t\t\t\t\tvEnd.fromBufferAttribute( positionAttribute, i + 1 );\n\n\t\t\t\t\tconst distSq = _ray$1.distanceSqToSegment( vStart, vEnd, interRay, interSegment );\n\n\t\t\t\t\tif ( distSq > localThresholdSq ) continue;\n\n\t\t\t\t\tinterRay.applyMatrix4( this.matrixWorld ); //Move back to world space for distance calculation\n\n\t\t\t\t\tconst distance = raycaster.ray.origin.distanceTo( interRay );\n\n\t\t\t\t\tif ( distance < raycaster.near || distance > raycaster.far ) continue;\n\n\t\t\t\t\tintersects.push( {\n\n\t\t\t\t\t\tdistance: distance,\n\t\t\t\t\t\t// What do we want? intersection point on the ray or on the segment??\n\t\t\t\t\t\t// point: raycaster.ray.at( distance ),\n\t\t\t\t\t\tpoint: interSegment.clone().applyMatrix4( this.matrixWorld ),\n\t\t\t\t\t\tindex: i,\n\t\t\t\t\t\tface: null,\n\t\t\t\t\t\tfaceIndex: null,\n\t\t\t\t\t\tobject: this\n\n\t\t\t\t\t} );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else if ( geometry.isGeometry ) {\n\n\t\t\tconsole.error( 'THREE.Line.raycast() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t}\n\n\t}\n\n\tupdateMorphTargets() {\n\n\t\tconst geometry = this.geometry;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\tconst morphAttributes = geometry.morphAttributes;\n\t\t\tconst keys = Object.keys( morphAttributes );\n\n\t\t\tif ( keys.length > 0 ) {\n\n\t\t\t\tconst morphAttribute = morphAttributes[ keys[ 0 ] ];\n\n\t\t\t\tif ( morphAttribute !== undefined ) {\n\n\t\t\t\t\tthis.morphTargetInfluences = [];\n\t\t\t\t\tthis.morphTargetDictionary = {};\n\n\t\t\t\t\tfor ( let m = 0, ml = morphAttribute.length; m < ml; m ++ ) {\n\n\t\t\t\t\t\tconst name = morphAttribute[ m ].name || String( m );\n\n\t\t\t\t\t\tthis.morphTargetInfluences.push( 0 );\n\t\t\t\t\t\tthis.morphTargetDictionary[ name ] = m;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconst morphTargets = geometry.morphTargets;\n\n\t\t\tif ( morphTargets !== undefined && morphTargets.length > 0 ) {\n\n\t\t\t\tconsole.error( 'THREE.Line.updateMorphTargets() does not support THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n}\n\nLine.prototype.isLine = true;\n\nconst _start = /*@__PURE__*/ new Vector3();\nconst _end = /*@__PURE__*/ new Vector3();\n\nclass LineSegments extends Line {\n\n\tconstructor( geometry, material ) {\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'LineSegments';\n\n\t}\n\n\tcomputeLineDistances() {\n\n\t\tconst geometry = this.geometry;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\t// we assume non-indexed geometry\n\n\t\t\tif ( geometry.index === null ) {\n\n\t\t\t\tconst positionAttribute = geometry.attributes.position;\n\t\t\t\tconst lineDistances = [];\n\n\t\t\t\tfor ( let i = 0, l = positionAttribute.count; i < l; i += 2 ) {\n\n\t\t\t\t\t_start.fromBufferAttribute( positionAttribute, i );\n\t\t\t\t\t_end.fromBufferAttribute( positionAttribute, i + 1 );\n\n\t\t\t\t\tlineDistances[ i ] = ( i === 0 ) ? 0 : lineDistances[ i - 1 ];\n\t\t\t\t\tlineDistances[ i + 1 ] = lineDistances[ i ] + _start.distanceTo( _end );\n\n\t\t\t\t}\n\n\t\t\t\tgeometry.setAttribute( 'lineDistance', new Float32BufferAttribute( lineDistances, 1 ) );\n\n\t\t\t} else {\n\n\t\t\t\tconsole.warn( 'THREE.LineSegments.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.' );\n\n\t\t\t}\n\n\t\t} else if ( geometry.isGeometry ) {\n\n\t\t\tconsole.error( 'THREE.LineSegments.computeLineDistances() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\nLineSegments.prototype.isLineSegments = true;\n\nclass LineLoop extends Line {\n\n\tconstructor( geometry, material ) {\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'LineLoop';\n\n\t}\n\n}\n\nLineLoop.prototype.isLineLoop = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  opacity: <float>,\n *  map: new THREE.Texture( <Image> ),\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  size: <float>,\n *  sizeAttenuation: <bool>\n *\n * }\n */\n\nclass PointsMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'PointsMaterial';\n\n\t\tthis.color = new Color( 0xffffff );\n\n\t\tthis.map = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.size = 1;\n\t\tthis.sizeAttenuation = true;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.map = source.map;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.size = source.size;\n\t\tthis.sizeAttenuation = source.sizeAttenuation;\n\n\t\treturn this;\n\n\t}\n\n}\n\nPointsMaterial.prototype.isPointsMaterial = true;\n\nconst _inverseMatrix = /*@__PURE__*/ new Matrix4();\nconst _ray = /*@__PURE__*/ new Ray();\nconst _sphere = /*@__PURE__*/ new Sphere();\nconst _position$2 = /*@__PURE__*/ new Vector3();\n\nclass Points extends Object3D {\n\n\tconstructor( geometry = new BufferGeometry(), material = new PointsMaterial() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'Points';\n\n\t\tthis.geometry = geometry;\n\t\tthis.material = material;\n\n\t\tthis.updateMorphTargets();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.material = source.material;\n\t\tthis.geometry = source.geometry;\n\n\t\treturn this;\n\n\t}\n\n\traycast( raycaster, intersects ) {\n\n\t\tconst geometry = this.geometry;\n\t\tconst matrixWorld = this.matrixWorld;\n\t\tconst threshold = raycaster.params.Points.threshold;\n\t\tconst drawRange = geometry.drawRange;\n\n\t\t// Checking boundingSphere distance to ray\n\n\t\tif ( geometry.boundingSphere === null ) geometry.computeBoundingSphere();\n\n\t\t_sphere.copy( geometry.boundingSphere );\n\t\t_sphere.applyMatrix4( matrixWorld );\n\t\t_sphere.radius += threshold;\n\n\t\tif ( raycaster.ray.intersectsSphere( _sphere ) === false ) return;\n\n\t\t//\n\n\t\t_inverseMatrix.copy( matrixWorld ).invert();\n\t\t_ray.copy( raycaster.ray ).applyMatrix4( _inverseMatrix );\n\n\t\tconst localThreshold = threshold / ( ( this.scale.x + this.scale.y + this.scale.z ) / 3 );\n\t\tconst localThresholdSq = localThreshold * localThreshold;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\tconst index = geometry.index;\n\t\t\tconst attributes = geometry.attributes;\n\t\t\tconst positionAttribute = attributes.position;\n\n\t\t\tif ( index !== null ) {\n\n\t\t\t\tconst start = Math.max( 0, drawRange.start );\n\t\t\t\tconst end = Math.min( index.count, ( drawRange.start + drawRange.count ) );\n\n\t\t\t\tfor ( let i = start, il = end; i < il; i ++ ) {\n\n\t\t\t\t\tconst a = index.getX( i );\n\n\t\t\t\t\t_position$2.fromBufferAttribute( positionAttribute, a );\n\n\t\t\t\t\ttestPoint( _position$2, a, localThresholdSq, matrixWorld, raycaster, intersects, this );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tconst start = Math.max( 0, drawRange.start );\n\t\t\t\tconst end = Math.min( positionAttribute.count, ( drawRange.start + drawRange.count ) );\n\n\t\t\t\tfor ( let i = start, l = end; i < l; i ++ ) {\n\n\t\t\t\t\t_position$2.fromBufferAttribute( positionAttribute, i );\n\n\t\t\t\t\ttestPoint( _position$2, i, localThresholdSq, matrixWorld, raycaster, intersects, this );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconsole.error( 'THREE.Points.raycast() no longer supports THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t}\n\n\t}\n\n\tupdateMorphTargets() {\n\n\t\tconst geometry = this.geometry;\n\n\t\tif ( geometry.isBufferGeometry ) {\n\n\t\t\tconst morphAttributes = geometry.morphAttributes;\n\t\t\tconst keys = Object.keys( morphAttributes );\n\n\t\t\tif ( keys.length > 0 ) {\n\n\t\t\t\tconst morphAttribute = morphAttributes[ keys[ 0 ] ];\n\n\t\t\t\tif ( morphAttribute !== undefined ) {\n\n\t\t\t\t\tthis.morphTargetInfluences = [];\n\t\t\t\t\tthis.morphTargetDictionary = {};\n\n\t\t\t\t\tfor ( let m = 0, ml = morphAttribute.length; m < ml; m ++ ) {\n\n\t\t\t\t\t\tconst name = morphAttribute[ m ].name || String( m );\n\n\t\t\t\t\t\tthis.morphTargetInfluences.push( 0 );\n\t\t\t\t\t\tthis.morphTargetDictionary[ name ] = m;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconst morphTargets = geometry.morphTargets;\n\n\t\t\tif ( morphTargets !== undefined && morphTargets.length > 0 ) {\n\n\t\t\t\tconsole.error( 'THREE.Points.updateMorphTargets() does not support THREE.Geometry. Use THREE.BufferGeometry instead.' );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n}\n\nPoints.prototype.isPoints = true;\n\nfunction testPoint( point, index, localThresholdSq, matrixWorld, raycaster, intersects, object ) {\n\n\tconst rayPointDistanceSq = _ray.distanceSqToPoint( point );\n\n\tif ( rayPointDistanceSq < localThresholdSq ) {\n\n\t\tconst intersectPoint = new Vector3();\n\n\t\t_ray.closestPointToPoint( point, intersectPoint );\n\t\tintersectPoint.applyMatrix4( matrixWorld );\n\n\t\tconst distance = raycaster.ray.origin.distanceTo( intersectPoint );\n\n\t\tif ( distance < raycaster.near || distance > raycaster.far ) return;\n\n\t\tintersects.push( {\n\n\t\t\tdistance: distance,\n\t\t\tdistanceToRay: Math.sqrt( rayPointDistanceSq ),\n\t\t\tpoint: intersectPoint,\n\t\t\tindex: index,\n\t\t\tface: null,\n\t\t\tobject: object\n\n\t\t} );\n\n\t}\n\n}\n\nclass VideoTexture extends Texture {\n\n\tconstructor( video, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy ) {\n\n\t\tsuper( video, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy );\n\n\t\tthis.minFilter = minFilter !== undefined ? minFilter : LinearFilter;\n\t\tthis.magFilter = magFilter !== undefined ? magFilter : LinearFilter;\n\n\t\tthis.generateMipmaps = false;\n\n\t\tconst scope = this;\n\n\t\tfunction updateVideo() {\n\n\t\t\tscope.needsUpdate = true;\n\t\t\tvideo.requestVideoFrameCallback( updateVideo );\n\n\t\t}\n\n\t\tif ( 'requestVideoFrameCallback' in video ) {\n\n\t\t\tvideo.requestVideoFrameCallback( updateVideo );\n\n\t\t}\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor( this.image ).copy( this );\n\n\t}\n\n\tupdate() {\n\n\t\tconst video = this.image;\n\t\tconst hasVideoFrameCallback = 'requestVideoFrameCallback' in video;\n\n\t\tif ( hasVideoFrameCallback === false && video.readyState >= video.HAVE_CURRENT_DATA ) {\n\n\t\t\tthis.needsUpdate = true;\n\n\t\t}\n\n\t}\n\n}\n\nVideoTexture.prototype.isVideoTexture = true;\n\nclass FramebufferTexture extends Texture {\n\n\tconstructor( width, height, format ) {\n\n\t\tsuper( { width, height } );\n\n\t\tthis.format = format;\n\n\t\tthis.magFilter = NearestFilter;\n\t\tthis.minFilter = NearestFilter;\n\n\t\tthis.generateMipmaps = false;\n\n\t\tthis.needsUpdate = true;\n\n\t}\n\n}\n\nFramebufferTexture.prototype.isFramebufferTexture = true;\n\nclass CompressedTexture extends Texture {\n\n\tconstructor( mipmaps, width, height, format, type, mapping, wrapS, wrapT, magFilter, minFilter, anisotropy, encoding ) {\n\n\t\tsuper( null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, encoding );\n\n\t\tthis.image = { width: width, height: height };\n\t\tthis.mipmaps = mipmaps;\n\n\t\t// no flipping for cube textures\n\t\t// (also flipping doesn't work for compressed textures )\n\n\t\tthis.flipY = false;\n\n\t\t// can't generate mipmaps for compressed textures\n\t\t// mips must be embedded in DDS files\n\n\t\tthis.generateMipmaps = false;\n\n\t}\n\n}\n\nCompressedTexture.prototype.isCompressedTexture = true;\n\nclass CanvasTexture extends Texture {\n\n\tconstructor( canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy ) {\n\n\t\tsuper( canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy );\n\n\t\tthis.needsUpdate = true;\n\n\t}\n\n}\n\nCanvasTexture.prototype.isCanvasTexture = true;\n\nclass CircleGeometry extends BufferGeometry {\n\n\tconstructor( radius = 1, segments = 8, thetaStart = 0, thetaLength = Math.PI * 2 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'CircleGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\tsegments: segments,\n\t\t\tthetaStart: thetaStart,\n\t\t\tthetaLength: thetaLength\n\t\t};\n\n\t\tsegments = Math.max( 3, segments );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// helper variables\n\n\t\tconst vertex = new Vector3();\n\t\tconst uv = new Vector2();\n\n\t\t// center point\n\n\t\tvertices.push( 0, 0, 0 );\n\t\tnormals.push( 0, 0, 1 );\n\t\tuvs.push( 0.5, 0.5 );\n\n\t\tfor ( let s = 0, i = 3; s <= segments; s ++, i += 3 ) {\n\n\t\t\tconst segment = thetaStart + s / segments * thetaLength;\n\n\t\t\t// vertex\n\n\t\t\tvertex.x = radius * Math.cos( segment );\n\t\t\tvertex.y = radius * Math.sin( segment );\n\n\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t// normal\n\n\t\t\tnormals.push( 0, 0, 1 );\n\n\t\t\t// uvs\n\n\t\t\tuv.x = ( vertices[ i ] / radius + 1 ) / 2;\n\t\t\tuv.y = ( vertices[ i + 1 ] / radius + 1 ) / 2;\n\n\t\t\tuvs.push( uv.x, uv.y );\n\n\t\t}\n\n\t\t// indices\n\n\t\tfor ( let i = 1; i <= segments; i ++ ) {\n\n\t\t\tindices.push( i, i + 1, 0 );\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new CircleGeometry( data.radius, data.segments, data.thetaStart, data.thetaLength );\n\n\t}\n\n}\n\nclass CylinderGeometry extends BufferGeometry {\n\n\tconstructor( radiusTop = 1, radiusBottom = 1, height = 1, radialSegments = 8, heightSegments = 1, openEnded = false, thetaStart = 0, thetaLength = Math.PI * 2 ) {\n\n\t\tsuper();\n\t\tthis.type = 'CylinderGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradiusTop: radiusTop,\n\t\t\tradiusBottom: radiusBottom,\n\t\t\theight: height,\n\t\t\tradialSegments: radialSegments,\n\t\t\theightSegments: heightSegments,\n\t\t\topenEnded: openEnded,\n\t\t\tthetaStart: thetaStart,\n\t\t\tthetaLength: thetaLength\n\t\t};\n\n\t\tconst scope = this;\n\n\t\tradialSegments = Math.floor( radialSegments );\n\t\theightSegments = Math.floor( heightSegments );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// helper variables\n\n\t\tlet index = 0;\n\t\tconst indexArray = [];\n\t\tconst halfHeight = height / 2;\n\t\tlet groupStart = 0;\n\n\t\t// generate geometry\n\n\t\tgenerateTorso();\n\n\t\tif ( openEnded === false ) {\n\n\t\t\tif ( radiusTop > 0 ) generateCap( true );\n\t\t\tif ( radiusBottom > 0 ) generateCap( false );\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t\tfunction generateTorso() {\n\n\t\t\tconst normal = new Vector3();\n\t\t\tconst vertex = new Vector3();\n\n\t\t\tlet groupCount = 0;\n\n\t\t\t// this will be used to calculate the normal\n\t\t\tconst slope = ( radiusBottom - radiusTop ) / height;\n\n\t\t\t// generate vertices, normals and uvs\n\n\t\t\tfor ( let y = 0; y <= heightSegments; y ++ ) {\n\n\t\t\t\tconst indexRow = [];\n\n\t\t\t\tconst v = y / heightSegments;\n\n\t\t\t\t// calculate the radius of the current row\n\n\t\t\t\tconst radius = v * ( radiusBottom - radiusTop ) + radiusTop;\n\n\t\t\t\tfor ( let x = 0; x <= radialSegments; x ++ ) {\n\n\t\t\t\t\tconst u = x / radialSegments;\n\n\t\t\t\t\tconst theta = u * thetaLength + thetaStart;\n\n\t\t\t\t\tconst sinTheta = Math.sin( theta );\n\t\t\t\t\tconst cosTheta = Math.cos( theta );\n\n\t\t\t\t\t// vertex\n\n\t\t\t\t\tvertex.x = radius * sinTheta;\n\t\t\t\t\tvertex.y = - v * height + halfHeight;\n\t\t\t\t\tvertex.z = radius * cosTheta;\n\t\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t\t// normal\n\n\t\t\t\t\tnormal.set( sinTheta, slope, cosTheta ).normalize();\n\t\t\t\t\tnormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t\t// uv\n\n\t\t\t\t\tuvs.push( u, 1 - v );\n\n\t\t\t\t\t// save index of vertex in respective row\n\n\t\t\t\t\tindexRow.push( index ++ );\n\n\t\t\t\t}\n\n\t\t\t\t// now save vertices of the row in our index array\n\n\t\t\t\tindexArray.push( indexRow );\n\n\t\t\t}\n\n\t\t\t// generate indices\n\n\t\t\tfor ( let x = 0; x < radialSegments; x ++ ) {\n\n\t\t\t\tfor ( let y = 0; y < heightSegments; y ++ ) {\n\n\t\t\t\t\t// we use the index array to access the correct indices\n\n\t\t\t\t\tconst a = indexArray[ y ][ x ];\n\t\t\t\t\tconst b = indexArray[ y + 1 ][ x ];\n\t\t\t\t\tconst c = indexArray[ y + 1 ][ x + 1 ];\n\t\t\t\t\tconst d = indexArray[ y ][ x + 1 ];\n\n\t\t\t\t\t// faces\n\n\t\t\t\t\tindices.push( a, b, d );\n\t\t\t\t\tindices.push( b, c, d );\n\n\t\t\t\t\t// update group counter\n\n\t\t\t\t\tgroupCount += 6;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// add a group to the geometry. this will ensure multi material support\n\n\t\t\tscope.addGroup( groupStart, groupCount, 0 );\n\n\t\t\t// calculate new start value for groups\n\n\t\t\tgroupStart += groupCount;\n\n\t\t}\n\n\t\tfunction generateCap( top ) {\n\n\t\t\t// save the index of the first center vertex\n\t\t\tconst centerIndexStart = index;\n\n\t\t\tconst uv = new Vector2();\n\t\t\tconst vertex = new Vector3();\n\n\t\t\tlet groupCount = 0;\n\n\t\t\tconst radius = ( top === true ) ? radiusTop : radiusBottom;\n\t\t\tconst sign = ( top === true ) ? 1 : - 1;\n\n\t\t\t// first we generate the center vertex data of the cap.\n\t\t\t// because the geometry needs one set of uvs per face,\n\t\t\t// we must generate a center vertex per face/segment\n\n\t\t\tfor ( let x = 1; x <= radialSegments; x ++ ) {\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertices.push( 0, halfHeight * sign, 0 );\n\n\t\t\t\t// normal\n\n\t\t\t\tnormals.push( 0, sign, 0 );\n\n\t\t\t\t// uv\n\n\t\t\t\tuvs.push( 0.5, 0.5 );\n\n\t\t\t\t// increase index\n\n\t\t\t\tindex ++;\n\n\t\t\t}\n\n\t\t\t// save the index of the last center vertex\n\t\t\tconst centerIndexEnd = index;\n\n\t\t\t// now we generate the surrounding vertices, normals and uvs\n\n\t\t\tfor ( let x = 0; x <= radialSegments; x ++ ) {\n\n\t\t\t\tconst u = x / radialSegments;\n\t\t\t\tconst theta = u * thetaLength + thetaStart;\n\n\t\t\t\tconst cosTheta = Math.cos( theta );\n\t\t\t\tconst sinTheta = Math.sin( theta );\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertex.x = radius * sinTheta;\n\t\t\t\tvertex.y = halfHeight * sign;\n\t\t\t\tvertex.z = radius * cosTheta;\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t// normal\n\n\t\t\t\tnormals.push( 0, sign, 0 );\n\n\t\t\t\t// uv\n\n\t\t\t\tuv.x = ( cosTheta * 0.5 ) + 0.5;\n\t\t\t\tuv.y = ( sinTheta * 0.5 * sign ) + 0.5;\n\t\t\t\tuvs.push( uv.x, uv.y );\n\n\t\t\t\t// increase index\n\n\t\t\t\tindex ++;\n\n\t\t\t}\n\n\t\t\t// generate indices\n\n\t\t\tfor ( let x = 0; x < radialSegments; x ++ ) {\n\n\t\t\t\tconst c = centerIndexStart + x;\n\t\t\t\tconst i = centerIndexEnd + x;\n\n\t\t\t\tif ( top === true ) {\n\n\t\t\t\t\t// face top\n\n\t\t\t\t\tindices.push( i, i + 1, c );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// face bottom\n\n\t\t\t\t\tindices.push( i + 1, i, c );\n\n\t\t\t\t}\n\n\t\t\t\tgroupCount += 3;\n\n\t\t\t}\n\n\t\t\t// add a group to the geometry. this will ensure multi material support\n\n\t\t\tscope.addGroup( groupStart, groupCount, top === true ? 1 : 2 );\n\n\t\t\t// calculate new start value for groups\n\n\t\t\tgroupStart += groupCount;\n\n\t\t}\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new CylinderGeometry( data.radiusTop, data.radiusBottom, data.height, data.radialSegments, data.heightSegments, data.openEnded, data.thetaStart, data.thetaLength );\n\n\t}\n\n}\n\nclass ConeGeometry extends CylinderGeometry {\n\n\tconstructor( radius = 1, height = 1, radialSegments = 8, heightSegments = 1, openEnded = false, thetaStart = 0, thetaLength = Math.PI * 2 ) {\n\n\t\tsuper( 0, radius, height, radialSegments, heightSegments, openEnded, thetaStart, thetaLength );\n\n\t\tthis.type = 'ConeGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\theight: height,\n\t\t\tradialSegments: radialSegments,\n\t\t\theightSegments: heightSegments,\n\t\t\topenEnded: openEnded,\n\t\t\tthetaStart: thetaStart,\n\t\t\tthetaLength: thetaLength\n\t\t};\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new ConeGeometry( data.radius, data.height, data.radialSegments, data.heightSegments, data.openEnded, data.thetaStart, data.thetaLength );\n\n\t}\n\n}\n\nclass PolyhedronGeometry extends BufferGeometry {\n\n\tconstructor( vertices = [], indices = [], radius = 1, detail = 0 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'PolyhedronGeometry';\n\n\t\tthis.parameters = {\n\t\t\tvertices: vertices,\n\t\t\tindices: indices,\n\t\t\tradius: radius,\n\t\t\tdetail: detail\n\t\t};\n\n\t\t// default buffer data\n\n\t\tconst vertexBuffer = [];\n\t\tconst uvBuffer = [];\n\n\t\t// the subdivision creates the vertex buffer data\n\n\t\tsubdivide( detail );\n\n\t\t// all vertices should lie on a conceptual sphere with a given radius\n\n\t\tapplyRadius( radius );\n\n\t\t// finally, create the uv data\n\n\t\tgenerateUVs();\n\n\t\t// build non-indexed geometry\n\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertexBuffer, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( vertexBuffer.slice(), 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvBuffer, 2 ) );\n\n\t\tif ( detail === 0 ) {\n\n\t\t\tthis.computeVertexNormals(); // flat normals\n\n\t\t} else {\n\n\t\t\tthis.normalizeNormals(); // smooth normals\n\n\t\t}\n\n\t\t// helper functions\n\n\t\tfunction subdivide( detail ) {\n\n\t\t\tconst a = new Vector3();\n\t\t\tconst b = new Vector3();\n\t\t\tconst c = new Vector3();\n\n\t\t\t// iterate over all faces and apply a subdivison with the given detail value\n\n\t\t\tfor ( let i = 0; i < indices.length; i += 3 ) {\n\n\t\t\t\t// get the vertices of the face\n\n\t\t\t\tgetVertexByIndex( indices[ i + 0 ], a );\n\t\t\t\tgetVertexByIndex( indices[ i + 1 ], b );\n\t\t\t\tgetVertexByIndex( indices[ i + 2 ], c );\n\n\t\t\t\t// perform subdivision\n\n\t\t\t\tsubdivideFace( a, b, c, detail );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction subdivideFace( a, b, c, detail ) {\n\n\t\t\tconst cols = detail + 1;\n\n\t\t\t// we use this multidimensional array as a data structure for creating the subdivision\n\n\t\t\tconst v = [];\n\n\t\t\t// construct all of the vertices for this subdivision\n\n\t\t\tfor ( let i = 0; i <= cols; i ++ ) {\n\n\t\t\t\tv[ i ] = [];\n\n\t\t\t\tconst aj = a.clone().lerp( c, i / cols );\n\t\t\t\tconst bj = b.clone().lerp( c, i / cols );\n\n\t\t\t\tconst rows = cols - i;\n\n\t\t\t\tfor ( let j = 0; j <= rows; j ++ ) {\n\n\t\t\t\t\tif ( j === 0 && i === cols ) {\n\n\t\t\t\t\t\tv[ i ][ j ] = aj;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tv[ i ][ j ] = aj.clone().lerp( bj, j / rows );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// construct all of the faces\n\n\t\t\tfor ( let i = 0; i < cols; i ++ ) {\n\n\t\t\t\tfor ( let j = 0; j < 2 * ( cols - i ) - 1; j ++ ) {\n\n\t\t\t\t\tconst k = Math.floor( j / 2 );\n\n\t\t\t\t\tif ( j % 2 === 0 ) {\n\n\t\t\t\t\t\tpushVertex( v[ i ][ k + 1 ] );\n\t\t\t\t\t\tpushVertex( v[ i + 1 ][ k ] );\n\t\t\t\t\t\tpushVertex( v[ i ][ k ] );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tpushVertex( v[ i ][ k + 1 ] );\n\t\t\t\t\t\tpushVertex( v[ i + 1 ][ k + 1 ] );\n\t\t\t\t\t\tpushVertex( v[ i + 1 ][ k ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction applyRadius( radius ) {\n\n\t\t\tconst vertex = new Vector3();\n\n\t\t\t// iterate over the entire buffer and apply the radius to each vertex\n\n\t\t\tfor ( let i = 0; i < vertexBuffer.length; i += 3 ) {\n\n\t\t\t\tvertex.x = vertexBuffer[ i + 0 ];\n\t\t\t\tvertex.y = vertexBuffer[ i + 1 ];\n\t\t\t\tvertex.z = vertexBuffer[ i + 2 ];\n\n\t\t\t\tvertex.normalize().multiplyScalar( radius );\n\n\t\t\t\tvertexBuffer[ i + 0 ] = vertex.x;\n\t\t\t\tvertexBuffer[ i + 1 ] = vertex.y;\n\t\t\t\tvertexBuffer[ i + 2 ] = vertex.z;\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction generateUVs() {\n\n\t\t\tconst vertex = new Vector3();\n\n\t\t\tfor ( let i = 0; i < vertexBuffer.length; i += 3 ) {\n\n\t\t\t\tvertex.x = vertexBuffer[ i + 0 ];\n\t\t\t\tvertex.y = vertexBuffer[ i + 1 ];\n\t\t\t\tvertex.z = vertexBuffer[ i + 2 ];\n\n\t\t\t\tconst u = azimuth( vertex ) / 2 / Math.PI + 0.5;\n\t\t\t\tconst v = inclination( vertex ) / Math.PI + 0.5;\n\t\t\t\tuvBuffer.push( u, 1 - v );\n\n\t\t\t}\n\n\t\t\tcorrectUVs();\n\n\t\t\tcorrectSeam();\n\n\t\t}\n\n\t\tfunction correctSeam() {\n\n\t\t\t// handle case when face straddles the seam, see #3269\n\n\t\t\tfor ( let i = 0; i < uvBuffer.length; i += 6 ) {\n\n\t\t\t\t// uv data of a single face\n\n\t\t\t\tconst x0 = uvBuffer[ i + 0 ];\n\t\t\t\tconst x1 = uvBuffer[ i + 2 ];\n\t\t\t\tconst x2 = uvBuffer[ i + 4 ];\n\n\t\t\t\tconst max = Math.max( x0, x1, x2 );\n\t\t\t\tconst min = Math.min( x0, x1, x2 );\n\n\t\t\t\t// 0.9 is somewhat arbitrary\n\n\t\t\t\tif ( max > 0.9 && min < 0.1 ) {\n\n\t\t\t\t\tif ( x0 < 0.2 ) uvBuffer[ i + 0 ] += 1;\n\t\t\t\t\tif ( x1 < 0.2 ) uvBuffer[ i + 2 ] += 1;\n\t\t\t\t\tif ( x2 < 0.2 ) uvBuffer[ i + 4 ] += 1;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction pushVertex( vertex ) {\n\n\t\t\tvertexBuffer.push( vertex.x, vertex.y, vertex.z );\n\n\t\t}\n\n\t\tfunction getVertexByIndex( index, vertex ) {\n\n\t\t\tconst stride = index * 3;\n\n\t\t\tvertex.x = vertices[ stride + 0 ];\n\t\t\tvertex.y = vertices[ stride + 1 ];\n\t\t\tvertex.z = vertices[ stride + 2 ];\n\n\t\t}\n\n\t\tfunction correctUVs() {\n\n\t\t\tconst a = new Vector3();\n\t\t\tconst b = new Vector3();\n\t\t\tconst c = new Vector3();\n\n\t\t\tconst centroid = new Vector3();\n\n\t\t\tconst uvA = new Vector2();\n\t\t\tconst uvB = new Vector2();\n\t\t\tconst uvC = new Vector2();\n\n\t\t\tfor ( let i = 0, j = 0; i < vertexBuffer.length; i += 9, j += 6 ) {\n\n\t\t\t\ta.set( vertexBuffer[ i + 0 ], vertexBuffer[ i + 1 ], vertexBuffer[ i + 2 ] );\n\t\t\t\tb.set( vertexBuffer[ i + 3 ], vertexBuffer[ i + 4 ], vertexBuffer[ i + 5 ] );\n\t\t\t\tc.set( vertexBuffer[ i + 6 ], vertexBuffer[ i + 7 ], vertexBuffer[ i + 8 ] );\n\n\t\t\t\tuvA.set( uvBuffer[ j + 0 ], uvBuffer[ j + 1 ] );\n\t\t\t\tuvB.set( uvBuffer[ j + 2 ], uvBuffer[ j + 3 ] );\n\t\t\t\tuvC.set( uvBuffer[ j + 4 ], uvBuffer[ j + 5 ] );\n\n\t\t\t\tcentroid.copy( a ).add( b ).add( c ).divideScalar( 3 );\n\n\t\t\t\tconst azi = azimuth( centroid );\n\n\t\t\t\tcorrectUV( uvA, j + 0, a, azi );\n\t\t\t\tcorrectUV( uvB, j + 2, b, azi );\n\t\t\t\tcorrectUV( uvC, j + 4, c, azi );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction correctUV( uv, stride, vector, azimuth ) {\n\n\t\t\tif ( ( azimuth < 0 ) && ( uv.x === 1 ) ) {\n\n\t\t\t\tuvBuffer[ stride ] = uv.x - 1;\n\n\t\t\t}\n\n\t\t\tif ( ( vector.x === 0 ) && ( vector.z === 0 ) ) {\n\n\t\t\t\tuvBuffer[ stride ] = azimuth / 2 / Math.PI + 0.5;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Angle around the Y axis, counter-clockwise when looking from above.\n\n\t\tfunction azimuth( vector ) {\n\n\t\t\treturn Math.atan2( vector.z, - vector.x );\n\n\t\t}\n\n\n\t\t// Angle above the XZ plane.\n\n\t\tfunction inclination( vector ) {\n\n\t\t\treturn Math.atan2( - vector.y, Math.sqrt( ( vector.x * vector.x ) + ( vector.z * vector.z ) ) );\n\n\t\t}\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new PolyhedronGeometry( data.vertices, data.indices, data.radius, data.details );\n\n\t}\n\n}\n\nclass DodecahedronGeometry extends PolyhedronGeometry {\n\n\tconstructor( radius = 1, detail = 0 ) {\n\n\t\tconst t = ( 1 + Math.sqrt( 5 ) ) / 2;\n\t\tconst r = 1 / t;\n\n\t\tconst vertices = [\n\n\t\t\t// (1, 1, 1)\n\t\t\t- 1, - 1, - 1,\t- 1, - 1, 1,\n\t\t\t- 1, 1, - 1, - 1, 1, 1,\n\t\t\t1, - 1, - 1, 1, - 1, 1,\n\t\t\t1, 1, - 1, 1, 1, 1,\n\n\t\t\t// (0, 1/, )\n\t\t\t0, - r, - t, 0, - r, t,\n\t\t\t0, r, - t, 0, r, t,\n\n\t\t\t// (1/, , 0)\n\t\t\t- r, - t, 0, - r, t, 0,\n\t\t\tr, - t, 0, r, t, 0,\n\n\t\t\t// (, 0, 1/)\n\t\t\t- t, 0, - r, t, 0, - r,\n\t\t\t- t, 0, r, t, 0, r\n\t\t];\n\n\t\tconst indices = [\n\t\t\t3, 11, 7, \t3, 7, 15, \t3, 15, 13,\n\t\t\t7, 19, 17, \t7, 17, 6, \t7, 6, 15,\n\t\t\t17, 4, 8, \t17, 8, 10, \t17, 10, 6,\n\t\t\t8, 0, 16, \t8, 16, 2, \t8, 2, 10,\n\t\t\t0, 12, 1, \t0, 1, 18, \t0, 18, 16,\n\t\t\t6, 10, 2, \t6, 2, 13, \t6, 13, 15,\n\t\t\t2, 16, 18, \t2, 18, 3, \t2, 3, 13,\n\t\t\t18, 1, 9, \t18, 9, 11, \t18, 11, 3,\n\t\t\t4, 14, 12, \t4, 12, 0, \t4, 0, 8,\n\t\t\t11, 9, 5, \t11, 5, 19, \t11, 19, 7,\n\t\t\t19, 5, 14, \t19, 14, 4, \t19, 4, 17,\n\t\t\t1, 12, 14, \t1, 14, 5, \t1, 5, 9\n\t\t];\n\n\t\tsuper( vertices, indices, radius, detail );\n\n\t\tthis.type = 'DodecahedronGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\tdetail: detail\n\t\t};\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new DodecahedronGeometry( data.radius, data.detail );\n\n\t}\n\n}\n\nconst _v0 = new Vector3();\nconst _v1$1 = new Vector3();\nconst _normal = new Vector3();\nconst _triangle = new Triangle();\n\nclass EdgesGeometry extends BufferGeometry {\n\n\tconstructor( geometry = null, thresholdAngle = 1 ) {\n\n\t\tsuper();\n\t\tthis.type = 'EdgesGeometry';\n\n\t\tthis.parameters = {\n\t\t\tgeometry: geometry,\n\t\t\tthresholdAngle: thresholdAngle\n\t\t};\n\n\t\tif ( geometry !== null ) {\n\n\t\t\tconst precisionPoints = 4;\n\t\t\tconst precision = Math.pow( 10, precisionPoints );\n\t\t\tconst thresholdDot = Math.cos( DEG2RAD * thresholdAngle );\n\n\t\t\tconst indexAttr = geometry.getIndex();\n\t\t\tconst positionAttr = geometry.getAttribute( 'position' );\n\t\t\tconst indexCount = indexAttr ? indexAttr.count : positionAttr.count;\n\n\t\t\tconst indexArr = [ 0, 0, 0 ];\n\t\t\tconst vertKeys = [ 'a', 'b', 'c' ];\n\t\t\tconst hashes = new Array( 3 );\n\n\t\t\tconst edgeData = {};\n\t\t\tconst vertices = [];\n\t\t\tfor ( let i = 0; i < indexCount; i += 3 ) {\n\n\t\t\t\tif ( indexAttr ) {\n\n\t\t\t\t\tindexArr[ 0 ] = indexAttr.getX( i );\n\t\t\t\t\tindexArr[ 1 ] = indexAttr.getX( i + 1 );\n\t\t\t\t\tindexArr[ 2 ] = indexAttr.getX( i + 2 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tindexArr[ 0 ] = i;\n\t\t\t\t\tindexArr[ 1 ] = i + 1;\n\t\t\t\t\tindexArr[ 2 ] = i + 2;\n\n\t\t\t\t}\n\n\t\t\t\tconst { a, b, c } = _triangle;\n\t\t\t\ta.fromBufferAttribute( positionAttr, indexArr[ 0 ] );\n\t\t\t\tb.fromBufferAttribute( positionAttr, indexArr[ 1 ] );\n\t\t\t\tc.fromBufferAttribute( positionAttr, indexArr[ 2 ] );\n\t\t\t\t_triangle.getNormal( _normal );\n\n\t\t\t\t// create hashes for the edge from the vertices\n\t\t\t\thashes[ 0 ] = `${ Math.round( a.x * precision ) },${ Math.round( a.y * precision ) },${ Math.round( a.z * precision ) }`;\n\t\t\t\thashes[ 1 ] = `${ Math.round( b.x * precision ) },${ Math.round( b.y * precision ) },${ Math.round( b.z * precision ) }`;\n\t\t\t\thashes[ 2 ] = `${ Math.round( c.x * precision ) },${ Math.round( c.y * precision ) },${ Math.round( c.z * precision ) }`;\n\n\t\t\t\t// skip degenerate triangles\n\t\t\t\tif ( hashes[ 0 ] === hashes[ 1 ] || hashes[ 1 ] === hashes[ 2 ] || hashes[ 2 ] === hashes[ 0 ] ) {\n\n\t\t\t\t\tcontinue;\n\n\t\t\t\t}\n\n\t\t\t\t// iterate over every edge\n\t\t\t\tfor ( let j = 0; j < 3; j ++ ) {\n\n\t\t\t\t\t// get the first and next vertex making up the edge\n\t\t\t\t\tconst jNext = ( j + 1 ) % 3;\n\t\t\t\t\tconst vecHash0 = hashes[ j ];\n\t\t\t\t\tconst vecHash1 = hashes[ jNext ];\n\t\t\t\t\tconst v0 = _triangle[ vertKeys[ j ] ];\n\t\t\t\t\tconst v1 = _triangle[ vertKeys[ jNext ] ];\n\n\t\t\t\t\tconst hash = `${ vecHash0 }_${ vecHash1 }`;\n\t\t\t\t\tconst reverseHash = `${ vecHash1 }_${ vecHash0 }`;\n\n\t\t\t\t\tif ( reverseHash in edgeData && edgeData[ reverseHash ] ) {\n\n\t\t\t\t\t\t// if we found a sibling edge add it into the vertex array if\n\t\t\t\t\t\t// it meets the angle threshold and delete the edge from the map.\n\t\t\t\t\t\tif ( _normal.dot( edgeData[ reverseHash ].normal ) <= thresholdDot ) {\n\n\t\t\t\t\t\t\tvertices.push( v0.x, v0.y, v0.z );\n\t\t\t\t\t\t\tvertices.push( v1.x, v1.y, v1.z );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tedgeData[ reverseHash ] = null;\n\n\t\t\t\t\t} else if ( ! ( hash in edgeData ) ) {\n\n\t\t\t\t\t\t// if we've already got an edge here then skip adding a new one\n\t\t\t\t\t\tedgeData[ hash ] = {\n\n\t\t\t\t\t\t\tindex0: indexArr[ j ],\n\t\t\t\t\t\t\tindex1: indexArr[ jNext ],\n\t\t\t\t\t\t\tnormal: _normal.clone(),\n\n\t\t\t\t\t\t};\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// iterate over all remaining, unmatched edges and add them to the vertex array\n\t\t\tfor ( const key in edgeData ) {\n\n\t\t\t\tif ( edgeData[ key ] ) {\n\n\t\t\t\t\tconst { index0, index1 } = edgeData[ key ];\n\t\t\t\t\t_v0.fromBufferAttribute( positionAttr, index0 );\n\t\t\t\t\t_v1$1.fromBufferAttribute( positionAttr, index1 );\n\n\t\t\t\t\tvertices.push( _v0.x, _v0.y, _v0.z );\n\t\t\t\t\tvertices.push( _v1$1.x, _v1$1.y, _v1$1.z );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\n\t\t}\n\n\t}\n\n}\n\n/**\n * Extensible curve object.\n *\n * Some common of curve methods:\n * .getPoint( t, optionalTarget ), .getTangent( t, optionalTarget )\n * .getPointAt( u, optionalTarget ), .getTangentAt( u, optionalTarget )\n * .getPoints(), .getSpacedPoints()\n * .getLength()\n * .updateArcLengths()\n *\n * This following curves inherit from THREE.Curve:\n *\n * -- 2D curves --\n * THREE.ArcCurve\n * THREE.CubicBezierCurve\n * THREE.EllipseCurve\n * THREE.LineCurve\n * THREE.QuadraticBezierCurve\n * THREE.SplineCurve\n *\n * -- 3D curves --\n * THREE.CatmullRomCurve3\n * THREE.CubicBezierCurve3\n * THREE.LineCurve3\n * THREE.QuadraticBezierCurve3\n *\n * A series of curves can be represented as a THREE.CurvePath.\n *\n **/\n\nclass Curve {\n\n\tconstructor() {\n\n\t\tthis.type = 'Curve';\n\n\t\tthis.arcLengthDivisions = 200;\n\n\t}\n\n\t// Virtual base class method to overwrite and implement in subclasses\n\t//\t- t [0 .. 1]\n\n\tgetPoint( /* t, optionalTarget */ ) {\n\n\t\tconsole.warn( 'THREE.Curve: .getPoint() not implemented.' );\n\t\treturn null;\n\n\t}\n\n\t// Get point at relative position in curve according to arc length\n\t// - u [0 .. 1]\n\n\tgetPointAt( u, optionalTarget ) {\n\n\t\tconst t = this.getUtoTmapping( u );\n\t\treturn this.getPoint( t, optionalTarget );\n\n\t}\n\n\t// Get sequence of points using getPoint( t )\n\n\tgetPoints( divisions = 5 ) {\n\n\t\tconst points = [];\n\n\t\tfor ( let d = 0; d <= divisions; d ++ ) {\n\n\t\t\tpoints.push( this.getPoint( d / divisions ) );\n\n\t\t}\n\n\t\treturn points;\n\n\t}\n\n\t// Get sequence of points using getPointAt( u )\n\n\tgetSpacedPoints( divisions = 5 ) {\n\n\t\tconst points = [];\n\n\t\tfor ( let d = 0; d <= divisions; d ++ ) {\n\n\t\t\tpoints.push( this.getPointAt( d / divisions ) );\n\n\t\t}\n\n\t\treturn points;\n\n\t}\n\n\t// Get total curve arc length\n\n\tgetLength() {\n\n\t\tconst lengths = this.getLengths();\n\t\treturn lengths[ lengths.length - 1 ];\n\n\t}\n\n\t// Get list of cumulative segment lengths\n\n\tgetLengths( divisions = this.arcLengthDivisions ) {\n\n\t\tif ( this.cacheArcLengths &&\n\t\t\t( this.cacheArcLengths.length === divisions + 1 ) &&\n\t\t\t! this.needsUpdate ) {\n\n\t\t\treturn this.cacheArcLengths;\n\n\t\t}\n\n\t\tthis.needsUpdate = false;\n\n\t\tconst cache = [];\n\t\tlet current, last = this.getPoint( 0 );\n\t\tlet sum = 0;\n\n\t\tcache.push( 0 );\n\n\t\tfor ( let p = 1; p <= divisions; p ++ ) {\n\n\t\t\tcurrent = this.getPoint( p / divisions );\n\t\t\tsum += current.distanceTo( last );\n\t\t\tcache.push( sum );\n\t\t\tlast = current;\n\n\t\t}\n\n\t\tthis.cacheArcLengths = cache;\n\n\t\treturn cache; // { sums: cache, sum: sum }; Sum is in the last element.\n\n\t}\n\n\tupdateArcLengths() {\n\n\t\tthis.needsUpdate = true;\n\t\tthis.getLengths();\n\n\t}\n\n\t// Given u ( 0 .. 1 ), get a t to find p. This gives you points which are equidistant\n\n\tgetUtoTmapping( u, distance ) {\n\n\t\tconst arcLengths = this.getLengths();\n\n\t\tlet i = 0;\n\t\tconst il = arcLengths.length;\n\n\t\tlet targetArcLength; // The targeted u distance value to get\n\n\t\tif ( distance ) {\n\n\t\t\ttargetArcLength = distance;\n\n\t\t} else {\n\n\t\t\ttargetArcLength = u * arcLengths[ il - 1 ];\n\n\t\t}\n\n\t\t// binary search for the index with largest value smaller than target u distance\n\n\t\tlet low = 0, high = il - 1, comparison;\n\n\t\twhile ( low <= high ) {\n\n\t\t\ti = Math.floor( low + ( high - low ) / 2 ); // less likely to overflow, though probably not issue here, JS doesn't really have integers, all numbers are floats\n\n\t\t\tcomparison = arcLengths[ i ] - targetArcLength;\n\n\t\t\tif ( comparison < 0 ) {\n\n\t\t\t\tlow = i + 1;\n\n\t\t\t} else if ( comparison > 0 ) {\n\n\t\t\t\thigh = i - 1;\n\n\t\t\t} else {\n\n\t\t\t\thigh = i;\n\t\t\t\tbreak;\n\n\t\t\t\t// DONE\n\n\t\t\t}\n\n\t\t}\n\n\t\ti = high;\n\n\t\tif ( arcLengths[ i ] === targetArcLength ) {\n\n\t\t\treturn i / ( il - 1 );\n\n\t\t}\n\n\t\t// we could get finer grain at lengths, or use simple interpolation between two points\n\n\t\tconst lengthBefore = arcLengths[ i ];\n\t\tconst lengthAfter = arcLengths[ i + 1 ];\n\n\t\tconst segmentLength = lengthAfter - lengthBefore;\n\n\t\t// determine where we are between the 'before' and 'after' points\n\n\t\tconst segmentFraction = ( targetArcLength - lengthBefore ) / segmentLength;\n\n\t\t// add that fractional amount to t\n\n\t\tconst t = ( i + segmentFraction ) / ( il - 1 );\n\n\t\treturn t;\n\n\t}\n\n\t// Returns a unit vector tangent at t\n\t// In case any sub curve does not implement its tangent derivation,\n\t// 2 points a small delta apart will be used to find its gradient\n\t// which seems to give a reasonable approximation\n\n\tgetTangent( t, optionalTarget ) {\n\n\t\tconst delta = 0.0001;\n\t\tlet t1 = t - delta;\n\t\tlet t2 = t + delta;\n\n\t\t// Capping in case of danger\n\n\t\tif ( t1 < 0 ) t1 = 0;\n\t\tif ( t2 > 1 ) t2 = 1;\n\n\t\tconst pt1 = this.getPoint( t1 );\n\t\tconst pt2 = this.getPoint( t2 );\n\n\t\tconst tangent = optionalTarget || ( ( pt1.isVector2 ) ? new Vector2() : new Vector3() );\n\n\t\ttangent.copy( pt2 ).sub( pt1 ).normalize();\n\n\t\treturn tangent;\n\n\t}\n\n\tgetTangentAt( u, optionalTarget ) {\n\n\t\tconst t = this.getUtoTmapping( u );\n\t\treturn this.getTangent( t, optionalTarget );\n\n\t}\n\n\tcomputeFrenetFrames( segments, closed ) {\n\n\t\t// see http://www.cs.indiana.edu/pub/techreports/TR425.pdf\n\n\t\tconst normal = new Vector3();\n\n\t\tconst tangents = [];\n\t\tconst normals = [];\n\t\tconst binormals = [];\n\n\t\tconst vec = new Vector3();\n\t\tconst mat = new Matrix4();\n\n\t\t// compute the tangent vectors for each segment on the curve\n\n\t\tfor ( let i = 0; i <= segments; i ++ ) {\n\n\t\t\tconst u = i / segments;\n\n\t\t\ttangents[ i ] = this.getTangentAt( u, new Vector3() );\n\n\t\t}\n\n\t\t// select an initial normal vector perpendicular to the first tangent vector,\n\t\t// and in the direction of the minimum tangent xyz component\n\n\t\tnormals[ 0 ] = new Vector3();\n\t\tbinormals[ 0 ] = new Vector3();\n\t\tlet min = Number.MAX_VALUE;\n\t\tconst tx = Math.abs( tangents[ 0 ].x );\n\t\tconst ty = Math.abs( tangents[ 0 ].y );\n\t\tconst tz = Math.abs( tangents[ 0 ].z );\n\n\t\tif ( tx <= min ) {\n\n\t\t\tmin = tx;\n\t\t\tnormal.set( 1, 0, 0 );\n\n\t\t}\n\n\t\tif ( ty <= min ) {\n\n\t\t\tmin = ty;\n\t\t\tnormal.set( 0, 1, 0 );\n\n\t\t}\n\n\t\tif ( tz <= min ) {\n\n\t\t\tnormal.set( 0, 0, 1 );\n\n\t\t}\n\n\t\tvec.crossVectors( tangents[ 0 ], normal ).normalize();\n\n\t\tnormals[ 0 ].crossVectors( tangents[ 0 ], vec );\n\t\tbinormals[ 0 ].crossVectors( tangents[ 0 ], normals[ 0 ] );\n\n\n\t\t// compute the slowly-varying normal and binormal vectors for each segment on the curve\n\n\t\tfor ( let i = 1; i <= segments; i ++ ) {\n\n\t\t\tnormals[ i ] = normals[ i - 1 ].clone();\n\n\t\t\tbinormals[ i ] = binormals[ i - 1 ].clone();\n\n\t\t\tvec.crossVectors( tangents[ i - 1 ], tangents[ i ] );\n\n\t\t\tif ( vec.length() > Number.EPSILON ) {\n\n\t\t\t\tvec.normalize();\n\n\t\t\t\tconst theta = Math.acos( clamp( tangents[ i - 1 ].dot( tangents[ i ] ), - 1, 1 ) ); // clamp for floating pt errors\n\n\t\t\t\tnormals[ i ].applyMatrix4( mat.makeRotationAxis( vec, theta ) );\n\n\t\t\t}\n\n\t\t\tbinormals[ i ].crossVectors( tangents[ i ], normals[ i ] );\n\n\t\t}\n\n\t\t// if the curve is closed, postprocess the vectors so the first and last normal vectors are the same\n\n\t\tif ( closed === true ) {\n\n\t\t\tlet theta = Math.acos( clamp( normals[ 0 ].dot( normals[ segments ] ), - 1, 1 ) );\n\t\t\ttheta /= segments;\n\n\t\t\tif ( tangents[ 0 ].dot( vec.crossVectors( normals[ 0 ], normals[ segments ] ) ) > 0 ) {\n\n\t\t\t\ttheta = - theta;\n\n\t\t\t}\n\n\t\t\tfor ( let i = 1; i <= segments; i ++ ) {\n\n\t\t\t\t// twist a little...\n\t\t\t\tnormals[ i ].applyMatrix4( mat.makeRotationAxis( tangents[ i ], theta * i ) );\n\t\t\t\tbinormals[ i ].crossVectors( tangents[ i ], normals[ i ] );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn {\n\t\t\ttangents: tangents,\n\t\t\tnormals: normals,\n\t\t\tbinormals: binormals\n\t\t};\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.arcLengthDivisions = source.arcLengthDivisions;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = {\n\t\t\tmetadata: {\n\t\t\t\tversion: 4.5,\n\t\t\t\ttype: 'Curve',\n\t\t\t\tgenerator: 'Curve.toJSON'\n\t\t\t}\n\t\t};\n\n\t\tdata.arcLengthDivisions = this.arcLengthDivisions;\n\t\tdata.type = this.type;\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tthis.arcLengthDivisions = json.arcLengthDivisions;\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass EllipseCurve extends Curve {\n\n\tconstructor( aX = 0, aY = 0, xRadius = 1, yRadius = 1, aStartAngle = 0, aEndAngle = Math.PI * 2, aClockwise = false, aRotation = 0 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'EllipseCurve';\n\n\t\tthis.aX = aX;\n\t\tthis.aY = aY;\n\n\t\tthis.xRadius = xRadius;\n\t\tthis.yRadius = yRadius;\n\n\t\tthis.aStartAngle = aStartAngle;\n\t\tthis.aEndAngle = aEndAngle;\n\n\t\tthis.aClockwise = aClockwise;\n\n\t\tthis.aRotation = aRotation;\n\n\t}\n\n\tgetPoint( t, optionalTarget ) {\n\n\t\tconst point = optionalTarget || new Vector2();\n\n\t\tconst twoPi = Math.PI * 2;\n\t\tlet deltaAngle = this.aEndAngle - this.aStartAngle;\n\t\tconst samePoints = Math.abs( deltaAngle ) < Number.EPSILON;\n\n\t\t// ensures that deltaAngle is 0 .. 2 PI\n\t\twhile ( deltaAngle < 0 ) deltaAngle += twoPi;\n\t\twhile ( deltaAngle > twoPi ) deltaAngle -= twoPi;\n\n\t\tif ( deltaAngle < Number.EPSILON ) {\n\n\t\t\tif ( samePoints ) {\n\n\t\t\t\tdeltaAngle = 0;\n\n\t\t\t} else {\n\n\t\t\t\tdeltaAngle = twoPi;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( this.aClockwise === true && ! samePoints ) {\n\n\t\t\tif ( deltaAngle === twoPi ) {\n\n\t\t\t\tdeltaAngle = - twoPi;\n\n\t\t\t} else {\n\n\t\t\t\tdeltaAngle = deltaAngle - twoPi;\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst angle = this.aStartAngle + t * deltaAngle;\n\t\tlet x = this.aX + this.xRadius * Math.cos( angle );\n\t\tlet y = this.aY + this.yRadius * Math.sin( angle );\n\n\t\tif ( this.aRotation !== 0 ) {\n\n\t\t\tconst cos = Math.cos( this.aRotation );\n\t\t\tconst sin = Math.sin( this.aRotation );\n\n\t\t\tconst tx = x - this.aX;\n\t\t\tconst ty = y - this.aY;\n\n\t\t\t// Rotate the point about the center of the ellipse.\n\t\t\tx = tx * cos - ty * sin + this.aX;\n\t\t\ty = tx * sin + ty * cos + this.aY;\n\n\t\t}\n\n\t\treturn point.set( x, y );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.aX = source.aX;\n\t\tthis.aY = source.aY;\n\n\t\tthis.xRadius = source.xRadius;\n\t\tthis.yRadius = source.yRadius;\n\n\t\tthis.aStartAngle = source.aStartAngle;\n\t\tthis.aEndAngle = source.aEndAngle;\n\n\t\tthis.aClockwise = source.aClockwise;\n\n\t\tthis.aRotation = source.aRotation;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.aX = this.aX;\n\t\tdata.aY = this.aY;\n\n\t\tdata.xRadius = this.xRadius;\n\t\tdata.yRadius = this.yRadius;\n\n\t\tdata.aStartAngle = this.aStartAngle;\n\t\tdata.aEndAngle = this.aEndAngle;\n\n\t\tdata.aClockwise = this.aClockwise;\n\n\t\tdata.aRotation = this.aRotation;\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.aX = json.aX;\n\t\tthis.aY = json.aY;\n\n\t\tthis.xRadius = json.xRadius;\n\t\tthis.yRadius = json.yRadius;\n\n\t\tthis.aStartAngle = json.aStartAngle;\n\t\tthis.aEndAngle = json.aEndAngle;\n\n\t\tthis.aClockwise = json.aClockwise;\n\n\t\tthis.aRotation = json.aRotation;\n\n\t\treturn this;\n\n\t}\n\n}\n\nEllipseCurve.prototype.isEllipseCurve = true;\n\nclass ArcCurve extends EllipseCurve {\n\n\tconstructor( aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise ) {\n\n\t\tsuper( aX, aY, aRadius, aRadius, aStartAngle, aEndAngle, aClockwise );\n\n\t\tthis.type = 'ArcCurve';\n\n\t}\n\n}\n\nArcCurve.prototype.isArcCurve = true;\n\n/**\n * Centripetal CatmullRom Curve - which is useful for avoiding\n * cusps and self-intersections in non-uniform catmull rom curves.\n * http://www.cemyuksel.com/research/catmullrom_param/catmullrom.pdf\n *\n * curve.type accepts centripetal(default), chordal and catmullrom\n * curve.tension is used for catmullrom which defaults to 0.5\n */\n\n\n/*\nBased on an optimized c++ solution in\n - http://stackoverflow.com/questions/9489736/catmull-rom-curve-with-no-cusps-and-no-self-intersections/\n - http://ideone.com/NoEbVM\n\nThis CubicPoly class could be used for reusing some variables and calculations,\nbut for three.js curve use, it could be possible inlined and flatten into a single function call\nwhich can be placed in CurveUtils.\n*/\n\nfunction CubicPoly() {\n\n\tlet c0 = 0, c1 = 0, c2 = 0, c3 = 0;\n\n\t/*\n\t * Compute coefficients for a cubic polynomial\n\t *   p(s) = c0 + c1*s + c2*s^2 + c3*s^3\n\t * such that\n\t *   p(0) = x0, p(1) = x1\n\t *  and\n\t *   p'(0) = t0, p'(1) = t1.\n\t */\n\tfunction init( x0, x1, t0, t1 ) {\n\n\t\tc0 = x0;\n\t\tc1 = t0;\n\t\tc2 = - 3 * x0 + 3 * x1 - 2 * t0 - t1;\n\t\tc3 = 2 * x0 - 2 * x1 + t0 + t1;\n\n\t}\n\n\treturn {\n\n\t\tinitCatmullRom: function ( x0, x1, x2, x3, tension ) {\n\n\t\t\tinit( x1, x2, tension * ( x2 - x0 ), tension * ( x3 - x1 ) );\n\n\t\t},\n\n\t\tinitNonuniformCatmullRom: function ( x0, x1, x2, x3, dt0, dt1, dt2 ) {\n\n\t\t\t// compute tangents when parameterized in [t1,t2]\n\t\t\tlet t1 = ( x1 - x0 ) / dt0 - ( x2 - x0 ) / ( dt0 + dt1 ) + ( x2 - x1 ) / dt1;\n\t\t\tlet t2 = ( x2 - x1 ) / dt1 - ( x3 - x1 ) / ( dt1 + dt2 ) + ( x3 - x2 ) / dt2;\n\n\t\t\t// rescale tangents for parametrization in [0,1]\n\t\t\tt1 *= dt1;\n\t\t\tt2 *= dt1;\n\n\t\t\tinit( x1, x2, t1, t2 );\n\n\t\t},\n\n\t\tcalc: function ( t ) {\n\n\t\t\tconst t2 = t * t;\n\t\t\tconst t3 = t2 * t;\n\t\t\treturn c0 + c1 * t + c2 * t2 + c3 * t3;\n\n\t\t}\n\n\t};\n\n}\n\n//\n\nconst tmp = new Vector3();\nconst px = new CubicPoly(), py = new CubicPoly(), pz = new CubicPoly();\n\nclass CatmullRomCurve3 extends Curve {\n\n\tconstructor( points = [], closed = false, curveType = 'centripetal', tension = 0.5 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'CatmullRomCurve3';\n\n\t\tthis.points = points;\n\t\tthis.closed = closed;\n\t\tthis.curveType = curveType;\n\t\tthis.tension = tension;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector3() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tconst points = this.points;\n\t\tconst l = points.length;\n\n\t\tconst p = ( l - ( this.closed ? 0 : 1 ) ) * t;\n\t\tlet intPoint = Math.floor( p );\n\t\tlet weight = p - intPoint;\n\n\t\tif ( this.closed ) {\n\n\t\t\tintPoint += intPoint > 0 ? 0 : ( Math.floor( Math.abs( intPoint ) / l ) + 1 ) * l;\n\n\t\t} else if ( weight === 0 && intPoint === l - 1 ) {\n\n\t\t\tintPoint = l - 2;\n\t\t\tweight = 1;\n\n\t\t}\n\n\t\tlet p0, p3; // 4 points (p1 & p2 defined below)\n\n\t\tif ( this.closed || intPoint > 0 ) {\n\n\t\t\tp0 = points[ ( intPoint - 1 ) % l ];\n\n\t\t} else {\n\n\t\t\t// extrapolate first point\n\t\t\ttmp.subVectors( points[ 0 ], points[ 1 ] ).add( points[ 0 ] );\n\t\t\tp0 = tmp;\n\n\t\t}\n\n\t\tconst p1 = points[ intPoint % l ];\n\t\tconst p2 = points[ ( intPoint + 1 ) % l ];\n\n\t\tif ( this.closed || intPoint + 2 < l ) {\n\n\t\t\tp3 = points[ ( intPoint + 2 ) % l ];\n\n\t\t} else {\n\n\t\t\t// extrapolate last point\n\t\t\ttmp.subVectors( points[ l - 1 ], points[ l - 2 ] ).add( points[ l - 1 ] );\n\t\t\tp3 = tmp;\n\n\t\t}\n\n\t\tif ( this.curveType === 'centripetal' || this.curveType === 'chordal' ) {\n\n\t\t\t// init Centripetal / Chordal Catmull-Rom\n\t\t\tconst pow = this.curveType === 'chordal' ? 0.5 : 0.25;\n\t\t\tlet dt0 = Math.pow( p0.distanceToSquared( p1 ), pow );\n\t\t\tlet dt1 = Math.pow( p1.distanceToSquared( p2 ), pow );\n\t\t\tlet dt2 = Math.pow( p2.distanceToSquared( p3 ), pow );\n\n\t\t\t// safety check for repeated points\n\t\t\tif ( dt1 < 1e-4 ) dt1 = 1.0;\n\t\t\tif ( dt0 < 1e-4 ) dt0 = dt1;\n\t\t\tif ( dt2 < 1e-4 ) dt2 = dt1;\n\n\t\t\tpx.initNonuniformCatmullRom( p0.x, p1.x, p2.x, p3.x, dt0, dt1, dt2 );\n\t\t\tpy.initNonuniformCatmullRom( p0.y, p1.y, p2.y, p3.y, dt0, dt1, dt2 );\n\t\t\tpz.initNonuniformCatmullRom( p0.z, p1.z, p2.z, p3.z, dt0, dt1, dt2 );\n\n\t\t} else if ( this.curveType === 'catmullrom' ) {\n\n\t\t\tpx.initCatmullRom( p0.x, p1.x, p2.x, p3.x, this.tension );\n\t\t\tpy.initCatmullRom( p0.y, p1.y, p2.y, p3.y, this.tension );\n\t\t\tpz.initCatmullRom( p0.z, p1.z, p2.z, p3.z, this.tension );\n\n\t\t}\n\n\t\tpoint.set(\n\t\t\tpx.calc( weight ),\n\t\t\tpy.calc( weight ),\n\t\t\tpz.calc( weight )\n\t\t);\n\n\t\treturn point;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.points = [];\n\n\t\tfor ( let i = 0, l = source.points.length; i < l; i ++ ) {\n\n\t\t\tconst point = source.points[ i ];\n\n\t\t\tthis.points.push( point.clone() );\n\n\t\t}\n\n\t\tthis.closed = source.closed;\n\t\tthis.curveType = source.curveType;\n\t\tthis.tension = source.tension;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.points = [];\n\n\t\tfor ( let i = 0, l = this.points.length; i < l; i ++ ) {\n\n\t\t\tconst point = this.points[ i ];\n\t\t\tdata.points.push( point.toArray() );\n\n\t\t}\n\n\t\tdata.closed = this.closed;\n\t\tdata.curveType = this.curveType;\n\t\tdata.tension = this.tension;\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.points = [];\n\n\t\tfor ( let i = 0, l = json.points.length; i < l; i ++ ) {\n\n\t\t\tconst point = json.points[ i ];\n\t\t\tthis.points.push( new Vector3().fromArray( point ) );\n\n\t\t}\n\n\t\tthis.closed = json.closed;\n\t\tthis.curveType = json.curveType;\n\t\tthis.tension = json.tension;\n\n\t\treturn this;\n\n\t}\n\n}\n\nCatmullRomCurve3.prototype.isCatmullRomCurve3 = true;\n\n/**\n * Bezier Curves formulas obtained from\n * https://en.wikipedia.org/wiki/B%C3%A9zier_curve\n */\n\nfunction CatmullRom( t, p0, p1, p2, p3 ) {\n\n\tconst v0 = ( p2 - p0 ) * 0.5;\n\tconst v1 = ( p3 - p1 ) * 0.5;\n\tconst t2 = t * t;\n\tconst t3 = t * t2;\n\treturn ( 2 * p1 - 2 * p2 + v0 + v1 ) * t3 + ( - 3 * p1 + 3 * p2 - 2 * v0 - v1 ) * t2 + v0 * t + p1;\n\n}\n\n//\n\nfunction QuadraticBezierP0( t, p ) {\n\n\tconst k = 1 - t;\n\treturn k * k * p;\n\n}\n\nfunction QuadraticBezierP1( t, p ) {\n\n\treturn 2 * ( 1 - t ) * t * p;\n\n}\n\nfunction QuadraticBezierP2( t, p ) {\n\n\treturn t * t * p;\n\n}\n\nfunction QuadraticBezier( t, p0, p1, p2 ) {\n\n\treturn QuadraticBezierP0( t, p0 ) + QuadraticBezierP1( t, p1 ) +\n\t\tQuadraticBezierP2( t, p2 );\n\n}\n\n//\n\nfunction CubicBezierP0( t, p ) {\n\n\tconst k = 1 - t;\n\treturn k * k * k * p;\n\n}\n\nfunction CubicBezierP1( t, p ) {\n\n\tconst k = 1 - t;\n\treturn 3 * k * k * t * p;\n\n}\n\nfunction CubicBezierP2( t, p ) {\n\n\treturn 3 * ( 1 - t ) * t * t * p;\n\n}\n\nfunction CubicBezierP3( t, p ) {\n\n\treturn t * t * t * p;\n\n}\n\nfunction CubicBezier( t, p0, p1, p2, p3 ) {\n\n\treturn CubicBezierP0( t, p0 ) + CubicBezierP1( t, p1 ) + CubicBezierP2( t, p2 ) +\n\t\tCubicBezierP3( t, p3 );\n\n}\n\nclass CubicBezierCurve extends Curve {\n\n\tconstructor( v0 = new Vector2(), v1 = new Vector2(), v2 = new Vector2(), v3 = new Vector2() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'CubicBezierCurve';\n\n\t\tthis.v0 = v0;\n\t\tthis.v1 = v1;\n\t\tthis.v2 = v2;\n\t\tthis.v3 = v3;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector2() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tconst v0 = this.v0, v1 = this.v1, v2 = this.v2, v3 = this.v3;\n\n\t\tpoint.set(\n\t\t\tCubicBezier( t, v0.x, v1.x, v2.x, v3.x ),\n\t\t\tCubicBezier( t, v0.y, v1.y, v2.y, v3.y )\n\t\t);\n\n\t\treturn point;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.v0.copy( source.v0 );\n\t\tthis.v1.copy( source.v1 );\n\t\tthis.v2.copy( source.v2 );\n\t\tthis.v3.copy( source.v3 );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.v0 = this.v0.toArray();\n\t\tdata.v1 = this.v1.toArray();\n\t\tdata.v2 = this.v2.toArray();\n\t\tdata.v3 = this.v3.toArray();\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.v0.fromArray( json.v0 );\n\t\tthis.v1.fromArray( json.v1 );\n\t\tthis.v2.fromArray( json.v2 );\n\t\tthis.v3.fromArray( json.v3 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nCubicBezierCurve.prototype.isCubicBezierCurve = true;\n\nclass CubicBezierCurve3 extends Curve {\n\n\tconstructor( v0 = new Vector3(), v1 = new Vector3(), v2 = new Vector3(), v3 = new Vector3() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'CubicBezierCurve3';\n\n\t\tthis.v0 = v0;\n\t\tthis.v1 = v1;\n\t\tthis.v2 = v2;\n\t\tthis.v3 = v3;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector3() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tconst v0 = this.v0, v1 = this.v1, v2 = this.v2, v3 = this.v3;\n\n\t\tpoint.set(\n\t\t\tCubicBezier( t, v0.x, v1.x, v2.x, v3.x ),\n\t\t\tCubicBezier( t, v0.y, v1.y, v2.y, v3.y ),\n\t\t\tCubicBezier( t, v0.z, v1.z, v2.z, v3.z )\n\t\t);\n\n\t\treturn point;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.v0.copy( source.v0 );\n\t\tthis.v1.copy( source.v1 );\n\t\tthis.v2.copy( source.v2 );\n\t\tthis.v3.copy( source.v3 );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.v0 = this.v0.toArray();\n\t\tdata.v1 = this.v1.toArray();\n\t\tdata.v2 = this.v2.toArray();\n\t\tdata.v3 = this.v3.toArray();\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.v0.fromArray( json.v0 );\n\t\tthis.v1.fromArray( json.v1 );\n\t\tthis.v2.fromArray( json.v2 );\n\t\tthis.v3.fromArray( json.v3 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nCubicBezierCurve3.prototype.isCubicBezierCurve3 = true;\n\nclass LineCurve extends Curve {\n\n\tconstructor( v1 = new Vector2(), v2 = new Vector2() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'LineCurve';\n\n\t\tthis.v1 = v1;\n\t\tthis.v2 = v2;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector2() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tif ( t === 1 ) {\n\n\t\t\tpoint.copy( this.v2 );\n\n\t\t} else {\n\n\t\t\tpoint.copy( this.v2 ).sub( this.v1 );\n\t\t\tpoint.multiplyScalar( t ).add( this.v1 );\n\n\t\t}\n\n\t\treturn point;\n\n\t}\n\n\t// Line curve is linear, so we can overwrite default getPointAt\n\tgetPointAt( u, optionalTarget ) {\n\n\t\treturn this.getPoint( u, optionalTarget );\n\n\t}\n\n\tgetTangent( t, optionalTarget ) {\n\n\t\tconst tangent = optionalTarget || new Vector2();\n\n\t\ttangent.copy( this.v2 ).sub( this.v1 ).normalize();\n\n\t\treturn tangent;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.v1.copy( source.v1 );\n\t\tthis.v2.copy( source.v2 );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.v1 = this.v1.toArray();\n\t\tdata.v2 = this.v2.toArray();\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.v1.fromArray( json.v1 );\n\t\tthis.v2.fromArray( json.v2 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nLineCurve.prototype.isLineCurve = true;\n\nclass LineCurve3 extends Curve {\n\n\tconstructor( v1 = new Vector3(), v2 = new Vector3() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'LineCurve3';\n\t\tthis.isLineCurve3 = true;\n\n\t\tthis.v1 = v1;\n\t\tthis.v2 = v2;\n\n\t}\n\tgetPoint( t, optionalTarget = new Vector3() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tif ( t === 1 ) {\n\n\t\t\tpoint.copy( this.v2 );\n\n\t\t} else {\n\n\t\t\tpoint.copy( this.v2 ).sub( this.v1 );\n\t\t\tpoint.multiplyScalar( t ).add( this.v1 );\n\n\t\t}\n\n\t\treturn point;\n\n\t}\n\t// Line curve is linear, so we can overwrite default getPointAt\n\tgetPointAt( u, optionalTarget ) {\n\n\t\treturn this.getPoint( u, optionalTarget );\n\n\t}\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.v1.copy( source.v1 );\n\t\tthis.v2.copy( source.v2 );\n\n\t\treturn this;\n\n\t}\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.v1 = this.v1.toArray();\n\t\tdata.v2 = this.v2.toArray();\n\n\t\treturn data;\n\n\t}\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.v1.fromArray( json.v1 );\n\t\tthis.v2.fromArray( json.v2 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass QuadraticBezierCurve extends Curve {\n\n\tconstructor( v0 = new Vector2(), v1 = new Vector2(), v2 = new Vector2() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'QuadraticBezierCurve';\n\n\t\tthis.v0 = v0;\n\t\tthis.v1 = v1;\n\t\tthis.v2 = v2;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector2() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tconst v0 = this.v0, v1 = this.v1, v2 = this.v2;\n\n\t\tpoint.set(\n\t\t\tQuadraticBezier( t, v0.x, v1.x, v2.x ),\n\t\t\tQuadraticBezier( t, v0.y, v1.y, v2.y )\n\t\t);\n\n\t\treturn point;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.v0.copy( source.v0 );\n\t\tthis.v1.copy( source.v1 );\n\t\tthis.v2.copy( source.v2 );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.v0 = this.v0.toArray();\n\t\tdata.v1 = this.v1.toArray();\n\t\tdata.v2 = this.v2.toArray();\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.v0.fromArray( json.v0 );\n\t\tthis.v1.fromArray( json.v1 );\n\t\tthis.v2.fromArray( json.v2 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nQuadraticBezierCurve.prototype.isQuadraticBezierCurve = true;\n\nclass QuadraticBezierCurve3 extends Curve {\n\n\tconstructor( v0 = new Vector3(), v1 = new Vector3(), v2 = new Vector3() ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'QuadraticBezierCurve3';\n\n\t\tthis.v0 = v0;\n\t\tthis.v1 = v1;\n\t\tthis.v2 = v2;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector3() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tconst v0 = this.v0, v1 = this.v1, v2 = this.v2;\n\n\t\tpoint.set(\n\t\t\tQuadraticBezier( t, v0.x, v1.x, v2.x ),\n\t\t\tQuadraticBezier( t, v0.y, v1.y, v2.y ),\n\t\t\tQuadraticBezier( t, v0.z, v1.z, v2.z )\n\t\t);\n\n\t\treturn point;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.v0.copy( source.v0 );\n\t\tthis.v1.copy( source.v1 );\n\t\tthis.v2.copy( source.v2 );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.v0 = this.v0.toArray();\n\t\tdata.v1 = this.v1.toArray();\n\t\tdata.v2 = this.v2.toArray();\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.v0.fromArray( json.v0 );\n\t\tthis.v1.fromArray( json.v1 );\n\t\tthis.v2.fromArray( json.v2 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nQuadraticBezierCurve3.prototype.isQuadraticBezierCurve3 = true;\n\nclass SplineCurve extends Curve {\n\n\tconstructor( points = [] ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'SplineCurve';\n\n\t\tthis.points = points;\n\n\t}\n\n\tgetPoint( t, optionalTarget = new Vector2() ) {\n\n\t\tconst point = optionalTarget;\n\n\t\tconst points = this.points;\n\t\tconst p = ( points.length - 1 ) * t;\n\n\t\tconst intPoint = Math.floor( p );\n\t\tconst weight = p - intPoint;\n\n\t\tconst p0 = points[ intPoint === 0 ? intPoint : intPoint - 1 ];\n\t\tconst p1 = points[ intPoint ];\n\t\tconst p2 = points[ intPoint > points.length - 2 ? points.length - 1 : intPoint + 1 ];\n\t\tconst p3 = points[ intPoint > points.length - 3 ? points.length - 1 : intPoint + 2 ];\n\n\t\tpoint.set(\n\t\t\tCatmullRom( weight, p0.x, p1.x, p2.x, p3.x ),\n\t\t\tCatmullRom( weight, p0.y, p1.y, p2.y, p3.y )\n\t\t);\n\n\t\treturn point;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.points = [];\n\n\t\tfor ( let i = 0, l = source.points.length; i < l; i ++ ) {\n\n\t\t\tconst point = source.points[ i ];\n\n\t\t\tthis.points.push( point.clone() );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.points = [];\n\n\t\tfor ( let i = 0, l = this.points.length; i < l; i ++ ) {\n\n\t\t\tconst point = this.points[ i ];\n\t\t\tdata.points.push( point.toArray() );\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.points = [];\n\n\t\tfor ( let i = 0, l = json.points.length; i < l; i ++ ) {\n\n\t\t\tconst point = json.points[ i ];\n\t\t\tthis.points.push( new Vector2().fromArray( point ) );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\nSplineCurve.prototype.isSplineCurve = true;\n\nvar Curves = /*#__PURE__*/Object.freeze({\n\t__proto__: null,\n\tArcCurve: ArcCurve,\n\tCatmullRomCurve3: CatmullRomCurve3,\n\tCubicBezierCurve: CubicBezierCurve,\n\tCubicBezierCurve3: CubicBezierCurve3,\n\tEllipseCurve: EllipseCurve,\n\tLineCurve: LineCurve,\n\tLineCurve3: LineCurve3,\n\tQuadraticBezierCurve: QuadraticBezierCurve,\n\tQuadraticBezierCurve3: QuadraticBezierCurve3,\n\tSplineCurve: SplineCurve\n});\n\n/**************************************************************\n *\tCurved Path - a curve path is simply a array of connected\n *  curves, but retains the api of a curve\n **************************************************************/\n\nclass CurvePath extends Curve {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'CurvePath';\n\n\t\tthis.curves = [];\n\t\tthis.autoClose = false; // Automatically closes the path\n\n\t}\n\n\tadd( curve ) {\n\n\t\tthis.curves.push( curve );\n\n\t}\n\n\tclosePath() {\n\n\t\t// Add a line curve if start and end of lines are not connected\n\t\tconst startPoint = this.curves[ 0 ].getPoint( 0 );\n\t\tconst endPoint = this.curves[ this.curves.length - 1 ].getPoint( 1 );\n\n\t\tif ( ! startPoint.equals( endPoint ) ) {\n\n\t\t\tthis.curves.push( new LineCurve( endPoint, startPoint ) );\n\n\t\t}\n\n\t}\n\n\t// To get accurate point with reference to\n\t// entire path distance at time t,\n\t// following has to be done:\n\n\t// 1. Length of each sub path have to be known\n\t// 2. Locate and identify type of curve\n\t// 3. Get t for the curve\n\t// 4. Return curve.getPointAt(t')\n\n\tgetPoint( t, optionalTarget ) {\n\n\t\tconst d = t * this.getLength();\n\t\tconst curveLengths = this.getCurveLengths();\n\t\tlet i = 0;\n\n\t\t// To think about boundaries points.\n\n\t\twhile ( i < curveLengths.length ) {\n\n\t\t\tif ( curveLengths[ i ] >= d ) {\n\n\t\t\t\tconst diff = curveLengths[ i ] - d;\n\t\t\t\tconst curve = this.curves[ i ];\n\n\t\t\t\tconst segmentLength = curve.getLength();\n\t\t\t\tconst u = segmentLength === 0 ? 0 : 1 - diff / segmentLength;\n\n\t\t\t\treturn curve.getPointAt( u, optionalTarget );\n\n\t\t\t}\n\n\t\t\ti ++;\n\n\t\t}\n\n\t\treturn null;\n\n\t\t// loop where sum != 0, sum > d , sum+1 <d\n\n\t}\n\n\t// We cannot use the default THREE.Curve getPoint() with getLength() because in\n\t// THREE.Curve, getLength() depends on getPoint() but in THREE.CurvePath\n\t// getPoint() depends on getLength\n\n\tgetLength() {\n\n\t\tconst lens = this.getCurveLengths();\n\t\treturn lens[ lens.length - 1 ];\n\n\t}\n\n\t// cacheLengths must be recalculated.\n\tupdateArcLengths() {\n\n\t\tthis.needsUpdate = true;\n\t\tthis.cacheLengths = null;\n\t\tthis.getCurveLengths();\n\n\t}\n\n\t// Compute lengths and cache them\n\t// We cannot overwrite getLengths() because UtoT mapping uses it.\n\n\tgetCurveLengths() {\n\n\t\t// We use cache values if curves and cache array are same length\n\n\t\tif ( this.cacheLengths && this.cacheLengths.length === this.curves.length ) {\n\n\t\t\treturn this.cacheLengths;\n\n\t\t}\n\n\t\t// Get length of sub-curve\n\t\t// Push sums into cached array\n\n\t\tconst lengths = [];\n\t\tlet sums = 0;\n\n\t\tfor ( let i = 0, l = this.curves.length; i < l; i ++ ) {\n\n\t\t\tsums += this.curves[ i ].getLength();\n\t\t\tlengths.push( sums );\n\n\t\t}\n\n\t\tthis.cacheLengths = lengths;\n\n\t\treturn lengths;\n\n\t}\n\n\tgetSpacedPoints( divisions = 40 ) {\n\n\t\tconst points = [];\n\n\t\tfor ( let i = 0; i <= divisions; i ++ ) {\n\n\t\t\tpoints.push( this.getPoint( i / divisions ) );\n\n\t\t}\n\n\t\tif ( this.autoClose ) {\n\n\t\t\tpoints.push( points[ 0 ] );\n\n\t\t}\n\n\t\treturn points;\n\n\t}\n\n\tgetPoints( divisions = 12 ) {\n\n\t\tconst points = [];\n\t\tlet last;\n\n\t\tfor ( let i = 0, curves = this.curves; i < curves.length; i ++ ) {\n\n\t\t\tconst curve = curves[ i ];\n\t\t\tconst resolution = curve.isEllipseCurve ? divisions * 2\n\t\t\t\t: ( curve.isLineCurve || curve.isLineCurve3 ) ? 1\n\t\t\t\t\t: curve.isSplineCurve ? divisions * curve.points.length\n\t\t\t\t\t\t: divisions;\n\n\t\t\tconst pts = curve.getPoints( resolution );\n\n\t\t\tfor ( let j = 0; j < pts.length; j ++ ) {\n\n\t\t\t\tconst point = pts[ j ];\n\n\t\t\t\tif ( last && last.equals( point ) ) continue; // ensures no consecutive points are duplicates\n\n\t\t\t\tpoints.push( point );\n\t\t\t\tlast = point;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( this.autoClose && points.length > 1 && ! points[ points.length - 1 ].equals( points[ 0 ] ) ) {\n\n\t\t\tpoints.push( points[ 0 ] );\n\n\t\t}\n\n\t\treturn points;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.curves = [];\n\n\t\tfor ( let i = 0, l = source.curves.length; i < l; i ++ ) {\n\n\t\t\tconst curve = source.curves[ i ];\n\n\t\t\tthis.curves.push( curve.clone() );\n\n\t\t}\n\n\t\tthis.autoClose = source.autoClose;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.autoClose = this.autoClose;\n\t\tdata.curves = [];\n\n\t\tfor ( let i = 0, l = this.curves.length; i < l; i ++ ) {\n\n\t\t\tconst curve = this.curves[ i ];\n\t\t\tdata.curves.push( curve.toJSON() );\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.autoClose = json.autoClose;\n\t\tthis.curves = [];\n\n\t\tfor ( let i = 0, l = json.curves.length; i < l; i ++ ) {\n\n\t\t\tconst curve = json.curves[ i ];\n\t\t\tthis.curves.push( new Curves[ curve.type ]().fromJSON( curve ) );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass Path extends CurvePath {\n\n\tconstructor( points ) {\n\n\t\tsuper();\n\t\tthis.type = 'Path';\n\n\t\tthis.currentPoint = new Vector2();\n\n\t\tif ( points ) {\n\n\t\t\tthis.setFromPoints( points );\n\n\t\t}\n\n\t}\n\n\tsetFromPoints( points ) {\n\n\t\tthis.moveTo( points[ 0 ].x, points[ 0 ].y );\n\n\t\tfor ( let i = 1, l = points.length; i < l; i ++ ) {\n\n\t\t\tthis.lineTo( points[ i ].x, points[ i ].y );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tmoveTo( x, y ) {\n\n\t\tthis.currentPoint.set( x, y ); // TODO consider referencing vectors instead of copying?\n\n\t\treturn this;\n\n\t}\n\n\tlineTo( x, y ) {\n\n\t\tconst curve = new LineCurve( this.currentPoint.clone(), new Vector2( x, y ) );\n\t\tthis.curves.push( curve );\n\n\t\tthis.currentPoint.set( x, y );\n\n\t\treturn this;\n\n\t}\n\n\tquadraticCurveTo( aCPx, aCPy, aX, aY ) {\n\n\t\tconst curve = new QuadraticBezierCurve(\n\t\t\tthis.currentPoint.clone(),\n\t\t\tnew Vector2( aCPx, aCPy ),\n\t\t\tnew Vector2( aX, aY )\n\t\t);\n\n\t\tthis.curves.push( curve );\n\n\t\tthis.currentPoint.set( aX, aY );\n\n\t\treturn this;\n\n\t}\n\n\tbezierCurveTo( aCP1x, aCP1y, aCP2x, aCP2y, aX, aY ) {\n\n\t\tconst curve = new CubicBezierCurve(\n\t\t\tthis.currentPoint.clone(),\n\t\t\tnew Vector2( aCP1x, aCP1y ),\n\t\t\tnew Vector2( aCP2x, aCP2y ),\n\t\t\tnew Vector2( aX, aY )\n\t\t);\n\n\t\tthis.curves.push( curve );\n\n\t\tthis.currentPoint.set( aX, aY );\n\n\t\treturn this;\n\n\t}\n\n\tsplineThru( pts /*Array of Vector*/ ) {\n\n\t\tconst npts = [ this.currentPoint.clone() ].concat( pts );\n\n\t\tconst curve = new SplineCurve( npts );\n\t\tthis.curves.push( curve );\n\n\t\tthis.currentPoint.copy( pts[ pts.length - 1 ] );\n\n\t\treturn this;\n\n\t}\n\n\tarc( aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise ) {\n\n\t\tconst x0 = this.currentPoint.x;\n\t\tconst y0 = this.currentPoint.y;\n\n\t\tthis.absarc( aX + x0, aY + y0, aRadius,\n\t\t\taStartAngle, aEndAngle, aClockwise );\n\n\t\treturn this;\n\n\t}\n\n\tabsarc( aX, aY, aRadius, aStartAngle, aEndAngle, aClockwise ) {\n\n\t\tthis.absellipse( aX, aY, aRadius, aRadius, aStartAngle, aEndAngle, aClockwise );\n\n\t\treturn this;\n\n\t}\n\n\tellipse( aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation ) {\n\n\t\tconst x0 = this.currentPoint.x;\n\t\tconst y0 = this.currentPoint.y;\n\n\t\tthis.absellipse( aX + x0, aY + y0, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation );\n\n\t\treturn this;\n\n\t}\n\n\tabsellipse( aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation ) {\n\n\t\tconst curve = new EllipseCurve( aX, aY, xRadius, yRadius, aStartAngle, aEndAngle, aClockwise, aRotation );\n\n\t\tif ( this.curves.length > 0 ) {\n\n\t\t\t// if a previous curve is present, attempt to join\n\t\t\tconst firstPoint = curve.getPoint( 0 );\n\n\t\t\tif ( ! firstPoint.equals( this.currentPoint ) ) {\n\n\t\t\t\tthis.lineTo( firstPoint.x, firstPoint.y );\n\n\t\t\t}\n\n\t\t}\n\n\t\tthis.curves.push( curve );\n\n\t\tconst lastPoint = curve.getPoint( 1 );\n\t\tthis.currentPoint.copy( lastPoint );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.currentPoint.copy( source.currentPoint );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.currentPoint = this.currentPoint.toArray();\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.currentPoint.fromArray( json.currentPoint );\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass Shape extends Path {\n\n\tconstructor( points ) {\n\n\t\tsuper( points );\n\n\t\tthis.uuid = generateUUID();\n\n\t\tthis.type = 'Shape';\n\n\t\tthis.holes = [];\n\n\t}\n\n\tgetPointsHoles( divisions ) {\n\n\t\tconst holesPts = [];\n\n\t\tfor ( let i = 0, l = this.holes.length; i < l; i ++ ) {\n\n\t\t\tholesPts[ i ] = this.holes[ i ].getPoints( divisions );\n\n\t\t}\n\n\t\treturn holesPts;\n\n\t}\n\n\t// get points of shape and holes (keypoints based on segments parameter)\n\n\textractPoints( divisions ) {\n\n\t\treturn {\n\n\t\t\tshape: this.getPoints( divisions ),\n\t\t\tholes: this.getPointsHoles( divisions )\n\n\t\t};\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.holes = [];\n\n\t\tfor ( let i = 0, l = source.holes.length; i < l; i ++ ) {\n\n\t\t\tconst hole = source.holes[ i ];\n\n\t\t\tthis.holes.push( hole.clone() );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.uuid = this.uuid;\n\t\tdata.holes = [];\n\n\t\tfor ( let i = 0, l = this.holes.length; i < l; i ++ ) {\n\n\t\t\tconst hole = this.holes[ i ];\n\t\t\tdata.holes.push( hole.toJSON() );\n\n\t\t}\n\n\t\treturn data;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tsuper.fromJSON( json );\n\n\t\tthis.uuid = json.uuid;\n\t\tthis.holes = [];\n\n\t\tfor ( let i = 0, l = json.holes.length; i < l; i ++ ) {\n\n\t\t\tconst hole = json.holes[ i ];\n\t\t\tthis.holes.push( new Path().fromJSON( hole ) );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n}\n\n/**\n * Port from https://github.com/mapbox/earcut (v2.2.2)\n */\n\nconst Earcut = {\n\n\ttriangulate: function ( data, holeIndices, dim = 2 ) {\n\n\t\tconst hasHoles = holeIndices && holeIndices.length;\n\t\tconst outerLen = hasHoles ? holeIndices[ 0 ] * dim : data.length;\n\t\tlet outerNode = linkedList( data, 0, outerLen, dim, true );\n\t\tconst triangles = [];\n\n\t\tif ( ! outerNode || outerNode.next === outerNode.prev ) return triangles;\n\n\t\tlet minX, minY, maxX, maxY, x, y, invSize;\n\n\t\tif ( hasHoles ) outerNode = eliminateHoles( data, holeIndices, outerNode, dim );\n\n\t\t// if the shape is not too simple, we'll use z-order curve hash later; calculate polygon bbox\n\t\tif ( data.length > 80 * dim ) {\n\n\t\t\tminX = maxX = data[ 0 ];\n\t\t\tminY = maxY = data[ 1 ];\n\n\t\t\tfor ( let i = dim; i < outerLen; i += dim ) {\n\n\t\t\t\tx = data[ i ];\n\t\t\t\ty = data[ i + 1 ];\n\t\t\t\tif ( x < minX ) minX = x;\n\t\t\t\tif ( y < minY ) minY = y;\n\t\t\t\tif ( x > maxX ) maxX = x;\n\t\t\t\tif ( y > maxY ) maxY = y;\n\n\t\t\t}\n\n\t\t\t// minX, minY and invSize are later used to transform coords into integers for z-order calculation\n\t\t\tinvSize = Math.max( maxX - minX, maxY - minY );\n\t\t\tinvSize = invSize !== 0 ? 1 / invSize : 0;\n\n\t\t}\n\n\t\tearcutLinked( outerNode, triangles, dim, minX, minY, invSize );\n\n\t\treturn triangles;\n\n\t}\n\n};\n\n// create a circular doubly linked list from polygon points in the specified winding order\nfunction linkedList( data, start, end, dim, clockwise ) {\n\n\tlet i, last;\n\n\tif ( clockwise === ( signedArea( data, start, end, dim ) > 0 ) ) {\n\n\t\tfor ( i = start; i < end; i += dim ) last = insertNode( i, data[ i ], data[ i + 1 ], last );\n\n\t} else {\n\n\t\tfor ( i = end - dim; i >= start; i -= dim ) last = insertNode( i, data[ i ], data[ i + 1 ], last );\n\n\t}\n\n\tif ( last && equals( last, last.next ) ) {\n\n\t\tremoveNode( last );\n\t\tlast = last.next;\n\n\t}\n\n\treturn last;\n\n}\n\n// eliminate colinear or duplicate points\nfunction filterPoints( start, end ) {\n\n\tif ( ! start ) return start;\n\tif ( ! end ) end = start;\n\n\tlet p = start,\n\t\tagain;\n\tdo {\n\n\t\tagain = false;\n\n\t\tif ( ! p.steiner && ( equals( p, p.next ) || area( p.prev, p, p.next ) === 0 ) ) {\n\n\t\t\tremoveNode( p );\n\t\t\tp = end = p.prev;\n\t\t\tif ( p === p.next ) break;\n\t\t\tagain = true;\n\n\t\t} else {\n\n\t\t\tp = p.next;\n\n\t\t}\n\n\t} while ( again || p !== end );\n\n\treturn end;\n\n}\n\n// main ear slicing loop which triangulates a polygon (given as a linked list)\nfunction earcutLinked( ear, triangles, dim, minX, minY, invSize, pass ) {\n\n\tif ( ! ear ) return;\n\n\t// interlink polygon nodes in z-order\n\tif ( ! pass && invSize ) indexCurve( ear, minX, minY, invSize );\n\n\tlet stop = ear,\n\t\tprev, next;\n\n\t// iterate through ears, slicing them one by one\n\twhile ( ear.prev !== ear.next ) {\n\n\t\tprev = ear.prev;\n\t\tnext = ear.next;\n\n\t\tif ( invSize ? isEarHashed( ear, minX, minY, invSize ) : isEar( ear ) ) {\n\n\t\t\t// cut off the triangle\n\t\t\ttriangles.push( prev.i / dim );\n\t\t\ttriangles.push( ear.i / dim );\n\t\t\ttriangles.push( next.i / dim );\n\n\t\t\tremoveNode( ear );\n\n\t\t\t// skipping the next vertex leads to less sliver triangles\n\t\t\tear = next.next;\n\t\t\tstop = next.next;\n\n\t\t\tcontinue;\n\n\t\t}\n\n\t\tear = next;\n\n\t\t// if we looped through the whole remaining polygon and can't find any more ears\n\t\tif ( ear === stop ) {\n\n\t\t\t// try filtering points and slicing again\n\t\t\tif ( ! pass ) {\n\n\t\t\t\tearcutLinked( filterPoints( ear ), triangles, dim, minX, minY, invSize, 1 );\n\n\t\t\t\t// if this didn't work, try curing all small self-intersections locally\n\n\t\t\t} else if ( pass === 1 ) {\n\n\t\t\t\tear = cureLocalIntersections( filterPoints( ear ), triangles, dim );\n\t\t\t\tearcutLinked( ear, triangles, dim, minX, minY, invSize, 2 );\n\n\t\t\t\t// as a last resort, try splitting the remaining polygon into two\n\n\t\t\t} else if ( pass === 2 ) {\n\n\t\t\t\tsplitEarcut( ear, triangles, dim, minX, minY, invSize );\n\n\t\t\t}\n\n\t\t\tbreak;\n\n\t\t}\n\n\t}\n\n}\n\n// check whether a polygon node forms a valid ear with adjacent nodes\nfunction isEar( ear ) {\n\n\tconst a = ear.prev,\n\t\tb = ear,\n\t\tc = ear.next;\n\n\tif ( area( a, b, c ) >= 0 ) return false; // reflex, can't be an ear\n\n\t// now make sure we don't have other points inside the potential ear\n\tlet p = ear.next.next;\n\n\twhile ( p !== ear.prev ) {\n\n\t\tif ( pointInTriangle( a.x, a.y, b.x, b.y, c.x, c.y, p.x, p.y ) &&\n\t\t\tarea( p.prev, p, p.next ) >= 0 ) return false;\n\t\tp = p.next;\n\n\t}\n\n\treturn true;\n\n}\n\nfunction isEarHashed( ear, minX, minY, invSize ) {\n\n\tconst a = ear.prev,\n\t\tb = ear,\n\t\tc = ear.next;\n\n\tif ( area( a, b, c ) >= 0 ) return false; // reflex, can't be an ear\n\n\t// triangle bbox; min & max are calculated like this for speed\n\tconst minTX = a.x < b.x ? ( a.x < c.x ? a.x : c.x ) : ( b.x < c.x ? b.x : c.x ),\n\t\tminTY = a.y < b.y ? ( a.y < c.y ? a.y : c.y ) : ( b.y < c.y ? b.y : c.y ),\n\t\tmaxTX = a.x > b.x ? ( a.x > c.x ? a.x : c.x ) : ( b.x > c.x ? b.x : c.x ),\n\t\tmaxTY = a.y > b.y ? ( a.y > c.y ? a.y : c.y ) : ( b.y > c.y ? b.y : c.y );\n\n\t// z-order range for the current triangle bbox;\n\tconst minZ = zOrder( minTX, minTY, minX, minY, invSize ),\n\t\tmaxZ = zOrder( maxTX, maxTY, minX, minY, invSize );\n\n\tlet p = ear.prevZ,\n\t\tn = ear.nextZ;\n\n\t// look for points inside the triangle in both directions\n\twhile ( p && p.z >= minZ && n && n.z <= maxZ ) {\n\n\t\tif ( p !== ear.prev && p !== ear.next &&\n\t\t\tpointInTriangle( a.x, a.y, b.x, b.y, c.x, c.y, p.x, p.y ) &&\n\t\t\tarea( p.prev, p, p.next ) >= 0 ) return false;\n\t\tp = p.prevZ;\n\n\t\tif ( n !== ear.prev && n !== ear.next &&\n\t\t\tpointInTriangle( a.x, a.y, b.x, b.y, c.x, c.y, n.x, n.y ) &&\n\t\t\tarea( n.prev, n, n.next ) >= 0 ) return false;\n\t\tn = n.nextZ;\n\n\t}\n\n\t// look for remaining points in decreasing z-order\n\twhile ( p && p.z >= minZ ) {\n\n\t\tif ( p !== ear.prev && p !== ear.next &&\n\t\t\tpointInTriangle( a.x, a.y, b.x, b.y, c.x, c.y, p.x, p.y ) &&\n\t\t\tarea( p.prev, p, p.next ) >= 0 ) return false;\n\t\tp = p.prevZ;\n\n\t}\n\n\t// look for remaining points in increasing z-order\n\twhile ( n && n.z <= maxZ ) {\n\n\t\tif ( n !== ear.prev && n !== ear.next &&\n\t\t\tpointInTriangle( a.x, a.y, b.x, b.y, c.x, c.y, n.x, n.y ) &&\n\t\t\tarea( n.prev, n, n.next ) >= 0 ) return false;\n\t\tn = n.nextZ;\n\n\t}\n\n\treturn true;\n\n}\n\n// go through all polygon nodes and cure small local self-intersections\nfunction cureLocalIntersections( start, triangles, dim ) {\n\n\tlet p = start;\n\tdo {\n\n\t\tconst a = p.prev,\n\t\t\tb = p.next.next;\n\n\t\tif ( ! equals( a, b ) && intersects( a, p, p.next, b ) && locallyInside( a, b ) && locallyInside( b, a ) ) {\n\n\t\t\ttriangles.push( a.i / dim );\n\t\t\ttriangles.push( p.i / dim );\n\t\t\ttriangles.push( b.i / dim );\n\n\t\t\t// remove two nodes involved\n\t\t\tremoveNode( p );\n\t\t\tremoveNode( p.next );\n\n\t\t\tp = start = b;\n\n\t\t}\n\n\t\tp = p.next;\n\n\t} while ( p !== start );\n\n\treturn filterPoints( p );\n\n}\n\n// try splitting polygon into two and triangulate them independently\nfunction splitEarcut( start, triangles, dim, minX, minY, invSize ) {\n\n\t// look for a valid diagonal that divides the polygon into two\n\tlet a = start;\n\tdo {\n\n\t\tlet b = a.next.next;\n\t\twhile ( b !== a.prev ) {\n\n\t\t\tif ( a.i !== b.i && isValidDiagonal( a, b ) ) {\n\n\t\t\t\t// split the polygon in two by the diagonal\n\t\t\t\tlet c = splitPolygon( a, b );\n\n\t\t\t\t// filter colinear points around the cuts\n\t\t\t\ta = filterPoints( a, a.next );\n\t\t\t\tc = filterPoints( c, c.next );\n\n\t\t\t\t// run earcut on each half\n\t\t\t\tearcutLinked( a, triangles, dim, minX, minY, invSize );\n\t\t\t\tearcutLinked( c, triangles, dim, minX, minY, invSize );\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t\tb = b.next;\n\n\t\t}\n\n\t\ta = a.next;\n\n\t} while ( a !== start );\n\n}\n\n// link every hole into the outer loop, producing a single-ring polygon without holes\nfunction eliminateHoles( data, holeIndices, outerNode, dim ) {\n\n\tconst queue = [];\n\tlet i, len, start, end, list;\n\n\tfor ( i = 0, len = holeIndices.length; i < len; i ++ ) {\n\n\t\tstart = holeIndices[ i ] * dim;\n\t\tend = i < len - 1 ? holeIndices[ i + 1 ] * dim : data.length;\n\t\tlist = linkedList( data, start, end, dim, false );\n\t\tif ( list === list.next ) list.steiner = true;\n\t\tqueue.push( getLeftmost( list ) );\n\n\t}\n\n\tqueue.sort( compareX );\n\n\t// process holes from left to right\n\tfor ( i = 0; i < queue.length; i ++ ) {\n\n\t\teliminateHole( queue[ i ], outerNode );\n\t\touterNode = filterPoints( outerNode, outerNode.next );\n\n\t}\n\n\treturn outerNode;\n\n}\n\nfunction compareX( a, b ) {\n\n\treturn a.x - b.x;\n\n}\n\n// find a bridge between vertices that connects hole with an outer ring and and link it\nfunction eliminateHole( hole, outerNode ) {\n\n\touterNode = findHoleBridge( hole, outerNode );\n\tif ( outerNode ) {\n\n\t\tconst b = splitPolygon( outerNode, hole );\n\n\t\t// filter collinear points around the cuts\n\t\tfilterPoints( outerNode, outerNode.next );\n\t\tfilterPoints( b, b.next );\n\n\t}\n\n}\n\n// David Eberly's algorithm for finding a bridge between hole and outer polygon\nfunction findHoleBridge( hole, outerNode ) {\n\n\tlet p = outerNode;\n\tconst hx = hole.x;\n\tconst hy = hole.y;\n\tlet qx = - Infinity, m;\n\n\t// find a segment intersected by a ray from the hole's leftmost point to the left;\n\t// segment's endpoint with lesser x will be potential connection point\n\tdo {\n\n\t\tif ( hy <= p.y && hy >= p.next.y && p.next.y !== p.y ) {\n\n\t\t\tconst x = p.x + ( hy - p.y ) * ( p.next.x - p.x ) / ( p.next.y - p.y );\n\t\t\tif ( x <= hx && x > qx ) {\n\n\t\t\t\tqx = x;\n\t\t\t\tif ( x === hx ) {\n\n\t\t\t\t\tif ( hy === p.y ) return p;\n\t\t\t\t\tif ( hy === p.next.y ) return p.next;\n\n\t\t\t\t}\n\n\t\t\t\tm = p.x < p.next.x ? p : p.next;\n\n\t\t\t}\n\n\t\t}\n\n\t\tp = p.next;\n\n\t} while ( p !== outerNode );\n\n\tif ( ! m ) return null;\n\n\tif ( hx === qx ) return m; // hole touches outer segment; pick leftmost endpoint\n\n\t// look for points inside the triangle of hole point, segment intersection and endpoint;\n\t// if there are no points found, we have a valid connection;\n\t// otherwise choose the point of the minimum angle with the ray as connection point\n\n\tconst stop = m,\n\t\tmx = m.x,\n\t\tmy = m.y;\n\tlet tanMin = Infinity, tan;\n\n\tp = m;\n\n\tdo {\n\n\t\tif ( hx >= p.x && p.x >= mx && hx !== p.x &&\n\t\t\t\tpointInTriangle( hy < my ? hx : qx, hy, mx, my, hy < my ? qx : hx, hy, p.x, p.y ) ) {\n\n\t\t\ttan = Math.abs( hy - p.y ) / ( hx - p.x ); // tangential\n\n\t\t\tif ( locallyInside( p, hole ) && ( tan < tanMin || ( tan === tanMin && ( p.x > m.x || ( p.x === m.x && sectorContainsSector( m, p ) ) ) ) ) ) {\n\n\t\t\t\tm = p;\n\t\t\t\ttanMin = tan;\n\n\t\t\t}\n\n\t\t}\n\n\t\tp = p.next;\n\n\t} while ( p !== stop );\n\n\treturn m;\n\n}\n\n// whether sector in vertex m contains sector in vertex p in the same coordinates\nfunction sectorContainsSector( m, p ) {\n\n\treturn area( m.prev, m, p.prev ) < 0 && area( p.next, m, m.next ) < 0;\n\n}\n\n// interlink polygon nodes in z-order\nfunction indexCurve( start, minX, minY, invSize ) {\n\n\tlet p = start;\n\tdo {\n\n\t\tif ( p.z === null ) p.z = zOrder( p.x, p.y, minX, minY, invSize );\n\t\tp.prevZ = p.prev;\n\t\tp.nextZ = p.next;\n\t\tp = p.next;\n\n\t} while ( p !== start );\n\n\tp.prevZ.nextZ = null;\n\tp.prevZ = null;\n\n\tsortLinked( p );\n\n}\n\n// Simon Tatham's linked list merge sort algorithm\n// http://www.chiark.greenend.org.uk/~sgtatham/algorithms/listsort.html\nfunction sortLinked( list ) {\n\n\tlet i, p, q, e, tail, numMerges, pSize, qSize,\n\t\tinSize = 1;\n\n\tdo {\n\n\t\tp = list;\n\t\tlist = null;\n\t\ttail = null;\n\t\tnumMerges = 0;\n\n\t\twhile ( p ) {\n\n\t\t\tnumMerges ++;\n\t\t\tq = p;\n\t\t\tpSize = 0;\n\t\t\tfor ( i = 0; i < inSize; i ++ ) {\n\n\t\t\t\tpSize ++;\n\t\t\t\tq = q.nextZ;\n\t\t\t\tif ( ! q ) break;\n\n\t\t\t}\n\n\t\t\tqSize = inSize;\n\n\t\t\twhile ( pSize > 0 || ( qSize > 0 && q ) ) {\n\n\t\t\t\tif ( pSize !== 0 && ( qSize === 0 || ! q || p.z <= q.z ) ) {\n\n\t\t\t\t\te = p;\n\t\t\t\t\tp = p.nextZ;\n\t\t\t\t\tpSize --;\n\n\t\t\t\t} else {\n\n\t\t\t\t\te = q;\n\t\t\t\t\tq = q.nextZ;\n\t\t\t\t\tqSize --;\n\n\t\t\t\t}\n\n\t\t\t\tif ( tail ) tail.nextZ = e;\n\t\t\t\telse list = e;\n\n\t\t\t\te.prevZ = tail;\n\t\t\t\ttail = e;\n\n\t\t\t}\n\n\t\t\tp = q;\n\n\t\t}\n\n\t\ttail.nextZ = null;\n\t\tinSize *= 2;\n\n\t} while ( numMerges > 1 );\n\n\treturn list;\n\n}\n\n// z-order of a point given coords and inverse of the longer side of data bbox\nfunction zOrder( x, y, minX, minY, invSize ) {\n\n\t// coords are transformed into non-negative 15-bit integer range\n\tx = 32767 * ( x - minX ) * invSize;\n\ty = 32767 * ( y - minY ) * invSize;\n\n\tx = ( x | ( x << 8 ) ) & 0x00FF00FF;\n\tx = ( x | ( x << 4 ) ) & 0x0F0F0F0F;\n\tx = ( x | ( x << 2 ) ) & 0x33333333;\n\tx = ( x | ( x << 1 ) ) & 0x55555555;\n\n\ty = ( y | ( y << 8 ) ) & 0x00FF00FF;\n\ty = ( y | ( y << 4 ) ) & 0x0F0F0F0F;\n\ty = ( y | ( y << 2 ) ) & 0x33333333;\n\ty = ( y | ( y << 1 ) ) & 0x55555555;\n\n\treturn x | ( y << 1 );\n\n}\n\n// find the leftmost node of a polygon ring\nfunction getLeftmost( start ) {\n\n\tlet p = start,\n\t\tleftmost = start;\n\tdo {\n\n\t\tif ( p.x < leftmost.x || ( p.x === leftmost.x && p.y < leftmost.y ) ) leftmost = p;\n\t\tp = p.next;\n\n\t} while ( p !== start );\n\n\treturn leftmost;\n\n}\n\n// check if a point lies within a convex triangle\nfunction pointInTriangle( ax, ay, bx, by, cx, cy, px, py ) {\n\n\treturn ( cx - px ) * ( ay - py ) - ( ax - px ) * ( cy - py ) >= 0 &&\n\t\t\t( ax - px ) * ( by - py ) - ( bx - px ) * ( ay - py ) >= 0 &&\n\t\t\t( bx - px ) * ( cy - py ) - ( cx - px ) * ( by - py ) >= 0;\n\n}\n\n// check if a diagonal between two polygon nodes is valid (lies in polygon interior)\nfunction isValidDiagonal( a, b ) {\n\n\treturn a.next.i !== b.i && a.prev.i !== b.i && ! intersectsPolygon( a, b ) && // dones't intersect other edges\n\t\t( locallyInside( a, b ) && locallyInside( b, a ) && middleInside( a, b ) && // locally visible\n\t\t( area( a.prev, a, b.prev ) || area( a, b.prev, b ) ) || // does not create opposite-facing sectors\n\t\tequals( a, b ) && area( a.prev, a, a.next ) > 0 && area( b.prev, b, b.next ) > 0 ); // special zero-length case\n\n}\n\n// signed area of a triangle\nfunction area( p, q, r ) {\n\n\treturn ( q.y - p.y ) * ( r.x - q.x ) - ( q.x - p.x ) * ( r.y - q.y );\n\n}\n\n// check if two points are equal\nfunction equals( p1, p2 ) {\n\n\treturn p1.x === p2.x && p1.y === p2.y;\n\n}\n\n// check if two segments intersect\nfunction intersects( p1, q1, p2, q2 ) {\n\n\tconst o1 = sign( area( p1, q1, p2 ) );\n\tconst o2 = sign( area( p1, q1, q2 ) );\n\tconst o3 = sign( area( p2, q2, p1 ) );\n\tconst o4 = sign( area( p2, q2, q1 ) );\n\n\tif ( o1 !== o2 && o3 !== o4 ) return true; // general case\n\n\tif ( o1 === 0 && onSegment( p1, p2, q1 ) ) return true; // p1, q1 and p2 are collinear and p2 lies on p1q1\n\tif ( o2 === 0 && onSegment( p1, q2, q1 ) ) return true; // p1, q1 and q2 are collinear and q2 lies on p1q1\n\tif ( o3 === 0 && onSegment( p2, p1, q2 ) ) return true; // p2, q2 and p1 are collinear and p1 lies on p2q2\n\tif ( o4 === 0 && onSegment( p2, q1, q2 ) ) return true; // p2, q2 and q1 are collinear and q1 lies on p2q2\n\n\treturn false;\n\n}\n\n// for collinear points p, q, r, check if point q lies on segment pr\nfunction onSegment( p, q, r ) {\n\n\treturn q.x <= Math.max( p.x, r.x ) && q.x >= Math.min( p.x, r.x ) && q.y <= Math.max( p.y, r.y ) && q.y >= Math.min( p.y, r.y );\n\n}\n\nfunction sign( num ) {\n\n\treturn num > 0 ? 1 : num < 0 ? - 1 : 0;\n\n}\n\n// check if a polygon diagonal intersects any polygon segments\nfunction intersectsPolygon( a, b ) {\n\n\tlet p = a;\n\tdo {\n\n\t\tif ( p.i !== a.i && p.next.i !== a.i && p.i !== b.i && p.next.i !== b.i &&\n\t\t\t\tintersects( p, p.next, a, b ) ) return true;\n\t\tp = p.next;\n\n\t} while ( p !== a );\n\n\treturn false;\n\n}\n\n// check if a polygon diagonal is locally inside the polygon\nfunction locallyInside( a, b ) {\n\n\treturn area( a.prev, a, a.next ) < 0 ?\n\t\tarea( a, b, a.next ) >= 0 && area( a, a.prev, b ) >= 0 :\n\t\tarea( a, b, a.prev ) < 0 || area( a, a.next, b ) < 0;\n\n}\n\n// check if the middle point of a polygon diagonal is inside the polygon\nfunction middleInside( a, b ) {\n\n\tlet p = a,\n\t\tinside = false;\n\tconst px = ( a.x + b.x ) / 2,\n\t\tpy = ( a.y + b.y ) / 2;\n\tdo {\n\n\t\tif ( ( ( p.y > py ) !== ( p.next.y > py ) ) && p.next.y !== p.y &&\n\t\t\t\t( px < ( p.next.x - p.x ) * ( py - p.y ) / ( p.next.y - p.y ) + p.x ) )\n\t\t\tinside = ! inside;\n\t\tp = p.next;\n\n\t} while ( p !== a );\n\n\treturn inside;\n\n}\n\n// link two polygon vertices with a bridge; if the vertices belong to the same ring, it splits polygon into two;\n// if one belongs to the outer ring and another to a hole, it merges it into a single ring\nfunction splitPolygon( a, b ) {\n\n\tconst a2 = new Node( a.i, a.x, a.y ),\n\t\tb2 = new Node( b.i, b.x, b.y ),\n\t\tan = a.next,\n\t\tbp = b.prev;\n\n\ta.next = b;\n\tb.prev = a;\n\n\ta2.next = an;\n\tan.prev = a2;\n\n\tb2.next = a2;\n\ta2.prev = b2;\n\n\tbp.next = b2;\n\tb2.prev = bp;\n\n\treturn b2;\n\n}\n\n// create a node and optionally link it with previous one (in a circular doubly linked list)\nfunction insertNode( i, x, y, last ) {\n\n\tconst p = new Node( i, x, y );\n\n\tif ( ! last ) {\n\n\t\tp.prev = p;\n\t\tp.next = p;\n\n\t} else {\n\n\t\tp.next = last.next;\n\t\tp.prev = last;\n\t\tlast.next.prev = p;\n\t\tlast.next = p;\n\n\t}\n\n\treturn p;\n\n}\n\nfunction removeNode( p ) {\n\n\tp.next.prev = p.prev;\n\tp.prev.next = p.next;\n\n\tif ( p.prevZ ) p.prevZ.nextZ = p.nextZ;\n\tif ( p.nextZ ) p.nextZ.prevZ = p.prevZ;\n\n}\n\nfunction Node( i, x, y ) {\n\n\t// vertex index in coordinates array\n\tthis.i = i;\n\n\t// vertex coordinates\n\tthis.x = x;\n\tthis.y = y;\n\n\t// previous and next vertex nodes in a polygon ring\n\tthis.prev = null;\n\tthis.next = null;\n\n\t// z-order curve value\n\tthis.z = null;\n\n\t// previous and next nodes in z-order\n\tthis.prevZ = null;\n\tthis.nextZ = null;\n\n\t// indicates whether this is a steiner point\n\tthis.steiner = false;\n\n}\n\nfunction signedArea( data, start, end, dim ) {\n\n\tlet sum = 0;\n\tfor ( let i = start, j = end - dim; i < end; i += dim ) {\n\n\t\tsum += ( data[ j ] - data[ i ] ) * ( data[ i + 1 ] + data[ j + 1 ] );\n\t\tj = i;\n\n\t}\n\n\treturn sum;\n\n}\n\nclass ShapeUtils {\n\n\t// calculate area of the contour polygon\n\n\tstatic area( contour ) {\n\n\t\tconst n = contour.length;\n\t\tlet a = 0.0;\n\n\t\tfor ( let p = n - 1, q = 0; q < n; p = q ++ ) {\n\n\t\t\ta += contour[ p ].x * contour[ q ].y - contour[ q ].x * contour[ p ].y;\n\n\t\t}\n\n\t\treturn a * 0.5;\n\n\t}\n\n\tstatic isClockWise( pts ) {\n\n\t\treturn ShapeUtils.area( pts ) < 0;\n\n\t}\n\n\tstatic triangulateShape( contour, holes ) {\n\n\t\tconst vertices = []; // flat array of vertices like [ x0,y0, x1,y1, x2,y2, ... ]\n\t\tconst holeIndices = []; // array of hole indices\n\t\tconst faces = []; // final array of vertex indices like [ [ a,b,d ], [ b,c,d ] ]\n\n\t\tremoveDupEndPts( contour );\n\t\taddContour( vertices, contour );\n\n\t\t//\n\n\t\tlet holeIndex = contour.length;\n\n\t\tholes.forEach( removeDupEndPts );\n\n\t\tfor ( let i = 0; i < holes.length; i ++ ) {\n\n\t\t\tholeIndices.push( holeIndex );\n\t\t\tholeIndex += holes[ i ].length;\n\t\t\taddContour( vertices, holes[ i ] );\n\n\t\t}\n\n\t\t//\n\n\t\tconst triangles = Earcut.triangulate( vertices, holeIndices );\n\n\t\t//\n\n\t\tfor ( let i = 0; i < triangles.length; i += 3 ) {\n\n\t\t\tfaces.push( triangles.slice( i, i + 3 ) );\n\n\t\t}\n\n\t\treturn faces;\n\n\t}\n\n}\n\nfunction removeDupEndPts( points ) {\n\n\tconst l = points.length;\n\n\tif ( l > 2 && points[ l - 1 ].equals( points[ 0 ] ) ) {\n\n\t\tpoints.pop();\n\n\t}\n\n}\n\nfunction addContour( vertices, contour ) {\n\n\tfor ( let i = 0; i < contour.length; i ++ ) {\n\n\t\tvertices.push( contour[ i ].x );\n\t\tvertices.push( contour[ i ].y );\n\n\t}\n\n}\n\n/**\n * Creates extruded geometry from a path shape.\n *\n * parameters = {\n *\n *  curveSegments: <int>, // number of points on the curves\n *  steps: <int>, // number of points for z-side extrusions / used for subdividing segments of extrude spline too\n *  depth: <float>, // Depth to extrude the shape\n *\n *  bevelEnabled: <bool>, // turn on bevel\n *  bevelThickness: <float>, // how deep into the original shape bevel goes\n *  bevelSize: <float>, // how far from shape outline (including bevelOffset) is bevel\n *  bevelOffset: <float>, // how far from shape outline does bevel start\n *  bevelSegments: <int>, // number of bevel layers\n *\n *  extrudePath: <THREE.Curve> // curve to extrude shape along\n *\n *  UVGenerator: <Object> // object that provides UV generator functions\n *\n * }\n */\n\nclass ExtrudeGeometry extends BufferGeometry {\n\n\tconstructor( shapes = new Shape( [ new Vector2( 0.5, 0.5 ), new Vector2( - 0.5, 0.5 ), new Vector2( - 0.5, - 0.5 ), new Vector2( 0.5, - 0.5 ) ] ), options = {} ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'ExtrudeGeometry';\n\n\t\tthis.parameters = {\n\t\t\tshapes: shapes,\n\t\t\toptions: options\n\t\t};\n\n\t\tshapes = Array.isArray( shapes ) ? shapes : [ shapes ];\n\n\t\tconst scope = this;\n\n\t\tconst verticesArray = [];\n\t\tconst uvArray = [];\n\n\t\tfor ( let i = 0, l = shapes.length; i < l; i ++ ) {\n\n\t\t\tconst shape = shapes[ i ];\n\t\t\taddShape( shape );\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( verticesArray, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvArray, 2 ) );\n\n\t\tthis.computeVertexNormals();\n\n\t\t// functions\n\n\t\tfunction addShape( shape ) {\n\n\t\t\tconst placeholder = [];\n\n\t\t\t// options\n\n\t\t\tconst curveSegments = options.curveSegments !== undefined ? options.curveSegments : 12;\n\t\t\tconst steps = options.steps !== undefined ? options.steps : 1;\n\t\t\tlet depth = options.depth !== undefined ? options.depth : 1;\n\n\t\t\tlet bevelEnabled = options.bevelEnabled !== undefined ? options.bevelEnabled : true;\n\t\t\tlet bevelThickness = options.bevelThickness !== undefined ? options.bevelThickness : 0.2;\n\t\t\tlet bevelSize = options.bevelSize !== undefined ? options.bevelSize : bevelThickness - 0.1;\n\t\t\tlet bevelOffset = options.bevelOffset !== undefined ? options.bevelOffset : 0;\n\t\t\tlet bevelSegments = options.bevelSegments !== undefined ? options.bevelSegments : 3;\n\n\t\t\tconst extrudePath = options.extrudePath;\n\n\t\t\tconst uvgen = options.UVGenerator !== undefined ? options.UVGenerator : WorldUVGenerator;\n\n\t\t\t// deprecated options\n\n\t\t\tif ( options.amount !== undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.ExtrudeBufferGeometry: amount has been renamed to depth.' );\n\t\t\t\tdepth = options.amount;\n\n\t\t\t}\n\n\t\t\t//\n\n\t\t\tlet extrudePts, extrudeByPath = false;\n\t\t\tlet splineTube, binormal, normal, position2;\n\n\t\t\tif ( extrudePath ) {\n\n\t\t\t\textrudePts = extrudePath.getSpacedPoints( steps );\n\n\t\t\t\textrudeByPath = true;\n\t\t\t\tbevelEnabled = false; // bevels not supported for path extrusion\n\n\t\t\t\t// SETUP TNB variables\n\n\t\t\t\t// TODO1 - have a .isClosed in spline?\n\n\t\t\t\tsplineTube = extrudePath.computeFrenetFrames( steps, false );\n\n\t\t\t\t// console.log(splineTube, 'splineTube', splineTube.normals.length, 'steps', steps, 'extrudePts', extrudePts.length);\n\n\t\t\t\tbinormal = new Vector3();\n\t\t\t\tnormal = new Vector3();\n\t\t\t\tposition2 = new Vector3();\n\n\t\t\t}\n\n\t\t\t// Safeguards if bevels are not enabled\n\n\t\t\tif ( ! bevelEnabled ) {\n\n\t\t\t\tbevelSegments = 0;\n\t\t\t\tbevelThickness = 0;\n\t\t\t\tbevelSize = 0;\n\t\t\t\tbevelOffset = 0;\n\n\t\t\t}\n\n\t\t\t// Variables initialization\n\n\t\t\tconst shapePoints = shape.extractPoints( curveSegments );\n\n\t\t\tlet vertices = shapePoints.shape;\n\t\t\tconst holes = shapePoints.holes;\n\n\t\t\tconst reverse = ! ShapeUtils.isClockWise( vertices );\n\n\t\t\tif ( reverse ) {\n\n\t\t\t\tvertices = vertices.reverse();\n\n\t\t\t\t// Maybe we should also check if holes are in the opposite direction, just to be safe ...\n\n\t\t\t\tfor ( let h = 0, hl = holes.length; h < hl; h ++ ) {\n\n\t\t\t\t\tconst ahole = holes[ h ];\n\n\t\t\t\t\tif ( ShapeUtils.isClockWise( ahole ) ) {\n\n\t\t\t\t\t\tholes[ h ] = ahole.reverse();\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\n\t\t\tconst faces = ShapeUtils.triangulateShape( vertices, holes );\n\n\t\t\t/* Vertices */\n\n\t\t\tconst contour = vertices; // vertices has all points but contour has only points of circumference\n\n\t\t\tfor ( let h = 0, hl = holes.length; h < hl; h ++ ) {\n\n\t\t\t\tconst ahole = holes[ h ];\n\n\t\t\t\tvertices = vertices.concat( ahole );\n\n\t\t\t}\n\n\n\t\t\tfunction scalePt2( pt, vec, size ) {\n\n\t\t\t\tif ( ! vec ) console.error( 'THREE.ExtrudeGeometry: vec does not exist' );\n\n\t\t\t\treturn vec.clone().multiplyScalar( size ).add( pt );\n\n\t\t\t}\n\n\t\t\tconst vlen = vertices.length, flen = faces.length;\n\n\n\t\t\t// Find directions for point movement\n\n\n\t\t\tfunction getBevelVec( inPt, inPrev, inNext ) {\n\n\t\t\t\t// computes for inPt the corresponding point inPt' on a new contour\n\t\t\t\t//   shifted by 1 unit (length of normalized vector) to the left\n\t\t\t\t// if we walk along contour clockwise, this new contour is outside the old one\n\t\t\t\t//\n\t\t\t\t// inPt' is the intersection of the two lines parallel to the two\n\t\t\t\t//  adjacent edges of inPt at a distance of 1 unit on the left side.\n\n\t\t\t\tlet v_trans_x, v_trans_y, shrink_by; // resulting translation vector for inPt\n\n\t\t\t\t// good reading for geometry algorithms (here: line-line intersection)\n\t\t\t\t// http://geomalgorithms.com/a05-_intersect-1.html\n\n\t\t\t\tconst v_prev_x = inPt.x - inPrev.x,\n\t\t\t\t\tv_prev_y = inPt.y - inPrev.y;\n\t\t\t\tconst v_next_x = inNext.x - inPt.x,\n\t\t\t\t\tv_next_y = inNext.y - inPt.y;\n\n\t\t\t\tconst v_prev_lensq = ( v_prev_x * v_prev_x + v_prev_y * v_prev_y );\n\n\t\t\t\t// check for collinear edges\n\t\t\t\tconst collinear0 = ( v_prev_x * v_next_y - v_prev_y * v_next_x );\n\n\t\t\t\tif ( Math.abs( collinear0 ) > Number.EPSILON ) {\n\n\t\t\t\t\t// not collinear\n\n\t\t\t\t\t// length of vectors for normalizing\n\n\t\t\t\t\tconst v_prev_len = Math.sqrt( v_prev_lensq );\n\t\t\t\t\tconst v_next_len = Math.sqrt( v_next_x * v_next_x + v_next_y * v_next_y );\n\n\t\t\t\t\t// shift adjacent points by unit vectors to the left\n\n\t\t\t\t\tconst ptPrevShift_x = ( inPrev.x - v_prev_y / v_prev_len );\n\t\t\t\t\tconst ptPrevShift_y = ( inPrev.y + v_prev_x / v_prev_len );\n\n\t\t\t\t\tconst ptNextShift_x = ( inNext.x - v_next_y / v_next_len );\n\t\t\t\t\tconst ptNextShift_y = ( inNext.y + v_next_x / v_next_len );\n\n\t\t\t\t\t// scaling factor for v_prev to intersection point\n\n\t\t\t\t\tconst sf = ( ( ptNextShift_x - ptPrevShift_x ) * v_next_y -\n\t\t\t\t\t\t\t( ptNextShift_y - ptPrevShift_y ) * v_next_x ) /\n\t\t\t\t\t\t( v_prev_x * v_next_y - v_prev_y * v_next_x );\n\n\t\t\t\t\t// vector from inPt to intersection point\n\n\t\t\t\t\tv_trans_x = ( ptPrevShift_x + v_prev_x * sf - inPt.x );\n\t\t\t\t\tv_trans_y = ( ptPrevShift_y + v_prev_y * sf - inPt.y );\n\n\t\t\t\t\t// Don't normalize!, otherwise sharp corners become ugly\n\t\t\t\t\t//  but prevent crazy spikes\n\t\t\t\t\tconst v_trans_lensq = ( v_trans_x * v_trans_x + v_trans_y * v_trans_y );\n\t\t\t\t\tif ( v_trans_lensq <= 2 ) {\n\n\t\t\t\t\t\treturn new Vector2( v_trans_x, v_trans_y );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tshrink_by = Math.sqrt( v_trans_lensq / 2 );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// handle special case of collinear edges\n\n\t\t\t\t\tlet direction_eq = false; // assumes: opposite\n\n\t\t\t\t\tif ( v_prev_x > Number.EPSILON ) {\n\n\t\t\t\t\t\tif ( v_next_x > Number.EPSILON ) {\n\n\t\t\t\t\t\t\tdirection_eq = true;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tif ( v_prev_x < - Number.EPSILON ) {\n\n\t\t\t\t\t\t\tif ( v_next_x < - Number.EPSILON ) {\n\n\t\t\t\t\t\t\t\tdirection_eq = true;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tif ( Math.sign( v_prev_y ) === Math.sign( v_next_y ) ) {\n\n\t\t\t\t\t\t\t\tdirection_eq = true;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( direction_eq ) {\n\n\t\t\t\t\t\t// console.log(\"Warning: lines are a straight sequence\");\n\t\t\t\t\t\tv_trans_x = - v_prev_y;\n\t\t\t\t\t\tv_trans_y = v_prev_x;\n\t\t\t\t\t\tshrink_by = Math.sqrt( v_prev_lensq );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t// console.log(\"Warning: lines are a straight spike\");\n\t\t\t\t\t\tv_trans_x = v_prev_x;\n\t\t\t\t\t\tv_trans_y = v_prev_y;\n\t\t\t\t\t\tshrink_by = Math.sqrt( v_prev_lensq / 2 );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\treturn new Vector2( v_trans_x / shrink_by, v_trans_y / shrink_by );\n\n\t\t\t}\n\n\n\t\t\tconst contourMovements = [];\n\n\t\t\tfor ( let i = 0, il = contour.length, j = il - 1, k = i + 1; i < il; i ++, j ++, k ++ ) {\n\n\t\t\t\tif ( j === il ) j = 0;\n\t\t\t\tif ( k === il ) k = 0;\n\n\t\t\t\t//  (j)---(i)---(k)\n\t\t\t\t// console.log('i,j,k', i, j , k)\n\n\t\t\t\tcontourMovements[ i ] = getBevelVec( contour[ i ], contour[ j ], contour[ k ] );\n\n\t\t\t}\n\n\t\t\tconst holesMovements = [];\n\t\t\tlet oneHoleMovements, verticesMovements = contourMovements.concat();\n\n\t\t\tfor ( let h = 0, hl = holes.length; h < hl; h ++ ) {\n\n\t\t\t\tconst ahole = holes[ h ];\n\n\t\t\t\toneHoleMovements = [];\n\n\t\t\t\tfor ( let i = 0, il = ahole.length, j = il - 1, k = i + 1; i < il; i ++, j ++, k ++ ) {\n\n\t\t\t\t\tif ( j === il ) j = 0;\n\t\t\t\t\tif ( k === il ) k = 0;\n\n\t\t\t\t\t//  (j)---(i)---(k)\n\t\t\t\t\toneHoleMovements[ i ] = getBevelVec( ahole[ i ], ahole[ j ], ahole[ k ] );\n\n\t\t\t\t}\n\n\t\t\t\tholesMovements.push( oneHoleMovements );\n\t\t\t\tverticesMovements = verticesMovements.concat( oneHoleMovements );\n\n\t\t\t}\n\n\n\t\t\t// Loop bevelSegments, 1 for the front, 1 for the back\n\n\t\t\tfor ( let b = 0; b < bevelSegments; b ++ ) {\n\n\t\t\t\t//for ( b = bevelSegments; b > 0; b -- ) {\n\n\t\t\t\tconst t = b / bevelSegments;\n\t\t\t\tconst z = bevelThickness * Math.cos( t * Math.PI / 2 );\n\t\t\t\tconst bs = bevelSize * Math.sin( t * Math.PI / 2 ) + bevelOffset;\n\n\t\t\t\t// contract shape\n\n\t\t\t\tfor ( let i = 0, il = contour.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst vert = scalePt2( contour[ i ], contourMovements[ i ], bs );\n\n\t\t\t\t\tv( vert.x, vert.y, - z );\n\n\t\t\t\t}\n\n\t\t\t\t// expand holes\n\n\t\t\t\tfor ( let h = 0, hl = holes.length; h < hl; h ++ ) {\n\n\t\t\t\t\tconst ahole = holes[ h ];\n\t\t\t\t\toneHoleMovements = holesMovements[ h ];\n\n\t\t\t\t\tfor ( let i = 0, il = ahole.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tconst vert = scalePt2( ahole[ i ], oneHoleMovements[ i ], bs );\n\n\t\t\t\t\t\tv( vert.x, vert.y, - z );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tconst bs = bevelSize + bevelOffset;\n\n\t\t\t// Back facing vertices\n\n\t\t\tfor ( let i = 0; i < vlen; i ++ ) {\n\n\t\t\t\tconst vert = bevelEnabled ? scalePt2( vertices[ i ], verticesMovements[ i ], bs ) : vertices[ i ];\n\n\t\t\t\tif ( ! extrudeByPath ) {\n\n\t\t\t\t\tv( vert.x, vert.y, 0 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// v( vert.x, vert.y + extrudePts[ 0 ].y, extrudePts[ 0 ].x );\n\n\t\t\t\t\tnormal.copy( splineTube.normals[ 0 ] ).multiplyScalar( vert.x );\n\t\t\t\t\tbinormal.copy( splineTube.binormals[ 0 ] ).multiplyScalar( vert.y );\n\n\t\t\t\t\tposition2.copy( extrudePts[ 0 ] ).add( normal ).add( binormal );\n\n\t\t\t\t\tv( position2.x, position2.y, position2.z );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// Add stepped vertices...\n\t\t\t// Including front facing vertices\n\n\t\t\tfor ( let s = 1; s <= steps; s ++ ) {\n\n\t\t\t\tfor ( let i = 0; i < vlen; i ++ ) {\n\n\t\t\t\t\tconst vert = bevelEnabled ? scalePt2( vertices[ i ], verticesMovements[ i ], bs ) : vertices[ i ];\n\n\t\t\t\t\tif ( ! extrudeByPath ) {\n\n\t\t\t\t\t\tv( vert.x, vert.y, depth / steps * s );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t// v( vert.x, vert.y + extrudePts[ s - 1 ].y, extrudePts[ s - 1 ].x );\n\n\t\t\t\t\t\tnormal.copy( splineTube.normals[ s ] ).multiplyScalar( vert.x );\n\t\t\t\t\t\tbinormal.copy( splineTube.binormals[ s ] ).multiplyScalar( vert.y );\n\n\t\t\t\t\t\tposition2.copy( extrudePts[ s ] ).add( normal ).add( binormal );\n\n\t\t\t\t\t\tv( position2.x, position2.y, position2.z );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\n\t\t\t// Add bevel segments planes\n\n\t\t\t//for ( b = 1; b <= bevelSegments; b ++ ) {\n\t\t\tfor ( let b = bevelSegments - 1; b >= 0; b -- ) {\n\n\t\t\t\tconst t = b / bevelSegments;\n\t\t\t\tconst z = bevelThickness * Math.cos( t * Math.PI / 2 );\n\t\t\t\tconst bs = bevelSize * Math.sin( t * Math.PI / 2 ) + bevelOffset;\n\n\t\t\t\t// contract shape\n\n\t\t\t\tfor ( let i = 0, il = contour.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst vert = scalePt2( contour[ i ], contourMovements[ i ], bs );\n\t\t\t\t\tv( vert.x, vert.y, depth + z );\n\n\t\t\t\t}\n\n\t\t\t\t// expand holes\n\n\t\t\t\tfor ( let h = 0, hl = holes.length; h < hl; h ++ ) {\n\n\t\t\t\t\tconst ahole = holes[ h ];\n\t\t\t\t\toneHoleMovements = holesMovements[ h ];\n\n\t\t\t\t\tfor ( let i = 0, il = ahole.length; i < il; i ++ ) {\n\n\t\t\t\t\t\tconst vert = scalePt2( ahole[ i ], oneHoleMovements[ i ], bs );\n\n\t\t\t\t\t\tif ( ! extrudeByPath ) {\n\n\t\t\t\t\t\t\tv( vert.x, vert.y, depth + z );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tv( vert.x, vert.y + extrudePts[ steps - 1 ].y, extrudePts[ steps - 1 ].x + z );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t/* Faces */\n\n\t\t\t// Top and bottom faces\n\n\t\t\tbuildLidFaces();\n\n\t\t\t// Sides faces\n\n\t\t\tbuildSideFaces();\n\n\n\t\t\t/////  Internal functions\n\n\t\t\tfunction buildLidFaces() {\n\n\t\t\t\tconst start = verticesArray.length / 3;\n\n\t\t\t\tif ( bevelEnabled ) {\n\n\t\t\t\t\tlet layer = 0; // steps + 1\n\t\t\t\t\tlet offset = vlen * layer;\n\n\t\t\t\t\t// Bottom faces\n\n\t\t\t\t\tfor ( let i = 0; i < flen; i ++ ) {\n\n\t\t\t\t\t\tconst face = faces[ i ];\n\t\t\t\t\t\tf3( face[ 2 ] + offset, face[ 1 ] + offset, face[ 0 ] + offset );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tlayer = steps + bevelSegments * 2;\n\t\t\t\t\toffset = vlen * layer;\n\n\t\t\t\t\t// Top faces\n\n\t\t\t\t\tfor ( let i = 0; i < flen; i ++ ) {\n\n\t\t\t\t\t\tconst face = faces[ i ];\n\t\t\t\t\t\tf3( face[ 0 ] + offset, face[ 1 ] + offset, face[ 2 ] + offset );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// Bottom faces\n\n\t\t\t\t\tfor ( let i = 0; i < flen; i ++ ) {\n\n\t\t\t\t\t\tconst face = faces[ i ];\n\t\t\t\t\t\tf3( face[ 2 ], face[ 1 ], face[ 0 ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t\t// Top faces\n\n\t\t\t\t\tfor ( let i = 0; i < flen; i ++ ) {\n\n\t\t\t\t\t\tconst face = faces[ i ];\n\t\t\t\t\t\tf3( face[ 0 ] + vlen * steps, face[ 1 ] + vlen * steps, face[ 2 ] + vlen * steps );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tscope.addGroup( start, verticesArray.length / 3 - start, 0 );\n\n\t\t\t}\n\n\t\t\t// Create faces for the z-sides of the shape\n\n\t\t\tfunction buildSideFaces() {\n\n\t\t\t\tconst start = verticesArray.length / 3;\n\t\t\t\tlet layeroffset = 0;\n\t\t\t\tsidewalls( contour, layeroffset );\n\t\t\t\tlayeroffset += contour.length;\n\n\t\t\t\tfor ( let h = 0, hl = holes.length; h < hl; h ++ ) {\n\n\t\t\t\t\tconst ahole = holes[ h ];\n\t\t\t\t\tsidewalls( ahole, layeroffset );\n\n\t\t\t\t\t//, true\n\t\t\t\t\tlayeroffset += ahole.length;\n\n\t\t\t\t}\n\n\n\t\t\t\tscope.addGroup( start, verticesArray.length / 3 - start, 1 );\n\n\n\t\t\t}\n\n\t\t\tfunction sidewalls( contour, layeroffset ) {\n\n\t\t\t\tlet i = contour.length;\n\n\t\t\t\twhile ( -- i >= 0 ) {\n\n\t\t\t\t\tconst j = i;\n\t\t\t\t\tlet k = i - 1;\n\t\t\t\t\tif ( k < 0 ) k = contour.length - 1;\n\n\t\t\t\t\t//console.log('b', i,j, i-1, k,vertices.length);\n\n\t\t\t\t\tfor ( let s = 0, sl = ( steps + bevelSegments * 2 ); s < sl; s ++ ) {\n\n\t\t\t\t\t\tconst slen1 = vlen * s;\n\t\t\t\t\t\tconst slen2 = vlen * ( s + 1 );\n\n\t\t\t\t\t\tconst a = layeroffset + j + slen1,\n\t\t\t\t\t\t\tb = layeroffset + k + slen1,\n\t\t\t\t\t\t\tc = layeroffset + k + slen2,\n\t\t\t\t\t\t\td = layeroffset + j + slen2;\n\n\t\t\t\t\t\tf4( a, b, c, d );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tfunction v( x, y, z ) {\n\n\t\t\t\tplaceholder.push( x );\n\t\t\t\tplaceholder.push( y );\n\t\t\t\tplaceholder.push( z );\n\n\t\t\t}\n\n\n\t\t\tfunction f3( a, b, c ) {\n\n\t\t\t\taddVertex( a );\n\t\t\t\taddVertex( b );\n\t\t\t\taddVertex( c );\n\n\t\t\t\tconst nextIndex = verticesArray.length / 3;\n\t\t\t\tconst uvs = uvgen.generateTopUV( scope, verticesArray, nextIndex - 3, nextIndex - 2, nextIndex - 1 );\n\n\t\t\t\taddUV( uvs[ 0 ] );\n\t\t\t\taddUV( uvs[ 1 ] );\n\t\t\t\taddUV( uvs[ 2 ] );\n\n\t\t\t}\n\n\t\t\tfunction f4( a, b, c, d ) {\n\n\t\t\t\taddVertex( a );\n\t\t\t\taddVertex( b );\n\t\t\t\taddVertex( d );\n\n\t\t\t\taddVertex( b );\n\t\t\t\taddVertex( c );\n\t\t\t\taddVertex( d );\n\n\n\t\t\t\tconst nextIndex = verticesArray.length / 3;\n\t\t\t\tconst uvs = uvgen.generateSideWallUV( scope, verticesArray, nextIndex - 6, nextIndex - 3, nextIndex - 2, nextIndex - 1 );\n\n\t\t\t\taddUV( uvs[ 0 ] );\n\t\t\t\taddUV( uvs[ 1 ] );\n\t\t\t\taddUV( uvs[ 3 ] );\n\n\t\t\t\taddUV( uvs[ 1 ] );\n\t\t\t\taddUV( uvs[ 2 ] );\n\t\t\t\taddUV( uvs[ 3 ] );\n\n\t\t\t}\n\n\t\t\tfunction addVertex( index ) {\n\n\t\t\t\tverticesArray.push( placeholder[ index * 3 + 0 ] );\n\t\t\t\tverticesArray.push( placeholder[ index * 3 + 1 ] );\n\t\t\t\tverticesArray.push( placeholder[ index * 3 + 2 ] );\n\n\t\t\t}\n\n\n\t\t\tfunction addUV( vector2 ) {\n\n\t\t\t\tuvArray.push( vector2.x );\n\t\t\t\tuvArray.push( vector2.y );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tconst shapes = this.parameters.shapes;\n\t\tconst options = this.parameters.options;\n\n\t\treturn toJSON$1( shapes, options, data );\n\n\t}\n\n\tstatic fromJSON( data, shapes ) {\n\n\t\tconst geometryShapes = [];\n\n\t\tfor ( let j = 0, jl = data.shapes.length; j < jl; j ++ ) {\n\n\t\t\tconst shape = shapes[ data.shapes[ j ] ];\n\n\t\t\tgeometryShapes.push( shape );\n\n\t\t}\n\n\t\tconst extrudePath = data.options.extrudePath;\n\n\t\tif ( extrudePath !== undefined ) {\n\n\t\t\tdata.options.extrudePath = new Curves[ extrudePath.type ]().fromJSON( extrudePath );\n\n\t\t}\n\n\t\treturn new ExtrudeGeometry( geometryShapes, data.options );\n\n\t}\n\n}\n\nconst WorldUVGenerator = {\n\n\tgenerateTopUV: function ( geometry, vertices, indexA, indexB, indexC ) {\n\n\t\tconst a_x = vertices[ indexA * 3 ];\n\t\tconst a_y = vertices[ indexA * 3 + 1 ];\n\t\tconst b_x = vertices[ indexB * 3 ];\n\t\tconst b_y = vertices[ indexB * 3 + 1 ];\n\t\tconst c_x = vertices[ indexC * 3 ];\n\t\tconst c_y = vertices[ indexC * 3 + 1 ];\n\n\t\treturn [\n\t\t\tnew Vector2( a_x, a_y ),\n\t\t\tnew Vector2( b_x, b_y ),\n\t\t\tnew Vector2( c_x, c_y )\n\t\t];\n\n\t},\n\n\tgenerateSideWallUV: function ( geometry, vertices, indexA, indexB, indexC, indexD ) {\n\n\t\tconst a_x = vertices[ indexA * 3 ];\n\t\tconst a_y = vertices[ indexA * 3 + 1 ];\n\t\tconst a_z = vertices[ indexA * 3 + 2 ];\n\t\tconst b_x = vertices[ indexB * 3 ];\n\t\tconst b_y = vertices[ indexB * 3 + 1 ];\n\t\tconst b_z = vertices[ indexB * 3 + 2 ];\n\t\tconst c_x = vertices[ indexC * 3 ];\n\t\tconst c_y = vertices[ indexC * 3 + 1 ];\n\t\tconst c_z = vertices[ indexC * 3 + 2 ];\n\t\tconst d_x = vertices[ indexD * 3 ];\n\t\tconst d_y = vertices[ indexD * 3 + 1 ];\n\t\tconst d_z = vertices[ indexD * 3 + 2 ];\n\n\t\tif ( Math.abs( a_y - b_y ) < Math.abs( a_x - b_x ) ) {\n\n\t\t\treturn [\n\t\t\t\tnew Vector2( a_x, 1 - a_z ),\n\t\t\t\tnew Vector2( b_x, 1 - b_z ),\n\t\t\t\tnew Vector2( c_x, 1 - c_z ),\n\t\t\t\tnew Vector2( d_x, 1 - d_z )\n\t\t\t];\n\n\t\t} else {\n\n\t\t\treturn [\n\t\t\t\tnew Vector2( a_y, 1 - a_z ),\n\t\t\t\tnew Vector2( b_y, 1 - b_z ),\n\t\t\t\tnew Vector2( c_y, 1 - c_z ),\n\t\t\t\tnew Vector2( d_y, 1 - d_z )\n\t\t\t];\n\n\t\t}\n\n\t}\n\n};\n\nfunction toJSON$1( shapes, options, data ) {\n\n\tdata.shapes = [];\n\n\tif ( Array.isArray( shapes ) ) {\n\n\t\tfor ( let i = 0, l = shapes.length; i < l; i ++ ) {\n\n\t\t\tconst shape = shapes[ i ];\n\n\t\t\tdata.shapes.push( shape.uuid );\n\n\t\t}\n\n\t} else {\n\n\t\tdata.shapes.push( shapes.uuid );\n\n\t}\n\n\tif ( options.extrudePath !== undefined ) data.options.extrudePath = options.extrudePath.toJSON();\n\n\treturn data;\n\n}\n\nclass IcosahedronGeometry extends PolyhedronGeometry {\n\n\tconstructor( radius = 1, detail = 0 ) {\n\n\t\tconst t = ( 1 + Math.sqrt( 5 ) ) / 2;\n\n\t\tconst vertices = [\n\t\t\t- 1, t, 0, \t1, t, 0, \t- 1, - t, 0, \t1, - t, 0,\n\t\t\t0, - 1, t, \t0, 1, t,\t0, - 1, - t, \t0, 1, - t,\n\t\t\tt, 0, - 1, \tt, 0, 1, \t- t, 0, - 1, \t- t, 0, 1\n\t\t];\n\n\t\tconst indices = [\n\t\t\t0, 11, 5, \t0, 5, 1, \t0, 1, 7, \t0, 7, 10, \t0, 10, 11,\n\t\t\t1, 5, 9, \t5, 11, 4,\t11, 10, 2,\t10, 7, 6,\t7, 1, 8,\n\t\t\t3, 9, 4, \t3, 4, 2,\t3, 2, 6,\t3, 6, 8,\t3, 8, 9,\n\t\t\t4, 9, 5, \t2, 4, 11,\t6, 2, 10,\t8, 6, 7,\t9, 8, 1\n\t\t];\n\n\t\tsuper( vertices, indices, radius, detail );\n\n\t\tthis.type = 'IcosahedronGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\tdetail: detail\n\t\t};\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new IcosahedronGeometry( data.radius, data.detail );\n\n\t}\n\n}\n\nclass LatheGeometry extends BufferGeometry {\n\n\tconstructor( points = [ new Vector2( 0, 0.5 ), new Vector2( 0.5, 0 ), new Vector2( 0, - 0.5 ) ], segments = 12, phiStart = 0, phiLength = Math.PI * 2 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'LatheGeometry';\n\n\t\tthis.parameters = {\n\t\t\tpoints: points,\n\t\t\tsegments: segments,\n\t\t\tphiStart: phiStart,\n\t\t\tphiLength: phiLength\n\t\t};\n\n\t\tsegments = Math.floor( segments );\n\n\t\t// clamp phiLength so it's in range of [ 0, 2PI ]\n\n\t\tphiLength = clamp( phiLength, 0, Math.PI * 2 );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst uvs = [];\n\t\tconst initNormals = [];\n\t\tconst normals = [];\n\n\t\t// helper variables\n\n\t\tconst inverseSegments = 1.0 / segments;\n\t\tconst vertex = new Vector3();\n\t\tconst uv = new Vector2();\n\t\tconst normal = new Vector3();\n\t\tconst curNormal = new Vector3();\n\t\tconst prevNormal = new Vector3();\n\t\tlet dx = 0;\n\t\tlet dy = 0;\n\n\t\t// pre-compute normals for initial \"meridian\"\n\n\t\tfor ( let j = 0; j <= ( points.length - 1 ); j ++ ) {\n\n\t\t\tswitch ( j ) {\n\n\t\t\t\tcase 0:\t\t\t\t// special handling for 1st vertex on path\n\n\t\t\t\t\tdx = points[ j + 1 ].x - points[ j ].x;\n\t\t\t\t\tdy = points[ j + 1 ].y - points[ j ].y;\n\n\t\t\t\t\tnormal.x = dy * 1.0;\n\t\t\t\t\tnormal.y = - dx;\n\t\t\t\t\tnormal.z = dy * 0.0;\n\n\t\t\t\t\tprevNormal.copy( normal );\n\n\t\t\t\t\tnormal.normalize();\n\n\t\t\t\t\tinitNormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase ( points.length - 1 ):\t// special handling for last Vertex on path\n\n\t\t\t\t\tinitNormals.push( prevNormal.x, prevNormal.y, prevNormal.z );\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\t\t\t// default handling for all vertices in between\n\n\t\t\t\t\tdx = points[ j + 1 ].x - points[ j ].x;\n\t\t\t\t\tdy = points[ j + 1 ].y - points[ j ].y;\n\n\t\t\t\t\tnormal.x = dy * 1.0;\n\t\t\t\t\tnormal.y = - dx;\n\t\t\t\t\tnormal.z = dy * 0.0;\n\n\t\t\t\t\tcurNormal.copy( normal );\n\n\t\t\t\t\tnormal.x += prevNormal.x;\n\t\t\t\t\tnormal.y += prevNormal.y;\n\t\t\t\t\tnormal.z += prevNormal.z;\n\n\t\t\t\t\tnormal.normalize();\n\n\t\t\t\t\tinitNormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t\tprevNormal.copy( curNormal );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// generate vertices, uvs and normals\n\n\t\tfor ( let i = 0; i <= segments; i ++ ) {\n\n\t\t\tconst phi = phiStart + i * inverseSegments * phiLength;\n\n\t\t\tconst sin = Math.sin( phi );\n\t\t\tconst cos = Math.cos( phi );\n\n\t\t\tfor ( let j = 0; j <= ( points.length - 1 ); j ++ ) {\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertex.x = points[ j ].x * sin;\n\t\t\t\tvertex.y = points[ j ].y;\n\t\t\t\tvertex.z = points[ j ].x * cos;\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t// uv\n\n\t\t\t\tuv.x = i / segments;\n\t\t\t\tuv.y = j / ( points.length - 1 );\n\n\t\t\t\tuvs.push( uv.x, uv.y );\n\n\t\t\t\t// normal\n\n\t\t\t\tconst x = initNormals[ 3 * j + 0 ] * sin;\n\t\t\t\tconst y = initNormals[ 3 * j + 1 ];\n\t\t\t\tconst z = initNormals[ 3 * j + 0 ] * cos;\n\n\t\t\t\tnormals.push( x, y, z );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// indices\n\n\t\tfor ( let i = 0; i < segments; i ++ ) {\n\n\t\t\tfor ( let j = 0; j < ( points.length - 1 ); j ++ ) {\n\n\t\t\t\tconst base = j + i * points.length;\n\n\t\t\t\tconst a = base;\n\t\t\t\tconst b = base + points.length;\n\t\t\t\tconst c = base + points.length + 1;\n\t\t\t\tconst d = base + 1;\n\n\t\t\t\t// faces\n\n\t\t\t\tindices.push( a, b, d );\n\t\t\t\tindices.push( c, d, b );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new LatheGeometry( data.points, data.segments, data.phiStart, data.phiLength );\n\n\t}\n\n}\n\nclass OctahedronGeometry extends PolyhedronGeometry {\n\n\tconstructor( radius = 1, detail = 0 ) {\n\n\t\tconst vertices = [\n\t\t\t1, 0, 0, \t- 1, 0, 0,\t0, 1, 0,\n\t\t\t0, - 1, 0, \t0, 0, 1,\t0, 0, - 1\n\t\t];\n\n\t\tconst indices = [\n\t\t\t0, 2, 4,\t0, 4, 3,\t0, 3, 5,\n\t\t\t0, 5, 2,\t1, 2, 5,\t1, 5, 3,\n\t\t\t1, 3, 4,\t1, 4, 2\n\t\t];\n\n\t\tsuper( vertices, indices, radius, detail );\n\n\t\tthis.type = 'OctahedronGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\tdetail: detail\n\t\t};\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new OctahedronGeometry( data.radius, data.detail );\n\n\t}\n\n}\n\nclass RingGeometry extends BufferGeometry {\n\n\tconstructor( innerRadius = 0.5, outerRadius = 1, thetaSegments = 8, phiSegments = 1, thetaStart = 0, thetaLength = Math.PI * 2 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'RingGeometry';\n\n\t\tthis.parameters = {\n\t\t\tinnerRadius: innerRadius,\n\t\t\touterRadius: outerRadius,\n\t\t\tthetaSegments: thetaSegments,\n\t\t\tphiSegments: phiSegments,\n\t\t\tthetaStart: thetaStart,\n\t\t\tthetaLength: thetaLength\n\t\t};\n\n\t\tthetaSegments = Math.max( 3, thetaSegments );\n\t\tphiSegments = Math.max( 1, phiSegments );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// some helper variables\n\n\t\tlet radius = innerRadius;\n\t\tconst radiusStep = ( ( outerRadius - innerRadius ) / phiSegments );\n\t\tconst vertex = new Vector3();\n\t\tconst uv = new Vector2();\n\n\t\t// generate vertices, normals and uvs\n\n\t\tfor ( let j = 0; j <= phiSegments; j ++ ) {\n\n\t\t\tfor ( let i = 0; i <= thetaSegments; i ++ ) {\n\n\t\t\t\t// values are generate from the inside of the ring to the outside\n\n\t\t\t\tconst segment = thetaStart + i / thetaSegments * thetaLength;\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertex.x = radius * Math.cos( segment );\n\t\t\t\tvertex.y = radius * Math.sin( segment );\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t// normal\n\n\t\t\t\tnormals.push( 0, 0, 1 );\n\n\t\t\t\t// uv\n\n\t\t\t\tuv.x = ( vertex.x / outerRadius + 1 ) / 2;\n\t\t\t\tuv.y = ( vertex.y / outerRadius + 1 ) / 2;\n\n\t\t\t\tuvs.push( uv.x, uv.y );\n\n\t\t\t}\n\n\t\t\t// increase the radius for next row of vertices\n\n\t\t\tradius += radiusStep;\n\n\t\t}\n\n\t\t// indices\n\n\t\tfor ( let j = 0; j < phiSegments; j ++ ) {\n\n\t\t\tconst thetaSegmentLevel = j * ( thetaSegments + 1 );\n\n\t\t\tfor ( let i = 0; i < thetaSegments; i ++ ) {\n\n\t\t\t\tconst segment = i + thetaSegmentLevel;\n\n\t\t\t\tconst a = segment;\n\t\t\t\tconst b = segment + thetaSegments + 1;\n\t\t\t\tconst c = segment + thetaSegments + 2;\n\t\t\t\tconst d = segment + 1;\n\n\t\t\t\t// faces\n\n\t\t\t\tindices.push( a, b, d );\n\t\t\t\tindices.push( b, c, d );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new RingGeometry( data.innerRadius, data.outerRadius, data.thetaSegments, data.phiSegments, data.thetaStart, data.thetaLength );\n\n\t}\n\n}\n\nclass ShapeGeometry extends BufferGeometry {\n\n\tconstructor( shapes = new Shape( [ new Vector2( 0, 0.5 ), new Vector2( - 0.5, - 0.5 ), new Vector2( 0.5, - 0.5 ) ] ), curveSegments = 12 ) {\n\n\t\tsuper();\n\t\tthis.type = 'ShapeGeometry';\n\n\t\tthis.parameters = {\n\t\t\tshapes: shapes,\n\t\t\tcurveSegments: curveSegments\n\t\t};\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// helper variables\n\n\t\tlet groupStart = 0;\n\t\tlet groupCount = 0;\n\n\t\t// allow single and array values for \"shapes\" parameter\n\n\t\tif ( Array.isArray( shapes ) === false ) {\n\n\t\t\taddShape( shapes );\n\n\t\t} else {\n\n\t\t\tfor ( let i = 0; i < shapes.length; i ++ ) {\n\n\t\t\t\taddShape( shapes[ i ] );\n\n\t\t\t\tthis.addGroup( groupStart, groupCount, i ); // enables MultiMaterial support\n\n\t\t\t\tgroupStart += groupCount;\n\t\t\t\tgroupCount = 0;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\n\t\t// helper functions\n\n\t\tfunction addShape( shape ) {\n\n\t\t\tconst indexOffset = vertices.length / 3;\n\t\t\tconst points = shape.extractPoints( curveSegments );\n\n\t\t\tlet shapeVertices = points.shape;\n\t\t\tconst shapeHoles = points.holes;\n\n\t\t\t// check direction of vertices\n\n\t\t\tif ( ShapeUtils.isClockWise( shapeVertices ) === false ) {\n\n\t\t\t\tshapeVertices = shapeVertices.reverse();\n\n\t\t\t}\n\n\t\t\tfor ( let i = 0, l = shapeHoles.length; i < l; i ++ ) {\n\n\t\t\t\tconst shapeHole = shapeHoles[ i ];\n\n\t\t\t\tif ( ShapeUtils.isClockWise( shapeHole ) === true ) {\n\n\t\t\t\t\tshapeHoles[ i ] = shapeHole.reverse();\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tconst faces = ShapeUtils.triangulateShape( shapeVertices, shapeHoles );\n\n\t\t\t// join vertices of inner and outer paths to a single array\n\n\t\t\tfor ( let i = 0, l = shapeHoles.length; i < l; i ++ ) {\n\n\t\t\t\tconst shapeHole = shapeHoles[ i ];\n\t\t\t\tshapeVertices = shapeVertices.concat( shapeHole );\n\n\t\t\t}\n\n\t\t\t// vertices, normals, uvs\n\n\t\t\tfor ( let i = 0, l = shapeVertices.length; i < l; i ++ ) {\n\n\t\t\t\tconst vertex = shapeVertices[ i ];\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, 0 );\n\t\t\t\tnormals.push( 0, 0, 1 );\n\t\t\t\tuvs.push( vertex.x, vertex.y ); // world uvs\n\n\t\t\t}\n\n\t\t\t// incides\n\n\t\t\tfor ( let i = 0, l = faces.length; i < l; i ++ ) {\n\n\t\t\t\tconst face = faces[ i ];\n\n\t\t\t\tconst a = face[ 0 ] + indexOffset;\n\t\t\t\tconst b = face[ 1 ] + indexOffset;\n\t\t\t\tconst c = face[ 2 ] + indexOffset;\n\n\t\t\t\tindices.push( a, b, c );\n\t\t\t\tgroupCount += 3;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tconst shapes = this.parameters.shapes;\n\n\t\treturn toJSON( shapes, data );\n\n\t}\n\n\tstatic fromJSON( data, shapes ) {\n\n\t\tconst geometryShapes = [];\n\n\t\tfor ( let j = 0, jl = data.shapes.length; j < jl; j ++ ) {\n\n\t\t\tconst shape = shapes[ data.shapes[ j ] ];\n\n\t\t\tgeometryShapes.push( shape );\n\n\t\t}\n\n\t\treturn new ShapeGeometry( geometryShapes, data.curveSegments );\n\n\t}\n\n}\n\nfunction toJSON( shapes, data ) {\n\n\tdata.shapes = [];\n\n\tif ( Array.isArray( shapes ) ) {\n\n\t\tfor ( let i = 0, l = shapes.length; i < l; i ++ ) {\n\n\t\t\tconst shape = shapes[ i ];\n\n\t\t\tdata.shapes.push( shape.uuid );\n\n\t\t}\n\n\t} else {\n\n\t\tdata.shapes.push( shapes.uuid );\n\n\t}\n\n\treturn data;\n\n}\n\nclass SphereGeometry extends BufferGeometry {\n\n\tconstructor( radius = 1, widthSegments = 32, heightSegments = 16, phiStart = 0, phiLength = Math.PI * 2, thetaStart = 0, thetaLength = Math.PI ) {\n\n\t\tsuper();\n\t\tthis.type = 'SphereGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\twidthSegments: widthSegments,\n\t\t\theightSegments: heightSegments,\n\t\t\tphiStart: phiStart,\n\t\t\tphiLength: phiLength,\n\t\t\tthetaStart: thetaStart,\n\t\t\tthetaLength: thetaLength\n\t\t};\n\n\t\twidthSegments = Math.max( 3, Math.floor( widthSegments ) );\n\t\theightSegments = Math.max( 2, Math.floor( heightSegments ) );\n\n\t\tconst thetaEnd = Math.min( thetaStart + thetaLength, Math.PI );\n\n\t\tlet index = 0;\n\t\tconst grid = [];\n\n\t\tconst vertex = new Vector3();\n\t\tconst normal = new Vector3();\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// generate vertices, normals and uvs\n\n\t\tfor ( let iy = 0; iy <= heightSegments; iy ++ ) {\n\n\t\t\tconst verticesRow = [];\n\n\t\t\tconst v = iy / heightSegments;\n\n\t\t\t// special case for the poles\n\n\t\t\tlet uOffset = 0;\n\n\t\t\tif ( iy == 0 && thetaStart == 0 ) {\n\n\t\t\t\tuOffset = 0.5 / widthSegments;\n\n\t\t\t} else if ( iy == heightSegments && thetaEnd == Math.PI ) {\n\n\t\t\t\tuOffset = - 0.5 / widthSegments;\n\n\t\t\t}\n\n\t\t\tfor ( let ix = 0; ix <= widthSegments; ix ++ ) {\n\n\t\t\t\tconst u = ix / widthSegments;\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertex.x = - radius * Math.cos( phiStart + u * phiLength ) * Math.sin( thetaStart + v * thetaLength );\n\t\t\t\tvertex.y = radius * Math.cos( thetaStart + v * thetaLength );\n\t\t\t\tvertex.z = radius * Math.sin( phiStart + u * phiLength ) * Math.sin( thetaStart + v * thetaLength );\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t// normal\n\n\t\t\t\tnormal.copy( vertex ).normalize();\n\t\t\t\tnormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t// uv\n\n\t\t\t\tuvs.push( u + uOffset, 1 - v );\n\n\t\t\t\tverticesRow.push( index ++ );\n\n\t\t\t}\n\n\t\t\tgrid.push( verticesRow );\n\n\t\t}\n\n\t\t// indices\n\n\t\tfor ( let iy = 0; iy < heightSegments; iy ++ ) {\n\n\t\t\tfor ( let ix = 0; ix < widthSegments; ix ++ ) {\n\n\t\t\t\tconst a = grid[ iy ][ ix + 1 ];\n\t\t\t\tconst b = grid[ iy ][ ix ];\n\t\t\t\tconst c = grid[ iy + 1 ][ ix ];\n\t\t\t\tconst d = grid[ iy + 1 ][ ix + 1 ];\n\n\t\t\t\tif ( iy !== 0 || thetaStart > 0 ) indices.push( a, b, d );\n\t\t\t\tif ( iy !== heightSegments - 1 || thetaEnd < Math.PI ) indices.push( b, c, d );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new SphereGeometry( data.radius, data.widthSegments, data.heightSegments, data.phiStart, data.phiLength, data.thetaStart, data.thetaLength );\n\n\t}\n\n}\n\nclass TetrahedronGeometry extends PolyhedronGeometry {\n\n\tconstructor( radius = 1, detail = 0 ) {\n\n\t\tconst vertices = [\n\t\t\t1, 1, 1, \t- 1, - 1, 1, \t- 1, 1, - 1, \t1, - 1, - 1\n\t\t];\n\n\t\tconst indices = [\n\t\t\t2, 1, 0, \t0, 3, 2,\t1, 3, 0,\t2, 3, 1\n\t\t];\n\n\t\tsuper( vertices, indices, radius, detail );\n\n\t\tthis.type = 'TetrahedronGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\tdetail: detail\n\t\t};\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new TetrahedronGeometry( data.radius, data.detail );\n\n\t}\n\n}\n\nclass TorusGeometry extends BufferGeometry {\n\n\tconstructor( radius = 1, tube = 0.4, radialSegments = 8, tubularSegments = 6, arc = Math.PI * 2 ) {\n\n\t\tsuper();\n\t\tthis.type = 'TorusGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\ttube: tube,\n\t\t\tradialSegments: radialSegments,\n\t\t\ttubularSegments: tubularSegments,\n\t\t\tarc: arc\n\t\t};\n\n\t\tradialSegments = Math.floor( radialSegments );\n\t\ttubularSegments = Math.floor( tubularSegments );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// helper variables\n\n\t\tconst center = new Vector3();\n\t\tconst vertex = new Vector3();\n\t\tconst normal = new Vector3();\n\n\t\t// generate vertices, normals and uvs\n\n\t\tfor ( let j = 0; j <= radialSegments; j ++ ) {\n\n\t\t\tfor ( let i = 0; i <= tubularSegments; i ++ ) {\n\n\t\t\t\tconst u = i / tubularSegments * arc;\n\t\t\t\tconst v = j / radialSegments * Math.PI * 2;\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertex.x = ( radius + tube * Math.cos( v ) ) * Math.cos( u );\n\t\t\t\tvertex.y = ( radius + tube * Math.cos( v ) ) * Math.sin( u );\n\t\t\t\tvertex.z = tube * Math.sin( v );\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t// normal\n\n\t\t\t\tcenter.x = radius * Math.cos( u );\n\t\t\t\tcenter.y = radius * Math.sin( u );\n\t\t\t\tnormal.subVectors( vertex, center ).normalize();\n\n\t\t\t\tnormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t// uv\n\n\t\t\t\tuvs.push( i / tubularSegments );\n\t\t\t\tuvs.push( j / radialSegments );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// generate indices\n\n\t\tfor ( let j = 1; j <= radialSegments; j ++ ) {\n\n\t\t\tfor ( let i = 1; i <= tubularSegments; i ++ ) {\n\n\t\t\t\t// indices\n\n\t\t\t\tconst a = ( tubularSegments + 1 ) * j + i - 1;\n\t\t\t\tconst b = ( tubularSegments + 1 ) * ( j - 1 ) + i - 1;\n\t\t\t\tconst c = ( tubularSegments + 1 ) * ( j - 1 ) + i;\n\t\t\t\tconst d = ( tubularSegments + 1 ) * j + i;\n\n\t\t\t\t// faces\n\n\t\t\t\tindices.push( a, b, d );\n\t\t\t\tindices.push( b, c, d );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new TorusGeometry( data.radius, data.tube, data.radialSegments, data.tubularSegments, data.arc );\n\n\t}\n\n}\n\nclass TorusKnotGeometry extends BufferGeometry {\n\n\tconstructor( radius = 1, tube = 0.4, tubularSegments = 64, radialSegments = 8, p = 2, q = 3 ) {\n\n\t\tsuper();\n\t\tthis.type = 'TorusKnotGeometry';\n\n\t\tthis.parameters = {\n\t\t\tradius: radius,\n\t\t\ttube: tube,\n\t\t\ttubularSegments: tubularSegments,\n\t\t\tradialSegments: radialSegments,\n\t\t\tp: p,\n\t\t\tq: q\n\t\t};\n\n\t\ttubularSegments = Math.floor( tubularSegments );\n\t\tradialSegments = Math.floor( radialSegments );\n\n\t\t// buffers\n\n\t\tconst indices = [];\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\n\t\t// helper variables\n\n\t\tconst vertex = new Vector3();\n\t\tconst normal = new Vector3();\n\n\t\tconst P1 = new Vector3();\n\t\tconst P2 = new Vector3();\n\n\t\tconst B = new Vector3();\n\t\tconst T = new Vector3();\n\t\tconst N = new Vector3();\n\n\t\t// generate vertices, normals and uvs\n\n\t\tfor ( let i = 0; i <= tubularSegments; ++ i ) {\n\n\t\t\t// the radian \"u\" is used to calculate the position on the torus curve of the current tubular segement\n\n\t\t\tconst u = i / tubularSegments * p * Math.PI * 2;\n\n\t\t\t// now we calculate two points. P1 is our current position on the curve, P2 is a little farther ahead.\n\t\t\t// these points are used to create a special \"coordinate space\", which is necessary to calculate the correct vertex positions\n\n\t\t\tcalculatePositionOnCurve( u, p, q, radius, P1 );\n\t\t\tcalculatePositionOnCurve( u + 0.01, p, q, radius, P2 );\n\n\t\t\t// calculate orthonormal basis\n\n\t\t\tT.subVectors( P2, P1 );\n\t\t\tN.addVectors( P2, P1 );\n\t\t\tB.crossVectors( T, N );\n\t\t\tN.crossVectors( B, T );\n\n\t\t\t// normalize B, N. T can be ignored, we don't use it\n\n\t\t\tB.normalize();\n\t\t\tN.normalize();\n\n\t\t\tfor ( let j = 0; j <= radialSegments; ++ j ) {\n\n\t\t\t\t// now calculate the vertices. they are nothing more than an extrusion of the torus curve.\n\t\t\t\t// because we extrude a shape in the xy-plane, there is no need to calculate a z-value.\n\n\t\t\t\tconst v = j / radialSegments * Math.PI * 2;\n\t\t\t\tconst cx = - tube * Math.cos( v );\n\t\t\t\tconst cy = tube * Math.sin( v );\n\n\t\t\t\t// now calculate the final vertex position.\n\t\t\t\t// first we orient the extrusion with our basis vectos, then we add it to the current position on the curve\n\n\t\t\t\tvertex.x = P1.x + ( cx * N.x + cy * B.x );\n\t\t\t\tvertex.y = P1.y + ( cx * N.y + cy * B.y );\n\t\t\t\tvertex.z = P1.z + ( cx * N.z + cy * B.z );\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t\t// normal (P1 is always the center/origin of the extrusion, thus we can use it to calculate the normal)\n\n\t\t\t\tnormal.subVectors( vertex, P1 ).normalize();\n\n\t\t\t\tnormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t// uv\n\n\t\t\t\tuvs.push( i / tubularSegments );\n\t\t\t\tuvs.push( j / radialSegments );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// generate indices\n\n\t\tfor ( let j = 1; j <= tubularSegments; j ++ ) {\n\n\t\t\tfor ( let i = 1; i <= radialSegments; i ++ ) {\n\n\t\t\t\t// indices\n\n\t\t\t\tconst a = ( radialSegments + 1 ) * ( j - 1 ) + ( i - 1 );\n\t\t\t\tconst b = ( radialSegments + 1 ) * j + ( i - 1 );\n\t\t\t\tconst c = ( radialSegments + 1 ) * j + i;\n\t\t\t\tconst d = ( radialSegments + 1 ) * ( j - 1 ) + i;\n\n\t\t\t\t// faces\n\n\t\t\t\tindices.push( a, b, d );\n\t\t\t\tindices.push( b, c, d );\n\n\t\t\t}\n\n\t\t}\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t\t// this function calculates the current position on the torus curve\n\n\t\tfunction calculatePositionOnCurve( u, p, q, radius, position ) {\n\n\t\t\tconst cu = Math.cos( u );\n\t\t\tconst su = Math.sin( u );\n\t\t\tconst quOverP = q / p * u;\n\t\t\tconst cs = Math.cos( quOverP );\n\n\t\t\tposition.x = radius * ( 2 + cs ) * 0.5 * cu;\n\t\t\tposition.y = radius * ( 2 + cs ) * su * 0.5;\n\t\t\tposition.z = radius * Math.sin( quOverP ) * 0.5;\n\n\t\t}\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\treturn new TorusKnotGeometry( data.radius, data.tube, data.tubularSegments, data.radialSegments, data.p, data.q );\n\n\t}\n\n}\n\nclass TubeGeometry extends BufferGeometry {\n\n\tconstructor( path = new QuadraticBezierCurve3( new Vector3( - 1, - 1, 0 ), new Vector3( - 1, 1, 0 ), new Vector3( 1, 1, 0 ) ), tubularSegments = 64, radius = 1, radialSegments = 8, closed = false ) {\n\n\t\tsuper();\n\t\tthis.type = 'TubeGeometry';\n\n\t\tthis.parameters = {\n\t\t\tpath: path,\n\t\t\ttubularSegments: tubularSegments,\n\t\t\tradius: radius,\n\t\t\tradialSegments: radialSegments,\n\t\t\tclosed: closed\n\t\t};\n\n\t\tconst frames = path.computeFrenetFrames( tubularSegments, closed );\n\n\t\t// expose internals\n\n\t\tthis.tangents = frames.tangents;\n\t\tthis.normals = frames.normals;\n\t\tthis.binormals = frames.binormals;\n\n\t\t// helper variables\n\n\t\tconst vertex = new Vector3();\n\t\tconst normal = new Vector3();\n\t\tconst uv = new Vector2();\n\t\tlet P = new Vector3();\n\n\t\t// buffer\n\n\t\tconst vertices = [];\n\t\tconst normals = [];\n\t\tconst uvs = [];\n\t\tconst indices = [];\n\n\t\t// create buffer data\n\n\t\tgenerateBufferData();\n\n\t\t// build geometry\n\n\t\tthis.setIndex( indices );\n\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tthis.setAttribute( 'normal', new Float32BufferAttribute( normals, 3 ) );\n\t\tthis.setAttribute( 'uv', new Float32BufferAttribute( uvs, 2 ) );\n\n\t\t// functions\n\n\t\tfunction generateBufferData() {\n\n\t\t\tfor ( let i = 0; i < tubularSegments; i ++ ) {\n\n\t\t\t\tgenerateSegment( i );\n\n\t\t\t}\n\n\t\t\t// if the geometry is not closed, generate the last row of vertices and normals\n\t\t\t// at the regular position on the given path\n\t\t\t//\n\t\t\t// if the geometry is closed, duplicate the first row of vertices and normals (uvs will differ)\n\n\t\t\tgenerateSegment( ( closed === false ) ? tubularSegments : 0 );\n\n\t\t\t// uvs are generated in a separate function.\n\t\t\t// this makes it easy compute correct values for closed geometries\n\n\t\t\tgenerateUVs();\n\n\t\t\t// finally create faces\n\n\t\t\tgenerateIndices();\n\n\t\t}\n\n\t\tfunction generateSegment( i ) {\n\n\t\t\t// we use getPointAt to sample evenly distributed points from the given path\n\n\t\t\tP = path.getPointAt( i / tubularSegments, P );\n\n\t\t\t// retrieve corresponding normal and binormal\n\n\t\t\tconst N = frames.normals[ i ];\n\t\t\tconst B = frames.binormals[ i ];\n\n\t\t\t// generate normals and vertices for the current segment\n\n\t\t\tfor ( let j = 0; j <= radialSegments; j ++ ) {\n\n\t\t\t\tconst v = j / radialSegments * Math.PI * 2;\n\n\t\t\t\tconst sin = Math.sin( v );\n\t\t\t\tconst cos = - Math.cos( v );\n\n\t\t\t\t// normal\n\n\t\t\t\tnormal.x = ( cos * N.x + sin * B.x );\n\t\t\t\tnormal.y = ( cos * N.y + sin * B.y );\n\t\t\t\tnormal.z = ( cos * N.z + sin * B.z );\n\t\t\t\tnormal.normalize();\n\n\t\t\t\tnormals.push( normal.x, normal.y, normal.z );\n\n\t\t\t\t// vertex\n\n\t\t\t\tvertex.x = P.x + radius * normal.x;\n\t\t\t\tvertex.y = P.y + radius * normal.y;\n\t\t\t\tvertex.z = P.z + radius * normal.z;\n\n\t\t\t\tvertices.push( vertex.x, vertex.y, vertex.z );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction generateIndices() {\n\n\t\t\tfor ( let j = 1; j <= tubularSegments; j ++ ) {\n\n\t\t\t\tfor ( let i = 1; i <= radialSegments; i ++ ) {\n\n\t\t\t\t\tconst a = ( radialSegments + 1 ) * ( j - 1 ) + ( i - 1 );\n\t\t\t\t\tconst b = ( radialSegments + 1 ) * j + ( i - 1 );\n\t\t\t\t\tconst c = ( radialSegments + 1 ) * j + i;\n\t\t\t\t\tconst d = ( radialSegments + 1 ) * ( j - 1 ) + i;\n\n\t\t\t\t\t// faces\n\n\t\t\t\t\tindices.push( a, b, d );\n\t\t\t\t\tindices.push( b, c, d );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction generateUVs() {\n\n\t\t\tfor ( let i = 0; i <= tubularSegments; i ++ ) {\n\n\t\t\t\tfor ( let j = 0; j <= radialSegments; j ++ ) {\n\n\t\t\t\t\tuv.x = i / tubularSegments;\n\t\t\t\t\tuv.y = j / radialSegments;\n\n\t\t\t\t\tuvs.push( uv.x, uv.y );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON();\n\n\t\tdata.path = this.parameters.path.toJSON();\n\n\t\treturn data;\n\n\t}\n\n\tstatic fromJSON( data ) {\n\n\t\t// This only works for built-in curves (e.g. CatmullRomCurve3).\n\t\t// User defined curves or instances of CurvePath will not be deserialized.\n\t\treturn new TubeGeometry(\n\t\t\tnew Curves[ data.path.type ]().fromJSON( data.path ),\n\t\t\tdata.tubularSegments,\n\t\t\tdata.radius,\n\t\t\tdata.radialSegments,\n\t\t\tdata.closed\n\t\t);\n\n\t}\n\n}\n\nclass WireframeGeometry extends BufferGeometry {\n\n\tconstructor( geometry = null ) {\n\n\t\tsuper();\n\t\tthis.type = 'WireframeGeometry';\n\n\t\tthis.parameters = {\n\t\t\tgeometry: geometry\n\t\t};\n\n\t\tif ( geometry !== null ) {\n\n\t\t\t// buffer\n\n\t\t\tconst vertices = [];\n\t\t\tconst edges = new Set();\n\n\t\t\t// helper variables\n\n\t\t\tconst start = new Vector3();\n\t\t\tconst end = new Vector3();\n\n\t\t\tif ( geometry.index !== null ) {\n\n\t\t\t\t// indexed BufferGeometry\n\n\t\t\t\tconst position = geometry.attributes.position;\n\t\t\t\tconst indices = geometry.index;\n\t\t\t\tlet groups = geometry.groups;\n\n\t\t\t\tif ( groups.length === 0 ) {\n\n\t\t\t\t\tgroups = [ { start: 0, count: indices.count, materialIndex: 0 } ];\n\n\t\t\t\t}\n\n\t\t\t\t// create a data structure that contains all eges without duplicates\n\n\t\t\t\tfor ( let o = 0, ol = groups.length; o < ol; ++ o ) {\n\n\t\t\t\t\tconst group = groups[ o ];\n\n\t\t\t\t\tconst groupStart = group.start;\n\t\t\t\t\tconst groupCount = group.count;\n\n\t\t\t\t\tfor ( let i = groupStart, l = ( groupStart + groupCount ); i < l; i += 3 ) {\n\n\t\t\t\t\t\tfor ( let j = 0; j < 3; j ++ ) {\n\n\t\t\t\t\t\t\tconst index1 = indices.getX( i + j );\n\t\t\t\t\t\t\tconst index2 = indices.getX( i + ( j + 1 ) % 3 );\n\n\t\t\t\t\t\t\tstart.fromBufferAttribute( position, index1 );\n\t\t\t\t\t\t\tend.fromBufferAttribute( position, index2 );\n\n\t\t\t\t\t\t\tif ( isUniqueEdge( start, end, edges ) === true ) {\n\n\t\t\t\t\t\t\t\tvertices.push( start.x, start.y, start.z );\n\t\t\t\t\t\t\t\tvertices.push( end.x, end.y, end.z );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\t// non-indexed BufferGeometry\n\n\t\t\t\tconst position = geometry.attributes.position;\n\n\t\t\t\tfor ( let i = 0, l = ( position.count / 3 ); i < l; i ++ ) {\n\n\t\t\t\t\tfor ( let j = 0; j < 3; j ++ ) {\n\n\t\t\t\t\t\t// three edges per triangle, an edge is represented as (index1, index2)\n\t\t\t\t\t\t// e.g. the first triangle has the following edges: (0,1),(1,2),(2,0)\n\n\t\t\t\t\t\tconst index1 = 3 * i + j;\n\t\t\t\t\t\tconst index2 = 3 * i + ( ( j + 1 ) % 3 );\n\n\t\t\t\t\t\tstart.fromBufferAttribute( position, index1 );\n\t\t\t\t\t\tend.fromBufferAttribute( position, index2 );\n\n\t\t\t\t\t\tif ( isUniqueEdge( start, end, edges ) === true ) {\n\n\t\t\t\t\t\t\tvertices.push( start.x, start.y, start.z );\n\t\t\t\t\t\t\tvertices.push( end.x, end.y, end.z );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// build geometry\n\n\t\t\tthis.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\n\t\t}\n\n\t}\n\n}\n\nfunction isUniqueEdge( start, end, edges ) {\n\n\tconst hash1 = `${start.x},${start.y},${start.z}-${end.x},${end.y},${end.z}`;\n\tconst hash2 = `${end.x},${end.y},${end.z}-${start.x},${start.y},${start.z}`; // coincident edge\n\n\tif ( edges.has( hash1 ) === true || edges.has( hash2 ) === true ) {\n\n\t\treturn false;\n\n\t} else {\n\n\t\tedges.add( hash1 );\n\t\tedges.add( hash2 );\n\t\treturn true;\n\n\t}\n\n}\n\nvar Geometries = /*#__PURE__*/Object.freeze({\n\t__proto__: null,\n\tBoxGeometry: BoxGeometry,\n\tBoxBufferGeometry: BoxGeometry,\n\tCircleGeometry: CircleGeometry,\n\tCircleBufferGeometry: CircleGeometry,\n\tConeGeometry: ConeGeometry,\n\tConeBufferGeometry: ConeGeometry,\n\tCylinderGeometry: CylinderGeometry,\n\tCylinderBufferGeometry: CylinderGeometry,\n\tDodecahedronGeometry: DodecahedronGeometry,\n\tDodecahedronBufferGeometry: DodecahedronGeometry,\n\tEdgesGeometry: EdgesGeometry,\n\tExtrudeGeometry: ExtrudeGeometry,\n\tExtrudeBufferGeometry: ExtrudeGeometry,\n\tIcosahedronGeometry: IcosahedronGeometry,\n\tIcosahedronBufferGeometry: IcosahedronGeometry,\n\tLatheGeometry: LatheGeometry,\n\tLatheBufferGeometry: LatheGeometry,\n\tOctahedronGeometry: OctahedronGeometry,\n\tOctahedronBufferGeometry: OctahedronGeometry,\n\tPlaneGeometry: PlaneGeometry,\n\tPlaneBufferGeometry: PlaneGeometry,\n\tPolyhedronGeometry: PolyhedronGeometry,\n\tPolyhedronBufferGeometry: PolyhedronGeometry,\n\tRingGeometry: RingGeometry,\n\tRingBufferGeometry: RingGeometry,\n\tShapeGeometry: ShapeGeometry,\n\tShapeBufferGeometry: ShapeGeometry,\n\tSphereGeometry: SphereGeometry,\n\tSphereBufferGeometry: SphereGeometry,\n\tTetrahedronGeometry: TetrahedronGeometry,\n\tTetrahedronBufferGeometry: TetrahedronGeometry,\n\tTorusGeometry: TorusGeometry,\n\tTorusBufferGeometry: TorusGeometry,\n\tTorusKnotGeometry: TorusKnotGeometry,\n\tTorusKnotBufferGeometry: TorusKnotGeometry,\n\tTubeGeometry: TubeGeometry,\n\tTubeBufferGeometry: TubeGeometry,\n\tWireframeGeometry: WireframeGeometry\n});\n\n/**\n * parameters = {\n *  color: <THREE.Color>\n * }\n */\n\nclass ShadowMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'ShadowMaterial';\n\n\t\tthis.color = new Color( 0x000000 );\n\t\tthis.transparent = true;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\treturn this;\n\n\t}\n\n}\n\nShadowMaterial.prototype.isShadowMaterial = true;\n\nclass RawShaderMaterial extends ShaderMaterial {\n\n\tconstructor( parameters ) {\n\n\t\tsuper( parameters );\n\n\t\tthis.type = 'RawShaderMaterial';\n\n\t}\n\n}\n\nRawShaderMaterial.prototype.isRawShaderMaterial = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  roughness: <float>,\n *  metalness: <float>,\n *  opacity: <float>,\n *\n *  map: new THREE.Texture( <Image> ),\n *\n *  lightMap: new THREE.Texture( <Image> ),\n *  lightMapIntensity: <float>\n *\n *  aoMap: new THREE.Texture( <Image> ),\n *  aoMapIntensity: <float>\n *\n *  emissive: <hex>,\n *  emissiveIntensity: <float>\n *  emissiveMap: new THREE.Texture( <Image> ),\n *\n *  bumpMap: new THREE.Texture( <Image> ),\n *  bumpScale: <float>,\n *\n *  normalMap: new THREE.Texture( <Image> ),\n *  normalMapType: THREE.TangentSpaceNormalMap,\n *  normalScale: <Vector2>,\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>,\n *\n *  roughnessMap: new THREE.Texture( <Image> ),\n *\n *  metalnessMap: new THREE.Texture( <Image> ),\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  envMap: new THREE.CubeTexture( [posx, negx, posy, negy, posz, negz] ),\n *  envMapIntensity: <float>\n *\n *  refractionRatio: <float>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>,\n *\n *  flatShading: <bool>\n * }\n */\n\nclass MeshStandardMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.defines = { 'STANDARD': '' };\n\n\t\tthis.type = 'MeshStandardMaterial';\n\n\t\tthis.color = new Color( 0xffffff ); // diffuse\n\t\tthis.roughness = 1.0;\n\t\tthis.metalness = 0.0;\n\n\t\tthis.map = null;\n\n\t\tthis.lightMap = null;\n\t\tthis.lightMapIntensity = 1.0;\n\n\t\tthis.aoMap = null;\n\t\tthis.aoMapIntensity = 1.0;\n\n\t\tthis.emissive = new Color( 0x000000 );\n\t\tthis.emissiveIntensity = 1.0;\n\t\tthis.emissiveMap = null;\n\n\t\tthis.bumpMap = null;\n\t\tthis.bumpScale = 1;\n\n\t\tthis.normalMap = null;\n\t\tthis.normalMapType = TangentSpaceNormalMap;\n\t\tthis.normalScale = new Vector2( 1, 1 );\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.roughnessMap = null;\n\n\t\tthis.metalnessMap = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.envMap = null;\n\t\tthis.envMapIntensity = 1.0;\n\n\t\tthis.refractionRatio = 0.98;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\t\tthis.wireframeLinecap = 'round';\n\t\tthis.wireframeLinejoin = 'round';\n\n\t\tthis.flatShading = false;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.defines = { 'STANDARD': '' };\n\n\t\tthis.color.copy( source.color );\n\t\tthis.roughness = source.roughness;\n\t\tthis.metalness = source.metalness;\n\n\t\tthis.map = source.map;\n\n\t\tthis.lightMap = source.lightMap;\n\t\tthis.lightMapIntensity = source.lightMapIntensity;\n\n\t\tthis.aoMap = source.aoMap;\n\t\tthis.aoMapIntensity = source.aoMapIntensity;\n\n\t\tthis.emissive.copy( source.emissive );\n\t\tthis.emissiveMap = source.emissiveMap;\n\t\tthis.emissiveIntensity = source.emissiveIntensity;\n\n\t\tthis.bumpMap = source.bumpMap;\n\t\tthis.bumpScale = source.bumpScale;\n\n\t\tthis.normalMap = source.normalMap;\n\t\tthis.normalMapType = source.normalMapType;\n\t\tthis.normalScale.copy( source.normalScale );\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\tthis.roughnessMap = source.roughnessMap;\n\n\t\tthis.metalnessMap = source.metalnessMap;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.envMap = source.envMap;\n\t\tthis.envMapIntensity = source.envMapIntensity;\n\n\t\tthis.refractionRatio = source.refractionRatio;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\t\tthis.wireframeLinecap = source.wireframeLinecap;\n\t\tthis.wireframeLinejoin = source.wireframeLinejoin;\n\n\t\tthis.flatShading = source.flatShading;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshStandardMaterial.prototype.isMeshStandardMaterial = true;\n\n/**\n * parameters = {\n *  clearcoat: <float>,\n *  clearcoatMap: new THREE.Texture( <Image> ),\n *  clearcoatRoughness: <float>,\n *  clearcoatRoughnessMap: new THREE.Texture( <Image> ),\n *  clearcoatNormalScale: <Vector2>,\n *  clearcoatNormalMap: new THREE.Texture( <Image> ),\n *\n *  ior: <float>,\n *  reflectivity: <float>,\n *\n *  sheen: <float>,\n *  sheenColor: <Color>,\n *  sheenColorMap: new THREE.Texture( <Image> ),\n *  sheenRoughness: <float>,\n *  sheenRoughnessMap: new THREE.Texture( <Image> ),\n *\n *  transmission: <float>,\n *  transmissionMap: new THREE.Texture( <Image> ),\n *\n *  thickness: <float>,\n *  thicknessMap: new THREE.Texture( <Image> ),\n *  attenuationDistance: <float>,\n *  attenuationColor: <Color>,\n *\n *  specularIntensity: <float>,\n *  specularIntensityMap: new THREE.Texture( <Image> ),\n *  specularColor: <Color>,\n *  specularColorMap: new THREE.Texture( <Image> )\n * }\n */\n\nclass MeshPhysicalMaterial extends MeshStandardMaterial {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.defines = {\n\n\t\t\t'STANDARD': '',\n\t\t\t'PHYSICAL': ''\n\n\t\t};\n\n\t\tthis.type = 'MeshPhysicalMaterial';\n\n\t\tthis.clearcoatMap = null;\n\t\tthis.clearcoatRoughness = 0.0;\n\t\tthis.clearcoatRoughnessMap = null;\n\t\tthis.clearcoatNormalScale = new Vector2( 1, 1 );\n\t\tthis.clearcoatNormalMap = null;\n\n\t\tthis.ior = 1.5;\n\n\t\tObject.defineProperty( this, 'reflectivity', {\n\t\t\tget: function () {\n\n\t\t\t\treturn ( clamp( 2.5 * ( this.ior - 1 ) / ( this.ior + 1 ), 0, 1 ) );\n\n\t\t\t},\n\t\t\tset: function ( reflectivity ) {\n\n\t\t\t\tthis.ior = ( 1 + 0.4 * reflectivity ) / ( 1 - 0.4 * reflectivity );\n\n\t\t\t}\n\t\t} );\n\n\t\tthis.sheenColor = new Color( 0x000000 );\n\t\tthis.sheenColorMap = null;\n\t\tthis.sheenRoughness = 1.0;\n\t\tthis.sheenRoughnessMap = null;\n\n\t\tthis.transmissionMap = null;\n\n\t\tthis.thickness = 0;\n\t\tthis.thicknessMap = null;\n\t\tthis.attenuationDistance = 0.0;\n\t\tthis.attenuationColor = new Color( 1, 1, 1 );\n\n\t\tthis.specularIntensity = 1.0;\n\t\tthis.specularIntensityMap = null;\n\t\tthis.specularColor = new Color( 1, 1, 1 );\n\t\tthis.specularColorMap = null;\n\n\t\tthis._sheen = 0.0;\n\t\tthis._clearcoat = 0;\n\t\tthis._transmission = 0;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tget sheen() {\n\n\t\treturn this._sheen;\n\n\t}\n\n\tset sheen( value ) {\n\n\t\tif ( this._sheen > 0 !== value > 0 ) {\n\n\t\t\tthis.version ++;\n\n\t\t}\n\n\t\tthis._sheen = value;\n\n\t}\n\n\tget clearcoat() {\n\n\t\treturn this._clearcoat;\n\n\t}\n\n\tset clearcoat( value ) {\n\n\t\tif ( this._clearcoat > 0 !== value > 0 ) {\n\n\t\t\tthis.version ++;\n\n\t\t}\n\n\t\tthis._clearcoat = value;\n\n\t}\n\n\tget transmission() {\n\n\t\treturn this._transmission;\n\n\t}\n\n\tset transmission( value ) {\n\n\t\tif ( this._transmission > 0 !== value > 0 ) {\n\n\t\t\tthis.version ++;\n\n\t\t}\n\n\t\tthis._transmission = value;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.defines = {\n\n\t\t\t'STANDARD': '',\n\t\t\t'PHYSICAL': ''\n\n\t\t};\n\n\t\tthis.clearcoat = source.clearcoat;\n\t\tthis.clearcoatMap = source.clearcoatMap;\n\t\tthis.clearcoatRoughness = source.clearcoatRoughness;\n\t\tthis.clearcoatRoughnessMap = source.clearcoatRoughnessMap;\n\t\tthis.clearcoatNormalMap = source.clearcoatNormalMap;\n\t\tthis.clearcoatNormalScale.copy( source.clearcoatNormalScale );\n\n\t\tthis.ior = source.ior;\n\n\t\tthis.sheen = source.sheen;\n\t\tthis.sheenColor.copy( source.sheenColor );\n\t\tthis.sheenColorMap = source.sheenColorMap;\n\t\tthis.sheenRoughness = source.sheenRoughness;\n\t\tthis.sheenRoughnessMap = source.sheenRoughnessMap;\n\n\t\tthis.transmission = source.transmission;\n\t\tthis.transmissionMap = source.transmissionMap;\n\n\t\tthis.thickness = source.thickness;\n\t\tthis.thicknessMap = source.thicknessMap;\n\t\tthis.attenuationDistance = source.attenuationDistance;\n\t\tthis.attenuationColor.copy( source.attenuationColor );\n\n\t\tthis.specularIntensity = source.specularIntensity;\n\t\tthis.specularIntensityMap = source.specularIntensityMap;\n\t\tthis.specularColor.copy( source.specularColor );\n\t\tthis.specularColorMap = source.specularColorMap;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshPhysicalMaterial.prototype.isMeshPhysicalMaterial = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  specular: <hex>,\n *  shininess: <float>,\n *  opacity: <float>,\n *\n *  map: new THREE.Texture( <Image> ),\n *\n *  lightMap: new THREE.Texture( <Image> ),\n *  lightMapIntensity: <float>\n *\n *  aoMap: new THREE.Texture( <Image> ),\n *  aoMapIntensity: <float>\n *\n *  emissive: <hex>,\n *  emissiveIntensity: <float>\n *  emissiveMap: new THREE.Texture( <Image> ),\n *\n *  bumpMap: new THREE.Texture( <Image> ),\n *  bumpScale: <float>,\n *\n *  normalMap: new THREE.Texture( <Image> ),\n *  normalMapType: THREE.TangentSpaceNormalMap,\n *  normalScale: <Vector2>,\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>,\n *\n *  specularMap: new THREE.Texture( <Image> ),\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  envMap: new THREE.CubeTexture( [posx, negx, posy, negy, posz, negz] ),\n *  combine: THREE.MultiplyOperation,\n *  reflectivity: <float>,\n *  refractionRatio: <float>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>,\n *\n *  flatShading: <bool>\n * }\n */\n\nclass MeshPhongMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'MeshPhongMaterial';\n\n\t\tthis.color = new Color( 0xffffff ); // diffuse\n\t\tthis.specular = new Color( 0x111111 );\n\t\tthis.shininess = 30;\n\n\t\tthis.map = null;\n\n\t\tthis.lightMap = null;\n\t\tthis.lightMapIntensity = 1.0;\n\n\t\tthis.aoMap = null;\n\t\tthis.aoMapIntensity = 1.0;\n\n\t\tthis.emissive = new Color( 0x000000 );\n\t\tthis.emissiveIntensity = 1.0;\n\t\tthis.emissiveMap = null;\n\n\t\tthis.bumpMap = null;\n\t\tthis.bumpScale = 1;\n\n\t\tthis.normalMap = null;\n\t\tthis.normalMapType = TangentSpaceNormalMap;\n\t\tthis.normalScale = new Vector2( 1, 1 );\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.specularMap = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.envMap = null;\n\t\tthis.combine = MultiplyOperation;\n\t\tthis.reflectivity = 1;\n\t\tthis.refractionRatio = 0.98;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\t\tthis.wireframeLinecap = 'round';\n\t\tthis.wireframeLinejoin = 'round';\n\n\t\tthis.flatShading = false;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\t\tthis.specular.copy( source.specular );\n\t\tthis.shininess = source.shininess;\n\n\t\tthis.map = source.map;\n\n\t\tthis.lightMap = source.lightMap;\n\t\tthis.lightMapIntensity = source.lightMapIntensity;\n\n\t\tthis.aoMap = source.aoMap;\n\t\tthis.aoMapIntensity = source.aoMapIntensity;\n\n\t\tthis.emissive.copy( source.emissive );\n\t\tthis.emissiveMap = source.emissiveMap;\n\t\tthis.emissiveIntensity = source.emissiveIntensity;\n\n\t\tthis.bumpMap = source.bumpMap;\n\t\tthis.bumpScale = source.bumpScale;\n\n\t\tthis.normalMap = source.normalMap;\n\t\tthis.normalMapType = source.normalMapType;\n\t\tthis.normalScale.copy( source.normalScale );\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\tthis.specularMap = source.specularMap;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.envMap = source.envMap;\n\t\tthis.combine = source.combine;\n\t\tthis.reflectivity = source.reflectivity;\n\t\tthis.refractionRatio = source.refractionRatio;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\t\tthis.wireframeLinecap = source.wireframeLinecap;\n\t\tthis.wireframeLinejoin = source.wireframeLinejoin;\n\n\t\tthis.flatShading = source.flatShading;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshPhongMaterial.prototype.isMeshPhongMaterial = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *\n *  map: new THREE.Texture( <Image> ),\n *  gradientMap: new THREE.Texture( <Image> ),\n *\n *  lightMap: new THREE.Texture( <Image> ),\n *  lightMapIntensity: <float>\n *\n *  aoMap: new THREE.Texture( <Image> ),\n *  aoMapIntensity: <float>\n *\n *  emissive: <hex>,\n *  emissiveIntensity: <float>\n *  emissiveMap: new THREE.Texture( <Image> ),\n *\n *  bumpMap: new THREE.Texture( <Image> ),\n *  bumpScale: <float>,\n *\n *  normalMap: new THREE.Texture( <Image> ),\n *  normalMapType: THREE.TangentSpaceNormalMap,\n *  normalScale: <Vector2>,\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>,\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>,\n *\n * }\n */\n\nclass MeshToonMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.defines = { 'TOON': '' };\n\n\t\tthis.type = 'MeshToonMaterial';\n\n\t\tthis.color = new Color( 0xffffff );\n\n\t\tthis.map = null;\n\t\tthis.gradientMap = null;\n\n\t\tthis.lightMap = null;\n\t\tthis.lightMapIntensity = 1.0;\n\n\t\tthis.aoMap = null;\n\t\tthis.aoMapIntensity = 1.0;\n\n\t\tthis.emissive = new Color( 0x000000 );\n\t\tthis.emissiveIntensity = 1.0;\n\t\tthis.emissiveMap = null;\n\n\t\tthis.bumpMap = null;\n\t\tthis.bumpScale = 1;\n\n\t\tthis.normalMap = null;\n\t\tthis.normalMapType = TangentSpaceNormalMap;\n\t\tthis.normalScale = new Vector2( 1, 1 );\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\t\tthis.wireframeLinecap = 'round';\n\t\tthis.wireframeLinejoin = 'round';\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.map = source.map;\n\t\tthis.gradientMap = source.gradientMap;\n\n\t\tthis.lightMap = source.lightMap;\n\t\tthis.lightMapIntensity = source.lightMapIntensity;\n\n\t\tthis.aoMap = source.aoMap;\n\t\tthis.aoMapIntensity = source.aoMapIntensity;\n\n\t\tthis.emissive.copy( source.emissive );\n\t\tthis.emissiveMap = source.emissiveMap;\n\t\tthis.emissiveIntensity = source.emissiveIntensity;\n\n\t\tthis.bumpMap = source.bumpMap;\n\t\tthis.bumpScale = source.bumpScale;\n\n\t\tthis.normalMap = source.normalMap;\n\t\tthis.normalMapType = source.normalMapType;\n\t\tthis.normalScale.copy( source.normalScale );\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\t\tthis.wireframeLinecap = source.wireframeLinecap;\n\t\tthis.wireframeLinejoin = source.wireframeLinejoin;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshToonMaterial.prototype.isMeshToonMaterial = true;\n\n/**\n * parameters = {\n *  opacity: <float>,\n *\n *  bumpMap: new THREE.Texture( <Image> ),\n *  bumpScale: <float>,\n *\n *  normalMap: new THREE.Texture( <Image> ),\n *  normalMapType: THREE.TangentSpaceNormalMap,\n *  normalScale: <Vector2>,\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>\n *\n *  flatShading: <bool>\n * }\n */\n\nclass MeshNormalMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'MeshNormalMaterial';\n\n\t\tthis.bumpMap = null;\n\t\tthis.bumpScale = 1;\n\n\t\tthis.normalMap = null;\n\t\tthis.normalMapType = TangentSpaceNormalMap;\n\t\tthis.normalScale = new Vector2( 1, 1 );\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\n\t\tthis.fog = false;\n\n\t\tthis.flatShading = false;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.bumpMap = source.bumpMap;\n\t\tthis.bumpScale = source.bumpScale;\n\n\t\tthis.normalMap = source.normalMap;\n\t\tthis.normalMapType = source.normalMapType;\n\t\tthis.normalScale.copy( source.normalScale );\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\n\t\tthis.flatShading = source.flatShading;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshNormalMaterial.prototype.isMeshNormalMaterial = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  opacity: <float>,\n *\n *  map: new THREE.Texture( <Image> ),\n *\n *  lightMap: new THREE.Texture( <Image> ),\n *  lightMapIntensity: <float>\n *\n *  aoMap: new THREE.Texture( <Image> ),\n *  aoMapIntensity: <float>\n *\n *  emissive: <hex>,\n *  emissiveIntensity: <float>\n *  emissiveMap: new THREE.Texture( <Image> ),\n *\n *  specularMap: new THREE.Texture( <Image> ),\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  envMap: new THREE.CubeTexture( [posx, negx, posy, negy, posz, negz] ),\n *  combine: THREE.Multiply,\n *  reflectivity: <float>,\n *  refractionRatio: <float>,\n *\n *  wireframe: <boolean>,\n *  wireframeLinewidth: <float>,\n *\n * }\n */\n\nclass MeshLambertMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'MeshLambertMaterial';\n\n\t\tthis.color = new Color( 0xffffff ); // diffuse\n\n\t\tthis.map = null;\n\n\t\tthis.lightMap = null;\n\t\tthis.lightMapIntensity = 1.0;\n\n\t\tthis.aoMap = null;\n\t\tthis.aoMapIntensity = 1.0;\n\n\t\tthis.emissive = new Color( 0x000000 );\n\t\tthis.emissiveIntensity = 1.0;\n\t\tthis.emissiveMap = null;\n\n\t\tthis.specularMap = null;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.envMap = null;\n\t\tthis.combine = MultiplyOperation;\n\t\tthis.reflectivity = 1;\n\t\tthis.refractionRatio = 0.98;\n\n\t\tthis.wireframe = false;\n\t\tthis.wireframeLinewidth = 1;\n\t\tthis.wireframeLinecap = 'round';\n\t\tthis.wireframeLinejoin = 'round';\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.map = source.map;\n\n\t\tthis.lightMap = source.lightMap;\n\t\tthis.lightMapIntensity = source.lightMapIntensity;\n\n\t\tthis.aoMap = source.aoMap;\n\t\tthis.aoMapIntensity = source.aoMapIntensity;\n\n\t\tthis.emissive.copy( source.emissive );\n\t\tthis.emissiveMap = source.emissiveMap;\n\t\tthis.emissiveIntensity = source.emissiveIntensity;\n\n\t\tthis.specularMap = source.specularMap;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.envMap = source.envMap;\n\t\tthis.combine = source.combine;\n\t\tthis.reflectivity = source.reflectivity;\n\t\tthis.refractionRatio = source.refractionRatio;\n\n\t\tthis.wireframe = source.wireframe;\n\t\tthis.wireframeLinewidth = source.wireframeLinewidth;\n\t\tthis.wireframeLinecap = source.wireframeLinecap;\n\t\tthis.wireframeLinejoin = source.wireframeLinejoin;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshLambertMaterial.prototype.isMeshLambertMaterial = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  opacity: <float>,\n *\n *  matcap: new THREE.Texture( <Image> ),\n *\n *  map: new THREE.Texture( <Image> ),\n *\n *  bumpMap: new THREE.Texture( <Image> ),\n *  bumpScale: <float>,\n *\n *  normalMap: new THREE.Texture( <Image> ),\n *  normalMapType: THREE.TangentSpaceNormalMap,\n *  normalScale: <Vector2>,\n *\n *  displacementMap: new THREE.Texture( <Image> ),\n *  displacementScale: <float>,\n *  displacementBias: <float>,\n *\n *  alphaMap: new THREE.Texture( <Image> ),\n *\n *  flatShading: <bool>\n * }\n */\n\nclass MeshMatcapMaterial extends Material {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.defines = { 'MATCAP': '' };\n\n\t\tthis.type = 'MeshMatcapMaterial';\n\n\t\tthis.color = new Color( 0xffffff ); // diffuse\n\n\t\tthis.matcap = null;\n\n\t\tthis.map = null;\n\n\t\tthis.bumpMap = null;\n\t\tthis.bumpScale = 1;\n\n\t\tthis.normalMap = null;\n\t\tthis.normalMapType = TangentSpaceNormalMap;\n\t\tthis.normalScale = new Vector2( 1, 1 );\n\n\t\tthis.displacementMap = null;\n\t\tthis.displacementScale = 1;\n\t\tthis.displacementBias = 0;\n\n\t\tthis.alphaMap = null;\n\n\t\tthis.flatShading = false;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.defines = { 'MATCAP': '' };\n\n\t\tthis.color.copy( source.color );\n\n\t\tthis.matcap = source.matcap;\n\n\t\tthis.map = source.map;\n\n\t\tthis.bumpMap = source.bumpMap;\n\t\tthis.bumpScale = source.bumpScale;\n\n\t\tthis.normalMap = source.normalMap;\n\t\tthis.normalMapType = source.normalMapType;\n\t\tthis.normalScale.copy( source.normalScale );\n\n\t\tthis.displacementMap = source.displacementMap;\n\t\tthis.displacementScale = source.displacementScale;\n\t\tthis.displacementBias = source.displacementBias;\n\n\t\tthis.alphaMap = source.alphaMap;\n\n\t\tthis.flatShading = source.flatShading;\n\n\t\treturn this;\n\n\t}\n\n}\n\nMeshMatcapMaterial.prototype.isMeshMatcapMaterial = true;\n\n/**\n * parameters = {\n *  color: <hex>,\n *  opacity: <float>,\n *\n *  linewidth: <float>,\n *\n *  scale: <float>,\n *  dashSize: <float>,\n *  gapSize: <float>\n * }\n */\n\nclass LineDashedMaterial extends LineBasicMaterial {\n\n\tconstructor( parameters ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'LineDashedMaterial';\n\n\t\tthis.scale = 1;\n\t\tthis.dashSize = 3;\n\t\tthis.gapSize = 1;\n\n\t\tthis.setValues( parameters );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.scale = source.scale;\n\t\tthis.dashSize = source.dashSize;\n\t\tthis.gapSize = source.gapSize;\n\n\t\treturn this;\n\n\t}\n\n}\n\nLineDashedMaterial.prototype.isLineDashedMaterial = true;\n\nconst materialLib = {\n\tShadowMaterial,\n\tSpriteMaterial,\n\tRawShaderMaterial,\n\tShaderMaterial,\n\tPointsMaterial,\n\tMeshPhysicalMaterial,\n\tMeshStandardMaterial,\n\tMeshPhongMaterial,\n\tMeshToonMaterial,\n\tMeshNormalMaterial,\n\tMeshLambertMaterial,\n\tMeshDepthMaterial,\n\tMeshDistanceMaterial,\n\tMeshBasicMaterial,\n\tMeshMatcapMaterial,\n\tLineDashedMaterial,\n\tLineBasicMaterial,\n\tMaterial\n};\n\nMaterial.fromType = function ( type ) {\n\n\treturn new materialLib[ type ]();\n\n};\n\nconst AnimationUtils = {\n\n\t// same as Array.prototype.slice, but also works on typed arrays\n\tarraySlice: function ( array, from, to ) {\n\n\t\tif ( AnimationUtils.isTypedArray( array ) ) {\n\n\t\t\t// in ios9 array.subarray(from, undefined) will return empty array\n\t\t\t// but array.subarray(from) or array.subarray(from, len) is correct\n\t\t\treturn new array.constructor( array.subarray( from, to !== undefined ? to : array.length ) );\n\n\t\t}\n\n\t\treturn array.slice( from, to );\n\n\t},\n\n\t// converts an array to a specific type\n\tconvertArray: function ( array, type, forceClone ) {\n\n\t\tif ( ! array || // let 'undefined' and 'null' pass\n\t\t\t! forceClone && array.constructor === type ) return array;\n\n\t\tif ( typeof type.BYTES_PER_ELEMENT === 'number' ) {\n\n\t\t\treturn new type( array ); // create typed array\n\n\t\t}\n\n\t\treturn Array.prototype.slice.call( array ); // create Array\n\n\t},\n\n\tisTypedArray: function ( object ) {\n\n\t\treturn ArrayBuffer.isView( object ) &&\n\t\t\t! ( object instanceof DataView );\n\n\t},\n\n\t// returns an array by which times and values can be sorted\n\tgetKeyframeOrder: function ( times ) {\n\n\t\tfunction compareTime( i, j ) {\n\n\t\t\treturn times[ i ] - times[ j ];\n\n\t\t}\n\n\t\tconst n = times.length;\n\t\tconst result = new Array( n );\n\t\tfor ( let i = 0; i !== n; ++ i ) result[ i ] = i;\n\n\t\tresult.sort( compareTime );\n\n\t\treturn result;\n\n\t},\n\n\t// uses the array previously returned by 'getKeyframeOrder' to sort data\n\tsortedArray: function ( values, stride, order ) {\n\n\t\tconst nValues = values.length;\n\t\tconst result = new values.constructor( nValues );\n\n\t\tfor ( let i = 0, dstOffset = 0; dstOffset !== nValues; ++ i ) {\n\n\t\t\tconst srcOffset = order[ i ] * stride;\n\n\t\t\tfor ( let j = 0; j !== stride; ++ j ) {\n\n\t\t\t\tresult[ dstOffset ++ ] = values[ srcOffset + j ];\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn result;\n\n\t},\n\n\t// function for parsing AOS keyframe formats\n\tflattenJSON: function ( jsonKeys, times, values, valuePropertyName ) {\n\n\t\tlet i = 1, key = jsonKeys[ 0 ];\n\n\t\twhile ( key !== undefined && key[ valuePropertyName ] === undefined ) {\n\n\t\t\tkey = jsonKeys[ i ++ ];\n\n\t\t}\n\n\t\tif ( key === undefined ) return; // no data\n\n\t\tlet value = key[ valuePropertyName ];\n\t\tif ( value === undefined ) return; // no data\n\n\t\tif ( Array.isArray( value ) ) {\n\n\t\t\tdo {\n\n\t\t\t\tvalue = key[ valuePropertyName ];\n\n\t\t\t\tif ( value !== undefined ) {\n\n\t\t\t\t\ttimes.push( key.time );\n\t\t\t\t\tvalues.push.apply( values, value ); // push all elements\n\n\t\t\t\t}\n\n\t\t\t\tkey = jsonKeys[ i ++ ];\n\n\t\t\t} while ( key !== undefined );\n\n\t\t} else if ( value.toArray !== undefined ) {\n\n\t\t\t// ...assume THREE.Math-ish\n\n\t\t\tdo {\n\n\t\t\t\tvalue = key[ valuePropertyName ];\n\n\t\t\t\tif ( value !== undefined ) {\n\n\t\t\t\t\ttimes.push( key.time );\n\t\t\t\t\tvalue.toArray( values, values.length );\n\n\t\t\t\t}\n\n\t\t\t\tkey = jsonKeys[ i ++ ];\n\n\t\t\t} while ( key !== undefined );\n\n\t\t} else {\n\n\t\t\t// otherwise push as-is\n\n\t\t\tdo {\n\n\t\t\t\tvalue = key[ valuePropertyName ];\n\n\t\t\t\tif ( value !== undefined ) {\n\n\t\t\t\t\ttimes.push( key.time );\n\t\t\t\t\tvalues.push( value );\n\n\t\t\t\t}\n\n\t\t\t\tkey = jsonKeys[ i ++ ];\n\n\t\t\t} while ( key !== undefined );\n\n\t\t}\n\n\t},\n\n\tsubclip: function ( sourceClip, name, startFrame, endFrame, fps = 30 ) {\n\n\t\tconst clip = sourceClip.clone();\n\n\t\tclip.name = name;\n\n\t\tconst tracks = [];\n\n\t\tfor ( let i = 0; i < clip.tracks.length; ++ i ) {\n\n\t\t\tconst track = clip.tracks[ i ];\n\t\t\tconst valueSize = track.getValueSize();\n\n\t\t\tconst times = [];\n\t\t\tconst values = [];\n\n\t\t\tfor ( let j = 0; j < track.times.length; ++ j ) {\n\n\t\t\t\tconst frame = track.times[ j ] * fps;\n\n\t\t\t\tif ( frame < startFrame || frame >= endFrame ) continue;\n\n\t\t\t\ttimes.push( track.times[ j ] );\n\n\t\t\t\tfor ( let k = 0; k < valueSize; ++ k ) {\n\n\t\t\t\t\tvalues.push( track.values[ j * valueSize + k ] );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( times.length === 0 ) continue;\n\n\t\t\ttrack.times = AnimationUtils.convertArray( times, track.times.constructor );\n\t\t\ttrack.values = AnimationUtils.convertArray( values, track.values.constructor );\n\n\t\t\ttracks.push( track );\n\n\t\t}\n\n\t\tclip.tracks = tracks;\n\n\t\t// find minimum .times value across all tracks in the trimmed clip\n\n\t\tlet minStartTime = Infinity;\n\n\t\tfor ( let i = 0; i < clip.tracks.length; ++ i ) {\n\n\t\t\tif ( minStartTime > clip.tracks[ i ].times[ 0 ] ) {\n\n\t\t\t\tminStartTime = clip.tracks[ i ].times[ 0 ];\n\n\t\t\t}\n\n\t\t}\n\n\t\t// shift all tracks such that clip begins at t=0\n\n\t\tfor ( let i = 0; i < clip.tracks.length; ++ i ) {\n\n\t\t\tclip.tracks[ i ].shift( - 1 * minStartTime );\n\n\t\t}\n\n\t\tclip.resetDuration();\n\n\t\treturn clip;\n\n\t},\n\n\tmakeClipAdditive: function ( targetClip, referenceFrame = 0, referenceClip = targetClip, fps = 30 ) {\n\n\t\tif ( fps <= 0 ) fps = 30;\n\n\t\tconst numTracks = referenceClip.tracks.length;\n\t\tconst referenceTime = referenceFrame / fps;\n\n\t\t// Make each track's values relative to the values at the reference frame\n\t\tfor ( let i = 0; i < numTracks; ++ i ) {\n\n\t\t\tconst referenceTrack = referenceClip.tracks[ i ];\n\t\t\tconst referenceTrackType = referenceTrack.ValueTypeName;\n\n\t\t\t// Skip this track if it's non-numeric\n\t\t\tif ( referenceTrackType === 'bool' || referenceTrackType === 'string' ) continue;\n\n\t\t\t// Find the track in the target clip whose name and type matches the reference track\n\t\t\tconst targetTrack = targetClip.tracks.find( function ( track ) {\n\n\t\t\t\treturn track.name === referenceTrack.name\n\t\t\t\t\t&& track.ValueTypeName === referenceTrackType;\n\n\t\t\t} );\n\n\t\t\tif ( targetTrack === undefined ) continue;\n\n\t\t\tlet referenceOffset = 0;\n\t\t\tconst referenceValueSize = referenceTrack.getValueSize();\n\n\t\t\tif ( referenceTrack.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline ) {\n\n\t\t\t\treferenceOffset = referenceValueSize / 3;\n\n\t\t\t}\n\n\t\t\tlet targetOffset = 0;\n\t\t\tconst targetValueSize = targetTrack.getValueSize();\n\n\t\t\tif ( targetTrack.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline ) {\n\n\t\t\t\ttargetOffset = targetValueSize / 3;\n\n\t\t\t}\n\n\t\t\tconst lastIndex = referenceTrack.times.length - 1;\n\t\t\tlet referenceValue;\n\n\t\t\t// Find the value to subtract out of the track\n\t\t\tif ( referenceTime <= referenceTrack.times[ 0 ] ) {\n\n\t\t\t\t// Reference frame is earlier than the first keyframe, so just use the first keyframe\n\t\t\t\tconst startIndex = referenceOffset;\n\t\t\t\tconst endIndex = referenceValueSize - referenceOffset;\n\t\t\t\treferenceValue = AnimationUtils.arraySlice( referenceTrack.values, startIndex, endIndex );\n\n\t\t\t} else if ( referenceTime >= referenceTrack.times[ lastIndex ] ) {\n\n\t\t\t\t// Reference frame is after the last keyframe, so just use the last keyframe\n\t\t\t\tconst startIndex = lastIndex * referenceValueSize + referenceOffset;\n\t\t\t\tconst endIndex = startIndex + referenceValueSize - referenceOffset;\n\t\t\t\treferenceValue = AnimationUtils.arraySlice( referenceTrack.values, startIndex, endIndex );\n\n\t\t\t} else {\n\n\t\t\t\t// Interpolate to the reference value\n\t\t\t\tconst interpolant = referenceTrack.createInterpolant();\n\t\t\t\tconst startIndex = referenceOffset;\n\t\t\t\tconst endIndex = referenceValueSize - referenceOffset;\n\t\t\t\tinterpolant.evaluate( referenceTime );\n\t\t\t\treferenceValue = AnimationUtils.arraySlice( interpolant.resultBuffer, startIndex, endIndex );\n\n\t\t\t}\n\n\t\t\t// Conjugate the quaternion\n\t\t\tif ( referenceTrackType === 'quaternion' ) {\n\n\t\t\t\tconst referenceQuat = new Quaternion().fromArray( referenceValue ).normalize().conjugate();\n\t\t\t\treferenceQuat.toArray( referenceValue );\n\n\t\t\t}\n\n\t\t\t// Subtract the reference value from all of the track values\n\n\t\t\tconst numTimes = targetTrack.times.length;\n\t\t\tfor ( let j = 0; j < numTimes; ++ j ) {\n\n\t\t\t\tconst valueStart = j * targetValueSize + targetOffset;\n\n\t\t\t\tif ( referenceTrackType === 'quaternion' ) {\n\n\t\t\t\t\t// Multiply the conjugate for quaternion track types\n\t\t\t\t\tQuaternion.multiplyQuaternionsFlat(\n\t\t\t\t\t\ttargetTrack.values,\n\t\t\t\t\t\tvalueStart,\n\t\t\t\t\t\treferenceValue,\n\t\t\t\t\t\t0,\n\t\t\t\t\t\ttargetTrack.values,\n\t\t\t\t\t\tvalueStart\n\t\t\t\t\t);\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconst valueEnd = targetValueSize - targetOffset * 2;\n\n\t\t\t\t\t// Subtract each value for all other numeric track types\n\t\t\t\t\tfor ( let k = 0; k < valueEnd; ++ k ) {\n\n\t\t\t\t\t\ttargetTrack.values[ valueStart + k ] -= referenceValue[ k ];\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\ttargetClip.blendMode = AdditiveAnimationBlendMode;\n\n\t\treturn targetClip;\n\n\t}\n\n};\n\n/**\n * Abstract base class of interpolants over parametric samples.\n *\n * The parameter domain is one dimensional, typically the time or a path\n * along a curve defined by the data.\n *\n * The sample values can have any dimensionality and derived classes may\n * apply special interpretations to the data.\n *\n * This class provides the interval seek in a Template Method, deferring\n * the actual interpolation to derived classes.\n *\n * Time complexity is O(1) for linear access crossing at most two points\n * and O(log N) for random access, where N is the number of positions.\n *\n * References:\n *\n * \t\thttp://www.oodesign.com/template-method-pattern.html\n *\n */\n\nclass Interpolant {\n\n\tconstructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {\n\n\t\tthis.parameterPositions = parameterPositions;\n\t\tthis._cachedIndex = 0;\n\n\t\tthis.resultBuffer = resultBuffer !== undefined ?\n\t\t\tresultBuffer : new sampleValues.constructor( sampleSize );\n\t\tthis.sampleValues = sampleValues;\n\t\tthis.valueSize = sampleSize;\n\n\t\tthis.settings = null;\n\t\tthis.DefaultSettings_ = {};\n\n\t}\n\n\tevaluate( t ) {\n\n\t\tconst pp = this.parameterPositions;\n\t\tlet i1 = this._cachedIndex,\n\t\t\tt1 = pp[ i1 ],\n\t\t\tt0 = pp[ i1 - 1 ];\n\n\t\tvalidate_interval: {\n\n\t\t\tseek: {\n\n\t\t\t\tlet right;\n\n\t\t\t\tlinear_scan: {\n\n\t\t\t\t\t//- See http://jsperf.com/comparison-to-undefined/3\n\t\t\t\t\t//- slower code:\n\t\t\t\t\t//-\n\t\t\t\t\t//- \t\t\t\tif ( t >= t1 || t1 === undefined ) {\n\t\t\t\t\tforward_scan: if ( ! ( t < t1 ) ) {\n\n\t\t\t\t\t\tfor ( let giveUpAt = i1 + 2; ; ) {\n\n\t\t\t\t\t\t\tif ( t1 === undefined ) {\n\n\t\t\t\t\t\t\t\tif ( t < t0 ) break forward_scan;\n\n\t\t\t\t\t\t\t\t// after end\n\n\t\t\t\t\t\t\t\ti1 = pp.length;\n\t\t\t\t\t\t\t\tthis._cachedIndex = i1;\n\t\t\t\t\t\t\t\treturn this.afterEnd_( i1 - 1, t, t0 );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif ( i1 === giveUpAt ) break; // this loop\n\n\t\t\t\t\t\t\tt0 = t1;\n\t\t\t\t\t\t\tt1 = pp[ ++ i1 ];\n\n\t\t\t\t\t\t\tif ( t < t1 ) {\n\n\t\t\t\t\t\t\t\t// we have arrived at the sought interval\n\t\t\t\t\t\t\t\tbreak seek;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// prepare binary search on the right side of the index\n\t\t\t\t\t\tright = pp.length;\n\t\t\t\t\t\tbreak linear_scan;\n\n\t\t\t\t\t}\n\n\t\t\t\t\t//- slower code:\n\t\t\t\t\t//-\t\t\t\t\tif ( t < t0 || t0 === undefined ) {\n\t\t\t\t\tif ( ! ( t >= t0 ) ) {\n\n\t\t\t\t\t\t// looping?\n\n\t\t\t\t\t\tconst t1global = pp[ 1 ];\n\n\t\t\t\t\t\tif ( t < t1global ) {\n\n\t\t\t\t\t\t\ti1 = 2; // + 1, using the scan for the details\n\t\t\t\t\t\t\tt0 = t1global;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// linear reverse scan\n\n\t\t\t\t\t\tfor ( let giveUpAt = i1 - 2; ; ) {\n\n\t\t\t\t\t\t\tif ( t0 === undefined ) {\n\n\t\t\t\t\t\t\t\t// before start\n\n\t\t\t\t\t\t\t\tthis._cachedIndex = 0;\n\t\t\t\t\t\t\t\treturn this.beforeStart_( 0, t, t1 );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif ( i1 === giveUpAt ) break; // this loop\n\n\t\t\t\t\t\t\tt1 = t0;\n\t\t\t\t\t\t\tt0 = pp[ -- i1 - 1 ];\n\n\t\t\t\t\t\t\tif ( t >= t0 ) {\n\n\t\t\t\t\t\t\t\t// we have arrived at the sought interval\n\t\t\t\t\t\t\t\tbreak seek;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// prepare binary search on the left side of the index\n\t\t\t\t\t\tright = i1;\n\t\t\t\t\t\ti1 = 0;\n\t\t\t\t\t\tbreak linear_scan;\n\n\t\t\t\t\t}\n\n\t\t\t\t\t// the interval is valid\n\n\t\t\t\t\tbreak validate_interval;\n\n\t\t\t\t} // linear scan\n\n\t\t\t\t// binary search\n\n\t\t\t\twhile ( i1 < right ) {\n\n\t\t\t\t\tconst mid = ( i1 + right ) >>> 1;\n\n\t\t\t\t\tif ( t < pp[ mid ] ) {\n\n\t\t\t\t\t\tright = mid;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\ti1 = mid + 1;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tt1 = pp[ i1 ];\n\t\t\t\tt0 = pp[ i1 - 1 ];\n\n\t\t\t\t// check boundary cases, again\n\n\t\t\t\tif ( t0 === undefined ) {\n\n\t\t\t\t\tthis._cachedIndex = 0;\n\t\t\t\t\treturn this.beforeStart_( 0, t, t1 );\n\n\t\t\t\t}\n\n\t\t\t\tif ( t1 === undefined ) {\n\n\t\t\t\t\ti1 = pp.length;\n\t\t\t\t\tthis._cachedIndex = i1;\n\t\t\t\t\treturn this.afterEnd_( i1 - 1, t0, t );\n\n\t\t\t\t}\n\n\t\t\t} // seek\n\n\t\t\tthis._cachedIndex = i1;\n\n\t\t\tthis.intervalChanged_( i1, t0, t1 );\n\n\t\t} // validate_interval\n\n\t\treturn this.interpolate_( i1, t0, t, t1 );\n\n\t}\n\n\tgetSettings_() {\n\n\t\treturn this.settings || this.DefaultSettings_;\n\n\t}\n\n\tcopySampleValue_( index ) {\n\n\t\t// copies a sample value to the result buffer\n\n\t\tconst result = this.resultBuffer,\n\t\t\tvalues = this.sampleValues,\n\t\t\tstride = this.valueSize,\n\t\t\toffset = index * stride;\n\n\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\tresult[ i ] = values[ offset + i ];\n\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n\t// Template methods for derived classes:\n\n\tinterpolate_( /* i1, t0, t, t1 */ ) {\n\n\t\tthrow new Error( 'call to abstract method' );\n\t\t// implementations shall return this.resultBuffer\n\n\t}\n\n\tintervalChanged_( /* i1, t0, t1 */ ) {\n\n\t\t// empty\n\n\t}\n\n}\n\n// ALIAS DEFINITIONS\n\nInterpolant.prototype.beforeStart_ = Interpolant.prototype.copySampleValue_;\nInterpolant.prototype.afterEnd_ = Interpolant.prototype.copySampleValue_;\n\n/**\n * Fast and simple cubic spline interpolant.\n *\n * It was derived from a Hermitian construction setting the first derivative\n * at each sample position to the linear slope between neighboring positions\n * over their parameter interval.\n */\n\nclass CubicInterpolant extends Interpolant {\n\n\tconstructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {\n\n\t\tsuper( parameterPositions, sampleValues, sampleSize, resultBuffer );\n\n\t\tthis._weightPrev = - 0;\n\t\tthis._offsetPrev = - 0;\n\t\tthis._weightNext = - 0;\n\t\tthis._offsetNext = - 0;\n\n\t\tthis.DefaultSettings_ = {\n\n\t\t\tendingStart: ZeroCurvatureEnding,\n\t\t\tendingEnd: ZeroCurvatureEnding\n\n\t\t};\n\n\t}\n\n\tintervalChanged_( i1, t0, t1 ) {\n\n\t\tconst pp = this.parameterPositions;\n\t\tlet iPrev = i1 - 2,\n\t\t\tiNext = i1 + 1,\n\n\t\t\ttPrev = pp[ iPrev ],\n\t\t\ttNext = pp[ iNext ];\n\n\t\tif ( tPrev === undefined ) {\n\n\t\t\tswitch ( this.getSettings_().endingStart ) {\n\n\t\t\t\tcase ZeroSlopeEnding:\n\n\t\t\t\t\t// f'(t0) = 0\n\t\t\t\t\tiPrev = i1;\n\t\t\t\t\ttPrev = 2 * t0 - t1;\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase WrapAroundEnding:\n\n\t\t\t\t\t// use the other end of the curve\n\t\t\t\t\tiPrev = pp.length - 2;\n\t\t\t\t\ttPrev = t0 + pp[ iPrev ] - pp[ iPrev + 1 ];\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault: // ZeroCurvatureEnding\n\n\t\t\t\t\t// f''(t0) = 0 a.k.a. Natural Spline\n\t\t\t\t\tiPrev = i1;\n\t\t\t\t\ttPrev = t1;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( tNext === undefined ) {\n\n\t\t\tswitch ( this.getSettings_().endingEnd ) {\n\n\t\t\t\tcase ZeroSlopeEnding:\n\n\t\t\t\t\t// f'(tN) = 0\n\t\t\t\t\tiNext = i1;\n\t\t\t\t\ttNext = 2 * t1 - t0;\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase WrapAroundEnding:\n\n\t\t\t\t\t// use the other end of the curve\n\t\t\t\t\tiNext = 1;\n\t\t\t\t\ttNext = t1 + pp[ 1 ] - pp[ 0 ];\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault: // ZeroCurvatureEnding\n\n\t\t\t\t\t// f''(tN) = 0, a.k.a. Natural Spline\n\t\t\t\t\tiNext = i1 - 1;\n\t\t\t\t\ttNext = t0;\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst halfDt = ( t1 - t0 ) * 0.5,\n\t\t\tstride = this.valueSize;\n\n\t\tthis._weightPrev = halfDt / ( t0 - tPrev );\n\t\tthis._weightNext = halfDt / ( tNext - t1 );\n\t\tthis._offsetPrev = iPrev * stride;\n\t\tthis._offsetNext = iNext * stride;\n\n\t}\n\n\tinterpolate_( i1, t0, t, t1 ) {\n\n\t\tconst result = this.resultBuffer,\n\t\t\tvalues = this.sampleValues,\n\t\t\tstride = this.valueSize,\n\n\t\t\to1 = i1 * stride,\t\to0 = o1 - stride,\n\t\t\toP = this._offsetPrev, \toN = this._offsetNext,\n\t\t\twP = this._weightPrev,\twN = this._weightNext,\n\n\t\t\tp = ( t - t0 ) / ( t1 - t0 ),\n\t\t\tpp = p * p,\n\t\t\tppp = pp * p;\n\n\t\t// evaluate polynomials\n\n\t\tconst sP = - wP * ppp + 2 * wP * pp - wP * p;\n\t\tconst s0 = ( 1 + wP ) * ppp + ( - 1.5 - 2 * wP ) * pp + ( - 0.5 + wP ) * p + 1;\n\t\tconst s1 = ( - 1 - wN ) * ppp + ( 1.5 + wN ) * pp + 0.5 * p;\n\t\tconst sN = wN * ppp - wN * pp;\n\n\t\t// combine data linearly\n\n\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\tresult[ i ] =\n\t\t\t\t\tsP * values[ oP + i ] +\n\t\t\t\t\ts0 * values[ o0 + i ] +\n\t\t\t\t\ts1 * values[ o1 + i ] +\n\t\t\t\t\tsN * values[ oN + i ];\n\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n}\n\nclass LinearInterpolant extends Interpolant {\n\n\tconstructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {\n\n\t\tsuper( parameterPositions, sampleValues, sampleSize, resultBuffer );\n\n\t}\n\n\tinterpolate_( i1, t0, t, t1 ) {\n\n\t\tconst result = this.resultBuffer,\n\t\t\tvalues = this.sampleValues,\n\t\t\tstride = this.valueSize,\n\n\t\t\toffset1 = i1 * stride,\n\t\t\toffset0 = offset1 - stride,\n\n\t\t\tweight1 = ( t - t0 ) / ( t1 - t0 ),\n\t\t\tweight0 = 1 - weight1;\n\n\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\tresult[ i ] =\n\t\t\t\t\tvalues[ offset0 + i ] * weight0 +\n\t\t\t\t\tvalues[ offset1 + i ] * weight1;\n\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n}\n\n/**\n *\n * Interpolant that evaluates to the sample value at the position preceeding\n * the parameter.\n */\n\nclass DiscreteInterpolant extends Interpolant {\n\n\tconstructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {\n\n\t\tsuper( parameterPositions, sampleValues, sampleSize, resultBuffer );\n\n\t}\n\n\tinterpolate_( i1 /*, t0, t, t1 */ ) {\n\n\t\treturn this.copySampleValue_( i1 - 1 );\n\n\t}\n\n}\n\nclass KeyframeTrack {\n\n\tconstructor( name, times, values, interpolation ) {\n\n\t\tif ( name === undefined ) throw new Error( 'THREE.KeyframeTrack: track name is undefined' );\n\t\tif ( times === undefined || times.length === 0 ) throw new Error( 'THREE.KeyframeTrack: no keyframes in track named ' + name );\n\n\t\tthis.name = name;\n\n\t\tthis.times = AnimationUtils.convertArray( times, this.TimeBufferType );\n\t\tthis.values = AnimationUtils.convertArray( values, this.ValueBufferType );\n\n\t\tthis.setInterpolation( interpolation || this.DefaultInterpolation );\n\n\t}\n\n\t// Serialization (in static context, because of constructor invocation\n\t// and automatic invocation of .toJSON):\n\n\tstatic toJSON( track ) {\n\n\t\tconst trackType = track.constructor;\n\n\t\tlet json;\n\n\t\t// derived classes can define a static toJSON method\n\t\tif ( trackType.toJSON !== this.toJSON ) {\n\n\t\t\tjson = trackType.toJSON( track );\n\n\t\t} else {\n\n\t\t\t// by default, we assume the data can be serialized as-is\n\t\t\tjson = {\n\n\t\t\t\t'name': track.name,\n\t\t\t\t'times': AnimationUtils.convertArray( track.times, Array ),\n\t\t\t\t'values': AnimationUtils.convertArray( track.values, Array )\n\n\t\t\t};\n\n\t\t\tconst interpolation = track.getInterpolation();\n\n\t\t\tif ( interpolation !== track.DefaultInterpolation ) {\n\n\t\t\t\tjson.interpolation = interpolation;\n\n\t\t\t}\n\n\t\t}\n\n\t\tjson.type = track.ValueTypeName; // mandatory\n\n\t\treturn json;\n\n\t}\n\n\tInterpolantFactoryMethodDiscrete( result ) {\n\n\t\treturn new DiscreteInterpolant( this.times, this.values, this.getValueSize(), result );\n\n\t}\n\n\tInterpolantFactoryMethodLinear( result ) {\n\n\t\treturn new LinearInterpolant( this.times, this.values, this.getValueSize(), result );\n\n\t}\n\n\tInterpolantFactoryMethodSmooth( result ) {\n\n\t\treturn new CubicInterpolant( this.times, this.values, this.getValueSize(), result );\n\n\t}\n\n\tsetInterpolation( interpolation ) {\n\n\t\tlet factoryMethod;\n\n\t\tswitch ( interpolation ) {\n\n\t\t\tcase InterpolateDiscrete:\n\n\t\t\t\tfactoryMethod = this.InterpolantFactoryMethodDiscrete;\n\n\t\t\t\tbreak;\n\n\t\t\tcase InterpolateLinear:\n\n\t\t\t\tfactoryMethod = this.InterpolantFactoryMethodLinear;\n\n\t\t\t\tbreak;\n\n\t\t\tcase InterpolateSmooth:\n\n\t\t\t\tfactoryMethod = this.InterpolantFactoryMethodSmooth;\n\n\t\t\t\tbreak;\n\n\t\t}\n\n\t\tif ( factoryMethod === undefined ) {\n\n\t\t\tconst message = 'unsupported interpolation for ' +\n\t\t\t\tthis.ValueTypeName + ' keyframe track named ' + this.name;\n\n\t\t\tif ( this.createInterpolant === undefined ) {\n\n\t\t\t\t// fall back to default, unless the default itself is messed up\n\t\t\t\tif ( interpolation !== this.DefaultInterpolation ) {\n\n\t\t\t\t\tthis.setInterpolation( this.DefaultInterpolation );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthrow new Error( message ); // fatal, in this case\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tconsole.warn( 'THREE.KeyframeTrack:', message );\n\t\t\treturn this;\n\n\t\t}\n\n\t\tthis.createInterpolant = factoryMethod;\n\n\t\treturn this;\n\n\t}\n\n\tgetInterpolation() {\n\n\t\tswitch ( this.createInterpolant ) {\n\n\t\t\tcase this.InterpolantFactoryMethodDiscrete:\n\n\t\t\t\treturn InterpolateDiscrete;\n\n\t\t\tcase this.InterpolantFactoryMethodLinear:\n\n\t\t\t\treturn InterpolateLinear;\n\n\t\t\tcase this.InterpolantFactoryMethodSmooth:\n\n\t\t\t\treturn InterpolateSmooth;\n\n\t\t}\n\n\t}\n\n\tgetValueSize() {\n\n\t\treturn this.values.length / this.times.length;\n\n\t}\n\n\t// move all keyframes either forwards or backwards in time\n\tshift( timeOffset ) {\n\n\t\tif ( timeOffset !== 0.0 ) {\n\n\t\t\tconst times = this.times;\n\n\t\t\tfor ( let i = 0, n = times.length; i !== n; ++ i ) {\n\n\t\t\t\ttimes[ i ] += timeOffset;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// scale all keyframe times by a factor (useful for frame <-> seconds conversions)\n\tscale( timeScale ) {\n\n\t\tif ( timeScale !== 1.0 ) {\n\n\t\t\tconst times = this.times;\n\n\t\t\tfor ( let i = 0, n = times.length; i !== n; ++ i ) {\n\n\t\t\t\ttimes[ i ] *= timeScale;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// removes keyframes before and after animation without changing any values within the range [startTime, endTime].\n\t// IMPORTANT: We do not shift around keys to the start of the track time, because for interpolated keys this will change their values\n\ttrim( startTime, endTime ) {\n\n\t\tconst times = this.times,\n\t\t\tnKeys = times.length;\n\n\t\tlet from = 0,\n\t\t\tto = nKeys - 1;\n\n\t\twhile ( from !== nKeys && times[ from ] < startTime ) {\n\n\t\t\t++ from;\n\n\t\t}\n\n\t\twhile ( to !== - 1 && times[ to ] > endTime ) {\n\n\t\t\t-- to;\n\n\t\t}\n\n\t\t++ to; // inclusive -> exclusive bound\n\n\t\tif ( from !== 0 || to !== nKeys ) {\n\n\t\t\t// empty tracks are forbidden, so keep at least one keyframe\n\t\t\tif ( from >= to ) {\n\n\t\t\t\tto = Math.max( to, 1 );\n\t\t\t\tfrom = to - 1;\n\n\t\t\t}\n\n\t\t\tconst stride = this.getValueSize();\n\t\t\tthis.times = AnimationUtils.arraySlice( times, from, to );\n\t\t\tthis.values = AnimationUtils.arraySlice( this.values, from * stride, to * stride );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// ensure we do not get a GarbageInGarbageOut situation, make sure tracks are at least minimally viable\n\tvalidate() {\n\n\t\tlet valid = true;\n\n\t\tconst valueSize = this.getValueSize();\n\t\tif ( valueSize - Math.floor( valueSize ) !== 0 ) {\n\n\t\t\tconsole.error( 'THREE.KeyframeTrack: Invalid value size in track.', this );\n\t\t\tvalid = false;\n\n\t\t}\n\n\t\tconst times = this.times,\n\t\t\tvalues = this.values,\n\n\t\t\tnKeys = times.length;\n\n\t\tif ( nKeys === 0 ) {\n\n\t\t\tconsole.error( 'THREE.KeyframeTrack: Track is empty.', this );\n\t\t\tvalid = false;\n\n\t\t}\n\n\t\tlet prevTime = null;\n\n\t\tfor ( let i = 0; i !== nKeys; i ++ ) {\n\n\t\t\tconst currTime = times[ i ];\n\n\t\t\tif ( typeof currTime === 'number' && isNaN( currTime ) ) {\n\n\t\t\t\tconsole.error( 'THREE.KeyframeTrack: Time is not a valid number.', this, i, currTime );\n\t\t\t\tvalid = false;\n\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\tif ( prevTime !== null && prevTime > currTime ) {\n\n\t\t\t\tconsole.error( 'THREE.KeyframeTrack: Out of order keys.', this, i, currTime, prevTime );\n\t\t\t\tvalid = false;\n\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\tprevTime = currTime;\n\n\t\t}\n\n\t\tif ( values !== undefined ) {\n\n\t\t\tif ( AnimationUtils.isTypedArray( values ) ) {\n\n\t\t\t\tfor ( let i = 0, n = values.length; i !== n; ++ i ) {\n\n\t\t\t\t\tconst value = values[ i ];\n\n\t\t\t\t\tif ( isNaN( value ) ) {\n\n\t\t\t\t\t\tconsole.error( 'THREE.KeyframeTrack: Value is not a valid number.', this, i, value );\n\t\t\t\t\t\tvalid = false;\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn valid;\n\n\t}\n\n\t// removes equivalent sequential keys as common in morph target sequences\n\t// (0,0,0,0,1,1,1,0,0,0,0,0,0,0) --> (0,0,1,1,0,0)\n\toptimize() {\n\n\t\t// times or values may be shared with other tracks, so overwriting is unsafe\n\t\tconst times = AnimationUtils.arraySlice( this.times ),\n\t\t\tvalues = AnimationUtils.arraySlice( this.values ),\n\t\t\tstride = this.getValueSize(),\n\n\t\t\tsmoothInterpolation = this.getInterpolation() === InterpolateSmooth,\n\n\t\t\tlastIndex = times.length - 1;\n\n\t\tlet writeIndex = 1;\n\n\t\tfor ( let i = 1; i < lastIndex; ++ i ) {\n\n\t\t\tlet keep = false;\n\n\t\t\tconst time = times[ i ];\n\t\t\tconst timeNext = times[ i + 1 ];\n\n\t\t\t// remove adjacent keyframes scheduled at the same time\n\n\t\t\tif ( time !== timeNext && ( i !== 1 || time !== times[ 0 ] ) ) {\n\n\t\t\t\tif ( ! smoothInterpolation ) {\n\n\t\t\t\t\t// remove unnecessary keyframes same as their neighbors\n\n\t\t\t\t\tconst offset = i * stride,\n\t\t\t\t\t\toffsetP = offset - stride,\n\t\t\t\t\t\toffsetN = offset + stride;\n\n\t\t\t\t\tfor ( let j = 0; j !== stride; ++ j ) {\n\n\t\t\t\t\t\tconst value = values[ offset + j ];\n\n\t\t\t\t\t\tif ( value !== values[ offsetP + j ] ||\n\t\t\t\t\t\t\tvalue !== values[ offsetN + j ] ) {\n\n\t\t\t\t\t\t\tkeep = true;\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\tkeep = true;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\t// in-place compaction\n\n\t\t\tif ( keep ) {\n\n\t\t\t\tif ( i !== writeIndex ) {\n\n\t\t\t\t\ttimes[ writeIndex ] = times[ i ];\n\n\t\t\t\t\tconst readOffset = i * stride,\n\t\t\t\t\t\twriteOffset = writeIndex * stride;\n\n\t\t\t\t\tfor ( let j = 0; j !== stride; ++ j ) {\n\n\t\t\t\t\t\tvalues[ writeOffset + j ] = values[ readOffset + j ];\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\t++ writeIndex;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// flush last keyframe (compaction looks ahead)\n\n\t\tif ( lastIndex > 0 ) {\n\n\t\t\ttimes[ writeIndex ] = times[ lastIndex ];\n\n\t\t\tfor ( let readOffset = lastIndex * stride, writeOffset = writeIndex * stride, j = 0; j !== stride; ++ j ) {\n\n\t\t\t\tvalues[ writeOffset + j ] = values[ readOffset + j ];\n\n\t\t\t}\n\n\t\t\t++ writeIndex;\n\n\t\t}\n\n\t\tif ( writeIndex !== times.length ) {\n\n\t\t\tthis.times = AnimationUtils.arraySlice( times, 0, writeIndex );\n\t\t\tthis.values = AnimationUtils.arraySlice( values, 0, writeIndex * stride );\n\n\t\t} else {\n\n\t\t\tthis.times = times;\n\t\t\tthis.values = values;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\tconst times = AnimationUtils.arraySlice( this.times, 0 );\n\t\tconst values = AnimationUtils.arraySlice( this.values, 0 );\n\n\t\tconst TypedKeyframeTrack = this.constructor;\n\t\tconst track = new TypedKeyframeTrack( this.name, times, values );\n\n\t\t// Interpolant argument to constructor is not saved, so copy the factory method directly.\n\t\ttrack.createInterpolant = this.createInterpolant;\n\n\t\treturn track;\n\n\t}\n\n}\n\nKeyframeTrack.prototype.TimeBufferType = Float32Array;\nKeyframeTrack.prototype.ValueBufferType = Float32Array;\nKeyframeTrack.prototype.DefaultInterpolation = InterpolateLinear;\n\n/**\n * A Track of Boolean keyframe values.\n */\nclass BooleanKeyframeTrack extends KeyframeTrack {}\n\nBooleanKeyframeTrack.prototype.ValueTypeName = 'bool';\nBooleanKeyframeTrack.prototype.ValueBufferType = Array;\nBooleanKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;\nBooleanKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;\nBooleanKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;\n\n/**\n * A Track of keyframe values that represent color.\n */\nclass ColorKeyframeTrack extends KeyframeTrack {}\n\nColorKeyframeTrack.prototype.ValueTypeName = 'color';\n\n/**\n * A Track of numeric keyframe values.\n */\nclass NumberKeyframeTrack extends KeyframeTrack {}\n\nNumberKeyframeTrack.prototype.ValueTypeName = 'number';\n\n/**\n * Spherical linear unit quaternion interpolant.\n */\n\nclass QuaternionLinearInterpolant extends Interpolant {\n\n\tconstructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {\n\n\t\tsuper( parameterPositions, sampleValues, sampleSize, resultBuffer );\n\n\t}\n\n\tinterpolate_( i1, t0, t, t1 ) {\n\n\t\tconst result = this.resultBuffer,\n\t\t\tvalues = this.sampleValues,\n\t\t\tstride = this.valueSize,\n\n\t\t\talpha = ( t - t0 ) / ( t1 - t0 );\n\n\t\tlet offset = i1 * stride;\n\n\t\tfor ( let end = offset + stride; offset !== end; offset += 4 ) {\n\n\t\t\tQuaternion.slerpFlat( result, 0, values, offset - stride, values, offset, alpha );\n\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n}\n\n/**\n * A Track of quaternion keyframe values.\n */\nclass QuaternionKeyframeTrack extends KeyframeTrack {\n\n\tInterpolantFactoryMethodLinear( result ) {\n\n\t\treturn new QuaternionLinearInterpolant( this.times, this.values, this.getValueSize(), result );\n\n\t}\n\n}\n\nQuaternionKeyframeTrack.prototype.ValueTypeName = 'quaternion';\n// ValueBufferType is inherited\nQuaternionKeyframeTrack.prototype.DefaultInterpolation = InterpolateLinear;\nQuaternionKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;\n\n/**\n * A Track that interpolates Strings\n */\nclass StringKeyframeTrack extends KeyframeTrack {}\n\nStringKeyframeTrack.prototype.ValueTypeName = 'string';\nStringKeyframeTrack.prototype.ValueBufferType = Array;\nStringKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;\nStringKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;\nStringKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;\n\n/**\n * A Track of vectored keyframe values.\n */\nclass VectorKeyframeTrack extends KeyframeTrack {}\n\nVectorKeyframeTrack.prototype.ValueTypeName = 'vector';\n\nclass AnimationClip {\n\n\tconstructor( name, duration = - 1, tracks, blendMode = NormalAnimationBlendMode ) {\n\n\t\tthis.name = name;\n\t\tthis.tracks = tracks;\n\t\tthis.duration = duration;\n\t\tthis.blendMode = blendMode;\n\n\t\tthis.uuid = generateUUID();\n\n\t\t// this means it should figure out its duration by scanning the tracks\n\t\tif ( this.duration < 0 ) {\n\n\t\t\tthis.resetDuration();\n\n\t\t}\n\n\t}\n\n\n\tstatic parse( json ) {\n\n\t\tconst tracks = [],\n\t\t\tjsonTracks = json.tracks,\n\t\t\tframeTime = 1.0 / ( json.fps || 1.0 );\n\n\t\tfor ( let i = 0, n = jsonTracks.length; i !== n; ++ i ) {\n\n\t\t\ttracks.push( parseKeyframeTrack( jsonTracks[ i ] ).scale( frameTime ) );\n\n\t\t}\n\n\t\tconst clip = new this( json.name, json.duration, tracks, json.blendMode );\n\t\tclip.uuid = json.uuid;\n\n\t\treturn clip;\n\n\t}\n\n\tstatic toJSON( clip ) {\n\n\t\tconst tracks = [],\n\t\t\tclipTracks = clip.tracks;\n\n\t\tconst json = {\n\n\t\t\t'name': clip.name,\n\t\t\t'duration': clip.duration,\n\t\t\t'tracks': tracks,\n\t\t\t'uuid': clip.uuid,\n\t\t\t'blendMode': clip.blendMode\n\n\t\t};\n\n\t\tfor ( let i = 0, n = clipTracks.length; i !== n; ++ i ) {\n\n\t\t\ttracks.push( KeyframeTrack.toJSON( clipTracks[ i ] ) );\n\n\t\t}\n\n\t\treturn json;\n\n\t}\n\n\tstatic CreateFromMorphTargetSequence( name, morphTargetSequence, fps, noLoop ) {\n\n\t\tconst numMorphTargets = morphTargetSequence.length;\n\t\tconst tracks = [];\n\n\t\tfor ( let i = 0; i < numMorphTargets; i ++ ) {\n\n\t\t\tlet times = [];\n\t\t\tlet values = [];\n\n\t\t\ttimes.push(\n\t\t\t\t( i + numMorphTargets - 1 ) % numMorphTargets,\n\t\t\t\ti,\n\t\t\t\t( i + 1 ) % numMorphTargets );\n\n\t\t\tvalues.push( 0, 1, 0 );\n\n\t\t\tconst order = AnimationUtils.getKeyframeOrder( times );\n\t\t\ttimes = AnimationUtils.sortedArray( times, 1, order );\n\t\t\tvalues = AnimationUtils.sortedArray( values, 1, order );\n\n\t\t\t// if there is a key at the first frame, duplicate it as the\n\t\t\t// last frame as well for perfect loop.\n\t\t\tif ( ! noLoop && times[ 0 ] === 0 ) {\n\n\t\t\t\ttimes.push( numMorphTargets );\n\t\t\t\tvalues.push( values[ 0 ] );\n\n\t\t\t}\n\n\t\t\ttracks.push(\n\t\t\t\tnew NumberKeyframeTrack(\n\t\t\t\t\t'.morphTargetInfluences[' + morphTargetSequence[ i ].name + ']',\n\t\t\t\t\ttimes, values\n\t\t\t\t).scale( 1.0 / fps ) );\n\n\t\t}\n\n\t\treturn new this( name, - 1, tracks );\n\n\t}\n\n\tstatic findByName( objectOrClipArray, name ) {\n\n\t\tlet clipArray = objectOrClipArray;\n\n\t\tif ( ! Array.isArray( objectOrClipArray ) ) {\n\n\t\t\tconst o = objectOrClipArray;\n\t\t\tclipArray = o.geometry && o.geometry.animations || o.animations;\n\n\t\t}\n\n\t\tfor ( let i = 0; i < clipArray.length; i ++ ) {\n\n\t\t\tif ( clipArray[ i ].name === name ) {\n\n\t\t\t\treturn clipArray[ i ];\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn null;\n\n\t}\n\n\tstatic CreateClipsFromMorphTargetSequences( morphTargets, fps, noLoop ) {\n\n\t\tconst animationToMorphTargets = {};\n\n\t\t// tested with https://regex101.com/ on trick sequences\n\t\t// such flamingo_flyA_003, flamingo_run1_003, crdeath0059\n\t\tconst pattern = /^([\\w-]*?)([\\d]+)$/;\n\n\t\t// sort morph target names into animation groups based\n\t\t// patterns like Walk_001, Walk_002, Run_001, Run_002\n\t\tfor ( let i = 0, il = morphTargets.length; i < il; i ++ ) {\n\n\t\t\tconst morphTarget = morphTargets[ i ];\n\t\t\tconst parts = morphTarget.name.match( pattern );\n\n\t\t\tif ( parts && parts.length > 1 ) {\n\n\t\t\t\tconst name = parts[ 1 ];\n\n\t\t\t\tlet animationMorphTargets = animationToMorphTargets[ name ];\n\n\t\t\t\tif ( ! animationMorphTargets ) {\n\n\t\t\t\t\tanimationToMorphTargets[ name ] = animationMorphTargets = [];\n\n\t\t\t\t}\n\n\t\t\t\tanimationMorphTargets.push( morphTarget );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst clips = [];\n\n\t\tfor ( const name in animationToMorphTargets ) {\n\n\t\t\tclips.push( this.CreateFromMorphTargetSequence( name, animationToMorphTargets[ name ], fps, noLoop ) );\n\n\t\t}\n\n\t\treturn clips;\n\n\t}\n\n\t// parse the animation.hierarchy format\n\tstatic parseAnimation( animation, bones ) {\n\n\t\tif ( ! animation ) {\n\n\t\t\tconsole.error( 'THREE.AnimationClip: No animation in JSONLoader data.' );\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst addNonemptyTrack = function ( trackType, trackName, animationKeys, propertyName, destTracks ) {\n\n\t\t\t// only return track if there are actually keys.\n\t\t\tif ( animationKeys.length !== 0 ) {\n\n\t\t\t\tconst times = [];\n\t\t\t\tconst values = [];\n\n\t\t\t\tAnimationUtils.flattenJSON( animationKeys, times, values, propertyName );\n\n\t\t\t\t// empty keys are filtered out, so check again\n\t\t\t\tif ( times.length !== 0 ) {\n\n\t\t\t\t\tdestTracks.push( new trackType( trackName, times, values ) );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t};\n\n\t\tconst tracks = [];\n\n\t\tconst clipName = animation.name || 'default';\n\t\tconst fps = animation.fps || 30;\n\t\tconst blendMode = animation.blendMode;\n\n\t\t// automatic length determination in AnimationClip.\n\t\tlet duration = animation.length || - 1;\n\n\t\tconst hierarchyTracks = animation.hierarchy || [];\n\n\t\tfor ( let h = 0; h < hierarchyTracks.length; h ++ ) {\n\n\t\t\tconst animationKeys = hierarchyTracks[ h ].keys;\n\n\t\t\t// skip empty tracks\n\t\t\tif ( ! animationKeys || animationKeys.length === 0 ) continue;\n\n\t\t\t// process morph targets\n\t\t\tif ( animationKeys[ 0 ].morphTargets ) {\n\n\t\t\t\t// figure out all morph targets used in this track\n\t\t\t\tconst morphTargetNames = {};\n\n\t\t\t\tlet k;\n\n\t\t\t\tfor ( k = 0; k < animationKeys.length; k ++ ) {\n\n\t\t\t\t\tif ( animationKeys[ k ].morphTargets ) {\n\n\t\t\t\t\t\tfor ( let m = 0; m < animationKeys[ k ].morphTargets.length; m ++ ) {\n\n\t\t\t\t\t\t\tmorphTargetNames[ animationKeys[ k ].morphTargets[ m ] ] = - 1;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\t// create a track for each morph target with all zero\n\t\t\t\t// morphTargetInfluences except for the keys in which\n\t\t\t\t// the morphTarget is named.\n\t\t\t\tfor ( const morphTargetName in morphTargetNames ) {\n\n\t\t\t\t\tconst times = [];\n\t\t\t\t\tconst values = [];\n\n\t\t\t\t\tfor ( let m = 0; m !== animationKeys[ k ].morphTargets.length; ++ m ) {\n\n\t\t\t\t\t\tconst animationKey = animationKeys[ k ];\n\n\t\t\t\t\t\ttimes.push( animationKey.time );\n\t\t\t\t\t\tvalues.push( ( animationKey.morphTarget === morphTargetName ) ? 1 : 0 );\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttracks.push( new NumberKeyframeTrack( '.morphTargetInfluence[' + morphTargetName + ']', times, values ) );\n\n\t\t\t\t}\n\n\t\t\t\tduration = morphTargetNames.length * fps;\n\n\t\t\t} else {\n\n\t\t\t\t// ...assume skeletal animation\n\n\t\t\t\tconst boneName = '.bones[' + bones[ h ].name + ']';\n\n\t\t\t\taddNonemptyTrack(\n\t\t\t\t\tVectorKeyframeTrack, boneName + '.position',\n\t\t\t\t\tanimationKeys, 'pos', tracks );\n\n\t\t\t\taddNonemptyTrack(\n\t\t\t\t\tQuaternionKeyframeTrack, boneName + '.quaternion',\n\t\t\t\t\tanimationKeys, 'rot', tracks );\n\n\t\t\t\taddNonemptyTrack(\n\t\t\t\t\tVectorKeyframeTrack, boneName + '.scale',\n\t\t\t\t\tanimationKeys, 'scl', tracks );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( tracks.length === 0 ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst clip = new this( clipName, duration, tracks, blendMode );\n\n\t\treturn clip;\n\n\t}\n\n\tresetDuration() {\n\n\t\tconst tracks = this.tracks;\n\t\tlet duration = 0;\n\n\t\tfor ( let i = 0, n = tracks.length; i !== n; ++ i ) {\n\n\t\t\tconst track = this.tracks[ i ];\n\n\t\t\tduration = Math.max( duration, track.times[ track.times.length - 1 ] );\n\n\t\t}\n\n\t\tthis.duration = duration;\n\n\t\treturn this;\n\n\t}\n\n\ttrim() {\n\n\t\tfor ( let i = 0; i < this.tracks.length; i ++ ) {\n\n\t\t\tthis.tracks[ i ].trim( 0, this.duration );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tvalidate() {\n\n\t\tlet valid = true;\n\n\t\tfor ( let i = 0; i < this.tracks.length; i ++ ) {\n\n\t\t\tvalid = valid && this.tracks[ i ].validate();\n\n\t\t}\n\n\t\treturn valid;\n\n\t}\n\n\toptimize() {\n\n\t\tfor ( let i = 0; i < this.tracks.length; i ++ ) {\n\n\t\t\tthis.tracks[ i ].optimize();\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\tconst tracks = [];\n\n\t\tfor ( let i = 0; i < this.tracks.length; i ++ ) {\n\n\t\t\ttracks.push( this.tracks[ i ].clone() );\n\n\t\t}\n\n\t\treturn new this.constructor( this.name, this.duration, tracks, this.blendMode );\n\n\t}\n\n\ttoJSON() {\n\n\t\treturn this.constructor.toJSON( this );\n\n\t}\n\n}\n\nfunction getTrackTypeForValueTypeName( typeName ) {\n\n\tswitch ( typeName.toLowerCase() ) {\n\n\t\tcase 'scalar':\n\t\tcase 'double':\n\t\tcase 'float':\n\t\tcase 'number':\n\t\tcase 'integer':\n\n\t\t\treturn NumberKeyframeTrack;\n\n\t\tcase 'vector':\n\t\tcase 'vector2':\n\t\tcase 'vector3':\n\t\tcase 'vector4':\n\n\t\t\treturn VectorKeyframeTrack;\n\n\t\tcase 'color':\n\n\t\t\treturn ColorKeyframeTrack;\n\n\t\tcase 'quaternion':\n\n\t\t\treturn QuaternionKeyframeTrack;\n\n\t\tcase 'bool':\n\t\tcase 'boolean':\n\n\t\t\treturn BooleanKeyframeTrack;\n\n\t\tcase 'string':\n\n\t\t\treturn StringKeyframeTrack;\n\n\t}\n\n\tthrow new Error( 'THREE.KeyframeTrack: Unsupported typeName: ' + typeName );\n\n}\n\nfunction parseKeyframeTrack( json ) {\n\n\tif ( json.type === undefined ) {\n\n\t\tthrow new Error( 'THREE.KeyframeTrack: track type undefined, can not parse' );\n\n\t}\n\n\tconst trackType = getTrackTypeForValueTypeName( json.type );\n\n\tif ( json.times === undefined ) {\n\n\t\tconst times = [], values = [];\n\n\t\tAnimationUtils.flattenJSON( json.keys, times, values, 'value' );\n\n\t\tjson.times = times;\n\t\tjson.values = values;\n\n\t}\n\n\t// derived classes can define a static parse method\n\tif ( trackType.parse !== undefined ) {\n\n\t\treturn trackType.parse( json );\n\n\t} else {\n\n\t\t// by default, we assume a constructor compatible with the base\n\t\treturn new trackType( json.name, json.times, json.values, json.interpolation );\n\n\t}\n\n}\n\nconst Cache = {\n\n\tenabled: false,\n\n\tfiles: {},\n\n\tadd: function ( key, file ) {\n\n\t\tif ( this.enabled === false ) return;\n\n\t\t// console.log( 'THREE.Cache', 'Adding key:', key );\n\n\t\tthis.files[ key ] = file;\n\n\t},\n\n\tget: function ( key ) {\n\n\t\tif ( this.enabled === false ) return;\n\n\t\t// console.log( 'THREE.Cache', 'Checking key:', key );\n\n\t\treturn this.files[ key ];\n\n\t},\n\n\tremove: function ( key ) {\n\n\t\tdelete this.files[ key ];\n\n\t},\n\n\tclear: function () {\n\n\t\tthis.files = {};\n\n\t}\n\n};\n\nclass LoadingManager {\n\n\tconstructor( onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tlet isLoading = false;\n\t\tlet itemsLoaded = 0;\n\t\tlet itemsTotal = 0;\n\t\tlet urlModifier = undefined;\n\t\tconst handlers = [];\n\n\t\t// Refer to #5689 for the reason why we don't set .onStart\n\t\t// in the constructor\n\n\t\tthis.onStart = undefined;\n\t\tthis.onLoad = onLoad;\n\t\tthis.onProgress = onProgress;\n\t\tthis.onError = onError;\n\n\t\tthis.itemStart = function ( url ) {\n\n\t\t\titemsTotal ++;\n\n\t\t\tif ( isLoading === false ) {\n\n\t\t\t\tif ( scope.onStart !== undefined ) {\n\n\t\t\t\t\tscope.onStart( url, itemsLoaded, itemsTotal );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tisLoading = true;\n\n\t\t};\n\n\t\tthis.itemEnd = function ( url ) {\n\n\t\t\titemsLoaded ++;\n\n\t\t\tif ( scope.onProgress !== undefined ) {\n\n\t\t\t\tscope.onProgress( url, itemsLoaded, itemsTotal );\n\n\t\t\t}\n\n\t\t\tif ( itemsLoaded === itemsTotal ) {\n\n\t\t\t\tisLoading = false;\n\n\t\t\t\tif ( scope.onLoad !== undefined ) {\n\n\t\t\t\t\tscope.onLoad();\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t};\n\n\t\tthis.itemError = function ( url ) {\n\n\t\t\tif ( scope.onError !== undefined ) {\n\n\t\t\t\tscope.onError( url );\n\n\t\t\t}\n\n\t\t};\n\n\t\tthis.resolveURL = function ( url ) {\n\n\t\t\tif ( urlModifier ) {\n\n\t\t\t\treturn urlModifier( url );\n\n\t\t\t}\n\n\t\t\treturn url;\n\n\t\t};\n\n\t\tthis.setURLModifier = function ( transform ) {\n\n\t\t\turlModifier = transform;\n\n\t\t\treturn this;\n\n\t\t};\n\n\t\tthis.addHandler = function ( regex, loader ) {\n\n\t\t\thandlers.push( regex, loader );\n\n\t\t\treturn this;\n\n\t\t};\n\n\t\tthis.removeHandler = function ( regex ) {\n\n\t\t\tconst index = handlers.indexOf( regex );\n\n\t\t\tif ( index !== - 1 ) {\n\n\t\t\t\thandlers.splice( index, 2 );\n\n\t\t\t}\n\n\t\t\treturn this;\n\n\t\t};\n\n\t\tthis.getHandler = function ( file ) {\n\n\t\t\tfor ( let i = 0, l = handlers.length; i < l; i += 2 ) {\n\n\t\t\t\tconst regex = handlers[ i ];\n\t\t\t\tconst loader = handlers[ i + 1 ];\n\n\t\t\t\tif ( regex.global ) regex.lastIndex = 0; // see #17920\n\n\t\t\t\tif ( regex.test( file ) ) {\n\n\t\t\t\t\treturn loader;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn null;\n\n\t\t};\n\n\t}\n\n}\n\nconst DefaultLoadingManager = new LoadingManager();\n\nclass Loader {\n\n\tconstructor( manager ) {\n\n\t\tthis.manager = ( manager !== undefined ) ? manager : DefaultLoadingManager;\n\n\t\tthis.crossOrigin = 'anonymous';\n\t\tthis.withCredentials = false;\n\t\tthis.path = '';\n\t\tthis.resourcePath = '';\n\t\tthis.requestHeader = {};\n\n\t}\n\n\tload( /* url, onLoad, onProgress, onError */ ) {}\n\n\tloadAsync( url, onProgress ) {\n\n\t\tconst scope = this;\n\n\t\treturn new Promise( function ( resolve, reject ) {\n\n\t\t\tscope.load( url, resolve, onProgress, reject );\n\n\t\t} );\n\n\t}\n\n\tparse( /* data */ ) {}\n\n\tsetCrossOrigin( crossOrigin ) {\n\n\t\tthis.crossOrigin = crossOrigin;\n\t\treturn this;\n\n\t}\n\n\tsetWithCredentials( value ) {\n\n\t\tthis.withCredentials = value;\n\t\treturn this;\n\n\t}\n\n\tsetPath( path ) {\n\n\t\tthis.path = path;\n\t\treturn this;\n\n\t}\n\n\tsetResourcePath( resourcePath ) {\n\n\t\tthis.resourcePath = resourcePath;\n\t\treturn this;\n\n\t}\n\n\tsetRequestHeader( requestHeader ) {\n\n\t\tthis.requestHeader = requestHeader;\n\t\treturn this;\n\n\t}\n\n}\n\nconst loading = {};\n\nclass FileLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tif ( url === undefined ) url = '';\n\n\t\tif ( this.path !== undefined ) url = this.path + url;\n\n\t\turl = this.manager.resolveURL( url );\n\n\t\tconst cached = Cache.get( url );\n\n\t\tif ( cached !== undefined ) {\n\n\t\t\tthis.manager.itemStart( url );\n\n\t\t\tsetTimeout( () => {\n\n\t\t\t\tif ( onLoad ) onLoad( cached );\n\n\t\t\t\tthis.manager.itemEnd( url );\n\n\t\t\t}, 0 );\n\n\t\t\treturn cached;\n\n\t\t}\n\n\t\t// Check if request is duplicate\n\n\t\tif ( loading[ url ] !== undefined ) {\n\n\t\t\tloading[ url ].push( {\n\n\t\t\t\tonLoad: onLoad,\n\t\t\t\tonProgress: onProgress,\n\t\t\t\tonError: onError\n\n\t\t\t} );\n\n\t\t\treturn;\n\n\t\t}\n\n\t\t// Initialise array for duplicate requests\n\t\tloading[ url ] = [];\n\n\t\tloading[ url ].push( {\n\t\t\tonLoad: onLoad,\n\t\t\tonProgress: onProgress,\n\t\t\tonError: onError,\n\t\t} );\n\n\t\t// create request\n\t\tconst req = new Request( url, {\n\t\t\theaders: new Headers( this.requestHeader ),\n\t\t\tcredentials: this.withCredentials ? 'include' : 'same-origin',\n\t\t\t// An abort controller could be added within a future PR\n\t\t} );\n\n\t\t// record states ( avoid data race )\n\t\tconst mimeType = this.mimeType;\n\t\tconst responseType = this.responseType;\n\n\t\t// start the fetch\n\t\tfetch( req )\n\t\t\t.then( response => {\n\n\t\t\t\tif ( response.status === 200 || response.status === 0 ) {\n\n\t\t\t\t\t// Some browsers return HTTP Status 0 when using non-http protocol\n\t\t\t\t\t// e.g. 'file://' or 'data://'. Handle as success.\n\n\t\t\t\t\tif ( response.status === 0 ) {\n\n\t\t\t\t\t\tconsole.warn( 'THREE.FileLoader: HTTP Status 0 received.' );\n\n\t\t\t\t\t}\n\n\t\t\t\t\t// Workaround: Checking if response.body === undefined for Alipay browser #23548\n\n\t\t\t\t\tif ( typeof ReadableStream === 'undefined' || response.body === undefined || response.body.getReader === undefined ) {\n\n\t\t\t\t\t\treturn response;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst callbacks = loading[ url ];\n\t\t\t\t\tconst reader = response.body.getReader();\n\t\t\t\t\tconst contentLength = response.headers.get( 'Content-Length' );\n\t\t\t\t\tconst total = contentLength ? parseInt( contentLength ) : 0;\n\t\t\t\t\tconst lengthComputable = total !== 0;\n\t\t\t\t\tlet loaded = 0;\n\n\t\t\t\t\t// periodically read data into the new stream tracking while download progress\n\t\t\t\t\tconst stream = new ReadableStream( {\n\t\t\t\t\t\tstart( controller ) {\n\n\t\t\t\t\t\t\treadData();\n\n\t\t\t\t\t\t\tfunction readData() {\n\n\t\t\t\t\t\t\t\treader.read().then( ( { done, value } ) => {\n\n\t\t\t\t\t\t\t\t\tif ( done ) {\n\n\t\t\t\t\t\t\t\t\t\tcontroller.close();\n\n\t\t\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\t\t\tloaded += value.byteLength;\n\n\t\t\t\t\t\t\t\t\t\tconst event = new ProgressEvent( 'progress', { lengthComputable, loaded, total } );\n\t\t\t\t\t\t\t\t\t\tfor ( let i = 0, il = callbacks.length; i < il; i ++ ) {\n\n\t\t\t\t\t\t\t\t\t\t\tconst callback = callbacks[ i ];\n\t\t\t\t\t\t\t\t\t\t\tif ( callback.onProgress ) callback.onProgress( event );\n\n\t\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t\t\tcontroller.enqueue( value );\n\t\t\t\t\t\t\t\t\t\treadData();\n\n\t\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\t} );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} );\n\n\t\t\t\t\treturn new Response( stream );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthrow Error( `fetch for \"${response.url}\" responded with ${response.status}: ${response.statusText}` );\n\n\t\t\t\t}\n\n\t\t\t} )\n\t\t\t.then( response => {\n\n\t\t\t\tswitch ( responseType ) {\n\n\t\t\t\t\tcase 'arraybuffer':\n\n\t\t\t\t\t\treturn response.arrayBuffer();\n\n\t\t\t\t\tcase 'blob':\n\n\t\t\t\t\t\treturn response.blob();\n\n\t\t\t\t\tcase 'document':\n\n\t\t\t\t\t\treturn response.text()\n\t\t\t\t\t\t\t.then( text => {\n\n\t\t\t\t\t\t\t\tconst parser = new DOMParser();\n\t\t\t\t\t\t\t\treturn parser.parseFromString( text, mimeType );\n\n\t\t\t\t\t\t\t} );\n\n\t\t\t\t\tcase 'json':\n\n\t\t\t\t\t\treturn response.json();\n\n\t\t\t\t\tdefault:\n\n\t\t\t\t\t\tif ( mimeType === undefined ) {\n\n\t\t\t\t\t\t\treturn response.text();\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t// sniff encoding\n\t\t\t\t\t\t\tconst re = /charset=\"?([^;\"\\s]*)\"?/i;\n\t\t\t\t\t\t\tconst exec = re.exec( mimeType );\n\t\t\t\t\t\t\tconst label = exec && exec[ 1 ] ? exec[ 1 ].toLowerCase() : undefined;\n\t\t\t\t\t\t\tconst decoder = new TextDecoder( label );\n\t\t\t\t\t\t\treturn response.arrayBuffer().then( ab => decoder.decode( ab ) );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t} )\n\t\t\t.then( data => {\n\n\t\t\t\t// Add to cache only on HTTP success, so that we do not cache\n\t\t\t\t// error response bodies as proper responses to requests.\n\t\t\t\tCache.add( url, data );\n\n\t\t\t\tconst callbacks = loading[ url ];\n\t\t\t\tdelete loading[ url ];\n\n\t\t\t\tfor ( let i = 0, il = callbacks.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst callback = callbacks[ i ];\n\t\t\t\t\tif ( callback.onLoad ) callback.onLoad( data );\n\n\t\t\t\t}\n\n\t\t\t} )\n\t\t\t.catch( err => {\n\n\t\t\t\t// Abort errors and other errors are handled the same\n\n\t\t\t\tconst callbacks = loading[ url ];\n\n\t\t\t\tif ( callbacks === undefined ) {\n\n\t\t\t\t\t// When onLoad was called and url was deleted in `loading`\n\t\t\t\t\tthis.manager.itemError( url );\n\t\t\t\t\tthrow err;\n\n\t\t\t\t}\n\n\t\t\t\tdelete loading[ url ];\n\n\t\t\t\tfor ( let i = 0, il = callbacks.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst callback = callbacks[ i ];\n\t\t\t\t\tif ( callback.onError ) callback.onError( err );\n\n\t\t\t\t}\n\n\t\t\t\tthis.manager.itemError( url );\n\n\t\t\t} )\n\t\t\t.finally( () => {\n\n\t\t\t\tthis.manager.itemEnd( url );\n\n\t\t\t} );\n\n\t\tthis.manager.itemStart( url );\n\n\t}\n\n\tsetResponseType( value ) {\n\n\t\tthis.responseType = value;\n\t\treturn this;\n\n\t}\n\n\tsetMimeType( value ) {\n\n\t\tthis.mimeType = value;\n\t\treturn this;\n\n\t}\n\n}\n\nclass AnimationLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst loader = new FileLoader( this.manager );\n\t\tloader.setPath( this.path );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setWithCredentials( this.withCredentials );\n\t\tloader.load( url, function ( text ) {\n\n\t\t\ttry {\n\n\t\t\t\tonLoad( scope.parse( JSON.parse( text ) ) );\n\n\t\t\t} catch ( e ) {\n\n\t\t\t\tif ( onError ) {\n\n\t\t\t\t\tonError( e );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( e );\n\n\t\t\t\t}\n\n\t\t\t\tscope.manager.itemError( url );\n\n\t\t\t}\n\n\t\t}, onProgress, onError );\n\n\t}\n\n\tparse( json ) {\n\n\t\tconst animations = [];\n\n\t\tfor ( let i = 0; i < json.length; i ++ ) {\n\n\t\t\tconst clip = AnimationClip.parse( json[ i ] );\n\n\t\t\tanimations.push( clip );\n\n\t\t}\n\n\t\treturn animations;\n\n\t}\n\n}\n\n/**\n * Abstract Base class to block based textures loader (dds, pvr, ...)\n *\n * Sub classes have to implement the parse() method which will be used in load().\n */\n\nclass CompressedTextureLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst images = [];\n\n\t\tconst texture = new CompressedTexture();\n\n\t\tconst loader = new FileLoader( this.manager );\n\t\tloader.setPath( this.path );\n\t\tloader.setResponseType( 'arraybuffer' );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setWithCredentials( scope.withCredentials );\n\n\t\tlet loaded = 0;\n\n\t\tfunction loadTexture( i ) {\n\n\t\t\tloader.load( url[ i ], function ( buffer ) {\n\n\t\t\t\tconst texDatas = scope.parse( buffer, true );\n\n\t\t\t\timages[ i ] = {\n\t\t\t\t\twidth: texDatas.width,\n\t\t\t\t\theight: texDatas.height,\n\t\t\t\t\tformat: texDatas.format,\n\t\t\t\t\tmipmaps: texDatas.mipmaps\n\t\t\t\t};\n\n\t\t\t\tloaded += 1;\n\n\t\t\t\tif ( loaded === 6 ) {\n\n\t\t\t\t\tif ( texDatas.mipmapCount === 1 ) texture.minFilter = LinearFilter;\n\n\t\t\t\t\ttexture.image = images;\n\t\t\t\t\ttexture.format = texDatas.format;\n\t\t\t\t\ttexture.needsUpdate = true;\n\n\t\t\t\t\tif ( onLoad ) onLoad( texture );\n\n\t\t\t\t}\n\n\t\t\t}, onProgress, onError );\n\n\t\t}\n\n\t\tif ( Array.isArray( url ) ) {\n\n\t\t\tfor ( let i = 0, il = url.length; i < il; ++ i ) {\n\n\t\t\t\tloadTexture( i );\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\t// compressed cubemap texture stored in a single DDS file\n\n\t\t\tloader.load( url, function ( buffer ) {\n\n\t\t\t\tconst texDatas = scope.parse( buffer, true );\n\n\t\t\t\tif ( texDatas.isCubemap ) {\n\n\t\t\t\t\tconst faces = texDatas.mipmaps.length / texDatas.mipmapCount;\n\n\t\t\t\t\tfor ( let f = 0; f < faces; f ++ ) {\n\n\t\t\t\t\t\timages[ f ] = { mipmaps: [] };\n\n\t\t\t\t\t\tfor ( let i = 0; i < texDatas.mipmapCount; i ++ ) {\n\n\t\t\t\t\t\t\timages[ f ].mipmaps.push( texDatas.mipmaps[ f * texDatas.mipmapCount + i ] );\n\t\t\t\t\t\t\timages[ f ].format = texDatas.format;\n\t\t\t\t\t\t\timages[ f ].width = texDatas.width;\n\t\t\t\t\t\t\timages[ f ].height = texDatas.height;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttexture.image = images;\n\n\t\t\t\t} else {\n\n\t\t\t\t\ttexture.image.width = texDatas.width;\n\t\t\t\t\ttexture.image.height = texDatas.height;\n\t\t\t\t\ttexture.mipmaps = texDatas.mipmaps;\n\n\t\t\t\t}\n\n\t\t\t\tif ( texDatas.mipmapCount === 1 ) {\n\n\t\t\t\t\ttexture.minFilter = LinearFilter;\n\n\t\t\t\t}\n\n\t\t\t\ttexture.format = texDatas.format;\n\t\t\t\ttexture.needsUpdate = true;\n\n\t\t\t\tif ( onLoad ) onLoad( texture );\n\n\t\t\t}, onProgress, onError );\n\n\t\t}\n\n\t\treturn texture;\n\n\t}\n\n}\n\nclass ImageLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tif ( this.path !== undefined ) url = this.path + url;\n\n\t\turl = this.manager.resolveURL( url );\n\n\t\tconst scope = this;\n\n\t\tconst cached = Cache.get( url );\n\n\t\tif ( cached !== undefined ) {\n\n\t\t\tscope.manager.itemStart( url );\n\n\t\t\tsetTimeout( function () {\n\n\t\t\t\tif ( onLoad ) onLoad( cached );\n\n\t\t\t\tscope.manager.itemEnd( url );\n\n\t\t\t}, 0 );\n\n\t\t\treturn cached;\n\n\t\t}\n\n\t\tconst image = createElementNS( 'img' );\n\n\t\tfunction onImageLoad() {\n\n\t\t\tremoveEventListeners();\n\n\t\t\tCache.add( url, this );\n\n\t\t\tif ( onLoad ) onLoad( this );\n\n\t\t\tscope.manager.itemEnd( url );\n\n\t\t}\n\n\t\tfunction onImageError( event ) {\n\n\t\t\tremoveEventListeners();\n\n\t\t\tif ( onError ) onError( event );\n\n\t\t\tscope.manager.itemError( url );\n\t\t\tscope.manager.itemEnd( url );\n\n\t\t}\n\n\t\tfunction removeEventListeners() {\n\n\t\t\timage.removeEventListener( 'load', onImageLoad, false );\n\t\t\timage.removeEventListener( 'error', onImageError, false );\n\n\t\t}\n\n\t\timage.addEventListener( 'load', onImageLoad, false );\n\t\timage.addEventListener( 'error', onImageError, false );\n\n\t\tif ( url.slice( 0, 5 ) !== 'data:' ) {\n\n\t\t\tif ( this.crossOrigin !== undefined ) image.crossOrigin = this.crossOrigin;\n\n\t\t}\n\n\t\tscope.manager.itemStart( url );\n\n\t\timage.src = url;\n\n\t\treturn image;\n\n\t}\n\n}\n\nclass CubeTextureLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( urls, onLoad, onProgress, onError ) {\n\n\t\tconst texture = new CubeTexture();\n\n\t\tconst loader = new ImageLoader( this.manager );\n\t\tloader.setCrossOrigin( this.crossOrigin );\n\t\tloader.setPath( this.path );\n\n\t\tlet loaded = 0;\n\n\t\tfunction loadTexture( i ) {\n\n\t\t\tloader.load( urls[ i ], function ( image ) {\n\n\t\t\t\ttexture.images[ i ] = image;\n\n\t\t\t\tloaded ++;\n\n\t\t\t\tif ( loaded === 6 ) {\n\n\t\t\t\t\ttexture.needsUpdate = true;\n\n\t\t\t\t\tif ( onLoad ) onLoad( texture );\n\n\t\t\t\t}\n\n\t\t\t}, undefined, onError );\n\n\t\t}\n\n\t\tfor ( let i = 0; i < urls.length; ++ i ) {\n\n\t\t\tloadTexture( i );\n\n\t\t}\n\n\t\treturn texture;\n\n\t}\n\n}\n\n/**\n * Abstract Base class to load generic binary textures formats (rgbe, hdr, ...)\n *\n * Sub classes have to implement the parse() method which will be used in load().\n */\n\nclass DataTextureLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst texture = new DataTexture();\n\n\t\tconst loader = new FileLoader( this.manager );\n\t\tloader.setResponseType( 'arraybuffer' );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setPath( this.path );\n\t\tloader.setWithCredentials( scope.withCredentials );\n\t\tloader.load( url, function ( buffer ) {\n\n\t\t\tconst texData = scope.parse( buffer );\n\n\t\t\tif ( ! texData ) return;\n\n\t\t\tif ( texData.image !== undefined ) {\n\n\t\t\t\ttexture.image = texData.image;\n\n\t\t\t} else if ( texData.data !== undefined ) {\n\n\t\t\t\ttexture.image.width = texData.width;\n\t\t\t\ttexture.image.height = texData.height;\n\t\t\t\ttexture.image.data = texData.data;\n\n\t\t\t}\n\n\t\t\ttexture.wrapS = texData.wrapS !== undefined ? texData.wrapS : ClampToEdgeWrapping;\n\t\t\ttexture.wrapT = texData.wrapT !== undefined ? texData.wrapT : ClampToEdgeWrapping;\n\n\t\t\ttexture.magFilter = texData.magFilter !== undefined ? texData.magFilter : LinearFilter;\n\t\t\ttexture.minFilter = texData.minFilter !== undefined ? texData.minFilter : LinearFilter;\n\n\t\t\ttexture.anisotropy = texData.anisotropy !== undefined ? texData.anisotropy : 1;\n\n\t\t\tif ( texData.encoding !== undefined ) {\n\n\t\t\t\ttexture.encoding = texData.encoding;\n\n\t\t\t}\n\n\t\t\tif ( texData.flipY !== undefined ) {\n\n\t\t\t\ttexture.flipY = texData.flipY;\n\n\t\t\t}\n\n\t\t\tif ( texData.format !== undefined ) {\n\n\t\t\t\ttexture.format = texData.format;\n\n\t\t\t}\n\n\t\t\tif ( texData.type !== undefined ) {\n\n\t\t\t\ttexture.type = texData.type;\n\n\t\t\t}\n\n\t\t\tif ( texData.mipmaps !== undefined ) {\n\n\t\t\t\ttexture.mipmaps = texData.mipmaps;\n\t\t\t\ttexture.minFilter = LinearMipmapLinearFilter; // presumably...\n\n\t\t\t}\n\n\t\t\tif ( texData.mipmapCount === 1 ) {\n\n\t\t\t\ttexture.minFilter = LinearFilter;\n\n\t\t\t}\n\n\t\t\tif ( texData.generateMipmaps !== undefined ) {\n\n\t\t\t\ttexture.generateMipmaps = texData.generateMipmaps;\n\n\t\t\t}\n\n\t\t\ttexture.needsUpdate = true;\n\n\t\t\tif ( onLoad ) onLoad( texture, texData );\n\n\t\t}, onProgress, onError );\n\n\n\t\treturn texture;\n\n\t}\n\n}\n\nclass TextureLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst texture = new Texture();\n\n\t\tconst loader = new ImageLoader( this.manager );\n\t\tloader.setCrossOrigin( this.crossOrigin );\n\t\tloader.setPath( this.path );\n\n\t\tloader.load( url, function ( image ) {\n\n\t\t\ttexture.image = image;\n\t\t\ttexture.needsUpdate = true;\n\n\t\t\tif ( onLoad !== undefined ) {\n\n\t\t\t\tonLoad( texture );\n\n\t\t\t}\n\n\t\t}, onProgress, onError );\n\n\t\treturn texture;\n\n\t}\n\n}\n\nclass Light extends Object3D {\n\n\tconstructor( color, intensity = 1 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'Light';\n\n\t\tthis.color = new Color( color );\n\t\tthis.intensity = intensity;\n\n\t}\n\n\tdispose() {\n\n\t\t// Empty here in base class; some subclasses override.\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.color.copy( source.color );\n\t\tthis.intensity = source.intensity;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tdata.object.color = this.color.getHex();\n\t\tdata.object.intensity = this.intensity;\n\n\t\tif ( this.groundColor !== undefined ) data.object.groundColor = this.groundColor.getHex();\n\n\t\tif ( this.distance !== undefined ) data.object.distance = this.distance;\n\t\tif ( this.angle !== undefined ) data.object.angle = this.angle;\n\t\tif ( this.decay !== undefined ) data.object.decay = this.decay;\n\t\tif ( this.penumbra !== undefined ) data.object.penumbra = this.penumbra;\n\n\t\tif ( this.shadow !== undefined ) data.object.shadow = this.shadow.toJSON();\n\n\t\treturn data;\n\n\t}\n\n}\n\nLight.prototype.isLight = true;\n\nclass HemisphereLight extends Light {\n\n\tconstructor( skyColor, groundColor, intensity ) {\n\n\t\tsuper( skyColor, intensity );\n\n\t\tthis.type = 'HemisphereLight';\n\n\t\tthis.position.copy( Object3D.DefaultUp );\n\t\tthis.updateMatrix();\n\n\t\tthis.groundColor = new Color( groundColor );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tLight.prototype.copy.call( this, source );\n\n\t\tthis.groundColor.copy( source.groundColor );\n\n\t\treturn this;\n\n\t}\n\n}\n\nHemisphereLight.prototype.isHemisphereLight = true;\n\nconst _projScreenMatrix$1 = /*@__PURE__*/ new Matrix4();\nconst _lightPositionWorld$1 = /*@__PURE__*/ new Vector3();\nconst _lookTarget$1 = /*@__PURE__*/ new Vector3();\n\nclass LightShadow {\n\n\tconstructor( camera ) {\n\n\t\tthis.camera = camera;\n\n\t\tthis.bias = 0;\n\t\tthis.normalBias = 0;\n\t\tthis.radius = 1;\n\t\tthis.blurSamples = 8;\n\n\t\tthis.mapSize = new Vector2( 512, 512 );\n\n\t\tthis.map = null;\n\t\tthis.mapPass = null;\n\t\tthis.matrix = new Matrix4();\n\n\t\tthis.autoUpdate = true;\n\t\tthis.needsUpdate = false;\n\n\t\tthis._frustum = new Frustum();\n\t\tthis._frameExtents = new Vector2( 1, 1 );\n\n\t\tthis._viewportCount = 1;\n\n\t\tthis._viewports = [\n\n\t\t\tnew Vector4( 0, 0, 1, 1 )\n\n\t\t];\n\n\t}\n\n\tgetViewportCount() {\n\n\t\treturn this._viewportCount;\n\n\t}\n\n\tgetFrustum() {\n\n\t\treturn this._frustum;\n\n\t}\n\n\tupdateMatrices( light ) {\n\n\t\tconst shadowCamera = this.camera;\n\t\tconst shadowMatrix = this.matrix;\n\n\t\t_lightPositionWorld$1.setFromMatrixPosition( light.matrixWorld );\n\t\tshadowCamera.position.copy( _lightPositionWorld$1 );\n\n\t\t_lookTarget$1.setFromMatrixPosition( light.target.matrixWorld );\n\t\tshadowCamera.lookAt( _lookTarget$1 );\n\t\tshadowCamera.updateMatrixWorld();\n\n\t\t_projScreenMatrix$1.multiplyMatrices( shadowCamera.projectionMatrix, shadowCamera.matrixWorldInverse );\n\t\tthis._frustum.setFromProjectionMatrix( _projScreenMatrix$1 );\n\n\t\tshadowMatrix.set(\n\t\t\t0.5, 0.0, 0.0, 0.5,\n\t\t\t0.0, 0.5, 0.0, 0.5,\n\t\t\t0.0, 0.0, 0.5, 0.5,\n\t\t\t0.0, 0.0, 0.0, 1.0\n\t\t);\n\n\t\tshadowMatrix.multiply( shadowCamera.projectionMatrix );\n\t\tshadowMatrix.multiply( shadowCamera.matrixWorldInverse );\n\n\t}\n\n\tgetViewport( viewportIndex ) {\n\n\t\treturn this._viewports[ viewportIndex ];\n\n\t}\n\n\tgetFrameExtents() {\n\n\t\treturn this._frameExtents;\n\n\t}\n\n\tdispose() {\n\n\t\tif ( this.map ) {\n\n\t\t\tthis.map.dispose();\n\n\t\t}\n\n\t\tif ( this.mapPass ) {\n\n\t\t\tthis.mapPass.dispose();\n\n\t\t}\n\n\t}\n\n\tcopy( source ) {\n\n\t\tthis.camera = source.camera.clone();\n\n\t\tthis.bias = source.bias;\n\t\tthis.radius = source.radius;\n\n\t\tthis.mapSize.copy( source.mapSize );\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst object = {};\n\n\t\tif ( this.bias !== 0 ) object.bias = this.bias;\n\t\tif ( this.normalBias !== 0 ) object.normalBias = this.normalBias;\n\t\tif ( this.radius !== 1 ) object.radius = this.radius;\n\t\tif ( this.mapSize.x !== 512 || this.mapSize.y !== 512 ) object.mapSize = this.mapSize.toArray();\n\n\t\tobject.camera = this.camera.toJSON( false ).object;\n\t\tdelete object.camera.matrix;\n\n\t\treturn object;\n\n\t}\n\n}\n\nclass SpotLightShadow extends LightShadow {\n\n\tconstructor() {\n\n\t\tsuper( new PerspectiveCamera( 50, 1, 0.5, 500 ) );\n\n\t\tthis.focus = 1;\n\n\t}\n\n\tupdateMatrices( light ) {\n\n\t\tconst camera = this.camera;\n\n\t\tconst fov = RAD2DEG * 2 * light.angle * this.focus;\n\t\tconst aspect = this.mapSize.width / this.mapSize.height;\n\t\tconst far = light.distance || camera.far;\n\n\t\tif ( fov !== camera.fov || aspect !== camera.aspect || far !== camera.far ) {\n\n\t\t\tcamera.fov = fov;\n\t\t\tcamera.aspect = aspect;\n\t\t\tcamera.far = far;\n\t\t\tcamera.updateProjectionMatrix();\n\n\t\t}\n\n\t\tsuper.updateMatrices( light );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.focus = source.focus;\n\n\t\treturn this;\n\n\t}\n\n}\n\nSpotLightShadow.prototype.isSpotLightShadow = true;\n\nclass SpotLight extends Light {\n\n\tconstructor( color, intensity, distance = 0, angle = Math.PI / 3, penumbra = 0, decay = 1 ) {\n\n\t\tsuper( color, intensity );\n\n\t\tthis.type = 'SpotLight';\n\n\t\tthis.position.copy( Object3D.DefaultUp );\n\t\tthis.updateMatrix();\n\n\t\tthis.target = new Object3D();\n\n\t\tthis.distance = distance;\n\t\tthis.angle = angle;\n\t\tthis.penumbra = penumbra;\n\t\tthis.decay = decay; // for physically correct lights, should be 2.\n\n\t\tthis.shadow = new SpotLightShadow();\n\n\t}\n\n\tget power() {\n\n\t\t// compute the light's luminous power (in lumens) from its intensity (in candela)\n\t\t// by convention for a spotlight, luminous power (lm) =  * luminous intensity (cd)\n\t\treturn this.intensity * Math.PI;\n\n\t}\n\n\tset power( power ) {\n\n\t\t// set the light's intensity (in candela) from the desired luminous power (in lumens)\n\t\tthis.intensity = power / Math.PI;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.shadow.dispose();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.distance = source.distance;\n\t\tthis.angle = source.angle;\n\t\tthis.penumbra = source.penumbra;\n\t\tthis.decay = source.decay;\n\n\t\tthis.target = source.target.clone();\n\n\t\tthis.shadow = source.shadow.clone();\n\n\t\treturn this;\n\n\t}\n\n}\n\nSpotLight.prototype.isSpotLight = true;\n\nconst _projScreenMatrix = /*@__PURE__*/ new Matrix4();\nconst _lightPositionWorld = /*@__PURE__*/ new Vector3();\nconst _lookTarget = /*@__PURE__*/ new Vector3();\n\nclass PointLightShadow extends LightShadow {\n\n\tconstructor() {\n\n\t\tsuper( new PerspectiveCamera( 90, 1, 0.5, 500 ) );\n\n\t\tthis._frameExtents = new Vector2( 4, 2 );\n\n\t\tthis._viewportCount = 6;\n\n\t\tthis._viewports = [\n\t\t\t// These viewports map a cube-map onto a 2D texture with the\n\t\t\t// following orientation:\n\t\t\t//\n\t\t\t//  xzXZ\n\t\t\t//   y Y\n\t\t\t//\n\t\t\t// X - Positive x direction\n\t\t\t// x - Negative x direction\n\t\t\t// Y - Positive y direction\n\t\t\t// y - Negative y direction\n\t\t\t// Z - Positive z direction\n\t\t\t// z - Negative z direction\n\n\t\t\t// positive X\n\t\t\tnew Vector4( 2, 1, 1, 1 ),\n\t\t\t// negative X\n\t\t\tnew Vector4( 0, 1, 1, 1 ),\n\t\t\t// positive Z\n\t\t\tnew Vector4( 3, 1, 1, 1 ),\n\t\t\t// negative Z\n\t\t\tnew Vector4( 1, 1, 1, 1 ),\n\t\t\t// positive Y\n\t\t\tnew Vector4( 3, 0, 1, 1 ),\n\t\t\t// negative Y\n\t\t\tnew Vector4( 1, 0, 1, 1 )\n\t\t];\n\n\t\tthis._cubeDirections = [\n\t\t\tnew Vector3( 1, 0, 0 ), new Vector3( - 1, 0, 0 ), new Vector3( 0, 0, 1 ),\n\t\t\tnew Vector3( 0, 0, - 1 ), new Vector3( 0, 1, 0 ), new Vector3( 0, - 1, 0 )\n\t\t];\n\n\t\tthis._cubeUps = [\n\t\t\tnew Vector3( 0, 1, 0 ), new Vector3( 0, 1, 0 ), new Vector3( 0, 1, 0 ),\n\t\t\tnew Vector3( 0, 1, 0 ), new Vector3( 0, 0, 1 ),\tnew Vector3( 0, 0, - 1 )\n\t\t];\n\n\t}\n\n\tupdateMatrices( light, viewportIndex = 0 ) {\n\n\t\tconst camera = this.camera;\n\t\tconst shadowMatrix = this.matrix;\n\n\t\tconst far = light.distance || camera.far;\n\n\t\tif ( far !== camera.far ) {\n\n\t\t\tcamera.far = far;\n\t\t\tcamera.updateProjectionMatrix();\n\n\t\t}\n\n\t\t_lightPositionWorld.setFromMatrixPosition( light.matrixWorld );\n\t\tcamera.position.copy( _lightPositionWorld );\n\n\t\t_lookTarget.copy( camera.position );\n\t\t_lookTarget.add( this._cubeDirections[ viewportIndex ] );\n\t\tcamera.up.copy( this._cubeUps[ viewportIndex ] );\n\t\tcamera.lookAt( _lookTarget );\n\t\tcamera.updateMatrixWorld();\n\n\t\tshadowMatrix.makeTranslation( - _lightPositionWorld.x, - _lightPositionWorld.y, - _lightPositionWorld.z );\n\n\t\t_projScreenMatrix.multiplyMatrices( camera.projectionMatrix, camera.matrixWorldInverse );\n\t\tthis._frustum.setFromProjectionMatrix( _projScreenMatrix );\n\n\t}\n\n}\n\nPointLightShadow.prototype.isPointLightShadow = true;\n\nclass PointLight extends Light {\n\n\tconstructor( color, intensity, distance = 0, decay = 1 ) {\n\n\t\tsuper( color, intensity );\n\n\t\tthis.type = 'PointLight';\n\n\t\tthis.distance = distance;\n\t\tthis.decay = decay; // for physically correct lights, should be 2.\n\n\t\tthis.shadow = new PointLightShadow();\n\n\t}\n\n\tget power() {\n\n\t\t// compute the light's luminous power (in lumens) from its intensity (in candela)\n\t\t// for an isotropic light source, luminous power (lm) = 4  luminous intensity (cd)\n\t\treturn this.intensity * 4 * Math.PI;\n\n\t}\n\n\tset power( power ) {\n\n\t\t// set the light's intensity (in candela) from the desired luminous power (in lumens)\n\t\tthis.intensity = power / ( 4 * Math.PI );\n\n\t}\n\n\tdispose() {\n\n\t\tthis.shadow.dispose();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.distance = source.distance;\n\t\tthis.decay = source.decay;\n\n\t\tthis.shadow = source.shadow.clone();\n\n\t\treturn this;\n\n\t}\n\n}\n\nPointLight.prototype.isPointLight = true;\n\nclass DirectionalLightShadow extends LightShadow {\n\n\tconstructor() {\n\n\t\tsuper( new OrthographicCamera( - 5, 5, 5, - 5, 0.5, 500 ) );\n\n\t}\n\n}\n\nDirectionalLightShadow.prototype.isDirectionalLightShadow = true;\n\nclass DirectionalLight extends Light {\n\n\tconstructor( color, intensity ) {\n\n\t\tsuper( color, intensity );\n\n\t\tthis.type = 'DirectionalLight';\n\n\t\tthis.position.copy( Object3D.DefaultUp );\n\t\tthis.updateMatrix();\n\n\t\tthis.target = new Object3D();\n\n\t\tthis.shadow = new DirectionalLightShadow();\n\n\t}\n\n\tdispose() {\n\n\t\tthis.shadow.dispose();\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.target = source.target.clone();\n\t\tthis.shadow = source.shadow.clone();\n\n\t\treturn this;\n\n\t}\n\n}\n\nDirectionalLight.prototype.isDirectionalLight = true;\n\nclass AmbientLight extends Light {\n\n\tconstructor( color, intensity ) {\n\n\t\tsuper( color, intensity );\n\n\t\tthis.type = 'AmbientLight';\n\n\t}\n\n}\n\nAmbientLight.prototype.isAmbientLight = true;\n\nclass RectAreaLight extends Light {\n\n\tconstructor( color, intensity, width = 10, height = 10 ) {\n\n\t\tsuper( color, intensity );\n\n\t\tthis.type = 'RectAreaLight';\n\n\t\tthis.width = width;\n\t\tthis.height = height;\n\n\t}\n\n\tget power() {\n\n\t\t// compute the light's luminous power (in lumens) from its intensity (in nits)\n\t\treturn this.intensity * this.width * this.height * Math.PI;\n\n\t}\n\n\tset power( power ) {\n\n\t\t// set the light's intensity (in nits) from the desired luminous power (in lumens)\n\t\tthis.intensity = power / ( this.width * this.height * Math.PI );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.width = source.width;\n\t\tthis.height = source.height;\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tdata.object.width = this.width;\n\t\tdata.object.height = this.height;\n\n\t\treturn data;\n\n\t}\n\n}\n\nRectAreaLight.prototype.isRectAreaLight = true;\n\n/**\n * Primary reference:\n *   https://graphics.stanford.edu/papers/envmap/envmap.pdf\n *\n * Secondary reference:\n *   https://www.ppsloan.org/publications/StupidSH36.pdf\n */\n\n// 3-band SH defined by 9 coefficients\n\nclass SphericalHarmonics3 {\n\n\tconstructor() {\n\n\t\tthis.coefficients = [];\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients.push( new Vector3() );\n\n\t\t}\n\n\t}\n\n\tset( coefficients ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients[ i ].copy( coefficients[ i ] );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tzero() {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients[ i ].set( 0, 0, 0 );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// get the radiance in the direction of the normal\n\t// target is a Vector3\n\tgetAt( normal, target ) {\n\n\t\t// normal is assumed to be unit length\n\n\t\tconst x = normal.x, y = normal.y, z = normal.z;\n\n\t\tconst coeff = this.coefficients;\n\n\t\t// band 0\n\t\ttarget.copy( coeff[ 0 ] ).multiplyScalar( 0.282095 );\n\n\t\t// band 1\n\t\ttarget.addScaledVector( coeff[ 1 ], 0.488603 * y );\n\t\ttarget.addScaledVector( coeff[ 2 ], 0.488603 * z );\n\t\ttarget.addScaledVector( coeff[ 3 ], 0.488603 * x );\n\n\t\t// band 2\n\t\ttarget.addScaledVector( coeff[ 4 ], 1.092548 * ( x * y ) );\n\t\ttarget.addScaledVector( coeff[ 5 ], 1.092548 * ( y * z ) );\n\t\ttarget.addScaledVector( coeff[ 6 ], 0.315392 * ( 3.0 * z * z - 1.0 ) );\n\t\ttarget.addScaledVector( coeff[ 7 ], 1.092548 * ( x * z ) );\n\t\ttarget.addScaledVector( coeff[ 8 ], 0.546274 * ( x * x - y * y ) );\n\n\t\treturn target;\n\n\t}\n\n\t// get the irradiance (radiance convolved with cosine lobe) in the direction of the normal\n\t// target is a Vector3\n\t// https://graphics.stanford.edu/papers/envmap/envmap.pdf\n\tgetIrradianceAt( normal, target ) {\n\n\t\t// normal is assumed to be unit length\n\n\t\tconst x = normal.x, y = normal.y, z = normal.z;\n\n\t\tconst coeff = this.coefficients;\n\n\t\t// band 0\n\t\ttarget.copy( coeff[ 0 ] ).multiplyScalar( 0.886227 ); //  * 0.282095\n\n\t\t// band 1\n\t\ttarget.addScaledVector( coeff[ 1 ], 2.0 * 0.511664 * y ); // ( 2 *  / 3 ) * 0.488603\n\t\ttarget.addScaledVector( coeff[ 2 ], 2.0 * 0.511664 * z );\n\t\ttarget.addScaledVector( coeff[ 3 ], 2.0 * 0.511664 * x );\n\n\t\t// band 2\n\t\ttarget.addScaledVector( coeff[ 4 ], 2.0 * 0.429043 * x * y ); // (  / 4 ) * 1.092548\n\t\ttarget.addScaledVector( coeff[ 5 ], 2.0 * 0.429043 * y * z );\n\t\ttarget.addScaledVector( coeff[ 6 ], 0.743125 * z * z - 0.247708 ); // (  / 4 ) * 0.315392 * 3\n\t\ttarget.addScaledVector( coeff[ 7 ], 2.0 * 0.429043 * x * z );\n\t\ttarget.addScaledVector( coeff[ 8 ], 0.429043 * ( x * x - y * y ) ); // (  / 4 ) * 0.546274\n\n\t\treturn target;\n\n\t}\n\n\tadd( sh ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients[ i ].add( sh.coefficients[ i ] );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\taddScaledSH( sh, s ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients[ i ].addScaledVector( sh.coefficients[ i ], s );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tscale( s ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients[ i ].multiplyScalar( s );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tlerp( sh, alpha ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tthis.coefficients[ i ].lerp( sh.coefficients[ i ], alpha );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tequals( sh ) {\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tif ( ! this.coefficients[ i ].equals( sh.coefficients[ i ] ) ) {\n\n\t\t\t\treturn false;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn true;\n\n\t}\n\n\tcopy( sh ) {\n\n\t\treturn this.set( sh.coefficients );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tfromArray( array, offset = 0 ) {\n\n\t\tconst coefficients = this.coefficients;\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tcoefficients[ i ].fromArray( array, offset + ( i * 3 ) );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\ttoArray( array = [], offset = 0 ) {\n\n\t\tconst coefficients = this.coefficients;\n\n\t\tfor ( let i = 0; i < 9; i ++ ) {\n\n\t\t\tcoefficients[ i ].toArray( array, offset + ( i * 3 ) );\n\n\t\t}\n\n\t\treturn array;\n\n\t}\n\n\t// evaluate the basis functions\n\t// shBasis is an Array[ 9 ]\n\tstatic getBasisAt( normal, shBasis ) {\n\n\t\t// normal is assumed to be unit length\n\n\t\tconst x = normal.x, y = normal.y, z = normal.z;\n\n\t\t// band 0\n\t\tshBasis[ 0 ] = 0.282095;\n\n\t\t// band 1\n\t\tshBasis[ 1 ] = 0.488603 * y;\n\t\tshBasis[ 2 ] = 0.488603 * z;\n\t\tshBasis[ 3 ] = 0.488603 * x;\n\n\t\t// band 2\n\t\tshBasis[ 4 ] = 1.092548 * x * y;\n\t\tshBasis[ 5 ] = 1.092548 * y * z;\n\t\tshBasis[ 6 ] = 0.315392 * ( 3 * z * z - 1 );\n\t\tshBasis[ 7 ] = 1.092548 * x * z;\n\t\tshBasis[ 8 ] = 0.546274 * ( x * x - y * y );\n\n\t}\n\n}\n\nSphericalHarmonics3.prototype.isSphericalHarmonics3 = true;\n\nclass LightProbe extends Light {\n\n\tconstructor( sh = new SphericalHarmonics3(), intensity = 1 ) {\n\n\t\tsuper( undefined, intensity );\n\n\t\tthis.sh = sh;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.sh.copy( source.sh );\n\n\t\treturn this;\n\n\t}\n\n\tfromJSON( json ) {\n\n\t\tthis.intensity = json.intensity; // TODO: Move this bit to Light.fromJSON();\n\t\tthis.sh.fromArray( json.sh );\n\n\t\treturn this;\n\n\t}\n\n\ttoJSON( meta ) {\n\n\t\tconst data = super.toJSON( meta );\n\n\t\tdata.object.sh = this.sh.toArray();\n\n\t\treturn data;\n\n\t}\n\n}\n\nLightProbe.prototype.isLightProbe = true;\n\nclass MaterialLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\t\tthis.textures = {};\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst loader = new FileLoader( scope.manager );\n\t\tloader.setPath( scope.path );\n\t\tloader.setRequestHeader( scope.requestHeader );\n\t\tloader.setWithCredentials( scope.withCredentials );\n\t\tloader.load( url, function ( text ) {\n\n\t\t\ttry {\n\n\t\t\t\tonLoad( scope.parse( JSON.parse( text ) ) );\n\n\t\t\t} catch ( e ) {\n\n\t\t\t\tif ( onError ) {\n\n\t\t\t\t\tonError( e );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( e );\n\n\t\t\t\t}\n\n\t\t\t\tscope.manager.itemError( url );\n\n\t\t\t}\n\n\t\t}, onProgress, onError );\n\n\t}\n\n\tparse( json ) {\n\n\t\tconst textures = this.textures;\n\n\t\tfunction getTexture( name ) {\n\n\t\t\tif ( textures[ name ] === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.MaterialLoader: Undefined texture', name );\n\n\t\t\t}\n\n\t\t\treturn textures[ name ];\n\n\t\t}\n\n\t\tconst material = Material.fromType( json.type );\n\n\t\tif ( json.uuid !== undefined ) material.uuid = json.uuid;\n\t\tif ( json.name !== undefined ) material.name = json.name;\n\t\tif ( json.color !== undefined && material.color !== undefined ) material.color.setHex( json.color );\n\t\tif ( json.roughness !== undefined ) material.roughness = json.roughness;\n\t\tif ( json.metalness !== undefined ) material.metalness = json.metalness;\n\t\tif ( json.sheen !== undefined ) material.sheen = json.sheen;\n\t\tif ( json.sheenColor !== undefined ) material.sheenColor = new Color().setHex( json.sheenColor );\n\t\tif ( json.sheenRoughness !== undefined ) material.sheenRoughness = json.sheenRoughness;\n\t\tif ( json.emissive !== undefined && material.emissive !== undefined ) material.emissive.setHex( json.emissive );\n\t\tif ( json.specular !== undefined && material.specular !== undefined ) material.specular.setHex( json.specular );\n\t\tif ( json.specularIntensity !== undefined ) material.specularIntensity = json.specularIntensity;\n\t\tif ( json.specularColor !== undefined && material.specularColor !== undefined ) material.specularColor.setHex( json.specularColor );\n\t\tif ( json.shininess !== undefined ) material.shininess = json.shininess;\n\t\tif ( json.clearcoat !== undefined ) material.clearcoat = json.clearcoat;\n\t\tif ( json.clearcoatRoughness !== undefined ) material.clearcoatRoughness = json.clearcoatRoughness;\n\t\tif ( json.transmission !== undefined ) material.transmission = json.transmission;\n\t\tif ( json.thickness !== undefined ) material.thickness = json.thickness;\n\t\tif ( json.attenuationDistance !== undefined ) material.attenuationDistance = json.attenuationDistance;\n\t\tif ( json.attenuationColor !== undefined && material.attenuationColor !== undefined ) material.attenuationColor.setHex( json.attenuationColor );\n\t\tif ( json.fog !== undefined ) material.fog = json.fog;\n\t\tif ( json.flatShading !== undefined ) material.flatShading = json.flatShading;\n\t\tif ( json.blending !== undefined ) material.blending = json.blending;\n\t\tif ( json.combine !== undefined ) material.combine = json.combine;\n\t\tif ( json.side !== undefined ) material.side = json.side;\n\t\tif ( json.shadowSide !== undefined ) material.shadowSide = json.shadowSide;\n\t\tif ( json.opacity !== undefined ) material.opacity = json.opacity;\n\t\tif ( json.transparent !== undefined ) material.transparent = json.transparent;\n\t\tif ( json.alphaTest !== undefined ) material.alphaTest = json.alphaTest;\n\t\tif ( json.depthTest !== undefined ) material.depthTest = json.depthTest;\n\t\tif ( json.depthWrite !== undefined ) material.depthWrite = json.depthWrite;\n\t\tif ( json.colorWrite !== undefined ) material.colorWrite = json.colorWrite;\n\n\t\tif ( json.stencilWrite !== undefined ) material.stencilWrite = json.stencilWrite;\n\t\tif ( json.stencilWriteMask !== undefined ) material.stencilWriteMask = json.stencilWriteMask;\n\t\tif ( json.stencilFunc !== undefined ) material.stencilFunc = json.stencilFunc;\n\t\tif ( json.stencilRef !== undefined ) material.stencilRef = json.stencilRef;\n\t\tif ( json.stencilFuncMask !== undefined ) material.stencilFuncMask = json.stencilFuncMask;\n\t\tif ( json.stencilFail !== undefined ) material.stencilFail = json.stencilFail;\n\t\tif ( json.stencilZFail !== undefined ) material.stencilZFail = json.stencilZFail;\n\t\tif ( json.stencilZPass !== undefined ) material.stencilZPass = json.stencilZPass;\n\n\t\tif ( json.wireframe !== undefined ) material.wireframe = json.wireframe;\n\t\tif ( json.wireframeLinewidth !== undefined ) material.wireframeLinewidth = json.wireframeLinewidth;\n\t\tif ( json.wireframeLinecap !== undefined ) material.wireframeLinecap = json.wireframeLinecap;\n\t\tif ( json.wireframeLinejoin !== undefined ) material.wireframeLinejoin = json.wireframeLinejoin;\n\n\t\tif ( json.rotation !== undefined ) material.rotation = json.rotation;\n\n\t\tif ( json.linewidth !== 1 ) material.linewidth = json.linewidth;\n\t\tif ( json.dashSize !== undefined ) material.dashSize = json.dashSize;\n\t\tif ( json.gapSize !== undefined ) material.gapSize = json.gapSize;\n\t\tif ( json.scale !== undefined ) material.scale = json.scale;\n\n\t\tif ( json.polygonOffset !== undefined ) material.polygonOffset = json.polygonOffset;\n\t\tif ( json.polygonOffsetFactor !== undefined ) material.polygonOffsetFactor = json.polygonOffsetFactor;\n\t\tif ( json.polygonOffsetUnits !== undefined ) material.polygonOffsetUnits = json.polygonOffsetUnits;\n\n\t\tif ( json.dithering !== undefined ) material.dithering = json.dithering;\n\n\t\tif ( json.alphaToCoverage !== undefined ) material.alphaToCoverage = json.alphaToCoverage;\n\t\tif ( json.premultipliedAlpha !== undefined ) material.premultipliedAlpha = json.premultipliedAlpha;\n\n\t\tif ( json.visible !== undefined ) material.visible = json.visible;\n\n\t\tif ( json.toneMapped !== undefined ) material.toneMapped = json.toneMapped;\n\n\t\tif ( json.userData !== undefined ) material.userData = json.userData;\n\n\t\tif ( json.vertexColors !== undefined ) {\n\n\t\t\tif ( typeof json.vertexColors === 'number' ) {\n\n\t\t\t\tmaterial.vertexColors = ( json.vertexColors > 0 ) ? true : false;\n\n\t\t\t} else {\n\n\t\t\t\tmaterial.vertexColors = json.vertexColors;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Shader Material\n\n\t\tif ( json.uniforms !== undefined ) {\n\n\t\t\tfor ( const name in json.uniforms ) {\n\n\t\t\t\tconst uniform = json.uniforms[ name ];\n\n\t\t\t\tmaterial.uniforms[ name ] = {};\n\n\t\t\t\tswitch ( uniform.type ) {\n\n\t\t\t\t\tcase 't':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = getTexture( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'c':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = new Color().setHex( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'v2':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = new Vector2().fromArray( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'v3':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = new Vector3().fromArray( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'v4':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = new Vector4().fromArray( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'm3':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = new Matrix3().fromArray( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'm4':\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = new Matrix4().fromArray( uniform.value );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tmaterial.uniforms[ name ].value = uniform.value;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( json.defines !== undefined ) material.defines = json.defines;\n\t\tif ( json.vertexShader !== undefined ) material.vertexShader = json.vertexShader;\n\t\tif ( json.fragmentShader !== undefined ) material.fragmentShader = json.fragmentShader;\n\n\t\tif ( json.extensions !== undefined ) {\n\n\t\t\tfor ( const key in json.extensions ) {\n\n\t\t\t\tmaterial.extensions[ key ] = json.extensions[ key ];\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Deprecated\n\n\t\tif ( json.shading !== undefined ) material.flatShading = json.shading === 1; // THREE.FlatShading\n\n\t\t// for PointsMaterial\n\n\t\tif ( json.size !== undefined ) material.size = json.size;\n\t\tif ( json.sizeAttenuation !== undefined ) material.sizeAttenuation = json.sizeAttenuation;\n\n\t\t// maps\n\n\t\tif ( json.map !== undefined ) material.map = getTexture( json.map );\n\t\tif ( json.matcap !== undefined ) material.matcap = getTexture( json.matcap );\n\n\t\tif ( json.alphaMap !== undefined ) material.alphaMap = getTexture( json.alphaMap );\n\n\t\tif ( json.bumpMap !== undefined ) material.bumpMap = getTexture( json.bumpMap );\n\t\tif ( json.bumpScale !== undefined ) material.bumpScale = json.bumpScale;\n\n\t\tif ( json.normalMap !== undefined ) material.normalMap = getTexture( json.normalMap );\n\t\tif ( json.normalMapType !== undefined ) material.normalMapType = json.normalMapType;\n\t\tif ( json.normalScale !== undefined ) {\n\n\t\t\tlet normalScale = json.normalScale;\n\n\t\t\tif ( Array.isArray( normalScale ) === false ) {\n\n\t\t\t\t// Blender exporter used to export a scalar. See #7459\n\n\t\t\t\tnormalScale = [ normalScale, normalScale ];\n\n\t\t\t}\n\n\t\t\tmaterial.normalScale = new Vector2().fromArray( normalScale );\n\n\t\t}\n\n\t\tif ( json.displacementMap !== undefined ) material.displacementMap = getTexture( json.displacementMap );\n\t\tif ( json.displacementScale !== undefined ) material.displacementScale = json.displacementScale;\n\t\tif ( json.displacementBias !== undefined ) material.displacementBias = json.displacementBias;\n\n\t\tif ( json.roughnessMap !== undefined ) material.roughnessMap = getTexture( json.roughnessMap );\n\t\tif ( json.metalnessMap !== undefined ) material.metalnessMap = getTexture( json.metalnessMap );\n\n\t\tif ( json.emissiveMap !== undefined ) material.emissiveMap = getTexture( json.emissiveMap );\n\t\tif ( json.emissiveIntensity !== undefined ) material.emissiveIntensity = json.emissiveIntensity;\n\n\t\tif ( json.specularMap !== undefined ) material.specularMap = getTexture( json.specularMap );\n\t\tif ( json.specularIntensityMap !== undefined ) material.specularIntensityMap = getTexture( json.specularIntensityMap );\n\t\tif ( json.specularColorMap !== undefined ) material.specularColorMap = getTexture( json.specularColorMap );\n\n\t\tif ( json.envMap !== undefined ) material.envMap = getTexture( json.envMap );\n\t\tif ( json.envMapIntensity !== undefined ) material.envMapIntensity = json.envMapIntensity;\n\n\t\tif ( json.reflectivity !== undefined ) material.reflectivity = json.reflectivity;\n\t\tif ( json.refractionRatio !== undefined ) material.refractionRatio = json.refractionRatio;\n\n\t\tif ( json.lightMap !== undefined ) material.lightMap = getTexture( json.lightMap );\n\t\tif ( json.lightMapIntensity !== undefined ) material.lightMapIntensity = json.lightMapIntensity;\n\n\t\tif ( json.aoMap !== undefined ) material.aoMap = getTexture( json.aoMap );\n\t\tif ( json.aoMapIntensity !== undefined ) material.aoMapIntensity = json.aoMapIntensity;\n\n\t\tif ( json.gradientMap !== undefined ) material.gradientMap = getTexture( json.gradientMap );\n\n\t\tif ( json.clearcoatMap !== undefined ) material.clearcoatMap = getTexture( json.clearcoatMap );\n\t\tif ( json.clearcoatRoughnessMap !== undefined ) material.clearcoatRoughnessMap = getTexture( json.clearcoatRoughnessMap );\n\t\tif ( json.clearcoatNormalMap !== undefined ) material.clearcoatNormalMap = getTexture( json.clearcoatNormalMap );\n\t\tif ( json.clearcoatNormalScale !== undefined ) material.clearcoatNormalScale = new Vector2().fromArray( json.clearcoatNormalScale );\n\n\t\tif ( json.transmissionMap !== undefined ) material.transmissionMap = getTexture( json.transmissionMap );\n\t\tif ( json.thicknessMap !== undefined ) material.thicknessMap = getTexture( json.thicknessMap );\n\n\t\tif ( json.sheenColorMap !== undefined ) material.sheenColorMap = getTexture( json.sheenColorMap );\n\t\tif ( json.sheenRoughnessMap !== undefined ) material.sheenRoughnessMap = getTexture( json.sheenRoughnessMap );\n\n\t\treturn material;\n\n\t}\n\n\tsetTextures( value ) {\n\n\t\tthis.textures = value;\n\t\treturn this;\n\n\t}\n\n}\n\nclass LoaderUtils {\n\n\tstatic decodeText( array ) {\n\n\t\tif ( typeof TextDecoder !== 'undefined' ) {\n\n\t\t\treturn new TextDecoder().decode( array );\n\n\t\t}\n\n\t\t// Avoid the String.fromCharCode.apply(null, array) shortcut, which\n\t\t// throws a \"maximum call stack size exceeded\" error for large arrays.\n\n\t\tlet s = '';\n\n\t\tfor ( let i = 0, il = array.length; i < il; i ++ ) {\n\n\t\t\t// Implicitly assumes little-endian.\n\t\t\ts += String.fromCharCode( array[ i ] );\n\n\t\t}\n\n\t\ttry {\n\n\t\t\t// merges multi-byte utf-8 characters.\n\n\t\t\treturn decodeURIComponent( escape( s ) );\n\n\t\t} catch ( e ) { // see #16358\n\n\t\t\treturn s;\n\n\t\t}\n\n\t}\n\n\tstatic extractUrlBase( url ) {\n\n\t\tconst index = url.lastIndexOf( '/' );\n\n\t\tif ( index === - 1 ) return './';\n\n\t\treturn url.slice( 0, index + 1 );\n\n\t}\n\n\tstatic resolveURL( url, path ) {\n\n\t\t// Invalid URL\n\t\tif ( typeof url !== 'string' || url === '' ) return '';\n\n\t\t// Host Relative URL\n\t\tif ( /^https?:\\/\\//i.test( path ) && /^\\//.test( url ) ) {\n\n\t\t\tpath = path.replace( /(^https?:\\/\\/[^\\/]+).*/i, '$1' );\n\n\t\t}\n\n\t\t// Absolute URL http://,https://,//\n\t\tif ( /^(https?:)?\\/\\//i.test( url ) ) return url;\n\n\t\t// Data URI\n\t\tif ( /^data:.*,.*$/i.test( url ) ) return url;\n\n\t\t// Blob URL\n\t\tif ( /^blob:.*$/i.test( url ) ) return url;\n\n\t\t// Relative URL\n\t\treturn path + url;\n\n\t}\n\n}\n\nclass InstancedBufferGeometry extends BufferGeometry {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'InstancedBufferGeometry';\n\t\tthis.instanceCount = Infinity;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.instanceCount = source.instanceCount;\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\ttoJSON() {\n\n\t\tconst data = super.toJSON( this );\n\n\t\tdata.instanceCount = this.instanceCount;\n\n\t\tdata.isInstancedBufferGeometry = true;\n\n\t\treturn data;\n\n\t}\n\n}\n\nInstancedBufferGeometry.prototype.isInstancedBufferGeometry = true;\n\nclass BufferGeometryLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst loader = new FileLoader( scope.manager );\n\t\tloader.setPath( scope.path );\n\t\tloader.setRequestHeader( scope.requestHeader );\n\t\tloader.setWithCredentials( scope.withCredentials );\n\t\tloader.load( url, function ( text ) {\n\n\t\t\ttry {\n\n\t\t\t\tonLoad( scope.parse( JSON.parse( text ) ) );\n\n\t\t\t} catch ( e ) {\n\n\t\t\t\tif ( onError ) {\n\n\t\t\t\t\tonError( e );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( e );\n\n\t\t\t\t}\n\n\t\t\t\tscope.manager.itemError( url );\n\n\t\t\t}\n\n\t\t}, onProgress, onError );\n\n\t}\n\n\tparse( json ) {\n\n\t\tconst interleavedBufferMap = {};\n\t\tconst arrayBufferMap = {};\n\n\t\tfunction getInterleavedBuffer( json, uuid ) {\n\n\t\t\tif ( interleavedBufferMap[ uuid ] !== undefined ) return interleavedBufferMap[ uuid ];\n\n\t\t\tconst interleavedBuffers = json.interleavedBuffers;\n\t\t\tconst interleavedBuffer = interleavedBuffers[ uuid ];\n\n\t\t\tconst buffer = getArrayBuffer( json, interleavedBuffer.buffer );\n\n\t\t\tconst array = getTypedArray( interleavedBuffer.type, buffer );\n\t\t\tconst ib = new InterleavedBuffer( array, interleavedBuffer.stride );\n\t\t\tib.uuid = interleavedBuffer.uuid;\n\n\t\t\tinterleavedBufferMap[ uuid ] = ib;\n\n\t\t\treturn ib;\n\n\t\t}\n\n\t\tfunction getArrayBuffer( json, uuid ) {\n\n\t\t\tif ( arrayBufferMap[ uuid ] !== undefined ) return arrayBufferMap[ uuid ];\n\n\t\t\tconst arrayBuffers = json.arrayBuffers;\n\t\t\tconst arrayBuffer = arrayBuffers[ uuid ];\n\n\t\t\tconst ab = new Uint32Array( arrayBuffer ).buffer;\n\n\t\t\tarrayBufferMap[ uuid ] = ab;\n\n\t\t\treturn ab;\n\n\t\t}\n\n\t\tconst geometry = json.isInstancedBufferGeometry ? new InstancedBufferGeometry() : new BufferGeometry();\n\n\t\tconst index = json.data.index;\n\n\t\tif ( index !== undefined ) {\n\n\t\t\tconst typedArray = getTypedArray( index.type, index.array );\n\t\t\tgeometry.setIndex( new BufferAttribute( typedArray, 1 ) );\n\n\t\t}\n\n\t\tconst attributes = json.data.attributes;\n\n\t\tfor ( const key in attributes ) {\n\n\t\t\tconst attribute = attributes[ key ];\n\t\t\tlet bufferAttribute;\n\n\t\t\tif ( attribute.isInterleavedBufferAttribute ) {\n\n\t\t\t\tconst interleavedBuffer = getInterleavedBuffer( json.data, attribute.data );\n\t\t\t\tbufferAttribute = new InterleavedBufferAttribute( interleavedBuffer, attribute.itemSize, attribute.offset, attribute.normalized );\n\n\t\t\t} else {\n\n\t\t\t\tconst typedArray = getTypedArray( attribute.type, attribute.array );\n\t\t\t\tconst bufferAttributeConstr = attribute.isInstancedBufferAttribute ? InstancedBufferAttribute : BufferAttribute;\n\t\t\t\tbufferAttribute = new bufferAttributeConstr( typedArray, attribute.itemSize, attribute.normalized );\n\n\t\t\t}\n\n\t\t\tif ( attribute.name !== undefined ) bufferAttribute.name = attribute.name;\n\t\t\tif ( attribute.usage !== undefined ) bufferAttribute.setUsage( attribute.usage );\n\n\t\t\tif ( attribute.updateRange !== undefined ) {\n\n\t\t\t\tbufferAttribute.updateRange.offset = attribute.updateRange.offset;\n\t\t\t\tbufferAttribute.updateRange.count = attribute.updateRange.count;\n\n\t\t\t}\n\n\t\t\tgeometry.setAttribute( key, bufferAttribute );\n\n\t\t}\n\n\t\tconst morphAttributes = json.data.morphAttributes;\n\n\t\tif ( morphAttributes ) {\n\n\t\t\tfor ( const key in morphAttributes ) {\n\n\t\t\t\tconst attributeArray = morphAttributes[ key ];\n\n\t\t\t\tconst array = [];\n\n\t\t\t\tfor ( let i = 0, il = attributeArray.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst attribute = attributeArray[ i ];\n\t\t\t\t\tlet bufferAttribute;\n\n\t\t\t\t\tif ( attribute.isInterleavedBufferAttribute ) {\n\n\t\t\t\t\t\tconst interleavedBuffer = getInterleavedBuffer( json.data, attribute.data );\n\t\t\t\t\t\tbufferAttribute = new InterleavedBufferAttribute( interleavedBuffer, attribute.itemSize, attribute.offset, attribute.normalized );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tconst typedArray = getTypedArray( attribute.type, attribute.array );\n\t\t\t\t\t\tbufferAttribute = new BufferAttribute( typedArray, attribute.itemSize, attribute.normalized );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( attribute.name !== undefined ) bufferAttribute.name = attribute.name;\n\t\t\t\t\tarray.push( bufferAttribute );\n\n\t\t\t\t}\n\n\t\t\t\tgeometry.morphAttributes[ key ] = array;\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst morphTargetsRelative = json.data.morphTargetsRelative;\n\n\t\tif ( morphTargetsRelative ) {\n\n\t\t\tgeometry.morphTargetsRelative = true;\n\n\t\t}\n\n\t\tconst groups = json.data.groups || json.data.drawcalls || json.data.offsets;\n\n\t\tif ( groups !== undefined ) {\n\n\t\t\tfor ( let i = 0, n = groups.length; i !== n; ++ i ) {\n\n\t\t\t\tconst group = groups[ i ];\n\n\t\t\t\tgeometry.addGroup( group.start, group.count, group.materialIndex );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst boundingSphere = json.data.boundingSphere;\n\n\t\tif ( boundingSphere !== undefined ) {\n\n\t\t\tconst center = new Vector3();\n\n\t\t\tif ( boundingSphere.center !== undefined ) {\n\n\t\t\t\tcenter.fromArray( boundingSphere.center );\n\n\t\t\t}\n\n\t\t\tgeometry.boundingSphere = new Sphere( center, boundingSphere.radius );\n\n\t\t}\n\n\t\tif ( json.name ) geometry.name = json.name;\n\t\tif ( json.userData ) geometry.userData = json.userData;\n\n\t\treturn geometry;\n\n\t}\n\n}\n\nclass ObjectLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst path = ( this.path === '' ) ? LoaderUtils.extractUrlBase( url ) : this.path;\n\t\tthis.resourcePath = this.resourcePath || path;\n\n\t\tconst loader = new FileLoader( this.manager );\n\t\tloader.setPath( this.path );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setWithCredentials( this.withCredentials );\n\t\tloader.load( url, function ( text ) {\n\n\t\t\tlet json = null;\n\n\t\t\ttry {\n\n\t\t\t\tjson = JSON.parse( text );\n\n\t\t\t} catch ( error ) {\n\n\t\t\t\tif ( onError !== undefined ) onError( error );\n\n\t\t\t\tconsole.error( 'THREE:ObjectLoader: Can\\'t parse ' + url + '.', error.message );\n\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t\tconst metadata = json.metadata;\n\n\t\t\tif ( metadata === undefined || metadata.type === undefined || metadata.type.toLowerCase() === 'geometry' ) {\n\n\t\t\t\tconsole.error( 'THREE.ObjectLoader: Can\\'t load ' + url );\n\t\t\t\treturn;\n\n\t\t\t}\n\n\t\t\tscope.parse( json, onLoad );\n\n\t\t}, onProgress, onError );\n\n\t}\n\n\tasync loadAsync( url, onProgress ) {\n\n\t\tconst scope = this;\n\n\t\tconst path = ( this.path === '' ) ? LoaderUtils.extractUrlBase( url ) : this.path;\n\t\tthis.resourcePath = this.resourcePath || path;\n\n\t\tconst loader = new FileLoader( this.manager );\n\t\tloader.setPath( this.path );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setWithCredentials( this.withCredentials );\n\n\t\tconst text = await loader.loadAsync( url, onProgress );\n\n\t\tconst json = JSON.parse( text );\n\n\t\tconst metadata = json.metadata;\n\n\t\tif ( metadata === undefined || metadata.type === undefined || metadata.type.toLowerCase() === 'geometry' ) {\n\n\t\t\tthrow new Error( 'THREE.ObjectLoader: Can\\'t load ' + url );\n\n\t\t}\n\n\t\treturn await scope.parseAsync( json );\n\n\t}\n\n\tparse( json, onLoad ) {\n\n\t\tconst animations = this.parseAnimations( json.animations );\n\t\tconst shapes = this.parseShapes( json.shapes );\n\t\tconst geometries = this.parseGeometries( json.geometries, shapes );\n\n\t\tconst images = this.parseImages( json.images, function () {\n\n\t\t\tif ( onLoad !== undefined ) onLoad( object );\n\n\t\t} );\n\n\t\tconst textures = this.parseTextures( json.textures, images );\n\t\tconst materials = this.parseMaterials( json.materials, textures );\n\n\t\tconst object = this.parseObject( json.object, geometries, materials, textures, animations );\n\t\tconst skeletons = this.parseSkeletons( json.skeletons, object );\n\n\t\tthis.bindSkeletons( object, skeletons );\n\n\t\t//\n\n\t\tif ( onLoad !== undefined ) {\n\n\t\t\tlet hasImages = false;\n\n\t\t\tfor ( const uuid in images ) {\n\n\t\t\t\tif ( images[ uuid ] instanceof HTMLImageElement ) {\n\n\t\t\t\t\thasImages = true;\n\t\t\t\t\tbreak;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( hasImages === false ) onLoad( object );\n\n\t\t}\n\n\t\treturn object;\n\n\t}\n\n\tasync parseAsync( json ) {\n\n\t\tconst animations = this.parseAnimations( json.animations );\n\t\tconst shapes = this.parseShapes( json.shapes );\n\t\tconst geometries = this.parseGeometries( json.geometries, shapes );\n\n\t\tconst images = await this.parseImagesAsync( json.images );\n\n\t\tconst textures = this.parseTextures( json.textures, images );\n\t\tconst materials = this.parseMaterials( json.materials, textures );\n\n\t\tconst object = this.parseObject( json.object, geometries, materials, textures, animations );\n\t\tconst skeletons = this.parseSkeletons( json.skeletons, object );\n\n\t\tthis.bindSkeletons( object, skeletons );\n\n\t\treturn object;\n\n\t}\n\n\tparseShapes( json ) {\n\n\t\tconst shapes = {};\n\n\t\tif ( json !== undefined ) {\n\n\t\t\tfor ( let i = 0, l = json.length; i < l; i ++ ) {\n\n\t\t\t\tconst shape = new Shape().fromJSON( json[ i ] );\n\n\t\t\t\tshapes[ shape.uuid ] = shape;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn shapes;\n\n\t}\n\n\tparseSkeletons( json, object ) {\n\n\t\tconst skeletons = {};\n\t\tconst bones = {};\n\n\t\t// generate bone lookup table\n\n\t\tobject.traverse( function ( child ) {\n\n\t\t\tif ( child.isBone ) bones[ child.uuid ] = child;\n\n\t\t} );\n\n\t\t// create skeletons\n\n\t\tif ( json !== undefined ) {\n\n\t\t\tfor ( let i = 0, l = json.length; i < l; i ++ ) {\n\n\t\t\t\tconst skeleton = new Skeleton().fromJSON( json[ i ], bones );\n\n\t\t\t\tskeletons[ skeleton.uuid ] = skeleton;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn skeletons;\n\n\t}\n\n\tparseGeometries( json, shapes ) {\n\n\t\tconst geometries = {};\n\n\t\tif ( json !== undefined ) {\n\n\t\t\tconst bufferGeometryLoader = new BufferGeometryLoader();\n\n\t\t\tfor ( let i = 0, l = json.length; i < l; i ++ ) {\n\n\t\t\t\tlet geometry;\n\t\t\t\tconst data = json[ i ];\n\n\t\t\t\tswitch ( data.type ) {\n\n\t\t\t\t\tcase 'BufferGeometry':\n\t\t\t\t\tcase 'InstancedBufferGeometry':\n\n\t\t\t\t\t\tgeometry = bufferGeometryLoader.parse( data );\n\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase 'Geometry':\n\n\t\t\t\t\t\tconsole.error( 'THREE.ObjectLoader: The legacy Geometry type is no longer supported.' );\n\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tdefault:\n\n\t\t\t\t\t\tif ( data.type in Geometries ) {\n\n\t\t\t\t\t\t\tgeometry = Geometries[ data.type ].fromJSON( data, shapes );\n\n\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\tconsole.warn( `THREE.ObjectLoader: Unsupported geometry type \"${ data.type }\"` );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tgeometry.uuid = data.uuid;\n\n\t\t\t\tif ( data.name !== undefined ) geometry.name = data.name;\n\t\t\t\tif ( geometry.isBufferGeometry === true && data.userData !== undefined ) geometry.userData = data.userData;\n\n\t\t\t\tgeometries[ data.uuid ] = geometry;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn geometries;\n\n\t}\n\n\tparseMaterials( json, textures ) {\n\n\t\tconst cache = {}; // MultiMaterial\n\t\tconst materials = {};\n\n\t\tif ( json !== undefined ) {\n\n\t\t\tconst loader = new MaterialLoader();\n\t\t\tloader.setTextures( textures );\n\n\t\t\tfor ( let i = 0, l = json.length; i < l; i ++ ) {\n\n\t\t\t\tconst data = json[ i ];\n\n\t\t\t\tif ( data.type === 'MultiMaterial' ) {\n\n\t\t\t\t\t// Deprecated\n\n\t\t\t\t\tconst array = [];\n\n\t\t\t\t\tfor ( let j = 0; j < data.materials.length; j ++ ) {\n\n\t\t\t\t\t\tconst material = data.materials[ j ];\n\n\t\t\t\t\t\tif ( cache[ material.uuid ] === undefined ) {\n\n\t\t\t\t\t\t\tcache[ material.uuid ] = loader.parse( material );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tarray.push( cache[ material.uuid ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tmaterials[ data.uuid ] = array;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( cache[ data.uuid ] === undefined ) {\n\n\t\t\t\t\t\tcache[ data.uuid ] = loader.parse( data );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tmaterials[ data.uuid ] = cache[ data.uuid ];\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn materials;\n\n\t}\n\n\tparseAnimations( json ) {\n\n\t\tconst animations = {};\n\n\t\tif ( json !== undefined ) {\n\n\t\t\tfor ( let i = 0; i < json.length; i ++ ) {\n\n\t\t\t\tconst data = json[ i ];\n\n\t\t\t\tconst clip = AnimationClip.parse( data );\n\n\t\t\t\tanimations[ clip.uuid ] = clip;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn animations;\n\n\t}\n\n\tparseImages( json, onLoad ) {\n\n\t\tconst scope = this;\n\t\tconst images = {};\n\n\t\tlet loader;\n\n\t\tfunction loadImage( url ) {\n\n\t\t\tscope.manager.itemStart( url );\n\n\t\t\treturn loader.load( url, function () {\n\n\t\t\t\tscope.manager.itemEnd( url );\n\n\t\t\t}, undefined, function () {\n\n\t\t\t\tscope.manager.itemError( url );\n\t\t\t\tscope.manager.itemEnd( url );\n\n\t\t\t} );\n\n\t\t}\n\n\t\tfunction deserializeImage( image ) {\n\n\t\t\tif ( typeof image === 'string' ) {\n\n\t\t\t\tconst url = image;\n\n\t\t\t\tconst path = /^(\\/\\/)|([a-z]+:(\\/\\/)?)/i.test( url ) ? url : scope.resourcePath + url;\n\n\t\t\t\treturn loadImage( path );\n\n\t\t\t} else {\n\n\t\t\t\tif ( image.data ) {\n\n\t\t\t\t\treturn {\n\t\t\t\t\t\tdata: getTypedArray( image.type, image.data ),\n\t\t\t\t\t\twidth: image.width,\n\t\t\t\t\t\theight: image.height\n\t\t\t\t\t};\n\n\t\t\t\t} else {\n\n\t\t\t\t\treturn null;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( json !== undefined && json.length > 0 ) {\n\n\t\t\tconst manager = new LoadingManager( onLoad );\n\n\t\t\tloader = new ImageLoader( manager );\n\t\t\tloader.setCrossOrigin( this.crossOrigin );\n\n\t\t\tfor ( let i = 0, il = json.length; i < il; i ++ ) {\n\n\t\t\t\tconst image = json[ i ];\n\t\t\t\tconst url = image.url;\n\n\t\t\t\tif ( Array.isArray( url ) ) {\n\n\t\t\t\t\t// load array of images e.g CubeTexture\n\n\t\t\t\t\tconst imageArray = [];\n\n\t\t\t\t\tfor ( let j = 0, jl = url.length; j < jl; j ++ ) {\n\n\t\t\t\t\t\tconst currentUrl = url[ j ];\n\n\t\t\t\t\t\tconst deserializedImage = deserializeImage( currentUrl );\n\n\t\t\t\t\t\tif ( deserializedImage !== null ) {\n\n\t\t\t\t\t\t\tif ( deserializedImage instanceof HTMLImageElement ) {\n\n\t\t\t\t\t\t\t\timageArray.push( deserializedImage );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\t// special case: handle array of data textures for cube textures\n\n\t\t\t\t\t\t\t\timageArray.push( new DataTexture( deserializedImage.data, deserializedImage.width, deserializedImage.height ) );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\timages[ image.uuid ] = new Source( imageArray );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// load single image\n\n\t\t\t\t\tconst deserializedImage = deserializeImage( image.url );\n\t\t\t\t\timages[ image.uuid ] = new Source( deserializedImage );\n\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn images;\n\n\t}\n\n\tasync parseImagesAsync( json ) {\n\n\t\tconst scope = this;\n\t\tconst images = {};\n\n\t\tlet loader;\n\n\t\tasync function deserializeImage( image ) {\n\n\t\t\tif ( typeof image === 'string' ) {\n\n\t\t\t\tconst url = image;\n\n\t\t\t\tconst path = /^(\\/\\/)|([a-z]+:(\\/\\/)?)/i.test( url ) ? url : scope.resourcePath + url;\n\n\t\t\t\treturn await loader.loadAsync( path );\n\n\t\t\t} else {\n\n\t\t\t\tif ( image.data ) {\n\n\t\t\t\t\treturn {\n\t\t\t\t\t\tdata: getTypedArray( image.type, image.data ),\n\t\t\t\t\t\twidth: image.width,\n\t\t\t\t\t\theight: image.height\n\t\t\t\t\t};\n\n\t\t\t\t} else {\n\n\t\t\t\t\treturn null;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( json !== undefined && json.length > 0 ) {\n\n\t\t\tloader = new ImageLoader( this.manager );\n\t\t\tloader.setCrossOrigin( this.crossOrigin );\n\n\t\t\tfor ( let i = 0, il = json.length; i < il; i ++ ) {\n\n\t\t\t\tconst image = json[ i ];\n\t\t\t\tconst url = image.url;\n\n\t\t\t\tif ( Array.isArray( url ) ) {\n\n\t\t\t\t\t// load array of images e.g CubeTexture\n\n\t\t\t\t\tconst imageArray = [];\n\n\t\t\t\t\tfor ( let j = 0, jl = url.length; j < jl; j ++ ) {\n\n\t\t\t\t\t\tconst currentUrl = url[ j ];\n\n\t\t\t\t\t\tconst deserializedImage = await deserializeImage( currentUrl );\n\n\t\t\t\t\t\tif ( deserializedImage !== null ) {\n\n\t\t\t\t\t\t\tif ( deserializedImage instanceof HTMLImageElement ) {\n\n\t\t\t\t\t\t\t\timageArray.push( deserializedImage );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\t// special case: handle array of data textures for cube textures\n\n\t\t\t\t\t\t\t\timageArray.push( new DataTexture( deserializedImage.data, deserializedImage.width, deserializedImage.height ) );\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\timages[ image.uuid ] = new Source( imageArray );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// load single image\n\n\t\t\t\t\tconst deserializedImage = await deserializeImage( image.url );\n\t\t\t\t\timages[ image.uuid ] = new Source( deserializedImage );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn images;\n\n\t}\n\n\tparseTextures( json, images ) {\n\n\t\tfunction parseConstant( value, type ) {\n\n\t\t\tif ( typeof value === 'number' ) return value;\n\n\t\t\tconsole.warn( 'THREE.ObjectLoader.parseTexture: Constant should be in numeric form.', value );\n\n\t\t\treturn type[ value ];\n\n\t\t}\n\n\t\tconst textures = {};\n\n\t\tif ( json !== undefined ) {\n\n\t\t\tfor ( let i = 0, l = json.length; i < l; i ++ ) {\n\n\t\t\t\tconst data = json[ i ];\n\n\t\t\t\tif ( data.image === undefined ) {\n\n\t\t\t\t\tconsole.warn( 'THREE.ObjectLoader: No \"image\" specified for', data.uuid );\n\n\t\t\t\t}\n\n\t\t\t\tif ( images[ data.image ] === undefined ) {\n\n\t\t\t\t\tconsole.warn( 'THREE.ObjectLoader: Undefined image', data.image );\n\n\t\t\t\t}\n\n\t\t\t\tconst source = images[ data.image ];\n\t\t\t\tconst image = source.data;\n\n\t\t\t\tlet texture;\n\n\t\t\t\tif ( Array.isArray( image ) ) {\n\n\t\t\t\t\ttexture = new CubeTexture();\n\n\t\t\t\t\tif ( image.length === 6 ) texture.needsUpdate = true;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tif ( image && image.data ) {\n\n\t\t\t\t\t\ttexture = new DataTexture();\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\ttexture = new Texture();\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( image ) texture.needsUpdate = true; // textures can have undefined image data\n\n\t\t\t\t}\n\n\t\t\t\ttexture.source = source;\n\n\t\t\t\ttexture.uuid = data.uuid;\n\n\t\t\t\tif ( data.name !== undefined ) texture.name = data.name;\n\n\t\t\t\tif ( data.mapping !== undefined ) texture.mapping = parseConstant( data.mapping, TEXTURE_MAPPING );\n\n\t\t\t\tif ( data.offset !== undefined ) texture.offset.fromArray( data.offset );\n\t\t\t\tif ( data.repeat !== undefined ) texture.repeat.fromArray( data.repeat );\n\t\t\t\tif ( data.center !== undefined ) texture.center.fromArray( data.center );\n\t\t\t\tif ( data.rotation !== undefined ) texture.rotation = data.rotation;\n\n\t\t\t\tif ( data.wrap !== undefined ) {\n\n\t\t\t\t\ttexture.wrapS = parseConstant( data.wrap[ 0 ], TEXTURE_WRAPPING );\n\t\t\t\t\ttexture.wrapT = parseConstant( data.wrap[ 1 ], TEXTURE_WRAPPING );\n\n\t\t\t\t}\n\n\t\t\t\tif ( data.format !== undefined ) texture.format = data.format;\n\t\t\t\tif ( data.type !== undefined ) texture.type = data.type;\n\t\t\t\tif ( data.encoding !== undefined ) texture.encoding = data.encoding;\n\n\t\t\t\tif ( data.minFilter !== undefined ) texture.minFilter = parseConstant( data.minFilter, TEXTURE_FILTER );\n\t\t\t\tif ( data.magFilter !== undefined ) texture.magFilter = parseConstant( data.magFilter, TEXTURE_FILTER );\n\t\t\t\tif ( data.anisotropy !== undefined ) texture.anisotropy = data.anisotropy;\n\n\t\t\t\tif ( data.flipY !== undefined ) texture.flipY = data.flipY;\n\n\t\t\t\tif ( data.premultiplyAlpha !== undefined ) texture.premultiplyAlpha = data.premultiplyAlpha;\n\t\t\t\tif ( data.unpackAlignment !== undefined ) texture.unpackAlignment = data.unpackAlignment;\n\n\t\t\t\tif ( data.userData !== undefined ) texture.userData = data.userData;\n\n\t\t\t\ttextures[ data.uuid ] = texture;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn textures;\n\n\t}\n\n\tparseObject( data, geometries, materials, textures, animations ) {\n\n\t\tlet object;\n\n\t\tfunction getGeometry( name ) {\n\n\t\t\tif ( geometries[ name ] === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.ObjectLoader: Undefined geometry', name );\n\n\t\t\t}\n\n\t\t\treturn geometries[ name ];\n\n\t\t}\n\n\t\tfunction getMaterial( name ) {\n\n\t\t\tif ( name === undefined ) return undefined;\n\n\t\t\tif ( Array.isArray( name ) ) {\n\n\t\t\t\tconst array = [];\n\n\t\t\t\tfor ( let i = 0, l = name.length; i < l; i ++ ) {\n\n\t\t\t\t\tconst uuid = name[ i ];\n\n\t\t\t\t\tif ( materials[ uuid ] === undefined ) {\n\n\t\t\t\t\t\tconsole.warn( 'THREE.ObjectLoader: Undefined material', uuid );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tarray.push( materials[ uuid ] );\n\n\t\t\t\t}\n\n\t\t\t\treturn array;\n\n\t\t\t}\n\n\t\t\tif ( materials[ name ] === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.ObjectLoader: Undefined material', name );\n\n\t\t\t}\n\n\t\t\treturn materials[ name ];\n\n\t\t}\n\n\t\tfunction getTexture( uuid ) {\n\n\t\t\tif ( textures[ uuid ] === undefined ) {\n\n\t\t\t\tconsole.warn( 'THREE.ObjectLoader: Undefined texture', uuid );\n\n\t\t\t}\n\n\t\t\treturn textures[ uuid ];\n\n\t\t}\n\n\t\tlet geometry, material;\n\n\t\tswitch ( data.type ) {\n\n\t\t\tcase 'Scene':\n\n\t\t\t\tobject = new Scene();\n\n\t\t\t\tif ( data.background !== undefined ) {\n\n\t\t\t\t\tif ( Number.isInteger( data.background ) ) {\n\n\t\t\t\t\t\tobject.background = new Color( data.background );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tobject.background = getTexture( data.background );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tif ( data.environment !== undefined ) {\n\n\t\t\t\t\tobject.environment = getTexture( data.environment );\n\n\t\t\t\t}\n\n\t\t\t\tif ( data.fog !== undefined ) {\n\n\t\t\t\t\tif ( data.fog.type === 'Fog' ) {\n\n\t\t\t\t\t\tobject.fog = new Fog( data.fog.color, data.fog.near, data.fog.far );\n\n\t\t\t\t\t} else if ( data.fog.type === 'FogExp2' ) {\n\n\t\t\t\t\t\tobject.fog = new FogExp2( data.fog.color, data.fog.density );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'PerspectiveCamera':\n\n\t\t\t\tobject = new PerspectiveCamera( data.fov, data.aspect, data.near, data.far );\n\n\t\t\t\tif ( data.focus !== undefined ) object.focus = data.focus;\n\t\t\t\tif ( data.zoom !== undefined ) object.zoom = data.zoom;\n\t\t\t\tif ( data.filmGauge !== undefined ) object.filmGauge = data.filmGauge;\n\t\t\t\tif ( data.filmOffset !== undefined ) object.filmOffset = data.filmOffset;\n\t\t\t\tif ( data.view !== undefined ) object.view = Object.assign( {}, data.view );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'OrthographicCamera':\n\n\t\t\t\tobject = new OrthographicCamera( data.left, data.right, data.top, data.bottom, data.near, data.far );\n\n\t\t\t\tif ( data.zoom !== undefined ) object.zoom = data.zoom;\n\t\t\t\tif ( data.view !== undefined ) object.view = Object.assign( {}, data.view );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'AmbientLight':\n\n\t\t\t\tobject = new AmbientLight( data.color, data.intensity );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'DirectionalLight':\n\n\t\t\t\tobject = new DirectionalLight( data.color, data.intensity );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'PointLight':\n\n\t\t\t\tobject = new PointLight( data.color, data.intensity, data.distance, data.decay );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'RectAreaLight':\n\n\t\t\t\tobject = new RectAreaLight( data.color, data.intensity, data.width, data.height );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'SpotLight':\n\n\t\t\t\tobject = new SpotLight( data.color, data.intensity, data.distance, data.angle, data.penumbra, data.decay );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'HemisphereLight':\n\n\t\t\t\tobject = new HemisphereLight( data.color, data.groundColor, data.intensity );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'LightProbe':\n\n\t\t\t\tobject = new LightProbe().fromJSON( data );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'SkinnedMesh':\n\n\t\t\t\tgeometry = getGeometry( data.geometry );\n\t\t\t \tmaterial = getMaterial( data.material );\n\n\t\t\t\tobject = new SkinnedMesh( geometry, material );\n\n\t\t\t\tif ( data.bindMode !== undefined ) object.bindMode = data.bindMode;\n\t\t\t\tif ( data.bindMatrix !== undefined ) object.bindMatrix.fromArray( data.bindMatrix );\n\t\t\t\tif ( data.skeleton !== undefined ) object.skeleton = data.skeleton;\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'Mesh':\n\n\t\t\t\tgeometry = getGeometry( data.geometry );\n\t\t\t\tmaterial = getMaterial( data.material );\n\n\t\t\t\tobject = new Mesh( geometry, material );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'InstancedMesh':\n\n\t\t\t\tgeometry = getGeometry( data.geometry );\n\t\t\t\tmaterial = getMaterial( data.material );\n\t\t\t\tconst count = data.count;\n\t\t\t\tconst instanceMatrix = data.instanceMatrix;\n\t\t\t\tconst instanceColor = data.instanceColor;\n\n\t\t\t\tobject = new InstancedMesh( geometry, material, count );\n\t\t\t\tobject.instanceMatrix = new InstancedBufferAttribute( new Float32Array( instanceMatrix.array ), 16 );\n\t\t\t\tif ( instanceColor !== undefined ) object.instanceColor = new InstancedBufferAttribute( new Float32Array( instanceColor.array ), instanceColor.itemSize );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'LOD':\n\n\t\t\t\tobject = new LOD();\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'Line':\n\n\t\t\t\tobject = new Line( getGeometry( data.geometry ), getMaterial( data.material ) );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'LineLoop':\n\n\t\t\t\tobject = new LineLoop( getGeometry( data.geometry ), getMaterial( data.material ) );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'LineSegments':\n\n\t\t\t\tobject = new LineSegments( getGeometry( data.geometry ), getMaterial( data.material ) );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'PointCloud':\n\t\t\tcase 'Points':\n\n\t\t\t\tobject = new Points( getGeometry( data.geometry ), getMaterial( data.material ) );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'Sprite':\n\n\t\t\t\tobject = new Sprite( getMaterial( data.material ) );\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'Group':\n\n\t\t\t\tobject = new Group();\n\n\t\t\t\tbreak;\n\n\t\t\tcase 'Bone':\n\n\t\t\t\tobject = new Bone();\n\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\n\t\t\t\tobject = new Object3D();\n\n\t\t}\n\n\t\tobject.uuid = data.uuid;\n\n\t\tif ( data.name !== undefined ) object.name = data.name;\n\n\t\tif ( data.matrix !== undefined ) {\n\n\t\t\tobject.matrix.fromArray( data.matrix );\n\n\t\t\tif ( data.matrixAutoUpdate !== undefined ) object.matrixAutoUpdate = data.matrixAutoUpdate;\n\t\t\tif ( object.matrixAutoUpdate ) object.matrix.decompose( object.position, object.quaternion, object.scale );\n\n\t\t} else {\n\n\t\t\tif ( data.position !== undefined ) object.position.fromArray( data.position );\n\t\t\tif ( data.rotation !== undefined ) object.rotation.fromArray( data.rotation );\n\t\t\tif ( data.quaternion !== undefined ) object.quaternion.fromArray( data.quaternion );\n\t\t\tif ( data.scale !== undefined ) object.scale.fromArray( data.scale );\n\n\t\t}\n\n\t\tif ( data.castShadow !== undefined ) object.castShadow = data.castShadow;\n\t\tif ( data.receiveShadow !== undefined ) object.receiveShadow = data.receiveShadow;\n\n\t\tif ( data.shadow ) {\n\n\t\t\tif ( data.shadow.bias !== undefined ) object.shadow.bias = data.shadow.bias;\n\t\t\tif ( data.shadow.normalBias !== undefined ) object.shadow.normalBias = data.shadow.normalBias;\n\t\t\tif ( data.shadow.radius !== undefined ) object.shadow.radius = data.shadow.radius;\n\t\t\tif ( data.shadow.mapSize !== undefined ) object.shadow.mapSize.fromArray( data.shadow.mapSize );\n\t\t\tif ( data.shadow.camera !== undefined ) object.shadow.camera = this.parseObject( data.shadow.camera );\n\n\t\t}\n\n\t\tif ( data.visible !== undefined ) object.visible = data.visible;\n\t\tif ( data.frustumCulled !== undefined ) object.frustumCulled = data.frustumCulled;\n\t\tif ( data.renderOrder !== undefined ) object.renderOrder = data.renderOrder;\n\t\tif ( data.userData !== undefined ) object.userData = data.userData;\n\t\tif ( data.layers !== undefined ) object.layers.mask = data.layers;\n\n\t\tif ( data.children !== undefined ) {\n\n\t\t\tconst children = data.children;\n\n\t\t\tfor ( let i = 0; i < children.length; i ++ ) {\n\n\t\t\t\tobject.add( this.parseObject( children[ i ], geometries, materials, textures, animations ) );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( data.animations !== undefined ) {\n\n\t\t\tconst objectAnimations = data.animations;\n\n\t\t\tfor ( let i = 0; i < objectAnimations.length; i ++ ) {\n\n\t\t\t\tconst uuid = objectAnimations[ i ];\n\n\t\t\t\tobject.animations.push( animations[ uuid ] );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( data.type === 'LOD' ) {\n\n\t\t\tif ( data.autoUpdate !== undefined ) object.autoUpdate = data.autoUpdate;\n\n\t\t\tconst levels = data.levels;\n\n\t\t\tfor ( let l = 0; l < levels.length; l ++ ) {\n\n\t\t\t\tconst level = levels[ l ];\n\t\t\t\tconst child = object.getObjectByProperty( 'uuid', level.object );\n\n\t\t\t\tif ( child !== undefined ) {\n\n\t\t\t\t\tobject.addLevel( child, level.distance );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn object;\n\n\t}\n\n\tbindSkeletons( object, skeletons ) {\n\n\t\tif ( Object.keys( skeletons ).length === 0 ) return;\n\n\t\tobject.traverse( function ( child ) {\n\n\t\t\tif ( child.isSkinnedMesh === true && child.skeleton !== undefined ) {\n\n\t\t\t\tconst skeleton = skeletons[ child.skeleton ];\n\n\t\t\t\tif ( skeleton === undefined ) {\n\n\t\t\t\t\tconsole.warn( 'THREE.ObjectLoader: No skeleton found with UUID:', child.skeleton );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tchild.bind( skeleton, child.bindMatrix );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} );\n\n\t}\n\n\t/* DEPRECATED */\n\n\tsetTexturePath( value ) {\n\n\t\tconsole.warn( 'THREE.ObjectLoader: .setTexturePath() has been renamed to .setResourcePath().' );\n\t\treturn this.setResourcePath( value );\n\n\t}\n\n}\n\nconst TEXTURE_MAPPING = {\n\tUVMapping: UVMapping,\n\tCubeReflectionMapping: CubeReflectionMapping,\n\tCubeRefractionMapping: CubeRefractionMapping,\n\tEquirectangularReflectionMapping: EquirectangularReflectionMapping,\n\tEquirectangularRefractionMapping: EquirectangularRefractionMapping,\n\tCubeUVReflectionMapping: CubeUVReflectionMapping,\n\tCubeUVRefractionMapping: CubeUVRefractionMapping\n};\n\nconst TEXTURE_WRAPPING = {\n\tRepeatWrapping: RepeatWrapping,\n\tClampToEdgeWrapping: ClampToEdgeWrapping,\n\tMirroredRepeatWrapping: MirroredRepeatWrapping\n};\n\nconst TEXTURE_FILTER = {\n\tNearestFilter: NearestFilter,\n\tNearestMipmapNearestFilter: NearestMipmapNearestFilter,\n\tNearestMipmapLinearFilter: NearestMipmapLinearFilter,\n\tLinearFilter: LinearFilter,\n\tLinearMipmapNearestFilter: LinearMipmapNearestFilter,\n\tLinearMipmapLinearFilter: LinearMipmapLinearFilter\n};\n\nclass ImageBitmapLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t\tif ( typeof createImageBitmap === 'undefined' ) {\n\n\t\t\tconsole.warn( 'THREE.ImageBitmapLoader: createImageBitmap() not supported.' );\n\n\t\t}\n\n\t\tif ( typeof fetch === 'undefined' ) {\n\n\t\t\tconsole.warn( 'THREE.ImageBitmapLoader: fetch() not supported.' );\n\n\t\t}\n\n\t\tthis.options = { premultiplyAlpha: 'none' };\n\n\t}\n\n\tsetOptions( options ) {\n\n\t\tthis.options = options;\n\n\t\treturn this;\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tif ( url === undefined ) url = '';\n\n\t\tif ( this.path !== undefined ) url = this.path + url;\n\n\t\turl = this.manager.resolveURL( url );\n\n\t\tconst scope = this;\n\n\t\tconst cached = Cache.get( url );\n\n\t\tif ( cached !== undefined ) {\n\n\t\t\tscope.manager.itemStart( url );\n\n\t\t\tsetTimeout( function () {\n\n\t\t\t\tif ( onLoad ) onLoad( cached );\n\n\t\t\t\tscope.manager.itemEnd( url );\n\n\t\t\t}, 0 );\n\n\t\t\treturn cached;\n\n\t\t}\n\n\t\tconst fetchOptions = {};\n\t\tfetchOptions.credentials = ( this.crossOrigin === 'anonymous' ) ? 'same-origin' : 'include';\n\t\tfetchOptions.headers = this.requestHeader;\n\n\t\tfetch( url, fetchOptions ).then( function ( res ) {\n\n\t\t\treturn res.blob();\n\n\t\t} ).then( function ( blob ) {\n\n\t\t\treturn createImageBitmap( blob, Object.assign( scope.options, { colorSpaceConversion: 'none' } ) );\n\n\t\t} ).then( function ( imageBitmap ) {\n\n\t\t\tCache.add( url, imageBitmap );\n\n\t\t\tif ( onLoad ) onLoad( imageBitmap );\n\n\t\t\tscope.manager.itemEnd( url );\n\n\t\t} ).catch( function ( e ) {\n\n\t\t\tif ( onError ) onError( e );\n\n\t\t\tscope.manager.itemError( url );\n\t\t\tscope.manager.itemEnd( url );\n\n\t\t} );\n\n\t\tscope.manager.itemStart( url );\n\n\t}\n\n}\n\nImageBitmapLoader.prototype.isImageBitmapLoader = true;\n\nlet _context;\n\nconst AudioContext = {\n\n\tgetContext: function () {\n\n\t\tif ( _context === undefined ) {\n\n\t\t\t_context = new ( window.AudioContext || window.webkitAudioContext )();\n\n\t\t}\n\n\t\treturn _context;\n\n\t},\n\n\tsetContext: function ( value ) {\n\n\t\t_context = value;\n\n\t}\n\n};\n\nclass AudioLoader extends Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tconst loader = new FileLoader( this.manager );\n\t\tloader.setResponseType( 'arraybuffer' );\n\t\tloader.setPath( this.path );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setWithCredentials( this.withCredentials );\n\t\tloader.load( url, function ( buffer ) {\n\n\t\t\ttry {\n\n\t\t\t\t// Create a copy of the buffer. The `decodeAudioData` method\n\t\t\t\t// detaches the buffer when complete, preventing reuse.\n\t\t\t\tconst bufferCopy = buffer.slice( 0 );\n\n\t\t\t\tconst context = AudioContext.getContext();\n\t\t\t\tcontext.decodeAudioData( bufferCopy, function ( audioBuffer ) {\n\n\t\t\t\t\tonLoad( audioBuffer );\n\n\t\t\t\t} );\n\n\t\t\t} catch ( e ) {\n\n\t\t\t\tif ( onError ) {\n\n\t\t\t\t\tonError( e );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( e );\n\n\t\t\t\t}\n\n\t\t\t\tscope.manager.itemError( url );\n\n\t\t\t}\n\n\t\t}, onProgress, onError );\n\n\t}\n\n}\n\nclass HemisphereLightProbe extends LightProbe {\n\n\tconstructor( skyColor, groundColor, intensity = 1 ) {\n\n\t\tsuper( undefined, intensity );\n\n\t\tconst color1 = new Color().set( skyColor );\n\t\tconst color2 = new Color().set( groundColor );\n\n\t\tconst sky = new Vector3( color1.r, color1.g, color1.b );\n\t\tconst ground = new Vector3( color2.r, color2.g, color2.b );\n\n\t\t// without extra factor of PI in the shader, should = 1 / Math.sqrt( Math.PI );\n\t\tconst c0 = Math.sqrt( Math.PI );\n\t\tconst c1 = c0 * Math.sqrt( 0.75 );\n\n\t\tthis.sh.coefficients[ 0 ].copy( sky ).add( ground ).multiplyScalar( c0 );\n\t\tthis.sh.coefficients[ 1 ].copy( sky ).sub( ground ).multiplyScalar( c1 );\n\n\t}\n\n}\n\nHemisphereLightProbe.prototype.isHemisphereLightProbe = true;\n\nclass AmbientLightProbe extends LightProbe {\n\n\tconstructor( color, intensity = 1 ) {\n\n\t\tsuper( undefined, intensity );\n\n\t\tconst color1 = new Color().set( color );\n\n\t\t// without extra factor of PI in the shader, would be 2 / Math.sqrt( Math.PI );\n\t\tthis.sh.coefficients[ 0 ].set( color1.r, color1.g, color1.b ).multiplyScalar( 2 * Math.sqrt( Math.PI ) );\n\n\t}\n\n}\n\nAmbientLightProbe.prototype.isAmbientLightProbe = true;\n\nconst _eyeRight = /*@__PURE__*/ new Matrix4();\nconst _eyeLeft = /*@__PURE__*/ new Matrix4();\nconst _projectionMatrix = /*@__PURE__*/ new Matrix4();\n\nclass StereoCamera {\n\n\tconstructor() {\n\n\t\tthis.type = 'StereoCamera';\n\n\t\tthis.aspect = 1;\n\n\t\tthis.eyeSep = 0.064;\n\n\t\tthis.cameraL = new PerspectiveCamera();\n\t\tthis.cameraL.layers.enable( 1 );\n\t\tthis.cameraL.matrixAutoUpdate = false;\n\n\t\tthis.cameraR = new PerspectiveCamera();\n\t\tthis.cameraR.layers.enable( 2 );\n\t\tthis.cameraR.matrixAutoUpdate = false;\n\n\t\tthis._cache = {\n\t\t\tfocus: null,\n\t\t\tfov: null,\n\t\t\taspect: null,\n\t\t\tnear: null,\n\t\t\tfar: null,\n\t\t\tzoom: null,\n\t\t\teyeSep: null\n\t\t};\n\n\t}\n\n\tupdate( camera ) {\n\n\t\tconst cache = this._cache;\n\n\t\tconst needsUpdate = cache.focus !== camera.focus || cache.fov !== camera.fov ||\n\t\t\tcache.aspect !== camera.aspect * this.aspect || cache.near !== camera.near ||\n\t\t\tcache.far !== camera.far || cache.zoom !== camera.zoom || cache.eyeSep !== this.eyeSep;\n\n\t\tif ( needsUpdate ) {\n\n\t\t\tcache.focus = camera.focus;\n\t\t\tcache.fov = camera.fov;\n\t\t\tcache.aspect = camera.aspect * this.aspect;\n\t\t\tcache.near = camera.near;\n\t\t\tcache.far = camera.far;\n\t\t\tcache.zoom = camera.zoom;\n\t\t\tcache.eyeSep = this.eyeSep;\n\n\t\t\t// Off-axis stereoscopic effect based on\n\t\t\t// http://paulbourke.net/stereographics/stereorender/\n\n\t\t\t_projectionMatrix.copy( camera.projectionMatrix );\n\t\t\tconst eyeSepHalf = cache.eyeSep / 2;\n\t\t\tconst eyeSepOnProjection = eyeSepHalf * cache.near / cache.focus;\n\t\t\tconst ymax = ( cache.near * Math.tan( DEG2RAD * cache.fov * 0.5 ) ) / cache.zoom;\n\t\t\tlet xmin, xmax;\n\n\t\t\t// translate xOffset\n\n\t\t\t_eyeLeft.elements[ 12 ] = - eyeSepHalf;\n\t\t\t_eyeRight.elements[ 12 ] = eyeSepHalf;\n\n\t\t\t// for left eye\n\n\t\t\txmin = - ymax * cache.aspect + eyeSepOnProjection;\n\t\t\txmax = ymax * cache.aspect + eyeSepOnProjection;\n\n\t\t\t_projectionMatrix.elements[ 0 ] = 2 * cache.near / ( xmax - xmin );\n\t\t\t_projectionMatrix.elements[ 8 ] = ( xmax + xmin ) / ( xmax - xmin );\n\n\t\t\tthis.cameraL.projectionMatrix.copy( _projectionMatrix );\n\n\t\t\t// for right eye\n\n\t\t\txmin = - ymax * cache.aspect - eyeSepOnProjection;\n\t\t\txmax = ymax * cache.aspect - eyeSepOnProjection;\n\n\t\t\t_projectionMatrix.elements[ 0 ] = 2 * cache.near / ( xmax - xmin );\n\t\t\t_projectionMatrix.elements[ 8 ] = ( xmax + xmin ) / ( xmax - xmin );\n\n\t\t\tthis.cameraR.projectionMatrix.copy( _projectionMatrix );\n\n\t\t}\n\n\t\tthis.cameraL.matrixWorld.copy( camera.matrixWorld ).multiply( _eyeLeft );\n\t\tthis.cameraR.matrixWorld.copy( camera.matrixWorld ).multiply( _eyeRight );\n\n\t}\n\n}\n\nclass Clock {\n\n\tconstructor( autoStart = true ) {\n\n\t\tthis.autoStart = autoStart;\n\n\t\tthis.startTime = 0;\n\t\tthis.oldTime = 0;\n\t\tthis.elapsedTime = 0;\n\n\t\tthis.running = false;\n\n\t}\n\n\tstart() {\n\n\t\tthis.startTime = now();\n\n\t\tthis.oldTime = this.startTime;\n\t\tthis.elapsedTime = 0;\n\t\tthis.running = true;\n\n\t}\n\n\tstop() {\n\n\t\tthis.getElapsedTime();\n\t\tthis.running = false;\n\t\tthis.autoStart = false;\n\n\t}\n\n\tgetElapsedTime() {\n\n\t\tthis.getDelta();\n\t\treturn this.elapsedTime;\n\n\t}\n\n\tgetDelta() {\n\n\t\tlet diff = 0;\n\n\t\tif ( this.autoStart && ! this.running ) {\n\n\t\t\tthis.start();\n\t\t\treturn 0;\n\n\t\t}\n\n\t\tif ( this.running ) {\n\n\t\t\tconst newTime = now();\n\n\t\t\tdiff = ( newTime - this.oldTime ) / 1000;\n\t\t\tthis.oldTime = newTime;\n\n\t\t\tthis.elapsedTime += diff;\n\n\t\t}\n\n\t\treturn diff;\n\n\t}\n\n}\n\nfunction now() {\n\n\treturn ( typeof performance === 'undefined' ? Date : performance ).now(); // see #10732\n\n}\n\nconst _position$1 = /*@__PURE__*/ new Vector3();\nconst _quaternion$1 = /*@__PURE__*/ new Quaternion();\nconst _scale$1 = /*@__PURE__*/ new Vector3();\nconst _orientation$1 = /*@__PURE__*/ new Vector3();\n\nclass AudioListener extends Object3D {\n\n\tconstructor() {\n\n\t\tsuper();\n\n\t\tthis.type = 'AudioListener';\n\n\t\tthis.context = AudioContext.getContext();\n\n\t\tthis.gain = this.context.createGain();\n\t\tthis.gain.connect( this.context.destination );\n\n\t\tthis.filter = null;\n\n\t\tthis.timeDelta = 0;\n\n\t\t// private\n\n\t\tthis._clock = new Clock();\n\n\t}\n\n\tgetInput() {\n\n\t\treturn this.gain;\n\n\t}\n\n\tremoveFilter() {\n\n\t\tif ( this.filter !== null ) {\n\n\t\t\tthis.gain.disconnect( this.filter );\n\t\t\tthis.filter.disconnect( this.context.destination );\n\t\t\tthis.gain.connect( this.context.destination );\n\t\t\tthis.filter = null;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetFilter() {\n\n\t\treturn this.filter;\n\n\t}\n\n\tsetFilter( value ) {\n\n\t\tif ( this.filter !== null ) {\n\n\t\t\tthis.gain.disconnect( this.filter );\n\t\t\tthis.filter.disconnect( this.context.destination );\n\n\t\t} else {\n\n\t\t\tthis.gain.disconnect( this.context.destination );\n\n\t\t}\n\n\t\tthis.filter = value;\n\t\tthis.gain.connect( this.filter );\n\t\tthis.filter.connect( this.context.destination );\n\n\t\treturn this;\n\n\t}\n\n\tgetMasterVolume() {\n\n\t\treturn this.gain.gain.value;\n\n\t}\n\n\tsetMasterVolume( value ) {\n\n\t\tthis.gain.gain.setTargetAtTime( value, this.context.currentTime, 0.01 );\n\n\t\treturn this;\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t\tconst listener = this.context.listener;\n\t\tconst up = this.up;\n\n\t\tthis.timeDelta = this._clock.getDelta();\n\n\t\tthis.matrixWorld.decompose( _position$1, _quaternion$1, _scale$1 );\n\n\t\t_orientation$1.set( 0, 0, - 1 ).applyQuaternion( _quaternion$1 );\n\n\t\tif ( listener.positionX ) {\n\n\t\t\t// code path for Chrome (see #14393)\n\n\t\t\tconst endTime = this.context.currentTime + this.timeDelta;\n\n\t\t\tlistener.positionX.linearRampToValueAtTime( _position$1.x, endTime );\n\t\t\tlistener.positionY.linearRampToValueAtTime( _position$1.y, endTime );\n\t\t\tlistener.positionZ.linearRampToValueAtTime( _position$1.z, endTime );\n\t\t\tlistener.forwardX.linearRampToValueAtTime( _orientation$1.x, endTime );\n\t\t\tlistener.forwardY.linearRampToValueAtTime( _orientation$1.y, endTime );\n\t\t\tlistener.forwardZ.linearRampToValueAtTime( _orientation$1.z, endTime );\n\t\t\tlistener.upX.linearRampToValueAtTime( up.x, endTime );\n\t\t\tlistener.upY.linearRampToValueAtTime( up.y, endTime );\n\t\t\tlistener.upZ.linearRampToValueAtTime( up.z, endTime );\n\n\t\t} else {\n\n\t\t\tlistener.setPosition( _position$1.x, _position$1.y, _position$1.z );\n\t\t\tlistener.setOrientation( _orientation$1.x, _orientation$1.y, _orientation$1.z, up.x, up.y, up.z );\n\n\t\t}\n\n\t}\n\n}\n\nclass Audio extends Object3D {\n\n\tconstructor( listener ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'Audio';\n\n\t\tthis.listener = listener;\n\t\tthis.context = listener.context;\n\n\t\tthis.gain = this.context.createGain();\n\t\tthis.gain.connect( listener.getInput() );\n\n\t\tthis.autoplay = false;\n\n\t\tthis.buffer = null;\n\t\tthis.detune = 0;\n\t\tthis.loop = false;\n\t\tthis.loopStart = 0;\n\t\tthis.loopEnd = 0;\n\t\tthis.offset = 0;\n\t\tthis.duration = undefined;\n\t\tthis.playbackRate = 1;\n\t\tthis.isPlaying = false;\n\t\tthis.hasPlaybackControl = true;\n\t\tthis.source = null;\n\t\tthis.sourceType = 'empty';\n\n\t\tthis._startedAt = 0;\n\t\tthis._progress = 0;\n\t\tthis._connected = false;\n\n\t\tthis.filters = [];\n\n\t}\n\n\tgetOutput() {\n\n\t\treturn this.gain;\n\n\t}\n\n\tsetNodeSource( audioNode ) {\n\n\t\tthis.hasPlaybackControl = false;\n\t\tthis.sourceType = 'audioNode';\n\t\tthis.source = audioNode;\n\t\tthis.connect();\n\n\t\treturn this;\n\n\t}\n\n\tsetMediaElementSource( mediaElement ) {\n\n\t\tthis.hasPlaybackControl = false;\n\t\tthis.sourceType = 'mediaNode';\n\t\tthis.source = this.context.createMediaElementSource( mediaElement );\n\t\tthis.connect();\n\n\t\treturn this;\n\n\t}\n\n\tsetMediaStreamSource( mediaStream ) {\n\n\t\tthis.hasPlaybackControl = false;\n\t\tthis.sourceType = 'mediaStreamNode';\n\t\tthis.source = this.context.createMediaStreamSource( mediaStream );\n\t\tthis.connect();\n\n\t\treturn this;\n\n\t}\n\n\tsetBuffer( audioBuffer ) {\n\n\t\tthis.buffer = audioBuffer;\n\t\tthis.sourceType = 'buffer';\n\n\t\tif ( this.autoplay ) this.play();\n\n\t\treturn this;\n\n\t}\n\n\tplay( delay = 0 ) {\n\n\t\tif ( this.isPlaying === true ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: Audio is already playing.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( this.hasPlaybackControl === false ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: this Audio has no playback control.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tthis._startedAt = this.context.currentTime + delay;\n\n\t\tconst source = this.context.createBufferSource();\n\t\tsource.buffer = this.buffer;\n\t\tsource.loop = this.loop;\n\t\tsource.loopStart = this.loopStart;\n\t\tsource.loopEnd = this.loopEnd;\n\t\tsource.onended = this.onEnded.bind( this );\n\t\tsource.start( this._startedAt, this._progress + this.offset, this.duration );\n\n\t\tthis.isPlaying = true;\n\n\t\tthis.source = source;\n\n\t\tthis.setDetune( this.detune );\n\t\tthis.setPlaybackRate( this.playbackRate );\n\n\t\treturn this.connect();\n\n\t}\n\n\tpause() {\n\n\t\tif ( this.hasPlaybackControl === false ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: this Audio has no playback control.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( this.isPlaying === true ) {\n\n\t\t\t// update current progress\n\n\t\t\tthis._progress += Math.max( this.context.currentTime - this._startedAt, 0 ) * this.playbackRate;\n\n\t\t\tif ( this.loop === true ) {\n\n\t\t\t\t// ensure _progress does not exceed duration with looped audios\n\n\t\t\t\tthis._progress = this._progress % ( this.duration || this.buffer.duration );\n\n\t\t\t}\n\n\t\t\tthis.source.stop();\n\t\t\tthis.source.onended = null;\n\n\t\t\tthis.isPlaying = false;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tstop() {\n\n\t\tif ( this.hasPlaybackControl === false ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: this Audio has no playback control.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tthis._progress = 0;\n\n\t\tthis.source.stop();\n\t\tthis.source.onended = null;\n\t\tthis.isPlaying = false;\n\n\t\treturn this;\n\n\t}\n\n\tconnect() {\n\n\t\tif ( this.filters.length > 0 ) {\n\n\t\t\tthis.source.connect( this.filters[ 0 ] );\n\n\t\t\tfor ( let i = 1, l = this.filters.length; i < l; i ++ ) {\n\n\t\t\t\tthis.filters[ i - 1 ].connect( this.filters[ i ] );\n\n\t\t\t}\n\n\t\t\tthis.filters[ this.filters.length - 1 ].connect( this.getOutput() );\n\n\t\t} else {\n\n\t\t\tthis.source.connect( this.getOutput() );\n\n\t\t}\n\n\t\tthis._connected = true;\n\n\t\treturn this;\n\n\t}\n\n\tdisconnect() {\n\n\t\tif ( this.filters.length > 0 ) {\n\n\t\t\tthis.source.disconnect( this.filters[ 0 ] );\n\n\t\t\tfor ( let i = 1, l = this.filters.length; i < l; i ++ ) {\n\n\t\t\t\tthis.filters[ i - 1 ].disconnect( this.filters[ i ] );\n\n\t\t\t}\n\n\t\t\tthis.filters[ this.filters.length - 1 ].disconnect( this.getOutput() );\n\n\t\t} else {\n\n\t\t\tthis.source.disconnect( this.getOutput() );\n\n\t\t}\n\n\t\tthis._connected = false;\n\n\t\treturn this;\n\n\t}\n\n\tgetFilters() {\n\n\t\treturn this.filters;\n\n\t}\n\n\tsetFilters( value ) {\n\n\t\tif ( ! value ) value = [];\n\n\t\tif ( this._connected === true ) {\n\n\t\t\tthis.disconnect();\n\t\t\tthis.filters = value.slice();\n\t\t\tthis.connect();\n\n\t\t} else {\n\n\t\t\tthis.filters = value.slice();\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetDetune( value ) {\n\n\t\tthis.detune = value;\n\n\t\tif ( this.source.detune === undefined ) return; // only set detune when available\n\n\t\tif ( this.isPlaying === true ) {\n\n\t\t\tthis.source.detune.setTargetAtTime( this.detune, this.context.currentTime, 0.01 );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetDetune() {\n\n\t\treturn this.detune;\n\n\t}\n\n\tgetFilter() {\n\n\t\treturn this.getFilters()[ 0 ];\n\n\t}\n\n\tsetFilter( filter ) {\n\n\t\treturn this.setFilters( filter ? [ filter ] : [] );\n\n\t}\n\n\tsetPlaybackRate( value ) {\n\n\t\tif ( this.hasPlaybackControl === false ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: this Audio has no playback control.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tthis.playbackRate = value;\n\n\t\tif ( this.isPlaying === true ) {\n\n\t\t\tthis.source.playbackRate.setTargetAtTime( this.playbackRate, this.context.currentTime, 0.01 );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tgetPlaybackRate() {\n\n\t\treturn this.playbackRate;\n\n\t}\n\n\tonEnded() {\n\n\t\tthis.isPlaying = false;\n\n\t}\n\n\tgetLoop() {\n\n\t\tif ( this.hasPlaybackControl === false ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: this Audio has no playback control.' );\n\t\t\treturn false;\n\n\t\t}\n\n\t\treturn this.loop;\n\n\t}\n\n\tsetLoop( value ) {\n\n\t\tif ( this.hasPlaybackControl === false ) {\n\n\t\t\tconsole.warn( 'THREE.Audio: this Audio has no playback control.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tthis.loop = value;\n\n\t\tif ( this.isPlaying === true ) {\n\n\t\t\tthis.source.loop = this.loop;\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetLoopStart( value ) {\n\n\t\tthis.loopStart = value;\n\n\t\treturn this;\n\n\t}\n\n\tsetLoopEnd( value ) {\n\n\t\tthis.loopEnd = value;\n\n\t\treturn this;\n\n\t}\n\n\tgetVolume() {\n\n\t\treturn this.gain.gain.value;\n\n\t}\n\n\tsetVolume( value ) {\n\n\t\tthis.gain.gain.setTargetAtTime( value, this.context.currentTime, 0.01 );\n\n\t\treturn this;\n\n\t}\n\n}\n\nconst _position = /*@__PURE__*/ new Vector3();\nconst _quaternion = /*@__PURE__*/ new Quaternion();\nconst _scale = /*@__PURE__*/ new Vector3();\nconst _orientation = /*@__PURE__*/ new Vector3();\n\nclass PositionalAudio extends Audio {\n\n\tconstructor( listener ) {\n\n\t\tsuper( listener );\n\n\t\tthis.panner = this.context.createPanner();\n\t\tthis.panner.panningModel = 'HRTF';\n\t\tthis.panner.connect( this.gain );\n\n\t}\n\n\tgetOutput() {\n\n\t\treturn this.panner;\n\n\t}\n\n\tgetRefDistance() {\n\n\t\treturn this.panner.refDistance;\n\n\t}\n\n\tsetRefDistance( value ) {\n\n\t\tthis.panner.refDistance = value;\n\n\t\treturn this;\n\n\t}\n\n\tgetRolloffFactor() {\n\n\t\treturn this.panner.rolloffFactor;\n\n\t}\n\n\tsetRolloffFactor( value ) {\n\n\t\tthis.panner.rolloffFactor = value;\n\n\t\treturn this;\n\n\t}\n\n\tgetDistanceModel() {\n\n\t\treturn this.panner.distanceModel;\n\n\t}\n\n\tsetDistanceModel( value ) {\n\n\t\tthis.panner.distanceModel = value;\n\n\t\treturn this;\n\n\t}\n\n\tgetMaxDistance() {\n\n\t\treturn this.panner.maxDistance;\n\n\t}\n\n\tsetMaxDistance( value ) {\n\n\t\tthis.panner.maxDistance = value;\n\n\t\treturn this;\n\n\t}\n\n\tsetDirectionalCone( coneInnerAngle, coneOuterAngle, coneOuterGain ) {\n\n\t\tthis.panner.coneInnerAngle = coneInnerAngle;\n\t\tthis.panner.coneOuterAngle = coneOuterAngle;\n\t\tthis.panner.coneOuterGain = coneOuterGain;\n\n\t\treturn this;\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t\tif ( this.hasPlaybackControl === true && this.isPlaying === false ) return;\n\n\t\tthis.matrixWorld.decompose( _position, _quaternion, _scale );\n\n\t\t_orientation.set( 0, 0, 1 ).applyQuaternion( _quaternion );\n\n\t\tconst panner = this.panner;\n\n\t\tif ( panner.positionX ) {\n\n\t\t\t// code path for Chrome and Firefox (see #14393)\n\n\t\t\tconst endTime = this.context.currentTime + this.listener.timeDelta;\n\n\t\t\tpanner.positionX.linearRampToValueAtTime( _position.x, endTime );\n\t\t\tpanner.positionY.linearRampToValueAtTime( _position.y, endTime );\n\t\t\tpanner.positionZ.linearRampToValueAtTime( _position.z, endTime );\n\t\t\tpanner.orientationX.linearRampToValueAtTime( _orientation.x, endTime );\n\t\t\tpanner.orientationY.linearRampToValueAtTime( _orientation.y, endTime );\n\t\t\tpanner.orientationZ.linearRampToValueAtTime( _orientation.z, endTime );\n\n\t\t} else {\n\n\t\t\tpanner.setPosition( _position.x, _position.y, _position.z );\n\t\t\tpanner.setOrientation( _orientation.x, _orientation.y, _orientation.z );\n\n\t\t}\n\n\t}\n\n}\n\nclass AudioAnalyser {\n\n\tconstructor( audio, fftSize = 2048 ) {\n\n\t\tthis.analyser = audio.context.createAnalyser();\n\t\tthis.analyser.fftSize = fftSize;\n\n\t\tthis.data = new Uint8Array( this.analyser.frequencyBinCount );\n\n\t\taudio.getOutput().connect( this.analyser );\n\n\t}\n\n\n\tgetFrequencyData() {\n\n\t\tthis.analyser.getByteFrequencyData( this.data );\n\n\t\treturn this.data;\n\n\t}\n\n\tgetAverageFrequency() {\n\n\t\tlet value = 0;\n\t\tconst data = this.getFrequencyData();\n\n\t\tfor ( let i = 0; i < data.length; i ++ ) {\n\n\t\t\tvalue += data[ i ];\n\n\t\t}\n\n\t\treturn value / data.length;\n\n\t}\n\n}\n\nclass PropertyMixer {\n\n\tconstructor( binding, typeName, valueSize ) {\n\n\t\tthis.binding = binding;\n\t\tthis.valueSize = valueSize;\n\n\t\tlet mixFunction,\n\t\t\tmixFunctionAdditive,\n\t\t\tsetIdentity;\n\n\t\t// buffer layout: [ incoming | accu0 | accu1 | orig | addAccu | (optional work) ]\n\t\t//\n\t\t// interpolators can use .buffer as their .result\n\t\t// the data then goes to 'incoming'\n\t\t//\n\t\t// 'accu0' and 'accu1' are used frame-interleaved for\n\t\t// the cumulative result and are compared to detect\n\t\t// changes\n\t\t//\n\t\t// 'orig' stores the original state of the property\n\t\t//\n\t\t// 'add' is used for additive cumulative results\n\t\t//\n\t\t// 'work' is optional and is only present for quaternion types. It is used\n\t\t// to store intermediate quaternion multiplication results\n\n\t\tswitch ( typeName ) {\n\n\t\t\tcase 'quaternion':\n\t\t\t\tmixFunction = this._slerp;\n\t\t\t\tmixFunctionAdditive = this._slerpAdditive;\n\t\t\t\tsetIdentity = this._setAdditiveIdentityQuaternion;\n\n\t\t\t\tthis.buffer = new Float64Array( valueSize * 6 );\n\t\t\t\tthis._workIndex = 5;\n\t\t\t\tbreak;\n\n\t\t\tcase 'string':\n\t\t\tcase 'bool':\n\t\t\t\tmixFunction = this._select;\n\n\t\t\t\t// Use the regular mix function and for additive on these types,\n\t\t\t\t// additive is not relevant for non-numeric types\n\t\t\t\tmixFunctionAdditive = this._select;\n\n\t\t\t\tsetIdentity = this._setAdditiveIdentityOther;\n\n\t\t\t\tthis.buffer = new Array( valueSize * 5 );\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tmixFunction = this._lerp;\n\t\t\t\tmixFunctionAdditive = this._lerpAdditive;\n\t\t\t\tsetIdentity = this._setAdditiveIdentityNumeric;\n\n\t\t\t\tthis.buffer = new Float64Array( valueSize * 5 );\n\n\t\t}\n\n\t\tthis._mixBufferRegion = mixFunction;\n\t\tthis._mixBufferRegionAdditive = mixFunctionAdditive;\n\t\tthis._setIdentity = setIdentity;\n\t\tthis._origIndex = 3;\n\t\tthis._addIndex = 4;\n\n\t\tthis.cumulativeWeight = 0;\n\t\tthis.cumulativeWeightAdditive = 0;\n\n\t\tthis.useCount = 0;\n\t\tthis.referenceCount = 0;\n\n\t}\n\n\t// accumulate data in the 'incoming' region into 'accu<i>'\n\taccumulate( accuIndex, weight ) {\n\n\t\t// note: happily accumulating nothing when weight = 0, the caller knows\n\t\t// the weight and shouldn't have made the call in the first place\n\n\t\tconst buffer = this.buffer,\n\t\t\tstride = this.valueSize,\n\t\t\toffset = accuIndex * stride + stride;\n\n\t\tlet currentWeight = this.cumulativeWeight;\n\n\t\tif ( currentWeight === 0 ) {\n\n\t\t\t// accuN := incoming * weight\n\n\t\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\t\tbuffer[ offset + i ] = buffer[ i ];\n\n\t\t\t}\n\n\t\t\tcurrentWeight = weight;\n\n\t\t} else {\n\n\t\t\t// accuN := accuN + incoming * weight\n\n\t\t\tcurrentWeight += weight;\n\t\t\tconst mix = weight / currentWeight;\n\t\t\tthis._mixBufferRegion( buffer, offset, 0, mix, stride );\n\n\t\t}\n\n\t\tthis.cumulativeWeight = currentWeight;\n\n\t}\n\n\t// accumulate data in the 'incoming' region into 'add'\n\taccumulateAdditive( weight ) {\n\n\t\tconst buffer = this.buffer,\n\t\t\tstride = this.valueSize,\n\t\t\toffset = stride * this._addIndex;\n\n\t\tif ( this.cumulativeWeightAdditive === 0 ) {\n\n\t\t\t// add = identity\n\n\t\t\tthis._setIdentity();\n\n\t\t}\n\n\t\t// add := add + incoming * weight\n\n\t\tthis._mixBufferRegionAdditive( buffer, offset, 0, weight, stride );\n\t\tthis.cumulativeWeightAdditive += weight;\n\n\t}\n\n\t// apply the state of 'accu<i>' to the binding when accus differ\n\tapply( accuIndex ) {\n\n\t\tconst stride = this.valueSize,\n\t\t\tbuffer = this.buffer,\n\t\t\toffset = accuIndex * stride + stride,\n\n\t\t\tweight = this.cumulativeWeight,\n\t\t\tweightAdditive = this.cumulativeWeightAdditive,\n\n\t\t\tbinding = this.binding;\n\n\t\tthis.cumulativeWeight = 0;\n\t\tthis.cumulativeWeightAdditive = 0;\n\n\t\tif ( weight < 1 ) {\n\n\t\t\t// accuN := accuN + original * ( 1 - cumulativeWeight )\n\n\t\t\tconst originalValueOffset = stride * this._origIndex;\n\n\t\t\tthis._mixBufferRegion(\n\t\t\t\tbuffer, offset, originalValueOffset, 1 - weight, stride );\n\n\t\t}\n\n\t\tif ( weightAdditive > 0 ) {\n\n\t\t\t// accuN := accuN + additive accuN\n\n\t\t\tthis._mixBufferRegionAdditive( buffer, offset, this._addIndex * stride, 1, stride );\n\n\t\t}\n\n\t\tfor ( let i = stride, e = stride + stride; i !== e; ++ i ) {\n\n\t\t\tif ( buffer[ i ] !== buffer[ i + stride ] ) {\n\n\t\t\t\t// value has changed -> update scene graph\n\n\t\t\t\tbinding.setValue( buffer, offset );\n\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t// remember the state of the bound property and copy it to both accus\n\tsaveOriginalState() {\n\n\t\tconst binding = this.binding;\n\n\t\tconst buffer = this.buffer,\n\t\t\tstride = this.valueSize,\n\n\t\t\toriginalValueOffset = stride * this._origIndex;\n\n\t\tbinding.getValue( buffer, originalValueOffset );\n\n\t\t// accu[0..1] := orig -- initially detect changes against the original\n\t\tfor ( let i = stride, e = originalValueOffset; i !== e; ++ i ) {\n\n\t\t\tbuffer[ i ] = buffer[ originalValueOffset + ( i % stride ) ];\n\n\t\t}\n\n\t\t// Add to identity for additive\n\t\tthis._setIdentity();\n\n\t\tthis.cumulativeWeight = 0;\n\t\tthis.cumulativeWeightAdditive = 0;\n\n\t}\n\n\t// apply the state previously taken via 'saveOriginalState' to the binding\n\trestoreOriginalState() {\n\n\t\tconst originalValueOffset = this.valueSize * 3;\n\t\tthis.binding.setValue( this.buffer, originalValueOffset );\n\n\t}\n\n\t_setAdditiveIdentityNumeric() {\n\n\t\tconst startIndex = this._addIndex * this.valueSize;\n\t\tconst endIndex = startIndex + this.valueSize;\n\n\t\tfor ( let i = startIndex; i < endIndex; i ++ ) {\n\n\t\t\tthis.buffer[ i ] = 0;\n\n\t\t}\n\n\t}\n\n\t_setAdditiveIdentityQuaternion() {\n\n\t\tthis._setAdditiveIdentityNumeric();\n\t\tthis.buffer[ this._addIndex * this.valueSize + 3 ] = 1;\n\n\t}\n\n\t_setAdditiveIdentityOther() {\n\n\t\tconst startIndex = this._origIndex * this.valueSize;\n\t\tconst targetIndex = this._addIndex * this.valueSize;\n\n\t\tfor ( let i = 0; i < this.valueSize; i ++ ) {\n\n\t\t\tthis.buffer[ targetIndex + i ] = this.buffer[ startIndex + i ];\n\n\t\t}\n\n\t}\n\n\n\t// mix functions\n\n\t_select( buffer, dstOffset, srcOffset, t, stride ) {\n\n\t\tif ( t >= 0.5 ) {\n\n\t\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\t\tbuffer[ dstOffset + i ] = buffer[ srcOffset + i ];\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t_slerp( buffer, dstOffset, srcOffset, t ) {\n\n\t\tQuaternion.slerpFlat( buffer, dstOffset, buffer, dstOffset, buffer, srcOffset, t );\n\n\t}\n\n\t_slerpAdditive( buffer, dstOffset, srcOffset, t, stride ) {\n\n\t\tconst workOffset = this._workIndex * stride;\n\n\t\t// Store result in intermediate buffer offset\n\t\tQuaternion.multiplyQuaternionsFlat( buffer, workOffset, buffer, dstOffset, buffer, srcOffset );\n\n\t\t// Slerp to the intermediate result\n\t\tQuaternion.slerpFlat( buffer, dstOffset, buffer, dstOffset, buffer, workOffset, t );\n\n\t}\n\n\t_lerp( buffer, dstOffset, srcOffset, t, stride ) {\n\n\t\tconst s = 1 - t;\n\n\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\tconst j = dstOffset + i;\n\n\t\t\tbuffer[ j ] = buffer[ j ] * s + buffer[ srcOffset + i ] * t;\n\n\t\t}\n\n\t}\n\n\t_lerpAdditive( buffer, dstOffset, srcOffset, t, stride ) {\n\n\t\tfor ( let i = 0; i !== stride; ++ i ) {\n\n\t\t\tconst j = dstOffset + i;\n\n\t\t\tbuffer[ j ] = buffer[ j ] + buffer[ srcOffset + i ] * t;\n\n\t\t}\n\n\t}\n\n}\n\n// Characters [].:/ are reserved for track binding syntax.\nconst _RESERVED_CHARS_RE = '\\\\[\\\\]\\\\.:\\\\/';\nconst _reservedRe = new RegExp( '[' + _RESERVED_CHARS_RE + ']', 'g' );\n\n// Attempts to allow node names from any language. ES5's `\\w` regexp matches\n// only latin characters, and the unicode \\p{L} is not yet supported. So\n// instead, we exclude reserved characters and match everything else.\nconst _wordChar = '[^' + _RESERVED_CHARS_RE + ']';\nconst _wordCharOrDot = '[^' + _RESERVED_CHARS_RE.replace( '\\\\.', '' ) + ']';\n\n// Parent directories, delimited by '/' or ':'. Currently unused, but must\n// be matched to parse the rest of the track name.\nconst _directoryRe = /((?:WC+[\\/:])*)/.source.replace( 'WC', _wordChar );\n\n// Target node. May contain word characters (a-zA-Z0-9_) and '.' or '-'.\nconst _nodeRe = /(WCOD+)?/.source.replace( 'WCOD', _wordCharOrDot );\n\n// Object on target node, and accessor. May not contain reserved\n// characters. Accessor may contain any character except closing bracket.\nconst _objectRe = /(?:\\.(WC+)(?:\\[(.+)\\])?)?/.source.replace( 'WC', _wordChar );\n\n// Property and accessor. May not contain reserved characters. Accessor may\n// contain any non-bracket characters.\nconst _propertyRe = /\\.(WC+)(?:\\[(.+)\\])?/.source.replace( 'WC', _wordChar );\n\nconst _trackRe = new RegExp( ''\n\t+ '^'\n\t+ _directoryRe\n\t+ _nodeRe\n\t+ _objectRe\n\t+ _propertyRe\n\t+ '$'\n);\n\nconst _supportedObjectNames = [ 'material', 'materials', 'bones' ];\n\nclass Composite {\n\n\tconstructor( targetGroup, path, optionalParsedPath ) {\n\n\t\tconst parsedPath = optionalParsedPath || PropertyBinding.parseTrackName( path );\n\n\t\tthis._targetGroup = targetGroup;\n\t\tthis._bindings = targetGroup.subscribe_( path, parsedPath );\n\n\t}\n\n\tgetValue( array, offset ) {\n\n\t\tthis.bind(); // bind all binding\n\n\t\tconst firstValidIndex = this._targetGroup.nCachedObjects_,\n\t\t\tbinding = this._bindings[ firstValidIndex ];\n\n\t\t// and only call .getValue on the first\n\t\tif ( binding !== undefined ) binding.getValue( array, offset );\n\n\t}\n\n\tsetValue( array, offset ) {\n\n\t\tconst bindings = this._bindings;\n\n\t\tfor ( let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++ i ) {\n\n\t\t\tbindings[ i ].setValue( array, offset );\n\n\t\t}\n\n\t}\n\n\tbind() {\n\n\t\tconst bindings = this._bindings;\n\n\t\tfor ( let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++ i ) {\n\n\t\t\tbindings[ i ].bind();\n\n\t\t}\n\n\t}\n\n\tunbind() {\n\n\t\tconst bindings = this._bindings;\n\n\t\tfor ( let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++ i ) {\n\n\t\t\tbindings[ i ].unbind();\n\n\t\t}\n\n\t}\n\n}\n\n// Note: This class uses a State pattern on a per-method basis:\n// 'bind' sets 'this.getValue' / 'setValue' and shadows the\n// prototype version of these methods with one that represents\n// the bound state. When the property is not found, the methods\n// become no-ops.\nclass PropertyBinding {\n\n\tconstructor( rootNode, path, parsedPath ) {\n\n\t\tthis.path = path;\n\t\tthis.parsedPath = parsedPath || PropertyBinding.parseTrackName( path );\n\n\t\tthis.node = PropertyBinding.findNode( rootNode, this.parsedPath.nodeName ) || rootNode;\n\n\t\tthis.rootNode = rootNode;\n\n\t\t// initial state of these methods that calls 'bind'\n\t\tthis.getValue = this._getValue_unbound;\n\t\tthis.setValue = this._setValue_unbound;\n\n\t}\n\n\n\tstatic create( root, path, parsedPath ) {\n\n\t\tif ( ! ( root && root.isAnimationObjectGroup ) ) {\n\n\t\t\treturn new PropertyBinding( root, path, parsedPath );\n\n\t\t} else {\n\n\t\t\treturn new PropertyBinding.Composite( root, path, parsedPath );\n\n\t\t}\n\n\t}\n\n\t/**\n\t * Replaces spaces with underscores and removes unsupported characters from\n\t * node names, to ensure compatibility with parseTrackName().\n\t *\n\t * @param {string} name Node name to be sanitized.\n\t * @return {string}\n\t */\n\tstatic sanitizeNodeName( name ) {\n\n\t\treturn name.replace( /\\s/g, '_' ).replace( _reservedRe, '' );\n\n\t}\n\n\tstatic parseTrackName( trackName ) {\n\n\t\tconst matches = _trackRe.exec( trackName );\n\n\t\tif ( matches === null ) {\n\n\t\t\tthrow new Error( 'PropertyBinding: Cannot parse trackName: ' + trackName );\n\n\t\t}\n\n\t\tconst results = {\n\t\t\t// directoryName: matches[ 1 ], // (tschw) currently unused\n\t\t\tnodeName: matches[ 2 ],\n\t\t\tobjectName: matches[ 3 ],\n\t\t\tobjectIndex: matches[ 4 ],\n\t\t\tpropertyName: matches[ 5 ], // required\n\t\t\tpropertyIndex: matches[ 6 ]\n\t\t};\n\n\t\tconst lastDot = results.nodeName && results.nodeName.lastIndexOf( '.' );\n\n\t\tif ( lastDot !== undefined && lastDot !== - 1 ) {\n\n\t\t\tconst objectName = results.nodeName.substring( lastDot + 1 );\n\n\t\t\t// Object names must be checked against an allowlist. Otherwise, there\n\t\t\t// is no way to parse 'foo.bar.baz': 'baz' must be a property, but\n\t\t\t// 'bar' could be the objectName, or part of a nodeName (which can\n\t\t\t// include '.' characters).\n\t\t\tif ( _supportedObjectNames.indexOf( objectName ) !== - 1 ) {\n\n\t\t\t\tresults.nodeName = results.nodeName.substring( 0, lastDot );\n\t\t\t\tresults.objectName = objectName;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( results.propertyName === null || results.propertyName.length === 0 ) {\n\n\t\t\tthrow new Error( 'PropertyBinding: can not parse propertyName from trackName: ' + trackName );\n\n\t\t}\n\n\t\treturn results;\n\n\t}\n\n\tstatic findNode( root, nodeName ) {\n\n\t\tif ( nodeName === undefined || nodeName === '' || nodeName === '.' || nodeName === - 1 || nodeName === root.name || nodeName === root.uuid ) {\n\n\t\t\treturn root;\n\n\t\t}\n\n\t\t// search into skeleton bones.\n\t\tif ( root.skeleton ) {\n\n\t\t\tconst bone = root.skeleton.getBoneByName( nodeName );\n\n\t\t\tif ( bone !== undefined ) {\n\n\t\t\t\treturn bone;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// search into node subtree.\n\t\tif ( root.children ) {\n\n\t\t\tconst searchNodeSubtree = function ( children ) {\n\n\t\t\t\tfor ( let i = 0; i < children.length; i ++ ) {\n\n\t\t\t\t\tconst childNode = children[ i ];\n\n\t\t\t\t\tif ( childNode.name === nodeName || childNode.uuid === nodeName ) {\n\n\t\t\t\t\t\treturn childNode;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tconst result = searchNodeSubtree( childNode.children );\n\n\t\t\t\t\tif ( result ) return result;\n\n\t\t\t\t}\n\n\t\t\t\treturn null;\n\n\t\t\t};\n\n\t\t\tconst subTreeNode = searchNodeSubtree( root.children );\n\n\t\t\tif ( subTreeNode ) {\n\n\t\t\t\treturn subTreeNode;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn null;\n\n\t}\n\n\t// these are used to \"bind\" a nonexistent property\n\t_getValue_unavailable() {}\n\t_setValue_unavailable() {}\n\n\t// Getters\n\n\t_getValue_direct( buffer, offset ) {\n\n\t\tbuffer[ offset ] = this.targetObject[ this.propertyName ];\n\n\t}\n\n\t_getValue_array( buffer, offset ) {\n\n\t\tconst source = this.resolvedProperty;\n\n\t\tfor ( let i = 0, n = source.length; i !== n; ++ i ) {\n\n\t\t\tbuffer[ offset ++ ] = source[ i ];\n\n\t\t}\n\n\t}\n\n\t_getValue_arrayElement( buffer, offset ) {\n\n\t\tbuffer[ offset ] = this.resolvedProperty[ this.propertyIndex ];\n\n\t}\n\n\t_getValue_toArray( buffer, offset ) {\n\n\t\tthis.resolvedProperty.toArray( buffer, offset );\n\n\t}\n\n\t// Direct\n\n\t_setValue_direct( buffer, offset ) {\n\n\t\tthis.targetObject[ this.propertyName ] = buffer[ offset ];\n\n\t}\n\n\t_setValue_direct_setNeedsUpdate( buffer, offset ) {\n\n\t\tthis.targetObject[ this.propertyName ] = buffer[ offset ];\n\t\tthis.targetObject.needsUpdate = true;\n\n\t}\n\n\t_setValue_direct_setMatrixWorldNeedsUpdate( buffer, offset ) {\n\n\t\tthis.targetObject[ this.propertyName ] = buffer[ offset ];\n\t\tthis.targetObject.matrixWorldNeedsUpdate = true;\n\n\t}\n\n\t// EntireArray\n\n\t_setValue_array( buffer, offset ) {\n\n\t\tconst dest = this.resolvedProperty;\n\n\t\tfor ( let i = 0, n = dest.length; i !== n; ++ i ) {\n\n\t\t\tdest[ i ] = buffer[ offset ++ ];\n\n\t\t}\n\n\t}\n\n\t_setValue_array_setNeedsUpdate( buffer, offset ) {\n\n\t\tconst dest = this.resolvedProperty;\n\n\t\tfor ( let i = 0, n = dest.length; i !== n; ++ i ) {\n\n\t\t\tdest[ i ] = buffer[ offset ++ ];\n\n\t\t}\n\n\t\tthis.targetObject.needsUpdate = true;\n\n\t}\n\n\t_setValue_array_setMatrixWorldNeedsUpdate( buffer, offset ) {\n\n\t\tconst dest = this.resolvedProperty;\n\n\t\tfor ( let i = 0, n = dest.length; i !== n; ++ i ) {\n\n\t\t\tdest[ i ] = buffer[ offset ++ ];\n\n\t\t}\n\n\t\tthis.targetObject.matrixWorldNeedsUpdate = true;\n\n\t}\n\n\t// ArrayElement\n\n\t_setValue_arrayElement( buffer, offset ) {\n\n\t\tthis.resolvedProperty[ this.propertyIndex ] = buffer[ offset ];\n\n\t}\n\n\t_setValue_arrayElement_setNeedsUpdate( buffer, offset ) {\n\n\t\tthis.resolvedProperty[ this.propertyIndex ] = buffer[ offset ];\n\t\tthis.targetObject.needsUpdate = true;\n\n\t}\n\n\t_setValue_arrayElement_setMatrixWorldNeedsUpdate( buffer, offset ) {\n\n\t\tthis.resolvedProperty[ this.propertyIndex ] = buffer[ offset ];\n\t\tthis.targetObject.matrixWorldNeedsUpdate = true;\n\n\t}\n\n\t// HasToFromArray\n\n\t_setValue_fromArray( buffer, offset ) {\n\n\t\tthis.resolvedProperty.fromArray( buffer, offset );\n\n\t}\n\n\t_setValue_fromArray_setNeedsUpdate( buffer, offset ) {\n\n\t\tthis.resolvedProperty.fromArray( buffer, offset );\n\t\tthis.targetObject.needsUpdate = true;\n\n\t}\n\n\t_setValue_fromArray_setMatrixWorldNeedsUpdate( buffer, offset ) {\n\n\t\tthis.resolvedProperty.fromArray( buffer, offset );\n\t\tthis.targetObject.matrixWorldNeedsUpdate = true;\n\n\t}\n\n\t_getValue_unbound( targetArray, offset ) {\n\n\t\tthis.bind();\n\t\tthis.getValue( targetArray, offset );\n\n\t}\n\n\t_setValue_unbound( sourceArray, offset ) {\n\n\t\tthis.bind();\n\t\tthis.setValue( sourceArray, offset );\n\n\t}\n\n\t// create getter / setter pair for a property in the scene graph\n\tbind() {\n\n\t\tlet targetObject = this.node;\n\t\tconst parsedPath = this.parsedPath;\n\n\t\tconst objectName = parsedPath.objectName;\n\t\tconst propertyName = parsedPath.propertyName;\n\t\tlet propertyIndex = parsedPath.propertyIndex;\n\n\t\tif ( ! targetObject ) {\n\n\t\t\ttargetObject = PropertyBinding.findNode( this.rootNode, parsedPath.nodeName ) || this.rootNode;\n\n\t\t\tthis.node = targetObject;\n\n\t\t}\n\n\t\t// set fail state so we can just 'return' on error\n\t\tthis.getValue = this._getValue_unavailable;\n\t\tthis.setValue = this._setValue_unavailable;\n\n\t\t// ensure there is a value node\n\t\tif ( ! targetObject ) {\n\n\t\t\tconsole.error( 'THREE.PropertyBinding: Trying to update node for track: ' + this.path + ' but it wasn\\'t found.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( objectName ) {\n\n\t\t\tlet objectIndex = parsedPath.objectIndex;\n\n\t\t\t// special cases were we need to reach deeper into the hierarchy to get the face materials....\n\t\t\tswitch ( objectName ) {\n\n\t\t\t\tcase 'materials':\n\n\t\t\t\t\tif ( ! targetObject.material ) {\n\n\t\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to material as node does not have a material.', this );\n\t\t\t\t\t\treturn;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( ! targetObject.material.materials ) {\n\n\t\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to material.materials as node.material does not have a materials array.', this );\n\t\t\t\t\t\treturn;\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttargetObject = targetObject.material.materials;\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'bones':\n\n\t\t\t\t\tif ( ! targetObject.skeleton ) {\n\n\t\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to bones as node does not have a skeleton.', this );\n\t\t\t\t\t\treturn;\n\n\t\t\t\t\t}\n\n\t\t\t\t\t// potential future optimization: skip this if propertyIndex is already an integer\n\t\t\t\t\t// and convert the integer string to a true integer.\n\n\t\t\t\t\ttargetObject = targetObject.skeleton.bones;\n\n\t\t\t\t\t// support resolving morphTarget names into indices.\n\t\t\t\t\tfor ( let i = 0; i < targetObject.length; i ++ ) {\n\n\t\t\t\t\t\tif ( targetObject[ i ].name === objectIndex ) {\n\n\t\t\t\t\t\t\tobjectIndex = i;\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\n\t\t\t\t\tif ( targetObject[ objectName ] === undefined ) {\n\n\t\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to objectName of node undefined.', this );\n\t\t\t\t\t\treturn;\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttargetObject = targetObject[ objectName ];\n\n\t\t\t}\n\n\n\t\t\tif ( objectIndex !== undefined ) {\n\n\t\t\t\tif ( targetObject[ objectIndex ] === undefined ) {\n\n\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Trying to bind to objectIndex of objectName, but is undefined.', this, targetObject );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t\ttargetObject = targetObject[ objectIndex ];\n\n\t\t\t}\n\n\t\t}\n\n\t\t// resolve property\n\t\tconst nodeProperty = targetObject[ propertyName ];\n\n\t\tif ( nodeProperty === undefined ) {\n\n\t\t\tconst nodeName = parsedPath.nodeName;\n\n\t\t\tconsole.error( 'THREE.PropertyBinding: Trying to update property for track: ' + nodeName +\n\t\t\t\t'.' + propertyName + ' but it wasn\\'t found.', targetObject );\n\t\t\treturn;\n\n\t\t}\n\n\t\t// determine versioning scheme\n\t\tlet versioning = this.Versioning.None;\n\n\t\tthis.targetObject = targetObject;\n\n\t\tif ( targetObject.needsUpdate !== undefined ) { // material\n\n\t\t\tversioning = this.Versioning.NeedsUpdate;\n\n\t\t} else if ( targetObject.matrixWorldNeedsUpdate !== undefined ) { // node transform\n\n\t\t\tversioning = this.Versioning.MatrixWorldNeedsUpdate;\n\n\t\t}\n\n\t\t// determine how the property gets bound\n\t\tlet bindingType = this.BindingType.Direct;\n\n\t\tif ( propertyIndex !== undefined ) {\n\n\t\t\t// access a sub element of the property array (only primitives are supported right now)\n\n\t\t\tif ( propertyName === 'morphTargetInfluences' ) {\n\n\t\t\t\t// potential optimization, skip this if propertyIndex is already an integer, and convert the integer string to a true integer.\n\n\t\t\t\t// support resolving morphTarget names into indices.\n\t\t\t\tif ( ! targetObject.geometry ) {\n\n\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.', this );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t\tif ( targetObject.geometry.isBufferGeometry ) {\n\n\t\t\t\t\tif ( ! targetObject.geometry.morphAttributes ) {\n\n\t\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.morphAttributes.', this );\n\t\t\t\t\t\treturn;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( targetObject.morphTargetDictionary[ propertyIndex ] !== undefined ) {\n\n\t\t\t\t\t\tpropertyIndex = targetObject.morphTargetDictionary[ propertyIndex ];\n\n\t\t\t\t\t}\n\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.error( 'THREE.PropertyBinding: Can not bind to morphTargetInfluences on THREE.Geometry. Use THREE.BufferGeometry instead.', this );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tbindingType = this.BindingType.ArrayElement;\n\n\t\t\tthis.resolvedProperty = nodeProperty;\n\t\t\tthis.propertyIndex = propertyIndex;\n\n\t\t} else if ( nodeProperty.fromArray !== undefined && nodeProperty.toArray !== undefined ) {\n\n\t\t\t// must use copy for Object3D.Euler/Quaternion\n\n\t\t\tbindingType = this.BindingType.HasFromToArray;\n\n\t\t\tthis.resolvedProperty = nodeProperty;\n\n\t\t} else if ( Array.isArray( nodeProperty ) ) {\n\n\t\t\tbindingType = this.BindingType.EntireArray;\n\n\t\t\tthis.resolvedProperty = nodeProperty;\n\n\t\t} else {\n\n\t\t\tthis.propertyName = propertyName;\n\n\t\t}\n\n\t\t// select getter / setter\n\t\tthis.getValue = this.GetterByBindingType[ bindingType ];\n\t\tthis.setValue = this.SetterByBindingTypeAndVersioning[ bindingType ][ versioning ];\n\n\t}\n\n\tunbind() {\n\n\t\tthis.node = null;\n\n\t\t// back to the prototype version of getValue / setValue\n\t\t// note: avoiding to mutate the shape of 'this' via 'delete'\n\t\tthis.getValue = this._getValue_unbound;\n\t\tthis.setValue = this._setValue_unbound;\n\n\t}\n\n}\n\nPropertyBinding.Composite = Composite;\n\nPropertyBinding.prototype.BindingType = {\n\tDirect: 0,\n\tEntireArray: 1,\n\tArrayElement: 2,\n\tHasFromToArray: 3\n};\n\nPropertyBinding.prototype.Versioning = {\n\tNone: 0,\n\tNeedsUpdate: 1,\n\tMatrixWorldNeedsUpdate: 2\n};\n\nPropertyBinding.prototype.GetterByBindingType = [\n\n\tPropertyBinding.prototype._getValue_direct,\n\tPropertyBinding.prototype._getValue_array,\n\tPropertyBinding.prototype._getValue_arrayElement,\n\tPropertyBinding.prototype._getValue_toArray,\n\n];\n\nPropertyBinding.prototype.SetterByBindingTypeAndVersioning = [\n\n\t[\n\t\t// Direct\n\t\tPropertyBinding.prototype._setValue_direct,\n\t\tPropertyBinding.prototype._setValue_direct_setNeedsUpdate,\n\t\tPropertyBinding.prototype._setValue_direct_setMatrixWorldNeedsUpdate,\n\n\t], [\n\n\t\t// EntireArray\n\n\t\tPropertyBinding.prototype._setValue_array,\n\t\tPropertyBinding.prototype._setValue_array_setNeedsUpdate,\n\t\tPropertyBinding.prototype._setValue_array_setMatrixWorldNeedsUpdate,\n\n\t], [\n\n\t\t// ArrayElement\n\t\tPropertyBinding.prototype._setValue_arrayElement,\n\t\tPropertyBinding.prototype._setValue_arrayElement_setNeedsUpdate,\n\t\tPropertyBinding.prototype._setValue_arrayElement_setMatrixWorldNeedsUpdate,\n\n\t], [\n\n\t\t// HasToFromArray\n\t\tPropertyBinding.prototype._setValue_fromArray,\n\t\tPropertyBinding.prototype._setValue_fromArray_setNeedsUpdate,\n\t\tPropertyBinding.prototype._setValue_fromArray_setMatrixWorldNeedsUpdate,\n\n\t]\n\n];\n\n/**\n *\n * A group of objects that receives a shared animation state.\n *\n * Usage:\n *\n *  - Add objects you would otherwise pass as 'root' to the\n *    constructor or the .clipAction method of AnimationMixer.\n *\n *  - Instead pass this object as 'root'.\n *\n *  - You can also add and remove objects later when the mixer\n *    is running.\n *\n * Note:\n *\n *    Objects of this class appear as one object to the mixer,\n *    so cache control of the individual objects must be done\n *    on the group.\n *\n * Limitation:\n *\n *  - The animated properties must be compatible among the\n *    all objects in the group.\n *\n *  - A single property can either be controlled through a\n *    target group or directly, but not both.\n */\n\nclass AnimationObjectGroup {\n\n\tconstructor() {\n\n\t\tthis.uuid = generateUUID();\n\n\t\t// cached objects followed by the active ones\n\t\tthis._objects = Array.prototype.slice.call( arguments );\n\n\t\tthis.nCachedObjects_ = 0; // threshold\n\t\t// note: read by PropertyBinding.Composite\n\n\t\tconst indices = {};\n\t\tthis._indicesByUUID = indices; // for bookkeeping\n\n\t\tfor ( let i = 0, n = arguments.length; i !== n; ++ i ) {\n\n\t\t\tindices[ arguments[ i ].uuid ] = i;\n\n\t\t}\n\n\t\tthis._paths = []; // inside: string\n\t\tthis._parsedPaths = []; // inside: { we don't care, here }\n\t\tthis._bindings = []; // inside: Array< PropertyBinding >\n\t\tthis._bindingsIndicesByPath = {}; // inside: indices in these arrays\n\n\t\tconst scope = this;\n\n\t\tthis.stats = {\n\n\t\t\tobjects: {\n\t\t\t\tget total() {\n\n\t\t\t\t\treturn scope._objects.length;\n\n\t\t\t\t},\n\t\t\t\tget inUse() {\n\n\t\t\t\t\treturn this.total - scope.nCachedObjects_;\n\n\t\t\t\t}\n\t\t\t},\n\t\t\tget bindingsPerObject() {\n\n\t\t\t\treturn scope._bindings.length;\n\n\t\t\t}\n\n\t\t};\n\n\t}\n\n\tadd() {\n\n\t\tconst objects = this._objects,\n\t\t\tindicesByUUID = this._indicesByUUID,\n\t\t\tpaths = this._paths,\n\t\t\tparsedPaths = this._parsedPaths,\n\t\t\tbindings = this._bindings,\n\t\t\tnBindings = bindings.length;\n\n\t\tlet knownObject = undefined,\n\t\t\tnObjects = objects.length,\n\t\t\tnCachedObjects = this.nCachedObjects_;\n\n\t\tfor ( let i = 0, n = arguments.length; i !== n; ++ i ) {\n\n\t\t\tconst object = arguments[ i ],\n\t\t\t\tuuid = object.uuid;\n\t\t\tlet index = indicesByUUID[ uuid ];\n\n\t\t\tif ( index === undefined ) {\n\n\t\t\t\t// unknown object -> add it to the ACTIVE region\n\n\t\t\t\tindex = nObjects ++;\n\t\t\t\tindicesByUUID[ uuid ] = index;\n\t\t\t\tobjects.push( object );\n\n\t\t\t\t// accounting is done, now do the same for all bindings\n\n\t\t\t\tfor ( let j = 0, m = nBindings; j !== m; ++ j ) {\n\n\t\t\t\t\tbindings[ j ].push( new PropertyBinding( object, paths[ j ], parsedPaths[ j ] ) );\n\n\t\t\t\t}\n\n\t\t\t} else if ( index < nCachedObjects ) {\n\n\t\t\t\tknownObject = objects[ index ];\n\n\t\t\t\t// move existing object to the ACTIVE region\n\n\t\t\t\tconst firstActiveIndex = -- nCachedObjects,\n\t\t\t\t\tlastCachedObject = objects[ firstActiveIndex ];\n\n\t\t\t\tindicesByUUID[ lastCachedObject.uuid ] = index;\n\t\t\t\tobjects[ index ] = lastCachedObject;\n\n\t\t\t\tindicesByUUID[ uuid ] = firstActiveIndex;\n\t\t\t\tobjects[ firstActiveIndex ] = object;\n\n\t\t\t\t// accounting is done, now do the same for all bindings\n\n\t\t\t\tfor ( let j = 0, m = nBindings; j !== m; ++ j ) {\n\n\t\t\t\t\tconst bindingsForPath = bindings[ j ],\n\t\t\t\t\t\tlastCached = bindingsForPath[ firstActiveIndex ];\n\n\t\t\t\t\tlet binding = bindingsForPath[ index ];\n\n\t\t\t\t\tbindingsForPath[ index ] = lastCached;\n\n\t\t\t\t\tif ( binding === undefined ) {\n\n\t\t\t\t\t\t// since we do not bother to create new bindings\n\t\t\t\t\t\t// for objects that are cached, the binding may\n\t\t\t\t\t\t// or may not exist\n\n\t\t\t\t\t\tbinding = new PropertyBinding( object, paths[ j ], parsedPaths[ j ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbindingsForPath[ firstActiveIndex ] = binding;\n\n\t\t\t\t}\n\n\t\t\t} else if ( objects[ index ] !== knownObject ) {\n\n\t\t\t\tconsole.error( 'THREE.AnimationObjectGroup: Different objects with the same UUID ' +\n\t\t\t\t\t'detected. Clean the caches or recreate your infrastructure when reloading scenes.' );\n\n\t\t\t} // else the object is already where we want it to be\n\n\t\t} // for arguments\n\n\t\tthis.nCachedObjects_ = nCachedObjects;\n\n\t}\n\n\tremove() {\n\n\t\tconst objects = this._objects,\n\t\t\tindicesByUUID = this._indicesByUUID,\n\t\t\tbindings = this._bindings,\n\t\t\tnBindings = bindings.length;\n\n\t\tlet nCachedObjects = this.nCachedObjects_;\n\n\t\tfor ( let i = 0, n = arguments.length; i !== n; ++ i ) {\n\n\t\t\tconst object = arguments[ i ],\n\t\t\t\tuuid = object.uuid,\n\t\t\t\tindex = indicesByUUID[ uuid ];\n\n\t\t\tif ( index !== undefined && index >= nCachedObjects ) {\n\n\t\t\t\t// move existing object into the CACHED region\n\n\t\t\t\tconst lastCachedIndex = nCachedObjects ++,\n\t\t\t\t\tfirstActiveObject = objects[ lastCachedIndex ];\n\n\t\t\t\tindicesByUUID[ firstActiveObject.uuid ] = index;\n\t\t\t\tobjects[ index ] = firstActiveObject;\n\n\t\t\t\tindicesByUUID[ uuid ] = lastCachedIndex;\n\t\t\t\tobjects[ lastCachedIndex ] = object;\n\n\t\t\t\t// accounting is done, now do the same for all bindings\n\n\t\t\t\tfor ( let j = 0, m = nBindings; j !== m; ++ j ) {\n\n\t\t\t\t\tconst bindingsForPath = bindings[ j ],\n\t\t\t\t\t\tfirstActive = bindingsForPath[ lastCachedIndex ],\n\t\t\t\t\t\tbinding = bindingsForPath[ index ];\n\n\t\t\t\t\tbindingsForPath[ index ] = firstActive;\n\t\t\t\t\tbindingsForPath[ lastCachedIndex ] = binding;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t} // for arguments\n\n\t\tthis.nCachedObjects_ = nCachedObjects;\n\n\t}\n\n\t// remove & forget\n\tuncache() {\n\n\t\tconst objects = this._objects,\n\t\t\tindicesByUUID = this._indicesByUUID,\n\t\t\tbindings = this._bindings,\n\t\t\tnBindings = bindings.length;\n\n\t\tlet nCachedObjects = this.nCachedObjects_,\n\t\t\tnObjects = objects.length;\n\n\t\tfor ( let i = 0, n = arguments.length; i !== n; ++ i ) {\n\n\t\t\tconst object = arguments[ i ],\n\t\t\t\tuuid = object.uuid,\n\t\t\t\tindex = indicesByUUID[ uuid ];\n\n\t\t\tif ( index !== undefined ) {\n\n\t\t\t\tdelete indicesByUUID[ uuid ];\n\n\t\t\t\tif ( index < nCachedObjects ) {\n\n\t\t\t\t\t// object is cached, shrink the CACHED region\n\n\t\t\t\t\tconst firstActiveIndex = -- nCachedObjects,\n\t\t\t\t\t\tlastCachedObject = objects[ firstActiveIndex ],\n\t\t\t\t\t\tlastIndex = -- nObjects,\n\t\t\t\t\t\tlastObject = objects[ lastIndex ];\n\n\t\t\t\t\t// last cached object takes this object's place\n\t\t\t\t\tindicesByUUID[ lastCachedObject.uuid ] = index;\n\t\t\t\t\tobjects[ index ] = lastCachedObject;\n\n\t\t\t\t\t// last object goes to the activated slot and pop\n\t\t\t\t\tindicesByUUID[ lastObject.uuid ] = firstActiveIndex;\n\t\t\t\t\tobjects[ firstActiveIndex ] = lastObject;\n\t\t\t\t\tobjects.pop();\n\n\t\t\t\t\t// accounting is done, now do the same for all bindings\n\n\t\t\t\t\tfor ( let j = 0, m = nBindings; j !== m; ++ j ) {\n\n\t\t\t\t\t\tconst bindingsForPath = bindings[ j ],\n\t\t\t\t\t\t\tlastCached = bindingsForPath[ firstActiveIndex ],\n\t\t\t\t\t\t\tlast = bindingsForPath[ lastIndex ];\n\n\t\t\t\t\t\tbindingsForPath[ index ] = lastCached;\n\t\t\t\t\t\tbindingsForPath[ firstActiveIndex ] = last;\n\t\t\t\t\t\tbindingsForPath.pop();\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// object is active, just swap with the last and pop\n\n\t\t\t\t\tconst lastIndex = -- nObjects,\n\t\t\t\t\t\tlastObject = objects[ lastIndex ];\n\n\t\t\t\t\tif ( lastIndex > 0 ) {\n\n\t\t\t\t\t\tindicesByUUID[ lastObject.uuid ] = index;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tobjects[ index ] = lastObject;\n\t\t\t\t\tobjects.pop();\n\n\t\t\t\t\t// accounting is done, now do the same for all bindings\n\n\t\t\t\t\tfor ( let j = 0, m = nBindings; j !== m; ++ j ) {\n\n\t\t\t\t\t\tconst bindingsForPath = bindings[ j ];\n\n\t\t\t\t\t\tbindingsForPath[ index ] = bindingsForPath[ lastIndex ];\n\t\t\t\t\t\tbindingsForPath.pop();\n\n\t\t\t\t\t}\n\n\t\t\t\t} // cached or active\n\n\t\t\t} // if object is known\n\n\t\t} // for arguments\n\n\t\tthis.nCachedObjects_ = nCachedObjects;\n\n\t}\n\n\t// Internal interface used by befriended PropertyBinding.Composite:\n\n\tsubscribe_( path, parsedPath ) {\n\n\t\t// returns an array of bindings for the given path that is changed\n\t\t// according to the contained objects in the group\n\n\t\tconst indicesByPath = this._bindingsIndicesByPath;\n\t\tlet index = indicesByPath[ path ];\n\t\tconst bindings = this._bindings;\n\n\t\tif ( index !== undefined ) return bindings[ index ];\n\n\t\tconst paths = this._paths,\n\t\t\tparsedPaths = this._parsedPaths,\n\t\t\tobjects = this._objects,\n\t\t\tnObjects = objects.length,\n\t\t\tnCachedObjects = this.nCachedObjects_,\n\t\t\tbindingsForPath = new Array( nObjects );\n\n\t\tindex = bindings.length;\n\n\t\tindicesByPath[ path ] = index;\n\n\t\tpaths.push( path );\n\t\tparsedPaths.push( parsedPath );\n\t\tbindings.push( bindingsForPath );\n\n\t\tfor ( let i = nCachedObjects, n = objects.length; i !== n; ++ i ) {\n\n\t\t\tconst object = objects[ i ];\n\t\t\tbindingsForPath[ i ] = new PropertyBinding( object, path, parsedPath );\n\n\t\t}\n\n\t\treturn bindingsForPath;\n\n\t}\n\n\tunsubscribe_( path ) {\n\n\t\t// tells the group to forget about a property path and no longer\n\t\t// update the array previously obtained with 'subscribe_'\n\n\t\tconst indicesByPath = this._bindingsIndicesByPath,\n\t\t\tindex = indicesByPath[ path ];\n\n\t\tif ( index !== undefined ) {\n\n\t\t\tconst paths = this._paths,\n\t\t\t\tparsedPaths = this._parsedPaths,\n\t\t\t\tbindings = this._bindings,\n\t\t\t\tlastBindingsIndex = bindings.length - 1,\n\t\t\t\tlastBindings = bindings[ lastBindingsIndex ],\n\t\t\t\tlastBindingsPath = path[ lastBindingsIndex ];\n\n\t\t\tindicesByPath[ lastBindingsPath ] = index;\n\n\t\t\tbindings[ index ] = lastBindings;\n\t\t\tbindings.pop();\n\n\t\t\tparsedPaths[ index ] = parsedPaths[ lastBindingsIndex ];\n\t\t\tparsedPaths.pop();\n\n\t\t\tpaths[ index ] = paths[ lastBindingsIndex ];\n\t\t\tpaths.pop();\n\n\t\t}\n\n\t}\n\n}\n\nAnimationObjectGroup.prototype.isAnimationObjectGroup = true;\n\nclass AnimationAction {\n\n\tconstructor( mixer, clip, localRoot = null, blendMode = clip.blendMode ) {\n\n\t\tthis._mixer = mixer;\n\t\tthis._clip = clip;\n\t\tthis._localRoot = localRoot;\n\t\tthis.blendMode = blendMode;\n\n\t\tconst tracks = clip.tracks,\n\t\t\tnTracks = tracks.length,\n\t\t\tinterpolants = new Array( nTracks );\n\n\t\tconst interpolantSettings = {\n\t\t\tendingStart: ZeroCurvatureEnding,\n\t\t\tendingEnd: ZeroCurvatureEnding\n\t\t};\n\n\t\tfor ( let i = 0; i !== nTracks; ++ i ) {\n\n\t\t\tconst interpolant = tracks[ i ].createInterpolant( null );\n\t\t\tinterpolants[ i ] = interpolant;\n\t\t\tinterpolant.settings = interpolantSettings;\n\n\t\t}\n\n\t\tthis._interpolantSettings = interpolantSettings;\n\n\t\tthis._interpolants = interpolants; // bound by the mixer\n\n\t\t// inside: PropertyMixer (managed by the mixer)\n\t\tthis._propertyBindings = new Array( nTracks );\n\n\t\tthis._cacheIndex = null; // for the memory manager\n\t\tthis._byClipCacheIndex = null; // for the memory manager\n\n\t\tthis._timeScaleInterpolant = null;\n\t\tthis._weightInterpolant = null;\n\n\t\tthis.loop = LoopRepeat;\n\t\tthis._loopCount = - 1;\n\n\t\t// global mixer time when the action is to be started\n\t\t// it's set back to 'null' upon start of the action\n\t\tthis._startTime = null;\n\n\t\t// scaled local time of the action\n\t\t// gets clamped or wrapped to 0..clip.duration according to loop\n\t\tthis.time = 0;\n\n\t\tthis.timeScale = 1;\n\t\tthis._effectiveTimeScale = 1;\n\n\t\tthis.weight = 1;\n\t\tthis._effectiveWeight = 1;\n\n\t\tthis.repetitions = Infinity; // no. of repetitions when looping\n\n\t\tthis.paused = false; // true -> zero effective time scale\n\t\tthis.enabled = true; // false -> zero effective weight\n\n\t\tthis.clampWhenFinished = false;// keep feeding the last frame?\n\n\t\tthis.zeroSlopeAtStart = true;// for smooth interpolation w/o separate\n\t\tthis.zeroSlopeAtEnd = true;// clips for start, loop and end\n\n\t}\n\n\t// State & Scheduling\n\n\tplay() {\n\n\t\tthis._mixer._activateAction( this );\n\n\t\treturn this;\n\n\t}\n\n\tstop() {\n\n\t\tthis._mixer._deactivateAction( this );\n\n\t\treturn this.reset();\n\n\t}\n\n\treset() {\n\n\t\tthis.paused = false;\n\t\tthis.enabled = true;\n\n\t\tthis.time = 0; // restart clip\n\t\tthis._loopCount = - 1;// forget previous loops\n\t\tthis._startTime = null;// forget scheduling\n\n\t\treturn this.stopFading().stopWarping();\n\n\t}\n\n\tisRunning() {\n\n\t\treturn this.enabled && ! this.paused && this.timeScale !== 0 &&\n\t\t\tthis._startTime === null && this._mixer._isActiveAction( this );\n\n\t}\n\n\t// return true when play has been called\n\tisScheduled() {\n\n\t\treturn this._mixer._isActiveAction( this );\n\n\t}\n\n\tstartAt( time ) {\n\n\t\tthis._startTime = time;\n\n\t\treturn this;\n\n\t}\n\n\tsetLoop( mode, repetitions ) {\n\n\t\tthis.loop = mode;\n\t\tthis.repetitions = repetitions;\n\n\t\treturn this;\n\n\t}\n\n\t// Weight\n\n\t// set the weight stopping any scheduled fading\n\t// although .enabled = false yields an effective weight of zero, this\n\t// method does *not* change .enabled, because it would be confusing\n\tsetEffectiveWeight( weight ) {\n\n\t\tthis.weight = weight;\n\n\t\t// note: same logic as when updated at runtime\n\t\tthis._effectiveWeight = this.enabled ? weight : 0;\n\n\t\treturn this.stopFading();\n\n\t}\n\n\t// return the weight considering fading and .enabled\n\tgetEffectiveWeight() {\n\n\t\treturn this._effectiveWeight;\n\n\t}\n\n\tfadeIn( duration ) {\n\n\t\treturn this._scheduleFading( duration, 0, 1 );\n\n\t}\n\n\tfadeOut( duration ) {\n\n\t\treturn this._scheduleFading( duration, 1, 0 );\n\n\t}\n\n\tcrossFadeFrom( fadeOutAction, duration, warp ) {\n\n\t\tfadeOutAction.fadeOut( duration );\n\t\tthis.fadeIn( duration );\n\n\t\tif ( warp ) {\n\n\t\t\tconst fadeInDuration = this._clip.duration,\n\t\t\t\tfadeOutDuration = fadeOutAction._clip.duration,\n\n\t\t\t\tstartEndRatio = fadeOutDuration / fadeInDuration,\n\t\t\t\tendStartRatio = fadeInDuration / fadeOutDuration;\n\n\t\t\tfadeOutAction.warp( 1.0, startEndRatio, duration );\n\t\t\tthis.warp( endStartRatio, 1.0, duration );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tcrossFadeTo( fadeInAction, duration, warp ) {\n\n\t\treturn fadeInAction.crossFadeFrom( this, duration, warp );\n\n\t}\n\n\tstopFading() {\n\n\t\tconst weightInterpolant = this._weightInterpolant;\n\n\t\tif ( weightInterpolant !== null ) {\n\n\t\t\tthis._weightInterpolant = null;\n\t\t\tthis._mixer._takeBackControlInterpolant( weightInterpolant );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// Time Scale Control\n\n\t// set the time scale stopping any scheduled warping\n\t// although .paused = true yields an effective time scale of zero, this\n\t// method does *not* change .paused, because it would be confusing\n\tsetEffectiveTimeScale( timeScale ) {\n\n\t\tthis.timeScale = timeScale;\n\t\tthis._effectiveTimeScale = this.paused ? 0 : timeScale;\n\n\t\treturn this.stopWarping();\n\n\t}\n\n\t// return the time scale considering warping and .paused\n\tgetEffectiveTimeScale() {\n\n\t\treturn this._effectiveTimeScale;\n\n\t}\n\n\tsetDuration( duration ) {\n\n\t\tthis.timeScale = this._clip.duration / duration;\n\n\t\treturn this.stopWarping();\n\n\t}\n\n\tsyncWith( action ) {\n\n\t\tthis.time = action.time;\n\t\tthis.timeScale = action.timeScale;\n\n\t\treturn this.stopWarping();\n\n\t}\n\n\thalt( duration ) {\n\n\t\treturn this.warp( this._effectiveTimeScale, 0, duration );\n\n\t}\n\n\twarp( startTimeScale, endTimeScale, duration ) {\n\n\t\tconst mixer = this._mixer,\n\t\t\tnow = mixer.time,\n\t\t\ttimeScale = this.timeScale;\n\n\t\tlet interpolant = this._timeScaleInterpolant;\n\n\t\tif ( interpolant === null ) {\n\n\t\t\tinterpolant = mixer._lendControlInterpolant();\n\t\t\tthis._timeScaleInterpolant = interpolant;\n\n\t\t}\n\n\t\tconst times = interpolant.parameterPositions,\n\t\t\tvalues = interpolant.sampleValues;\n\n\t\ttimes[ 0 ] = now;\n\t\ttimes[ 1 ] = now + duration;\n\n\t\tvalues[ 0 ] = startTimeScale / timeScale;\n\t\tvalues[ 1 ] = endTimeScale / timeScale;\n\n\t\treturn this;\n\n\t}\n\n\tstopWarping() {\n\n\t\tconst timeScaleInterpolant = this._timeScaleInterpolant;\n\n\t\tif ( timeScaleInterpolant !== null ) {\n\n\t\t\tthis._timeScaleInterpolant = null;\n\t\t\tthis._mixer._takeBackControlInterpolant( timeScaleInterpolant );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// Object Accessors\n\n\tgetMixer() {\n\n\t\treturn this._mixer;\n\n\t}\n\n\tgetClip() {\n\n\t\treturn this._clip;\n\n\t}\n\n\tgetRoot() {\n\n\t\treturn this._localRoot || this._mixer._root;\n\n\t}\n\n\t// Interna\n\n\t_update( time, deltaTime, timeDirection, accuIndex ) {\n\n\t\t// called by the mixer\n\n\t\tif ( ! this.enabled ) {\n\n\t\t\t// call ._updateWeight() to update ._effectiveWeight\n\n\t\t\tthis._updateWeight( time );\n\t\t\treturn;\n\n\t\t}\n\n\t\tconst startTime = this._startTime;\n\n\t\tif ( startTime !== null ) {\n\n\t\t\t// check for scheduled start of action\n\n\t\t\tconst timeRunning = ( time - startTime ) * timeDirection;\n\t\t\tif ( timeRunning < 0 || timeDirection === 0 ) {\n\n\t\t\t\treturn; // yet to come / don't decide when delta = 0\n\n\t\t\t}\n\n\t\t\t// start\n\n\t\t\tthis._startTime = null; // unschedule\n\t\t\tdeltaTime = timeDirection * timeRunning;\n\n\t\t}\n\n\t\t// apply time scale and advance time\n\n\t\tdeltaTime *= this._updateTimeScale( time );\n\t\tconst clipTime = this._updateTime( deltaTime );\n\n\t\t// note: _updateTime may disable the action resulting in\n\t\t// an effective weight of 0\n\n\t\tconst weight = this._updateWeight( time );\n\n\t\tif ( weight > 0 ) {\n\n\t\t\tconst interpolants = this._interpolants;\n\t\t\tconst propertyMixers = this._propertyBindings;\n\n\t\t\tswitch ( this.blendMode ) {\n\n\t\t\t\tcase AdditiveAnimationBlendMode:\n\n\t\t\t\t\tfor ( let j = 0, m = interpolants.length; j !== m; ++ j ) {\n\n\t\t\t\t\t\tinterpolants[ j ].evaluate( clipTime );\n\t\t\t\t\t\tpropertyMixers[ j ].accumulateAdditive( weight );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase NormalAnimationBlendMode:\n\t\t\t\tdefault:\n\n\t\t\t\t\tfor ( let j = 0, m = interpolants.length; j !== m; ++ j ) {\n\n\t\t\t\t\t\tinterpolants[ j ].evaluate( clipTime );\n\t\t\t\t\t\tpropertyMixers[ j ].accumulate( accuIndex, weight );\n\n\t\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t_updateWeight( time ) {\n\n\t\tlet weight = 0;\n\n\t\tif ( this.enabled ) {\n\n\t\t\tweight = this.weight;\n\t\t\tconst interpolant = this._weightInterpolant;\n\n\t\t\tif ( interpolant !== null ) {\n\n\t\t\t\tconst interpolantValue = interpolant.evaluate( time )[ 0 ];\n\n\t\t\t\tweight *= interpolantValue;\n\n\t\t\t\tif ( time > interpolant.parameterPositions[ 1 ] ) {\n\n\t\t\t\t\tthis.stopFading();\n\n\t\t\t\t\tif ( interpolantValue === 0 ) {\n\n\t\t\t\t\t\t// faded out, disable\n\t\t\t\t\t\tthis.enabled = false;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tthis._effectiveWeight = weight;\n\t\treturn weight;\n\n\t}\n\n\t_updateTimeScale( time ) {\n\n\t\tlet timeScale = 0;\n\n\t\tif ( ! this.paused ) {\n\n\t\t\ttimeScale = this.timeScale;\n\n\t\t\tconst interpolant = this._timeScaleInterpolant;\n\n\t\t\tif ( interpolant !== null ) {\n\n\t\t\t\tconst interpolantValue = interpolant.evaluate( time )[ 0 ];\n\n\t\t\t\ttimeScale *= interpolantValue;\n\n\t\t\t\tif ( time > interpolant.parameterPositions[ 1 ] ) {\n\n\t\t\t\t\tthis.stopWarping();\n\n\t\t\t\t\tif ( timeScale === 0 ) {\n\n\t\t\t\t\t\t// motion has halted, pause\n\t\t\t\t\t\tthis.paused = true;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\t// warp done - apply final time scale\n\t\t\t\t\t\tthis.timeScale = timeScale;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tthis._effectiveTimeScale = timeScale;\n\t\treturn timeScale;\n\n\t}\n\n\t_updateTime( deltaTime ) {\n\n\t\tconst duration = this._clip.duration;\n\t\tconst loop = this.loop;\n\n\t\tlet time = this.time + deltaTime;\n\t\tlet loopCount = this._loopCount;\n\n\t\tconst pingPong = ( loop === LoopPingPong );\n\n\t\tif ( deltaTime === 0 ) {\n\n\t\t\tif ( loopCount === - 1 ) return time;\n\n\t\t\treturn ( pingPong && ( loopCount & 1 ) === 1 ) ? duration - time : time;\n\n\t\t}\n\n\t\tif ( loop === LoopOnce ) {\n\n\t\t\tif ( loopCount === - 1 ) {\n\n\t\t\t\t// just started\n\n\t\t\t\tthis._loopCount = 0;\n\t\t\t\tthis._setEndings( true, true, false );\n\n\t\t\t}\n\n\t\t\thandle_stop: {\n\n\t\t\t\tif ( time >= duration ) {\n\n\t\t\t\t\ttime = duration;\n\n\t\t\t\t} else if ( time < 0 ) {\n\n\t\t\t\t\ttime = 0;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthis.time = time;\n\n\t\t\t\t\tbreak handle_stop;\n\n\t\t\t\t}\n\n\t\t\t\tif ( this.clampWhenFinished ) this.paused = true;\n\t\t\t\telse this.enabled = false;\n\n\t\t\t\tthis.time = time;\n\n\t\t\t\tthis._mixer.dispatchEvent( {\n\t\t\t\t\ttype: 'finished', action: this,\n\t\t\t\t\tdirection: deltaTime < 0 ? - 1 : 1\n\t\t\t\t} );\n\n\t\t\t}\n\n\t\t} else { // repetitive Repeat or PingPong\n\n\t\t\tif ( loopCount === - 1 ) {\n\n\t\t\t\t// just started\n\n\t\t\t\tif ( deltaTime >= 0 ) {\n\n\t\t\t\t\tloopCount = 0;\n\n\t\t\t\t\tthis._setEndings( true, this.repetitions === 0, pingPong );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// when looping in reverse direction, the initial\n\t\t\t\t\t// transition through zero counts as a repetition,\n\t\t\t\t\t// so leave loopCount at -1\n\n\t\t\t\t\tthis._setEndings( this.repetitions === 0, true, pingPong );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( time >= duration || time < 0 ) {\n\n\t\t\t\t// wrap around\n\n\t\t\t\tconst loopDelta = Math.floor( time / duration ); // signed\n\t\t\t\ttime -= duration * loopDelta;\n\n\t\t\t\tloopCount += Math.abs( loopDelta );\n\n\t\t\t\tconst pending = this.repetitions - loopCount;\n\n\t\t\t\tif ( pending <= 0 ) {\n\n\t\t\t\t\t// have to stop (switch state, clamp time, fire event)\n\n\t\t\t\t\tif ( this.clampWhenFinished ) this.paused = true;\n\t\t\t\t\telse this.enabled = false;\n\n\t\t\t\t\ttime = deltaTime > 0 ? duration : 0;\n\n\t\t\t\t\tthis.time = time;\n\n\t\t\t\t\tthis._mixer.dispatchEvent( {\n\t\t\t\t\t\ttype: 'finished', action: this,\n\t\t\t\t\t\tdirection: deltaTime > 0 ? 1 : - 1\n\t\t\t\t\t} );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// keep running\n\n\t\t\t\t\tif ( pending === 1 ) {\n\n\t\t\t\t\t\t// entering the last round\n\n\t\t\t\t\t\tconst atStart = deltaTime < 0;\n\t\t\t\t\t\tthis._setEndings( atStart, ! atStart, pingPong );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tthis._setEndings( false, false, pingPong );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tthis._loopCount = loopCount;\n\n\t\t\t\t\tthis.time = time;\n\n\t\t\t\t\tthis._mixer.dispatchEvent( {\n\t\t\t\t\t\ttype: 'loop', action: this, loopDelta: loopDelta\n\t\t\t\t\t} );\n\n\t\t\t\t}\n\n\t\t\t} else {\n\n\t\t\t\tthis.time = time;\n\n\t\t\t}\n\n\t\t\tif ( pingPong && ( loopCount & 1 ) === 1 ) {\n\n\t\t\t\t// invert time for the \"pong round\"\n\n\t\t\t\treturn duration - time;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn time;\n\n\t}\n\n\t_setEndings( atStart, atEnd, pingPong ) {\n\n\t\tconst settings = this._interpolantSettings;\n\n\t\tif ( pingPong ) {\n\n\t\t\tsettings.endingStart = ZeroSlopeEnding;\n\t\t\tsettings.endingEnd = ZeroSlopeEnding;\n\n\t\t} else {\n\n\t\t\t// assuming for LoopOnce atStart == atEnd == true\n\n\t\t\tif ( atStart ) {\n\n\t\t\t\tsettings.endingStart = this.zeroSlopeAtStart ? ZeroSlopeEnding : ZeroCurvatureEnding;\n\n\t\t\t} else {\n\n\t\t\t\tsettings.endingStart = WrapAroundEnding;\n\n\t\t\t}\n\n\t\t\tif ( atEnd ) {\n\n\t\t\t\tsettings.endingEnd = this.zeroSlopeAtEnd ? ZeroSlopeEnding : ZeroCurvatureEnding;\n\n\t\t\t} else {\n\n\t\t\t\tsettings.endingEnd \t = WrapAroundEnding;\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t_scheduleFading( duration, weightNow, weightThen ) {\n\n\t\tconst mixer = this._mixer, now = mixer.time;\n\t\tlet interpolant = this._weightInterpolant;\n\n\t\tif ( interpolant === null ) {\n\n\t\t\tinterpolant = mixer._lendControlInterpolant();\n\t\t\tthis._weightInterpolant = interpolant;\n\n\t\t}\n\n\t\tconst times = interpolant.parameterPositions,\n\t\t\tvalues = interpolant.sampleValues;\n\n\t\ttimes[ 0 ] = now;\n\t\tvalues[ 0 ] = weightNow;\n\t\ttimes[ 1 ] = now + duration;\n\t\tvalues[ 1 ] = weightThen;\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass AnimationMixer extends EventDispatcher {\n\n\tconstructor( root ) {\n\n\t\tsuper();\n\n\t\tthis._root = root;\n\t\tthis._initMemoryManager();\n\t\tthis._accuIndex = 0;\n\t\tthis.time = 0;\n\t\tthis.timeScale = 1.0;\n\n\t}\n\n\t_bindAction( action, prototypeAction ) {\n\n\t\tconst root = action._localRoot || this._root,\n\t\t\ttracks = action._clip.tracks,\n\t\t\tnTracks = tracks.length,\n\t\t\tbindings = action._propertyBindings,\n\t\t\tinterpolants = action._interpolants,\n\t\t\trootUuid = root.uuid,\n\t\t\tbindingsByRoot = this._bindingsByRootAndName;\n\n\t\tlet bindingsByName = bindingsByRoot[ rootUuid ];\n\n\t\tif ( bindingsByName === undefined ) {\n\n\t\t\tbindingsByName = {};\n\t\t\tbindingsByRoot[ rootUuid ] = bindingsByName;\n\n\t\t}\n\n\t\tfor ( let i = 0; i !== nTracks; ++ i ) {\n\n\t\t\tconst track = tracks[ i ],\n\t\t\t\ttrackName = track.name;\n\n\t\t\tlet binding = bindingsByName[ trackName ];\n\n\t\t\tif ( binding !== undefined ) {\n\n\t\t\t\t++ binding.referenceCount;\n\t\t\t\tbindings[ i ] = binding;\n\n\t\t\t} else {\n\n\t\t\t\tbinding = bindings[ i ];\n\n\t\t\t\tif ( binding !== undefined ) {\n\n\t\t\t\t\t// existing binding, make sure the cache knows\n\n\t\t\t\t\tif ( binding._cacheIndex === null ) {\n\n\t\t\t\t\t\t++ binding.referenceCount;\n\t\t\t\t\t\tthis._addInactiveBinding( binding, rootUuid, trackName );\n\n\t\t\t\t\t}\n\n\t\t\t\t\tcontinue;\n\n\t\t\t\t}\n\n\t\t\t\tconst path = prototypeAction && prototypeAction.\n\t\t\t\t\t_propertyBindings[ i ].binding.parsedPath;\n\n\t\t\t\tbinding = new PropertyMixer(\n\t\t\t\t\tPropertyBinding.create( root, trackName, path ),\n\t\t\t\t\ttrack.ValueTypeName, track.getValueSize() );\n\n\t\t\t\t++ binding.referenceCount;\n\t\t\t\tthis._addInactiveBinding( binding, rootUuid, trackName );\n\n\t\t\t\tbindings[ i ] = binding;\n\n\t\t\t}\n\n\t\t\tinterpolants[ i ].resultBuffer = binding.buffer;\n\n\t\t}\n\n\t}\n\n\t_activateAction( action ) {\n\n\t\tif ( ! this._isActiveAction( action ) ) {\n\n\t\t\tif ( action._cacheIndex === null ) {\n\n\t\t\t\t// this action has been forgotten by the cache, but the user\n\t\t\t\t// appears to be still using it -> rebind\n\n\t\t\t\tconst rootUuid = ( action._localRoot || this._root ).uuid,\n\t\t\t\t\tclipUuid = action._clip.uuid,\n\t\t\t\t\tactionsForClip = this._actionsByClip[ clipUuid ];\n\n\t\t\t\tthis._bindAction( action,\n\t\t\t\t\tactionsForClip && actionsForClip.knownActions[ 0 ] );\n\n\t\t\t\tthis._addInactiveAction( action, clipUuid, rootUuid );\n\n\t\t\t}\n\n\t\t\tconst bindings = action._propertyBindings;\n\n\t\t\t// increment reference counts / sort out state\n\t\t\tfor ( let i = 0, n = bindings.length; i !== n; ++ i ) {\n\n\t\t\t\tconst binding = bindings[ i ];\n\n\t\t\t\tif ( binding.useCount ++ === 0 ) {\n\n\t\t\t\t\tthis._lendBinding( binding );\n\t\t\t\t\tbinding.saveOriginalState();\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis._lendAction( action );\n\n\t\t}\n\n\t}\n\n\t_deactivateAction( action ) {\n\n\t\tif ( this._isActiveAction( action ) ) {\n\n\t\t\tconst bindings = action._propertyBindings;\n\n\t\t\t// decrement reference counts / sort out state\n\t\t\tfor ( let i = 0, n = bindings.length; i !== n; ++ i ) {\n\n\t\t\t\tconst binding = bindings[ i ];\n\n\t\t\t\tif ( -- binding.useCount === 0 ) {\n\n\t\t\t\t\tbinding.restoreOriginalState();\n\t\t\t\t\tthis._takeBackBinding( binding );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tthis._takeBackAction( action );\n\n\t\t}\n\n\t}\n\n\t// Memory manager\n\n\t_initMemoryManager() {\n\n\t\tthis._actions = []; // 'nActiveActions' followed by inactive ones\n\t\tthis._nActiveActions = 0;\n\n\t\tthis._actionsByClip = {};\n\t\t// inside:\n\t\t// {\n\t\t// \tknownActions: Array< AnimationAction > - used as prototypes\n\t\t// \tactionByRoot: AnimationAction - lookup\n\t\t// }\n\n\n\t\tthis._bindings = []; // 'nActiveBindings' followed by inactive ones\n\t\tthis._nActiveBindings = 0;\n\n\t\tthis._bindingsByRootAndName = {}; // inside: Map< name, PropertyMixer >\n\n\n\t\tthis._controlInterpolants = []; // same game as above\n\t\tthis._nActiveControlInterpolants = 0;\n\n\t\tconst scope = this;\n\n\t\tthis.stats = {\n\n\t\t\tactions: {\n\t\t\t\tget total() {\n\n\t\t\t\t\treturn scope._actions.length;\n\n\t\t\t\t},\n\t\t\t\tget inUse() {\n\n\t\t\t\t\treturn scope._nActiveActions;\n\n\t\t\t\t}\n\t\t\t},\n\t\t\tbindings: {\n\t\t\t\tget total() {\n\n\t\t\t\t\treturn scope._bindings.length;\n\n\t\t\t\t},\n\t\t\t\tget inUse() {\n\n\t\t\t\t\treturn scope._nActiveBindings;\n\n\t\t\t\t}\n\t\t\t},\n\t\t\tcontrolInterpolants: {\n\t\t\t\tget total() {\n\n\t\t\t\t\treturn scope._controlInterpolants.length;\n\n\t\t\t\t},\n\t\t\t\tget inUse() {\n\n\t\t\t\t\treturn scope._nActiveControlInterpolants;\n\n\t\t\t\t}\n\t\t\t}\n\n\t\t};\n\n\t}\n\n\t// Memory management for AnimationAction objects\n\n\t_isActiveAction( action ) {\n\n\t\tconst index = action._cacheIndex;\n\t\treturn index !== null && index < this._nActiveActions;\n\n\t}\n\n\t_addInactiveAction( action, clipUuid, rootUuid ) {\n\n\t\tconst actions = this._actions,\n\t\t\tactionsByClip = this._actionsByClip;\n\n\t\tlet actionsForClip = actionsByClip[ clipUuid ];\n\n\t\tif ( actionsForClip === undefined ) {\n\n\t\t\tactionsForClip = {\n\n\t\t\t\tknownActions: [ action ],\n\t\t\t\tactionByRoot: {}\n\n\t\t\t};\n\n\t\t\taction._byClipCacheIndex = 0;\n\n\t\t\tactionsByClip[ clipUuid ] = actionsForClip;\n\n\t\t} else {\n\n\t\t\tconst knownActions = actionsForClip.knownActions;\n\n\t\t\taction._byClipCacheIndex = knownActions.length;\n\t\t\tknownActions.push( action );\n\n\t\t}\n\n\t\taction._cacheIndex = actions.length;\n\t\tactions.push( action );\n\n\t\tactionsForClip.actionByRoot[ rootUuid ] = action;\n\n\t}\n\n\t_removeInactiveAction( action ) {\n\n\t\tconst actions = this._actions,\n\t\t\tlastInactiveAction = actions[ actions.length - 1 ],\n\t\t\tcacheIndex = action._cacheIndex;\n\n\t\tlastInactiveAction._cacheIndex = cacheIndex;\n\t\tactions[ cacheIndex ] = lastInactiveAction;\n\t\tactions.pop();\n\n\t\taction._cacheIndex = null;\n\n\n\t\tconst clipUuid = action._clip.uuid,\n\t\t\tactionsByClip = this._actionsByClip,\n\t\t\tactionsForClip = actionsByClip[ clipUuid ],\n\t\t\tknownActionsForClip = actionsForClip.knownActions,\n\n\t\t\tlastKnownAction =\n\t\t\t\tknownActionsForClip[ knownActionsForClip.length - 1 ],\n\n\t\t\tbyClipCacheIndex = action._byClipCacheIndex;\n\n\t\tlastKnownAction._byClipCacheIndex = byClipCacheIndex;\n\t\tknownActionsForClip[ byClipCacheIndex ] = lastKnownAction;\n\t\tknownActionsForClip.pop();\n\n\t\taction._byClipCacheIndex = null;\n\n\n\t\tconst actionByRoot = actionsForClip.actionByRoot,\n\t\t\trootUuid = ( action._localRoot || this._root ).uuid;\n\n\t\tdelete actionByRoot[ rootUuid ];\n\n\t\tif ( knownActionsForClip.length === 0 ) {\n\n\t\t\tdelete actionsByClip[ clipUuid ];\n\n\t\t}\n\n\t\tthis._removeInactiveBindingsForAction( action );\n\n\t}\n\n\t_removeInactiveBindingsForAction( action ) {\n\n\t\tconst bindings = action._propertyBindings;\n\n\t\tfor ( let i = 0, n = bindings.length; i !== n; ++ i ) {\n\n\t\t\tconst binding = bindings[ i ];\n\n\t\t\tif ( -- binding.referenceCount === 0 ) {\n\n\t\t\t\tthis._removeInactiveBinding( binding );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t_lendAction( action ) {\n\n\t\t// [ active actions |  inactive actions  ]\n\t\t// [  active actions >| inactive actions ]\n\t\t//                 s        a\n\t\t//                  <-swap->\n\t\t//                 a        s\n\n\t\tconst actions = this._actions,\n\t\t\tprevIndex = action._cacheIndex,\n\n\t\t\tlastActiveIndex = this._nActiveActions ++,\n\n\t\t\tfirstInactiveAction = actions[ lastActiveIndex ];\n\n\t\taction._cacheIndex = lastActiveIndex;\n\t\tactions[ lastActiveIndex ] = action;\n\n\t\tfirstInactiveAction._cacheIndex = prevIndex;\n\t\tactions[ prevIndex ] = firstInactiveAction;\n\n\t}\n\n\t_takeBackAction( action ) {\n\n\t\t// [  active actions  | inactive actions ]\n\t\t// [ active actions |< inactive actions  ]\n\t\t//        a        s\n\t\t//         <-swap->\n\t\t//        s        a\n\n\t\tconst actions = this._actions,\n\t\t\tprevIndex = action._cacheIndex,\n\n\t\t\tfirstInactiveIndex = -- this._nActiveActions,\n\n\t\t\tlastActiveAction = actions[ firstInactiveIndex ];\n\n\t\taction._cacheIndex = firstInactiveIndex;\n\t\tactions[ firstInactiveIndex ] = action;\n\n\t\tlastActiveAction._cacheIndex = prevIndex;\n\t\tactions[ prevIndex ] = lastActiveAction;\n\n\t}\n\n\t// Memory management for PropertyMixer objects\n\n\t_addInactiveBinding( binding, rootUuid, trackName ) {\n\n\t\tconst bindingsByRoot = this._bindingsByRootAndName,\n\t\t\tbindings = this._bindings;\n\n\t\tlet bindingByName = bindingsByRoot[ rootUuid ];\n\n\t\tif ( bindingByName === undefined ) {\n\n\t\t\tbindingByName = {};\n\t\t\tbindingsByRoot[ rootUuid ] = bindingByName;\n\n\t\t}\n\n\t\tbindingByName[ trackName ] = binding;\n\n\t\tbinding._cacheIndex = bindings.length;\n\t\tbindings.push( binding );\n\n\t}\n\n\t_removeInactiveBinding( binding ) {\n\n\t\tconst bindings = this._bindings,\n\t\t\tpropBinding = binding.binding,\n\t\t\trootUuid = propBinding.rootNode.uuid,\n\t\t\ttrackName = propBinding.path,\n\t\t\tbindingsByRoot = this._bindingsByRootAndName,\n\t\t\tbindingByName = bindingsByRoot[ rootUuid ],\n\n\t\t\tlastInactiveBinding = bindings[ bindings.length - 1 ],\n\t\t\tcacheIndex = binding._cacheIndex;\n\n\t\tlastInactiveBinding._cacheIndex = cacheIndex;\n\t\tbindings[ cacheIndex ] = lastInactiveBinding;\n\t\tbindings.pop();\n\n\t\tdelete bindingByName[ trackName ];\n\n\t\tif ( Object.keys( bindingByName ).length === 0 ) {\n\n\t\t\tdelete bindingsByRoot[ rootUuid ];\n\n\t\t}\n\n\t}\n\n\t_lendBinding( binding ) {\n\n\t\tconst bindings = this._bindings,\n\t\t\tprevIndex = binding._cacheIndex,\n\n\t\t\tlastActiveIndex = this._nActiveBindings ++,\n\n\t\t\tfirstInactiveBinding = bindings[ lastActiveIndex ];\n\n\t\tbinding._cacheIndex = lastActiveIndex;\n\t\tbindings[ lastActiveIndex ] = binding;\n\n\t\tfirstInactiveBinding._cacheIndex = prevIndex;\n\t\tbindings[ prevIndex ] = firstInactiveBinding;\n\n\t}\n\n\t_takeBackBinding( binding ) {\n\n\t\tconst bindings = this._bindings,\n\t\t\tprevIndex = binding._cacheIndex,\n\n\t\t\tfirstInactiveIndex = -- this._nActiveBindings,\n\n\t\t\tlastActiveBinding = bindings[ firstInactiveIndex ];\n\n\t\tbinding._cacheIndex = firstInactiveIndex;\n\t\tbindings[ firstInactiveIndex ] = binding;\n\n\t\tlastActiveBinding._cacheIndex = prevIndex;\n\t\tbindings[ prevIndex ] = lastActiveBinding;\n\n\t}\n\n\n\t// Memory management of Interpolants for weight and time scale\n\n\t_lendControlInterpolant() {\n\n\t\tconst interpolants = this._controlInterpolants,\n\t\t\tlastActiveIndex = this._nActiveControlInterpolants ++;\n\n\t\tlet interpolant = interpolants[ lastActiveIndex ];\n\n\t\tif ( interpolant === undefined ) {\n\n\t\t\tinterpolant = new LinearInterpolant(\n\t\t\t\tnew Float32Array( 2 ), new Float32Array( 2 ),\n\t\t\t\t1, this._controlInterpolantsResultBuffer );\n\n\t\t\tinterpolant.__cacheIndex = lastActiveIndex;\n\t\t\tinterpolants[ lastActiveIndex ] = interpolant;\n\n\t\t}\n\n\t\treturn interpolant;\n\n\t}\n\n\t_takeBackControlInterpolant( interpolant ) {\n\n\t\tconst interpolants = this._controlInterpolants,\n\t\t\tprevIndex = interpolant.__cacheIndex,\n\n\t\t\tfirstInactiveIndex = -- this._nActiveControlInterpolants,\n\n\t\t\tlastActiveInterpolant = interpolants[ firstInactiveIndex ];\n\n\t\tinterpolant.__cacheIndex = firstInactiveIndex;\n\t\tinterpolants[ firstInactiveIndex ] = interpolant;\n\n\t\tlastActiveInterpolant.__cacheIndex = prevIndex;\n\t\tinterpolants[ prevIndex ] = lastActiveInterpolant;\n\n\t}\n\n\t// return an action for a clip optionally using a custom root target\n\t// object (this method allocates a lot of dynamic memory in case a\n\t// previously unknown clip/root combination is specified)\n\tclipAction( clip, optionalRoot, blendMode ) {\n\n\t\tconst root = optionalRoot || this._root,\n\t\t\trootUuid = root.uuid;\n\n\t\tlet clipObject = typeof clip === 'string' ? AnimationClip.findByName( root, clip ) : clip;\n\n\t\tconst clipUuid = clipObject !== null ? clipObject.uuid : clip;\n\n\t\tconst actionsForClip = this._actionsByClip[ clipUuid ];\n\t\tlet prototypeAction = null;\n\n\t\tif ( blendMode === undefined ) {\n\n\t\t\tif ( clipObject !== null ) {\n\n\t\t\t\tblendMode = clipObject.blendMode;\n\n\t\t\t} else {\n\n\t\t\t\tblendMode = NormalAnimationBlendMode;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( actionsForClip !== undefined ) {\n\n\t\t\tconst existingAction = actionsForClip.actionByRoot[ rootUuid ];\n\n\t\t\tif ( existingAction !== undefined && existingAction.blendMode === blendMode ) {\n\n\t\t\t\treturn existingAction;\n\n\t\t\t}\n\n\t\t\t// we know the clip, so we don't have to parse all\n\t\t\t// the bindings again but can just copy\n\t\t\tprototypeAction = actionsForClip.knownActions[ 0 ];\n\n\t\t\t// also, take the clip from the prototype action\n\t\t\tif ( clipObject === null )\n\t\t\t\tclipObject = prototypeAction._clip;\n\n\t\t}\n\n\t\t// clip must be known when specified via string\n\t\tif ( clipObject === null ) return null;\n\n\t\t// allocate all resources required to run it\n\t\tconst newAction = new AnimationAction( this, clipObject, optionalRoot, blendMode );\n\n\t\tthis._bindAction( newAction, prototypeAction );\n\n\t\t// and make the action known to the memory manager\n\t\tthis._addInactiveAction( newAction, clipUuid, rootUuid );\n\n\t\treturn newAction;\n\n\t}\n\n\t// get an existing action\n\texistingAction( clip, optionalRoot ) {\n\n\t\tconst root = optionalRoot || this._root,\n\t\t\trootUuid = root.uuid,\n\n\t\t\tclipObject = typeof clip === 'string' ?\n\t\t\t\tAnimationClip.findByName( root, clip ) : clip,\n\n\t\t\tclipUuid = clipObject ? clipObject.uuid : clip,\n\n\t\t\tactionsForClip = this._actionsByClip[ clipUuid ];\n\n\t\tif ( actionsForClip !== undefined ) {\n\n\t\t\treturn actionsForClip.actionByRoot[ rootUuid ] || null;\n\n\t\t}\n\n\t\treturn null;\n\n\t}\n\n\t// deactivates all previously scheduled actions\n\tstopAllAction() {\n\n\t\tconst actions = this._actions,\n\t\t\tnActions = this._nActiveActions;\n\n\t\tfor ( let i = nActions - 1; i >= 0; -- i ) {\n\n\t\t\tactions[ i ].stop();\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// advance the time and update apply the animation\n\tupdate( deltaTime ) {\n\n\t\tdeltaTime *= this.timeScale;\n\n\t\tconst actions = this._actions,\n\t\t\tnActions = this._nActiveActions,\n\n\t\t\ttime = this.time += deltaTime,\n\t\t\ttimeDirection = Math.sign( deltaTime ),\n\n\t\t\taccuIndex = this._accuIndex ^= 1;\n\n\t\t// run active actions\n\n\t\tfor ( let i = 0; i !== nActions; ++ i ) {\n\n\t\t\tconst action = actions[ i ];\n\n\t\t\taction._update( time, deltaTime, timeDirection, accuIndex );\n\n\t\t}\n\n\t\t// update scene graph\n\n\t\tconst bindings = this._bindings,\n\t\t\tnBindings = this._nActiveBindings;\n\n\t\tfor ( let i = 0; i !== nBindings; ++ i ) {\n\n\t\t\tbindings[ i ].apply( accuIndex );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\t// Allows you to seek to a specific time in an animation.\n\tsetTime( timeInSeconds ) {\n\n\t\tthis.time = 0; // Zero out time attribute for AnimationMixer object;\n\t\tfor ( let i = 0; i < this._actions.length; i ++ ) {\n\n\t\t\tthis._actions[ i ].time = 0; // Zero out time attribute for all associated AnimationAction objects.\n\n\t\t}\n\n\t\treturn this.update( timeInSeconds ); // Update used to set exact time. Returns \"this\" AnimationMixer object.\n\n\t}\n\n\t// return this mixer's root target object\n\tgetRoot() {\n\n\t\treturn this._root;\n\n\t}\n\n\t// free all resources specific to a particular clip\n\tuncacheClip( clip ) {\n\n\t\tconst actions = this._actions,\n\t\t\tclipUuid = clip.uuid,\n\t\t\tactionsByClip = this._actionsByClip,\n\t\t\tactionsForClip = actionsByClip[ clipUuid ];\n\n\t\tif ( actionsForClip !== undefined ) {\n\n\t\t\t// note: just calling _removeInactiveAction would mess up the\n\t\t\t// iteration state and also require updating the state we can\n\t\t\t// just throw away\n\n\t\t\tconst actionsToRemove = actionsForClip.knownActions;\n\n\t\t\tfor ( let i = 0, n = actionsToRemove.length; i !== n; ++ i ) {\n\n\t\t\t\tconst action = actionsToRemove[ i ];\n\n\t\t\t\tthis._deactivateAction( action );\n\n\t\t\t\tconst cacheIndex = action._cacheIndex,\n\t\t\t\t\tlastInactiveAction = actions[ actions.length - 1 ];\n\n\t\t\t\taction._cacheIndex = null;\n\t\t\t\taction._byClipCacheIndex = null;\n\n\t\t\t\tlastInactiveAction._cacheIndex = cacheIndex;\n\t\t\t\tactions[ cacheIndex ] = lastInactiveAction;\n\t\t\t\tactions.pop();\n\n\t\t\t\tthis._removeInactiveBindingsForAction( action );\n\n\t\t\t}\n\n\t\t\tdelete actionsByClip[ clipUuid ];\n\n\t\t}\n\n\t}\n\n\t// free all resources specific to a particular root target object\n\tuncacheRoot( root ) {\n\n\t\tconst rootUuid = root.uuid,\n\t\t\tactionsByClip = this._actionsByClip;\n\n\t\tfor ( const clipUuid in actionsByClip ) {\n\n\t\t\tconst actionByRoot = actionsByClip[ clipUuid ].actionByRoot,\n\t\t\t\taction = actionByRoot[ rootUuid ];\n\n\t\t\tif ( action !== undefined ) {\n\n\t\t\t\tthis._deactivateAction( action );\n\t\t\t\tthis._removeInactiveAction( action );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst bindingsByRoot = this._bindingsByRootAndName,\n\t\t\tbindingByName = bindingsByRoot[ rootUuid ];\n\n\t\tif ( bindingByName !== undefined ) {\n\n\t\t\tfor ( const trackName in bindingByName ) {\n\n\t\t\t\tconst binding = bindingByName[ trackName ];\n\t\t\t\tbinding.restoreOriginalState();\n\t\t\t\tthis._removeInactiveBinding( binding );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t// remove a targeted clip from the cache\n\tuncacheAction( clip, optionalRoot ) {\n\n\t\tconst action = this.existingAction( clip, optionalRoot );\n\n\t\tif ( action !== null ) {\n\n\t\t\tthis._deactivateAction( action );\n\t\t\tthis._removeInactiveAction( action );\n\n\t\t}\n\n\t}\n\n}\n\nAnimationMixer.prototype._controlInterpolantsResultBuffer = new Float32Array( 1 );\n\nclass Uniform {\n\n\tconstructor( value ) {\n\n\t\tif ( typeof value === 'string' ) {\n\n\t\t\tconsole.warn( 'THREE.Uniform: Type parameter is no longer needed.' );\n\t\t\tvalue = arguments[ 1 ];\n\n\t\t}\n\n\t\tthis.value = value;\n\n\t}\n\n\tclone() {\n\n\t\treturn new Uniform( this.value.clone === undefined ? this.value : this.value.clone() );\n\n\t}\n\n}\n\nclass InstancedInterleavedBuffer extends InterleavedBuffer {\n\n\tconstructor( array, stride, meshPerAttribute = 1 ) {\n\n\t\tsuper( array, stride );\n\n\t\tthis.meshPerAttribute = meshPerAttribute;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.meshPerAttribute = source.meshPerAttribute;\n\n\t\treturn this;\n\n\t}\n\n\tclone( data ) {\n\n\t\tconst ib = super.clone( data );\n\n\t\tib.meshPerAttribute = this.meshPerAttribute;\n\n\t\treturn ib;\n\n\t}\n\n\ttoJSON( data ) {\n\n\t\tconst json = super.toJSON( data );\n\n\t\tjson.isInstancedInterleavedBuffer = true;\n\t\tjson.meshPerAttribute = this.meshPerAttribute;\n\n\t\treturn json;\n\n\t}\n\n}\n\nInstancedInterleavedBuffer.prototype.isInstancedInterleavedBuffer = true;\n\nclass GLBufferAttribute {\n\n\tconstructor( buffer, type, itemSize, elementSize, count ) {\n\n\t\tthis.buffer = buffer;\n\t\tthis.type = type;\n\t\tthis.itemSize = itemSize;\n\t\tthis.elementSize = elementSize;\n\t\tthis.count = count;\n\n\t\tthis.version = 0;\n\n\t}\n\n\tset needsUpdate( value ) {\n\n\t\tif ( value === true ) this.version ++;\n\n\t}\n\n\tsetBuffer( buffer ) {\n\n\t\tthis.buffer = buffer;\n\n\t\treturn this;\n\n\t}\n\n\tsetType( type, elementSize ) {\n\n\t\tthis.type = type;\n\t\tthis.elementSize = elementSize;\n\n\t\treturn this;\n\n\t}\n\n\tsetItemSize( itemSize ) {\n\n\t\tthis.itemSize = itemSize;\n\n\t\treturn this;\n\n\t}\n\n\tsetCount( count ) {\n\n\t\tthis.count = count;\n\n\t\treturn this;\n\n\t}\n\n}\n\nGLBufferAttribute.prototype.isGLBufferAttribute = true;\n\nclass Raycaster {\n\n\tconstructor( origin, direction, near = 0, far = Infinity ) {\n\n\t\tthis.ray = new Ray( origin, direction );\n\t\t// direction is assumed to be normalized (for accurate distance calculations)\n\n\t\tthis.near = near;\n\t\tthis.far = far;\n\t\tthis.camera = null;\n\t\tthis.layers = new Layers();\n\n\t\tthis.params = {\n\t\t\tMesh: {},\n\t\t\tLine: { threshold: 1 },\n\t\t\tLOD: {},\n\t\t\tPoints: { threshold: 1 },\n\t\t\tSprite: {}\n\t\t};\n\n\t}\n\n\tset( origin, direction ) {\n\n\t\t// direction is assumed to be normalized (for accurate distance calculations)\n\n\t\tthis.ray.set( origin, direction );\n\n\t}\n\n\tsetFromCamera( coords, camera ) {\n\n\t\tif ( camera.isPerspectiveCamera ) {\n\n\t\t\tthis.ray.origin.setFromMatrixPosition( camera.matrixWorld );\n\t\t\tthis.ray.direction.set( coords.x, coords.y, 0.5 ).unproject( camera ).sub( this.ray.origin ).normalize();\n\t\t\tthis.camera = camera;\n\n\t\t} else if ( camera.isOrthographicCamera ) {\n\n\t\t\tthis.ray.origin.set( coords.x, coords.y, ( camera.near + camera.far ) / ( camera.near - camera.far ) ).unproject( camera ); // set origin in plane of camera\n\t\t\tthis.ray.direction.set( 0, 0, - 1 ).transformDirection( camera.matrixWorld );\n\t\t\tthis.camera = camera;\n\n\t\t} else {\n\n\t\t\tconsole.error( 'THREE.Raycaster: Unsupported camera type: ' + camera.type );\n\n\t\t}\n\n\t}\n\n\tintersectObject( object, recursive = true, intersects = [] ) {\n\n\t\tintersectObject( object, this, intersects, recursive );\n\n\t\tintersects.sort( ascSort );\n\n\t\treturn intersects;\n\n\t}\n\n\tintersectObjects( objects, recursive = true, intersects = [] ) {\n\n\t\tfor ( let i = 0, l = objects.length; i < l; i ++ ) {\n\n\t\t\tintersectObject( objects[ i ], this, intersects, recursive );\n\n\t\t}\n\n\t\tintersects.sort( ascSort );\n\n\t\treturn intersects;\n\n\t}\n\n}\n\nfunction ascSort( a, b ) {\n\n\treturn a.distance - b.distance;\n\n}\n\nfunction intersectObject( object, raycaster, intersects, recursive ) {\n\n\tif ( object.layers.test( raycaster.layers ) ) {\n\n\t\tobject.raycast( raycaster, intersects );\n\n\t}\n\n\tif ( recursive === true ) {\n\n\t\tconst children = object.children;\n\n\t\tfor ( let i = 0, l = children.length; i < l; i ++ ) {\n\n\t\t\tintersectObject( children[ i ], raycaster, intersects, true );\n\n\t\t}\n\n\t}\n\n}\n\n/**\n * Ref: https://en.wikipedia.org/wiki/Spherical_coordinate_system\n *\n * The polar angle (phi) is measured from the positive y-axis. The positive y-axis is up.\n * The azimuthal angle (theta) is measured from the positive z-axis.\n */\n\nclass Spherical {\n\n\tconstructor( radius = 1, phi = 0, theta = 0 ) {\n\n\t\tthis.radius = radius;\n\t\tthis.phi = phi; // polar angle\n\t\tthis.theta = theta; // azimuthal angle\n\n\t\treturn this;\n\n\t}\n\n\tset( radius, phi, theta ) {\n\n\t\tthis.radius = radius;\n\t\tthis.phi = phi;\n\t\tthis.theta = theta;\n\n\t\treturn this;\n\n\t}\n\n\tcopy( other ) {\n\n\t\tthis.radius = other.radius;\n\t\tthis.phi = other.phi;\n\t\tthis.theta = other.theta;\n\n\t\treturn this;\n\n\t}\n\n\t// restrict phi to be betwee EPS and PI-EPS\n\tmakeSafe() {\n\n\t\tconst EPS = 0.000001;\n\t\tthis.phi = Math.max( EPS, Math.min( Math.PI - EPS, this.phi ) );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromVector3( v ) {\n\n\t\treturn this.setFromCartesianCoords( v.x, v.y, v.z );\n\n\t}\n\n\tsetFromCartesianCoords( x, y, z ) {\n\n\t\tthis.radius = Math.sqrt( x * x + y * y + z * z );\n\n\t\tif ( this.radius === 0 ) {\n\n\t\t\tthis.theta = 0;\n\t\t\tthis.phi = 0;\n\n\t\t} else {\n\n\t\t\tthis.theta = Math.atan2( x, z );\n\t\t\tthis.phi = Math.acos( clamp( y / this.radius, - 1, 1 ) );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\n/**\n * Ref: https://en.wikipedia.org/wiki/Cylindrical_coordinate_system\n */\n\nclass Cylindrical {\n\n\tconstructor( radius = 1, theta = 0, y = 0 ) {\n\n\t\tthis.radius = radius; // distance from the origin to a point in the x-z plane\n\t\tthis.theta = theta; // counterclockwise angle in the x-z plane measured in radians from the positive z-axis\n\t\tthis.y = y; // height above the x-z plane\n\n\t\treturn this;\n\n\t}\n\n\tset( radius, theta, y ) {\n\n\t\tthis.radius = radius;\n\t\tthis.theta = theta;\n\t\tthis.y = y;\n\n\t\treturn this;\n\n\t}\n\n\tcopy( other ) {\n\n\t\tthis.radius = other.radius;\n\t\tthis.theta = other.theta;\n\t\tthis.y = other.y;\n\n\t\treturn this;\n\n\t}\n\n\tsetFromVector3( v ) {\n\n\t\treturn this.setFromCartesianCoords( v.x, v.y, v.z );\n\n\t}\n\n\tsetFromCartesianCoords( x, y, z ) {\n\n\t\tthis.radius = Math.sqrt( x * x + z * z );\n\t\tthis.theta = Math.atan2( x, z );\n\t\tthis.y = y;\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nconst _vector$4 = /*@__PURE__*/ new Vector2();\n\nclass Box2 {\n\n\tconstructor( min = new Vector2( + Infinity, + Infinity ), max = new Vector2( - Infinity, - Infinity ) ) {\n\n\t\tthis.min = min;\n\t\tthis.max = max;\n\n\t}\n\n\tset( min, max ) {\n\n\t\tthis.min.copy( min );\n\t\tthis.max.copy( max );\n\n\t\treturn this;\n\n\t}\n\n\tsetFromPoints( points ) {\n\n\t\tthis.makeEmpty();\n\n\t\tfor ( let i = 0, il = points.length; i < il; i ++ ) {\n\n\t\t\tthis.expandByPoint( points[ i ] );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tsetFromCenterAndSize( center, size ) {\n\n\t\tconst halfSize = _vector$4.copy( size ).multiplyScalar( 0.5 );\n\t\tthis.min.copy( center ).sub( halfSize );\n\t\tthis.max.copy( center ).add( halfSize );\n\n\t\treturn this;\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n\tcopy( box ) {\n\n\t\tthis.min.copy( box.min );\n\t\tthis.max.copy( box.max );\n\n\t\treturn this;\n\n\t}\n\n\tmakeEmpty() {\n\n\t\tthis.min.x = this.min.y = + Infinity;\n\t\tthis.max.x = this.max.y = - Infinity;\n\n\t\treturn this;\n\n\t}\n\n\tisEmpty() {\n\n\t\t// this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes\n\n\t\treturn ( this.max.x < this.min.x ) || ( this.max.y < this.min.y );\n\n\t}\n\n\tgetCenter( target ) {\n\n\t\treturn this.isEmpty() ? target.set( 0, 0 ) : target.addVectors( this.min, this.max ).multiplyScalar( 0.5 );\n\n\t}\n\n\tgetSize( target ) {\n\n\t\treturn this.isEmpty() ? target.set( 0, 0 ) : target.subVectors( this.max, this.min );\n\n\t}\n\n\texpandByPoint( point ) {\n\n\t\tthis.min.min( point );\n\t\tthis.max.max( point );\n\n\t\treturn this;\n\n\t}\n\n\texpandByVector( vector ) {\n\n\t\tthis.min.sub( vector );\n\t\tthis.max.add( vector );\n\n\t\treturn this;\n\n\t}\n\n\texpandByScalar( scalar ) {\n\n\t\tthis.min.addScalar( - scalar );\n\t\tthis.max.addScalar( scalar );\n\n\t\treturn this;\n\n\t}\n\n\tcontainsPoint( point ) {\n\n\t\treturn point.x < this.min.x || point.x > this.max.x ||\n\t\t\tpoint.y < this.min.y || point.y > this.max.y ? false : true;\n\n\t}\n\n\tcontainsBox( box ) {\n\n\t\treturn this.min.x <= box.min.x && box.max.x <= this.max.x &&\n\t\t\tthis.min.y <= box.min.y && box.max.y <= this.max.y;\n\n\t}\n\n\tgetParameter( point, target ) {\n\n\t\t// This can potentially have a divide by zero if the box\n\t\t// has a size dimension of 0.\n\n\t\treturn target.set(\n\t\t\t( point.x - this.min.x ) / ( this.max.x - this.min.x ),\n\t\t\t( point.y - this.min.y ) / ( this.max.y - this.min.y )\n\t\t);\n\n\t}\n\n\tintersectsBox( box ) {\n\n\t\t// using 4 splitting planes to rule out intersections\n\n\t\treturn box.max.x < this.min.x || box.min.x > this.max.x ||\n\t\t\tbox.max.y < this.min.y || box.min.y > this.max.y ? false : true;\n\n\t}\n\n\tclampPoint( point, target ) {\n\n\t\treturn target.copy( point ).clamp( this.min, this.max );\n\n\t}\n\n\tdistanceToPoint( point ) {\n\n\t\tconst clampedPoint = _vector$4.copy( point ).clamp( this.min, this.max );\n\t\treturn clampedPoint.sub( point ).length();\n\n\t}\n\n\tintersect( box ) {\n\n\t\tthis.min.max( box.min );\n\t\tthis.max.min( box.max );\n\n\t\treturn this;\n\n\t}\n\n\tunion( box ) {\n\n\t\tthis.min.min( box.min );\n\t\tthis.max.max( box.max );\n\n\t\treturn this;\n\n\t}\n\n\ttranslate( offset ) {\n\n\t\tthis.min.add( offset );\n\t\tthis.max.add( offset );\n\n\t\treturn this;\n\n\t}\n\n\tequals( box ) {\n\n\t\treturn box.min.equals( this.min ) && box.max.equals( this.max );\n\n\t}\n\n}\n\nBox2.prototype.isBox2 = true;\n\nconst _startP = /*@__PURE__*/ new Vector3();\nconst _startEnd = /*@__PURE__*/ new Vector3();\n\nclass Line3 {\n\n\tconstructor( start = new Vector3(), end = new Vector3() ) {\n\n\t\tthis.start = start;\n\t\tthis.end = end;\n\n\t}\n\n\tset( start, end ) {\n\n\t\tthis.start.copy( start );\n\t\tthis.end.copy( end );\n\n\t\treturn this;\n\n\t}\n\n\tcopy( line ) {\n\n\t\tthis.start.copy( line.start );\n\t\tthis.end.copy( line.end );\n\n\t\treturn this;\n\n\t}\n\n\tgetCenter( target ) {\n\n\t\treturn target.addVectors( this.start, this.end ).multiplyScalar( 0.5 );\n\n\t}\n\n\tdelta( target ) {\n\n\t\treturn target.subVectors( this.end, this.start );\n\n\t}\n\n\tdistanceSq() {\n\n\t\treturn this.start.distanceToSquared( this.end );\n\n\t}\n\n\tdistance() {\n\n\t\treturn this.start.distanceTo( this.end );\n\n\t}\n\n\tat( t, target ) {\n\n\t\treturn this.delta( target ).multiplyScalar( t ).add( this.start );\n\n\t}\n\n\tclosestPointToPointParameter( point, clampToLine ) {\n\n\t\t_startP.subVectors( point, this.start );\n\t\t_startEnd.subVectors( this.end, this.start );\n\n\t\tconst startEnd2 = _startEnd.dot( _startEnd );\n\t\tconst startEnd_startP = _startEnd.dot( _startP );\n\n\t\tlet t = startEnd_startP / startEnd2;\n\n\t\tif ( clampToLine ) {\n\n\t\t\tt = clamp( t, 0, 1 );\n\n\t\t}\n\n\t\treturn t;\n\n\t}\n\n\tclosestPointToPoint( point, clampToLine, target ) {\n\n\t\tconst t = this.closestPointToPointParameter( point, clampToLine );\n\n\t\treturn this.delta( target ).multiplyScalar( t ).add( this.start );\n\n\t}\n\n\tapplyMatrix4( matrix ) {\n\n\t\tthis.start.applyMatrix4( matrix );\n\t\tthis.end.applyMatrix4( matrix );\n\n\t\treturn this;\n\n\t}\n\n\tequals( line ) {\n\n\t\treturn line.start.equals( this.start ) && line.end.equals( this.end );\n\n\t}\n\n\tclone() {\n\n\t\treturn new this.constructor().copy( this );\n\n\t}\n\n}\n\nconst _vector$3 = /*@__PURE__*/ new Vector3();\n\nclass SpotLightHelper extends Object3D {\n\n\tconstructor( light, color ) {\n\n\t\tsuper();\n\t\tthis.light = light;\n\t\tthis.light.updateMatrixWorld();\n\n\t\tthis.matrix = light.matrixWorld;\n\t\tthis.matrixAutoUpdate = false;\n\n\t\tthis.color = color;\n\n\t\tconst geometry = new BufferGeometry();\n\n\t\tconst positions = [\n\t\t\t0, 0, 0, \t0, 0, 1,\n\t\t\t0, 0, 0, \t1, 0, 1,\n\t\t\t0, 0, 0,\t- 1, 0, 1,\n\t\t\t0, 0, 0, \t0, 1, 1,\n\t\t\t0, 0, 0, \t0, - 1, 1\n\t\t];\n\n\t\tfor ( let i = 0, j = 1, l = 32; i < l; i ++, j ++ ) {\n\n\t\t\tconst p1 = ( i / l ) * Math.PI * 2;\n\t\t\tconst p2 = ( j / l ) * Math.PI * 2;\n\n\t\t\tpositions.push(\n\t\t\t\tMath.cos( p1 ), Math.sin( p1 ), 1,\n\t\t\t\tMath.cos( p2 ), Math.sin( p2 ), 1\n\t\t\t);\n\n\t\t}\n\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( positions, 3 ) );\n\n\t\tconst material = new LineBasicMaterial( { fog: false, toneMapped: false } );\n\n\t\tthis.cone = new LineSegments( geometry, material );\n\t\tthis.add( this.cone );\n\n\t\tthis.update();\n\n\t}\n\n\tdispose() {\n\n\t\tthis.cone.geometry.dispose();\n\t\tthis.cone.material.dispose();\n\n\t}\n\n\tupdate() {\n\n\t\tthis.light.updateMatrixWorld();\n\n\t\tconst coneLength = this.light.distance ? this.light.distance : 1000;\n\t\tconst coneWidth = coneLength * Math.tan( this.light.angle );\n\n\t\tthis.cone.scale.set( coneWidth, coneWidth, coneLength );\n\n\t\t_vector$3.setFromMatrixPosition( this.light.target.matrixWorld );\n\n\t\tthis.cone.lookAt( _vector$3 );\n\n\t\tif ( this.color !== undefined ) {\n\n\t\t\tthis.cone.material.color.set( this.color );\n\n\t\t} else {\n\n\t\t\tthis.cone.material.color.copy( this.light.color );\n\n\t\t}\n\n\t}\n\n}\n\nconst _vector$2 = /*@__PURE__*/ new Vector3();\nconst _boneMatrix = /*@__PURE__*/ new Matrix4();\nconst _matrixWorldInv = /*@__PURE__*/ new Matrix4();\n\n\nclass SkeletonHelper extends LineSegments {\n\n\tconstructor( object ) {\n\n\t\tconst bones = getBoneList( object );\n\n\t\tconst geometry = new BufferGeometry();\n\n\t\tconst vertices = [];\n\t\tconst colors = [];\n\n\t\tconst color1 = new Color( 0, 0, 1 );\n\t\tconst color2 = new Color( 0, 1, 0 );\n\n\t\tfor ( let i = 0; i < bones.length; i ++ ) {\n\n\t\t\tconst bone = bones[ i ];\n\n\t\t\tif ( bone.parent && bone.parent.isBone ) {\n\n\t\t\t\tvertices.push( 0, 0, 0 );\n\t\t\t\tvertices.push( 0, 0, 0 );\n\t\t\t\tcolors.push( color1.r, color1.g, color1.b );\n\t\t\t\tcolors.push( color2.r, color2.g, color2.b );\n\n\t\t\t}\n\n\t\t}\n\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tgeometry.setAttribute( 'color', new Float32BufferAttribute( colors, 3 ) );\n\n\t\tconst material = new LineBasicMaterial( { vertexColors: true, depthTest: false, depthWrite: false, toneMapped: false, transparent: true } );\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'SkeletonHelper';\n\t\tthis.isSkeletonHelper = true;\n\n\t\tthis.root = object;\n\t\tthis.bones = bones;\n\n\t\tthis.matrix = object.matrixWorld;\n\t\tthis.matrixAutoUpdate = false;\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tconst bones = this.bones;\n\n\t\tconst geometry = this.geometry;\n\t\tconst position = geometry.getAttribute( 'position' );\n\n\t\t_matrixWorldInv.copy( this.root.matrixWorld ).invert();\n\n\t\tfor ( let i = 0, j = 0; i < bones.length; i ++ ) {\n\n\t\t\tconst bone = bones[ i ];\n\n\t\t\tif ( bone.parent && bone.parent.isBone ) {\n\n\t\t\t\t_boneMatrix.multiplyMatrices( _matrixWorldInv, bone.matrixWorld );\n\t\t\t\t_vector$2.setFromMatrixPosition( _boneMatrix );\n\t\t\t\tposition.setXYZ( j, _vector$2.x, _vector$2.y, _vector$2.z );\n\n\t\t\t\t_boneMatrix.multiplyMatrices( _matrixWorldInv, bone.parent.matrixWorld );\n\t\t\t\t_vector$2.setFromMatrixPosition( _boneMatrix );\n\t\t\t\tposition.setXYZ( j + 1, _vector$2.x, _vector$2.y, _vector$2.z );\n\n\t\t\t\tj += 2;\n\n\t\t\t}\n\n\t\t}\n\n\t\tgeometry.getAttribute( 'position' ).needsUpdate = true;\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t}\n\n}\n\n\nfunction getBoneList( object ) {\n\n\tconst boneList = [];\n\n\tif ( object.isBone === true ) {\n\n\t\tboneList.push( object );\n\n\t}\n\n\tfor ( let i = 0; i < object.children.length; i ++ ) {\n\n\t\tboneList.push.apply( boneList, getBoneList( object.children[ i ] ) );\n\n\t}\n\n\treturn boneList;\n\n}\n\nclass PointLightHelper extends Mesh {\n\n\tconstructor( light, sphereSize, color ) {\n\n\t\tconst geometry = new SphereGeometry( sphereSize, 4, 2 );\n\t\tconst material = new MeshBasicMaterial( { wireframe: true, fog: false, toneMapped: false } );\n\n\t\tsuper( geometry, material );\n\n\t\tthis.light = light;\n\t\tthis.light.updateMatrixWorld();\n\n\t\tthis.color = color;\n\n\t\tthis.type = 'PointLightHelper';\n\n\t\tthis.matrix = this.light.matrixWorld;\n\t\tthis.matrixAutoUpdate = false;\n\n\t\tthis.update();\n\n\n\t\t/*\n\t// TODO: delete this comment?\n\tconst distanceGeometry = new THREE.IcosahedronGeometry( 1, 2 );\n\tconst distanceMaterial = new THREE.MeshBasicMaterial( { color: hexColor, fog: false, wireframe: true, opacity: 0.1, transparent: true } );\n\n\tthis.lightSphere = new THREE.Mesh( bulbGeometry, bulbMaterial );\n\tthis.lightDistance = new THREE.Mesh( distanceGeometry, distanceMaterial );\n\n\tconst d = light.distance;\n\n\tif ( d === 0.0 ) {\n\n\t\tthis.lightDistance.visible = false;\n\n\t} else {\n\n\t\tthis.lightDistance.scale.set( d, d, d );\n\n\t}\n\n\tthis.add( this.lightDistance );\n\t*/\n\n\t}\n\n\tdispose() {\n\n\t\tthis.geometry.dispose();\n\t\tthis.material.dispose();\n\n\t}\n\n\tupdate() {\n\n\t\tif ( this.color !== undefined ) {\n\n\t\t\tthis.material.color.set( this.color );\n\n\t\t} else {\n\n\t\t\tthis.material.color.copy( this.light.color );\n\n\t\t}\n\n\t\t/*\n\t\tconst d = this.light.distance;\n\n\t\tif ( d === 0.0 ) {\n\n\t\t\tthis.lightDistance.visible = false;\n\n\t\t} else {\n\n\t\t\tthis.lightDistance.visible = true;\n\t\t\tthis.lightDistance.scale.set( d, d, d );\n\n\t\t}\n\t\t*/\n\n\t}\n\n}\n\nconst _vector$1 = /*@__PURE__*/ new Vector3();\nconst _color1 = /*@__PURE__*/ new Color();\nconst _color2 = /*@__PURE__*/ new Color();\n\nclass HemisphereLightHelper extends Object3D {\n\n\tconstructor( light, size, color ) {\n\n\t\tsuper();\n\t\tthis.light = light;\n\t\tthis.light.updateMatrixWorld();\n\n\t\tthis.matrix = light.matrixWorld;\n\t\tthis.matrixAutoUpdate = false;\n\n\t\tthis.color = color;\n\n\t\tconst geometry = new OctahedronGeometry( size );\n\t\tgeometry.rotateY( Math.PI * 0.5 );\n\n\t\tthis.material = new MeshBasicMaterial( { wireframe: true, fog: false, toneMapped: false } );\n\t\tif ( this.color === undefined ) this.material.vertexColors = true;\n\n\t\tconst position = geometry.getAttribute( 'position' );\n\t\tconst colors = new Float32Array( position.count * 3 );\n\n\t\tgeometry.setAttribute( 'color', new BufferAttribute( colors, 3 ) );\n\n\t\tthis.add( new Mesh( geometry, this.material ) );\n\n\t\tthis.update();\n\n\t}\n\n\tdispose() {\n\n\t\tthis.children[ 0 ].geometry.dispose();\n\t\tthis.children[ 0 ].material.dispose();\n\n\t}\n\n\tupdate() {\n\n\t\tconst mesh = this.children[ 0 ];\n\n\t\tif ( this.color !== undefined ) {\n\n\t\t\tthis.material.color.set( this.color );\n\n\t\t} else {\n\n\t\t\tconst colors = mesh.geometry.getAttribute( 'color' );\n\n\t\t\t_color1.copy( this.light.color );\n\t\t\t_color2.copy( this.light.groundColor );\n\n\t\t\tfor ( let i = 0, l = colors.count; i < l; i ++ ) {\n\n\t\t\t\tconst color = ( i < ( l / 2 ) ) ? _color1 : _color2;\n\n\t\t\t\tcolors.setXYZ( i, color.r, color.g, color.b );\n\n\t\t\t}\n\n\t\t\tcolors.needsUpdate = true;\n\n\t\t}\n\n\t\tmesh.lookAt( _vector$1.setFromMatrixPosition( this.light.matrixWorld ).negate() );\n\n\t}\n\n}\n\nclass GridHelper extends LineSegments {\n\n\tconstructor( size = 10, divisions = 10, color1 = 0x444444, color2 = 0x888888 ) {\n\n\t\tcolor1 = new Color( color1 );\n\t\tcolor2 = new Color( color2 );\n\n\t\tconst center = divisions / 2;\n\t\tconst step = size / divisions;\n\t\tconst halfSize = size / 2;\n\n\t\tconst vertices = [], colors = [];\n\n\t\tfor ( let i = 0, j = 0, k = - halfSize; i <= divisions; i ++, k += step ) {\n\n\t\t\tvertices.push( - halfSize, 0, k, halfSize, 0, k );\n\t\t\tvertices.push( k, 0, - halfSize, k, 0, halfSize );\n\n\t\t\tconst color = i === center ? color1 : color2;\n\n\t\t\tcolor.toArray( colors, j ); j += 3;\n\t\t\tcolor.toArray( colors, j ); j += 3;\n\t\t\tcolor.toArray( colors, j ); j += 3;\n\t\t\tcolor.toArray( colors, j ); j += 3;\n\n\t\t}\n\n\t\tconst geometry = new BufferGeometry();\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tgeometry.setAttribute( 'color', new Float32BufferAttribute( colors, 3 ) );\n\n\t\tconst material = new LineBasicMaterial( { vertexColors: true, toneMapped: false } );\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'GridHelper';\n\n\t}\n\n}\n\nclass PolarGridHelper extends LineSegments {\n\n\tconstructor( radius = 10, radials = 16, circles = 8, divisions = 64, color1 = 0x444444, color2 = 0x888888 ) {\n\n\t\tcolor1 = new Color( color1 );\n\t\tcolor2 = new Color( color2 );\n\n\t\tconst vertices = [];\n\t\tconst colors = [];\n\n\t\t// create the radials\n\n\t\tfor ( let i = 0; i <= radials; i ++ ) {\n\n\t\t\tconst v = ( i / radials ) * ( Math.PI * 2 );\n\n\t\t\tconst x = Math.sin( v ) * radius;\n\t\t\tconst z = Math.cos( v ) * radius;\n\n\t\t\tvertices.push( 0, 0, 0 );\n\t\t\tvertices.push( x, 0, z );\n\n\t\t\tconst color = ( i & 1 ) ? color1 : color2;\n\n\t\t\tcolors.push( color.r, color.g, color.b );\n\t\t\tcolors.push( color.r, color.g, color.b );\n\n\t\t}\n\n\t\t// create the circles\n\n\t\tfor ( let i = 0; i <= circles; i ++ ) {\n\n\t\t\tconst color = ( i & 1 ) ? color1 : color2;\n\n\t\t\tconst r = radius - ( radius / circles * i );\n\n\t\t\tfor ( let j = 0; j < divisions; j ++ ) {\n\n\t\t\t\t// first vertex\n\n\t\t\t\tlet v = ( j / divisions ) * ( Math.PI * 2 );\n\n\t\t\t\tlet x = Math.sin( v ) * r;\n\t\t\t\tlet z = Math.cos( v ) * r;\n\n\t\t\t\tvertices.push( x, 0, z );\n\t\t\t\tcolors.push( color.r, color.g, color.b );\n\n\t\t\t\t// second vertex\n\n\t\t\t\tv = ( ( j + 1 ) / divisions ) * ( Math.PI * 2 );\n\n\t\t\t\tx = Math.sin( v ) * r;\n\t\t\t\tz = Math.cos( v ) * r;\n\n\t\t\t\tvertices.push( x, 0, z );\n\t\t\t\tcolors.push( color.r, color.g, color.b );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst geometry = new BufferGeometry();\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tgeometry.setAttribute( 'color', new Float32BufferAttribute( colors, 3 ) );\n\n\t\tconst material = new LineBasicMaterial( { vertexColors: true, toneMapped: false } );\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'PolarGridHelper';\n\n\t}\n\n}\n\nconst _v1 = /*@__PURE__*/ new Vector3();\nconst _v2 = /*@__PURE__*/ new Vector3();\nconst _v3 = /*@__PURE__*/ new Vector3();\n\nclass DirectionalLightHelper extends Object3D {\n\n\tconstructor( light, size, color ) {\n\n\t\tsuper();\n\t\tthis.light = light;\n\t\tthis.light.updateMatrixWorld();\n\n\t\tthis.matrix = light.matrixWorld;\n\t\tthis.matrixAutoUpdate = false;\n\n\t\tthis.color = color;\n\n\t\tif ( size === undefined ) size = 1;\n\n\t\tlet geometry = new BufferGeometry();\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( [\n\t\t\t- size, size, 0,\n\t\t\tsize, size, 0,\n\t\t\tsize, - size, 0,\n\t\t\t- size, - size, 0,\n\t\t\t- size, size, 0\n\t\t], 3 ) );\n\n\t\tconst material = new LineBasicMaterial( { fog: false, toneMapped: false } );\n\n\t\tthis.lightPlane = new Line( geometry, material );\n\t\tthis.add( this.lightPlane );\n\n\t\tgeometry = new BufferGeometry();\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( [ 0, 0, 0, 0, 0, 1 ], 3 ) );\n\n\t\tthis.targetLine = new Line( geometry, material );\n\t\tthis.add( this.targetLine );\n\n\t\tthis.update();\n\n\t}\n\n\tdispose() {\n\n\t\tthis.lightPlane.geometry.dispose();\n\t\tthis.lightPlane.material.dispose();\n\t\tthis.targetLine.geometry.dispose();\n\t\tthis.targetLine.material.dispose();\n\n\t}\n\n\tupdate() {\n\n\t\t_v1.setFromMatrixPosition( this.light.matrixWorld );\n\t\t_v2.setFromMatrixPosition( this.light.target.matrixWorld );\n\t\t_v3.subVectors( _v2, _v1 );\n\n\t\tthis.lightPlane.lookAt( _v2 );\n\n\t\tif ( this.color !== undefined ) {\n\n\t\t\tthis.lightPlane.material.color.set( this.color );\n\t\t\tthis.targetLine.material.color.set( this.color );\n\n\t\t} else {\n\n\t\t\tthis.lightPlane.material.color.copy( this.light.color );\n\t\t\tthis.targetLine.material.color.copy( this.light.color );\n\n\t\t}\n\n\t\tthis.targetLine.lookAt( _v2 );\n\t\tthis.targetLine.scale.z = _v3.length();\n\n\t}\n\n}\n\nconst _vector = /*@__PURE__*/ new Vector3();\nconst _camera = /*@__PURE__*/ new Camera();\n\n/**\n *\t- shows frustum, line of sight and up of the camera\n *\t- suitable for fast updates\n * \t- based on frustum visualization in lightgl.js shadowmap example\n *\t\thttps://github.com/evanw/lightgl.js/blob/master/tests/shadowmap.html\n */\n\nclass CameraHelper extends LineSegments {\n\n\tconstructor( camera ) {\n\n\t\tconst geometry = new BufferGeometry();\n\t\tconst material = new LineBasicMaterial( { color: 0xffffff, vertexColors: true, toneMapped: false } );\n\n\t\tconst vertices = [];\n\t\tconst colors = [];\n\n\t\tconst pointMap = {};\n\n\t\t// colors\n\n\t\tconst colorFrustum = new Color( 0xffaa00 );\n\t\tconst colorCone = new Color( 0xff0000 );\n\t\tconst colorUp = new Color( 0x00aaff );\n\t\tconst colorTarget = new Color( 0xffffff );\n\t\tconst colorCross = new Color( 0x333333 );\n\n\t\t// near\n\n\t\taddLine( 'n1', 'n2', colorFrustum );\n\t\taddLine( 'n2', 'n4', colorFrustum );\n\t\taddLine( 'n4', 'n3', colorFrustum );\n\t\taddLine( 'n3', 'n1', colorFrustum );\n\n\t\t// far\n\n\t\taddLine( 'f1', 'f2', colorFrustum );\n\t\taddLine( 'f2', 'f4', colorFrustum );\n\t\taddLine( 'f4', 'f3', colorFrustum );\n\t\taddLine( 'f3', 'f1', colorFrustum );\n\n\t\t// sides\n\n\t\taddLine( 'n1', 'f1', colorFrustum );\n\t\taddLine( 'n2', 'f2', colorFrustum );\n\t\taddLine( 'n3', 'f3', colorFrustum );\n\t\taddLine( 'n4', 'f4', colorFrustum );\n\n\t\t// cone\n\n\t\taddLine( 'p', 'n1', colorCone );\n\t\taddLine( 'p', 'n2', colorCone );\n\t\taddLine( 'p', 'n3', colorCone );\n\t\taddLine( 'p', 'n4', colorCone );\n\n\t\t// up\n\n\t\taddLine( 'u1', 'u2', colorUp );\n\t\taddLine( 'u2', 'u3', colorUp );\n\t\taddLine( 'u3', 'u1', colorUp );\n\n\t\t// target\n\n\t\taddLine( 'c', 't', colorTarget );\n\t\taddLine( 'p', 'c', colorCross );\n\n\t\t// cross\n\n\t\taddLine( 'cn1', 'cn2', colorCross );\n\t\taddLine( 'cn3', 'cn4', colorCross );\n\n\t\taddLine( 'cf1', 'cf2', colorCross );\n\t\taddLine( 'cf3', 'cf4', colorCross );\n\n\t\tfunction addLine( a, b, color ) {\n\n\t\t\taddPoint( a, color );\n\t\t\taddPoint( b, color );\n\n\t\t}\n\n\t\tfunction addPoint( id, color ) {\n\n\t\t\tvertices.push( 0, 0, 0 );\n\t\t\tcolors.push( color.r, color.g, color.b );\n\n\t\t\tif ( pointMap[ id ] === undefined ) {\n\n\t\t\t\tpointMap[ id ] = [];\n\n\t\t\t}\n\n\t\t\tpointMap[ id ].push( ( vertices.length / 3 ) - 1 );\n\n\t\t}\n\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tgeometry.setAttribute( 'color', new Float32BufferAttribute( colors, 3 ) );\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'CameraHelper';\n\n\t\tthis.camera = camera;\n\t\tif ( this.camera.updateProjectionMatrix ) this.camera.updateProjectionMatrix();\n\n\t\tthis.matrix = camera.matrixWorld;\n\t\tthis.matrixAutoUpdate = false;\n\n\t\tthis.pointMap = pointMap;\n\n\t\tthis.update();\n\n\t}\n\n\tupdate() {\n\n\t\tconst geometry = this.geometry;\n\t\tconst pointMap = this.pointMap;\n\n\t\tconst w = 1, h = 1;\n\n\t\t// we need just camera projection matrix inverse\n\t\t// world matrix must be identity\n\n\t\t_camera.projectionMatrixInverse.copy( this.camera.projectionMatrixInverse );\n\n\t\t// center / target\n\n\t\tsetPoint( 'c', pointMap, geometry, _camera, 0, 0, - 1 );\n\t\tsetPoint( 't', pointMap, geometry, _camera, 0, 0, 1 );\n\n\t\t// near\n\n\t\tsetPoint( 'n1', pointMap, geometry, _camera, - w, - h, - 1 );\n\t\tsetPoint( 'n2', pointMap, geometry, _camera, w, - h, - 1 );\n\t\tsetPoint( 'n3', pointMap, geometry, _camera, - w, h, - 1 );\n\t\tsetPoint( 'n4', pointMap, geometry, _camera, w, h, - 1 );\n\n\t\t// far\n\n\t\tsetPoint( 'f1', pointMap, geometry, _camera, - w, - h, 1 );\n\t\tsetPoint( 'f2', pointMap, geometry, _camera, w, - h, 1 );\n\t\tsetPoint( 'f3', pointMap, geometry, _camera, - w, h, 1 );\n\t\tsetPoint( 'f4', pointMap, geometry, _camera, w, h, 1 );\n\n\t\t// up\n\n\t\tsetPoint( 'u1', pointMap, geometry, _camera, w * 0.7, h * 1.1, - 1 );\n\t\tsetPoint( 'u2', pointMap, geometry, _camera, - w * 0.7, h * 1.1, - 1 );\n\t\tsetPoint( 'u3', pointMap, geometry, _camera, 0, h * 2, - 1 );\n\n\t\t// cross\n\n\t\tsetPoint( 'cf1', pointMap, geometry, _camera, - w, 0, 1 );\n\t\tsetPoint( 'cf2', pointMap, geometry, _camera, w, 0, 1 );\n\t\tsetPoint( 'cf3', pointMap, geometry, _camera, 0, - h, 1 );\n\t\tsetPoint( 'cf4', pointMap, geometry, _camera, 0, h, 1 );\n\n\t\tsetPoint( 'cn1', pointMap, geometry, _camera, - w, 0, - 1 );\n\t\tsetPoint( 'cn2', pointMap, geometry, _camera, w, 0, - 1 );\n\t\tsetPoint( 'cn3', pointMap, geometry, _camera, 0, - h, - 1 );\n\t\tsetPoint( 'cn4', pointMap, geometry, _camera, 0, h, - 1 );\n\n\t\tgeometry.getAttribute( 'position' ).needsUpdate = true;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.geometry.dispose();\n\t\tthis.material.dispose();\n\n\t}\n\n}\n\n\nfunction setPoint( point, pointMap, geometry, camera, x, y, z ) {\n\n\t_vector.set( x, y, z ).unproject( camera );\n\n\tconst points = pointMap[ point ];\n\n\tif ( points !== undefined ) {\n\n\t\tconst position = geometry.getAttribute( 'position' );\n\n\t\tfor ( let i = 0, l = points.length; i < l; i ++ ) {\n\n\t\t\tposition.setXYZ( points[ i ], _vector.x, _vector.y, _vector.z );\n\n\t\t}\n\n\t}\n\n}\n\nconst _box = /*@__PURE__*/ new Box3();\n\nclass BoxHelper extends LineSegments {\n\n\tconstructor( object, color = 0xffff00 ) {\n\n\t\tconst indices = new Uint16Array( [ 0, 1, 1, 2, 2, 3, 3, 0, 4, 5, 5, 6, 6, 7, 7, 4, 0, 4, 1, 5, 2, 6, 3, 7 ] );\n\t\tconst positions = new Float32Array( 8 * 3 );\n\n\t\tconst geometry = new BufferGeometry();\n\t\tgeometry.setIndex( new BufferAttribute( indices, 1 ) );\n\t\tgeometry.setAttribute( 'position', new BufferAttribute( positions, 3 ) );\n\n\t\tsuper( geometry, new LineBasicMaterial( { color: color, toneMapped: false } ) );\n\n\t\tthis.object = object;\n\t\tthis.type = 'BoxHelper';\n\n\t\tthis.matrixAutoUpdate = false;\n\n\t\tthis.update();\n\n\t}\n\n\tupdate( object ) {\n\n\t\tif ( object !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.BoxHelper: .update() has no longer arguments.' );\n\n\t\t}\n\n\t\tif ( this.object !== undefined ) {\n\n\t\t\t_box.setFromObject( this.object );\n\n\t\t}\n\n\t\tif ( _box.isEmpty() ) return;\n\n\t\tconst min = _box.min;\n\t\tconst max = _box.max;\n\n\t\t/*\n\t\t\t5____4\n\t\t1/___0/|\n\t\t| 6__|_7\n\t\t2/___3/\n\n\t\t0: max.x, max.y, max.z\n\t\t1: min.x, max.y, max.z\n\t\t2: min.x, min.y, max.z\n\t\t3: max.x, min.y, max.z\n\t\t4: max.x, max.y, min.z\n\t\t5: min.x, max.y, min.z\n\t\t6: min.x, min.y, min.z\n\t\t7: max.x, min.y, min.z\n\t\t*/\n\n\t\tconst position = this.geometry.attributes.position;\n\t\tconst array = position.array;\n\n\t\tarray[ 0 ] = max.x; array[ 1 ] = max.y; array[ 2 ] = max.z;\n\t\tarray[ 3 ] = min.x; array[ 4 ] = max.y; array[ 5 ] = max.z;\n\t\tarray[ 6 ] = min.x; array[ 7 ] = min.y; array[ 8 ] = max.z;\n\t\tarray[ 9 ] = max.x; array[ 10 ] = min.y; array[ 11 ] = max.z;\n\t\tarray[ 12 ] = max.x; array[ 13 ] = max.y; array[ 14 ] = min.z;\n\t\tarray[ 15 ] = min.x; array[ 16 ] = max.y; array[ 17 ] = min.z;\n\t\tarray[ 18 ] = min.x; array[ 19 ] = min.y; array[ 20 ] = min.z;\n\t\tarray[ 21 ] = max.x; array[ 22 ] = min.y; array[ 23 ] = min.z;\n\n\t\tposition.needsUpdate = true;\n\n\t\tthis.geometry.computeBoundingSphere();\n\n\n\t}\n\n\tsetFromObject( object ) {\n\n\t\tthis.object = object;\n\t\tthis.update();\n\n\t\treturn this;\n\n\t}\n\n\tcopy( source ) {\n\n\t\tLineSegments.prototype.copy.call( this, source );\n\n\t\tthis.object = source.object;\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass Box3Helper extends LineSegments {\n\n\tconstructor( box, color = 0xffff00 ) {\n\n\t\tconst indices = new Uint16Array( [ 0, 1, 1, 2, 2, 3, 3, 0, 4, 5, 5, 6, 6, 7, 7, 4, 0, 4, 1, 5, 2, 6, 3, 7 ] );\n\n\t\tconst positions = [ 1, 1, 1, - 1, 1, 1, - 1, - 1, 1, 1, - 1, 1, 1, 1, - 1, - 1, 1, - 1, - 1, - 1, - 1, 1, - 1, - 1 ];\n\n\t\tconst geometry = new BufferGeometry();\n\n\t\tgeometry.setIndex( new BufferAttribute( indices, 1 ) );\n\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( positions, 3 ) );\n\n\t\tsuper( geometry, new LineBasicMaterial( { color: color, toneMapped: false } ) );\n\n\t\tthis.box = box;\n\n\t\tthis.type = 'Box3Helper';\n\n\t\tthis.geometry.computeBoundingSphere();\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tconst box = this.box;\n\n\t\tif ( box.isEmpty() ) return;\n\n\t\tbox.getCenter( this.position );\n\n\t\tbox.getSize( this.scale );\n\n\t\tthis.scale.multiplyScalar( 0.5 );\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t}\n\n}\n\nclass PlaneHelper extends Line {\n\n\tconstructor( plane, size = 1, hex = 0xffff00 ) {\n\n\t\tconst color = hex;\n\n\t\tconst positions = [ 1, - 1, 1, - 1, 1, 1, - 1, - 1, 1, 1, 1, 1, - 1, 1, 1, - 1, - 1, 1, 1, - 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0 ];\n\n\t\tconst geometry = new BufferGeometry();\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( positions, 3 ) );\n\t\tgeometry.computeBoundingSphere();\n\n\t\tsuper( geometry, new LineBasicMaterial( { color: color, toneMapped: false } ) );\n\n\t\tthis.type = 'PlaneHelper';\n\n\t\tthis.plane = plane;\n\n\t\tthis.size = size;\n\n\t\tconst positions2 = [ 1, 1, 1, - 1, 1, 1, - 1, - 1, 1, 1, 1, 1, - 1, - 1, 1, 1, - 1, 1 ];\n\n\t\tconst geometry2 = new BufferGeometry();\n\t\tgeometry2.setAttribute( 'position', new Float32BufferAttribute( positions2, 3 ) );\n\t\tgeometry2.computeBoundingSphere();\n\n\t\tthis.add( new Mesh( geometry2, new MeshBasicMaterial( { color: color, opacity: 0.2, transparent: true, depthWrite: false, toneMapped: false } ) ) );\n\n\t}\n\n\tupdateMatrixWorld( force ) {\n\n\t\tlet scale = - this.plane.constant;\n\n\t\tif ( Math.abs( scale ) < 1e-8 ) scale = 1e-8; // sign does not matter\n\n\t\tthis.scale.set( 0.5 * this.size, 0.5 * this.size, scale );\n\n\t\tthis.children[ 0 ].material.side = ( scale < 0 ) ? BackSide : FrontSide; // renderer flips side when determinant < 0; flipping not wanted here\n\n\t\tthis.lookAt( this.plane.normal );\n\n\t\tsuper.updateMatrixWorld( force );\n\n\t}\n\n}\n\nconst _axis = /*@__PURE__*/ new Vector3();\nlet _lineGeometry, _coneGeometry;\n\nclass ArrowHelper extends Object3D {\n\n\t// dir is assumed to be normalized\n\n\tconstructor( dir = new Vector3( 0, 0, 1 ), origin = new Vector3( 0, 0, 0 ), length = 1, color = 0xffff00, headLength = length * 0.2, headWidth = headLength * 0.2 ) {\n\n\t\tsuper();\n\n\t\tthis.type = 'ArrowHelper';\n\n\t\tif ( _lineGeometry === undefined ) {\n\n\t\t\t_lineGeometry = new BufferGeometry();\n\t\t\t_lineGeometry.setAttribute( 'position', new Float32BufferAttribute( [ 0, 0, 0, 0, 1, 0 ], 3 ) );\n\n\t\t\t_coneGeometry = new CylinderGeometry( 0, 0.5, 1, 5, 1 );\n\t\t\t_coneGeometry.translate( 0, - 0.5, 0 );\n\n\t\t}\n\n\t\tthis.position.copy( origin );\n\n\t\tthis.line = new Line( _lineGeometry, new LineBasicMaterial( { color: color, toneMapped: false } ) );\n\t\tthis.line.matrixAutoUpdate = false;\n\t\tthis.add( this.line );\n\n\t\tthis.cone = new Mesh( _coneGeometry, new MeshBasicMaterial( { color: color, toneMapped: false } ) );\n\t\tthis.cone.matrixAutoUpdate = false;\n\t\tthis.add( this.cone );\n\n\t\tthis.setDirection( dir );\n\t\tthis.setLength( length, headLength, headWidth );\n\n\t}\n\n\tsetDirection( dir ) {\n\n\t\t// dir is assumed to be normalized\n\n\t\tif ( dir.y > 0.99999 ) {\n\n\t\t\tthis.quaternion.set( 0, 0, 0, 1 );\n\n\t\t} else if ( dir.y < - 0.99999 ) {\n\n\t\t\tthis.quaternion.set( 1, 0, 0, 0 );\n\n\t\t} else {\n\n\t\t\t_axis.set( dir.z, 0, - dir.x ).normalize();\n\n\t\t\tconst radians = Math.acos( dir.y );\n\n\t\t\tthis.quaternion.setFromAxisAngle( _axis, radians );\n\n\t\t}\n\n\t}\n\n\tsetLength( length, headLength = length * 0.2, headWidth = headLength * 0.2 ) {\n\n\t\tthis.line.scale.set( 1, Math.max( 0.0001, length - headLength ), 1 ); // see #17458\n\t\tthis.line.updateMatrix();\n\n\t\tthis.cone.scale.set( headWidth, headLength, headWidth );\n\t\tthis.cone.position.y = length;\n\t\tthis.cone.updateMatrix();\n\n\t}\n\n\tsetColor( color ) {\n\n\t\tthis.line.material.color.set( color );\n\t\tthis.cone.material.color.set( color );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source, false );\n\n\t\tthis.line.copy( source.line );\n\t\tthis.cone.copy( source.cone );\n\n\t\treturn this;\n\n\t}\n\n}\n\nclass AxesHelper extends LineSegments {\n\n\tconstructor( size = 1 ) {\n\n\t\tconst vertices = [\n\t\t\t0, 0, 0,\tsize, 0, 0,\n\t\t\t0, 0, 0,\t0, size, 0,\n\t\t\t0, 0, 0,\t0, 0, size\n\t\t];\n\n\t\tconst colors = [\n\t\t\t1, 0, 0,\t1, 0.6, 0,\n\t\t\t0, 1, 0,\t0.6, 1, 0,\n\t\t\t0, 0, 1,\t0, 0.6, 1\n\t\t];\n\n\t\tconst geometry = new BufferGeometry();\n\t\tgeometry.setAttribute( 'position', new Float32BufferAttribute( vertices, 3 ) );\n\t\tgeometry.setAttribute( 'color', new Float32BufferAttribute( colors, 3 ) );\n\n\t\tconst material = new LineBasicMaterial( { vertexColors: true, toneMapped: false } );\n\n\t\tsuper( geometry, material );\n\n\t\tthis.type = 'AxesHelper';\n\n\t}\n\n\tsetColors( xAxisColor, yAxisColor, zAxisColor ) {\n\n\t\tconst color = new Color();\n\t\tconst array = this.geometry.attributes.color.array;\n\n\t\tcolor.set( xAxisColor );\n\t\tcolor.toArray( array, 0 );\n\t\tcolor.toArray( array, 3 );\n\n\t\tcolor.set( yAxisColor );\n\t\tcolor.toArray( array, 6 );\n\t\tcolor.toArray( array, 9 );\n\n\t\tcolor.set( zAxisColor );\n\t\tcolor.toArray( array, 12 );\n\t\tcolor.toArray( array, 15 );\n\n\t\tthis.geometry.attributes.color.needsUpdate = true;\n\n\t\treturn this;\n\n\t}\n\n\tdispose() {\n\n\t\tthis.geometry.dispose();\n\t\tthis.material.dispose();\n\n\t}\n\n}\n\nclass ShapePath {\n\n\tconstructor() {\n\n\t\tthis.type = 'ShapePath';\n\n\t\tthis.color = new Color();\n\n\t\tthis.subPaths = [];\n\t\tthis.currentPath = null;\n\n\t}\n\n\tmoveTo( x, y ) {\n\n\t\tthis.currentPath = new Path();\n\t\tthis.subPaths.push( this.currentPath );\n\t\tthis.currentPath.moveTo( x, y );\n\n\t\treturn this;\n\n\t}\n\n\tlineTo( x, y ) {\n\n\t\tthis.currentPath.lineTo( x, y );\n\n\t\treturn this;\n\n\t}\n\n\tquadraticCurveTo( aCPx, aCPy, aX, aY ) {\n\n\t\tthis.currentPath.quadraticCurveTo( aCPx, aCPy, aX, aY );\n\n\t\treturn this;\n\n\t}\n\n\tbezierCurveTo( aCP1x, aCP1y, aCP2x, aCP2y, aX, aY ) {\n\n\t\tthis.currentPath.bezierCurveTo( aCP1x, aCP1y, aCP2x, aCP2y, aX, aY );\n\n\t\treturn this;\n\n\t}\n\n\tsplineThru( pts ) {\n\n\t\tthis.currentPath.splineThru( pts );\n\n\t\treturn this;\n\n\t}\n\n\ttoShapes( isCCW, noHoles ) {\n\n\t\tfunction toShapesNoHoles( inSubpaths ) {\n\n\t\t\tconst shapes = [];\n\n\t\t\tfor ( let i = 0, l = inSubpaths.length; i < l; i ++ ) {\n\n\t\t\t\tconst tmpPath = inSubpaths[ i ];\n\n\t\t\t\tconst tmpShape = new Shape();\n\t\t\t\ttmpShape.curves = tmpPath.curves;\n\n\t\t\t\tshapes.push( tmpShape );\n\n\t\t\t}\n\n\t\t\treturn shapes;\n\n\t\t}\n\n\t\tfunction isPointInsidePolygon( inPt, inPolygon ) {\n\n\t\t\tconst polyLen = inPolygon.length;\n\n\t\t\t// inPt on polygon contour => immediate success    or\n\t\t\t// toggling of inside/outside at every single! intersection point of an edge\n\t\t\t//  with the horizontal line through inPt, left of inPt\n\t\t\t//  not counting lowerY endpoints of edges and whole edges on that line\n\t\t\tlet inside = false;\n\t\t\tfor ( let p = polyLen - 1, q = 0; q < polyLen; p = q ++ ) {\n\n\t\t\t\tlet edgeLowPt = inPolygon[ p ];\n\t\t\t\tlet edgeHighPt = inPolygon[ q ];\n\n\t\t\t\tlet edgeDx = edgeHighPt.x - edgeLowPt.x;\n\t\t\t\tlet edgeDy = edgeHighPt.y - edgeLowPt.y;\n\n\t\t\t\tif ( Math.abs( edgeDy ) > Number.EPSILON ) {\n\n\t\t\t\t\t// not parallel\n\t\t\t\t\tif ( edgeDy < 0 ) {\n\n\t\t\t\t\t\tedgeLowPt = inPolygon[ q ]; edgeDx = - edgeDx;\n\t\t\t\t\t\tedgeHighPt = inPolygon[ p ]; edgeDy = - edgeDy;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( ( inPt.y < edgeLowPt.y ) || ( inPt.y > edgeHighPt.y ) ) \t\tcontinue;\n\n\t\t\t\t\tif ( inPt.y === edgeLowPt.y ) {\n\n\t\t\t\t\t\tif ( inPt.x === edgeLowPt.x )\t\treturn\ttrue;\t\t// inPt is on contour ?\n\t\t\t\t\t\t// continue;\t\t\t\t// no intersection or edgeLowPt => doesn't count !!!\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tconst perpEdge = edgeDy * ( inPt.x - edgeLowPt.x ) - edgeDx * ( inPt.y - edgeLowPt.y );\n\t\t\t\t\t\tif ( perpEdge === 0 )\t\t\t\treturn\ttrue;\t\t// inPt is on contour ?\n\t\t\t\t\t\tif ( perpEdge < 0 ) \t\t\t\tcontinue;\n\t\t\t\t\t\tinside = ! inside;\t\t// true intersection left of inPt\n\n\t\t\t\t\t}\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// parallel or collinear\n\t\t\t\t\tif ( inPt.y !== edgeLowPt.y ) \t\tcontinue;\t\t\t// parallel\n\t\t\t\t\t// edge lies on the same horizontal line as inPt\n\t\t\t\t\tif ( ( ( edgeHighPt.x <= inPt.x ) && ( inPt.x <= edgeLowPt.x ) ) ||\n\t\t\t\t\t\t ( ( edgeLowPt.x <= inPt.x ) && ( inPt.x <= edgeHighPt.x ) ) )\t\treturn\ttrue;\t// inPt: Point on contour !\n\t\t\t\t\t// continue;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn\tinside;\n\n\t\t}\n\n\t\tconst isClockWise = ShapeUtils.isClockWise;\n\n\t\tconst subPaths = this.subPaths;\n\t\tif ( subPaths.length === 0 ) return [];\n\n\t\tif ( noHoles === true )\treturn\ttoShapesNoHoles( subPaths );\n\n\n\t\tlet solid, tmpPath, tmpShape;\n\t\tconst shapes = [];\n\n\t\tif ( subPaths.length === 1 ) {\n\n\t\t\ttmpPath = subPaths[ 0 ];\n\t\t\ttmpShape = new Shape();\n\t\t\ttmpShape.curves = tmpPath.curves;\n\t\t\tshapes.push( tmpShape );\n\t\t\treturn shapes;\n\n\t\t}\n\n\t\tlet holesFirst = ! isClockWise( subPaths[ 0 ].getPoints() );\n\t\tholesFirst = isCCW ? ! holesFirst : holesFirst;\n\n\t\t// console.log(\"Holes first\", holesFirst);\n\n\t\tconst betterShapeHoles = [];\n\t\tconst newShapes = [];\n\t\tlet newShapeHoles = [];\n\t\tlet mainIdx = 0;\n\t\tlet tmpPoints;\n\n\t\tnewShapes[ mainIdx ] = undefined;\n\t\tnewShapeHoles[ mainIdx ] = [];\n\n\t\tfor ( let i = 0, l = subPaths.length; i < l; i ++ ) {\n\n\t\t\ttmpPath = subPaths[ i ];\n\t\t\ttmpPoints = tmpPath.getPoints();\n\t\t\tsolid = isClockWise( tmpPoints );\n\t\t\tsolid = isCCW ? ! solid : solid;\n\n\t\t\tif ( solid ) {\n\n\t\t\t\tif ( ( ! holesFirst ) && ( newShapes[ mainIdx ] ) )\tmainIdx ++;\n\n\t\t\t\tnewShapes[ mainIdx ] = { s: new Shape(), p: tmpPoints };\n\t\t\t\tnewShapes[ mainIdx ].s.curves = tmpPath.curves;\n\n\t\t\t\tif ( holesFirst )\tmainIdx ++;\n\t\t\t\tnewShapeHoles[ mainIdx ] = [];\n\n\t\t\t\t//console.log('cw', i);\n\n\t\t\t} else {\n\n\t\t\t\tnewShapeHoles[ mainIdx ].push( { h: tmpPath, p: tmpPoints[ 0 ] } );\n\n\t\t\t\t//console.log('ccw', i);\n\n\t\t\t}\n\n\t\t}\n\n\t\t// only Holes? -> probably all Shapes with wrong orientation\n\t\tif ( ! newShapes[ 0 ] )\treturn\ttoShapesNoHoles( subPaths );\n\n\n\t\tif ( newShapes.length > 1 ) {\n\n\t\t\tlet ambiguous = false;\n\t\t\tlet toChange = 0;\n\n\t\t\tfor ( let sIdx = 0, sLen = newShapes.length; sIdx < sLen; sIdx ++ ) {\n\n\t\t\t\tbetterShapeHoles[ sIdx ] = [];\n\n\t\t\t}\n\n\t\t\tfor ( let sIdx = 0, sLen = newShapes.length; sIdx < sLen; sIdx ++ ) {\n\n\t\t\t\tconst sho = newShapeHoles[ sIdx ];\n\n\t\t\t\tfor ( let hIdx = 0; hIdx < sho.length; hIdx ++ ) {\n\n\t\t\t\t\tconst ho = sho[ hIdx ];\n\t\t\t\t\tlet hole_unassigned = true;\n\n\t\t\t\t\tfor ( let s2Idx = 0; s2Idx < newShapes.length; s2Idx ++ ) {\n\n\t\t\t\t\t\tif ( isPointInsidePolygon( ho.p, newShapes[ s2Idx ].p ) ) {\n\n\t\t\t\t\t\t\tif ( sIdx !== s2Idx )\ttoChange ++;\n\n\t\t\t\t\t\t\tif ( hole_unassigned ) {\n\n\t\t\t\t\t\t\t\thole_unassigned = false;\n\t\t\t\t\t\t\t\tbetterShapeHoles[ s2Idx ].push( ho );\n\n\t\t\t\t\t\t\t} else {\n\n\t\t\t\t\t\t\t\tambiguous = true;\n\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( hole_unassigned ) {\n\n\t\t\t\t\t\tbetterShapeHoles[ sIdx ].push( ho );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( toChange > 0 && ambiguous === false ) {\n\n\t\t\t\tnewShapeHoles = betterShapeHoles;\n\n\t\t\t}\n\n\t\t}\n\n\t\tlet tmpHoles;\n\n\t\tfor ( let i = 0, il = newShapes.length; i < il; i ++ ) {\n\n\t\t\ttmpShape = newShapes[ i ].s;\n\t\t\tshapes.push( tmpShape );\n\t\t\ttmpHoles = newShapeHoles[ i ];\n\n\t\t\tfor ( let j = 0, jl = tmpHoles.length; j < jl; j ++ ) {\n\n\t\t\t\ttmpShape.holes.push( tmpHoles[ j ].h );\n\n\t\t\t}\n\n\t\t}\n\n\t\t//console.log(\"shape\", shapes);\n\n\t\treturn shapes;\n\n\t}\n\n}\n\nconst _floatView = new Float32Array( 1 );\nconst _int32View = new Int32Array( _floatView.buffer );\n\nclass DataUtils {\n\n\t// Converts float32 to float16 (stored as uint16 value).\n\n\tstatic toHalfFloat( val ) {\n\n\t\tif ( val > 65504 ) {\n\n\t\t\tconsole.warn( 'THREE.DataUtils.toHalfFloat(): value exceeds 65504.' );\n\n\t\t\tval = 65504; // maximum representable value in float16\n\n\t\t}\n\n\t\t// Source: http://gamedev.stackexchange.com/questions/17326/conversion-of-a-number-from-single-precision-floating-point-representation-to-a/17410#17410\n\n\t\t/* This method is faster than the OpenEXR implementation (very often\n\t\t* used, eg. in Ogre), with the additional benefit of rounding, inspired\n\t\t* by James Tursa?s half-precision code. */\n\n\t\t_floatView[ 0 ] = val;\n\t\tconst x = _int32View[ 0 ];\n\n\t\tlet bits = ( x >> 16 ) & 0x8000; /* Get the sign */\n\t\tlet m = ( x >> 12 ) & 0x07ff; /* Keep one extra bit for rounding */\n\t\tconst e = ( x >> 23 ) & 0xff; /* Using int is faster here */\n\n\t\t/* If zero, or denormal, or exponent underflows too much for a denormal\n\t\t\t* half, return signed zero. */\n\t\tif ( e < 103 ) return bits;\n\n\t\t/* If NaN, return NaN. If Inf or exponent overflow, return Inf. */\n\t\tif ( e > 142 ) {\n\n\t\t\tbits |= 0x7c00;\n\t\t\t/* If exponent was 0xff and one mantissa bit was set, it means NaN,\n\t\t\t\t\t\t* not Inf, so make sure we set one mantissa bit too. */\n\t\t\tbits |= ( ( e == 255 ) ? 0 : 1 ) && ( x & 0x007fffff );\n\t\t\treturn bits;\n\n\t\t}\n\n\t\t/* If exponent underflows but not too much, return a denormal */\n\t\tif ( e < 113 ) {\n\n\t\t\tm |= 0x0800;\n\t\t\t/* Extra rounding may overflow and set mantissa to 0 and exponent\n\t\t\t\t* to 1, which is OK. */\n\t\t\tbits |= ( m >> ( 114 - e ) ) + ( ( m >> ( 113 - e ) ) & 1 );\n\t\t\treturn bits;\n\n\t\t}\n\n\t\tbits |= ( ( e - 112 ) << 10 ) | ( m >> 1 );\n\t\t/* Extra rounding. An overflow will set mantissa to 0 and increment\n\t\t\t* the exponent, which is OK. */\n\t\tbits += m & 1;\n\t\treturn bits;\n\n\t}\n\n}\n\nconst LineStrip = 0;\nconst LinePieces = 1;\nconst NoColors = 0;\nconst FaceColors = 1;\nconst VertexColors = 2;\n\nfunction MeshFaceMaterial( materials ) {\n\n\tconsole.warn( 'THREE.MeshFaceMaterial has been removed. Use an Array instead.' );\n\treturn materials;\n\n}\n\nfunction MultiMaterial( materials = [] ) {\n\n\tconsole.warn( 'THREE.MultiMaterial has been removed. Use an Array instead.' );\n\tmaterials.isMultiMaterial = true;\n\tmaterials.materials = materials;\n\tmaterials.clone = function () {\n\n\t\treturn materials.slice();\n\n\t};\n\n\treturn materials;\n\n}\n\nfunction PointCloud( geometry, material ) {\n\n\tconsole.warn( 'THREE.PointCloud has been renamed to THREE.Points.' );\n\treturn new Points( geometry, material );\n\n}\n\nfunction Particle( material ) {\n\n\tconsole.warn( 'THREE.Particle has been renamed to THREE.Sprite.' );\n\treturn new Sprite( material );\n\n}\n\nfunction ParticleSystem( geometry, material ) {\n\n\tconsole.warn( 'THREE.ParticleSystem has been renamed to THREE.Points.' );\n\treturn new Points( geometry, material );\n\n}\n\nfunction PointCloudMaterial( parameters ) {\n\n\tconsole.warn( 'THREE.PointCloudMaterial has been renamed to THREE.PointsMaterial.' );\n\treturn new PointsMaterial( parameters );\n\n}\n\nfunction ParticleBasicMaterial( parameters ) {\n\n\tconsole.warn( 'THREE.ParticleBasicMaterial has been renamed to THREE.PointsMaterial.' );\n\treturn new PointsMaterial( parameters );\n\n}\n\nfunction ParticleSystemMaterial( parameters ) {\n\n\tconsole.warn( 'THREE.ParticleSystemMaterial has been renamed to THREE.PointsMaterial.' );\n\treturn new PointsMaterial( parameters );\n\n}\n\nfunction Vertex( x, y, z ) {\n\n\tconsole.warn( 'THREE.Vertex has been removed. Use THREE.Vector3 instead.' );\n\treturn new Vector3( x, y, z );\n\n}\n\n//\n\nfunction DynamicBufferAttribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.DynamicBufferAttribute has been removed. Use new THREE.BufferAttribute().setUsage( THREE.DynamicDrawUsage ) instead.' );\n\treturn new BufferAttribute( array, itemSize ).setUsage( DynamicDrawUsage );\n\n}\n\nfunction Int8Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Int8Attribute has been removed. Use new THREE.Int8BufferAttribute() instead.' );\n\treturn new Int8BufferAttribute( array, itemSize );\n\n}\n\nfunction Uint8Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Uint8Attribute has been removed. Use new THREE.Uint8BufferAttribute() instead.' );\n\treturn new Uint8BufferAttribute( array, itemSize );\n\n}\n\nfunction Uint8ClampedAttribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Uint8ClampedAttribute has been removed. Use new THREE.Uint8ClampedBufferAttribute() instead.' );\n\treturn new Uint8ClampedBufferAttribute( array, itemSize );\n\n}\n\nfunction Int16Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Int16Attribute has been removed. Use new THREE.Int16BufferAttribute() instead.' );\n\treturn new Int16BufferAttribute( array, itemSize );\n\n}\n\nfunction Uint16Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Uint16Attribute has been removed. Use new THREE.Uint16BufferAttribute() instead.' );\n\treturn new Uint16BufferAttribute( array, itemSize );\n\n}\n\nfunction Int32Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Int32Attribute has been removed. Use new THREE.Int32BufferAttribute() instead.' );\n\treturn new Int32BufferAttribute( array, itemSize );\n\n}\n\nfunction Uint32Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Uint32Attribute has been removed. Use new THREE.Uint32BufferAttribute() instead.' );\n\treturn new Uint32BufferAttribute( array, itemSize );\n\n}\n\nfunction Float32Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Float32Attribute has been removed. Use new THREE.Float32BufferAttribute() instead.' );\n\treturn new Float32BufferAttribute( array, itemSize );\n\n}\n\nfunction Float64Attribute( array, itemSize ) {\n\n\tconsole.warn( 'THREE.Float64Attribute has been removed. Use new THREE.Float64BufferAttribute() instead.' );\n\treturn new Float64BufferAttribute( array, itemSize );\n\n}\n\n//\n\nCurve.create = function ( construct, getPoint ) {\n\n\tconsole.log( 'THREE.Curve.create() has been deprecated' );\n\n\tconstruct.prototype = Object.create( Curve.prototype );\n\tconstruct.prototype.constructor = construct;\n\tconstruct.prototype.getPoint = getPoint;\n\n\treturn construct;\n\n};\n\n//\n\nPath.prototype.fromPoints = function ( points ) {\n\n\tconsole.warn( 'THREE.Path: .fromPoints() has been renamed to .setFromPoints().' );\n\treturn this.setFromPoints( points );\n\n};\n\n//\n\nfunction AxisHelper( size ) {\n\n\tconsole.warn( 'THREE.AxisHelper has been renamed to THREE.AxesHelper.' );\n\treturn new AxesHelper( size );\n\n}\n\nfunction BoundingBoxHelper( object, color ) {\n\n\tconsole.warn( 'THREE.BoundingBoxHelper has been deprecated. Creating a THREE.BoxHelper instead.' );\n\treturn new BoxHelper( object, color );\n\n}\n\nfunction EdgesHelper( object, hex ) {\n\n\tconsole.warn( 'THREE.EdgesHelper has been removed. Use THREE.EdgesGeometry instead.' );\n\treturn new LineSegments( new EdgesGeometry( object.geometry ), new LineBasicMaterial( { color: hex !== undefined ? hex : 0xffffff } ) );\n\n}\n\nGridHelper.prototype.setColors = function () {\n\n\tconsole.error( 'THREE.GridHelper: setColors() has been deprecated, pass them in the constructor instead.' );\n\n};\n\nSkeletonHelper.prototype.update = function () {\n\n\tconsole.error( 'THREE.SkeletonHelper: update() no longer needs to be called.' );\n\n};\n\nfunction WireframeHelper( object, hex ) {\n\n\tconsole.warn( 'THREE.WireframeHelper has been removed. Use THREE.WireframeGeometry instead.' );\n\treturn new LineSegments( new WireframeGeometry( object.geometry ), new LineBasicMaterial( { color: hex !== undefined ? hex : 0xffffff } ) );\n\n}\n\n//\n\nLoader.prototype.extractUrlBase = function ( url ) {\n\n\tconsole.warn( 'THREE.Loader: .extractUrlBase() has been deprecated. Use THREE.LoaderUtils.extractUrlBase() instead.' );\n\treturn LoaderUtils.extractUrlBase( url );\n\n};\n\nLoader.Handlers = {\n\n\tadd: function ( /* regex, loader */ ) {\n\n\t\tconsole.error( 'THREE.Loader: Handlers.add() has been removed. Use LoadingManager.addHandler() instead.' );\n\n\t},\n\n\tget: function ( /* file */ ) {\n\n\t\tconsole.error( 'THREE.Loader: Handlers.get() has been removed. Use LoadingManager.getHandler() instead.' );\n\n\t}\n\n};\n\nfunction XHRLoader( manager ) {\n\n\tconsole.warn( 'THREE.XHRLoader has been renamed to THREE.FileLoader.' );\n\treturn new FileLoader( manager );\n\n}\n\nfunction BinaryTextureLoader( manager ) {\n\n\tconsole.warn( 'THREE.BinaryTextureLoader has been renamed to THREE.DataTextureLoader.' );\n\treturn new DataTextureLoader( manager );\n\n}\n\n//\n\nBox2.prototype.center = function ( optionalTarget ) {\n\n\tconsole.warn( 'THREE.Box2: .center() has been renamed to .getCenter().' );\n\treturn this.getCenter( optionalTarget );\n\n};\n\nBox2.prototype.empty = function () {\n\n\tconsole.warn( 'THREE.Box2: .empty() has been renamed to .isEmpty().' );\n\treturn this.isEmpty();\n\n};\n\nBox2.prototype.isIntersectionBox = function ( box ) {\n\n\tconsole.warn( 'THREE.Box2: .isIntersectionBox() has been renamed to .intersectsBox().' );\n\treturn this.intersectsBox( box );\n\n};\n\nBox2.prototype.size = function ( optionalTarget ) {\n\n\tconsole.warn( 'THREE.Box2: .size() has been renamed to .getSize().' );\n\treturn this.getSize( optionalTarget );\n\n};\n\n//\n\nBox3.prototype.center = function ( optionalTarget ) {\n\n\tconsole.warn( 'THREE.Box3: .center() has been renamed to .getCenter().' );\n\treturn this.getCenter( optionalTarget );\n\n};\n\nBox3.prototype.empty = function () {\n\n\tconsole.warn( 'THREE.Box3: .empty() has been renamed to .isEmpty().' );\n\treturn this.isEmpty();\n\n};\n\nBox3.prototype.isIntersectionBox = function ( box ) {\n\n\tconsole.warn( 'THREE.Box3: .isIntersectionBox() has been renamed to .intersectsBox().' );\n\treturn this.intersectsBox( box );\n\n};\n\nBox3.prototype.isIntersectionSphere = function ( sphere ) {\n\n\tconsole.warn( 'THREE.Box3: .isIntersectionSphere() has been renamed to .intersectsSphere().' );\n\treturn this.intersectsSphere( sphere );\n\n};\n\nBox3.prototype.size = function ( optionalTarget ) {\n\n\tconsole.warn( 'THREE.Box3: .size() has been renamed to .getSize().' );\n\treturn this.getSize( optionalTarget );\n\n};\n\n//\n\nEuler.prototype.toVector3 = function () {\n\n\tconsole.error( 'THREE.Euler: .toVector3() has been removed. Use Vector3.setFromEuler() instead' );\n\n};\n\n\n//\n\nSphere.prototype.empty = function () {\n\n\tconsole.warn( 'THREE.Sphere: .empty() has been renamed to .isEmpty().' );\n\treturn this.isEmpty();\n\n};\n\n//\n\nFrustum.prototype.setFromMatrix = function ( m ) {\n\n\tconsole.warn( 'THREE.Frustum: .setFromMatrix() has been renamed to .setFromProjectionMatrix().' );\n\treturn this.setFromProjectionMatrix( m );\n\n};\n\n//\n\nLine3.prototype.center = function ( optionalTarget ) {\n\n\tconsole.warn( 'THREE.Line3: .center() has been renamed to .getCenter().' );\n\treturn this.getCenter( optionalTarget );\n\n};\n\n//\n\nMatrix3.prototype.flattenToArrayOffset = function ( array, offset ) {\n\n\tconsole.warn( 'THREE.Matrix3: .flattenToArrayOffset() has been deprecated. Use .toArray() instead.' );\n\treturn this.toArray( array, offset );\n\n};\n\nMatrix3.prototype.multiplyVector3 = function ( vector ) {\n\n\tconsole.warn( 'THREE.Matrix3: .multiplyVector3() has been removed. Use vector.applyMatrix3( matrix ) instead.' );\n\treturn vector.applyMatrix3( this );\n\n};\n\nMatrix3.prototype.multiplyVector3Array = function ( /* a */ ) {\n\n\tconsole.error( 'THREE.Matrix3: .multiplyVector3Array() has been removed.' );\n\n};\n\nMatrix3.prototype.applyToBufferAttribute = function ( attribute ) {\n\n\tconsole.warn( 'THREE.Matrix3: .applyToBufferAttribute() has been removed. Use attribute.applyMatrix3( matrix ) instead.' );\n\treturn attribute.applyMatrix3( this );\n\n};\n\nMatrix3.prototype.applyToVector3Array = function ( /* array, offset, length */ ) {\n\n\tconsole.error( 'THREE.Matrix3: .applyToVector3Array() has been removed.' );\n\n};\n\nMatrix3.prototype.getInverse = function ( matrix ) {\n\n\tconsole.warn( 'THREE.Matrix3: .getInverse() has been removed. Use matrixInv.copy( matrix ).invert(); instead.' );\n\treturn this.copy( matrix ).invert();\n\n};\n\n//\n\nMatrix4.prototype.extractPosition = function ( m ) {\n\n\tconsole.warn( 'THREE.Matrix4: .extractPosition() has been renamed to .copyPosition().' );\n\treturn this.copyPosition( m );\n\n};\n\nMatrix4.prototype.flattenToArrayOffset = function ( array, offset ) {\n\n\tconsole.warn( 'THREE.Matrix4: .flattenToArrayOffset() has been deprecated. Use .toArray() instead.' );\n\treturn this.toArray( array, offset );\n\n};\n\nMatrix4.prototype.getPosition = function () {\n\n\tconsole.warn( 'THREE.Matrix4: .getPosition() has been removed. Use Vector3.setFromMatrixPosition( matrix ) instead.' );\n\treturn new Vector3().setFromMatrixColumn( this, 3 );\n\n};\n\nMatrix4.prototype.setRotationFromQuaternion = function ( q ) {\n\n\tconsole.warn( 'THREE.Matrix4: .setRotationFromQuaternion() has been renamed to .makeRotationFromQuaternion().' );\n\treturn this.makeRotationFromQuaternion( q );\n\n};\n\nMatrix4.prototype.multiplyToArray = function () {\n\n\tconsole.warn( 'THREE.Matrix4: .multiplyToArray() has been removed.' );\n\n};\n\nMatrix4.prototype.multiplyVector3 = function ( vector ) {\n\n\tconsole.warn( 'THREE.Matrix4: .multiplyVector3() has been removed. Use vector.applyMatrix4( matrix ) instead.' );\n\treturn vector.applyMatrix4( this );\n\n};\n\nMatrix4.prototype.multiplyVector4 = function ( vector ) {\n\n\tconsole.warn( 'THREE.Matrix4: .multiplyVector4() has been removed. Use vector.applyMatrix4( matrix ) instead.' );\n\treturn vector.applyMatrix4( this );\n\n};\n\nMatrix4.prototype.multiplyVector3Array = function ( /* a */ ) {\n\n\tconsole.error( 'THREE.Matrix4: .multiplyVector3Array() has been removed.' );\n\n};\n\nMatrix4.prototype.rotateAxis = function ( v ) {\n\n\tconsole.warn( 'THREE.Matrix4: .rotateAxis() has been removed. Use Vector3.transformDirection( matrix ) instead.' );\n\tv.transformDirection( this );\n\n};\n\nMatrix4.prototype.crossVector = function ( vector ) {\n\n\tconsole.warn( 'THREE.Matrix4: .crossVector() has been removed. Use vector.applyMatrix4( matrix ) instead.' );\n\treturn vector.applyMatrix4( this );\n\n};\n\nMatrix4.prototype.translate = function () {\n\n\tconsole.error( 'THREE.Matrix4: .translate() has been removed.' );\n\n};\n\nMatrix4.prototype.rotateX = function () {\n\n\tconsole.error( 'THREE.Matrix4: .rotateX() has been removed.' );\n\n};\n\nMatrix4.prototype.rotateY = function () {\n\n\tconsole.error( 'THREE.Matrix4: .rotateY() has been removed.' );\n\n};\n\nMatrix4.prototype.rotateZ = function () {\n\n\tconsole.error( 'THREE.Matrix4: .rotateZ() has been removed.' );\n\n};\n\nMatrix4.prototype.rotateByAxis = function () {\n\n\tconsole.error( 'THREE.Matrix4: .rotateByAxis() has been removed.' );\n\n};\n\nMatrix4.prototype.applyToBufferAttribute = function ( attribute ) {\n\n\tconsole.warn( 'THREE.Matrix4: .applyToBufferAttribute() has been removed. Use attribute.applyMatrix4( matrix ) instead.' );\n\treturn attribute.applyMatrix4( this );\n\n};\n\nMatrix4.prototype.applyToVector3Array = function ( /* array, offset, length */ ) {\n\n\tconsole.error( 'THREE.Matrix4: .applyToVector3Array() has been removed.' );\n\n};\n\nMatrix4.prototype.makeFrustum = function ( left, right, bottom, top, near, far ) {\n\n\tconsole.warn( 'THREE.Matrix4: .makeFrustum() has been removed. Use .makePerspective( left, right, top, bottom, near, far ) instead.' );\n\treturn this.makePerspective( left, right, top, bottom, near, far );\n\n};\n\nMatrix4.prototype.getInverse = function ( matrix ) {\n\n\tconsole.warn( 'THREE.Matrix4: .getInverse() has been removed. Use matrixInv.copy( matrix ).invert(); instead.' );\n\treturn this.copy( matrix ).invert();\n\n};\n\n//\n\nPlane.prototype.isIntersectionLine = function ( line ) {\n\n\tconsole.warn( 'THREE.Plane: .isIntersectionLine() has been renamed to .intersectsLine().' );\n\treturn this.intersectsLine( line );\n\n};\n\n//\n\nQuaternion.prototype.multiplyVector3 = function ( vector ) {\n\n\tconsole.warn( 'THREE.Quaternion: .multiplyVector3() has been removed. Use is now vector.applyQuaternion( quaternion ) instead.' );\n\treturn vector.applyQuaternion( this );\n\n};\n\nQuaternion.prototype.inverse = function ( ) {\n\n\tconsole.warn( 'THREE.Quaternion: .inverse() has been renamed to invert().' );\n\treturn this.invert();\n\n};\n\n//\n\nRay.prototype.isIntersectionBox = function ( box ) {\n\n\tconsole.warn( 'THREE.Ray: .isIntersectionBox() has been renamed to .intersectsBox().' );\n\treturn this.intersectsBox( box );\n\n};\n\nRay.prototype.isIntersectionPlane = function ( plane ) {\n\n\tconsole.warn( 'THREE.Ray: .isIntersectionPlane() has been renamed to .intersectsPlane().' );\n\treturn this.intersectsPlane( plane );\n\n};\n\nRay.prototype.isIntersectionSphere = function ( sphere ) {\n\n\tconsole.warn( 'THREE.Ray: .isIntersectionSphere() has been renamed to .intersectsSphere().' );\n\treturn this.intersectsSphere( sphere );\n\n};\n\n//\n\nTriangle.prototype.area = function () {\n\n\tconsole.warn( 'THREE.Triangle: .area() has been renamed to .getArea().' );\n\treturn this.getArea();\n\n};\n\nTriangle.prototype.barycoordFromPoint = function ( point, target ) {\n\n\tconsole.warn( 'THREE.Triangle: .barycoordFromPoint() has been renamed to .getBarycoord().' );\n\treturn this.getBarycoord( point, target );\n\n};\n\nTriangle.prototype.midpoint = function ( target ) {\n\n\tconsole.warn( 'THREE.Triangle: .midpoint() has been renamed to .getMidpoint().' );\n\treturn this.getMidpoint( target );\n\n};\n\nTriangle.prototypenormal = function ( target ) {\n\n\tconsole.warn( 'THREE.Triangle: .normal() has been renamed to .getNormal().' );\n\treturn this.getNormal( target );\n\n};\n\nTriangle.prototype.plane = function ( target ) {\n\n\tconsole.warn( 'THREE.Triangle: .plane() has been renamed to .getPlane().' );\n\treturn this.getPlane( target );\n\n};\n\nTriangle.barycoordFromPoint = function ( point, a, b, c, target ) {\n\n\tconsole.warn( 'THREE.Triangle: .barycoordFromPoint() has been renamed to .getBarycoord().' );\n\treturn Triangle.getBarycoord( point, a, b, c, target );\n\n};\n\nTriangle.normal = function ( a, b, c, target ) {\n\n\tconsole.warn( 'THREE.Triangle: .normal() has been renamed to .getNormal().' );\n\treturn Triangle.getNormal( a, b, c, target );\n\n};\n\n//\n\nShape.prototype.extractAllPoints = function ( divisions ) {\n\n\tconsole.warn( 'THREE.Shape: .extractAllPoints() has been removed. Use .extractPoints() instead.' );\n\treturn this.extractPoints( divisions );\n\n};\n\nShape.prototype.extrude = function ( options ) {\n\n\tconsole.warn( 'THREE.Shape: .extrude() has been removed. Use ExtrudeGeometry() instead.' );\n\treturn new ExtrudeGeometry( this, options );\n\n};\n\nShape.prototype.makeGeometry = function ( options ) {\n\n\tconsole.warn( 'THREE.Shape: .makeGeometry() has been removed. Use ShapeGeometry() instead.' );\n\treturn new ShapeGeometry( this, options );\n\n};\n\n//\n\nVector2.prototype.fromAttribute = function ( attribute, index, offset ) {\n\n\tconsole.warn( 'THREE.Vector2: .fromAttribute() has been renamed to .fromBufferAttribute().' );\n\treturn this.fromBufferAttribute( attribute, index, offset );\n\n};\n\nVector2.prototype.distanceToManhattan = function ( v ) {\n\n\tconsole.warn( 'THREE.Vector2: .distanceToManhattan() has been renamed to .manhattanDistanceTo().' );\n\treturn this.manhattanDistanceTo( v );\n\n};\n\nVector2.prototype.lengthManhattan = function () {\n\n\tconsole.warn( 'THREE.Vector2: .lengthManhattan() has been renamed to .manhattanLength().' );\n\treturn this.manhattanLength();\n\n};\n\n//\n\nVector3.prototype.setEulerFromRotationMatrix = function () {\n\n\tconsole.error( 'THREE.Vector3: .setEulerFromRotationMatrix() has been removed. Use Euler.setFromRotationMatrix() instead.' );\n\n};\n\nVector3.prototype.setEulerFromQuaternion = function () {\n\n\tconsole.error( 'THREE.Vector3: .setEulerFromQuaternion() has been removed. Use Euler.setFromQuaternion() instead.' );\n\n};\n\nVector3.prototype.getPositionFromMatrix = function ( m ) {\n\n\tconsole.warn( 'THREE.Vector3: .getPositionFromMatrix() has been renamed to .setFromMatrixPosition().' );\n\treturn this.setFromMatrixPosition( m );\n\n};\n\nVector3.prototype.getScaleFromMatrix = function ( m ) {\n\n\tconsole.warn( 'THREE.Vector3: .getScaleFromMatrix() has been renamed to .setFromMatrixScale().' );\n\treturn this.setFromMatrixScale( m );\n\n};\n\nVector3.prototype.getColumnFromMatrix = function ( index, matrix ) {\n\n\tconsole.warn( 'THREE.Vector3: .getColumnFromMatrix() has been renamed to .setFromMatrixColumn().' );\n\treturn this.setFromMatrixColumn( matrix, index );\n\n};\n\nVector3.prototype.applyProjection = function ( m ) {\n\n\tconsole.warn( 'THREE.Vector3: .applyProjection() has been removed. Use .applyMatrix4( m ) instead.' );\n\treturn this.applyMatrix4( m );\n\n};\n\nVector3.prototype.fromAttribute = function ( attribute, index, offset ) {\n\n\tconsole.warn( 'THREE.Vector3: .fromAttribute() has been renamed to .fromBufferAttribute().' );\n\treturn this.fromBufferAttribute( attribute, index, offset );\n\n};\n\nVector3.prototype.distanceToManhattan = function ( v ) {\n\n\tconsole.warn( 'THREE.Vector3: .distanceToManhattan() has been renamed to .manhattanDistanceTo().' );\n\treturn this.manhattanDistanceTo( v );\n\n};\n\nVector3.prototype.lengthManhattan = function () {\n\n\tconsole.warn( 'THREE.Vector3: .lengthManhattan() has been renamed to .manhattanLength().' );\n\treturn this.manhattanLength();\n\n};\n\n//\n\nVector4.prototype.fromAttribute = function ( attribute, index, offset ) {\n\n\tconsole.warn( 'THREE.Vector4: .fromAttribute() has been renamed to .fromBufferAttribute().' );\n\treturn this.fromBufferAttribute( attribute, index, offset );\n\n};\n\nVector4.prototype.lengthManhattan = function () {\n\n\tconsole.warn( 'THREE.Vector4: .lengthManhattan() has been renamed to .manhattanLength().' );\n\treturn this.manhattanLength();\n\n};\n\n//\n\nObject3D.prototype.getChildByName = function ( name ) {\n\n\tconsole.warn( 'THREE.Object3D: .getChildByName() has been renamed to .getObjectByName().' );\n\treturn this.getObjectByName( name );\n\n};\n\nObject3D.prototype.renderDepth = function () {\n\n\tconsole.warn( 'THREE.Object3D: .renderDepth has been removed. Use .renderOrder, instead.' );\n\n};\n\nObject3D.prototype.translate = function ( distance, axis ) {\n\n\tconsole.warn( 'THREE.Object3D: .translate() has been removed. Use .translateOnAxis( axis, distance ) instead.' );\n\treturn this.translateOnAxis( axis, distance );\n\n};\n\nObject3D.prototype.getWorldRotation = function () {\n\n\tconsole.error( 'THREE.Object3D: .getWorldRotation() has been removed. Use THREE.Object3D.getWorldQuaternion( target ) instead.' );\n\n};\n\nObject3D.prototype.applyMatrix = function ( matrix ) {\n\n\tconsole.warn( 'THREE.Object3D: .applyMatrix() has been renamed to .applyMatrix4().' );\n\treturn this.applyMatrix4( matrix );\n\n};\n\nObject.defineProperties( Object3D.prototype, {\n\n\teulerOrder: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.Object3D: .eulerOrder is now .rotation.order.' );\n\t\t\treturn this.rotation.order;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Object3D: .eulerOrder is now .rotation.order.' );\n\t\t\tthis.rotation.order = value;\n\n\t\t}\n\t},\n\tuseQuaternion: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.Object3D: .useQuaternion has been removed. The library now uses quaternions by default.' );\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.Object3D: .useQuaternion has been removed. The library now uses quaternions by default.' );\n\n\t\t}\n\t}\n\n} );\n\nMesh.prototype.setDrawMode = function () {\n\n\tconsole.error( 'THREE.Mesh: .setDrawMode() has been removed. The renderer now always assumes THREE.TrianglesDrawMode. Transform your geometry via BufferGeometryUtils.toTrianglesDrawMode() if necessary.' );\n\n};\n\nObject.defineProperties( Mesh.prototype, {\n\n\tdrawMode: {\n\t\tget: function () {\n\n\t\t\tconsole.error( 'THREE.Mesh: .drawMode has been removed. The renderer now always assumes THREE.TrianglesDrawMode.' );\n\t\t\treturn TrianglesDrawMode;\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.error( 'THREE.Mesh: .drawMode has been removed. The renderer now always assumes THREE.TrianglesDrawMode. Transform your geometry via BufferGeometryUtils.toTrianglesDrawMode() if necessary.' );\n\n\t\t}\n\t}\n\n} );\n\nSkinnedMesh.prototype.initBones = function () {\n\n\tconsole.error( 'THREE.SkinnedMesh: initBones() has been removed.' );\n\n};\n\n//\n\nPerspectiveCamera.prototype.setLens = function ( focalLength, filmGauge ) {\n\n\tconsole.warn( 'THREE.PerspectiveCamera.setLens is deprecated. ' +\n\t\t\t'Use .setFocalLength and .filmGauge for a photographic setup.' );\n\n\tif ( filmGauge !== undefined ) this.filmGauge = filmGauge;\n\tthis.setFocalLength( focalLength );\n\n};\n\n//\n\nObject.defineProperties( Light.prototype, {\n\tonlyShadow: {\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.Light: .onlyShadow has been removed.' );\n\n\t\t}\n\t},\n\tshadowCameraFov: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraFov is now .shadow.camera.fov.' );\n\t\t\tthis.shadow.camera.fov = value;\n\n\t\t}\n\t},\n\tshadowCameraLeft: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraLeft is now .shadow.camera.left.' );\n\t\t\tthis.shadow.camera.left = value;\n\n\t\t}\n\t},\n\tshadowCameraRight: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraRight is now .shadow.camera.right.' );\n\t\t\tthis.shadow.camera.right = value;\n\n\t\t}\n\t},\n\tshadowCameraTop: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraTop is now .shadow.camera.top.' );\n\t\t\tthis.shadow.camera.top = value;\n\n\t\t}\n\t},\n\tshadowCameraBottom: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraBottom is now .shadow.camera.bottom.' );\n\t\t\tthis.shadow.camera.bottom = value;\n\n\t\t}\n\t},\n\tshadowCameraNear: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraNear is now .shadow.camera.near.' );\n\t\t\tthis.shadow.camera.near = value;\n\n\t\t}\n\t},\n\tshadowCameraFar: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraFar is now .shadow.camera.far.' );\n\t\t\tthis.shadow.camera.far = value;\n\n\t\t}\n\t},\n\tshadowCameraVisible: {\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowCameraVisible has been removed. Use new THREE.CameraHelper( light.shadow.camera ) instead.' );\n\n\t\t}\n\t},\n\tshadowBias: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowBias is now .shadow.bias.' );\n\t\t\tthis.shadow.bias = value;\n\n\t\t}\n\t},\n\tshadowDarkness: {\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowDarkness has been removed.' );\n\n\t\t}\n\t},\n\tshadowMapWidth: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowMapWidth is now .shadow.mapSize.width.' );\n\t\t\tthis.shadow.mapSize.width = value;\n\n\t\t}\n\t},\n\tshadowMapHeight: {\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.Light: .shadowMapHeight is now .shadow.mapSize.height.' );\n\t\t\tthis.shadow.mapSize.height = value;\n\n\t\t}\n\t}\n} );\n\n//\n\nObject.defineProperties( BufferAttribute.prototype, {\n\n\tlength: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.BufferAttribute: .length has been deprecated. Use .count instead.' );\n\t\t\treturn this.array.length;\n\n\t\t}\n\t},\n\tdynamic: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.BufferAttribute: .dynamic has been deprecated. Use .usage instead.' );\n\t\t\treturn this.usage === DynamicDrawUsage;\n\n\t\t},\n\t\tset: function ( /* value */ ) {\n\n\t\t\tconsole.warn( 'THREE.BufferAttribute: .dynamic has been deprecated. Use .usage instead.' );\n\t\t\tthis.setUsage( DynamicDrawUsage );\n\n\t\t}\n\t}\n\n} );\n\nBufferAttribute.prototype.setDynamic = function ( value ) {\n\n\tconsole.warn( 'THREE.BufferAttribute: .setDynamic() has been deprecated. Use .setUsage() instead.' );\n\tthis.setUsage( value === true ? DynamicDrawUsage : StaticDrawUsage );\n\treturn this;\n\n};\n\nBufferAttribute.prototype.copyIndicesArray = function ( /* indices */ ) {\n\n\tconsole.error( 'THREE.BufferAttribute: .copyIndicesArray() has been removed.' );\n\n},\n\nBufferAttribute.prototype.setArray = function ( /* array */ ) {\n\n\tconsole.error( 'THREE.BufferAttribute: .setArray has been removed. Use BufferGeometry .setAttribute to replace/resize attribute buffers' );\n\n};\n\n//\n\nBufferGeometry.prototype.addIndex = function ( index ) {\n\n\tconsole.warn( 'THREE.BufferGeometry: .addIndex() has been renamed to .setIndex().' );\n\tthis.setIndex( index );\n\n};\n\nBufferGeometry.prototype.addAttribute = function ( name, attribute ) {\n\n\tconsole.warn( 'THREE.BufferGeometry: .addAttribute() has been renamed to .setAttribute().' );\n\n\tif ( ! ( attribute && attribute.isBufferAttribute ) && ! ( attribute && attribute.isInterleavedBufferAttribute ) ) {\n\n\t\tconsole.warn( 'THREE.BufferGeometry: .addAttribute() now expects ( name, attribute ).' );\n\n\t\treturn this.setAttribute( name, new BufferAttribute( arguments[ 1 ], arguments[ 2 ] ) );\n\n\t}\n\n\tif ( name === 'index' ) {\n\n\t\tconsole.warn( 'THREE.BufferGeometry.addAttribute: Use .setIndex() for index attribute.' );\n\t\tthis.setIndex( attribute );\n\n\t\treturn this;\n\n\t}\n\n\treturn this.setAttribute( name, attribute );\n\n};\n\nBufferGeometry.prototype.addDrawCall = function ( start, count, indexOffset ) {\n\n\tif ( indexOffset !== undefined ) {\n\n\t\tconsole.warn( 'THREE.BufferGeometry: .addDrawCall() no longer supports indexOffset.' );\n\n\t}\n\n\tconsole.warn( 'THREE.BufferGeometry: .addDrawCall() is now .addGroup().' );\n\tthis.addGroup( start, count );\n\n};\n\nBufferGeometry.prototype.clearDrawCalls = function () {\n\n\tconsole.warn( 'THREE.BufferGeometry: .clearDrawCalls() is now .clearGroups().' );\n\tthis.clearGroups();\n\n};\n\nBufferGeometry.prototype.computeOffsets = function () {\n\n\tconsole.warn( 'THREE.BufferGeometry: .computeOffsets() has been removed.' );\n\n};\n\nBufferGeometry.prototype.removeAttribute = function ( name ) {\n\n\tconsole.warn( 'THREE.BufferGeometry: .removeAttribute() has been renamed to .deleteAttribute().' );\n\n\treturn this.deleteAttribute( name );\n\n};\n\nBufferGeometry.prototype.applyMatrix = function ( matrix ) {\n\n\tconsole.warn( 'THREE.BufferGeometry: .applyMatrix() has been renamed to .applyMatrix4().' );\n\treturn this.applyMatrix4( matrix );\n\n};\n\nObject.defineProperties( BufferGeometry.prototype, {\n\n\tdrawcalls: {\n\t\tget: function () {\n\n\t\t\tconsole.error( 'THREE.BufferGeometry: .drawcalls has been renamed to .groups.' );\n\t\t\treturn this.groups;\n\n\t\t}\n\t},\n\toffsets: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.BufferGeometry: .offsets has been renamed to .groups.' );\n\t\t\treturn this.groups;\n\n\t\t}\n\t}\n\n} );\n\nInterleavedBuffer.prototype.setDynamic = function ( value ) {\n\n\tconsole.warn( 'THREE.InterleavedBuffer: .setDynamic() has been deprecated. Use .setUsage() instead.' );\n\tthis.setUsage( value === true ? DynamicDrawUsage : StaticDrawUsage );\n\treturn this;\n\n};\n\nInterleavedBuffer.prototype.setArray = function ( /* array */ ) {\n\n\tconsole.error( 'THREE.InterleavedBuffer: .setArray has been removed. Use BufferGeometry .setAttribute to replace/resize attribute buffers' );\n\n};\n\n//\n\nExtrudeGeometry.prototype.getArrays = function () {\n\n\tconsole.error( 'THREE.ExtrudeGeometry: .getArrays() has been removed.' );\n\n};\n\nExtrudeGeometry.prototype.addShapeList = function () {\n\n\tconsole.error( 'THREE.ExtrudeGeometry: .addShapeList() has been removed.' );\n\n};\n\nExtrudeGeometry.prototype.addShape = function () {\n\n\tconsole.error( 'THREE.ExtrudeGeometry: .addShape() has been removed.' );\n\n};\n\n//\n\nScene.prototype.dispose = function () {\n\n\tconsole.error( 'THREE.Scene: .dispose() has been removed.' );\n\n};\n\n//\n\nUniform.prototype.onUpdate = function () {\n\n\tconsole.warn( 'THREE.Uniform: .onUpdate() has been removed. Use object.onBeforeRender() instead.' );\n\treturn this;\n\n};\n\n//\n\nObject.defineProperties( Material.prototype, {\n\n\twrapAround: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.Material: .wrapAround has been removed.' );\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.Material: .wrapAround has been removed.' );\n\n\t\t}\n\t},\n\n\toverdraw: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.Material: .overdraw has been removed.' );\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.Material: .overdraw has been removed.' );\n\n\t\t}\n\t},\n\n\twrapRGB: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.Material: .wrapRGB has been removed.' );\n\t\t\treturn new Color();\n\n\t\t}\n\t},\n\n\tshading: {\n\t\tget: function () {\n\n\t\t\tconsole.error( 'THREE.' + this.type + ': .shading has been removed. Use the boolean .flatShading instead.' );\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.' + this.type + ': .shading has been removed. Use the boolean .flatShading instead.' );\n\t\t\tthis.flatShading = ( value === FlatShading );\n\n\t\t}\n\t},\n\n\tstencilMask: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.' + this.type + ': .stencilMask has been removed. Use .stencilFuncMask instead.' );\n\t\t\treturn this.stencilFuncMask;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.' + this.type + ': .stencilMask has been removed. Use .stencilFuncMask instead.' );\n\t\t\tthis.stencilFuncMask = value;\n\n\t\t}\n\t},\n\n\tvertexTangents: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.' + this.type + ': .vertexTangents has been removed.' );\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.' + this.type + ': .vertexTangents has been removed.' );\n\n\t\t}\n\t},\n\n} );\n\nObject.defineProperties( ShaderMaterial.prototype, {\n\n\tderivatives: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.ShaderMaterial: .derivatives has been moved to .extensions.derivatives.' );\n\t\t\treturn this.extensions.derivatives;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE. ShaderMaterial: .derivatives has been moved to .extensions.derivatives.' );\n\t\t\tthis.extensions.derivatives = value;\n\n\t\t}\n\t}\n\n} );\n\n//\n\nWebGLRenderer.prototype.clearTarget = function ( renderTarget, color, depth, stencil ) {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .clearTarget() has been deprecated. Use .setRenderTarget() and .clear() instead.' );\n\tthis.setRenderTarget( renderTarget );\n\tthis.clear( color, depth, stencil );\n\n};\n\nWebGLRenderer.prototype.animate = function ( callback ) {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .animate() is now .setAnimationLoop().' );\n\tthis.setAnimationLoop( callback );\n\n};\n\nWebGLRenderer.prototype.getCurrentRenderTarget = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .getCurrentRenderTarget() is now .getRenderTarget().' );\n\treturn this.getRenderTarget();\n\n};\n\nWebGLRenderer.prototype.getMaxAnisotropy = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .getMaxAnisotropy() is now .capabilities.getMaxAnisotropy().' );\n\treturn this.capabilities.getMaxAnisotropy();\n\n};\n\nWebGLRenderer.prototype.getPrecision = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .getPrecision() is now .capabilities.precision.' );\n\treturn this.capabilities.precision;\n\n};\n\nWebGLRenderer.prototype.resetGLState = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .resetGLState() is now .state.reset().' );\n\treturn this.state.reset();\n\n};\n\nWebGLRenderer.prototype.supportsFloatTextures = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsFloatTextures() is now .extensions.get( \\'OES_texture_float\\' ).' );\n\treturn this.extensions.get( 'OES_texture_float' );\n\n};\n\nWebGLRenderer.prototype.supportsHalfFloatTextures = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsHalfFloatTextures() is now .extensions.get( \\'OES_texture_half_float\\' ).' );\n\treturn this.extensions.get( 'OES_texture_half_float' );\n\n};\n\nWebGLRenderer.prototype.supportsStandardDerivatives = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsStandardDerivatives() is now .extensions.get( \\'OES_standard_derivatives\\' ).' );\n\treturn this.extensions.get( 'OES_standard_derivatives' );\n\n};\n\nWebGLRenderer.prototype.supportsCompressedTextureS3TC = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsCompressedTextureS3TC() is now .extensions.get( \\'WEBGL_compressed_texture_s3tc\\' ).' );\n\treturn this.extensions.get( 'WEBGL_compressed_texture_s3tc' );\n\n};\n\nWebGLRenderer.prototype.supportsCompressedTexturePVRTC = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsCompressedTexturePVRTC() is now .extensions.get( \\'WEBGL_compressed_texture_pvrtc\\' ).' );\n\treturn this.extensions.get( 'WEBGL_compressed_texture_pvrtc' );\n\n};\n\nWebGLRenderer.prototype.supportsBlendMinMax = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsBlendMinMax() is now .extensions.get( \\'EXT_blend_minmax\\' ).' );\n\treturn this.extensions.get( 'EXT_blend_minmax' );\n\n};\n\nWebGLRenderer.prototype.supportsVertexTextures = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsVertexTextures() is now .capabilities.vertexTextures.' );\n\treturn this.capabilities.vertexTextures;\n\n};\n\nWebGLRenderer.prototype.supportsInstancedArrays = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .supportsInstancedArrays() is now .extensions.get( \\'ANGLE_instanced_arrays\\' ).' );\n\treturn this.extensions.get( 'ANGLE_instanced_arrays' );\n\n};\n\nWebGLRenderer.prototype.enableScissorTest = function ( boolean ) {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .enableScissorTest() is now .setScissorTest().' );\n\tthis.setScissorTest( boolean );\n\n};\n\nWebGLRenderer.prototype.initMaterial = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .initMaterial() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.addPrePlugin = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .addPrePlugin() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.addPostPlugin = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .addPostPlugin() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.updateShadowMap = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .updateShadowMap() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.setFaceCulling = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .setFaceCulling() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.allocTextureUnit = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .allocTextureUnit() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.setTexture = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .setTexture() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.setTexture2D = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .setTexture2D() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.setTextureCube = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .setTextureCube() has been removed.' );\n\n};\n\nWebGLRenderer.prototype.getActiveMipMapLevel = function () {\n\n\tconsole.warn( 'THREE.WebGLRenderer: .getActiveMipMapLevel() is now .getActiveMipmapLevel().' );\n\treturn this.getActiveMipmapLevel();\n\n};\n\nObject.defineProperties( WebGLRenderer.prototype, {\n\n\tshadowMapEnabled: {\n\t\tget: function () {\n\n\t\t\treturn this.shadowMap.enabled;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMapEnabled is now .shadowMap.enabled.' );\n\t\t\tthis.shadowMap.enabled = value;\n\n\t\t}\n\t},\n\tshadowMapType: {\n\t\tget: function () {\n\n\t\t\treturn this.shadowMap.type;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMapType is now .shadowMap.type.' );\n\t\t\tthis.shadowMap.type = value;\n\n\t\t}\n\t},\n\tshadowMapCullFace: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMapCullFace has been removed. Set Material.shadowSide instead.' );\n\t\t\treturn undefined;\n\n\t\t},\n\t\tset: function ( /* value */ ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMapCullFace has been removed. Set Material.shadowSide instead.' );\n\n\t\t}\n\t},\n\tcontext: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .context has been removed. Use .getContext() instead.' );\n\t\t\treturn this.getContext();\n\n\t\t}\n\t},\n\tvr: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .vr has been renamed to .xr' );\n\t\t\treturn this.xr;\n\n\t\t}\n\t},\n\tgammaInput: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .gammaInput has been removed. Set the encoding for textures via Texture.encoding instead.' );\n\t\t\treturn false;\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .gammaInput has been removed. Set the encoding for textures via Texture.encoding instead.' );\n\n\t\t}\n\t},\n\tgammaOutput: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .gammaOutput has been removed. Set WebGLRenderer.outputEncoding instead.' );\n\t\t\treturn false;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .gammaOutput has been removed. Set WebGLRenderer.outputEncoding instead.' );\n\t\t\tthis.outputEncoding = ( value === true ) ? sRGBEncoding : LinearEncoding;\n\n\t\t}\n\t},\n\ttoneMappingWhitePoint: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .toneMappingWhitePoint has been removed.' );\n\t\t\treturn 1.0;\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .toneMappingWhitePoint has been removed.' );\n\n\t\t}\n\t},\n\tgammaFactor: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .gammaFactor has been removed.' );\n\t\t\treturn 2;\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .gammaFactor has been removed.' );\n\n\t\t}\n\t}\n} );\n\nObject.defineProperties( WebGLShadowMap.prototype, {\n\n\tcullFace: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMap.cullFace has been removed. Set Material.shadowSide instead.' );\n\t\t\treturn undefined;\n\n\t\t},\n\t\tset: function ( /* cullFace */ ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMap.cullFace has been removed. Set Material.shadowSide instead.' );\n\n\t\t}\n\t},\n\trenderReverseSided: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMap.renderReverseSided has been removed. Set Material.shadowSide instead.' );\n\t\t\treturn undefined;\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMap.renderReverseSided has been removed. Set Material.shadowSide instead.' );\n\n\t\t}\n\t},\n\trenderSingleSided: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMap.renderSingleSided has been removed. Set Material.shadowSide instead.' );\n\t\t\treturn undefined;\n\n\t\t},\n\t\tset: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderer: .shadowMap.renderSingleSided has been removed. Set Material.shadowSide instead.' );\n\n\t\t}\n\t}\n\n} );\n\nfunction WebGLRenderTargetCube( width, height, options ) {\n\n\tconsole.warn( 'THREE.WebGLRenderTargetCube( width, height, options ) is now WebGLCubeRenderTarget( size, options ).' );\n\treturn new WebGLCubeRenderTarget( width, options );\n\n}\n\n//\n\nObject.defineProperties( WebGLRenderTarget.prototype, {\n\n\twrapS: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .wrapS is now .texture.wrapS.' );\n\t\t\treturn this.texture.wrapS;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .wrapS is now .texture.wrapS.' );\n\t\t\tthis.texture.wrapS = value;\n\n\t\t}\n\t},\n\twrapT: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .wrapT is now .texture.wrapT.' );\n\t\t\treturn this.texture.wrapT;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .wrapT is now .texture.wrapT.' );\n\t\t\tthis.texture.wrapT = value;\n\n\t\t}\n\t},\n\tmagFilter: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .magFilter is now .texture.magFilter.' );\n\t\t\treturn this.texture.magFilter;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .magFilter is now .texture.magFilter.' );\n\t\t\tthis.texture.magFilter = value;\n\n\t\t}\n\t},\n\tminFilter: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .minFilter is now .texture.minFilter.' );\n\t\t\treturn this.texture.minFilter;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .minFilter is now .texture.minFilter.' );\n\t\t\tthis.texture.minFilter = value;\n\n\t\t}\n\t},\n\tanisotropy: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .anisotropy is now .texture.anisotropy.' );\n\t\t\treturn this.texture.anisotropy;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .anisotropy is now .texture.anisotropy.' );\n\t\t\tthis.texture.anisotropy = value;\n\n\t\t}\n\t},\n\toffset: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .offset is now .texture.offset.' );\n\t\t\treturn this.texture.offset;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .offset is now .texture.offset.' );\n\t\t\tthis.texture.offset = value;\n\n\t\t}\n\t},\n\trepeat: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .repeat is now .texture.repeat.' );\n\t\t\treturn this.texture.repeat;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .repeat is now .texture.repeat.' );\n\t\t\tthis.texture.repeat = value;\n\n\t\t}\n\t},\n\tformat: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .format is now .texture.format.' );\n\t\t\treturn this.texture.format;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .format is now .texture.format.' );\n\t\t\tthis.texture.format = value;\n\n\t\t}\n\t},\n\ttype: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .type is now .texture.type.' );\n\t\t\treturn this.texture.type;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .type is now .texture.type.' );\n\t\t\tthis.texture.type = value;\n\n\t\t}\n\t},\n\tgenerateMipmaps: {\n\t\tget: function () {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .generateMipmaps is now .texture.generateMipmaps.' );\n\t\t\treturn this.texture.generateMipmaps;\n\n\t\t},\n\t\tset: function ( value ) {\n\n\t\t\tconsole.warn( 'THREE.WebGLRenderTarget: .generateMipmaps is now .texture.generateMipmaps.' );\n\t\t\tthis.texture.generateMipmaps = value;\n\n\t\t}\n\t}\n\n} );\n\n//\n\nAudio.prototype.load = function ( file ) {\n\n\tconsole.warn( 'THREE.Audio: .load has been deprecated. Use THREE.AudioLoader instead.' );\n\tconst scope = this;\n\tconst audioLoader = new AudioLoader();\n\taudioLoader.load( file, function ( buffer ) {\n\n\t\tscope.setBuffer( buffer );\n\n\t} );\n\treturn this;\n\n};\n\n\nAudioAnalyser.prototype.getData = function () {\n\n\tconsole.warn( 'THREE.AudioAnalyser: .getData() is now .getFrequencyData().' );\n\treturn this.getFrequencyData();\n\n};\n\n//\n\nCubeCamera.prototype.updateCubeMap = function ( renderer, scene ) {\n\n\tconsole.warn( 'THREE.CubeCamera: .updateCubeMap() is now .update().' );\n\treturn this.update( renderer, scene );\n\n};\n\nCubeCamera.prototype.clear = function ( renderer, color, depth, stencil ) {\n\n\tconsole.warn( 'THREE.CubeCamera: .clear() is now .renderTarget.clear().' );\n\treturn this.renderTarget.clear( renderer, color, depth, stencil );\n\n};\n\nImageUtils.crossOrigin = undefined;\n\nImageUtils.loadTexture = function ( url, mapping, onLoad, onError ) {\n\n\tconsole.warn( 'THREE.ImageUtils.loadTexture has been deprecated. Use THREE.TextureLoader() instead.' );\n\n\tconst loader = new TextureLoader();\n\tloader.setCrossOrigin( this.crossOrigin );\n\n\tconst texture = loader.load( url, onLoad, undefined, onError );\n\n\tif ( mapping ) texture.mapping = mapping;\n\n\treturn texture;\n\n};\n\nImageUtils.loadTextureCube = function ( urls, mapping, onLoad, onError ) {\n\n\tconsole.warn( 'THREE.ImageUtils.loadTextureCube has been deprecated. Use THREE.CubeTextureLoader() instead.' );\n\n\tconst loader = new CubeTextureLoader();\n\tloader.setCrossOrigin( this.crossOrigin );\n\n\tconst texture = loader.load( urls, onLoad, undefined, onError );\n\n\tif ( mapping ) texture.mapping = mapping;\n\n\treturn texture;\n\n};\n\nImageUtils.loadCompressedTexture = function () {\n\n\tconsole.error( 'THREE.ImageUtils.loadCompressedTexture has been removed. Use THREE.DDSLoader instead.' );\n\n};\n\nImageUtils.loadCompressedTextureCube = function () {\n\n\tconsole.error( 'THREE.ImageUtils.loadCompressedTextureCube has been removed. Use THREE.DDSLoader instead.' );\n\n};\n\n//\n\nfunction CanvasRenderer() {\n\n\tconsole.error( 'THREE.CanvasRenderer has been removed' );\n\n}\n\n//\n\nfunction JSONLoader() {\n\n\tconsole.error( 'THREE.JSONLoader has been removed.' );\n\n}\n\n//\n\nconst SceneUtils = {\n\n\tcreateMultiMaterialObject: function ( /* geometry, materials */ ) {\n\n\t\tconsole.error( 'THREE.SceneUtils has been moved to /examples/jsm/utils/SceneUtils.js' );\n\n\t},\n\n\tdetach: function ( /* child, parent, scene */ ) {\n\n\t\tconsole.error( 'THREE.SceneUtils has been moved to /examples/jsm/utils/SceneUtils.js' );\n\n\t},\n\n\tattach: function ( /* child, scene, parent */ ) {\n\n\t\tconsole.error( 'THREE.SceneUtils has been moved to /examples/jsm/utils/SceneUtils.js' );\n\n\t}\n\n};\n\n//\n\nfunction LensFlare() {\n\n\tconsole.error( 'THREE.LensFlare has been moved to /examples/jsm/objects/Lensflare.js' );\n\n}\n\n//\n\nfunction ParametricGeometry() {\n\n\tconsole.error( 'THREE.ParametricGeometry has been moved to /examples/jsm/geometries/ParametricGeometry.js' );\n\treturn new BufferGeometry();\n\n}\n\nfunction TextGeometry() {\n\n\tconsole.error( 'THREE.TextGeometry has been moved to /examples/jsm/geometries/TextGeometry.js' );\n\treturn new BufferGeometry();\n\n}\n\nfunction FontLoader() {\n\n\tconsole.error( 'THREE.FontLoader has been moved to /examples/jsm/loaders/FontLoader.js' );\n\n}\n\nfunction Font() {\n\n\tconsole.error( 'THREE.Font has been moved to /examples/jsm/loaders/FontLoader.js' );\n\n}\n\nfunction ImmediateRenderObject() {\n\n\tconsole.error( 'THREE.ImmediateRenderObject has been removed.' );\n\n}\n\nfunction WebGLMultisampleRenderTarget( width, height, options ) {\n\n\tconsole.error( 'THREE.WebGLMultisampleRenderTarget has been removed. Use a normal render target and set the \"samples\" property to greater 0 to enable multisampling.' );\n\tconst renderTarget = new WebGLRenderTarget( width, height, options );\n\trenderTarget.samples = 4;\n\treturn renderTarget;\n\n}\n\nfunction DataTexture2DArray( data, width, height, depth ) {\n\n\tconsole.warn( 'THREE.DataTexture2DArray has been renamed to DataArrayTexture.' );\n\treturn new DataArrayTexture( data, width, height, depth );\n\n}\n\nfunction DataTexture3D( data, width, height, depth ) {\n\n\tconsole.warn( 'THREE.DataTexture3D has been renamed to Data3DTexture.' );\n\treturn new Data3DTexture( data, width, height, depth );\n\n}\n\nif ( typeof __THREE_DEVTOOLS__ !== 'undefined' ) {\n\n\t__THREE_DEVTOOLS__.dispatchEvent( new CustomEvent( 'register', { detail: {\n\t\trevision: REVISION,\n\t} } ) );\n\n}\n\nif ( typeof window !== 'undefined' ) {\n\n\tif ( window.__THREE__ ) {\n\n\t\tconsole.warn( 'WARNING: Multiple instances of Three.js being imported.' );\n\n\t} else {\n\n\t\twindow.__THREE__ = REVISION;\n\n\t}\n\n}\n\n\n\n\n//# sourceURL=webpack://Something/./node_modules/three/build/three.module.js?");

/***/ }),

/***/ "./node_modules/three/examples/jsm/controls/OrbitControls.js":
/*!*******************************************************************!*\
  !*** ./node_modules/three/examples/jsm/controls/OrbitControls.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"MapControls\": () => (/* binding */ MapControls),\n/* harmony export */   \"OrbitControls\": () => (/* binding */ OrbitControls)\n/* harmony export */ });\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! three */ \"./node_modules/three/build/three.module.js\");\n\n\n// This set of controls performs orbiting, dollying (zooming), and panning.\n// Unlike TrackballControls, it maintains the \"up\" direction object.up (+Y by default).\n//\n//    Orbit - left mouse / touch: one-finger move\n//    Zoom - middle mouse, or mousewheel / touch: two-finger spread or squish\n//    Pan - right mouse, or left mouse + ctrl/meta/shiftKey, or arrow keys / touch: two-finger move\n\nconst _changeEvent = { type: 'change' };\nconst _startEvent = { type: 'start' };\nconst _endEvent = { type: 'end' };\n\nclass OrbitControls extends three__WEBPACK_IMPORTED_MODULE_0__.EventDispatcher {\n\n\tconstructor( object, domElement ) {\n\n\t\tsuper();\n\n\t\tif ( domElement === undefined ) console.warn( 'THREE.OrbitControls: The second parameter \"domElement\" is now mandatory.' );\n\t\tif ( domElement === document ) console.error( 'THREE.OrbitControls: \"document\" should not be used as the target \"domElement\". Please use \"renderer.domElement\" instead.' );\n\n\t\tthis.object = object;\n\t\tthis.domElement = domElement;\n\t\tthis.domElement.style.touchAction = 'none'; // disable touch scroll\n\n\t\t// Set to false to disable this control\n\t\tthis.enabled = true;\n\n\t\t// \"target\" sets the location of focus, where the object orbits around\n\t\tthis.target = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\n\t\t// How far you can dolly in and out ( PerspectiveCamera only )\n\t\tthis.minDistance = 0;\n\t\tthis.maxDistance = Infinity;\n\n\t\t// How far you can zoom in and out ( OrthographicCamera only )\n\t\tthis.minZoom = 0;\n\t\tthis.maxZoom = Infinity;\n\n\t\t// How far you can orbit vertically, upper and lower limits.\n\t\t// Range is 0 to Math.PI radians.\n\t\tthis.minPolarAngle = 0; // radians\n\t\tthis.maxPolarAngle = Math.PI; // radians\n\n\t\t// How far you can orbit horizontally, upper and lower limits.\n\t\t// If set, the interval [ min, max ] must be a sub-interval of [ - 2 PI, 2 PI ], with ( max - min < 2 PI )\n\t\tthis.minAzimuthAngle = - Infinity; // radians\n\t\tthis.maxAzimuthAngle = Infinity; // radians\n\n\t\t// Set to true to enable damping (inertia)\n\t\t// If damping is enabled, you must call controls.update() in your animation loop\n\t\tthis.enableDamping = false;\n\t\tthis.dampingFactor = 0.05;\n\n\t\t// This option actually enables dollying in and out; left as \"zoom\" for backwards compatibility.\n\t\t// Set to false to disable zooming\n\t\tthis.enableZoom = true;\n\t\tthis.zoomSpeed = 1.0;\n\n\t\t// Set to false to disable rotating\n\t\tthis.enableRotate = true;\n\t\tthis.rotateSpeed = 1.0;\n\n\t\t// Set to false to disable panning\n\t\tthis.enablePan = true;\n\t\tthis.panSpeed = 1.0;\n\t\tthis.screenSpacePanning = true; // if false, pan orthogonal to world-space direction camera.up\n\t\tthis.keyPanSpeed = 7.0;\t// pixels moved per arrow key push\n\n\t\t// Set to true to automatically rotate around the target\n\t\t// If auto-rotate is enabled, you must call controls.update() in your animation loop\n\t\tthis.autoRotate = false;\n\t\tthis.autoRotateSpeed = 2.0; // 30 seconds per orbit when fps is 60\n\n\t\t// The four arrow keys\n\t\tthis.keys = { LEFT: 'ArrowLeft', UP: 'ArrowUp', RIGHT: 'ArrowRight', BOTTOM: 'ArrowDown' };\n\n\t\t// Mouse buttons\n\t\tthis.mouseButtons = { LEFT: three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.ROTATE, MIDDLE: three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.DOLLY, RIGHT: three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.PAN };\n\n\t\t// Touch fingers\n\t\tthis.touches = { ONE: three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.ROTATE, TWO: three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.DOLLY_PAN };\n\n\t\t// for reset\n\t\tthis.target0 = this.target.clone();\n\t\tthis.position0 = this.object.position.clone();\n\t\tthis.zoom0 = this.object.zoom;\n\n\t\t// the target DOM element for key events\n\t\tthis._domElementKeyEvents = null;\n\n\t\t//\n\t\t// public methods\n\t\t//\n\n\t\tthis.getPolarAngle = function () {\n\n\t\t\treturn spherical.phi;\n\n\t\t};\n\n\t\tthis.getAzimuthalAngle = function () {\n\n\t\t\treturn spherical.theta;\n\n\t\t};\n\n\t\tthis.getDistance = function () {\n\n\t\t\treturn this.object.position.distanceTo( this.target );\n\n\t\t};\n\n\t\tthis.listenToKeyEvents = function ( domElement ) {\n\n\t\t\tdomElement.addEventListener( 'keydown', onKeyDown );\n\t\t\tthis._domElementKeyEvents = domElement;\n\n\t\t};\n\n\t\tthis.saveState = function () {\n\n\t\t\tscope.target0.copy( scope.target );\n\t\t\tscope.position0.copy( scope.object.position );\n\t\t\tscope.zoom0 = scope.object.zoom;\n\n\t\t};\n\n\t\tthis.reset = function () {\n\n\t\t\tscope.target.copy( scope.target0 );\n\t\t\tscope.object.position.copy( scope.position0 );\n\t\t\tscope.object.zoom = scope.zoom0;\n\n\t\t\tscope.object.updateProjectionMatrix();\n\t\t\tscope.dispatchEvent( _changeEvent );\n\n\t\t\tscope.update();\n\n\t\t\tstate = STATE.NONE;\n\n\t\t};\n\n\t\t// this method is exposed, but perhaps it would be better if we can make it private...\n\t\tthis.update = function () {\n\n\t\t\tconst offset = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\n\t\t\t// so camera.up is the orbit axis\n\t\t\tconst quat = new three__WEBPACK_IMPORTED_MODULE_0__.Quaternion().setFromUnitVectors( object.up, new three__WEBPACK_IMPORTED_MODULE_0__.Vector3( 0, 1, 0 ) );\n\t\t\tconst quatInverse = quat.clone().invert();\n\n\t\t\tconst lastPosition = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\t\t\tconst lastQuaternion = new three__WEBPACK_IMPORTED_MODULE_0__.Quaternion();\n\n\t\t\tconst twoPI = 2 * Math.PI;\n\n\t\t\treturn function update() {\n\n\t\t\t\tconst position = scope.object.position;\n\n\t\t\t\toffset.copy( position ).sub( scope.target );\n\n\t\t\t\t// rotate offset to \"y-axis-is-up\" space\n\t\t\t\toffset.applyQuaternion( quat );\n\n\t\t\t\t// angle from z-axis around y-axis\n\t\t\t\tspherical.setFromVector3( offset );\n\n\t\t\t\tif ( scope.autoRotate && state === STATE.NONE ) {\n\n\t\t\t\t\trotateLeft( getAutoRotationAngle() );\n\n\t\t\t\t}\n\n\t\t\t\tif ( scope.enableDamping ) {\n\n\t\t\t\t\tspherical.theta += sphericalDelta.theta * scope.dampingFactor;\n\t\t\t\t\tspherical.phi += sphericalDelta.phi * scope.dampingFactor;\n\n\t\t\t\t} else {\n\n\t\t\t\t\tspherical.theta += sphericalDelta.theta;\n\t\t\t\t\tspherical.phi += sphericalDelta.phi;\n\n\t\t\t\t}\n\n\t\t\t\t// restrict theta to be between desired limits\n\n\t\t\t\tlet min = scope.minAzimuthAngle;\n\t\t\t\tlet max = scope.maxAzimuthAngle;\n\n\t\t\t\tif ( isFinite( min ) && isFinite( max ) ) {\n\n\t\t\t\t\tif ( min < - Math.PI ) min += twoPI; else if ( min > Math.PI ) min -= twoPI;\n\n\t\t\t\t\tif ( max < - Math.PI ) max += twoPI; else if ( max > Math.PI ) max -= twoPI;\n\n\t\t\t\t\tif ( min <= max ) {\n\n\t\t\t\t\t\tspherical.theta = Math.max( min, Math.min( max, spherical.theta ) );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tspherical.theta = ( spherical.theta > ( min + max ) / 2 ) ?\n\t\t\t\t\t\t\tMath.max( min, spherical.theta ) :\n\t\t\t\t\t\t\tMath.min( max, spherical.theta );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\t// restrict phi to be between desired limits\n\t\t\t\tspherical.phi = Math.max( scope.minPolarAngle, Math.min( scope.maxPolarAngle, spherical.phi ) );\n\n\t\t\t\tspherical.makeSafe();\n\n\n\t\t\t\tspherical.radius *= scale;\n\n\t\t\t\t// restrict radius to be between desired limits\n\t\t\t\tspherical.radius = Math.max( scope.minDistance, Math.min( scope.maxDistance, spherical.radius ) );\n\n\t\t\t\t// move target to panned location\n\n\t\t\t\tif ( scope.enableDamping === true ) {\n\n\t\t\t\t\tscope.target.addScaledVector( panOffset, scope.dampingFactor );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tscope.target.add( panOffset );\n\n\t\t\t\t}\n\n\t\t\t\toffset.setFromSpherical( spherical );\n\n\t\t\t\t// rotate offset back to \"camera-up-vector-is-up\" space\n\t\t\t\toffset.applyQuaternion( quatInverse );\n\n\t\t\t\tposition.copy( scope.target ).add( offset );\n\n\t\t\t\tscope.object.lookAt( scope.target );\n\n\t\t\t\tif ( scope.enableDamping === true ) {\n\n\t\t\t\t\tsphericalDelta.theta *= ( 1 - scope.dampingFactor );\n\t\t\t\t\tsphericalDelta.phi *= ( 1 - scope.dampingFactor );\n\n\t\t\t\t\tpanOffset.multiplyScalar( 1 - scope.dampingFactor );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tsphericalDelta.set( 0, 0, 0 );\n\n\t\t\t\t\tpanOffset.set( 0, 0, 0 );\n\n\t\t\t\t}\n\n\t\t\t\tscale = 1;\n\n\t\t\t\t// update condition is:\n\t\t\t\t// min(camera displacement, camera rotation in radians)^2 > EPS\n\t\t\t\t// using small-angle approximation cos(x/2) = 1 - x^2 / 8\n\n\t\t\t\tif ( zoomChanged ||\n\t\t\t\t\tlastPosition.distanceToSquared( scope.object.position ) > EPS ||\n\t\t\t\t\t8 * ( 1 - lastQuaternion.dot( scope.object.quaternion ) ) > EPS ) {\n\n\t\t\t\t\tscope.dispatchEvent( _changeEvent );\n\n\t\t\t\t\tlastPosition.copy( scope.object.position );\n\t\t\t\t\tlastQuaternion.copy( scope.object.quaternion );\n\t\t\t\t\tzoomChanged = false;\n\n\t\t\t\t\treturn true;\n\n\t\t\t\t}\n\n\t\t\t\treturn false;\n\n\t\t\t};\n\n\t\t}();\n\n\t\tthis.dispose = function () {\n\n\t\t\tscope.domElement.removeEventListener( 'contextmenu', onContextMenu );\n\n\t\t\tscope.domElement.removeEventListener( 'pointerdown', onPointerDown );\n\t\t\tscope.domElement.removeEventListener( 'pointercancel', onPointerCancel );\n\t\t\tscope.domElement.removeEventListener( 'wheel', onMouseWheel );\n\n\t\t\tscope.domElement.removeEventListener( 'pointermove', onPointerMove );\n\t\t\tscope.domElement.removeEventListener( 'pointerup', onPointerUp );\n\n\n\t\t\tif ( scope._domElementKeyEvents !== null ) {\n\n\t\t\t\tscope._domElementKeyEvents.removeEventListener( 'keydown', onKeyDown );\n\n\t\t\t}\n\n\t\t\t//scope.dispatchEvent( { type: 'dispose' } ); // should this be added here?\n\n\t\t};\n\n\t\t//\n\t\t// internals\n\t\t//\n\n\t\tconst scope = this;\n\n\t\tconst STATE = {\n\t\t\tNONE: - 1,\n\t\t\tROTATE: 0,\n\t\t\tDOLLY: 1,\n\t\t\tPAN: 2,\n\t\t\tTOUCH_ROTATE: 3,\n\t\t\tTOUCH_PAN: 4,\n\t\t\tTOUCH_DOLLY_PAN: 5,\n\t\t\tTOUCH_DOLLY_ROTATE: 6\n\t\t};\n\n\t\tlet state = STATE.NONE;\n\n\t\tconst EPS = 0.000001;\n\n\t\t// current position in spherical coordinates\n\t\tconst spherical = new three__WEBPACK_IMPORTED_MODULE_0__.Spherical();\n\t\tconst sphericalDelta = new three__WEBPACK_IMPORTED_MODULE_0__.Spherical();\n\n\t\tlet scale = 1;\n\t\tconst panOffset = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\t\tlet zoomChanged = false;\n\n\t\tconst rotateStart = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\tconst rotateEnd = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\tconst rotateDelta = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\n\t\tconst panStart = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\tconst panEnd = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\tconst panDelta = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\n\t\tconst dollyStart = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\tconst dollyEnd = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\tconst dollyDelta = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\n\t\tconst pointers = [];\n\t\tconst pointerPositions = {};\n\n\t\tfunction getAutoRotationAngle() {\n\n\t\t\treturn 2 * Math.PI / 60 / 60 * scope.autoRotateSpeed;\n\n\t\t}\n\n\t\tfunction getZoomScale() {\n\n\t\t\treturn Math.pow( 0.95, scope.zoomSpeed );\n\n\t\t}\n\n\t\tfunction rotateLeft( angle ) {\n\n\t\t\tsphericalDelta.theta -= angle;\n\n\t\t}\n\n\t\tfunction rotateUp( angle ) {\n\n\t\t\tsphericalDelta.phi -= angle;\n\n\t\t}\n\n\t\tconst panLeft = function () {\n\n\t\t\tconst v = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\n\t\t\treturn function panLeft( distance, objectMatrix ) {\n\n\t\t\t\tv.setFromMatrixColumn( objectMatrix, 0 ); // get X column of objectMatrix\n\t\t\t\tv.multiplyScalar( - distance );\n\n\t\t\t\tpanOffset.add( v );\n\n\t\t\t};\n\n\t\t}();\n\n\t\tconst panUp = function () {\n\n\t\t\tconst v = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\n\t\t\treturn function panUp( distance, objectMatrix ) {\n\n\t\t\t\tif ( scope.screenSpacePanning === true ) {\n\n\t\t\t\t\tv.setFromMatrixColumn( objectMatrix, 1 );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tv.setFromMatrixColumn( objectMatrix, 0 );\n\t\t\t\t\tv.crossVectors( scope.object.up, v );\n\n\t\t\t\t}\n\n\t\t\t\tv.multiplyScalar( distance );\n\n\t\t\t\tpanOffset.add( v );\n\n\t\t\t};\n\n\t\t}();\n\n\t\t// deltaX and deltaY are in pixels; right and down are positive\n\t\tconst pan = function () {\n\n\t\t\tconst offset = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\n\t\t\treturn function pan( deltaX, deltaY ) {\n\n\t\t\t\tconst element = scope.domElement;\n\n\t\t\t\tif ( scope.object.isPerspectiveCamera ) {\n\n\t\t\t\t\t// perspective\n\t\t\t\t\tconst position = scope.object.position;\n\t\t\t\t\toffset.copy( position ).sub( scope.target );\n\t\t\t\t\tlet targetDistance = offset.length();\n\n\t\t\t\t\t// half of the fov is center to top of screen\n\t\t\t\t\ttargetDistance *= Math.tan( ( scope.object.fov / 2 ) * Math.PI / 180.0 );\n\n\t\t\t\t\t// we use only clientHeight here so aspect ratio does not distort speed\n\t\t\t\t\tpanLeft( 2 * deltaX * targetDistance / element.clientHeight, scope.object.matrix );\n\t\t\t\t\tpanUp( 2 * deltaY * targetDistance / element.clientHeight, scope.object.matrix );\n\n\t\t\t\t} else if ( scope.object.isOrthographicCamera ) {\n\n\t\t\t\t\t// orthographic\n\t\t\t\t\tpanLeft( deltaX * ( scope.object.right - scope.object.left ) / scope.object.zoom / element.clientWidth, scope.object.matrix );\n\t\t\t\t\tpanUp( deltaY * ( scope.object.top - scope.object.bottom ) / scope.object.zoom / element.clientHeight, scope.object.matrix );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// camera neither orthographic nor perspective\n\t\t\t\t\tconsole.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - pan disabled.' );\n\t\t\t\t\tscope.enablePan = false;\n\n\t\t\t\t}\n\n\t\t\t};\n\n\t\t}();\n\n\t\tfunction dollyOut( dollyScale ) {\n\n\t\t\tif ( scope.object.isPerspectiveCamera ) {\n\n\t\t\t\tscale /= dollyScale;\n\n\t\t\t} else if ( scope.object.isOrthographicCamera ) {\n\n\t\t\t\tscope.object.zoom = Math.max( scope.minZoom, Math.min( scope.maxZoom, scope.object.zoom * dollyScale ) );\n\t\t\t\tscope.object.updateProjectionMatrix();\n\t\t\t\tzoomChanged = true;\n\n\t\t\t} else {\n\n\t\t\t\tconsole.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - dolly/zoom disabled.' );\n\t\t\t\tscope.enableZoom = false;\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction dollyIn( dollyScale ) {\n\n\t\t\tif ( scope.object.isPerspectiveCamera ) {\n\n\t\t\t\tscale *= dollyScale;\n\n\t\t\t} else if ( scope.object.isOrthographicCamera ) {\n\n\t\t\t\tscope.object.zoom = Math.max( scope.minZoom, Math.min( scope.maxZoom, scope.object.zoom / dollyScale ) );\n\t\t\t\tscope.object.updateProjectionMatrix();\n\t\t\t\tzoomChanged = true;\n\n\t\t\t} else {\n\n\t\t\t\tconsole.warn( 'WARNING: OrbitControls.js encountered an unknown camera type - dolly/zoom disabled.' );\n\t\t\t\tscope.enableZoom = false;\n\n\t\t\t}\n\n\t\t}\n\n\t\t//\n\t\t// event callbacks - update the object state\n\t\t//\n\n\t\tfunction handleMouseDownRotate( event ) {\n\n\t\t\trotateStart.set( event.clientX, event.clientY );\n\n\t\t}\n\n\t\tfunction handleMouseDownDolly( event ) {\n\n\t\t\tdollyStart.set( event.clientX, event.clientY );\n\n\t\t}\n\n\t\tfunction handleMouseDownPan( event ) {\n\n\t\t\tpanStart.set( event.clientX, event.clientY );\n\n\t\t}\n\n\t\tfunction handleMouseMoveRotate( event ) {\n\n\t\t\trotateEnd.set( event.clientX, event.clientY );\n\n\t\t\trotateDelta.subVectors( rotateEnd, rotateStart ).multiplyScalar( scope.rotateSpeed );\n\n\t\t\tconst element = scope.domElement;\n\n\t\t\trotateLeft( 2 * Math.PI * rotateDelta.x / element.clientHeight ); // yes, height\n\n\t\t\trotateUp( 2 * Math.PI * rotateDelta.y / element.clientHeight );\n\n\t\t\trotateStart.copy( rotateEnd );\n\n\t\t\tscope.update();\n\n\t\t}\n\n\t\tfunction handleMouseMoveDolly( event ) {\n\n\t\t\tdollyEnd.set( event.clientX, event.clientY );\n\n\t\t\tdollyDelta.subVectors( dollyEnd, dollyStart );\n\n\t\t\tif ( dollyDelta.y > 0 ) {\n\n\t\t\t\tdollyOut( getZoomScale() );\n\n\t\t\t} else if ( dollyDelta.y < 0 ) {\n\n\t\t\t\tdollyIn( getZoomScale() );\n\n\t\t\t}\n\n\t\t\tdollyStart.copy( dollyEnd );\n\n\t\t\tscope.update();\n\n\t\t}\n\n\t\tfunction handleMouseMovePan( event ) {\n\n\t\t\tpanEnd.set( event.clientX, event.clientY );\n\n\t\t\tpanDelta.subVectors( panEnd, panStart ).multiplyScalar( scope.panSpeed );\n\n\t\t\tpan( panDelta.x, panDelta.y );\n\n\t\t\tpanStart.copy( panEnd );\n\n\t\t\tscope.update();\n\n\t\t}\n\n\t\tfunction handleMouseWheel( event ) {\n\n\t\t\tif ( event.deltaY < 0 ) {\n\n\t\t\t\tdollyIn( getZoomScale() );\n\n\t\t\t} else if ( event.deltaY > 0 ) {\n\n\t\t\t\tdollyOut( getZoomScale() );\n\n\t\t\t}\n\n\t\t\tscope.update();\n\n\t\t}\n\n\t\tfunction handleKeyDown( event ) {\n\n\t\t\tlet needsUpdate = false;\n\n\t\t\tswitch ( event.code ) {\n\n\t\t\t\tcase scope.keys.UP:\n\t\t\t\t\tpan( 0, scope.keyPanSpeed );\n\t\t\t\t\tneedsUpdate = true;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase scope.keys.BOTTOM:\n\t\t\t\t\tpan( 0, - scope.keyPanSpeed );\n\t\t\t\t\tneedsUpdate = true;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase scope.keys.LEFT:\n\t\t\t\t\tpan( scope.keyPanSpeed, 0 );\n\t\t\t\t\tneedsUpdate = true;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase scope.keys.RIGHT:\n\t\t\t\t\tpan( - scope.keyPanSpeed, 0 );\n\t\t\t\t\tneedsUpdate = true;\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t\tif ( needsUpdate ) {\n\n\t\t\t\t// prevent the browser from scrolling on cursor keys\n\t\t\t\tevent.preventDefault();\n\n\t\t\t\tscope.update();\n\n\t\t\t}\n\n\n\t\t}\n\n\t\tfunction handleTouchStartRotate() {\n\n\t\t\tif ( pointers.length === 1 ) {\n\n\t\t\t\trotateStart.set( pointers[ 0 ].pageX, pointers[ 0 ].pageY );\n\n\t\t\t} else {\n\n\t\t\t\tconst x = 0.5 * ( pointers[ 0 ].pageX + pointers[ 1 ].pageX );\n\t\t\t\tconst y = 0.5 * ( pointers[ 0 ].pageY + pointers[ 1 ].pageY );\n\n\t\t\t\trotateStart.set( x, y );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction handleTouchStartPan() {\n\n\t\t\tif ( pointers.length === 1 ) {\n\n\t\t\t\tpanStart.set( pointers[ 0 ].pageX, pointers[ 0 ].pageY );\n\n\t\t\t} else {\n\n\t\t\t\tconst x = 0.5 * ( pointers[ 0 ].pageX + pointers[ 1 ].pageX );\n\t\t\t\tconst y = 0.5 * ( pointers[ 0 ].pageY + pointers[ 1 ].pageY );\n\n\t\t\t\tpanStart.set( x, y );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction handleTouchStartDolly() {\n\n\t\t\tconst dx = pointers[ 0 ].pageX - pointers[ 1 ].pageX;\n\t\t\tconst dy = pointers[ 0 ].pageY - pointers[ 1 ].pageY;\n\n\t\t\tconst distance = Math.sqrt( dx * dx + dy * dy );\n\n\t\t\tdollyStart.set( 0, distance );\n\n\t\t}\n\n\t\tfunction handleTouchStartDollyPan() {\n\n\t\t\tif ( scope.enableZoom ) handleTouchStartDolly();\n\n\t\t\tif ( scope.enablePan ) handleTouchStartPan();\n\n\t\t}\n\n\t\tfunction handleTouchStartDollyRotate() {\n\n\t\t\tif ( scope.enableZoom ) handleTouchStartDolly();\n\n\t\t\tif ( scope.enableRotate ) handleTouchStartRotate();\n\n\t\t}\n\n\t\tfunction handleTouchMoveRotate( event ) {\n\n\t\t\tif ( pointers.length == 1 ) {\n\n\t\t\t\trotateEnd.set( event.pageX, event.pageY );\n\n\t\t\t} else {\n\n\t\t\t\tconst position = getSecondPointerPosition( event );\n\n\t\t\t\tconst x = 0.5 * ( event.pageX + position.x );\n\t\t\t\tconst y = 0.5 * ( event.pageY + position.y );\n\n\t\t\t\trotateEnd.set( x, y );\n\n\t\t\t}\n\n\t\t\trotateDelta.subVectors( rotateEnd, rotateStart ).multiplyScalar( scope.rotateSpeed );\n\n\t\t\tconst element = scope.domElement;\n\n\t\t\trotateLeft( 2 * Math.PI * rotateDelta.x / element.clientHeight ); // yes, height\n\n\t\t\trotateUp( 2 * Math.PI * rotateDelta.y / element.clientHeight );\n\n\t\t\trotateStart.copy( rotateEnd );\n\n\t\t}\n\n\t\tfunction handleTouchMovePan( event ) {\n\n\t\t\tif ( pointers.length === 1 ) {\n\n\t\t\t\tpanEnd.set( event.pageX, event.pageY );\n\n\t\t\t} else {\n\n\t\t\t\tconst position = getSecondPointerPosition( event );\n\n\t\t\t\tconst x = 0.5 * ( event.pageX + position.x );\n\t\t\t\tconst y = 0.5 * ( event.pageY + position.y );\n\n\t\t\t\tpanEnd.set( x, y );\n\n\t\t\t}\n\n\t\t\tpanDelta.subVectors( panEnd, panStart ).multiplyScalar( scope.panSpeed );\n\n\t\t\tpan( panDelta.x, panDelta.y );\n\n\t\t\tpanStart.copy( panEnd );\n\n\t\t}\n\n\t\tfunction handleTouchMoveDolly( event ) {\n\n\t\t\tconst position = getSecondPointerPosition( event );\n\n\t\t\tconst dx = event.pageX - position.x;\n\t\t\tconst dy = event.pageY - position.y;\n\n\t\t\tconst distance = Math.sqrt( dx * dx + dy * dy );\n\n\t\t\tdollyEnd.set( 0, distance );\n\n\t\t\tdollyDelta.set( 0, Math.pow( dollyEnd.y / dollyStart.y, scope.zoomSpeed ) );\n\n\t\t\tdollyOut( dollyDelta.y );\n\n\t\t\tdollyStart.copy( dollyEnd );\n\n\t\t}\n\n\t\tfunction handleTouchMoveDollyPan( event ) {\n\n\t\t\tif ( scope.enableZoom ) handleTouchMoveDolly( event );\n\n\t\t\tif ( scope.enablePan ) handleTouchMovePan( event );\n\n\t\t}\n\n\t\tfunction handleTouchMoveDollyRotate( event ) {\n\n\t\t\tif ( scope.enableZoom ) handleTouchMoveDolly( event );\n\n\t\t\tif ( scope.enableRotate ) handleTouchMoveRotate( event );\n\n\t\t}\n\n\t\t//\n\t\t// event handlers - FSM: listen for events and reset state\n\t\t//\n\n\t\tfunction onPointerDown( event ) {\n\n\t\t\tif ( scope.enabled === false ) return;\n\n\t\t\tif ( pointers.length === 0 ) {\n\n\t\t\t\tscope.domElement.setPointerCapture( event.pointerId );\n\n\t\t\t\tscope.domElement.addEventListener( 'pointermove', onPointerMove );\n\t\t\t\tscope.domElement.addEventListener( 'pointerup', onPointerUp );\n\n\t\t\t}\n\n\t\t\t//\n\n\t\t\taddPointer( event );\n\n\t\t\tif ( event.pointerType === 'touch' ) {\n\n\t\t\t\tonTouchStart( event );\n\n\t\t\t} else {\n\n\t\t\t\tonMouseDown( event );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onPointerMove( event ) {\n\n\t\t\tif ( scope.enabled === false ) return;\n\n\t\t\tif ( event.pointerType === 'touch' ) {\n\n\t\t\t\tonTouchMove( event );\n\n\t\t\t} else {\n\n\t\t\t\tonMouseMove( event );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onPointerUp( event ) {\n\n\t\t    removePointer( event );\n\n\t\t    if ( pointers.length === 0 ) {\n\n\t\t        scope.domElement.releasePointerCapture( event.pointerId );\n\n\t\t        scope.domElement.removeEventListener( 'pointermove', onPointerMove );\n\t\t        scope.domElement.removeEventListener( 'pointerup', onPointerUp );\n\n\t\t    }\n\n\t\t    scope.dispatchEvent( _endEvent );\n\n\t\t    state = STATE.NONE;\n\n\t\t}\n\n\t\tfunction onPointerCancel( event ) {\n\n\t\t\tremovePointer( event );\n\n\t\t}\n\n\t\tfunction onMouseDown( event ) {\n\n\t\t\tlet mouseAction;\n\n\t\t\tswitch ( event.button ) {\n\n\t\t\t\tcase 0:\n\n\t\t\t\t\tmouseAction = scope.mouseButtons.LEFT;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 1:\n\n\t\t\t\t\tmouseAction = scope.mouseButtons.MIDDLE;\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\n\t\t\t\t\tmouseAction = scope.mouseButtons.RIGHT;\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\n\t\t\t\t\tmouseAction = - 1;\n\n\t\t\t}\n\n\t\t\tswitch ( mouseAction ) {\n\n\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.DOLLY:\n\n\t\t\t\t\tif ( scope.enableZoom === false ) return;\n\n\t\t\t\t\thandleMouseDownDolly( event );\n\n\t\t\t\t\tstate = STATE.DOLLY;\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.ROTATE:\n\n\t\t\t\t\tif ( event.ctrlKey || event.metaKey || event.shiftKey ) {\n\n\t\t\t\t\t\tif ( scope.enablePan === false ) return;\n\n\t\t\t\t\t\thandleMouseDownPan( event );\n\n\t\t\t\t\t\tstate = STATE.PAN;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tif ( scope.enableRotate === false ) return;\n\n\t\t\t\t\t\thandleMouseDownRotate( event );\n\n\t\t\t\t\t\tstate = STATE.ROTATE;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.PAN:\n\n\t\t\t\t\tif ( event.ctrlKey || event.metaKey || event.shiftKey ) {\n\n\t\t\t\t\t\tif ( scope.enableRotate === false ) return;\n\n\t\t\t\t\t\thandleMouseDownRotate( event );\n\n\t\t\t\t\t\tstate = STATE.ROTATE;\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tif ( scope.enablePan === false ) return;\n\n\t\t\t\t\t\thandleMouseDownPan( event );\n\n\t\t\t\t\t\tstate = STATE.PAN;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\n\t\t\t\t\tstate = STATE.NONE;\n\n\t\t\t}\n\n\t\t\tif ( state !== STATE.NONE ) {\n\n\t\t\t\tscope.dispatchEvent( _startEvent );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onMouseMove( event ) {\n\n\t\t\tif ( scope.enabled === false ) return;\n\n\t\t\tswitch ( state ) {\n\n\t\t\t\tcase STATE.ROTATE:\n\n\t\t\t\t\tif ( scope.enableRotate === false ) return;\n\n\t\t\t\t\thandleMouseMoveRotate( event );\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase STATE.DOLLY:\n\n\t\t\t\t\tif ( scope.enableZoom === false ) return;\n\n\t\t\t\t\thandleMouseMoveDolly( event );\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase STATE.PAN:\n\n\t\t\t\t\tif ( scope.enablePan === false ) return;\n\n\t\t\t\t\thandleMouseMovePan( event );\n\n\t\t\t\t\tbreak;\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onMouseWheel( event ) {\n\n\t\t\tif ( scope.enabled === false || scope.enableZoom === false || state !== STATE.NONE ) return;\n\n\t\t\tevent.preventDefault();\n\n\t\t\tscope.dispatchEvent( _startEvent );\n\n\t\t\thandleMouseWheel( event );\n\n\t\t\tscope.dispatchEvent( _endEvent );\n\n\t\t}\n\n\t\tfunction onKeyDown( event ) {\n\n\t\t\tif ( scope.enabled === false || scope.enablePan === false ) return;\n\n\t\t\thandleKeyDown( event );\n\n\t\t}\n\n\t\tfunction onTouchStart( event ) {\n\n\t\t\ttrackPointer( event );\n\n\t\t\tswitch ( pointers.length ) {\n\n\t\t\t\tcase 1:\n\n\t\t\t\t\tswitch ( scope.touches.ONE ) {\n\n\t\t\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.ROTATE:\n\n\t\t\t\t\t\t\tif ( scope.enableRotate === false ) return;\n\n\t\t\t\t\t\t\thandleTouchStartRotate();\n\n\t\t\t\t\t\t\tstate = STATE.TOUCH_ROTATE;\n\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.PAN:\n\n\t\t\t\t\t\t\tif ( scope.enablePan === false ) return;\n\n\t\t\t\t\t\t\thandleTouchStartPan();\n\n\t\t\t\t\t\t\tstate = STATE.TOUCH_PAN;\n\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tdefault:\n\n\t\t\t\t\t\t\tstate = STATE.NONE;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 2:\n\n\t\t\t\t\tswitch ( scope.touches.TWO ) {\n\n\t\t\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.DOLLY_PAN:\n\n\t\t\t\t\t\t\tif ( scope.enableZoom === false && scope.enablePan === false ) return;\n\n\t\t\t\t\t\t\thandleTouchStartDollyPan();\n\n\t\t\t\t\t\t\tstate = STATE.TOUCH_DOLLY_PAN;\n\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tcase three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.DOLLY_ROTATE:\n\n\t\t\t\t\t\t\tif ( scope.enableZoom === false && scope.enableRotate === false ) return;\n\n\t\t\t\t\t\t\thandleTouchStartDollyRotate();\n\n\t\t\t\t\t\t\tstate = STATE.TOUCH_DOLLY_ROTATE;\n\n\t\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t\tdefault:\n\n\t\t\t\t\t\t\tstate = STATE.NONE;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\n\t\t\t\t\tstate = STATE.NONE;\n\n\t\t\t}\n\n\t\t\tif ( state !== STATE.NONE ) {\n\n\t\t\t\tscope.dispatchEvent( _startEvent );\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onTouchMove( event ) {\n\n\t\t\ttrackPointer( event );\n\n\t\t\tswitch ( state ) {\n\n\t\t\t\tcase STATE.TOUCH_ROTATE:\n\n\t\t\t\t\tif ( scope.enableRotate === false ) return;\n\n\t\t\t\t\thandleTouchMoveRotate( event );\n\n\t\t\t\t\tscope.update();\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase STATE.TOUCH_PAN:\n\n\t\t\t\t\tif ( scope.enablePan === false ) return;\n\n\t\t\t\t\thandleTouchMovePan( event );\n\n\t\t\t\t\tscope.update();\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase STATE.TOUCH_DOLLY_PAN:\n\n\t\t\t\t\tif ( scope.enableZoom === false && scope.enablePan === false ) return;\n\n\t\t\t\t\thandleTouchMoveDollyPan( event );\n\n\t\t\t\t\tscope.update();\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase STATE.TOUCH_DOLLY_ROTATE:\n\n\t\t\t\t\tif ( scope.enableZoom === false && scope.enableRotate === false ) return;\n\n\t\t\t\t\thandleTouchMoveDollyRotate( event );\n\n\t\t\t\t\tscope.update();\n\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\n\t\t\t\t\tstate = STATE.NONE;\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction onContextMenu( event ) {\n\n\t\t\tif ( scope.enabled === false ) return;\n\n\t\t\tevent.preventDefault();\n\n\t\t}\n\n\t\tfunction addPointer( event ) {\n\n\t\t\tpointers.push( event );\n\n\t\t}\n\n\t\tfunction removePointer( event ) {\n\n\t\t\tdelete pointerPositions[ event.pointerId ];\n\n\t\t\tfor ( let i = 0; i < pointers.length; i ++ ) {\n\n\t\t\t\tif ( pointers[ i ].pointerId == event.pointerId ) {\n\n\t\t\t\t\tpointers.splice( i, 1 );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tfunction trackPointer( event ) {\n\n\t\t\tlet position = pointerPositions[ event.pointerId ];\n\n\t\t\tif ( position === undefined ) {\n\n\t\t\t\tposition = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2();\n\t\t\t\tpointerPositions[ event.pointerId ] = position;\n\n\t\t\t}\n\n\t\t\tposition.set( event.pageX, event.pageY );\n\n\t\t}\n\n\t\tfunction getSecondPointerPosition( event ) {\n\n\t\t\tconst pointer = ( event.pointerId === pointers[ 0 ].pointerId ) ? pointers[ 1 ] : pointers[ 0 ];\n\n\t\t\treturn pointerPositions[ pointer.pointerId ];\n\n\t\t}\n\n\t\t//\n\n\t\tscope.domElement.addEventListener( 'contextmenu', onContextMenu );\n\n\t\tscope.domElement.addEventListener( 'pointerdown', onPointerDown );\n\t\tscope.domElement.addEventListener( 'pointercancel', onPointerCancel );\n\t\tscope.domElement.addEventListener( 'wheel', onMouseWheel, { passive: false } );\n\n\t\t// force an update at start\n\n\t\tthis.update();\n\n\t}\n\n}\n\n\n// This set of controls performs orbiting, dollying (zooming), and panning.\n// Unlike TrackballControls, it maintains the \"up\" direction object.up (+Y by default).\n// This is very similar to OrbitControls, another set of touch behavior\n//\n//    Orbit - right mouse, or left mouse + ctrl/meta/shiftKey / touch: two-finger rotate\n//    Zoom - middle mouse, or mousewheel / touch: two-finger spread or squish\n//    Pan - left mouse, or arrow keys / touch: one-finger move\n\nclass MapControls extends OrbitControls {\n\n\tconstructor( object, domElement ) {\n\n\t\tsuper( object, domElement );\n\n\t\tthis.screenSpacePanning = false; // pan orthogonal to world-space direction camera.up\n\n\t\tthis.mouseButtons.LEFT = three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.PAN;\n\t\tthis.mouseButtons.RIGHT = three__WEBPACK_IMPORTED_MODULE_0__.MOUSE.ROTATE;\n\n\t\tthis.touches.ONE = three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.PAN;\n\t\tthis.touches.TWO = three__WEBPACK_IMPORTED_MODULE_0__.TOUCH.DOLLY_ROTATE;\n\n\t}\n\n}\n\n\n\n\n//# sourceURL=webpack://Something/./node_modules/three/examples/jsm/controls/OrbitControls.js?");

/***/ }),

/***/ "./node_modules/three/examples/jsm/loaders/GLTFLoader.js":
/*!***************************************************************!*\
  !*** ./node_modules/three/examples/jsm/loaders/GLTFLoader.js ***!
  \***************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"GLTFLoader\": () => (/* binding */ GLTFLoader)\n/* harmony export */ });\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! three */ \"./node_modules/three/build/three.module.js\");\n\n\nclass GLTFLoader extends three__WEBPACK_IMPORTED_MODULE_0__.Loader {\n\n\tconstructor( manager ) {\n\n\t\tsuper( manager );\n\n\t\tthis.dracoLoader = null;\n\t\tthis.ktx2Loader = null;\n\t\tthis.meshoptDecoder = null;\n\n\t\tthis.pluginCallbacks = [];\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMaterialsClearcoatExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFTextureBasisUExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFTextureWebPExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMaterialsSheenExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMaterialsTransmissionExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMaterialsVolumeExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMaterialsIorExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMaterialsSpecularExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFLightsExtension( parser );\n\n\t\t} );\n\n\t\tthis.register( function ( parser ) {\n\n\t\t\treturn new GLTFMeshoptCompression( parser );\n\n\t\t} );\n\n\t}\n\n\tload( url, onLoad, onProgress, onError ) {\n\n\t\tconst scope = this;\n\n\t\tlet resourcePath;\n\n\t\tif ( this.resourcePath !== '' ) {\n\n\t\t\tresourcePath = this.resourcePath;\n\n\t\t} else if ( this.path !== '' ) {\n\n\t\t\tresourcePath = this.path;\n\n\t\t} else {\n\n\t\t\tresourcePath = three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.extractUrlBase( url );\n\n\t\t}\n\n\t\t// Tells the LoadingManager to track an extra item, which resolves after\n\t\t// the model is fully loaded. This means the count of items loaded will\n\t\t// be incorrect, but ensures manager.onLoad() does not fire early.\n\t\tthis.manager.itemStart( url );\n\n\t\tconst _onError = function ( e ) {\n\n\t\t\tif ( onError ) {\n\n\t\t\t\tonError( e );\n\n\t\t\t} else {\n\n\t\t\t\tconsole.error( e );\n\n\t\t\t}\n\n\t\t\tscope.manager.itemError( url );\n\t\t\tscope.manager.itemEnd( url );\n\n\t\t};\n\n\t\tconst loader = new three__WEBPACK_IMPORTED_MODULE_0__.FileLoader( this.manager );\n\n\t\tloader.setPath( this.path );\n\t\tloader.setResponseType( 'arraybuffer' );\n\t\tloader.setRequestHeader( this.requestHeader );\n\t\tloader.setWithCredentials( this.withCredentials );\n\n\t\tloader.load( url, function ( data ) {\n\n\t\t\ttry {\n\n\t\t\t\tscope.parse( data, resourcePath, function ( gltf ) {\n\n\t\t\t\t\tonLoad( gltf );\n\n\t\t\t\t\tscope.manager.itemEnd( url );\n\n\t\t\t\t}, _onError );\n\n\t\t\t} catch ( e ) {\n\n\t\t\t\t_onError( e );\n\n\t\t\t}\n\n\t\t}, onProgress, _onError );\n\n\t}\n\n\tsetDRACOLoader( dracoLoader ) {\n\n\t\tthis.dracoLoader = dracoLoader;\n\t\treturn this;\n\n\t}\n\n\tsetDDSLoader() {\n\n\t\tthrow new Error(\n\n\t\t\t'THREE.GLTFLoader: \"MSFT_texture_dds\" no longer supported. Please update to \"KHR_texture_basisu\".'\n\n\t\t);\n\n\t}\n\n\tsetKTX2Loader( ktx2Loader ) {\n\n\t\tthis.ktx2Loader = ktx2Loader;\n\t\treturn this;\n\n\t}\n\n\tsetMeshoptDecoder( meshoptDecoder ) {\n\n\t\tthis.meshoptDecoder = meshoptDecoder;\n\t\treturn this;\n\n\t}\n\n\tregister( callback ) {\n\n\t\tif ( this.pluginCallbacks.indexOf( callback ) === - 1 ) {\n\n\t\t\tthis.pluginCallbacks.push( callback );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tunregister( callback ) {\n\n\t\tif ( this.pluginCallbacks.indexOf( callback ) !== - 1 ) {\n\n\t\t\tthis.pluginCallbacks.splice( this.pluginCallbacks.indexOf( callback ), 1 );\n\n\t\t}\n\n\t\treturn this;\n\n\t}\n\n\tparse( data, path, onLoad, onError ) {\n\n\t\tlet content;\n\t\tconst extensions = {};\n\t\tconst plugins = {};\n\n\t\tif ( typeof data === 'string' ) {\n\n\t\t\tcontent = data;\n\n\t\t} else {\n\n\t\t\tconst magic = three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.decodeText( new Uint8Array( data, 0, 4 ) );\n\n\t\t\tif ( magic === BINARY_EXTENSION_HEADER_MAGIC ) {\n\n\t\t\t\ttry {\n\n\t\t\t\t\textensions[ EXTENSIONS.KHR_BINARY_GLTF ] = new GLTFBinaryExtension( data );\n\n\t\t\t\t} catch ( error ) {\n\n\t\t\t\t\tif ( onError ) onError( error );\n\t\t\t\t\treturn;\n\n\t\t\t\t}\n\n\t\t\t\tcontent = extensions[ EXTENSIONS.KHR_BINARY_GLTF ].content;\n\n\t\t\t} else {\n\n\t\t\t\tcontent = three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.decodeText( new Uint8Array( data ) );\n\n\t\t\t}\n\n\t\t}\n\n\t\tconst json = JSON.parse( content );\n\n\t\tif ( json.asset === undefined || json.asset.version[ 0 ] < 2 ) {\n\n\t\t\tif ( onError ) onError( new Error( 'THREE.GLTFLoader: Unsupported asset. glTF versions >=2.0 are supported.' ) );\n\t\t\treturn;\n\n\t\t}\n\n\t\tconst parser = new GLTFParser( json, {\n\n\t\t\tpath: path || this.resourcePath || '',\n\t\t\tcrossOrigin: this.crossOrigin,\n\t\t\trequestHeader: this.requestHeader,\n\t\t\tmanager: this.manager,\n\t\t\tktx2Loader: this.ktx2Loader,\n\t\t\tmeshoptDecoder: this.meshoptDecoder\n\n\t\t} );\n\n\t\tparser.fileLoader.setRequestHeader( this.requestHeader );\n\n\t\tfor ( let i = 0; i < this.pluginCallbacks.length; i ++ ) {\n\n\t\t\tconst plugin = this.pluginCallbacks[ i ]( parser );\n\t\t\tplugins[ plugin.name ] = plugin;\n\n\t\t\t// Workaround to avoid determining as unknown extension\n\t\t\t// in addUnknownExtensionsToUserData().\n\t\t\t// Remove this workaround if we move all the existing\n\t\t\t// extension handlers to plugin system\n\t\t\textensions[ plugin.name ] = true;\n\n\t\t}\n\n\t\tif ( json.extensionsUsed ) {\n\n\t\t\tfor ( let i = 0; i < json.extensionsUsed.length; ++ i ) {\n\n\t\t\t\tconst extensionName = json.extensionsUsed[ i ];\n\t\t\t\tconst extensionsRequired = json.extensionsRequired || [];\n\n\t\t\t\tswitch ( extensionName ) {\n\n\t\t\t\t\tcase EXTENSIONS.KHR_MATERIALS_UNLIT:\n\t\t\t\t\t\textensions[ extensionName ] = new GLTFMaterialsUnlitExtension();\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase EXTENSIONS.KHR_MATERIALS_PBR_SPECULAR_GLOSSINESS:\n\t\t\t\t\t\textensions[ extensionName ] = new GLTFMaterialsPbrSpecularGlossinessExtension();\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase EXTENSIONS.KHR_DRACO_MESH_COMPRESSION:\n\t\t\t\t\t\textensions[ extensionName ] = new GLTFDracoMeshCompressionExtension( json, this.dracoLoader );\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase EXTENSIONS.KHR_TEXTURE_TRANSFORM:\n\t\t\t\t\t\textensions[ extensionName ] = new GLTFTextureTransformExtension();\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase EXTENSIONS.KHR_MESH_QUANTIZATION:\n\t\t\t\t\t\textensions[ extensionName ] = new GLTFMeshQuantizationExtension();\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tdefault:\n\n\t\t\t\t\t\tif ( extensionsRequired.indexOf( extensionName ) >= 0 && plugins[ extensionName ] === undefined ) {\n\n\t\t\t\t\t\t\tconsole.warn( 'THREE.GLTFLoader: Unknown extension \"' + extensionName + '\".' );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\tparser.setExtensions( extensions );\n\t\tparser.setPlugins( plugins );\n\t\tparser.parse( onLoad, onError );\n\n\t}\n\n\tparseAsync( data, path ) {\n\n\t\tconst scope = this;\n\n\t\treturn new Promise( function ( resolve, reject ) {\n\n\t\t\tscope.parse( data, path, resolve, reject );\n\n\t\t} );\n\n\t}\n\n}\n\n/* GLTFREGISTRY */\n\nfunction GLTFRegistry() {\n\n\tlet objects = {};\n\n\treturn\t{\n\n\t\tget: function ( key ) {\n\n\t\t\treturn objects[ key ];\n\n\t\t},\n\n\t\tadd: function ( key, object ) {\n\n\t\t\tobjects[ key ] = object;\n\n\t\t},\n\n\t\tremove: function ( key ) {\n\n\t\t\tdelete objects[ key ];\n\n\t\t},\n\n\t\tremoveAll: function () {\n\n\t\t\tobjects = {};\n\n\t\t}\n\n\t};\n\n}\n\n/*********************************/\n/********** EXTENSIONS ***********/\n/*********************************/\n\nconst EXTENSIONS = {\n\tKHR_BINARY_GLTF: 'KHR_binary_glTF',\n\tKHR_DRACO_MESH_COMPRESSION: 'KHR_draco_mesh_compression',\n\tKHR_LIGHTS_PUNCTUAL: 'KHR_lights_punctual',\n\tKHR_MATERIALS_CLEARCOAT: 'KHR_materials_clearcoat',\n\tKHR_MATERIALS_IOR: 'KHR_materials_ior',\n\tKHR_MATERIALS_PBR_SPECULAR_GLOSSINESS: 'KHR_materials_pbrSpecularGlossiness',\n\tKHR_MATERIALS_SHEEN: 'KHR_materials_sheen',\n\tKHR_MATERIALS_SPECULAR: 'KHR_materials_specular',\n\tKHR_MATERIALS_TRANSMISSION: 'KHR_materials_transmission',\n\tKHR_MATERIALS_UNLIT: 'KHR_materials_unlit',\n\tKHR_MATERIALS_VOLUME: 'KHR_materials_volume',\n\tKHR_TEXTURE_BASISU: 'KHR_texture_basisu',\n\tKHR_TEXTURE_TRANSFORM: 'KHR_texture_transform',\n\tKHR_MESH_QUANTIZATION: 'KHR_mesh_quantization',\n\tEXT_TEXTURE_WEBP: 'EXT_texture_webp',\n\tEXT_MESHOPT_COMPRESSION: 'EXT_meshopt_compression'\n};\n\n/**\n * Punctual Lights Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual\n */\nclass GLTFLightsExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_LIGHTS_PUNCTUAL;\n\n\t\t// Object3D instance caches\n\t\tthis.cache = { refs: {}, uses: {} };\n\n\t}\n\n\t_markDefs() {\n\n\t\tconst parser = this.parser;\n\t\tconst nodeDefs = this.parser.json.nodes || [];\n\n\t\tfor ( let nodeIndex = 0, nodeLength = nodeDefs.length; nodeIndex < nodeLength; nodeIndex ++ ) {\n\n\t\t\tconst nodeDef = nodeDefs[ nodeIndex ];\n\n\t\t\tif ( nodeDef.extensions\n\t\t\t\t\t&& nodeDef.extensions[ this.name ]\n\t\t\t\t\t&& nodeDef.extensions[ this.name ].light !== undefined ) {\n\n\t\t\t\tparser._addNodeRef( this.cache, nodeDef.extensions[ this.name ].light );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t_loadLight( lightIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst cacheKey = 'light:' + lightIndex;\n\t\tlet dependency = parser.cache.get( cacheKey );\n\n\t\tif ( dependency ) return dependency;\n\n\t\tconst json = parser.json;\n\t\tconst extensions = ( json.extensions && json.extensions[ this.name ] ) || {};\n\t\tconst lightDefs = extensions.lights || [];\n\t\tconst lightDef = lightDefs[ lightIndex ];\n\t\tlet lightNode;\n\n\t\tconst color = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 0xffffff );\n\n\t\tif ( lightDef.color !== undefined ) color.fromArray( lightDef.color );\n\n\t\tconst range = lightDef.range !== undefined ? lightDef.range : 0;\n\n\t\tswitch ( lightDef.type ) {\n\n\t\t\tcase 'directional':\n\t\t\t\tlightNode = new three__WEBPACK_IMPORTED_MODULE_0__.DirectionalLight( color );\n\t\t\t\tlightNode.target.position.set( 0, 0, - 1 );\n\t\t\t\tlightNode.add( lightNode.target );\n\t\t\t\tbreak;\n\n\t\t\tcase 'point':\n\t\t\t\tlightNode = new three__WEBPACK_IMPORTED_MODULE_0__.PointLight( color );\n\t\t\t\tlightNode.distance = range;\n\t\t\t\tbreak;\n\n\t\t\tcase 'spot':\n\t\t\t\tlightNode = new three__WEBPACK_IMPORTED_MODULE_0__.SpotLight( color );\n\t\t\t\tlightNode.distance = range;\n\t\t\t\t// Handle spotlight properties.\n\t\t\t\tlightDef.spot = lightDef.spot || {};\n\t\t\t\tlightDef.spot.innerConeAngle = lightDef.spot.innerConeAngle !== undefined ? lightDef.spot.innerConeAngle : 0;\n\t\t\t\tlightDef.spot.outerConeAngle = lightDef.spot.outerConeAngle !== undefined ? lightDef.spot.outerConeAngle : Math.PI / 4.0;\n\t\t\t\tlightNode.angle = lightDef.spot.outerConeAngle;\n\t\t\t\tlightNode.penumbra = 1.0 - lightDef.spot.innerConeAngle / lightDef.spot.outerConeAngle;\n\t\t\t\tlightNode.target.position.set( 0, 0, - 1 );\n\t\t\t\tlightNode.add( lightNode.target );\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\tthrow new Error( 'THREE.GLTFLoader: Unexpected light type: ' + lightDef.type );\n\n\t\t}\n\n\t\t// Some lights (e.g. spot) default to a position other than the origin. Reset the position\n\t\t// here, because node-level parsing will only override position if explicitly specified.\n\t\tlightNode.position.set( 0, 0, 0 );\n\n\t\tlightNode.decay = 2;\n\n\t\tif ( lightDef.intensity !== undefined ) lightNode.intensity = lightDef.intensity;\n\n\t\tlightNode.name = parser.createUniqueName( lightDef.name || ( 'light_' + lightIndex ) );\n\n\t\tdependency = Promise.resolve( lightNode );\n\n\t\tparser.cache.add( cacheKey, dependency );\n\n\t\treturn dependency;\n\n\t}\n\n\tcreateNodeAttachment( nodeIndex ) {\n\n\t\tconst self = this;\n\t\tconst parser = this.parser;\n\t\tconst json = parser.json;\n\t\tconst nodeDef = json.nodes[ nodeIndex ];\n\t\tconst lightDef = ( nodeDef.extensions && nodeDef.extensions[ this.name ] ) || {};\n\t\tconst lightIndex = lightDef.light;\n\n\t\tif ( lightIndex === undefined ) return null;\n\n\t\treturn this._loadLight( lightIndex ).then( function ( light ) {\n\n\t\t\treturn parser._getNodeRef( self.cache, lightIndex, light );\n\n\t\t} );\n\n\t}\n\n}\n\n/**\n * Unlit Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_unlit\n */\nclass GLTFMaterialsUnlitExtension {\n\n\tconstructor() {\n\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_UNLIT;\n\n\t}\n\n\tgetMaterialType() {\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshBasicMaterial;\n\n\t}\n\n\textendParams( materialParams, materialDef, parser ) {\n\n\t\tconst pending = [];\n\n\t\tmaterialParams.color = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 1.0, 1.0, 1.0 );\n\t\tmaterialParams.opacity = 1.0;\n\n\t\tconst metallicRoughness = materialDef.pbrMetallicRoughness;\n\n\t\tif ( metallicRoughness ) {\n\n\t\t\tif ( Array.isArray( metallicRoughness.baseColorFactor ) ) {\n\n\t\t\t\tconst array = metallicRoughness.baseColorFactor;\n\n\t\t\t\tmaterialParams.color.fromArray( array );\n\t\t\t\tmaterialParams.opacity = array[ 3 ];\n\n\t\t\t}\n\n\t\t\tif ( metallicRoughness.baseColorTexture !== undefined ) {\n\n\t\t\t\tpending.push( parser.assignTexture( materialParams, 'map', metallicRoughness.baseColorTexture ) );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n}\n\n/**\n * Clearcoat Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_clearcoat\n */\nclass GLTFMaterialsClearcoatExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_CLEARCOAT;\n\n\t}\n\n\tgetMaterialType( materialIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshPhysicalMaterial;\n\n\t}\n\n\textendMaterialParams( materialIndex, materialParams ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {\n\n\t\t\treturn Promise.resolve();\n\n\t\t}\n\n\t\tconst pending = [];\n\n\t\tconst extension = materialDef.extensions[ this.name ];\n\n\t\tif ( extension.clearcoatFactor !== undefined ) {\n\n\t\t\tmaterialParams.clearcoat = extension.clearcoatFactor;\n\n\t\t}\n\n\t\tif ( extension.clearcoatTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'clearcoatMap', extension.clearcoatTexture ) );\n\n\t\t}\n\n\t\tif ( extension.clearcoatRoughnessFactor !== undefined ) {\n\n\t\t\tmaterialParams.clearcoatRoughness = extension.clearcoatRoughnessFactor;\n\n\t\t}\n\n\t\tif ( extension.clearcoatRoughnessTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'clearcoatRoughnessMap', extension.clearcoatRoughnessTexture ) );\n\n\t\t}\n\n\t\tif ( extension.clearcoatNormalTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'clearcoatNormalMap', extension.clearcoatNormalTexture ) );\n\n\t\t\tif ( extension.clearcoatNormalTexture.scale !== undefined ) {\n\n\t\t\t\tconst scale = extension.clearcoatNormalTexture.scale;\n\n\t\t\t\tmaterialParams.clearcoatNormalScale = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2( scale, scale );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n}\n\n/**\n * Sheen Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_sheen\n */\nclass GLTFMaterialsSheenExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_SHEEN;\n\n\t}\n\n\tgetMaterialType( materialIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshPhysicalMaterial;\n\n\t}\n\n\textendMaterialParams( materialIndex, materialParams ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {\n\n\t\t\treturn Promise.resolve();\n\n\t\t}\n\n\t\tconst pending = [];\n\n\t\tmaterialParams.sheenColor = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 0, 0, 0 );\n\t\tmaterialParams.sheenRoughness = 0;\n\t\tmaterialParams.sheen = 1;\n\n\t\tconst extension = materialDef.extensions[ this.name ];\n\n\t\tif ( extension.sheenColorFactor !== undefined ) {\n\n\t\t\tmaterialParams.sheenColor.fromArray( extension.sheenColorFactor );\n\n\t\t}\n\n\t\tif ( extension.sheenRoughnessFactor !== undefined ) {\n\n\t\t\tmaterialParams.sheenRoughness = extension.sheenRoughnessFactor;\n\n\t\t}\n\n\t\tif ( extension.sheenColorTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'sheenColorMap', extension.sheenColorTexture ) );\n\n\t\t}\n\n\t\tif ( extension.sheenRoughnessTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'sheenRoughnessMap', extension.sheenRoughnessTexture ) );\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n}\n\n/**\n * Transmission Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_transmission\n * Draft: https://github.com/KhronosGroup/glTF/pull/1698\n */\nclass GLTFMaterialsTransmissionExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_TRANSMISSION;\n\n\t}\n\n\tgetMaterialType( materialIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshPhysicalMaterial;\n\n\t}\n\n\textendMaterialParams( materialIndex, materialParams ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {\n\n\t\t\treturn Promise.resolve();\n\n\t\t}\n\n\t\tconst pending = [];\n\n\t\tconst extension = materialDef.extensions[ this.name ];\n\n\t\tif ( extension.transmissionFactor !== undefined ) {\n\n\t\t\tmaterialParams.transmission = extension.transmissionFactor;\n\n\t\t}\n\n\t\tif ( extension.transmissionTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'transmissionMap', extension.transmissionTexture ) );\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n}\n\n/**\n * Materials Volume Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_volume\n */\nclass GLTFMaterialsVolumeExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_VOLUME;\n\n\t}\n\n\tgetMaterialType( materialIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshPhysicalMaterial;\n\n\t}\n\n\textendMaterialParams( materialIndex, materialParams ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {\n\n\t\t\treturn Promise.resolve();\n\n\t\t}\n\n\t\tconst pending = [];\n\n\t\tconst extension = materialDef.extensions[ this.name ];\n\n\t\tmaterialParams.thickness = extension.thicknessFactor !== undefined ? extension.thicknessFactor : 0;\n\n\t\tif ( extension.thicknessTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'thicknessMap', extension.thicknessTexture ) );\n\n\t\t}\n\n\t\tmaterialParams.attenuationDistance = extension.attenuationDistance || 0;\n\n\t\tconst colorArray = extension.attenuationColor || [ 1, 1, 1 ];\n\t\tmaterialParams.attenuationColor = new three__WEBPACK_IMPORTED_MODULE_0__.Color( colorArray[ 0 ], colorArray[ 1 ], colorArray[ 2 ] );\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n}\n\n/**\n * Materials ior Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_ior\n */\nclass GLTFMaterialsIorExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_IOR;\n\n\t}\n\n\tgetMaterialType( materialIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshPhysicalMaterial;\n\n\t}\n\n\textendMaterialParams( materialIndex, materialParams ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {\n\n\t\t\treturn Promise.resolve();\n\n\t\t}\n\n\t\tconst extension = materialDef.extensions[ this.name ];\n\n\t\tmaterialParams.ior = extension.ior !== undefined ? extension.ior : 1.5;\n\n\t\treturn Promise.resolve();\n\n\t}\n\n}\n\n/**\n * Materials specular Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_specular\n */\nclass GLTFMaterialsSpecularExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_SPECULAR;\n\n\t}\n\n\tgetMaterialType( materialIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) return null;\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshPhysicalMaterial;\n\n\t}\n\n\textendMaterialParams( materialIndex, materialParams ) {\n\n\t\tconst parser = this.parser;\n\t\tconst materialDef = parser.json.materials[ materialIndex ];\n\n\t\tif ( ! materialDef.extensions || ! materialDef.extensions[ this.name ] ) {\n\n\t\t\treturn Promise.resolve();\n\n\t\t}\n\n\t\tconst pending = [];\n\n\t\tconst extension = materialDef.extensions[ this.name ];\n\n\t\tmaterialParams.specularIntensity = extension.specularFactor !== undefined ? extension.specularFactor : 1.0;\n\n\t\tif ( extension.specularTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'specularIntensityMap', extension.specularTexture ) );\n\n\t\t}\n\n\t\tconst colorArray = extension.specularColorFactor || [ 1, 1, 1 ];\n\t\tmaterialParams.specularColor = new three__WEBPACK_IMPORTED_MODULE_0__.Color( colorArray[ 0 ], colorArray[ 1 ], colorArray[ 2 ] );\n\n\t\tif ( extension.specularColorTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'specularColorMap', extension.specularColorTexture ).then( function ( texture ) {\n\n\t\t\t\ttexture.encoding = three__WEBPACK_IMPORTED_MODULE_0__.sRGBEncoding;\n\n\t\t\t} ) );\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n}\n\n/**\n * BasisU Texture Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_texture_basisu\n */\nclass GLTFTextureBasisUExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.KHR_TEXTURE_BASISU;\n\n\t}\n\n\tloadTexture( textureIndex ) {\n\n\t\tconst parser = this.parser;\n\t\tconst json = parser.json;\n\n\t\tconst textureDef = json.textures[ textureIndex ];\n\n\t\tif ( ! textureDef.extensions || ! textureDef.extensions[ this.name ] ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst extension = textureDef.extensions[ this.name ];\n\t\tconst loader = parser.options.ktx2Loader;\n\n\t\tif ( ! loader ) {\n\n\t\t\tif ( json.extensionsRequired && json.extensionsRequired.indexOf( this.name ) >= 0 ) {\n\n\t\t\t\tthrow new Error( 'THREE.GLTFLoader: setKTX2Loader must be called before loading KTX2 textures' );\n\n\t\t\t} else {\n\n\t\t\t\t// Assumes that the extension is optional and that a fallback texture is present\n\t\t\t\treturn null;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn parser.loadTextureImage( textureIndex, extension.source, loader );\n\n\t}\n\n}\n\n/**\n * WebP Texture Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_texture_webp\n */\nclass GLTFTextureWebPExtension {\n\n\tconstructor( parser ) {\n\n\t\tthis.parser = parser;\n\t\tthis.name = EXTENSIONS.EXT_TEXTURE_WEBP;\n\t\tthis.isSupported = null;\n\n\t}\n\n\tloadTexture( textureIndex ) {\n\n\t\tconst name = this.name;\n\t\tconst parser = this.parser;\n\t\tconst json = parser.json;\n\n\t\tconst textureDef = json.textures[ textureIndex ];\n\n\t\tif ( ! textureDef.extensions || ! textureDef.extensions[ name ] ) {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t\tconst extension = textureDef.extensions[ name ];\n\t\tconst source = json.images[ extension.source ];\n\n\t\tlet loader = parser.textureLoader;\n\t\tif ( source.uri ) {\n\n\t\t\tconst handler = parser.options.manager.getHandler( source.uri );\n\t\t\tif ( handler !== null ) loader = handler;\n\n\t\t}\n\n\t\treturn this.detectSupport().then( function ( isSupported ) {\n\n\t\t\tif ( isSupported ) return parser.loadTextureImage( textureIndex, source, loader );\n\n\t\t\tif ( json.extensionsRequired && json.extensionsRequired.indexOf( name ) >= 0 ) {\n\n\t\t\t\tthrow new Error( 'THREE.GLTFLoader: WebP required by asset but unsupported.' );\n\n\t\t\t}\n\n\t\t\t// Fall back to PNG or JPEG.\n\t\t\treturn parser.loadTexture( textureIndex );\n\n\t\t} );\n\n\t}\n\n\tdetectSupport() {\n\n\t\tif ( ! this.isSupported ) {\n\n\t\t\tthis.isSupported = new Promise( function ( resolve ) {\n\n\t\t\t\tconst image = new Image();\n\n\t\t\t\t// Lossy test image. Support for lossy images doesn't guarantee support for all\n\t\t\t\t// WebP images, unfortunately.\n\t\t\t\timage.src = 'data:image/webp;base64,UklGRiIAAABXRUJQVlA4IBYAAAAwAQCdASoBAAEADsD+JaQAA3AAAAAA';\n\n\t\t\t\timage.onload = image.onerror = function () {\n\n\t\t\t\t\tresolve( image.height === 1 );\n\n\t\t\t\t};\n\n\t\t\t} );\n\n\t\t}\n\n\t\treturn this.isSupported;\n\n\t}\n\n}\n\n/**\n * meshopt BufferView Compression Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_meshopt_compression\n */\nclass GLTFMeshoptCompression {\n\n\tconstructor( parser ) {\n\n\t\tthis.name = EXTENSIONS.EXT_MESHOPT_COMPRESSION;\n\t\tthis.parser = parser;\n\n\t}\n\n\tloadBufferView( index ) {\n\n\t\tconst json = this.parser.json;\n\t\tconst bufferView = json.bufferViews[ index ];\n\n\t\tif ( bufferView.extensions && bufferView.extensions[ this.name ] ) {\n\n\t\t\tconst extensionDef = bufferView.extensions[ this.name ];\n\n\t\t\tconst buffer = this.parser.getDependency( 'buffer', extensionDef.buffer );\n\t\t\tconst decoder = this.parser.options.meshoptDecoder;\n\n\t\t\tif ( ! decoder || ! decoder.supported ) {\n\n\t\t\t\tif ( json.extensionsRequired && json.extensionsRequired.indexOf( this.name ) >= 0 ) {\n\n\t\t\t\t\tthrow new Error( 'THREE.GLTFLoader: setMeshoptDecoder must be called before loading compressed files' );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// Assumes that the extension is optional and that fallback buffer data is present\n\t\t\t\t\treturn null;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn Promise.all( [ buffer, decoder.ready ] ).then( function ( res ) {\n\n\t\t\t\tconst byteOffset = extensionDef.byteOffset || 0;\n\t\t\t\tconst byteLength = extensionDef.byteLength || 0;\n\n\t\t\t\tconst count = extensionDef.count;\n\t\t\t\tconst stride = extensionDef.byteStride;\n\n\t\t\t\tconst result = new ArrayBuffer( count * stride );\n\t\t\t\tconst source = new Uint8Array( res[ 0 ], byteOffset, byteLength );\n\n\t\t\t\tdecoder.decodeGltfBuffer( new Uint8Array( result ), count, stride, source, extensionDef.mode, extensionDef.filter );\n\t\t\t\treturn result;\n\n\t\t\t} );\n\n\t\t} else {\n\n\t\t\treturn null;\n\n\t\t}\n\n\t}\n\n}\n\n/* BINARY EXTENSION */\nconst BINARY_EXTENSION_HEADER_MAGIC = 'glTF';\nconst BINARY_EXTENSION_HEADER_LENGTH = 12;\nconst BINARY_EXTENSION_CHUNK_TYPES = { JSON: 0x4E4F534A, BIN: 0x004E4942 };\n\nclass GLTFBinaryExtension {\n\n\tconstructor( data ) {\n\n\t\tthis.name = EXTENSIONS.KHR_BINARY_GLTF;\n\t\tthis.content = null;\n\t\tthis.body = null;\n\n\t\tconst headerView = new DataView( data, 0, BINARY_EXTENSION_HEADER_LENGTH );\n\n\t\tthis.header = {\n\t\t\tmagic: three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.decodeText( new Uint8Array( data.slice( 0, 4 ) ) ),\n\t\t\tversion: headerView.getUint32( 4, true ),\n\t\t\tlength: headerView.getUint32( 8, true )\n\t\t};\n\n\t\tif ( this.header.magic !== BINARY_EXTENSION_HEADER_MAGIC ) {\n\n\t\t\tthrow new Error( 'THREE.GLTFLoader: Unsupported glTF-Binary header.' );\n\n\t\t} else if ( this.header.version < 2.0 ) {\n\n\t\t\tthrow new Error( 'THREE.GLTFLoader: Legacy binary file detected.' );\n\n\t\t}\n\n\t\tconst chunkContentsLength = this.header.length - BINARY_EXTENSION_HEADER_LENGTH;\n\t\tconst chunkView = new DataView( data, BINARY_EXTENSION_HEADER_LENGTH );\n\t\tlet chunkIndex = 0;\n\n\t\twhile ( chunkIndex < chunkContentsLength ) {\n\n\t\t\tconst chunkLength = chunkView.getUint32( chunkIndex, true );\n\t\t\tchunkIndex += 4;\n\n\t\t\tconst chunkType = chunkView.getUint32( chunkIndex, true );\n\t\t\tchunkIndex += 4;\n\n\t\t\tif ( chunkType === BINARY_EXTENSION_CHUNK_TYPES.JSON ) {\n\n\t\t\t\tconst contentArray = new Uint8Array( data, BINARY_EXTENSION_HEADER_LENGTH + chunkIndex, chunkLength );\n\t\t\t\tthis.content = three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.decodeText( contentArray );\n\n\t\t\t} else if ( chunkType === BINARY_EXTENSION_CHUNK_TYPES.BIN ) {\n\n\t\t\t\tconst byteOffset = BINARY_EXTENSION_HEADER_LENGTH + chunkIndex;\n\t\t\t\tthis.body = data.slice( byteOffset, byteOffset + chunkLength );\n\n\t\t\t}\n\n\t\t\t// Clients must ignore chunks with unknown types.\n\n\t\t\tchunkIndex += chunkLength;\n\n\t\t}\n\n\t\tif ( this.content === null ) {\n\n\t\t\tthrow new Error( 'THREE.GLTFLoader: JSON content not found.' );\n\n\t\t}\n\n\t}\n\n}\n\n/**\n * DRACO Mesh Compression Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression\n */\nclass GLTFDracoMeshCompressionExtension {\n\n\tconstructor( json, dracoLoader ) {\n\n\t\tif ( ! dracoLoader ) {\n\n\t\t\tthrow new Error( 'THREE.GLTFLoader: No DRACOLoader instance provided.' );\n\n\t\t}\n\n\t\tthis.name = EXTENSIONS.KHR_DRACO_MESH_COMPRESSION;\n\t\tthis.json = json;\n\t\tthis.dracoLoader = dracoLoader;\n\t\tthis.dracoLoader.preload();\n\n\t}\n\n\tdecodePrimitive( primitive, parser ) {\n\n\t\tconst json = this.json;\n\t\tconst dracoLoader = this.dracoLoader;\n\t\tconst bufferViewIndex = primitive.extensions[ this.name ].bufferView;\n\t\tconst gltfAttributeMap = primitive.extensions[ this.name ].attributes;\n\t\tconst threeAttributeMap = {};\n\t\tconst attributeNormalizedMap = {};\n\t\tconst attributeTypeMap = {};\n\n\t\tfor ( const attributeName in gltfAttributeMap ) {\n\n\t\t\tconst threeAttributeName = ATTRIBUTES[ attributeName ] || attributeName.toLowerCase();\n\n\t\t\tthreeAttributeMap[ threeAttributeName ] = gltfAttributeMap[ attributeName ];\n\n\t\t}\n\n\t\tfor ( const attributeName in primitive.attributes ) {\n\n\t\t\tconst threeAttributeName = ATTRIBUTES[ attributeName ] || attributeName.toLowerCase();\n\n\t\t\tif ( gltfAttributeMap[ attributeName ] !== undefined ) {\n\n\t\t\t\tconst accessorDef = json.accessors[ primitive.attributes[ attributeName ] ];\n\t\t\t\tconst componentType = WEBGL_COMPONENT_TYPES[ accessorDef.componentType ];\n\n\t\t\t\tattributeTypeMap[ threeAttributeName ] = componentType;\n\t\t\t\tattributeNormalizedMap[ threeAttributeName ] = accessorDef.normalized === true;\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn parser.getDependency( 'bufferView', bufferViewIndex ).then( function ( bufferView ) {\n\n\t\t\treturn new Promise( function ( resolve ) {\n\n\t\t\t\tdracoLoader.decodeDracoFile( bufferView, function ( geometry ) {\n\n\t\t\t\t\tfor ( const attributeName in geometry.attributes ) {\n\n\t\t\t\t\t\tconst attribute = geometry.attributes[ attributeName ];\n\t\t\t\t\t\tconst normalized = attributeNormalizedMap[ attributeName ];\n\n\t\t\t\t\t\tif ( normalized !== undefined ) attribute.normalized = normalized;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tresolve( geometry );\n\n\t\t\t\t}, threeAttributeMap, attributeTypeMap );\n\n\t\t\t} );\n\n\t\t} );\n\n\t}\n\n}\n\n/**\n * Texture Transform Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_texture_transform\n */\nclass GLTFTextureTransformExtension {\n\n\tconstructor() {\n\n\t\tthis.name = EXTENSIONS.KHR_TEXTURE_TRANSFORM;\n\n\t}\n\n\textendTexture( texture, transform ) {\n\n\t\tif ( transform.texCoord !== undefined ) {\n\n\t\t\tconsole.warn( 'THREE.GLTFLoader: Custom UV sets in \"' + this.name + '\" extension not yet supported.' );\n\n\t\t}\n\n\t\tif ( transform.offset === undefined && transform.rotation === undefined && transform.scale === undefined ) {\n\n\t\t\t// See https://github.com/mrdoob/three.js/issues/21819.\n\t\t\treturn texture;\n\n\t\t}\n\n\t\ttexture = texture.clone();\n\n\t\tif ( transform.offset !== undefined ) {\n\n\t\t\ttexture.offset.fromArray( transform.offset );\n\n\t\t}\n\n\t\tif ( transform.rotation !== undefined ) {\n\n\t\t\ttexture.rotation = transform.rotation;\n\n\t\t}\n\n\t\tif ( transform.scale !== undefined ) {\n\n\t\t\ttexture.repeat.fromArray( transform.scale );\n\n\t\t}\n\n\t\ttexture.needsUpdate = true;\n\n\t\treturn texture;\n\n\t}\n\n}\n\n/**\n * Specular-Glossiness Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Archived/KHR_materials_pbrSpecularGlossiness\n */\n\n/**\n * A sub class of StandardMaterial with some of the functionality\n * changed via the `onBeforeCompile` callback\n * @pailhead\n */\nclass GLTFMeshStandardSGMaterial extends three__WEBPACK_IMPORTED_MODULE_0__.MeshStandardMaterial {\n\n\tconstructor( params ) {\n\n\t\tsuper();\n\n\t\tthis.isGLTFSpecularGlossinessMaterial = true;\n\n\t\t//various chunks that need replacing\n\t\tconst specularMapParsFragmentChunk = [\n\t\t\t'#ifdef USE_SPECULARMAP',\n\t\t\t'\tuniform sampler2D specularMap;',\n\t\t\t'#endif'\n\t\t].join( '\\n' );\n\n\t\tconst glossinessMapParsFragmentChunk = [\n\t\t\t'#ifdef USE_GLOSSINESSMAP',\n\t\t\t'\tuniform sampler2D glossinessMap;',\n\t\t\t'#endif'\n\t\t].join( '\\n' );\n\n\t\tconst specularMapFragmentChunk = [\n\t\t\t'vec3 specularFactor = specular;',\n\t\t\t'#ifdef USE_SPECULARMAP',\n\t\t\t'\tvec4 texelSpecular = texture2D( specularMap, vUv );',\n\t\t\t'\t// reads channel RGB, compatible with a glTF Specular-Glossiness (RGBA) texture',\n\t\t\t'\tspecularFactor *= texelSpecular.rgb;',\n\t\t\t'#endif'\n\t\t].join( '\\n' );\n\n\t\tconst glossinessMapFragmentChunk = [\n\t\t\t'float glossinessFactor = glossiness;',\n\t\t\t'#ifdef USE_GLOSSINESSMAP',\n\t\t\t'\tvec4 texelGlossiness = texture2D( glossinessMap, vUv );',\n\t\t\t'\t// reads channel A, compatible with a glTF Specular-Glossiness (RGBA) texture',\n\t\t\t'\tglossinessFactor *= texelGlossiness.a;',\n\t\t\t'#endif'\n\t\t].join( '\\n' );\n\n\t\tconst lightPhysicalFragmentChunk = [\n\t\t\t'PhysicalMaterial material;',\n\t\t\t'material.diffuseColor = diffuseColor.rgb * ( 1. - max( specularFactor.r, max( specularFactor.g, specularFactor.b ) ) );',\n\t\t\t'vec3 dxy = max( abs( dFdx( geometryNormal ) ), abs( dFdy( geometryNormal ) ) );',\n\t\t\t'float geometryRoughness = max( max( dxy.x, dxy.y ), dxy.z );',\n\t\t\t'material.roughness = max( 1.0 - glossinessFactor, 0.0525 ); // 0.0525 corresponds to the base mip of a 256 cubemap.',\n\t\t\t'material.roughness += geometryRoughness;',\n\t\t\t'material.roughness = min( material.roughness, 1.0 );',\n\t\t\t'material.specularColor = specularFactor;',\n\t\t].join( '\\n' );\n\n\t\tconst uniforms = {\n\t\t\tspecular: { value: new three__WEBPACK_IMPORTED_MODULE_0__.Color().setHex( 0xffffff ) },\n\t\t\tglossiness: { value: 1 },\n\t\t\tspecularMap: { value: null },\n\t\t\tglossinessMap: { value: null }\n\t\t};\n\n\t\tthis._extraUniforms = uniforms;\n\n\t\tthis.onBeforeCompile = function ( shader ) {\n\n\t\t\tfor ( const uniformName in uniforms ) {\n\n\t\t\t\tshader.uniforms[ uniformName ] = uniforms[ uniformName ];\n\n\t\t\t}\n\n\t\t\tshader.fragmentShader = shader.fragmentShader\n\t\t\t\t.replace( 'uniform float roughness;', 'uniform vec3 specular;' )\n\t\t\t\t.replace( 'uniform float metalness;', 'uniform float glossiness;' )\n\t\t\t\t.replace( '#include <roughnessmap_pars_fragment>', specularMapParsFragmentChunk )\n\t\t\t\t.replace( '#include <metalnessmap_pars_fragment>', glossinessMapParsFragmentChunk )\n\t\t\t\t.replace( '#include <roughnessmap_fragment>', specularMapFragmentChunk )\n\t\t\t\t.replace( '#include <metalnessmap_fragment>', glossinessMapFragmentChunk )\n\t\t\t\t.replace( '#include <lights_physical_fragment>', lightPhysicalFragmentChunk );\n\n\t\t};\n\n\t\tObject.defineProperties( this, {\n\n\t\t\tspecular: {\n\t\t\t\tget: function () {\n\n\t\t\t\t\treturn uniforms.specular.value;\n\n\t\t\t\t},\n\t\t\t\tset: function ( v ) {\n\n\t\t\t\t\tuniforms.specular.value = v;\n\n\t\t\t\t}\n\t\t\t},\n\n\t\t\tspecularMap: {\n\t\t\t\tget: function () {\n\n\t\t\t\t\treturn uniforms.specularMap.value;\n\n\t\t\t\t},\n\t\t\t\tset: function ( v ) {\n\n\t\t\t\t\tuniforms.specularMap.value = v;\n\n\t\t\t\t\tif ( v ) {\n\n\t\t\t\t\t\tthis.defines.USE_SPECULARMAP = ''; // USE_UV is set by the renderer for specular maps\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tdelete this.defines.USE_SPECULARMAP;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t},\n\n\t\t\tglossiness: {\n\t\t\t\tget: function () {\n\n\t\t\t\t\treturn uniforms.glossiness.value;\n\n\t\t\t\t},\n\t\t\t\tset: function ( v ) {\n\n\t\t\t\t\tuniforms.glossiness.value = v;\n\n\t\t\t\t}\n\t\t\t},\n\n\t\t\tglossinessMap: {\n\t\t\t\tget: function () {\n\n\t\t\t\t\treturn uniforms.glossinessMap.value;\n\n\t\t\t\t},\n\t\t\t\tset: function ( v ) {\n\n\t\t\t\t\tuniforms.glossinessMap.value = v;\n\n\t\t\t\t\tif ( v ) {\n\n\t\t\t\t\t\tthis.defines.USE_GLOSSINESSMAP = '';\n\t\t\t\t\t\tthis.defines.USE_UV = '';\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tdelete this.defines.USE_GLOSSINESSMAP;\n\t\t\t\t\t\tdelete this.defines.USE_UV;\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t}\n\n\t\t} );\n\n\t\tdelete this.metalness;\n\t\tdelete this.roughness;\n\t\tdelete this.metalnessMap;\n\t\tdelete this.roughnessMap;\n\n\t\tthis.setValues( params );\n\n\t}\n\n\tcopy( source ) {\n\n\t\tsuper.copy( source );\n\n\t\tthis.specularMap = source.specularMap;\n\t\tthis.specular.copy( source.specular );\n\t\tthis.glossinessMap = source.glossinessMap;\n\t\tthis.glossiness = source.glossiness;\n\t\tdelete this.metalness;\n\t\tdelete this.roughness;\n\t\tdelete this.metalnessMap;\n\t\tdelete this.roughnessMap;\n\t\treturn this;\n\n\t}\n\n}\n\n\nclass GLTFMaterialsPbrSpecularGlossinessExtension {\n\n\tconstructor() {\n\n\t\tthis.name = EXTENSIONS.KHR_MATERIALS_PBR_SPECULAR_GLOSSINESS;\n\n\t\tthis.specularGlossinessParams = [\n\t\t\t'color',\n\t\t\t'map',\n\t\t\t'lightMap',\n\t\t\t'lightMapIntensity',\n\t\t\t'aoMap',\n\t\t\t'aoMapIntensity',\n\t\t\t'emissive',\n\t\t\t'emissiveIntensity',\n\t\t\t'emissiveMap',\n\t\t\t'bumpMap',\n\t\t\t'bumpScale',\n\t\t\t'normalMap',\n\t\t\t'normalMapType',\n\t\t\t'displacementMap',\n\t\t\t'displacementScale',\n\t\t\t'displacementBias',\n\t\t\t'specularMap',\n\t\t\t'specular',\n\t\t\t'glossinessMap',\n\t\t\t'glossiness',\n\t\t\t'alphaMap',\n\t\t\t'envMap',\n\t\t\t'envMapIntensity',\n\t\t\t'refractionRatio',\n\t\t];\n\n\t}\n\n\tgetMaterialType() {\n\n\t\treturn GLTFMeshStandardSGMaterial;\n\n\t}\n\n\textendParams( materialParams, materialDef, parser ) {\n\n\t\tconst pbrSpecularGlossiness = materialDef.extensions[ this.name ];\n\n\t\tmaterialParams.color = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 1.0, 1.0, 1.0 );\n\t\tmaterialParams.opacity = 1.0;\n\n\t\tconst pending = [];\n\n\t\tif ( Array.isArray( pbrSpecularGlossiness.diffuseFactor ) ) {\n\n\t\t\tconst array = pbrSpecularGlossiness.diffuseFactor;\n\n\t\t\tmaterialParams.color.fromArray( array );\n\t\t\tmaterialParams.opacity = array[ 3 ];\n\n\t\t}\n\n\t\tif ( pbrSpecularGlossiness.diffuseTexture !== undefined ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'map', pbrSpecularGlossiness.diffuseTexture ) );\n\n\t\t}\n\n\t\tmaterialParams.emissive = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 0.0, 0.0, 0.0 );\n\t\tmaterialParams.glossiness = pbrSpecularGlossiness.glossinessFactor !== undefined ? pbrSpecularGlossiness.glossinessFactor : 1.0;\n\t\tmaterialParams.specular = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 1.0, 1.0, 1.0 );\n\n\t\tif ( Array.isArray( pbrSpecularGlossiness.specularFactor ) ) {\n\n\t\t\tmaterialParams.specular.fromArray( pbrSpecularGlossiness.specularFactor );\n\n\t\t}\n\n\t\tif ( pbrSpecularGlossiness.specularGlossinessTexture !== undefined ) {\n\n\t\t\tconst specGlossMapDef = pbrSpecularGlossiness.specularGlossinessTexture;\n\t\t\tpending.push( parser.assignTexture( materialParams, 'glossinessMap', specGlossMapDef ) );\n\t\t\tpending.push( parser.assignTexture( materialParams, 'specularMap', specGlossMapDef ) );\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n\tcreateMaterial( materialParams ) {\n\n\t\tconst material = new GLTFMeshStandardSGMaterial( materialParams );\n\t\tmaterial.fog = true;\n\n\t\tmaterial.color = materialParams.color;\n\n\t\tmaterial.map = materialParams.map === undefined ? null : materialParams.map;\n\n\t\tmaterial.lightMap = null;\n\t\tmaterial.lightMapIntensity = 1.0;\n\n\t\tmaterial.aoMap = materialParams.aoMap === undefined ? null : materialParams.aoMap;\n\t\tmaterial.aoMapIntensity = 1.0;\n\n\t\tmaterial.emissive = materialParams.emissive;\n\t\tmaterial.emissiveIntensity = 1.0;\n\t\tmaterial.emissiveMap = materialParams.emissiveMap === undefined ? null : materialParams.emissiveMap;\n\n\t\tmaterial.bumpMap = materialParams.bumpMap === undefined ? null : materialParams.bumpMap;\n\t\tmaterial.bumpScale = 1;\n\n\t\tmaterial.normalMap = materialParams.normalMap === undefined ? null : materialParams.normalMap;\n\t\tmaterial.normalMapType = three__WEBPACK_IMPORTED_MODULE_0__.TangentSpaceNormalMap;\n\n\t\tif ( materialParams.normalScale ) material.normalScale = materialParams.normalScale;\n\n\t\tmaterial.displacementMap = null;\n\t\tmaterial.displacementScale = 1;\n\t\tmaterial.displacementBias = 0;\n\n\t\tmaterial.specularMap = materialParams.specularMap === undefined ? null : materialParams.specularMap;\n\t\tmaterial.specular = materialParams.specular;\n\n\t\tmaterial.glossinessMap = materialParams.glossinessMap === undefined ? null : materialParams.glossinessMap;\n\t\tmaterial.glossiness = materialParams.glossiness;\n\n\t\tmaterial.alphaMap = null;\n\n\t\tmaterial.envMap = materialParams.envMap === undefined ? null : materialParams.envMap;\n\t\tmaterial.envMapIntensity = 1.0;\n\n\t\tmaterial.refractionRatio = 0.98;\n\n\t\treturn material;\n\n\t}\n\n}\n\n/**\n * Mesh Quantization Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_mesh_quantization\n */\nclass GLTFMeshQuantizationExtension {\n\n\tconstructor() {\n\n\t\tthis.name = EXTENSIONS.KHR_MESH_QUANTIZATION;\n\n\t}\n\n}\n\n/*********************************/\n/********** INTERPOLATION ********/\n/*********************************/\n\n// Spline Interpolation\n// Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#appendix-c-spline-interpolation\nclass GLTFCubicSplineInterpolant extends three__WEBPACK_IMPORTED_MODULE_0__.Interpolant {\n\n\tconstructor( parameterPositions, sampleValues, sampleSize, resultBuffer ) {\n\n\t\tsuper( parameterPositions, sampleValues, sampleSize, resultBuffer );\n\n\t}\n\n\tcopySampleValue_( index ) {\n\n\t\t// Copies a sample value to the result buffer. See description of glTF\n\t\t// CUBICSPLINE values layout in interpolate_() function below.\n\n\t\tconst result = this.resultBuffer,\n\t\t\tvalues = this.sampleValues,\n\t\t\tvalueSize = this.valueSize,\n\t\t\toffset = index * valueSize * 3 + valueSize;\n\n\t\tfor ( let i = 0; i !== valueSize; i ++ ) {\n\n\t\t\tresult[ i ] = values[ offset + i ];\n\n\t\t}\n\n\t\treturn result;\n\n\t}\n\n}\n\nGLTFCubicSplineInterpolant.prototype.beforeStart_ = GLTFCubicSplineInterpolant.prototype.copySampleValue_;\n\nGLTFCubicSplineInterpolant.prototype.afterEnd_ = GLTFCubicSplineInterpolant.prototype.copySampleValue_;\n\nGLTFCubicSplineInterpolant.prototype.interpolate_ = function ( i1, t0, t, t1 ) {\n\n\tconst result = this.resultBuffer;\n\tconst values = this.sampleValues;\n\tconst stride = this.valueSize;\n\n\tconst stride2 = stride * 2;\n\tconst stride3 = stride * 3;\n\n\tconst td = t1 - t0;\n\n\tconst p = ( t - t0 ) / td;\n\tconst pp = p * p;\n\tconst ppp = pp * p;\n\n\tconst offset1 = i1 * stride3;\n\tconst offset0 = offset1 - stride3;\n\n\tconst s2 = - 2 * ppp + 3 * pp;\n\tconst s3 = ppp - pp;\n\tconst s0 = 1 - s2;\n\tconst s1 = s3 - pp + p;\n\n\t// Layout of keyframe output values for CUBICSPLINE animations:\n\t//   [ inTangent_1, splineVertex_1, outTangent_1, inTangent_2, splineVertex_2, ... ]\n\tfor ( let i = 0; i !== stride; i ++ ) {\n\n\t\tconst p0 = values[ offset0 + i + stride ]; // splineVertex_k\n\t\tconst m0 = values[ offset0 + i + stride2 ] * td; // outTangent_k * (t_k+1 - t_k)\n\t\tconst p1 = values[ offset1 + i + stride ]; // splineVertex_k+1\n\t\tconst m1 = values[ offset1 + i ] * td; // inTangent_k+1 * (t_k+1 - t_k)\n\n\t\tresult[ i ] = s0 * p0 + s1 * m0 + s2 * p1 + s3 * m1;\n\n\t}\n\n\treturn result;\n\n};\n\nconst _q = new three__WEBPACK_IMPORTED_MODULE_0__.Quaternion();\n\nclass GLTFCubicSplineQuaternionInterpolant extends GLTFCubicSplineInterpolant {\n\n\tinterpolate_( i1, t0, t, t1 ) {\n\n\t\tconst result = super.interpolate_( i1, t0, t, t1 );\n\n\t\t_q.fromArray( result ).normalize().toArray( result );\n\n\t\treturn result;\n\n\t}\n\n}\n\n\n/*********************************/\n/********** INTERNALS ************/\n/*********************************/\n\n/* CONSTANTS */\n\nconst WEBGL_CONSTANTS = {\n\tFLOAT: 5126,\n\t//FLOAT_MAT2: 35674,\n\tFLOAT_MAT3: 35675,\n\tFLOAT_MAT4: 35676,\n\tFLOAT_VEC2: 35664,\n\tFLOAT_VEC3: 35665,\n\tFLOAT_VEC4: 35666,\n\tLINEAR: 9729,\n\tREPEAT: 10497,\n\tSAMPLER_2D: 35678,\n\tPOINTS: 0,\n\tLINES: 1,\n\tLINE_LOOP: 2,\n\tLINE_STRIP: 3,\n\tTRIANGLES: 4,\n\tTRIANGLE_STRIP: 5,\n\tTRIANGLE_FAN: 6,\n\tUNSIGNED_BYTE: 5121,\n\tUNSIGNED_SHORT: 5123\n};\n\nconst WEBGL_COMPONENT_TYPES = {\n\t5120: Int8Array,\n\t5121: Uint8Array,\n\t5122: Int16Array,\n\t5123: Uint16Array,\n\t5125: Uint32Array,\n\t5126: Float32Array\n};\n\nconst WEBGL_FILTERS = {\n\t9728: three__WEBPACK_IMPORTED_MODULE_0__.NearestFilter,\n\t9729: three__WEBPACK_IMPORTED_MODULE_0__.LinearFilter,\n\t9984: three__WEBPACK_IMPORTED_MODULE_0__.NearestMipmapNearestFilter,\n\t9985: three__WEBPACK_IMPORTED_MODULE_0__.LinearMipmapNearestFilter,\n\t9986: three__WEBPACK_IMPORTED_MODULE_0__.NearestMipmapLinearFilter,\n\t9987: three__WEBPACK_IMPORTED_MODULE_0__.LinearMipmapLinearFilter\n};\n\nconst WEBGL_WRAPPINGS = {\n\t33071: three__WEBPACK_IMPORTED_MODULE_0__.ClampToEdgeWrapping,\n\t33648: three__WEBPACK_IMPORTED_MODULE_0__.MirroredRepeatWrapping,\n\t10497: three__WEBPACK_IMPORTED_MODULE_0__.RepeatWrapping\n};\n\nconst WEBGL_TYPE_SIZES = {\n\t'SCALAR': 1,\n\t'VEC2': 2,\n\t'VEC3': 3,\n\t'VEC4': 4,\n\t'MAT2': 4,\n\t'MAT3': 9,\n\t'MAT4': 16\n};\n\nconst ATTRIBUTES = {\n\tPOSITION: 'position',\n\tNORMAL: 'normal',\n\tTANGENT: 'tangent',\n\tTEXCOORD_0: 'uv',\n\tTEXCOORD_1: 'uv2',\n\tCOLOR_0: 'color',\n\tWEIGHTS_0: 'skinWeight',\n\tJOINTS_0: 'skinIndex',\n};\n\nconst PATH_PROPERTIES = {\n\tscale: 'scale',\n\ttranslation: 'position',\n\trotation: 'quaternion',\n\tweights: 'morphTargetInfluences'\n};\n\nconst INTERPOLATION = {\n\tCUBICSPLINE: undefined, // We use a custom interpolant (GLTFCubicSplineInterpolation) for CUBICSPLINE tracks. Each\n\t\t                        // keyframe track will be initialized with a default interpolation type, then modified.\n\tLINEAR: three__WEBPACK_IMPORTED_MODULE_0__.InterpolateLinear,\n\tSTEP: three__WEBPACK_IMPORTED_MODULE_0__.InterpolateDiscrete\n};\n\nconst ALPHA_MODES = {\n\tOPAQUE: 'OPAQUE',\n\tMASK: 'MASK',\n\tBLEND: 'BLEND'\n};\n\n/**\n * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#default-material\n */\nfunction createDefaultMaterial( cache ) {\n\n\tif ( cache[ 'DefaultMaterial' ] === undefined ) {\n\n\t\tcache[ 'DefaultMaterial' ] = new three__WEBPACK_IMPORTED_MODULE_0__.MeshStandardMaterial( {\n\t\t\tcolor: 0xFFFFFF,\n\t\t\temissive: 0x000000,\n\t\t\tmetalness: 1,\n\t\t\troughness: 1,\n\t\t\ttransparent: false,\n\t\t\tdepthTest: true,\n\t\t\tside: three__WEBPACK_IMPORTED_MODULE_0__.FrontSide\n\t\t} );\n\n\t}\n\n\treturn cache[ 'DefaultMaterial' ];\n\n}\n\nfunction addUnknownExtensionsToUserData( knownExtensions, object, objectDef ) {\n\n\t// Add unknown glTF extensions to an object's userData.\n\n\tfor ( const name in objectDef.extensions ) {\n\n\t\tif ( knownExtensions[ name ] === undefined ) {\n\n\t\t\tobject.userData.gltfExtensions = object.userData.gltfExtensions || {};\n\t\t\tobject.userData.gltfExtensions[ name ] = objectDef.extensions[ name ];\n\n\t\t}\n\n\t}\n\n}\n\n/**\n * @param {Object3D|Material|BufferGeometry} object\n * @param {GLTF.definition} gltfDef\n */\nfunction assignExtrasToUserData( object, gltfDef ) {\n\n\tif ( gltfDef.extras !== undefined ) {\n\n\t\tif ( typeof gltfDef.extras === 'object' ) {\n\n\t\t\tObject.assign( object.userData, gltfDef.extras );\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.GLTFLoader: Ignoring primitive type .extras, ' + gltfDef.extras );\n\n\t\t}\n\n\t}\n\n}\n\n/**\n * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#morph-targets\n *\n * @param {BufferGeometry} geometry\n * @param {Array<GLTF.Target>} targets\n * @param {GLTFParser} parser\n * @return {Promise<BufferGeometry>}\n */\nfunction addMorphTargets( geometry, targets, parser ) {\n\n\tlet hasMorphPosition = false;\n\tlet hasMorphNormal = false;\n\tlet hasMorphColor = false;\n\n\tfor ( let i = 0, il = targets.length; i < il; i ++ ) {\n\n\t\tconst target = targets[ i ];\n\n\t\tif ( target.POSITION !== undefined ) hasMorphPosition = true;\n\t\tif ( target.NORMAL !== undefined ) hasMorphNormal = true;\n\t\tif ( target.COLOR_0 !== undefined ) hasMorphColor = true;\n\n\t\tif ( hasMorphPosition && hasMorphNormal && hasMorphColor ) break;\n\n\t}\n\n\tif ( ! hasMorphPosition && ! hasMorphNormal && ! hasMorphColor ) return Promise.resolve( geometry );\n\n\tconst pendingPositionAccessors = [];\n\tconst pendingNormalAccessors = [];\n\tconst pendingColorAccessors = [];\n\n\tfor ( let i = 0, il = targets.length; i < il; i ++ ) {\n\n\t\tconst target = targets[ i ];\n\n\t\tif ( hasMorphPosition ) {\n\n\t\t\tconst pendingAccessor = target.POSITION !== undefined\n\t\t\t\t? parser.getDependency( 'accessor', target.POSITION )\n\t\t\t\t: geometry.attributes.position;\n\n\t\t\tpendingPositionAccessors.push( pendingAccessor );\n\n\t\t}\n\n\t\tif ( hasMorphNormal ) {\n\n\t\t\tconst pendingAccessor = target.NORMAL !== undefined\n\t\t\t\t? parser.getDependency( 'accessor', target.NORMAL )\n\t\t\t\t: geometry.attributes.normal;\n\n\t\t\tpendingNormalAccessors.push( pendingAccessor );\n\n\t\t}\n\n\t\tif ( hasMorphColor ) {\n\n\t\t\tconst pendingAccessor = target.COLOR_0 !== undefined\n\t\t\t\t? parser.getDependency( 'accessor', target.COLOR_0 )\n\t\t\t\t: geometry.attributes.color;\n\n\t\t\tpendingColorAccessors.push( pendingAccessor );\n\n\t\t}\n\n\t}\n\n\treturn Promise.all( [\n\t\tPromise.all( pendingPositionAccessors ),\n\t\tPromise.all( pendingNormalAccessors ),\n\t\tPromise.all( pendingColorAccessors )\n\t] ).then( function ( accessors ) {\n\n\t\tconst morphPositions = accessors[ 0 ];\n\t\tconst morphNormals = accessors[ 1 ];\n\t\tconst morphColors = accessors[ 2 ];\n\n\t\tif ( hasMorphPosition ) geometry.morphAttributes.position = morphPositions;\n\t\tif ( hasMorphNormal ) geometry.morphAttributes.normal = morphNormals;\n\t\tif ( hasMorphColor ) geometry.morphAttributes.color = morphColors;\n\t\tgeometry.morphTargetsRelative = true;\n\n\t\treturn geometry;\n\n\t} );\n\n}\n\n/**\n * @param {Mesh} mesh\n * @param {GLTF.Mesh} meshDef\n */\nfunction updateMorphTargets( mesh, meshDef ) {\n\n\tmesh.updateMorphTargets();\n\n\tif ( meshDef.weights !== undefined ) {\n\n\t\tfor ( let i = 0, il = meshDef.weights.length; i < il; i ++ ) {\n\n\t\t\tmesh.morphTargetInfluences[ i ] = meshDef.weights[ i ];\n\n\t\t}\n\n\t}\n\n\t// .extras has user-defined data, so check that .extras.targetNames is an array.\n\tif ( meshDef.extras && Array.isArray( meshDef.extras.targetNames ) ) {\n\n\t\tconst targetNames = meshDef.extras.targetNames;\n\n\t\tif ( mesh.morphTargetInfluences.length === targetNames.length ) {\n\n\t\t\tmesh.morphTargetDictionary = {};\n\n\t\t\tfor ( let i = 0, il = targetNames.length; i < il; i ++ ) {\n\n\t\t\t\tmesh.morphTargetDictionary[ targetNames[ i ] ] = i;\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.GLTFLoader: Invalid extras.targetNames length. Ignoring names.' );\n\n\t\t}\n\n\t}\n\n}\n\nfunction createPrimitiveKey( primitiveDef ) {\n\n\tconst dracoExtension = primitiveDef.extensions && primitiveDef.extensions[ EXTENSIONS.KHR_DRACO_MESH_COMPRESSION ];\n\tlet geometryKey;\n\n\tif ( dracoExtension ) {\n\n\t\tgeometryKey = 'draco:' + dracoExtension.bufferView\n\t\t\t\t+ ':' + dracoExtension.indices\n\t\t\t\t+ ':' + createAttributesKey( dracoExtension.attributes );\n\n\t} else {\n\n\t\tgeometryKey = primitiveDef.indices + ':' + createAttributesKey( primitiveDef.attributes ) + ':' + primitiveDef.mode;\n\n\t}\n\n\treturn geometryKey;\n\n}\n\nfunction createAttributesKey( attributes ) {\n\n\tlet attributesKey = '';\n\n\tconst keys = Object.keys( attributes ).sort();\n\n\tfor ( let i = 0, il = keys.length; i < il; i ++ ) {\n\n\t\tattributesKey += keys[ i ] + ':' + attributes[ keys[ i ] ] + ';';\n\n\t}\n\n\treturn attributesKey;\n\n}\n\nfunction getNormalizedComponentScale( constructor ) {\n\n\t// Reference:\n\t// https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_mesh_quantization#encoding-quantized-data\n\n\tswitch ( constructor ) {\n\n\t\tcase Int8Array:\n\t\t\treturn 1 / 127;\n\n\t\tcase Uint8Array:\n\t\t\treturn 1 / 255;\n\n\t\tcase Int16Array:\n\t\t\treturn 1 / 32767;\n\n\t\tcase Uint16Array:\n\t\t\treturn 1 / 65535;\n\n\t\tdefault:\n\t\t\tthrow new Error( 'THREE.GLTFLoader: Unsupported normalized accessor component type.' );\n\n\t}\n\n}\n\nfunction getImageURIMimeType( uri ) {\n\n\tif ( uri.search( /\\.jpe?g($|\\?)/i ) > 0 || uri.search( /^data\\:image\\/jpeg/ ) === 0 ) return 'image/jpeg';\n\tif ( uri.search( /\\.webp($|\\?)/i ) > 0 || uri.search( /^data\\:image\\/webp/ ) === 0 ) return 'image/webp';\n\n\treturn 'image/png';\n\n}\n\n/* GLTF PARSER */\n\nclass GLTFParser {\n\n\tconstructor( json = {}, options = {} ) {\n\n\t\tthis.json = json;\n\t\tthis.extensions = {};\n\t\tthis.plugins = {};\n\t\tthis.options = options;\n\n\t\t// loader object cache\n\t\tthis.cache = new GLTFRegistry();\n\n\t\t// associations between Three.js objects and glTF elements\n\t\tthis.associations = new Map();\n\n\t\t// BufferGeometry caching\n\t\tthis.primitiveCache = {};\n\n\t\t// Object3D instance caches\n\t\tthis.meshCache = { refs: {}, uses: {} };\n\t\tthis.cameraCache = { refs: {}, uses: {} };\n\t\tthis.lightCache = { refs: {}, uses: {} };\n\n\t\tthis.sourceCache = {};\n\t\tthis.textureCache = {};\n\n\t\t// Track node names, to ensure no duplicates\n\t\tthis.nodeNamesUsed = {};\n\n\t\t// Use an ImageBitmapLoader if imageBitmaps are supported. Moves much of the\n\t\t// expensive work of uploading a texture to the GPU off the main thread.\n\t\tif ( typeof createImageBitmap !== 'undefined' && /Firefox|^((?!chrome|android).)*safari/i.test( navigator.userAgent ) === false ) {\n\n\t\t\tthis.textureLoader = new three__WEBPACK_IMPORTED_MODULE_0__.ImageBitmapLoader( this.options.manager );\n\n\t\t} else {\n\n\t\t\tthis.textureLoader = new three__WEBPACK_IMPORTED_MODULE_0__.TextureLoader( this.options.manager );\n\n\t\t}\n\n\t\tthis.textureLoader.setCrossOrigin( this.options.crossOrigin );\n\t\tthis.textureLoader.setRequestHeader( this.options.requestHeader );\n\n\t\tthis.fileLoader = new three__WEBPACK_IMPORTED_MODULE_0__.FileLoader( this.options.manager );\n\t\tthis.fileLoader.setResponseType( 'arraybuffer' );\n\n\t\tif ( this.options.crossOrigin === 'use-credentials' ) {\n\n\t\t\tthis.fileLoader.setWithCredentials( true );\n\n\t\t}\n\n\t}\n\n\tsetExtensions( extensions ) {\n\n\t\tthis.extensions = extensions;\n\n\t}\n\n\tsetPlugins( plugins ) {\n\n\t\tthis.plugins = plugins;\n\n\t}\n\n\tparse( onLoad, onError ) {\n\n\t\tconst parser = this;\n\t\tconst json = this.json;\n\t\tconst extensions = this.extensions;\n\n\t\t// Clear the loader cache\n\t\tthis.cache.removeAll();\n\n\t\t// Mark the special nodes/meshes in json for efficient parse\n\t\tthis._invokeAll( function ( ext ) {\n\n\t\t\treturn ext._markDefs && ext._markDefs();\n\n\t\t} );\n\n\t\tPromise.all( this._invokeAll( function ( ext ) {\n\n\t\t\treturn ext.beforeRoot && ext.beforeRoot();\n\n\t\t} ) ).then( function () {\n\n\t\t\treturn Promise.all( [\n\n\t\t\t\tparser.getDependencies( 'scene' ),\n\t\t\t\tparser.getDependencies( 'animation' ),\n\t\t\t\tparser.getDependencies( 'camera' ),\n\n\t\t\t] );\n\n\t\t} ).then( function ( dependencies ) {\n\n\t\t\tconst result = {\n\t\t\t\tscene: dependencies[ 0 ][ json.scene || 0 ],\n\t\t\t\tscenes: dependencies[ 0 ],\n\t\t\t\tanimations: dependencies[ 1 ],\n\t\t\t\tcameras: dependencies[ 2 ],\n\t\t\t\tasset: json.asset,\n\t\t\t\tparser: parser,\n\t\t\t\tuserData: {}\n\t\t\t};\n\n\t\t\taddUnknownExtensionsToUserData( extensions, result, json );\n\n\t\t\tassignExtrasToUserData( result, json );\n\n\t\t\tPromise.all( parser._invokeAll( function ( ext ) {\n\n\t\t\t\treturn ext.afterRoot && ext.afterRoot( result );\n\n\t\t\t} ) ).then( function () {\n\n\t\t\t\tonLoad( result );\n\n\t\t\t} );\n\n\t\t} ).catch( onError );\n\n\t}\n\n\t/**\n\t * Marks the special nodes/meshes in json for efficient parse.\n\t */\n\t_markDefs() {\n\n\t\tconst nodeDefs = this.json.nodes || [];\n\t\tconst skinDefs = this.json.skins || [];\n\t\tconst meshDefs = this.json.meshes || [];\n\n\t\t// Nothing in the node definition indicates whether it is a Bone or an\n\t\t// Object3D. Use the skins' joint references to mark bones.\n\t\tfor ( let skinIndex = 0, skinLength = skinDefs.length; skinIndex < skinLength; skinIndex ++ ) {\n\n\t\t\tconst joints = skinDefs[ skinIndex ].joints;\n\n\t\t\tfor ( let i = 0, il = joints.length; i < il; i ++ ) {\n\n\t\t\t\tnodeDefs[ joints[ i ] ].isBone = true;\n\n\t\t\t}\n\n\t\t}\n\n\t\t// Iterate over all nodes, marking references to shared resources,\n\t\t// as well as skeleton joints.\n\t\tfor ( let nodeIndex = 0, nodeLength = nodeDefs.length; nodeIndex < nodeLength; nodeIndex ++ ) {\n\n\t\t\tconst nodeDef = nodeDefs[ nodeIndex ];\n\n\t\t\tif ( nodeDef.mesh !== undefined ) {\n\n\t\t\t\tthis._addNodeRef( this.meshCache, nodeDef.mesh );\n\n\t\t\t\t// Nothing in the mesh definition indicates whether it is\n\t\t\t\t// a SkinnedMesh or Mesh. Use the node's mesh reference\n\t\t\t\t// to mark SkinnedMesh if node has skin.\n\t\t\t\tif ( nodeDef.skin !== undefined ) {\n\n\t\t\t\t\tmeshDefs[ nodeDef.mesh ].isSkinnedMesh = true;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( nodeDef.camera !== undefined ) {\n\n\t\t\t\tthis._addNodeRef( this.cameraCache, nodeDef.camera );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\t/**\n\t * Counts references to shared node / Object3D resources. These resources\n\t * can be reused, or \"instantiated\", at multiple nodes in the scene\n\t * hierarchy. Mesh, Camera, and Light instances are instantiated and must\n\t * be marked. Non-scenegraph resources (like Materials, Geometries, and\n\t * Textures) can be reused directly and are not marked here.\n\t *\n\t * Example: CesiumMilkTruck sample model reuses \"Wheel\" meshes.\n\t */\n\t_addNodeRef( cache, index ) {\n\n\t\tif ( index === undefined ) return;\n\n\t\tif ( cache.refs[ index ] === undefined ) {\n\n\t\t\tcache.refs[ index ] = cache.uses[ index ] = 0;\n\n\t\t}\n\n\t\tcache.refs[ index ] ++;\n\n\t}\n\n\t/** Returns a reference to a shared resource, cloning it if necessary. */\n\t_getNodeRef( cache, index, object ) {\n\n\t\tif ( cache.refs[ index ] <= 1 ) return object;\n\n\t\tconst ref = object.clone();\n\n\t\t// Propagates mappings to the cloned object, prevents mappings on the\n\t\t// original object from being lost.\n\t\tconst updateMappings = ( original, clone ) => {\n\n\t\t\tconst mappings = this.associations.get( original );\n\t\t\tif ( mappings != null ) {\n\n\t\t\t\tthis.associations.set( clone, mappings );\n\n\t\t\t}\n\n\t\t\tfor ( const [ i, child ] of original.children.entries() ) {\n\n\t\t\t\tupdateMappings( child, clone.children[ i ] );\n\n\t\t\t}\n\n\t\t};\n\n\t\tupdateMappings( object, ref );\n\n\t\tref.name += '_instance_' + ( cache.uses[ index ] ++ );\n\n\t\treturn ref;\n\n\t}\n\n\t_invokeOne( func ) {\n\n\t\tconst extensions = Object.values( this.plugins );\n\t\textensions.push( this );\n\n\t\tfor ( let i = 0; i < extensions.length; i ++ ) {\n\n\t\t\tconst result = func( extensions[ i ] );\n\n\t\t\tif ( result ) return result;\n\n\t\t}\n\n\t\treturn null;\n\n\t}\n\n\t_invokeAll( func ) {\n\n\t\tconst extensions = Object.values( this.plugins );\n\t\textensions.unshift( this );\n\n\t\tconst pending = [];\n\n\t\tfor ( let i = 0; i < extensions.length; i ++ ) {\n\n\t\t\tconst result = func( extensions[ i ] );\n\n\t\t\tif ( result ) pending.push( result );\n\n\t\t}\n\n\t\treturn pending;\n\n\t}\n\n\t/**\n\t * Requests the specified dependency asynchronously, with caching.\n\t * @param {string} type\n\t * @param {number} index\n\t * @return {Promise<Object3D|Material|THREE.Texture|AnimationClip|ArrayBuffer|Object>}\n\t */\n\tgetDependency( type, index ) {\n\n\t\tconst cacheKey = type + ':' + index;\n\t\tlet dependency = this.cache.get( cacheKey );\n\n\t\tif ( ! dependency ) {\n\n\t\t\tswitch ( type ) {\n\n\t\t\t\tcase 'scene':\n\t\t\t\t\tdependency = this.loadScene( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'node':\n\t\t\t\t\tdependency = this.loadNode( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'mesh':\n\t\t\t\t\tdependency = this._invokeOne( function ( ext ) {\n\n\t\t\t\t\t\treturn ext.loadMesh && ext.loadMesh( index );\n\n\t\t\t\t\t} );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'accessor':\n\t\t\t\t\tdependency = this.loadAccessor( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'bufferView':\n\t\t\t\t\tdependency = this._invokeOne( function ( ext ) {\n\n\t\t\t\t\t\treturn ext.loadBufferView && ext.loadBufferView( index );\n\n\t\t\t\t\t} );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'buffer':\n\t\t\t\t\tdependency = this.loadBuffer( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'material':\n\t\t\t\t\tdependency = this._invokeOne( function ( ext ) {\n\n\t\t\t\t\t\treturn ext.loadMaterial && ext.loadMaterial( index );\n\n\t\t\t\t\t} );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'texture':\n\t\t\t\t\tdependency = this._invokeOne( function ( ext ) {\n\n\t\t\t\t\t\treturn ext.loadTexture && ext.loadTexture( index );\n\n\t\t\t\t\t} );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'skin':\n\t\t\t\t\tdependency = this.loadSkin( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'animation':\n\t\t\t\t\tdependency = this.loadAnimation( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tcase 'camera':\n\t\t\t\t\tdependency = this.loadCamera( index );\n\t\t\t\t\tbreak;\n\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new Error( 'Unknown type: ' + type );\n\n\t\t\t}\n\n\t\t\tthis.cache.add( cacheKey, dependency );\n\n\t\t}\n\n\t\treturn dependency;\n\n\t}\n\n\t/**\n\t * Requests all dependencies of the specified type asynchronously, with caching.\n\t * @param {string} type\n\t * @return {Promise<Array<Object>>}\n\t */\n\tgetDependencies( type ) {\n\n\t\tlet dependencies = this.cache.get( type );\n\n\t\tif ( ! dependencies ) {\n\n\t\t\tconst parser = this;\n\t\t\tconst defs = this.json[ type + ( type === 'mesh' ? 'es' : 's' ) ] || [];\n\n\t\t\tdependencies = Promise.all( defs.map( function ( def, index ) {\n\n\t\t\t\treturn parser.getDependency( type, index );\n\n\t\t\t} ) );\n\n\t\t\tthis.cache.add( type, dependencies );\n\n\t\t}\n\n\t\treturn dependencies;\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#buffers-and-buffer-views\n\t * @param {number} bufferIndex\n\t * @return {Promise<ArrayBuffer>}\n\t */\n\tloadBuffer( bufferIndex ) {\n\n\t\tconst bufferDef = this.json.buffers[ bufferIndex ];\n\t\tconst loader = this.fileLoader;\n\n\t\tif ( bufferDef.type && bufferDef.type !== 'arraybuffer' ) {\n\n\t\t\tthrow new Error( 'THREE.GLTFLoader: ' + bufferDef.type + ' buffer type is not supported.' );\n\n\t\t}\n\n\t\t// If present, GLB container is required to be the first buffer.\n\t\tif ( bufferDef.uri === undefined && bufferIndex === 0 ) {\n\n\t\t\treturn Promise.resolve( this.extensions[ EXTENSIONS.KHR_BINARY_GLTF ].body );\n\n\t\t}\n\n\t\tconst options = this.options;\n\n\t\treturn new Promise( function ( resolve, reject ) {\n\n\t\t\tloader.load( three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.resolveURL( bufferDef.uri, options.path ), resolve, undefined, function () {\n\n\t\t\t\treject( new Error( 'THREE.GLTFLoader: Failed to load buffer \"' + bufferDef.uri + '\".' ) );\n\n\t\t\t} );\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#buffers-and-buffer-views\n\t * @param {number} bufferViewIndex\n\t * @return {Promise<ArrayBuffer>}\n\t */\n\tloadBufferView( bufferViewIndex ) {\n\n\t\tconst bufferViewDef = this.json.bufferViews[ bufferViewIndex ];\n\n\t\treturn this.getDependency( 'buffer', bufferViewDef.buffer ).then( function ( buffer ) {\n\n\t\t\tconst byteLength = bufferViewDef.byteLength || 0;\n\t\t\tconst byteOffset = bufferViewDef.byteOffset || 0;\n\t\t\treturn buffer.slice( byteOffset, byteOffset + byteLength );\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#accessors\n\t * @param {number} accessorIndex\n\t * @return {Promise<BufferAttribute|InterleavedBufferAttribute>}\n\t */\n\tloadAccessor( accessorIndex ) {\n\n\t\tconst parser = this;\n\t\tconst json = this.json;\n\n\t\tconst accessorDef = this.json.accessors[ accessorIndex ];\n\n\t\tif ( accessorDef.bufferView === undefined && accessorDef.sparse === undefined ) {\n\n\t\t\t// Ignore empty accessors, which may be used to declare runtime\n\t\t\t// information about attributes coming from another source (e.g. Draco\n\t\t\t// compression extension).\n\t\t\treturn Promise.resolve( null );\n\n\t\t}\n\n\t\tconst pendingBufferViews = [];\n\n\t\tif ( accessorDef.bufferView !== undefined ) {\n\n\t\t\tpendingBufferViews.push( this.getDependency( 'bufferView', accessorDef.bufferView ) );\n\n\t\t} else {\n\n\t\t\tpendingBufferViews.push( null );\n\n\t\t}\n\n\t\tif ( accessorDef.sparse !== undefined ) {\n\n\t\t\tpendingBufferViews.push( this.getDependency( 'bufferView', accessorDef.sparse.indices.bufferView ) );\n\t\t\tpendingBufferViews.push( this.getDependency( 'bufferView', accessorDef.sparse.values.bufferView ) );\n\n\t\t}\n\n\t\treturn Promise.all( pendingBufferViews ).then( function ( bufferViews ) {\n\n\t\t\tconst bufferView = bufferViews[ 0 ];\n\n\t\t\tconst itemSize = WEBGL_TYPE_SIZES[ accessorDef.type ];\n\t\t\tconst TypedArray = WEBGL_COMPONENT_TYPES[ accessorDef.componentType ];\n\n\t\t\t// For VEC3: itemSize is 3, elementBytes is 4, itemBytes is 12.\n\t\t\tconst elementBytes = TypedArray.BYTES_PER_ELEMENT;\n\t\t\tconst itemBytes = elementBytes * itemSize;\n\t\t\tconst byteOffset = accessorDef.byteOffset || 0;\n\t\t\tconst byteStride = accessorDef.bufferView !== undefined ? json.bufferViews[ accessorDef.bufferView ].byteStride : undefined;\n\t\t\tconst normalized = accessorDef.normalized === true;\n\t\t\tlet array, bufferAttribute;\n\n\t\t\t// The buffer is not interleaved if the stride is the item size in bytes.\n\t\t\tif ( byteStride && byteStride !== itemBytes ) {\n\n\t\t\t\t// Each \"slice\" of the buffer, as defined by 'count' elements of 'byteStride' bytes, gets its own InterleavedBuffer\n\t\t\t\t// This makes sure that IBA.count reflects accessor.count properly\n\t\t\t\tconst ibSlice = Math.floor( byteOffset / byteStride );\n\t\t\t\tconst ibCacheKey = 'InterleavedBuffer:' + accessorDef.bufferView + ':' + accessorDef.componentType + ':' + ibSlice + ':' + accessorDef.count;\n\t\t\t\tlet ib = parser.cache.get( ibCacheKey );\n\n\t\t\t\tif ( ! ib ) {\n\n\t\t\t\t\tarray = new TypedArray( bufferView, ibSlice * byteStride, accessorDef.count * byteStride / elementBytes );\n\n\t\t\t\t\t// Integer parameters to IB/IBA are in array elements, not bytes.\n\t\t\t\t\tib = new three__WEBPACK_IMPORTED_MODULE_0__.InterleavedBuffer( array, byteStride / elementBytes );\n\n\t\t\t\t\tparser.cache.add( ibCacheKey, ib );\n\n\t\t\t\t}\n\n\t\t\t\tbufferAttribute = new three__WEBPACK_IMPORTED_MODULE_0__.InterleavedBufferAttribute( ib, itemSize, ( byteOffset % byteStride ) / elementBytes, normalized );\n\n\t\t\t} else {\n\n\t\t\t\tif ( bufferView === null ) {\n\n\t\t\t\t\tarray = new TypedArray( accessorDef.count * itemSize );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tarray = new TypedArray( bufferView, byteOffset, accessorDef.count * itemSize );\n\n\t\t\t\t}\n\n\t\t\t\tbufferAttribute = new three__WEBPACK_IMPORTED_MODULE_0__.BufferAttribute( array, itemSize, normalized );\n\n\t\t\t}\n\n\t\t\t// https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#sparse-accessors\n\t\t\tif ( accessorDef.sparse !== undefined ) {\n\n\t\t\t\tconst itemSizeIndices = WEBGL_TYPE_SIZES.SCALAR;\n\t\t\t\tconst TypedArrayIndices = WEBGL_COMPONENT_TYPES[ accessorDef.sparse.indices.componentType ];\n\n\t\t\t\tconst byteOffsetIndices = accessorDef.sparse.indices.byteOffset || 0;\n\t\t\t\tconst byteOffsetValues = accessorDef.sparse.values.byteOffset || 0;\n\n\t\t\t\tconst sparseIndices = new TypedArrayIndices( bufferViews[ 1 ], byteOffsetIndices, accessorDef.sparse.count * itemSizeIndices );\n\t\t\t\tconst sparseValues = new TypedArray( bufferViews[ 2 ], byteOffsetValues, accessorDef.sparse.count * itemSize );\n\n\t\t\t\tif ( bufferView !== null ) {\n\n\t\t\t\t\t// Avoid modifying the original ArrayBuffer, if the bufferView wasn't initialized with zeroes.\n\t\t\t\t\tbufferAttribute = new three__WEBPACK_IMPORTED_MODULE_0__.BufferAttribute( bufferAttribute.array.slice(), bufferAttribute.itemSize, bufferAttribute.normalized );\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let i = 0, il = sparseIndices.length; i < il; i ++ ) {\n\n\t\t\t\t\tconst index = sparseIndices[ i ];\n\n\t\t\t\t\tbufferAttribute.setX( index, sparseValues[ i * itemSize ] );\n\t\t\t\t\tif ( itemSize >= 2 ) bufferAttribute.setY( index, sparseValues[ i * itemSize + 1 ] );\n\t\t\t\t\tif ( itemSize >= 3 ) bufferAttribute.setZ( index, sparseValues[ i * itemSize + 2 ] );\n\t\t\t\t\tif ( itemSize >= 4 ) bufferAttribute.setW( index, sparseValues[ i * itemSize + 3 ] );\n\t\t\t\t\tif ( itemSize >= 5 ) throw new Error( 'THREE.GLTFLoader: Unsupported itemSize in sparse BufferAttribute.' );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\treturn bufferAttribute;\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#textures\n\t * @param {number} textureIndex\n\t * @return {Promise<THREE.Texture>}\n\t */\n\tloadTexture( textureIndex ) {\n\n\t\tconst json = this.json;\n\t\tconst options = this.options;\n\t\tconst textureDef = json.textures[ textureIndex ];\n\t\tconst sourceIndex = textureDef.source;\n\t\tconst sourceDef = json.images[ sourceIndex ];\n\n\t\tlet loader = this.textureLoader;\n\n\t\tif ( sourceDef.uri ) {\n\n\t\t\tconst handler = options.manager.getHandler( sourceDef.uri );\n\t\t\tif ( handler !== null ) loader = handler;\n\n\t\t}\n\n\t\treturn this.loadTextureImage( textureIndex, sourceIndex, loader );\n\n\t}\n\n\tloadTextureImage( textureIndex, sourceIndex, loader ) {\n\n\t\tconst parser = this;\n\t\tconst json = this.json;\n\n\t\tconst textureDef = json.textures[ textureIndex ];\n\t\tconst sourceDef = json.images[ sourceIndex ];\n\n\t\tconst cacheKey = ( sourceDef.uri || sourceDef.bufferView ) + ':' + textureDef.sampler;\n\n\t\tif ( this.textureCache[ cacheKey ] ) {\n\n\t\t\t// See https://github.com/mrdoob/three.js/issues/21559.\n\t\t\treturn this.textureCache[ cacheKey ];\n\n\t\t}\n\n\t\tconst promise = this.loadImageSource( sourceIndex, loader ).then( function ( texture ) {\n\n\t\t\ttexture.flipY = false;\n\n\t\t\tif ( textureDef.name ) texture.name = textureDef.name;\n\n\t\t\tconst samplers = json.samplers || {};\n\t\t\tconst sampler = samplers[ textureDef.sampler ] || {};\n\n\t\t\ttexture.magFilter = WEBGL_FILTERS[ sampler.magFilter ] || three__WEBPACK_IMPORTED_MODULE_0__.LinearFilter;\n\t\t\ttexture.minFilter = WEBGL_FILTERS[ sampler.minFilter ] || three__WEBPACK_IMPORTED_MODULE_0__.LinearMipmapLinearFilter;\n\t\t\ttexture.wrapS = WEBGL_WRAPPINGS[ sampler.wrapS ] || three__WEBPACK_IMPORTED_MODULE_0__.RepeatWrapping;\n\t\t\ttexture.wrapT = WEBGL_WRAPPINGS[ sampler.wrapT ] || three__WEBPACK_IMPORTED_MODULE_0__.RepeatWrapping;\n\n\t\t\tparser.associations.set( texture, { textures: textureIndex } );\n\n\t\t\treturn texture;\n\n\t\t} ).catch( function () {\n\n\t\t\treturn null;\n\n\t\t} );\n\n\t\tthis.textureCache[ cacheKey ] = promise;\n\n\t\treturn promise;\n\n\t}\n\n\tloadImageSource( sourceIndex, loader ) {\n\n\t\tconst parser = this;\n\t\tconst json = this.json;\n\t\tconst options = this.options;\n\n\t\tif ( this.sourceCache[ sourceIndex ] !== undefined ) {\n\n\t\t\treturn this.sourceCache[ sourceIndex ].then( function ( texture ) {\n\n\t\t\t\treturn texture.clone();\n\n\t\t\t} ).catch( function ( error ) {\n\n\t\t\t\tthrow error;\n\n\t\t\t} );\n\n\t\t}\n\n\t\tconst sourceDef = json.images[ sourceIndex ];\n\n\t\tconst URL = self.URL || self.webkitURL;\n\n\t\tlet sourceURI = sourceDef.uri || '';\n\t\tlet isObjectURL = false;\n\n\t\tif ( sourceDef.bufferView !== undefined ) {\n\n\t\t\t// Load binary image data from bufferView, if provided.\n\n\t\t\tsourceURI = parser.getDependency( 'bufferView', sourceDef.bufferView ).then( function ( bufferView ) {\n\n\t\t\t\tisObjectURL = true;\n\t\t\t\tconst blob = new Blob( [ bufferView ], { type: sourceDef.mimeType } );\n\t\t\t\tsourceURI = URL.createObjectURL( blob );\n\t\t\t\treturn sourceURI;\n\n\t\t\t} );\n\n\t\t} else if ( sourceDef.uri === undefined ) {\n\n\t\t\tthrow new Error( 'THREE.GLTFLoader: Image ' + sourceIndex + ' is missing URI and bufferView' );\n\n\t\t}\n\n\t\tconst promise = Promise.resolve( sourceURI ).then( function ( sourceURI ) {\n\n\t\t\treturn new Promise( function ( resolve, reject ) {\n\n\t\t\t\tlet onLoad = resolve;\n\n\t\t\t\tif ( loader.isImageBitmapLoader === true ) {\n\n\t\t\t\t\tonLoad = function ( imageBitmap ) {\n\n\t\t\t\t\t\tconst texture = new three__WEBPACK_IMPORTED_MODULE_0__.Texture( imageBitmap );\n\t\t\t\t\t\ttexture.needsUpdate = true;\n\n\t\t\t\t\t\tresolve( texture );\n\n\t\t\t\t\t};\n\n\t\t\t\t}\n\n\t\t\t\tloader.load( three__WEBPACK_IMPORTED_MODULE_0__.LoaderUtils.resolveURL( sourceURI, options.path ), onLoad, undefined, reject );\n\n\t\t\t} );\n\n\t\t} ).then( function ( texture ) {\n\n\t\t\t// Clean up resources and configure Texture.\n\n\t\t\tif ( isObjectURL === true ) {\n\n\t\t\t\tURL.revokeObjectURL( sourceURI );\n\n\t\t\t}\n\n\t\t\ttexture.userData.mimeType = sourceDef.mimeType || getImageURIMimeType( sourceDef.uri );\n\n\t\t\treturn texture;\n\n\t\t} ).catch( function ( error ) {\n\n\t\t\tconsole.error( 'THREE.GLTFLoader: Couldn\\'t load texture', sourceURI );\n\t\t\tthrow error;\n\n\t\t} );\n\n\t\tthis.sourceCache[ sourceIndex ] = promise;\n\t\treturn promise;\n\n\t}\n\n\t/**\n\t * Asynchronously assigns a texture to the given material parameters.\n\t * @param {Object} materialParams\n\t * @param {string} mapName\n\t * @param {Object} mapDef\n\t * @return {Promise<Texture>}\n\t */\n\tassignTexture( materialParams, mapName, mapDef ) {\n\n\t\tconst parser = this;\n\n\t\treturn this.getDependency( 'texture', mapDef.index ).then( function ( texture ) {\n\n\t\t\t// Materials sample aoMap from UV set 1 and other maps from UV set 0 - this can't be configured\n\t\t\t// However, we will copy UV set 0 to UV set 1 on demand for aoMap\n\t\t\tif ( mapDef.texCoord !== undefined && mapDef.texCoord != 0 && ! ( mapName === 'aoMap' && mapDef.texCoord == 1 ) ) {\n\n\t\t\t\tconsole.warn( 'THREE.GLTFLoader: Custom UV set ' + mapDef.texCoord + ' for texture ' + mapName + ' not yet supported.' );\n\n\t\t\t}\n\n\t\t\tif ( parser.extensions[ EXTENSIONS.KHR_TEXTURE_TRANSFORM ] ) {\n\n\t\t\t\tconst transform = mapDef.extensions !== undefined ? mapDef.extensions[ EXTENSIONS.KHR_TEXTURE_TRANSFORM ] : undefined;\n\n\t\t\t\tif ( transform ) {\n\n\t\t\t\t\tconst gltfReference = parser.associations.get( texture );\n\t\t\t\t\ttexture = parser.extensions[ EXTENSIONS.KHR_TEXTURE_TRANSFORM ].extendTexture( texture, transform );\n\t\t\t\t\tparser.associations.set( texture, gltfReference );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tmaterialParams[ mapName ] = texture;\n\n\t\t\treturn texture;\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Assigns final material to a Mesh, Line, or Points instance. The instance\n\t * already has a material (generated from the glTF material options alone)\n\t * but reuse of the same glTF material may require multiple threejs materials\n\t * to accommodate different primitive types, defines, etc. New materials will\n\t * be created if necessary, and reused from a cache.\n\t * @param  {Object3D} mesh Mesh, Line, or Points instance.\n\t */\n\tassignFinalMaterial( mesh ) {\n\n\t\tconst geometry = mesh.geometry;\n\t\tlet material = mesh.material;\n\n\t\tconst useDerivativeTangents = geometry.attributes.tangent === undefined;\n\t\tconst useVertexColors = geometry.attributes.color !== undefined;\n\t\tconst useFlatShading = geometry.attributes.normal === undefined;\n\n\t\tif ( mesh.isPoints ) {\n\n\t\t\tconst cacheKey = 'PointsMaterial:' + material.uuid;\n\n\t\t\tlet pointsMaterial = this.cache.get( cacheKey );\n\n\t\t\tif ( ! pointsMaterial ) {\n\n\t\t\t\tpointsMaterial = new three__WEBPACK_IMPORTED_MODULE_0__.PointsMaterial();\n\t\t\t\tthree__WEBPACK_IMPORTED_MODULE_0__.Material.prototype.copy.call( pointsMaterial, material );\n\t\t\t\tpointsMaterial.color.copy( material.color );\n\t\t\t\tpointsMaterial.map = material.map;\n\t\t\t\tpointsMaterial.sizeAttenuation = false; // glTF spec says points should be 1px\n\n\t\t\t\tthis.cache.add( cacheKey, pointsMaterial );\n\n\t\t\t}\n\n\t\t\tmaterial = pointsMaterial;\n\n\t\t} else if ( mesh.isLine ) {\n\n\t\t\tconst cacheKey = 'LineBasicMaterial:' + material.uuid;\n\n\t\t\tlet lineMaterial = this.cache.get( cacheKey );\n\n\t\t\tif ( ! lineMaterial ) {\n\n\t\t\t\tlineMaterial = new three__WEBPACK_IMPORTED_MODULE_0__.LineBasicMaterial();\n\t\t\t\tthree__WEBPACK_IMPORTED_MODULE_0__.Material.prototype.copy.call( lineMaterial, material );\n\t\t\t\tlineMaterial.color.copy( material.color );\n\n\t\t\t\tthis.cache.add( cacheKey, lineMaterial );\n\n\t\t\t}\n\n\t\t\tmaterial = lineMaterial;\n\n\t\t}\n\n\t\t// Clone the material if it will be modified\n\t\tif ( useDerivativeTangents || useVertexColors || useFlatShading ) {\n\n\t\t\tlet cacheKey = 'ClonedMaterial:' + material.uuid + ':';\n\n\t\t\tif ( material.isGLTFSpecularGlossinessMaterial ) cacheKey += 'specular-glossiness:';\n\t\t\tif ( useDerivativeTangents ) cacheKey += 'derivative-tangents:';\n\t\t\tif ( useVertexColors ) cacheKey += 'vertex-colors:';\n\t\t\tif ( useFlatShading ) cacheKey += 'flat-shading:';\n\n\t\t\tlet cachedMaterial = this.cache.get( cacheKey );\n\n\t\t\tif ( ! cachedMaterial ) {\n\n\t\t\t\tcachedMaterial = material.clone();\n\n\t\t\t\tif ( useVertexColors ) cachedMaterial.vertexColors = true;\n\t\t\t\tif ( useFlatShading ) cachedMaterial.flatShading = true;\n\n\t\t\t\tif ( useDerivativeTangents ) {\n\n\t\t\t\t\t// https://github.com/mrdoob/three.js/issues/11438#issuecomment-507003995\n\t\t\t\t\tif ( cachedMaterial.normalScale ) cachedMaterial.normalScale.y *= - 1;\n\t\t\t\t\tif ( cachedMaterial.clearcoatNormalScale ) cachedMaterial.clearcoatNormalScale.y *= - 1;\n\n\t\t\t\t}\n\n\t\t\t\tthis.cache.add( cacheKey, cachedMaterial );\n\n\t\t\t\tthis.associations.set( cachedMaterial, this.associations.get( material ) );\n\n\t\t\t}\n\n\t\t\tmaterial = cachedMaterial;\n\n\t\t}\n\n\t\t// workarounds for mesh and geometry\n\n\t\tif ( material.aoMap && geometry.attributes.uv2 === undefined && geometry.attributes.uv !== undefined ) {\n\n\t\t\tgeometry.setAttribute( 'uv2', geometry.attributes.uv );\n\n\t\t}\n\n\t\tmesh.material = material;\n\n\t}\n\n\tgetMaterialType( /* materialIndex */ ) {\n\n\t\treturn three__WEBPACK_IMPORTED_MODULE_0__.MeshStandardMaterial;\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#materials\n\t * @param {number} materialIndex\n\t * @return {Promise<Material>}\n\t */\n\tloadMaterial( materialIndex ) {\n\n\t\tconst parser = this;\n\t\tconst json = this.json;\n\t\tconst extensions = this.extensions;\n\t\tconst materialDef = json.materials[ materialIndex ];\n\n\t\tlet materialType;\n\t\tconst materialParams = {};\n\t\tconst materialExtensions = materialDef.extensions || {};\n\n\t\tconst pending = [];\n\n\t\tif ( materialExtensions[ EXTENSIONS.KHR_MATERIALS_PBR_SPECULAR_GLOSSINESS ] ) {\n\n\t\t\tconst sgExtension = extensions[ EXTENSIONS.KHR_MATERIALS_PBR_SPECULAR_GLOSSINESS ];\n\t\t\tmaterialType = sgExtension.getMaterialType();\n\t\t\tpending.push( sgExtension.extendParams( materialParams, materialDef, parser ) );\n\n\t\t} else if ( materialExtensions[ EXTENSIONS.KHR_MATERIALS_UNLIT ] ) {\n\n\t\t\tconst kmuExtension = extensions[ EXTENSIONS.KHR_MATERIALS_UNLIT ];\n\t\t\tmaterialType = kmuExtension.getMaterialType();\n\t\t\tpending.push( kmuExtension.extendParams( materialParams, materialDef, parser ) );\n\n\t\t} else {\n\n\t\t\t// Specification:\n\t\t\t// https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#metallic-roughness-material\n\n\t\t\tconst metallicRoughness = materialDef.pbrMetallicRoughness || {};\n\n\t\t\tmaterialParams.color = new three__WEBPACK_IMPORTED_MODULE_0__.Color( 1.0, 1.0, 1.0 );\n\t\t\tmaterialParams.opacity = 1.0;\n\n\t\t\tif ( Array.isArray( metallicRoughness.baseColorFactor ) ) {\n\n\t\t\t\tconst array = metallicRoughness.baseColorFactor;\n\n\t\t\t\tmaterialParams.color.fromArray( array );\n\t\t\t\tmaterialParams.opacity = array[ 3 ];\n\n\t\t\t}\n\n\t\t\tif ( metallicRoughness.baseColorTexture !== undefined ) {\n\n\t\t\t\tpending.push( parser.assignTexture( materialParams, 'map', metallicRoughness.baseColorTexture ) );\n\n\t\t\t}\n\n\t\t\tmaterialParams.metalness = metallicRoughness.metallicFactor !== undefined ? metallicRoughness.metallicFactor : 1.0;\n\t\t\tmaterialParams.roughness = metallicRoughness.roughnessFactor !== undefined ? metallicRoughness.roughnessFactor : 1.0;\n\n\t\t\tif ( metallicRoughness.metallicRoughnessTexture !== undefined ) {\n\n\t\t\t\tpending.push( parser.assignTexture( materialParams, 'metalnessMap', metallicRoughness.metallicRoughnessTexture ) );\n\t\t\t\tpending.push( parser.assignTexture( materialParams, 'roughnessMap', metallicRoughness.metallicRoughnessTexture ) );\n\n\t\t\t}\n\n\t\t\tmaterialType = this._invokeOne( function ( ext ) {\n\n\t\t\t\treturn ext.getMaterialType && ext.getMaterialType( materialIndex );\n\n\t\t\t} );\n\n\t\t\tpending.push( Promise.all( this._invokeAll( function ( ext ) {\n\n\t\t\t\treturn ext.extendMaterialParams && ext.extendMaterialParams( materialIndex, materialParams );\n\n\t\t\t} ) ) );\n\n\t\t}\n\n\t\tif ( materialDef.doubleSided === true ) {\n\n\t\t\tmaterialParams.side = three__WEBPACK_IMPORTED_MODULE_0__.DoubleSide;\n\n\t\t}\n\n\t\tconst alphaMode = materialDef.alphaMode || ALPHA_MODES.OPAQUE;\n\n\t\tif ( alphaMode === ALPHA_MODES.BLEND ) {\n\n\t\t\tmaterialParams.transparent = true;\n\n\t\t\t// See: https://github.com/mrdoob/three.js/issues/17706\n\t\t\tmaterialParams.depthWrite = false;\n\n\t\t} else {\n\n\t\t\tmaterialParams.transparent = false;\n\n\t\t\tif ( alphaMode === ALPHA_MODES.MASK ) {\n\n\t\t\t\tmaterialParams.alphaTest = materialDef.alphaCutoff !== undefined ? materialDef.alphaCutoff : 0.5;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( materialDef.normalTexture !== undefined && materialType !== three__WEBPACK_IMPORTED_MODULE_0__.MeshBasicMaterial ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'normalMap', materialDef.normalTexture ) );\n\n\t\t\tmaterialParams.normalScale = new three__WEBPACK_IMPORTED_MODULE_0__.Vector2( 1, 1 );\n\n\t\t\tif ( materialDef.normalTexture.scale !== undefined ) {\n\n\t\t\t\tconst scale = materialDef.normalTexture.scale;\n\n\t\t\t\tmaterialParams.normalScale.set( scale, scale );\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( materialDef.occlusionTexture !== undefined && materialType !== three__WEBPACK_IMPORTED_MODULE_0__.MeshBasicMaterial ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'aoMap', materialDef.occlusionTexture ) );\n\n\t\t\tif ( materialDef.occlusionTexture.strength !== undefined ) {\n\n\t\t\t\tmaterialParams.aoMapIntensity = materialDef.occlusionTexture.strength;\n\n\t\t\t}\n\n\t\t}\n\n\t\tif ( materialDef.emissiveFactor !== undefined && materialType !== three__WEBPACK_IMPORTED_MODULE_0__.MeshBasicMaterial ) {\n\n\t\t\tmaterialParams.emissive = new three__WEBPACK_IMPORTED_MODULE_0__.Color().fromArray( materialDef.emissiveFactor );\n\n\t\t}\n\n\t\tif ( materialDef.emissiveTexture !== undefined && materialType !== three__WEBPACK_IMPORTED_MODULE_0__.MeshBasicMaterial ) {\n\n\t\t\tpending.push( parser.assignTexture( materialParams, 'emissiveMap', materialDef.emissiveTexture ) );\n\n\t\t}\n\n\t\treturn Promise.all( pending ).then( function () {\n\n\t\t\tlet material;\n\n\t\t\tif ( materialType === GLTFMeshStandardSGMaterial ) {\n\n\t\t\t\tmaterial = extensions[ EXTENSIONS.KHR_MATERIALS_PBR_SPECULAR_GLOSSINESS ].createMaterial( materialParams );\n\n\t\t\t} else {\n\n\t\t\t\tmaterial = new materialType( materialParams );\n\n\t\t\t}\n\n\t\t\tif ( materialDef.name ) material.name = materialDef.name;\n\n\t\t\t// baseColorTexture, emissiveTexture, sheenColorMap, specularColorMap and specularGlossinessTexture use sRGB encoding.\n\t\t\tif ( material.map ) material.map.encoding = three__WEBPACK_IMPORTED_MODULE_0__.sRGBEncoding;\n\t\t\tif ( material.emissiveMap ) material.emissiveMap.encoding = three__WEBPACK_IMPORTED_MODULE_0__.sRGBEncoding;\n\t\t\tif ( material.sheenColorMap ) material.sheenColorMap.encoding = three__WEBPACK_IMPORTED_MODULE_0__.sRGBEncoding;\n\t\t\tif ( material.specularColorMap ) material.specularColorMap.encoding = three__WEBPACK_IMPORTED_MODULE_0__.sRGBEncoding;\n\t\t\tif ( material.specularMap ) material.specularMap.encoding = three__WEBPACK_IMPORTED_MODULE_0__.sRGBEncoding;\n\n\t\t\tassignExtrasToUserData( material, materialDef );\n\n\t\t\tparser.associations.set( material, { materials: materialIndex } );\n\n\t\t\tif ( materialDef.extensions ) addUnknownExtensionsToUserData( extensions, material, materialDef );\n\n\t\t\treturn material;\n\n\t\t} );\n\n\t}\n\n\t/** When Object3D instances are targeted by animation, they need unique names. */\n\tcreateUniqueName( originalName ) {\n\n\t\tconst sanitizedName = three__WEBPACK_IMPORTED_MODULE_0__.PropertyBinding.sanitizeNodeName( originalName || '' );\n\n\t\tlet name = sanitizedName;\n\n\t\tfor ( let i = 1; this.nodeNamesUsed[ name ]; ++ i ) {\n\n\t\t\tname = sanitizedName + '_' + i;\n\n\t\t}\n\n\t\tthis.nodeNamesUsed[ name ] = true;\n\n\t\treturn name;\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#geometry\n\t *\n\t * Creates BufferGeometries from primitives.\n\t *\n\t * @param {Array<GLTF.Primitive>} primitives\n\t * @return {Promise<Array<BufferGeometry>>}\n\t */\n\tloadGeometries( primitives ) {\n\n\t\tconst parser = this;\n\t\tconst extensions = this.extensions;\n\t\tconst cache = this.primitiveCache;\n\n\t\tfunction createDracoPrimitive( primitive ) {\n\n\t\t\treturn extensions[ EXTENSIONS.KHR_DRACO_MESH_COMPRESSION ]\n\t\t\t\t.decodePrimitive( primitive, parser )\n\t\t\t\t.then( function ( geometry ) {\n\n\t\t\t\t\treturn addPrimitiveAttributes( geometry, primitive, parser );\n\n\t\t\t\t} );\n\n\t\t}\n\n\t\tconst pending = [];\n\n\t\tfor ( let i = 0, il = primitives.length; i < il; i ++ ) {\n\n\t\t\tconst primitive = primitives[ i ];\n\t\t\tconst cacheKey = createPrimitiveKey( primitive );\n\n\t\t\t// See if we've already created this geometry\n\t\t\tconst cached = cache[ cacheKey ];\n\n\t\t\tif ( cached ) {\n\n\t\t\t\t// Use the cached geometry if it exists\n\t\t\t\tpending.push( cached.promise );\n\n\t\t\t} else {\n\n\t\t\t\tlet geometryPromise;\n\n\t\t\t\tif ( primitive.extensions && primitive.extensions[ EXTENSIONS.KHR_DRACO_MESH_COMPRESSION ] ) {\n\n\t\t\t\t\t// Use DRACO geometry if available\n\t\t\t\t\tgeometryPromise = createDracoPrimitive( primitive );\n\n\t\t\t\t} else {\n\n\t\t\t\t\t// Otherwise create a new geometry\n\t\t\t\t\tgeometryPromise = addPrimitiveAttributes( new three__WEBPACK_IMPORTED_MODULE_0__.BufferGeometry(), primitive, parser );\n\n\t\t\t\t}\n\n\t\t\t\t// Cache this geometry\n\t\t\t\tcache[ cacheKey ] = { primitive: primitive, promise: geometryPromise };\n\n\t\t\t\tpending.push( geometryPromise );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#meshes\n\t * @param {number} meshIndex\n\t * @return {Promise<Group|Mesh|SkinnedMesh>}\n\t */\n\tloadMesh( meshIndex ) {\n\n\t\tconst parser = this;\n\t\tconst json = this.json;\n\t\tconst extensions = this.extensions;\n\n\t\tconst meshDef = json.meshes[ meshIndex ];\n\t\tconst primitives = meshDef.primitives;\n\n\t\tconst pending = [];\n\n\t\tfor ( let i = 0, il = primitives.length; i < il; i ++ ) {\n\n\t\t\tconst material = primitives[ i ].material === undefined\n\t\t\t\t? createDefaultMaterial( this.cache )\n\t\t\t\t: this.getDependency( 'material', primitives[ i ].material );\n\n\t\t\tpending.push( material );\n\n\t\t}\n\n\t\tpending.push( parser.loadGeometries( primitives ) );\n\n\t\treturn Promise.all( pending ).then( function ( results ) {\n\n\t\t\tconst materials = results.slice( 0, results.length - 1 );\n\t\t\tconst geometries = results[ results.length - 1 ];\n\n\t\t\tconst meshes = [];\n\n\t\t\tfor ( let i = 0, il = geometries.length; i < il; i ++ ) {\n\n\t\t\t\tconst geometry = geometries[ i ];\n\t\t\t\tconst primitive = primitives[ i ];\n\n\t\t\t\t// 1. create Mesh\n\n\t\t\t\tlet mesh;\n\n\t\t\t\tconst material = materials[ i ];\n\n\t\t\t\tif ( primitive.mode === WEBGL_CONSTANTS.TRIANGLES ||\n\t\t\t\t\t\tprimitive.mode === WEBGL_CONSTANTS.TRIANGLE_STRIP ||\n\t\t\t\t\t\tprimitive.mode === WEBGL_CONSTANTS.TRIANGLE_FAN ||\n\t\t\t\t\t\tprimitive.mode === undefined ) {\n\n\t\t\t\t\t// .isSkinnedMesh isn't in glTF spec. See ._markDefs()\n\t\t\t\t\tmesh = meshDef.isSkinnedMesh === true\n\t\t\t\t\t\t? new three__WEBPACK_IMPORTED_MODULE_0__.SkinnedMesh( geometry, material )\n\t\t\t\t\t\t: new three__WEBPACK_IMPORTED_MODULE_0__.Mesh( geometry, material );\n\n\t\t\t\t\tif ( mesh.isSkinnedMesh === true && ! mesh.geometry.attributes.skinWeight.normalized ) {\n\n\t\t\t\t\t\t// we normalize floating point skin weight array to fix malformed assets (see #15319)\n\t\t\t\t\t\t// it's important to skip this for non-float32 data since normalizeSkinWeights assumes non-normalized inputs\n\t\t\t\t\t\tmesh.normalizeSkinWeights();\n\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( primitive.mode === WEBGL_CONSTANTS.TRIANGLE_STRIP ) {\n\n\t\t\t\t\t\tmesh.geometry = toTrianglesDrawMode( mesh.geometry, three__WEBPACK_IMPORTED_MODULE_0__.TriangleStripDrawMode );\n\n\t\t\t\t\t} else if ( primitive.mode === WEBGL_CONSTANTS.TRIANGLE_FAN ) {\n\n\t\t\t\t\t\tmesh.geometry = toTrianglesDrawMode( mesh.geometry, three__WEBPACK_IMPORTED_MODULE_0__.TriangleFanDrawMode );\n\n\t\t\t\t\t}\n\n\t\t\t\t} else if ( primitive.mode === WEBGL_CONSTANTS.LINES ) {\n\n\t\t\t\t\tmesh = new three__WEBPACK_IMPORTED_MODULE_0__.LineSegments( geometry, material );\n\n\t\t\t\t} else if ( primitive.mode === WEBGL_CONSTANTS.LINE_STRIP ) {\n\n\t\t\t\t\tmesh = new three__WEBPACK_IMPORTED_MODULE_0__.Line( geometry, material );\n\n\t\t\t\t} else if ( primitive.mode === WEBGL_CONSTANTS.LINE_LOOP ) {\n\n\t\t\t\t\tmesh = new three__WEBPACK_IMPORTED_MODULE_0__.LineLoop( geometry, material );\n\n\t\t\t\t} else if ( primitive.mode === WEBGL_CONSTANTS.POINTS ) {\n\n\t\t\t\t\tmesh = new three__WEBPACK_IMPORTED_MODULE_0__.Points( geometry, material );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tthrow new Error( 'THREE.GLTFLoader: Primitive mode unsupported: ' + primitive.mode );\n\n\t\t\t\t}\n\n\t\t\t\tif ( Object.keys( mesh.geometry.morphAttributes ).length > 0 ) {\n\n\t\t\t\t\tupdateMorphTargets( mesh, meshDef );\n\n\t\t\t\t}\n\n\t\t\t\tmesh.name = parser.createUniqueName( meshDef.name || ( 'mesh_' + meshIndex ) );\n\n\t\t\t\tassignExtrasToUserData( mesh, meshDef );\n\n\t\t\t\tif ( primitive.extensions ) addUnknownExtensionsToUserData( extensions, mesh, primitive );\n\n\t\t\t\tparser.assignFinalMaterial( mesh );\n\n\t\t\t\tmeshes.push( mesh );\n\n\t\t\t}\n\n\t\t\tfor ( let i = 0, il = meshes.length; i < il; i ++ ) {\n\n\t\t\t\tparser.associations.set( meshes[ i ], {\n\t\t\t\t\tmeshes: meshIndex,\n\t\t\t\t\tprimitives: i\n\t\t\t\t} );\n\n\t\t\t}\n\n\t\t\tif ( meshes.length === 1 ) {\n\n\t\t\t\treturn meshes[ 0 ];\n\n\t\t\t}\n\n\t\t\tconst group = new three__WEBPACK_IMPORTED_MODULE_0__.Group();\n\n\t\t\tparser.associations.set( group, { meshes: meshIndex } );\n\n\t\t\tfor ( let i = 0, il = meshes.length; i < il; i ++ ) {\n\n\t\t\t\tgroup.add( meshes[ i ] );\n\n\t\t\t}\n\n\t\t\treturn group;\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#cameras\n\t * @param {number} cameraIndex\n\t * @return {Promise<THREE.Camera>}\n\t */\n\tloadCamera( cameraIndex ) {\n\n\t\tlet camera;\n\t\tconst cameraDef = this.json.cameras[ cameraIndex ];\n\t\tconst params = cameraDef[ cameraDef.type ];\n\n\t\tif ( ! params ) {\n\n\t\t\tconsole.warn( 'THREE.GLTFLoader: Missing camera parameters.' );\n\t\t\treturn;\n\n\t\t}\n\n\t\tif ( cameraDef.type === 'perspective' ) {\n\n\t\t\tcamera = new three__WEBPACK_IMPORTED_MODULE_0__.PerspectiveCamera( three__WEBPACK_IMPORTED_MODULE_0__.MathUtils.radToDeg( params.yfov ), params.aspectRatio || 1, params.znear || 1, params.zfar || 2e6 );\n\n\t\t} else if ( cameraDef.type === 'orthographic' ) {\n\n\t\t\tcamera = new three__WEBPACK_IMPORTED_MODULE_0__.OrthographicCamera( - params.xmag, params.xmag, params.ymag, - params.ymag, params.znear, params.zfar );\n\n\t\t}\n\n\t\tif ( cameraDef.name ) camera.name = this.createUniqueName( cameraDef.name );\n\n\t\tassignExtrasToUserData( camera, cameraDef );\n\n\t\treturn Promise.resolve( camera );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#skins\n\t * @param {number} skinIndex\n\t * @return {Promise<Object>}\n\t */\n\tloadSkin( skinIndex ) {\n\n\t\tconst skinDef = this.json.skins[ skinIndex ];\n\n\t\tconst skinEntry = { joints: skinDef.joints };\n\n\t\tif ( skinDef.inverseBindMatrices === undefined ) {\n\n\t\t\treturn Promise.resolve( skinEntry );\n\n\t\t}\n\n\t\treturn this.getDependency( 'accessor', skinDef.inverseBindMatrices ).then( function ( accessor ) {\n\n\t\t\tskinEntry.inverseBindMatrices = accessor;\n\n\t\t\treturn skinEntry;\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#animations\n\t * @param {number} animationIndex\n\t * @return {Promise<AnimationClip>}\n\t */\n\tloadAnimation( animationIndex ) {\n\n\t\tconst json = this.json;\n\n\t\tconst animationDef = json.animations[ animationIndex ];\n\n\t\tconst pendingNodes = [];\n\t\tconst pendingInputAccessors = [];\n\t\tconst pendingOutputAccessors = [];\n\t\tconst pendingSamplers = [];\n\t\tconst pendingTargets = [];\n\n\t\tfor ( let i = 0, il = animationDef.channels.length; i < il; i ++ ) {\n\n\t\t\tconst channel = animationDef.channels[ i ];\n\t\t\tconst sampler = animationDef.samplers[ channel.sampler ];\n\t\t\tconst target = channel.target;\n\t\t\tconst name = target.node !== undefined ? target.node : target.id; // NOTE: target.id is deprecated.\n\t\t\tconst input = animationDef.parameters !== undefined ? animationDef.parameters[ sampler.input ] : sampler.input;\n\t\t\tconst output = animationDef.parameters !== undefined ? animationDef.parameters[ sampler.output ] : sampler.output;\n\n\t\t\tpendingNodes.push( this.getDependency( 'node', name ) );\n\t\t\tpendingInputAccessors.push( this.getDependency( 'accessor', input ) );\n\t\t\tpendingOutputAccessors.push( this.getDependency( 'accessor', output ) );\n\t\t\tpendingSamplers.push( sampler );\n\t\t\tpendingTargets.push( target );\n\n\t\t}\n\n\t\treturn Promise.all( [\n\n\t\t\tPromise.all( pendingNodes ),\n\t\t\tPromise.all( pendingInputAccessors ),\n\t\t\tPromise.all( pendingOutputAccessors ),\n\t\t\tPromise.all( pendingSamplers ),\n\t\t\tPromise.all( pendingTargets )\n\n\t\t] ).then( function ( dependencies ) {\n\n\t\t\tconst nodes = dependencies[ 0 ];\n\t\t\tconst inputAccessors = dependencies[ 1 ];\n\t\t\tconst outputAccessors = dependencies[ 2 ];\n\t\t\tconst samplers = dependencies[ 3 ];\n\t\t\tconst targets = dependencies[ 4 ];\n\n\t\t\tconst tracks = [];\n\n\t\t\tfor ( let i = 0, il = nodes.length; i < il; i ++ ) {\n\n\t\t\t\tconst node = nodes[ i ];\n\t\t\t\tconst inputAccessor = inputAccessors[ i ];\n\t\t\t\tconst outputAccessor = outputAccessors[ i ];\n\t\t\t\tconst sampler = samplers[ i ];\n\t\t\t\tconst target = targets[ i ];\n\n\t\t\t\tif ( node === undefined ) continue;\n\n\t\t\t\tnode.updateMatrix();\n\t\t\t\tnode.matrixAutoUpdate = true;\n\n\t\t\t\tlet TypedKeyframeTrack;\n\n\t\t\t\tswitch ( PATH_PROPERTIES[ target.path ] ) {\n\n\t\t\t\t\tcase PATH_PROPERTIES.weights:\n\n\t\t\t\t\t\tTypedKeyframeTrack = three__WEBPACK_IMPORTED_MODULE_0__.NumberKeyframeTrack;\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase PATH_PROPERTIES.rotation:\n\n\t\t\t\t\t\tTypedKeyframeTrack = three__WEBPACK_IMPORTED_MODULE_0__.QuaternionKeyframeTrack;\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tcase PATH_PROPERTIES.position:\n\t\t\t\t\tcase PATH_PROPERTIES.scale:\n\t\t\t\t\tdefault:\n\n\t\t\t\t\t\tTypedKeyframeTrack = three__WEBPACK_IMPORTED_MODULE_0__.VectorKeyframeTrack;\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t}\n\n\t\t\t\tconst targetName = node.name ? node.name : node.uuid;\n\n\t\t\t\tconst interpolation = sampler.interpolation !== undefined ? INTERPOLATION[ sampler.interpolation ] : three__WEBPACK_IMPORTED_MODULE_0__.InterpolateLinear;\n\n\t\t\t\tconst targetNames = [];\n\n\t\t\t\tif ( PATH_PROPERTIES[ target.path ] === PATH_PROPERTIES.weights ) {\n\n\t\t\t\t\tnode.traverse( function ( object ) {\n\n\t\t\t\t\t\tif ( object.morphTargetInfluences ) {\n\n\t\t\t\t\t\t\ttargetNames.push( object.name ? object.name : object.uuid );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t} );\n\n\t\t\t\t} else {\n\n\t\t\t\t\ttargetNames.push( targetName );\n\n\t\t\t\t}\n\n\t\t\t\tlet outputArray = outputAccessor.array;\n\n\t\t\t\tif ( outputAccessor.normalized ) {\n\n\t\t\t\t\tconst scale = getNormalizedComponentScale( outputArray.constructor );\n\t\t\t\t\tconst scaled = new Float32Array( outputArray.length );\n\n\t\t\t\t\tfor ( let j = 0, jl = outputArray.length; j < jl; j ++ ) {\n\n\t\t\t\t\t\tscaled[ j ] = outputArray[ j ] * scale;\n\n\t\t\t\t\t}\n\n\t\t\t\t\toutputArray = scaled;\n\n\t\t\t\t}\n\n\t\t\t\tfor ( let j = 0, jl = targetNames.length; j < jl; j ++ ) {\n\n\t\t\t\t\tconst track = new TypedKeyframeTrack(\n\t\t\t\t\t\ttargetNames[ j ] + '.' + PATH_PROPERTIES[ target.path ],\n\t\t\t\t\t\tinputAccessor.array,\n\t\t\t\t\t\toutputArray,\n\t\t\t\t\t\tinterpolation\n\t\t\t\t\t);\n\n\t\t\t\t\t// Override interpolation with custom factory method.\n\t\t\t\t\tif ( sampler.interpolation === 'CUBICSPLINE' ) {\n\n\t\t\t\t\t\ttrack.createInterpolant = function InterpolantFactoryMethodGLTFCubicSpline( result ) {\n\n\t\t\t\t\t\t\t// A CUBICSPLINE keyframe in glTF has three output values for each input value,\n\t\t\t\t\t\t\t// representing inTangent, splineVertex, and outTangent. As a result, track.getValueSize()\n\t\t\t\t\t\t\t// must be divided by three to get the interpolant's sampleSize argument.\n\n\t\t\t\t\t\t\tconst interpolantType = ( this instanceof three__WEBPACK_IMPORTED_MODULE_0__.QuaternionKeyframeTrack ) ? GLTFCubicSplineQuaternionInterpolant : GLTFCubicSplineInterpolant;\n\n\t\t\t\t\t\t\treturn new interpolantType( this.times, this.values, this.getValueSize() / 3, result );\n\n\t\t\t\t\t\t};\n\n\t\t\t\t\t\t// Mark as CUBICSPLINE. `track.getInterpolation()` doesn't support custom interpolants.\n\t\t\t\t\t\ttrack.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline = true;\n\n\t\t\t\t\t}\n\n\t\t\t\t\ttracks.push( track );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tconst name = animationDef.name ? animationDef.name : 'animation_' + animationIndex;\n\n\t\t\treturn new three__WEBPACK_IMPORTED_MODULE_0__.AnimationClip( name, undefined, tracks );\n\n\t\t} );\n\n\t}\n\n\tcreateNodeMesh( nodeIndex ) {\n\n\t\tconst json = this.json;\n\t\tconst parser = this;\n\t\tconst nodeDef = json.nodes[ nodeIndex ];\n\n\t\tif ( nodeDef.mesh === undefined ) return null;\n\n\t\treturn parser.getDependency( 'mesh', nodeDef.mesh ).then( function ( mesh ) {\n\n\t\t\tconst node = parser._getNodeRef( parser.meshCache, nodeDef.mesh, mesh );\n\n\t\t\t// if weights are provided on the node, override weights on the mesh.\n\t\t\tif ( nodeDef.weights !== undefined ) {\n\n\t\t\t\tnode.traverse( function ( o ) {\n\n\t\t\t\t\tif ( ! o.isMesh ) return;\n\n\t\t\t\t\tfor ( let i = 0, il = nodeDef.weights.length; i < il; i ++ ) {\n\n\t\t\t\t\t\to.morphTargetInfluences[ i ] = nodeDef.weights[ i ];\n\n\t\t\t\t\t}\n\n\t\t\t\t} );\n\n\t\t\t}\n\n\t\t\treturn node;\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#nodes-and-hierarchy\n\t * @param {number} nodeIndex\n\t * @return {Promise<Object3D>}\n\t */\n\tloadNode( nodeIndex ) {\n\n\t\tconst json = this.json;\n\t\tconst extensions = this.extensions;\n\t\tconst parser = this;\n\n\t\tconst nodeDef = json.nodes[ nodeIndex ];\n\n\t\t// reserve node's name before its dependencies, so the root has the intended name.\n\t\tconst nodeName = nodeDef.name ? parser.createUniqueName( nodeDef.name ) : '';\n\n\t\treturn ( function () {\n\n\t\t\tconst pending = [];\n\n\t\t\tconst meshPromise = parser._invokeOne( function ( ext ) {\n\n\t\t\t\treturn ext.createNodeMesh && ext.createNodeMesh( nodeIndex );\n\n\t\t\t} );\n\n\t\t\tif ( meshPromise ) {\n\n\t\t\t\tpending.push( meshPromise );\n\n\t\t\t}\n\n\t\t\tif ( nodeDef.camera !== undefined ) {\n\n\t\t\t\tpending.push( parser.getDependency( 'camera', nodeDef.camera ).then( function ( camera ) {\n\n\t\t\t\t\treturn parser._getNodeRef( parser.cameraCache, nodeDef.camera, camera );\n\n\t\t\t\t} ) );\n\n\t\t\t}\n\n\t\t\tparser._invokeAll( function ( ext ) {\n\n\t\t\t\treturn ext.createNodeAttachment && ext.createNodeAttachment( nodeIndex );\n\n\t\t\t} ).forEach( function ( promise ) {\n\n\t\t\t\tpending.push( promise );\n\n\t\t\t} );\n\n\t\t\treturn Promise.all( pending );\n\n\t\t}() ).then( function ( objects ) {\n\n\t\t\tlet node;\n\n\t\t\t// .isBone isn't in glTF spec. See ._markDefs\n\t\t\tif ( nodeDef.isBone === true ) {\n\n\t\t\t\tnode = new three__WEBPACK_IMPORTED_MODULE_0__.Bone();\n\n\t\t\t} else if ( objects.length > 1 ) {\n\n\t\t\t\tnode = new three__WEBPACK_IMPORTED_MODULE_0__.Group();\n\n\t\t\t} else if ( objects.length === 1 ) {\n\n\t\t\t\tnode = objects[ 0 ];\n\n\t\t\t} else {\n\n\t\t\t\tnode = new three__WEBPACK_IMPORTED_MODULE_0__.Object3D();\n\n\t\t\t}\n\n\t\t\tif ( node !== objects[ 0 ] ) {\n\n\t\t\t\tfor ( let i = 0, il = objects.length; i < il; i ++ ) {\n\n\t\t\t\t\tnode.add( objects[ i ] );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( nodeDef.name ) {\n\n\t\t\t\tnode.userData.name = nodeDef.name;\n\t\t\t\tnode.name = nodeName;\n\n\t\t\t}\n\n\t\t\tassignExtrasToUserData( node, nodeDef );\n\n\t\t\tif ( nodeDef.extensions ) addUnknownExtensionsToUserData( extensions, node, nodeDef );\n\n\t\t\tif ( nodeDef.matrix !== undefined ) {\n\n\t\t\t\tconst matrix = new three__WEBPACK_IMPORTED_MODULE_0__.Matrix4();\n\t\t\t\tmatrix.fromArray( nodeDef.matrix );\n\t\t\t\tnode.applyMatrix4( matrix );\n\n\t\t\t} else {\n\n\t\t\t\tif ( nodeDef.translation !== undefined ) {\n\n\t\t\t\t\tnode.position.fromArray( nodeDef.translation );\n\n\t\t\t\t}\n\n\t\t\t\tif ( nodeDef.rotation !== undefined ) {\n\n\t\t\t\t\tnode.quaternion.fromArray( nodeDef.rotation );\n\n\t\t\t\t}\n\n\t\t\t\tif ( nodeDef.scale !== undefined ) {\n\n\t\t\t\t\tnode.scale.fromArray( nodeDef.scale );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\tif ( ! parser.associations.has( node ) ) {\n\n\t\t\t\tparser.associations.set( node, {} );\n\n\t\t\t}\n\n\t\t\tparser.associations.get( node ).nodes = nodeIndex;\n\n\t\t\treturn node;\n\n\t\t} );\n\n\t}\n\n\t/**\n\t * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#scenes\n\t * @param {number} sceneIndex\n\t * @return {Promise<Group>}\n\t */\n\tloadScene( sceneIndex ) {\n\n\t\tconst json = this.json;\n\t\tconst extensions = this.extensions;\n\t\tconst sceneDef = this.json.scenes[ sceneIndex ];\n\t\tconst parser = this;\n\n\t\t// Loader returns Group, not Scene.\n\t\t// See: https://github.com/mrdoob/three.js/issues/18342#issuecomment-578981172\n\t\tconst scene = new three__WEBPACK_IMPORTED_MODULE_0__.Group();\n\t\tif ( sceneDef.name ) scene.name = parser.createUniqueName( sceneDef.name );\n\n\t\tassignExtrasToUserData( scene, sceneDef );\n\n\t\tif ( sceneDef.extensions ) addUnknownExtensionsToUserData( extensions, scene, sceneDef );\n\n\t\tconst nodeIds = sceneDef.nodes || [];\n\n\t\tconst pending = [];\n\n\t\tfor ( let i = 0, il = nodeIds.length; i < il; i ++ ) {\n\n\t\t\tpending.push( buildNodeHierarchy( nodeIds[ i ], scene, json, parser ) );\n\n\t\t}\n\n\t\treturn Promise.all( pending ).then( function () {\n\n\t\t\t// Removes dangling associations, associations that reference a node that\n\t\t\t// didn't make it into the scene.\n\t\t\tconst reduceAssociations = ( node ) => {\n\n\t\t\t\tconst reducedAssociations = new Map();\n\n\t\t\t\tfor ( const [ key, value ] of parser.associations ) {\n\n\t\t\t\t\tif ( key instanceof three__WEBPACK_IMPORTED_MODULE_0__.Material || key instanceof three__WEBPACK_IMPORTED_MODULE_0__.Texture ) {\n\n\t\t\t\t\t\treducedAssociations.set( key, value );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tnode.traverse( ( node ) => {\n\n\t\t\t\t\tconst mappings = parser.associations.get( node );\n\n\t\t\t\t\tif ( mappings != null ) {\n\n\t\t\t\t\t\treducedAssociations.set( node, mappings );\n\n\t\t\t\t\t}\n\n\t\t\t\t} );\n\n\t\t\t\treturn reducedAssociations;\n\n\t\t\t};\n\n\t\t\tparser.associations = reduceAssociations( scene );\n\n\t\t\treturn scene;\n\n\t\t} );\n\n\t}\n\n}\n\nfunction buildNodeHierarchy( nodeId, parentObject, json, parser ) {\n\n\tconst nodeDef = json.nodes[ nodeId ];\n\n\treturn parser.getDependency( 'node', nodeId ).then( function ( node ) {\n\n\t\tif ( nodeDef.skin === undefined ) return node;\n\n\t\t// build skeleton here as well\n\n\t\tlet skinEntry;\n\n\t\treturn parser.getDependency( 'skin', nodeDef.skin ).then( function ( skin ) {\n\n\t\t\tskinEntry = skin;\n\n\t\t\tconst pendingJoints = [];\n\n\t\t\tfor ( let i = 0, il = skinEntry.joints.length; i < il; i ++ ) {\n\n\t\t\t\tpendingJoints.push( parser.getDependency( 'node', skinEntry.joints[ i ] ) );\n\n\t\t\t}\n\n\t\t\treturn Promise.all( pendingJoints );\n\n\t\t} ).then( function ( jointNodes ) {\n\n\t\t\tnode.traverse( function ( mesh ) {\n\n\t\t\t\tif ( ! mesh.isMesh ) return;\n\n\t\t\t\tconst bones = [];\n\t\t\t\tconst boneInverses = [];\n\n\t\t\t\tfor ( let j = 0, jl = jointNodes.length; j < jl; j ++ ) {\n\n\t\t\t\t\tconst jointNode = jointNodes[ j ];\n\n\t\t\t\t\tif ( jointNode ) {\n\n\t\t\t\t\t\tbones.push( jointNode );\n\n\t\t\t\t\t\tconst mat = new three__WEBPACK_IMPORTED_MODULE_0__.Matrix4();\n\n\t\t\t\t\t\tif ( skinEntry.inverseBindMatrices !== undefined ) {\n\n\t\t\t\t\t\t\tmat.fromArray( skinEntry.inverseBindMatrices.array, j * 16 );\n\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tboneInverses.push( mat );\n\n\t\t\t\t\t} else {\n\n\t\t\t\t\t\tconsole.warn( 'THREE.GLTFLoader: Joint \"%s\" could not be found.', skinEntry.joints[ j ] );\n\n\t\t\t\t\t}\n\n\t\t\t\t}\n\n\t\t\t\tmesh.bind( new three__WEBPACK_IMPORTED_MODULE_0__.Skeleton( bones, boneInverses ), mesh.matrixWorld );\n\n\t\t\t} );\n\n\t\t\treturn node;\n\n\t\t} );\n\n\t} ).then( function ( node ) {\n\n\t\t// build node hierachy\n\n\t\tparentObject.add( node );\n\n\t\tconst pending = [];\n\n\t\tif ( nodeDef.children ) {\n\n\t\t\tconst children = nodeDef.children;\n\n\t\t\tfor ( let i = 0, il = children.length; i < il; i ++ ) {\n\n\t\t\t\tconst child = children[ i ];\n\t\t\t\tpending.push( buildNodeHierarchy( child, node, json, parser ) );\n\n\t\t\t}\n\n\t\t}\n\n\t\treturn Promise.all( pending );\n\n\t} );\n\n}\n\n/**\n * @param {BufferGeometry} geometry\n * @param {GLTF.Primitive} primitiveDef\n * @param {GLTFParser} parser\n */\nfunction computeBounds( geometry, primitiveDef, parser ) {\n\n\tconst attributes = primitiveDef.attributes;\n\n\tconst box = new three__WEBPACK_IMPORTED_MODULE_0__.Box3();\n\n\tif ( attributes.POSITION !== undefined ) {\n\n\t\tconst accessor = parser.json.accessors[ attributes.POSITION ];\n\n\t\tconst min = accessor.min;\n\t\tconst max = accessor.max;\n\n\t\t// glTF requires 'min' and 'max', but VRM (which extends glTF) currently ignores that requirement.\n\n\t\tif ( min !== undefined && max !== undefined ) {\n\n\t\t\tbox.set(\n\t\t\t\tnew three__WEBPACK_IMPORTED_MODULE_0__.Vector3( min[ 0 ], min[ 1 ], min[ 2 ] ),\n\t\t\t\tnew three__WEBPACK_IMPORTED_MODULE_0__.Vector3( max[ 0 ], max[ 1 ], max[ 2 ] )\n\t\t\t);\n\n\t\t\tif ( accessor.normalized ) {\n\n\t\t\t\tconst boxScale = getNormalizedComponentScale( WEBGL_COMPONENT_TYPES[ accessor.componentType ] );\n\t\t\t\tbox.min.multiplyScalar( boxScale );\n\t\t\t\tbox.max.multiplyScalar( boxScale );\n\n\t\t\t}\n\n\t\t} else {\n\n\t\t\tconsole.warn( 'THREE.GLTFLoader: Missing min/max properties for accessor POSITION.' );\n\n\t\t\treturn;\n\n\t\t}\n\n\t} else {\n\n\t\treturn;\n\n\t}\n\n\tconst targets = primitiveDef.targets;\n\n\tif ( targets !== undefined ) {\n\n\t\tconst maxDisplacement = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\t\tconst vector = new three__WEBPACK_IMPORTED_MODULE_0__.Vector3();\n\n\t\tfor ( let i = 0, il = targets.length; i < il; i ++ ) {\n\n\t\t\tconst target = targets[ i ];\n\n\t\t\tif ( target.POSITION !== undefined ) {\n\n\t\t\t\tconst accessor = parser.json.accessors[ target.POSITION ];\n\t\t\t\tconst min = accessor.min;\n\t\t\t\tconst max = accessor.max;\n\n\t\t\t\t// glTF requires 'min' and 'max', but VRM (which extends glTF) currently ignores that requirement.\n\n\t\t\t\tif ( min !== undefined && max !== undefined ) {\n\n\t\t\t\t\t// we need to get max of absolute components because target weight is [-1,1]\n\t\t\t\t\tvector.setX( Math.max( Math.abs( min[ 0 ] ), Math.abs( max[ 0 ] ) ) );\n\t\t\t\t\tvector.setY( Math.max( Math.abs( min[ 1 ] ), Math.abs( max[ 1 ] ) ) );\n\t\t\t\t\tvector.setZ( Math.max( Math.abs( min[ 2 ] ), Math.abs( max[ 2 ] ) ) );\n\n\n\t\t\t\t\tif ( accessor.normalized ) {\n\n\t\t\t\t\t\tconst boxScale = getNormalizedComponentScale( WEBGL_COMPONENT_TYPES[ accessor.componentType ] );\n\t\t\t\t\t\tvector.multiplyScalar( boxScale );\n\n\t\t\t\t\t}\n\n\t\t\t\t\t// Note: this assumes that the sum of all weights is at most 1. This isn't quite correct - it's more conservative\n\t\t\t\t\t// to assume that each target can have a max weight of 1. However, for some use cases - notably, when morph targets\n\t\t\t\t\t// are used to implement key-frame animations and as such only two are active at a time - this results in very large\n\t\t\t\t\t// boxes. So for now we make a box that's sometimes a touch too small but is hopefully mostly of reasonable size.\n\t\t\t\t\tmaxDisplacement.max( vector );\n\n\t\t\t\t} else {\n\n\t\t\t\t\tconsole.warn( 'THREE.GLTFLoader: Missing min/max properties for accessor POSITION.' );\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t}\n\n\t\t// As per comment above this box isn't conservative, but has a reasonable size for a very large number of morph targets.\n\t\tbox.expandByVector( maxDisplacement );\n\n\t}\n\n\tgeometry.boundingBox = box;\n\n\tconst sphere = new three__WEBPACK_IMPORTED_MODULE_0__.Sphere();\n\n\tbox.getCenter( sphere.center );\n\tsphere.radius = box.min.distanceTo( box.max ) / 2;\n\n\tgeometry.boundingSphere = sphere;\n\n}\n\n/**\n * @param {BufferGeometry} geometry\n * @param {GLTF.Primitive} primitiveDef\n * @param {GLTFParser} parser\n * @return {Promise<BufferGeometry>}\n */\nfunction addPrimitiveAttributes( geometry, primitiveDef, parser ) {\n\n\tconst attributes = primitiveDef.attributes;\n\n\tconst pending = [];\n\n\tfunction assignAttributeAccessor( accessorIndex, attributeName ) {\n\n\t\treturn parser.getDependency( 'accessor', accessorIndex )\n\t\t\t.then( function ( accessor ) {\n\n\t\t\t\tgeometry.setAttribute( attributeName, accessor );\n\n\t\t\t} );\n\n\t}\n\n\tfor ( const gltfAttributeName in attributes ) {\n\n\t\tconst threeAttributeName = ATTRIBUTES[ gltfAttributeName ] || gltfAttributeName.toLowerCase();\n\n\t\t// Skip attributes already provided by e.g. Draco extension.\n\t\tif ( threeAttributeName in geometry.attributes ) continue;\n\n\t\tpending.push( assignAttributeAccessor( attributes[ gltfAttributeName ], threeAttributeName ) );\n\n\t}\n\n\tif ( primitiveDef.indices !== undefined && ! geometry.index ) {\n\n\t\tconst accessor = parser.getDependency( 'accessor', primitiveDef.indices ).then( function ( accessor ) {\n\n\t\t\tgeometry.setIndex( accessor );\n\n\t\t} );\n\n\t\tpending.push( accessor );\n\n\t}\n\n\tassignExtrasToUserData( geometry, primitiveDef );\n\n\tcomputeBounds( geometry, primitiveDef, parser );\n\n\treturn Promise.all( pending ).then( function () {\n\n\t\treturn primitiveDef.targets !== undefined\n\t\t\t? addMorphTargets( geometry, primitiveDef.targets, parser )\n\t\t\t: geometry;\n\n\t} );\n\n}\n\n/**\n * @param {BufferGeometry} geometry\n * @param {Number} drawMode\n * @return {BufferGeometry}\n */\nfunction toTrianglesDrawMode( geometry, drawMode ) {\n\n\tlet index = geometry.getIndex();\n\n\t// generate index if not present\n\n\tif ( index === null ) {\n\n\t\tconst indices = [];\n\n\t\tconst position = geometry.getAttribute( 'position' );\n\n\t\tif ( position !== undefined ) {\n\n\t\t\tfor ( let i = 0; i < position.count; i ++ ) {\n\n\t\t\t\tindices.push( i );\n\n\t\t\t}\n\n\t\t\tgeometry.setIndex( indices );\n\t\t\tindex = geometry.getIndex();\n\n\t\t} else {\n\n\t\t\tconsole.error( 'THREE.GLTFLoader.toTrianglesDrawMode(): Undefined position attribute. Processing not possible.' );\n\t\t\treturn geometry;\n\n\t\t}\n\n\t}\n\n\t//\n\n\tconst numberOfTriangles = index.count - 2;\n\tconst newIndices = [];\n\n\tif ( drawMode === three__WEBPACK_IMPORTED_MODULE_0__.TriangleFanDrawMode ) {\n\n\t\t// gl.TRIANGLE_FAN\n\n\t\tfor ( let i = 1; i <= numberOfTriangles; i ++ ) {\n\n\t\t\tnewIndices.push( index.getX( 0 ) );\n\t\t\tnewIndices.push( index.getX( i ) );\n\t\t\tnewIndices.push( index.getX( i + 1 ) );\n\n\t\t}\n\n\t} else {\n\n\t\t// gl.TRIANGLE_STRIP\n\n\t\tfor ( let i = 0; i < numberOfTriangles; i ++ ) {\n\n\t\t\tif ( i % 2 === 0 ) {\n\n\t\t\t\tnewIndices.push( index.getX( i ) );\n\t\t\t\tnewIndices.push( index.getX( i + 1 ) );\n\t\t\t\tnewIndices.push( index.getX( i + 2 ) );\n\n\n\t\t\t} else {\n\n\t\t\t\tnewIndices.push( index.getX( i + 2 ) );\n\t\t\t\tnewIndices.push( index.getX( i + 1 ) );\n\t\t\t\tnewIndices.push( index.getX( i ) );\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\tif ( ( newIndices.length / 3 ) !== numberOfTriangles ) {\n\n\t\tconsole.error( 'THREE.GLTFLoader.toTrianglesDrawMode(): Unable to generate correct amount of triangles.' );\n\n\t}\n\n\t// build final geometry\n\n\tconst newGeometry = geometry.clone();\n\tnewGeometry.setIndex( newIndices );\n\n\treturn newGeometry;\n\n}\n\n\n\n\n//# sourceURL=webpack://Something/./node_modules/three/examples/jsm/loaders/GLTFLoader.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ })()
;